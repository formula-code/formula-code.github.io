{"version": 2, "width": 160, "height": 40, "timestamp": 1762942236, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[0.006, "o", "\u001b[?2004l\r\n\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n\u001b[0;31masciinema: use --append option if you want to append to existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[5.006, "o", "\u001b[?2004l\r\n\u001b[H\u001b[J\r\n"]
[10.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.006, "o", "\u001b[?2004l\r\ntotal 212\r\ndrwxr-xr-x 1 root root  4096 Oct  1 17:26 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 15 17:10 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root   971 Sep 12 21:42 .devcontainer.json\r\ndrwxr-xr-x 1 root root  4096 Oct  1 17:19 \u001b[01;34m.git\u001b[0m\r\n-rw-r--r-- 1 root root  1866 Sep 12 21:44 .gitattributes\r\ndrwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34m.github\u001b[0m\r\n-rw-r--r-- 1 root root  2004 Sep 12 21:42 .gitignore\r\n-rw-r--r-- 1 root root  2280 Sep 12 21:42 .gitpod.yml\r\n-rw-r--r-- 1 root root 11223 Sep 12 21:44 .pre-commit-config.yaml\r\n-rw-r--r-- 1 root root  2284 Sep 12 21:44 AUTHORS.md\r\n-rw-r--r-- 1 root root  1541 Sep 12 21:42 CITATION.cff\r\n-rw-r--r-- 1 root root   494 Sep 12 21:44 Dockerfile\r\n-rw-r--r-- 1 root root  1634 Sep 12 21:42 LICENSE\r\ndrwxr-xr-x 2 root root  4096 Sep 12 21:42 \u001b[01;34mLICENSES\u001b[0m\r\n-rw-r--r-- 1 root root  1531 Sep 12 21:44 MANIFEST.in\r\n-rw-r--r-- 1 root root 11661 Sep 12 21:44 README.md\r\ndrwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34masv_bench\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 14 00:14 \u001b[01;34mbuild\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mci\u001b[0m\r\n-rw-r--r-- 1 root root   256 Sep 12 21:42 codecov.yml\r\ndrwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mdoc\u001b[0m\r\n-rw-r--r-- 1 root root  2897 Sep 12 21:44 environment.yml\r\n-rw-r--r-- 1 root root   866 Sep 12 21:42 generate_pxi.py\r\n-rw-r--r-- 1 root root  1715 Sep 12 21:42 generate_version.py\r\ndrwxr-xr-x 2 root root  4096 Sep 12 21:42 \u001b[01;34mgitpod\u001b[0m\r\n-rw-r--r-- 1 root root  1774 Sep 12 21:44 meson.build\r\ndrwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mpandas\u001b[0m\r\n-rw-r--r-- 1 root root 22900 Sep 12 21:44 pyproject.toml\r\n-rw-r--r-- 1 root root  4307 Sep 12 21:42 pyright_reportGeneralTypeIssues.json\r\n-rw-r--r-- 1 root root  1459 Sep 12 21:44 requirements-dev.txt\r\ndrwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mscripts\u001b[0m\r\n-rwxr-xr-x 1 root root 21960 Sep 12 21:44 \u001b[01;32msetup.py\u001b[0m\r\ndrwxr-xr-x 3 root root  4096 Sep 12 21:42 \u001b[01;34mtooling\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 12 21:42 \u001b[01;34mtypings\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mweb\u001b[0m\r\n"]
[15.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[15.002, "i", "git status -sb\r"]
[15.004, "o", "git status -sb\r\n"]
[15.006, "o", "\u001b[?2004l\r\n## \u001b[32mmain\u001b[m\r\n"]
[20.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[20.002, "i", "find . -maxdepth 3 -type f -iname 'asv*.json' -o -iname 'asv.conf*' -o -path './asv.conf.*'\r"]
[20.004, "o", "find . -maxdepth 3 -type f -iname 'asv*.json' -o -iname 'asv.conf*' -o -path './asv.conf.*'\r\n"]
[20.006, "o", "\u001b[?2004l\r\n./asv_bench/asv.conf.json\r\n"]
[25.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[25.002, "i", "grep -RIn --line-number --color=never -E 'class\\s+Bench|benchmark|asv' . | head -n 200\r"]
[25.004, "o", "grep -RIn --line-number --color=never -E 'class\\s+Bench|benchmark|asv' . | head -n 200\r\n"]
[25.006, "o", "\u001b[?2004l\r\n./pyproject.toml:8:    \"Cython~=3.0.5\",  # Note: sync with setup.py, environment.yml and asv.conf.json\r\n./pyproject.toml:403:  # exclude asv benchmark environments from linting\r\n./pyproject.toml:425:# relative imports allowed for asv_bench\r\n./pyproject.toml:426:\"asv_bench/*\" = [\"TID\", \"NPY002\"]\r\n./.gitattributes:65:asv_bench export-ignore\r\n./.pre-commit-config.yaml:193:    -   id: seed-check-asv\r\n./.pre-commit-config.yaml:194:        name: Check for unnecessary random seeds in asv benchmarks\r\n./.pre-commit-config.yaml:197:        files: ^asv_bench/benchmarks\r\n./.pre-commit-config.yaml:198:        exclude: ^asv_bench/benchmarks/pandas_vb_common\\.py\r\n./.pre-commit-config.yaml:250:        exclude: ^(asv_bench|pandas/tests|doc)/\r\n./.pre-commit-config.yaml:258:            ^(asv_bench|pandas/tests|doc)/\r\n./scripts/tests/data/deps_minimum.toml:7:    \"Cython>=0.29.32,<3\",  # Note: sync with setup.py, environment.yml and asv.conf.json\r\n./scripts/tests/data/deps_minimum.toml:228:  # exclude asv benchmark environments from linting\r\n./pandas/tests/tools/test_to_datetime.py:1184:        # inspired by asv timeseries.ToDatetimeNONISO8601 benchmark\r\n./pandas/tests/io/data/html/banklist.html:300:\t\t\t\t<td class=\"city\">Douglasville</td>\r\n./pandas/tests/io/data/html/banklist.html:1992:\t\t\t\t<td class=\"city\">Douglasville</td>\r\n./pandas/tests/io/data/html/banklist.html:3188:\t\t\t\t<td class=\"institution\"><a href=\"benchmark-il.html\">Benchmark Bank</a></td>\r\n./pandas/tests/io/data/csv/banklist.csv:6:Douglas County Bank,Douglasville,GA,21649,Hamilton State Bank,26-Apr-13,16-May-13\r\n./pandas/tests/io/data/csv/banklist.csv:194:First Commerce Community Bank,Douglasville,GA,57448,Community & Southern Bank,17-Sep-10,15-Jan-13\r\n./pandas/tests/frame/indexing/test_setitem.py:99:    def test_setitem_benchmark(self):\r\n./.github/workflows/code-checks.yml:103:  asv-benchmarks:\r\n./.github/workflows/code-checks.yml:112:      group: ${{ github.event_name == 'push' && github.run_number || github.ref }}-asv-benchmarks\r\n./.github/workflows/code-checks.yml:128:    - name: Run ASV benchmarks\r\n./.github/workflows/code-checks.yml:130:        cd asv_bench\r\n./.github/workflows/code-checks.yml:131:        asv machine --yes\r\n./.github/workflows/code-checks.yml:132:        asv run --quick --dry-run --durations=30 --python=same --show-stderr\r\n./.github/workflows/comment-commands.yml:31:  asv_run:\r\n./.github/workflows/comment-commands.yml:33:    # TODO: Support more benchmarking options later, against different branches, against self, etc\r\n./.github/workflows/comment-commands.yml:34:    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '@github-actions benchmark')\r\n./.github/workflows/comment-commands.yml:44:      # each user can only run one concurrent benchmark bot at a time\r\n./.github/workflows/comment-commands.yml:45:      # We don't cancel in progress jobs, but if you want to benchmark multiple PRs, you're gonna have\r\n./.github/workflows/comment-commands.yml:47:      group: ${{ github.actor }}-asv\r\n./.github/workflows/comment-commands.yml:56:        # Although asv sets up its own env, deps are still needed\r\n./.github/workflows/comment-commands.yml:61:      - name: Run benchmarks\r\n./.github/workflows/comment-commands.yml:63:        continue-on-error: true # asv will exit code 1 for regressions\r\n./.github/workflows/comment-commands.yml:67:          cd asv_bench\r\n./.github/workflows/comment-commands.yml:68:          asv check -E existing\r\n./.github/workflows/comment-commands.yml:71:          asv machine --yes\r\n./.github/workflows/comment-commands.yml:72:          asv continuous -f 1.1 -b $REGEX upstream/main HEAD\r\n./.github/workflows/comment-commands.yml:74:          asv compare -f 1.1 upstream/main HEAD >> $GITHUB_ENV\r\n./.github/workflows/docbuild-and-upload.yml:81:      run: rsync -az --delete --exclude='pandas-docs' --exclude='docs' --exclude='benchmarks' web/build/ web@${{ secrets.server_ip }}:/var/www/html\r\n./setup.py:39:# note: sync with pyproject.toml, environment.yml and asv.conf.json\r\n./web/pandas/about/roadmap.md:180:Pandas uses [airspeed velocity](https://asv.readthedocs.io/en/stable/)\r\n./web/pandas/about/roadmap.md:185:The [asv-runner](https://github.com/asv-runner) organization, currently\r\n./web/pandas/about/roadmap.md:187:have a physical machine for running a number of project's benchmarks,\r\n./web/pandas/about/roadmap.md:188:and tools managing the benchmark runs and reporting on results.\r\n./web/pandas/about/roadmap.md:194:-   Tune the system for benchmarks to improve stability, following\r\n./web/pandas/about/roadmap.md:197:    Currently, the benchmarks are only run nightly.\r\n./web/pandas/config.yml:58:      target: community/benchmarks.html\r\n./web/pandas/config.yml:133:    responsibilities: \"Keep the pandas infrastructure up and working. In particular the servers for the website, benchmarks, CI and others needed.\"\r\n./web/pandas/community/benchmarks.md:4:kinds of benchmarks relevant to pandas:\r\n./web/pandas/community/benchmarks.md:6:* Internal pandas benchmarks to measure speed and memory usage over time\r\n./web/pandas/community/benchmarks.md:7:* Community benchmarks comparing the speed or memory usage of different tools at\r\n./web/pandas/community/benchmarks.md:10:## pandas benchmarks\r\n./web/pandas/community/benchmarks.md:12:pandas benchmarks are implemented in the [asv_bench](https://github.com/pandas-dev/pandas/tree/main/asv_bench)\r\n./web/pandas/community/benchmarks.md:13:directory of our repository. The benchmarks are implemented for the\r\n./web/pandas/community/benchmarks.md:14:[airspeed velocity](https://asv.readthedocs.io/en/v0.6.1/) (asv for short) framework.\r\n./web/pandas/community/benchmarks.md:16:The benchmarks can be run locally by any pandas developer. This can be done\r\n./web/pandas/community/benchmarks.md:17:with the `asv run` command, and it can be useful to detect if local changes have\r\n./web/pandas/community/benchmarks.md:18:an impact in performance, by running the benchmarks before and after the changes.\r\n./web/pandas/community/benchmarks.md:22:Note that benchmarks are not deterministic, and running in different hardware or\r\n./web/pandas/community/benchmarks.md:24:the result. Even running the benchmarks with identical hardware and almost identical\r\n./web/pandas/community/benchmarks.md:27:## pandas benchmarks servers\r\n./web/pandas/community/benchmarks.md:29:We currently have two physical servers running the benchmarks of pandas for every\r\n./web/pandas/community/benchmarks.md:37:Results of the benchmarks are available at:\r\n./web/pandas/community/benchmarks.md:39:- Original server: [asv](https://asv-runner.github.io/asv-collection/pandas/)\r\n./web/pandas/community/benchmarks.md:40:- OVH server: [asv](https://pandas.pydata.org/benchmarks/asv/) (benchmarks results can\r\n./web/pandas/community/benchmarks.md:46:[tomaugspurger/asv-runner](https://github.com/tomaugspurger/asv-runner).\r\n./web/pandas/community/benchmarks.md:48:[tomaugspurger/asv-collection](https://github.com/tomaugspurger/asv-collection).\r\n./web/pandas/community/benchmarks.md:50:The benchmarks are scheduled by [Airflow](https://airflow.apache.org/).\r\n./web/pandas/community/benchmarks.md:60:The server used to run the benchmarks has been configured to reduce system\r\n./web/pandas/community/benchmarks.md:61:noise and maximize the stability of the benchmarks times.\r\n./web/pandas/community/benchmarks.md:64:[pandas-benchmarks repository](https://github.com/pandas-dev/pandas-benchmarks).\r\n./web/pandas/community/benchmarks.md:67:- CPU isolation: Avoid user space tasks to execute in the same CPU as benchmarks, possibly interrupting them during the execution (include all virtual CPUs using a physical core)\r\n./web/pandas/community/benchmarks.md:69:- IRQ affinity: Ban benchmarks CPU to avoid many (but not all) kernel interruption in the isolated CPU\r\n./web/pandas/community/benchmarks.md:74:## Community benchmarks\r\n./web/pandas/community/benchmarks.md:76:The main benchmarks comparing dataframe tools that include pandas are:\r\n./web/pandas/community/benchmarks.md:78:- [DuckDB (former H2O.ai) benchmarks](https://duckdblabs.github.io/db-benchmark/)\r\n./web/pandas/community/benchmarks.md:79:- [TPCH benchmarks](https://pola.rs/posts/benchmarks/)\r\n./web/pandas/community/blog/asv-pandas-grant.md:1:Title: Write up of the NumFOCUS grant to improve pandas benchmarks and diversity\r\n./web/pandas/community/blog/asv-pandas-grant.md:4:# Write up of the NumFOCUS grant to improve pandas benchmarks and diversity\r\n./web/pandas/community/blog/asv-pandas-grant.md:9:**ASV benchmarking framework and diversity efforts** sponsored by\r\n./web/pandas/community/blog/asv-pandas-grant.md:14:[asv library](https://asv.readthedocs.io/en/stable/), a tool used by\r\n./web/pandas/community/blog/asv-pandas-grant.md:15:benchmarking Python packages and used by pandas; this project was\r\n./web/pandas/community/blog/asv-pandas-grant.md:39:connection, we were able to learn about this benchmarks grant.\r\n./web/pandas/community/blog/asv-pandas-grant.md:58:started building the CI on GitHub actions for the asv package; for that we\r\n./web/pandas/community/blog/asv-pandas-grant.md:91:with [PyLadies Colombia](https://bit.ly/sprint-asv).\r\n./.gitignore:116:asv_bench/env/\r\n./.gitignore:117:asv_bench/html/\r\n./.gitignore:118:asv_bench/results/\r\n./.gitignore:119:asv_bench/pandas/\r\n./asv_bench/asv.conf.json:6:    // The name of the project being benchmarked\r\n./asv_bench/asv.conf.json:13:    // benchmarked\r\n./asv_bench/asv.conf.json:16:    // List of branches to benchmark. If not provided, defaults to \"master\"\r\n./asv_bench/asv.conf.json:31:    // to the current version of Python used to run `asv`.\r\n./asv_bench/asv.conf.json:93:    // The directory (relative to the current directory) that benchmarks are\r\n./asv_bench/asv.conf.json:94:    // stored in.  If not provided, defaults to \"benchmarks\"\r\n./asv_bench/asv.conf.json:95:    // \"benchmark_dir\": \"benchmarks\",\r\n./asv_bench/asv.conf.json:101:    // The directory (relative to the current directory) that raw benchmark\r\n./asv_bench/asv.conf.json:112:    // `asv` will cache wheels of the recent builds in each\r\n./asv_bench/asv.conf.json:117:    // The commits after which the regression search in `asv publish`\r\n./asv_bench/asv.conf.json:119:    // regexps matching to benchmark names, and values corresponding to\r\n./asv_bench/asv.conf.json:123:    // skipped for the matching benchmark.\r\n./asv_bench/benchmarks/timedelta.py:2:Timedelta benchmarks with non-tslibs dependencies.  See\r\n./asv_bench/benchmarks/timedelta.py:3:benchmarks.tslibs.timedelta for benchmarks that rely only on tslibs.\r\n./asv_bench/benchmarks/groupby.py:492:            raise NotImplementedError  # skip benchmark\r\n./asv_bench/benchmarks/period.py:2:Period benchmarks with non-tslibs dependencies.  See\r\n./asv_bench/benchmarks/period.py:3:benchmarks.tslibs.period for benchmarks that rely only on tslibs.\r\n./asv_bench/benchmarks/indexing_engines.py:7:If a PR does not edit anything in _libs, it is very unlikely that benchmarks\r\n./asv_bench/benchmarks/indexing.py:2:These benchmarks are for Series and DataFrame indexing methods.  For the\r\n./asv_bench/benchmarks/frame_methods.py:148:    # mem_itertuples_* benchmarks are slow\r\n./asv_bench/benchmarks/__init__.py:1:\"\"\"Pandas benchmarks.\"\"\"\r\n./asv_bench/benchmarks/inference.py:2:The functions benchmarked in this file depend _almost_ exclusively on\r\n./asv_bench/benchmarks/inference.py:6:it is likely that these benchmarks will be unaffected.\r\n./asv_bench/benchmarks/inference.py:78:    #  go in benchmarks/libs.py\r\n./asv_bench/benchmarks/libs.py:6:benchmarks will be affected.\r\n./asv_bench/benchmarks/tslibs/timedelta.py:2:Timedelta benchmarks that rely only on tslibs. See benchmarks.timedeltas for\r\n./asv_bench/benchmarks/tslibs/timedelta.py:3:Timedelta benchmarks that rely on other parts of pandas.\r\n./asv_bench/benchmarks/tslibs/period.py:2:Period benchmarks that rely only on tslibs. See benchmarks.period for\r\n./asv_bench/benchmarks/tslibs/period.py:3:Period benchmarks that rely on other parts of pandas.\r\n./asv_bench/benchmarks/tslibs/__init__.py:6:run these benchmarks.\r\n./asv_bench/benchmarks/tslibs/tslib.py:59:            # tz is ignored, so avoid running redundant benchmarks\r\n./asv_bench/benchmarks/tslibs/tslib.py:60:            raise NotImplementedError  # skip benchmark\r\n./asv_bench/benchmarks/tslibs/tslib.py:63:            raise NotImplementedError  # skip benchmark\r\n./asv_bench/benchmarks/tslibs/offsets.py:2:offsets benchmarks that rely only on tslibs.  See benchmarks.offset for\r\n./asv_bench/benchmarks/tslibs/offsets.py:3:offsets benchmarks that rely on other parts of pandas.\r\n./asv_bench/benchmarks/io/parsers.py:4:    # Avoid whole benchmark suite import failure on asv (currently 0.4)\r\n./asv_bench/benchmarks/pandas_vb_common.py:57:    # This function just needs to be imported into each benchmark file to\r\n./asv_bench/benchmarks/pandas_vb_common.py:59:    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\r\n./asv_bench/benchmarks/pandas_vb_common.py:65:    Base class for IO benchmarks\r\n./doc/source/whatsnew/v0.17.0.rst:51:- Development support for benchmarking with the `Air Speed Velocity library <https://github.com/spacetelescope/asv/>`_ (:issue:`8361`)\r\n./doc/source/whatsnew/v0.17.0.rst:1023:- Development support for benchmarking with the `Air Speed Velocity library <https://github.com/spacetelescope/asv/>`_ (:issue:`8361`)\r\n./doc/source/whatsnew/v0.17.0.rst:1024:- Added vbench benchmarks for alternative ExcelWriter engines and reading Excel files (:issue:`7171`)\r\n./doc/source/whatsnew/v0.15.0.rst:1169:- Performance benchmarking of groupby for large value of ngroups (:issue:`6787`)\r\n./doc/source/whatsnew/v2.2.0.rst:318:1. Calamine is often faster than other engines, some benchmarks show results up to 5x faster than 'openpyxl', 20x - 'odf', 4x - 'pyxlsb', and 1.5x - 'xlrd'.\r\n./doc/source/getting_started/comparison/comparison_with_r.rst:16:* **Performance**: how fast are operations. Hard numbers/benchmarks are\r\n./doc/source/development/contributing_codebase.rst:864:`asv benchmarks <https://github.com/airspeed-velocity/asv>`__\r\n./doc/source/development/contributing_codebase.rst:866:These benchmarks are all found in the ``pandas/asv_bench`` directory, and the\r\n./doc/source/development/contributing_codebase.rst:867:test results can be found `here <https://asv-runner.github.io/asv-collection/pandas>`__.\r\n./doc/source/development/contributing_codebase.rst:869:To use all features of asv, you will need either ``conda`` or\r\n./doc/source/development/contributing_codebase.rst:870:``virtualenv``. For more details please check the `asv installation\r\n./doc/source/development/contributing_codebase.rst:871:webpage <https://asv.readthedocs.io/en/latest/installing.html>`_.\r\n./doc/source/development/contributing_codebase.rst:873:To install asv::\r\n./doc/source/development/contributing_codebase.rst:875:    pip install git+https://github.com/airspeed-velocity/asv\r\n./doc/source/development/contributing_codebase.rst:877:If you need to run a benchmark, change your directory to ``asv_bench/`` and run::\r\n./doc/source/development/contributing_codebase.rst:879:    asv continuous -f 1.1 upstream/main HEAD\r\n./doc/source/development/contributing_codebase.rst:882:and report benchmarks that changed by more than 10%.\r\n./doc/source/development/contributing_codebase.rst:883:The command uses ``conda`` by default for creating the benchmark\r\n./doc/source/development/contributing_codebase.rst:886:    asv continuous -f 1.1 -E virtualenv upstream/main HEAD\r\n./doc/source/development/contributing_codebase.rst:888:The ``-E virtualenv`` option should be added to all ``asv`` commands\r\n./doc/source/development/contributing_codebase.rst:889:that run benchmarks. The default value is defined in ``asv.conf.json``.\r\n./doc/source/development/contributing_codebase.rst:891:Running the full benchmark suite can be an all-day process, depending on your\r\n./doc/source/development/contributing_codebase.rst:894:do not cause unexpected performance regressions.  You can run specific benchmarks\r\n./doc/source/development/contributing_codebase.rst:896:only run benchmarks from a ``pandas/asv_bench/benchmarks/groupby.py`` file::\r\n./doc/source/development/contributing_codebase.rst:898:    asv continuous -f 1.1 upstream/main HEAD -b ^groupby\r\n./doc/source/development/contributing_codebase.rst:900:If you want to only run a specific group of benchmarks from a file, you can do it\r\n./doc/source/development/contributing_codebase.rst:903:    asv continuous -f 1.1 upstream/main HEAD -b groupby.GroupByMethods\r\n./doc/source/development/contributing_codebase.rst:905:will only run the ``GroupByMethods`` benchmark defined in ``groupby.py``.\r\n./doc/source/development/contributing_codebase.rst:907:You can also run the benchmark suite using the version of ``pandas``\r\n./doc/source/development/contributing_codebase.rst:912:``PYTHONPATH=\"$PWD/..\" asv [remaining arguments]``.\r\n./doc/source/development/contributing_codebase.rst:913:You can run benchmarks using an existing Python\r\n./doc/source/development/contributing_codebase.rst:916:    asv run -e -E existing\r\n./doc/source/development/contributing_codebase.rst:920:    asv run -e -E existing:python3.6\r\n./doc/source/development/contributing_codebase.rst:922:This will display stderr from the benchmarks, and use your local\r\n./doc/source/development/contributing_codebase.rst:925:Information on how to write a benchmark and how to use asv can be found in the\r\n./doc/source/development/contributing_codebase.rst:926:`asv documentation <https://asv.readthedocs.io/en/latest/writing_benchmarks.html>`_.\r\n./environment.yml:1:# Local development dependencies including docs building, website upload, ASV benchmark\r\n./environment.yml:72:  # benchmarks\r\n./environment.yml:73:  - asv>=0.6.1\r\n./requirements-dev.txt:56:asv>=0.6.1\r\n./build/cp310/pandas/_libs/byteswap.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/byteswap.pyx.c.dep:3:  ../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/Cython/Includes/libc/string.pxd \\\r\n./build/cp310/pandas/_libs/byteswap.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/byteswap.pyx.c.dep:4:  ../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/Cython/Includes/libc/stdint.pxd\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1395:  \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\",\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1628:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":769\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1637:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":770\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1646:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":771\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1655:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":772\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1664:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":776\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1673:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":777\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1682:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":778\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1691:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":779\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1700:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":783\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1709:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":784\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1718:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":791\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1727:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":792\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1736:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":794\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1745:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":795\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1754:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":797\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1763:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":798\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1772:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":799\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1887:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":1095\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:1896:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":1096\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:20325:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":285\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:20336:  /* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":287\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:20346:  /* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":285\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:20359:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":289\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:20370:  /* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":291\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:20380:  /* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":289\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:20393:/* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":295\r\n./build/cp310/pandas/_libs/tslib.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslib.pyx.c:20407:  /* \"../../../../opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/__init__.cython-30.pxd\":297\r\n"]
[30.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[30.002, "i", "ls -la benchmarks 2>/dev/null || true\r"]
[30.004, "o", "ls -la benchmarks 2>/dev/null || true\r\n"]
[30.006, "o", "\u001b[?2004l\r\n"]
[35.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[35.002, "i", "ls -la asv_benchmarks.txt 2>/dev/null || true\r"]
[35.004, "o", "ls -la asv_benchmarks.txt 2>/dev/null || true\r\n"]
[35.006, "o", "\u001b[?2004l\r\n"]
[40.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[40.002, "i", "asv dev -h\r"]
[40.004, "o", "asv dev -h\r\n"]
[40.006, "o", "\u001b[?2004l\r\nusage: asv [-h] [--verbose] [--config CONFIG] [--version]\r\n           {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages} ...\r\nasv: error: argument {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages}: invalid choice: 'dev' (choose from 'help', 'quickstart', 'machine', 'setup', 'run', 'continuous', 'find', 'rm', 'publish', 'preview', 'profile', 'update', 'show', 'compare', 'check', 'gh-pages')\r\n"]
[45.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[45.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*|arithmetic.Ops2.*|reindex.DropDuplicates.*\"\r"]
[45.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*|arithmetic.Ops2.*|reindex.DropDuplicates.*\"\r\n"]
[45.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mNo `asv.conf` file found for valid extensions: ['.json', '.jsonc'].\u001b[0m\r\n"]
[50.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[50.002, "i", "cd asv_bench\r"]
[50.004, "o", "cd asv_bench\r\n"]
[50.006, "o", "\u001b[?2004l\r\n"]
[55.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[55.002, "i", "ls -la benchmarks\r"]
[55.004, "o", "ls -la benchmarks\r\n"]
[55.006, "o", "\u001b[?2004l\r\ntotal 376\r\ndrwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root    25 Sep 12 21:42 __init__.py\r\n-rw-r--r-- 1 root root  6160 Sep 12 21:42 algorithms.py\r\ndrwxr-xr-x 2 root root  4096 Sep 12 21:42 \u001b[01;34malgos\u001b[0m\r\n-rw-r--r-- 1 root root 12498 Sep 12 21:42 arithmetic.py\r\n-rw-r--r-- 1 root root  4282 Sep 12 21:42 array.py\r\n-rw-r--r-- 1 root root  1414 Sep 12 21:42 attrs_caching.py\r\n-rw-r--r-- 1 root root   739 Sep 12 21:42 boolean.py\r\n-rw-r--r-- 1 root root  9776 Sep 12 21:42 categoricals.py\r\n-rw-r--r-- 1 root root  3462 Sep 12 21:42 ctors.py\r\n-rw-r--r-- 1 root root  3559 Sep 12 21:42 dtypes.py\r\n-rw-r--r-- 1 root root  1988 Sep 12 21:42 eval.py\r\n-rw-r--r-- 1 root root   379 Sep 12 21:42 finalize.py\r\n-rw-r--r-- 1 root root  5142 Sep 12 21:42 frame_ctor.py\r\n-rw-r--r-- 1 root root 24291 Sep 12 21:44 frame_methods.py\r\n-rw-r--r-- 1 root root  8150 Sep 12 21:44 gil.py\r\n-rw-r--r-- 1 root root 33292 Sep 12 21:42 groupby.py\r\n-rw-r--r-- 1 root root  2393 Sep 12 21:42 hash_functions.py\r\n-rw-r--r-- 1 root root  2274 Sep 12 21:42 index_cached_properties.py\r\n-rw-r--r-- 1 root root  7138 Sep 12 21:42 index_object.py\r\n-rw-r--r-- 1 root root 16813 Sep 12 21:42 indexing.py\r\n-rw-r--r-- 1 root root  6372 Sep 12 21:42 indexing_engines.py\r\n-rw-r--r-- 1 root root  8662 Sep 12 21:42 inference.py\r\ndrwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mio\u001b[0m\r\n-rw-r--r-- 1 root root 18607 Sep 12 21:42 join_merge.py\r\n-rw-r--r-- 1 root root  2445 Sep 12 21:42 libs.py\r\n-rw-r--r-- 1 root root 12356 Sep 12 21:42 multiindex_object.py\r\n-rw-r--r-- 1 root root   624 Sep 12 21:42 package.py\r\n-rw-r--r-- 1 root root  1740 Sep 12 21:42 pandas_vb_common.py\r\n-rw-r--r-- 1 root root  2909 Sep 12 21:42 period.py\r\n-rw-r--r-- 1 root root  4554 Sep 12 21:42 plotting.py\r\n-rw-r--r-- 1 root root  4948 Sep 12 21:42 reindex.py\r\n-rw-r--r-- 1 root root  2103 Sep 12 21:42 replace.py\r\n-rw-r--r-- 1 root root  9973 Sep 12 21:42 reshape.py\r\n-rw-r--r-- 1 root root 11628 Sep 12 21:42 rolling.py\r\n-rw-r--r-- 1 root root 10677 Sep 12 21:42 series_methods.py\r\n-rw-r--r-- 1 root root  6817 Sep 12 21:42 sparse.py\r\n-rw-r--r-- 1 root root  4685 Sep 12 21:42 stat_ops.py\r\n-rw-r--r-- 1 root root  3535 Sep 12 21:42 strftime.py\r\n-rw-r--r-- 1 root root  7996 Sep 12 21:44 strings.py\r\n-rw-r--r-- 1 root root  1528 Sep 12 21:42 timedelta.py\r\n-rw-r--r-- 1 root root  8565 Sep 12 21:42 timeseries.py\r\ndrwxr-xr-x 2 root root  4096 Sep 12 21:42 \u001b[01;34mtslibs\u001b[0m\r\n"]
[60.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[60.002, "i", "grep -RIn --line-number --color=never -E 'class\\s+Hashing|class\\s+Ops2|class\\s+DropDuplicates|algorithms\\\r"]
[60.004, "o", "grep -RIn --line-number --color=never -E 'class\\s+Hashing|class\\s+Ops2|class\\s+DropDuplicates|algorithms\\\r\n"]
[60.006, "o", "\\.Hashing|arithmetic\\.Ops2|reindex\\.DropDuplicates' benchmarks | head -n 200\r\n\u001b[?2004l\r\nbenchmarks/reindex.py:87:class DropDuplicates:\r\nbenchmarks/arithmetic.py:204:class Ops2:\r\nbenchmarks/algorithms.py:133:class Hashing:\r\n"]
[65.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[65.002, "i", "asv machine --yes\r"]
[65.004, "o", "asv machine --yes\r\n"]
[65.006, "o", "\u001b[?2004l\r\nI will now ask you some questions about this machine to identify it in the benchmarks.\r\n\r\n1. machine:  A unique name to identify this machine in the results.\r\n   May be anything, as long as it is unique across all the machines\r\n   used to benchmark this project.  NOTE: If changed from the default,\r\n   it will no longer match the hostname of this machine, and you may\r\n   need to explicitly use the --machine argument to asv.\r\nmachine [9fa129b0bc16]: 2. os:  The OS type and version of this machine.  For example,\r\n   'Macintosh OS-X 10.8'.\r\nos [Linux 4.14.355-280.684.amzn2.x86_64]: 3. arch:  The generic CPU architecture of this machine.  For example,\r\n   'i386' or 'x86_64'.\r\narch [x86_64]: 4. cpu:  A specific description of the CPU of this machine, including\r\n   its speed and class.  For example, 'Intel(R) Core(TM) i5-2520M CPU\r\n   @ 2.50GHz (4 cores)'.\r\ncpu [AMD EPYC 7R32]: 5. num_cpu:  The number of CPUs in the system. For example, '4'.\r\nnum_cpu [2]: 6. ram:  The amount of physical RAM on this machine.  For example,\r\n   '4GB'.\r\n"]
[70.0, "o", "ram [3964656]: \u001b[?2004h(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[70.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*|arithmetic.Ops2.*|reindex.DropDuplicates.*\"\r"]
[70.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*|arithmetic.Ops2.*|reindex.DropDuplicates.*\"\r\n"]
[70.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 22 total benchmarks (1 commits * 1 environments * 22 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 2.27%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 2.27%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             15.9\u00b10ms\r\n[ 4.55%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                4.09\u00b10ms\r\n[ 6.82%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.22\u00b10ms\r\n[ 9.09%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.37\u00b10ms\r\n[11.36%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.25\u00b10ms\r\n[13.64%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.5\u00b10ms\r\n[15.91%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.27\u00b10ms\r\n[18.18%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_dot\u001b[0m                                                                                                            47.2\u00b10ms\r\n[20.45%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_div\u001b[0m                                                                                                      29.0\u00b10ms\r\n[22.73%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_div_by_zero\u001b[0m                                                                                              1.29\u00b10ms\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_floor_by_zero\u001b[0m                                                                                            21.4\u00b10ms\r\n[27.27%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_mod\u001b[0m                                                                                                      25.3\u00b10ms\r\n[29.55%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_int_div_by_zero\u001b[0m                                                                                                1.87\u00b10ms\r\n[31.82%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_int_mod\u001b[0m                                                                                                        11.8\u00b10ms\r\n[34.09%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_series_dot\u001b[0m                                                                                                     1.17\u00b10ms\r\n[36.36%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_series_dot\u001b[0m                                                                                                            340\u00b10\u03bcs\r\n[38.64%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups\u001b[0m                                                                                                     ok\r\n[38.64%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    9.38\u00b10ms \r\n               False    9.08\u00b10ms \r\n             ========= ==========\r\n\r\n[40.91%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_bool\u001b[0m                                                                                                ok\r\n[40.91%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    2.63\u00b10ms \r\n               False    2.57\u00b10ms \r\n             ========= ==========\r\n\r\n[43.18%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_int\u001b[0m                                                                                                 ok\r\n[43.18%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    12.5\u00b10ms \r\n               False    12.4\u00b10ms \r\n             ========= ==========\r\n\r\n[45.45%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_na\u001b[0m                                                                                                  ok\r\n[45.45%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    12.1\u00b10ms \r\n               False    11.7\u00b10ms \r\n             ========= ==========\r\n\r\n[47.73%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_series_drop_dups_int\u001b[0m                                                                                                ok\r\n[47.73%] \u00b7\u00b7\u00b7 \u001b[0;39m========= =========\u001b[0m\r\n              inplace           \r\n             --------- ---------\r\n                True    545\u00b10\u03bcs \r\n               False    566\u00b10\u03bcs \r\n             ========= =========\r\n\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_series_drop_dups_string\u001b[0m                                                                                             ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========= =========\u001b[0m\r\n              inplace           \r\n             --------- ---------\r\n                True    603\u00b10\u03bcs \r\n               False    599\u00b10\u03bcs \r\n             ========= =========\r\n\r\n"]
[75.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[75.002, "i", "asv profile --python=same --config=asv.conf.json arithmetic.Ops2.time_frame_float_div\r"]
[75.004, "o", "asv profile --python=same --config=asv.conf.json arithmetic.Ops2.time_frame_float_div\r\n"]
[75.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (arithmetic.Ops2.time_frame_float_div--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_div\u001b[0m                                                                                                   28.3\u00b10.05ms\r\n\r\nWed Oct  1 17:31:25 2025    /tmp/tmp6cdwp48l\r\n\r\n         320 function calls (304 primitive calls) in 0.028 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.028    0.028 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.028    0.028 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.028    0.028 arithmetic.py:225(time_frame_float_div)\r\n        1    0.000    0.000    0.028    0.028 common.py:62(new_method)\r\n        1    0.000    0.000    0.028    0.028 arraylike.py:219(__floordiv__)\r\n        1    0.000    0.000    0.028    0.028 frame.py:7884(_arith_method)\r\n        1    0.000    0.000    0.028    0.028 frame.py:7899(_dispatch_frame_op)\r\n        1    0.000    0.000    0.028    0.028 managers.py:1624(operate_blockwise)\r\n        1    0.000    0.000    0.028    0.028 ops.py:57(operate_blockwise)\r\n        1    0.000    0.000    0.028    0.028 array_ops.py:239(arithmetic_op)\r\n        1    0.000    0.000    0.028    0.028 array_ops.py:188(_na_arithmetic_op)\r\n        1    0.000    0.000    0.027    0.027 expressions.py:227(evaluate)\r\n        1    0.000    0.000    0.027    0.027 expressions.py:68(_evaluate_standard)\r\n        1    0.027    0.027    0.027    0.027 {built-in method _operator.floordiv}\r\n        1    0.000    0.000    0.001    0.001 missing.py:132(dispatch_fill_zeros)\r\n        1    0.000    0.000    0.001    0.001 missing.py:72(mask_zero_div_zero)\r\n        1    0.000    0.000    0.000    0.000 frame.py:8272(_construct_result)\r\n        1    0.000    0.000    0.000    0.000 frame.py:8041(_should_reindex_frame_op)\r\n        1    0.000    0.000    0.000    0.000 frame.py:698(__init__)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        2    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        2    0.000    0.000    0.000    0.000 ops.py:29(_iter_block_pairs)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        2    0.000    0.000    0.000    0.000 base.py:2766(unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:3189(intersection)\r\n        6    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        2    0.000    0.000    0.000    0.000 managers.py:392(apply)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:367(_split_op_result)\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        2    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:227(make_block)\r\n        4    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:8079(_align_for_op)\r\n        2    0.000    0.000    0.000    0.000 common.py:83(get_op_result_name)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n    51/49    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 base.py:3537(_convert_can_do_setop)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1363(_indexed_same)\r\n        1    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n    29/15    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        3    0.000    0.000    0.000    0.000 generic.py:1365(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        1    0.000    0.000    0.000    0.000 _ufunc_config.py:441(__enter__)\r\n        1    0.000    0.000    0.000    0.000 array_ops.py:461(get_array_op)\r\n        1    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 ops.py:96(_reset_block_mgr_locs)\r\n        2    0.000    0.000    0.000    0.000 common.py:105(_maybe_match_name)\r\n        6    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 base.py:2932(_get_reconciled_name_object)\r\n       14    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        4    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        1    0.000    0.000    0.000    0.000 _ufunc_config.py:457(__exit__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:303(getitem_block_columns)\r\n        1    0.000    0.000    0.000    0.000 array_ops.py:504(maybe_prepare_scalar_for_op)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2306(extend_blocks)\r\n        8    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55d640233640}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:167(is_extension)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        1    0.000    0.000    0.000    0.000 ops.py:108(_get_same_shape_values)\r\n        1    0.000    0.000    0.000    0.000 dispatch.py:18(should_extension_dispatch)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:639(copy)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        6    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        5    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        2    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:3531(_assert_can_do_setop)\r\n        3    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        2    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        6    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        9    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:967(_slice)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy._core._multiarray_umath._make_extobj}\r\n        1    0.000    0.000    0.000    0.000 {method 'reset' of '_contextvars.ContextVar' objects}\r\n       11    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        1    0.000    0.000    0.000    0.000 _ufunc_config.py:431(__init__)\r\n        2    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 array_ops.py:591(_bool_arith_check)\r\n        4    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        4    0.000    0.000    0.000    0.000 blocks.py:219(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 {method 'set' of '_contextvars.ContextVar' objects}\r\n        4    0.000    0.000    0.000    0.000 generic.py:638(ndim)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:2943(_validate_sort_keyword)\r\n        6    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        2    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        1    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:223(mgr_locs)\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        3    0.000    0.000    0.000    0.000 range.py:446(is_unique)\r\n        4    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n        2    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        1    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:296(items)\r\n        2    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 frame.py:659(_constructor)\r\n        1    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\r\n\r\n\r\n"]
[80.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[80.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[80.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[80.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                  7.69\u00b10.02ms\r\n\r\nWed Oct  1 17:31:45 2025    /tmp/tmpat7mbjjj\r\n\r\n         798 function calls (782 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n      3/2    0.000    0.000    0.007    0.004 hashing.py:235(hash_array)\r\n      3/2    0.001    0.000    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:2406(is_unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55ca10baf640}\r\n        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n\r\n\r\n"]
[85.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[85.002, "i", "grep -RIn --line-number --color=never -E \"hash|factoriz|drop_duplicates|_hash|hashing\" ../pandas | head -\r"]
[85.004, "o", "grep -RIn --line-number --color=never -E \"hash|factoriz|drop_duplicates|_hash|hashing\" ../pandas | head -\r\n"]
[85.006, "o", "-n 200\r\n\u001b[?2004l\r\n../pandas/_libs/interval.pyx:35:from pandas._libs.hashtable cimport Int64Vector\r\n../pandas/_libs/interval.pyx:475:    def __hash__(self):\r\n../pandas/_libs/interval.pyx:476:        return hash((self.left, self.right, self.closed))\r\n../pandas/_libs/hashtable.pyi:21:    def factorize(\r\n../pandas/_libs/hashtable.pyi:28:    def hash_inner_join(\r\n../pandas/_libs/hashtable.pyi:214:    def factorize(\r\n../pandas/_libs/hashtable.pyi:222:    def hash_inner_join(\r\n../pandas/_libs/hashtable.pyi:273:def object_hash(obj) -> int: ...\r\n../pandas/_libs/khash.pxd:18:cdef extern from \"pandas/vendored/klib/khash_python.h\":\r\n../pandas/_libs/khash.pxd:29:        \"kh_complex_hash_equal\" (khcomplex128_t a, khcomplex128_t b) nogil\r\n../pandas/_libs/khash.pxd:36:        \"kh_complex_hash_equal\" (khcomplex64_t a, khcomplex64_t b) nogil\r\n../pandas/_libs/khash.pxd:39:        \"kh_floats_hash_equal\" (float64_t a, float64_t b) nogil\r\n../pandas/_libs/khash.pxd:42:        \"kh_floats_hash_equal\" (float32_t a, float32_t b) nogil\r\n../pandas/_libs/khash.pxd:44:    uint32_t kh_python_hash_func(object key)\r\n../pandas/_libs/khash.pxd:45:    bint kh_python_hash_equal(object a, object b)\r\n../pandas/_libs/khash.pxd:108:    # sweep factorize\r\n../pandas/_libs/khash.pxd:129:include \"khash_for_primitive_helper.pxi\"\r\n../pandas/_libs/src/parser/tokenizer.c:28:#include \"pandas/vendored/klib/khash.h\" // for kh_int64_t, kh_destroy_int64\r\n../pandas/_libs/hashtable_class_helper.pxi.in:2:Template for each `dtype` helper function for hashtable\r\n../pandas/_libs/hashtable_class_helper.pxi.in:56:# are_equivalent_{{c_type}} is cimported via khash.pxd\r\n../pandas/_libs/hashtable_class_helper.pxi.in:86:from pandas._libs.khash cimport (\r\n../pandas/_libs/hashtable_class_helper.pxi.in:109:# for uniques in hashtables)\r\n../pandas/_libs/hashtable_class_helper.pxi.in:434:        \"\"\" returns infos about the state of the hashtable\"\"\"\r\n../pandas/_libs/hashtable_class_helper.pxi.in:443:        \"\"\"Extracts the position of val from the hashtable.\r\n../pandas/_libs/hashtable_class_helper.pxi.in:448:            The value that is looked up in the hashtable\r\n../pandas/_libs/hashtable_class_helper.pxi.in:469:        \"\"\"Extracts the position of na_value from the hashtable.\r\n../pandas/_libs/hashtable_class_helper.pxi.in:561:    def hash_inner_join(self, const {{dtype}}_t[:] values, const uint8_t[:] mask = None) -> tuple[ndarray, ndarray]:\r\n../pandas/_libs/hashtable_class_helper.pxi.in:731:                    # ignore_na is True), skip the hashtable entry for them,\r\n../pandas/_libs/hashtable_class_helper.pxi.in:825:    def factorize(self, const {{dtype}}_t[:] values, Py_ssize_t na_sentinel=-1,\r\n../pandas/_libs/hashtable_class_helper.pxi.in:928:    def factorize(self, const {{c_type}}[:] values,\r\n../pandas/_libs/hashtable_class_helper.pxi.in:940:        >>> fac.factorize(np.array([1,2,3], dtype=\"{{dtype}}\"), na_sentinel=20)\r\n../pandas/_libs/hashtable_class_helper.pxi.in:956:    def hash_inner_join(self, const {{c_type}}[:] values, const uint8_t[:] mask = None) -> tuple[np.ndarray, np.ndarray]:\r\n../pandas/_libs/hashtable_class_helper.pxi.in:957:        return self.table.hash_inner_join(values, mask)\r\n../pandas/_libs/hashtable_class_helper.pxi.in:988:        \"\"\" returns infos about the state of the hashtable\"\"\"\r\n../pandas/_libs/hashtable_class_helper.pxi.in:1267:    def factorize(self, ndarray[object] values, Py_ssize_t na_sentinel=-1,\r\n../pandas/_libs/hashtable_class_helper.pxi.in:1330:        hash(key)\r\n../pandas/_libs/hashtable_class_helper.pxi.in:1345:        returns infos about the current state of the hashtable like size,\r\n../pandas/_libs/hashtable_class_helper.pxi.in:1371:        hash(key)\r\n../pandas/_libs/hashtable_class_helper.pxi.in:1389:            hash(val)\r\n../pandas/_libs/hashtable_class_helper.pxi.in:1406:            hash(val)\r\n../pandas/_libs/hashtable_class_helper.pxi.in:1470:            hash(val)\r\n../pandas/_libs/hashtable_class_helper.pxi.in:1481:                # ignore_na is True), skip the hashtable entry for them, and\r\n../pandas/_libs/hashtable_class_helper.pxi.in:1530:    def factorize(self, ndarray[object] values, Py_ssize_t na_sentinel=-1,\r\n../pandas/_libs/tslib.pyx:427:                    # dateutil timezone objects cannot be hashed, so\r\n../pandas/_libs/meson.build:13:_khash_primitive_helper = custom_target(\r\n../pandas/_libs/meson.build:14:    'khash_primitive_helper_pxi',\r\n../pandas/_libs/meson.build:15:    output: 'khash_for_primitive_helper.pxi',\r\n../pandas/_libs/meson.build:16:    input: 'khash_for_primitive_helper.pxi.in',\r\n../pandas/_libs/meson.build:19:_hashtable_class_helper = custom_target(\r\n../pandas/_libs/meson.build:20:    'hashtable_class_helper_pxi',\r\n../pandas/_libs/meson.build:21:    output: 'hashtable_class_helper.pxi',\r\n../pandas/_libs/meson.build:22:    input: 'hashtable_class_helper.pxi.in',\r\n../pandas/_libs/meson.build:25:_hashtable_func_helper = custom_target(\r\n../pandas/_libs/meson.build:26:    'hashtable_func_helper_pxi',\r\n../pandas/_libs/meson.build:27:    output: 'hashtable_func_helper.pxi',\r\n../pandas/_libs/meson.build:28:    input: 'hashtable_func_helper.pxi.in',\r\n../pandas/_libs/meson.build:49:_khash_primitive_helper_dep = declare_dependency(\r\n../pandas/_libs/meson.build:50:    sources: _khash_primitive_helper,\r\n../pandas/_libs/meson.build:73:        'deps': _khash_primitive_helper_dep,\r\n../pandas/_libs/meson.build:77:    'hashing': {'sources': ['hashing.pyx']},\r\n../pandas/_libs/meson.build:78:    'hashtable': {\r\n../pandas/_libs/meson.build:80:            'hashtable.pyx',\r\n../pandas/_libs/meson.build:81:            _hashtable_class_helper,\r\n../pandas/_libs/meson.build:82:            _hashtable_func_helper,\r\n../pandas/_libs/meson.build:84:        'deps': _khash_primitive_helper_dep,\r\n../pandas/_libs/meson.build:88:        'deps': _khash_primitive_helper_dep,\r\n../pandas/_libs/meson.build:94:        'deps': _khash_primitive_helper_dep,\r\n../pandas/_libs/meson.build:97:        'sources': ['join.pyx', _khash_primitive_helper],\r\n../pandas/_libs/meson.build:98:        'deps': _khash_primitive_helper_dep,\r\n../pandas/_libs/meson.build:119:        'deps': _khash_primitive_helper_dep,\r\n../pandas/_libs/meson.build:170:    'hashing.pyi',\r\n../pandas/_libs/meson.build:171:    'hashtable.pyi',\r\n../pandas/_libs/index.pyx:18:from pandas._libs.hashtable cimport HashTable\r\n../pandas/_libs/index.pyx:35:    hashtable as _hash,\r\n../pandas/_libs/index.pyx:53:        hash(val)\r\n../pandas/_libs/index.pyx:114:# Don't populate hash tables in monotonic indexes larger than this\r\n../pandas/_libs/index.pyx:161:        hash(val)\r\n../pandas/_libs/index.pyx:328:    cdef _make_hash_table(self, Py_ssize_t n):\r\n../pandas/_libs/index.pyx:332:        hash(val)\r\n../pandas/_libs/index.pyx:347:            self.mapping = self._make_hash_table(len(values))\r\n../pandas/_libs/index.pyx:537:    cdef _make_hash_table(self, Py_ssize_t n):\r\n../pandas/_libs/index.pyx:538:        return _hash.PyObjectHashTable(n)\r\n../pandas/_libs/index.pyx:552:    cdef _make_hash_table(self, Py_ssize_t n):\r\n../pandas/_libs/index.pyx:553:        return _hash.StringHashTable(n)\r\n../pandas/_libs/index.pyx:605:        #  - val is hashable\r\n../pandas/_libs/index.pyx:857:        #  - val is hashable\r\n../pandas/_libs/index.pyx:900:        #  - val is hashable\r\n../pandas/_libs/index.pyx:1179:        hash(val)\r\n../pandas/_libs/join.pyx:684:from pandas._libs.hashtable cimport Int64HashTable\r\n../pandas/_libs/join.pyx:693:                                 bint use_hashtable=True):\r\n../pandas/_libs/join.pyx:701:        Int64HashTable hash_table\r\n../pandas/_libs/join.pyx:714:    if use_hashtable:\r\n../pandas/_libs/join.pyx:715:        hash_table = Int64HashTable(right_size)\r\n../pandas/_libs/join.pyx:727:                if use_hashtable:\r\n../pandas/_libs/join.pyx:728:                    hash_table.set_item(right_by_values[right_pos], right_pos)\r\n../pandas/_libs/join.pyx:733:                if use_hashtable:\r\n../pandas/_libs/join.pyx:734:                    hash_table.set_item(right_by_values[right_pos], right_pos)\r\n../pandas/_libs/join.pyx:739:        if use_hashtable:\r\n../pandas/_libs/join.pyx:741:            found_right_pos = (hash_table.get_item(by_value)\r\n../pandas/_libs/join.pyx:742:                               if by_value in hash_table else -1)\r\n../pandas/_libs/join.pyx:764:                                bint use_hashtable=True):\r\n../pandas/_libs/join.pyx:772:        Int64HashTable hash_table\r\n../pandas/_libs/join.pyx:785:    if use_hashtable:\r\n../pandas/_libs/join.pyx:786:        hash_table = Int64HashTable(right_size)\r\n../pandas/_libs/join.pyx:798:                if use_hashtable:\r\n../pandas/_libs/join.pyx:799:                    hash_table.set_item(right_by_values[right_pos], right_pos)\r\n../pandas/_libs/join.pyx:804:                if use_hashtable:\r\n../pandas/_libs/join.pyx:805:                    hash_table.set_item(right_by_values[right_pos], right_pos)\r\n../pandas/_libs/join.pyx:810:        if use_hashtable:\r\n../pandas/_libs/join.pyx:812:            found_right_pos = (hash_table.get_item(by_value)\r\n../pandas/_libs/join.pyx:813:                               if by_value in hash_table else -1)\r\n../pandas/_libs/join.pyx:836:                                bint use_hashtable=True):\r\n../pandas/_libs/join.pyx:853:        use_hashtable\r\n../pandas/_libs/join.pyx:862:        use_hashtable\r\n../pandas/_libs/index_class_helper.pxi.in:38:    cdef _make_hash_table(self, Py_ssize_t n):\r\n../pandas/_libs/index_class_helper.pxi.in:40:        return _hash.{{name}}HashTable(n, uses_mask=True)\r\n../pandas/_libs/index_class_helper.pxi.in:42:        return _hash.{{name}}HashTable(n)\r\n../pandas/_libs/hashtable.pxd:6:from pandas._libs.khash cimport (\r\n../pandas/_libs/index.pyi:84:        levels: list[Index],  # all entries hashable\r\n../pandas/_libs/algos.pyx:45:from pandas._libs.khash cimport (\r\n../pandas/_libs/algos.pyx:234:    This is a reverse of the label factorization process.\r\n../pandas/_libs/khash_for_primitive_helper.pxi.in:2:Template for wrapping khash-tables for each primitive `dtype`\r\n../pandas/_libs/khash_for_primitive_helper.pxi.in:27:cdef extern from \"pandas/vendored/klib/khash_python.h\":\r\n../pandas/_libs/hashtable.pyx:22:from pandas._libs.khash cimport (\r\n../pandas/_libs/hashtable.pyx:29:    kh_python_hash_equal,\r\n../pandas/_libs/hashtable.pyx:30:    kh_python_hash_func,\r\n../pandas/_libs/hashtable.pyx:39:def get_hashtable_trace_domain():\r\n../pandas/_libs/hashtable.pyx:43:def object_hash(obj):\r\n../pandas/_libs/hashtable.pyx:44:    return kh_python_hash_func(obj)\r\n../pandas/_libs/hashtable.pyx:48:    return kh_python_hash_equal(a, b)\r\n../pandas/_libs/hashtable.pyx:57:include \"hashtable_class_helper.pxi\"\r\n../pandas/_libs/hashtable.pyx:58:include \"hashtable_func_helper.pxi\"\r\n../pandas/_libs/hashtable.pyx:61:# map derived hash-map types onto basic hash-map types:\r\n../pandas/_libs/hashtable.pyx:82:    def factorize(self, values, na_sentinel=-1, na_value=None, mask=None) -> np.ndarray:\r\n../pandas/_libs/hashtable.pyx:85:    def hash_inner_join(self, values, mask=None):\r\n../pandas/_libs/hashtable.pyx:98:    def factorize(\r\n../pandas/_libs/hashtable.pyx:112:        >>> fac.factorize(np.array([1,2,np.nan], dtype='O'), na_sentinel=20)\r\n../pandas/_libs/hashing.pyx:25:def hash_object_array(\r\n../pandas/_libs/hashing.pyx:32:    key : hash key, must be 16 byte len encoded\r\n../pandas/_libs/hashing.pyx:37:    1-d uint64 ndarray of hashes.\r\n../pandas/_libs/hashing.pyx:89:            #  the tuple entries are themselves hashable before converting\r\n../pandas/_libs/hashing.pyx:91:            hash(val)\r\n../pandas/_libs/hashing.pyx:95:                f\"{val} of type {type(val)} is not a valid type for hashing, \"\r\n../pandas/_libs/hashing.pyx:110:            result[i] = low_level_siphash(<uint8_t *>vecs[i], lens[i], kb)\r\n../pandas/_libs/hashing.pyx:151:cdef uint64_t low_level_siphash(uint8_t* data, size_t datalen,\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:56:#include \"khash.h\"\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:58:// Previously we were using the built in cpython hash function for doubles\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:60:// python 3.5 https://github.com/python/cpython/blob/3.5/Python/pyhash.c#L85\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:62:// The python 3 hash function has the invariant hash(x) == hash(int(x)) ==\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:63:// hash(decimal(x)) and the size of hash may be different by platform / version\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:65:// types will be cast before hashing, and if Py_ssize_t is 64 bits the\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:67:// hash, viewing the double bytes as an int64 and using khash's default hash for\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:69:// khash GH 28303 showed, that the simple xoring-version isn't good enough See\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:70:// GH 36729 for evaluation of the currently used murmur2-hash version An\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:71:// interesting alternative to expensive murmur2-hash would be to change the\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:91:static inline khuint32_t kh_float64_hash_func(double val) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:92:  // 0.0 and -0.0 should have the same hash:\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:96:  // all nans should have the same hash:\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:104:static inline khuint32_t kh_float32_hash_func(float val) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:105:  // 0.0 and -0.0 should have the same hash:\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:109:  // all nans should have the same hash:\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:117:#define kh_floats_hash_equal(a, b) ((a) == (b) || ((b) != (b) && (a) != (a)))\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:120:  KHASH_INIT(name, khfloat64_t, khval_t, 1, kh_float64_hash_func,              \\\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:121:             kh_floats_hash_equal)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:126:  KHASH_INIT(name, khfloat32_t, khval_t, 1, kh_float32_hash_func,              \\\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:127:             kh_floats_hash_equal)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:131:static inline khint32_t kh_complex128_hash_func(khcomplex128_t val) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:132:  return kh_float64_hash_func(val.real) ^ kh_float64_hash_func(val.imag);\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:134:static inline khint32_t kh_complex64_hash_func(khcomplex64_t val) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:135:  return kh_float32_hash_func(val.real) ^ kh_float32_hash_func(val.imag);\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:138:#define kh_complex_hash_equal(a, b)                                            \\\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:139:  (kh_floats_hash_equal(a.real, b.real) && kh_floats_hash_equal(a.imag, b.imag))\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:142:  KHASH_INIT(name, khcomplex64_t, khval_t, 1, kh_complex64_hash_func,          \\\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:143:             kh_complex_hash_equal)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:148:  KHASH_INIT(name, khcomplex128_t, khval_t, 1, kh_complex128_hash_func,        \\\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:149:             kh_complex_hash_equal)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:224:static inline Py_hash_t _Pandas_HashDouble(double val) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:225:  // Since Python3.10, nan is no longer has hash 0\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:236:static inline Py_hash_t floatobject_hash(PyFloatObject *key) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:243:static inline Py_hash_t complexobject_hash(PyComplexObject *key) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:244:  Py_uhash_t realhash = (Py_uhash_t)_Pandas_HashDouble(key->cval.real);\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:245:  Py_uhash_t imaghash = (Py_uhash_t)_Pandas_HashDouble(key->cval.imag);\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:246:  if (realhash == (Py_uhash_t)-1 || imaghash == (Py_uhash_t)-1) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:249:  Py_uhash_t combined = realhash + _PandasHASH_IMAG * imaghash;\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:250:  if (combined == (Py_uhash_t)-1) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:253:  return (Py_hash_t)combined;\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:256:static inline khuint32_t kh_python_hash_func(PyObject *key);\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:258:// we could use any hashing algorithm, this is the original CPython's for tuples\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:261:#define _PandasHASH_XXPRIME_1 ((Py_uhash_t)11400714785074694791ULL)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:262:#define _PandasHASH_XXPRIME_2 ((Py_uhash_t)14029467366897019727ULL)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:263:#define _PandasHASH_XXPRIME_5 ((Py_uhash_t)2870177450012600261ULL)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:267:#define _PandasHASH_XXPRIME_1 ((Py_uhash_t)2654435761UL)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:268:#define _PandasHASH_XXPRIME_2 ((Py_uhash_t)2246822519UL)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:269:#define _PandasHASH_XXPRIME_5 ((Py_uhash_t)374761393UL)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:274:static inline Py_hash_t tupleobject_hash(PyTupleObject *key) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:278:  Py_uhash_t acc = _PandasHASH_XXPRIME_5;\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:280:    Py_uhash_t lane = kh_python_hash_func(item[i]);\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:281:    if (lane == (Py_uhash_t)-1) {\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:289:  /* Add input length, mangled to keep the historical value of hash(()). */\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:292:  if (acc == (Py_uhash_t)-1) {\r\n"]
[90.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[90.002, "i", "sed -n '1,240p' benchmarks/algorithms.py\r"]
[90.004, "o", "sed -n '1,240p' benchmarks/algorithms.py\r\n"]
[90.006, "o", "\u001b[?2004l\r\nfrom importlib import import_module\r\n\r\nimport numpy as np\r\n\r\nimport pandas as pd\r\n\r\nfor imp in [\"pandas.util\", \"pandas.tools.hashing\"]:\r\n    try:\r\n        hashing = import_module(imp)\r\n        break\r\n    except (ImportError, TypeError, ValueError):\r\n        pass\r\n\r\n\r\nclass Factorize:\r\n    params = [\r\n        [True, False],\r\n        [True, False],\r\n        [\r\n            \"int64\",\r\n            \"uint64\",\r\n            \"float64\",\r\n            \"object\",\r\n            \"object_str\",\r\n            \"datetime64[ns]\",\r\n            \"datetime64[ns, tz]\",\r\n            \"Int64\",\r\n            \"boolean\",\r\n            \"string[pyarrow]\",\r\n        ],\r\n    ]\r\n    param_names = [\"unique\", \"sort\", \"dtype\"]\r\n\r\n    def setup(self, unique, sort, dtype):\r\n        N = 10**5\r\n\r\n        if dtype in [\"int64\", \"uint64\", \"Int64\", \"object\"]:\r\n            data = pd.Index(np.arange(N), dtype=dtype)\r\n        elif dtype == \"float64\":\r\n            data = pd.Index(np.random.randn(N), dtype=dtype)\r\n        elif dtype == \"boolean\":\r\n            data = pd.array(np.random.randint(0, 2, N), dtype=dtype)\r\n        elif dtype == \"datetime64[ns]\":\r\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\r\n        elif dtype == \"datetime64[ns, tz]\":\r\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\r\n        elif dtype == \"object_str\":\r\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\r\n        elif dtype == \"string[pyarrow]\":\r\n            data = pd.array(\r\n                pd.Index([f\"i-{i}\" for i in range(N)], dtype=object),\r\n                dtype=\"string[pyarrow]\",\r\n            )\r\n        else:\r\n            raise NotImplementedError\r\n\r\n        if not unique:\r\n            data = data.repeat(5)\r\n        self.data = data\r\n\r\n    def time_factorize(self, unique, sort, dtype):\r\n        pd.factorize(self.data, sort=sort)\r\n\r\n    def peakmem_factorize(self, unique, sort, dtype):\r\n        pd.factorize(self.data, sort=sort)\r\n\r\n\r\nclass Duplicated:\r\n    params = [\r\n        [True, False],\r\n        [\"first\", \"last\", False],\r\n        [\r\n            \"int64\",\r\n            \"uint64\",\r\n            \"float64\",\r\n            \"string\",\r\n            \"datetime64[ns]\",\r\n            \"datetime64[ns, tz]\",\r\n            \"timestamp[ms][pyarrow]\",\r\n            \"duration[s][pyarrow]\",\r\n        ],\r\n    ]\r\n    param_names = [\"unique\", \"keep\", \"dtype\"]\r\n\r\n    def setup(self, unique, keep, dtype):\r\n        N = 10**5\r\n        if dtype in [\"int64\", \"uint64\"]:\r\n            data = pd.Index(np.arange(N), dtype=dtype)\r\n        elif dtype == \"float64\":\r\n            data = pd.Index(np.random.randn(N), dtype=\"float64\")\r\n        elif dtype == \"string\":\r\n            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\r\n        elif dtype == \"datetime64[ns]\":\r\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\r\n        elif dtype == \"datetime64[ns, tz]\":\r\n            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\r\n        elif dtype in [\"timestamp[ms][pyarrow]\", \"duration[s][pyarrow]\"]:\r\n            data = pd.Index(np.arange(N), dtype=dtype)\r\n        else:\r\n            raise NotImplementedError\r\n        if not unique:\r\n            data = data.repeat(5)\r\n        self.idx = data\r\n        # cache is_unique\r\n        self.idx.is_unique\r\n\r\n    def time_duplicated(self, unique, keep, dtype):\r\n        self.idx.duplicated(keep=keep)\r\n\r\n\r\nclass DuplicatedMaskedArray:\r\n    params = [\r\n        [True, False],\r\n        [\"first\", \"last\", False],\r\n        [\"Int64\", \"Float64\"],\r\n    ]\r\n    param_names = [\"unique\", \"keep\", \"dtype\"]\r\n\r\n    def setup(self, unique, keep, dtype):\r\n        N = 10**5\r\n        data = pd.Series(np.arange(N), dtype=dtype)\r\n        data[list(range(1, N, 100))] = pd.NA\r\n        if not unique:\r\n            data = data.repeat(5)\r\n        self.ser = data\r\n        # cache is_unique\r\n        self.ser.is_unique\r\n\r\n    def time_duplicated(self, unique, keep, dtype):\r\n        self.ser.duplicated(keep=keep)\r\n\r\n\r\nclass Hashing:\r\n    def setup_cache(self):\r\n        N = 10**5\r\n\r\n        df = pd.DataFrame(\r\n            {\r\n                \"strings\": pd.Series(\r\n                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\r\n                        np.random.randint(0, 10000, size=N)\r\n                    )\r\n                ),\r\n                \"floats\": np.random.randn(N),\r\n                \"ints\": np.arange(N),\r\n                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\r\n                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\r\n            }\r\n        )\r\n        df[\"categories\"] = df[\"strings\"].astype(\"category\")\r\n        df.iloc[10:20] = np.nan\r\n        return df\r\n\r\n    def time_frame(self, df):\r\n        hashing.hash_pandas_object(df)\r\n\r\n    def time_series_int(self, df):\r\n        hashing.hash_pandas_object(df[\"ints\"])\r\n\r\n    def time_series_string(self, df):\r\n        hashing.hash_pandas_object(df[\"strings\"])\r\n\r\n    def time_series_float(self, df):\r\n        hashing.hash_pandas_object(df[\"floats\"])\r\n\r\n    def time_series_categorical(self, df):\r\n        hashing.hash_pandas_object(df[\"categories\"])\r\n\r\n    def time_series_timedeltas(self, df):\r\n        hashing.hash_pandas_object(df[\"timedeltas\"])\r\n\r\n    def time_series_dates(self, df):\r\n        hashing.hash_pandas_object(df[\"dates\"])\r\n\r\n\r\nclass Quantile:\r\n    params = [\r\n        [0, 0.5, 1],\r\n        [\"linear\", \"nearest\", \"lower\", \"higher\", \"midpoint\"],\r\n        [\"float64\", \"int64\", \"uint64\"],\r\n    ]\r\n    param_names = [\"quantile\", \"interpolation\", \"dtype\"]\r\n\r\n    def setup(self, quantile, interpolation, dtype):\r\n        N = 10**5\r\n        if dtype in [\"int64\", \"uint64\"]:\r\n            data = np.arange(N, dtype=dtype)\r\n        elif dtype == \"float64\":\r\n            data = np.random.randn(N)\r\n        else:\r\n            raise NotImplementedError\r\n        self.ser = pd.Series(data.repeat(5))\r\n\r\n    def time_quantile(self, quantile, interpolation, dtype):\r\n        self.ser.quantile(quantile, interpolation=interpolation)\r\n\r\n\r\nclass SortIntegerArray:\r\n    params = [10**3, 10**5]\r\n\r\n    def setup(self, N):\r\n        data = np.arange(N, dtype=float)\r\n        data[40] = np.nan\r\n        self.array = pd.array(data, dtype=\"Int64\")\r\n\r\n    def time_argsort(self, N):\r\n        self.array.argsort()\r\n\r\n\r\nfrom .pandas_vb_common import setup  # noqa: F401 isort:skip\r\n"]
[95.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[95.002, "i", "sed -n '180,320p' benchmarks/arithmetic.py\r"]
[95.004, "o", "sed -n '180,320p' benchmarks/arithmetic.py\r\n"]
[95.006, "o", "\u001b[?2004l\r\n        self.df2 = DataFrame(np.random.randn(20000, 100))\r\n\r\n        if threads != \"default\":\r\n            expr.set_numexpr_threads(threads)\r\n        if not use_numexpr:\r\n            expr.set_use_numexpr(False)\r\n\r\n    def time_frame_add(self, use_numexpr, threads):\r\n        self.df + self.df2\r\n\r\n    def time_frame_mult(self, use_numexpr, threads):\r\n        self.df * self.df2\r\n\r\n    def time_frame_multi_and(self, use_numexpr, threads):\r\n        self.df[(self.df > 0) & (self.df2 > 0)]\r\n\r\n    def time_frame_comparison(self, use_numexpr, threads):\r\n        self.df > self.df2\r\n\r\n    def teardown(self, use_numexpr, threads):\r\n        expr.set_use_numexpr(True)\r\n        expr.set_numexpr_threads()\r\n\r\n\r\nclass Ops2:\r\n    def setup(self):\r\n        N = 10**3\r\n        self.df = DataFrame(np.random.randn(N, N))\r\n        self.df2 = DataFrame(np.random.randn(N, N))\r\n\r\n        self.df_int = DataFrame(\r\n            np.random.randint(\r\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\r\n            )\r\n        )\r\n        self.df2_int = DataFrame(\r\n            np.random.randint(\r\n                np.iinfo(np.int16).min, np.iinfo(np.int16).max, size=(N, N)\r\n            )\r\n        )\r\n\r\n        self.s = Series(np.random.randn(N))\r\n\r\n    # Division\r\n\r\n    def time_frame_float_div(self):\r\n        self.df // self.df2\r\n\r\n    def time_frame_float_div_by_zero(self):\r\n        self.df / 0\r\n\r\n    def time_frame_float_floor_by_zero(self):\r\n        self.df // 0\r\n\r\n    def time_frame_int_div_by_zero(self):\r\n        self.df_int / 0\r\n\r\n    # Modulo\r\n\r\n    def time_frame_int_mod(self):\r\n        self.df_int % self.df2_int\r\n\r\n    def time_frame_float_mod(self):\r\n        self.df % self.df2\r\n\r\n    # Dot product\r\n\r\n    def time_frame_dot(self):\r\n        self.df.dot(self.df2)\r\n\r\n    def time_series_dot(self):\r\n        self.s.dot(self.s)\r\n\r\n    def time_frame_series_dot(self):\r\n        self.df.dot(self.s)\r\n\r\n\r\nclass Timeseries:\r\n    params = [None, \"US/Eastern\"]\r\n    param_names = [\"tz\"]\r\n\r\n    def setup(self, tz):\r\n        N = 10**6\r\n        halfway = (N // 2) - 1\r\n        self.s = Series(date_range(\"20010101\", periods=N, freq=\"min\", tz=tz))\r\n        self.ts = self.s[halfway]\r\n\r\n        self.s2 = Series(date_range(\"20010101\", periods=N, freq=\"s\", tz=tz))\r\n        self.ts_different_reso = Timestamp(\"2001-01-02\", tz=tz)\r\n\r\n    def time_series_timestamp_compare(self, tz):\r\n        self.s <= self.ts\r\n\r\n    def time_series_timestamp_different_reso_compare(self, tz):\r\n        self.s <= self.ts_different_reso\r\n\r\n    def time_timestamp_series_compare(self, tz):\r\n        self.ts >= self.s\r\n\r\n    def time_timestamp_ops_diff(self, tz):\r\n        self.s2.diff()\r\n\r\n    def time_timestamp_ops_diff_with_shift(self, tz):\r\n        self.s - self.s.shift()\r\n\r\n\r\nclass IrregularOps:\r\n    def setup(self):\r\n        N = 10**5\r\n        idx = date_range(start=\"1/1/2000\", periods=N, freq=\"s\")\r\n        s = Series(np.random.randn(N), index=idx)\r\n        self.left = s.sample(frac=1)\r\n        self.right = s.sample(frac=1)\r\n\r\n    def time_add(self):\r\n        self.left + self.right\r\n\r\n\r\nclass TimedeltaOps:\r\n    def setup(self):\r\n        self.td = to_timedelta(np.arange(1000000))\r\n        self.ts = Timestamp(\"2000\")\r\n\r\n    def time_add_td_ts(self):\r\n        self.td + self.ts\r\n\r\n\r\nclass CategoricalComparisons:\r\n    params = [\"__lt__\", \"__le__\", \"__eq__\", \"__ne__\", \"__ge__\", \"__gt__\"]\r\n    param_names = [\"op\"]\r\n\r\n    def setup(self, op):\r\n        N = 10**5\r\n        self.cat = pd.Categorical(list(\"aabbcd\") * N, ordered=True)\r\n\r\n    def time_categorical_op(self, op):\r\n        getattr(self.cat, op)(\"b\")\r\n\r\n\r\nclass IndexArithmetic:\r\n    params = [\"float\", \"int\"]\r\n"]
[100.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[100.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[100.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[100.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   8.04\u00b10.1ms\r\n\r\nWed Oct  1 17:33:16 2025    /tmp/tmpbs_7noqg\r\n\r\n         798 function calls (782 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n      3/2    0.000    0.000    0.007    0.004 hashing.py:235(hash_array)\r\n      3/2    0.001    0.000    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:2406(is_unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x556c9f754640}\r\n        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[105.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[105.002, "i", "sed -n '1,260p' ../pandas/core/util/hashing.py\r"]
[105.004, "o", "sed -n '1,260p' ../pandas/core/util/hashing.py\r\n"]
[105.006, "o", "\u001b[?2004l\r\n\"\"\"\r\ndata hash pandas / numpy objects\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport itertools\r\nfrom typing import TYPE_CHECKING\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs.hashing import hash_object_array\r\n\r\nfrom pandas.core.dtypes.common import is_list_like\r\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCExtensionArray,\r\n    ABCIndex,\r\n    ABCMultiIndex,\r\n    ABCSeries,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterable,\r\n        Iterator,\r\n    )\r\n\r\n    from pandas._typing import (\r\n        ArrayLike,\r\n        npt,\r\n    )\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        Index,\r\n        MultiIndex,\r\n        Series,\r\n    )\r\n\r\n\r\n# 16 byte long hashing key\r\n_default_hash_key = \"0123456789123456\"\r\n\r\n\r\ndef combine_hash_arrays(\r\n    arrays: Iterator[np.ndarray], num_items: int\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Parameters\r\n    ----------\r\n    arrays : Iterator[np.ndarray]\r\n    num_items : int\r\n\r\n    Returns\r\n    -------\r\n    np.ndarray[uint64]\r\n\r\n    Should be the same as CPython's tupleobject.c\r\n    \"\"\"\r\n    try:\r\n        first = next(arrays)\r\n    except StopIteration:\r\n        return np.array([], dtype=np.uint64)\r\n\r\n    arrays = itertools.chain([first], arrays)\r\n\r\n    mult = np.uint64(1000003)\r\n    out = np.zeros_like(first) + np.uint64(0x345678)\r\n    last_i = 0\r\n    for i, a in enumerate(arrays):\r\n        inverse_i = num_items - i\r\n        out ^= a\r\n        out *= mult\r\n        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n        last_i = i\r\n    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n    out += np.uint64(97531)\r\n    return out\r\n\r\n\r\ndef hash_pandas_object(\r\n    obj: Index | DataFrame | Series,\r\n    index: bool = True,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str | None = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> Series:\r\n    \"\"\"\r\n    Return a data hash of the Index/Series/DataFrame.\r\n\r\n    Parameters\r\n    ----------\r\n    obj : Index, Series, or DataFrame\r\n    index : bool, default True\r\n        Include the index in the hash (if Series/DataFrame).\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    Series of uint64\r\n        Same length as the object.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n    0    14639053686158035780\r\n    1     3869563279212530728\r\n    2      393322362522515241\r\n    dtype: uint64\r\n    \"\"\"\r\n    from pandas import Series\r\n\r\n    if hash_key is None:\r\n        hash_key = _default_hash_key\r\n\r\n    if isinstance(obj, ABCMultiIndex):\r\n        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCIndex):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCSeries):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        if index:\r\n            index_iter = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            arrays = itertools.chain([h], index_iter)\r\n            h = combine_hash_arrays(arrays, 2)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCDataFrame):\r\n        hashes = (\r\n            hash_array(series._values, encoding, hash_key, categorize)\r\n            for _, series in obj.items()\r\n        )\r\n        num_items = len(obj.columns)\r\n        if index:\r\n            index_hash_generator = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            num_items += 1\r\n\r\n            # keep `hashes` specifically a generator to keep mypy happy\r\n            _hashes = itertools.chain(hashes, index_hash_generator)\r\n            hashes = (x for x in _hashes)\r\n        h = combine_hash_arrays(hashes, num_items)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n    else:\r\n        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n\r\n    return ser\r\n\r\n\r\ndef hash_tuples(\r\n    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : MultiIndex or listlike-of-tuples\r\n    encoding : str, default 'utf8'\r\n    hash_key : str, default _default_hash_key\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64] of hashed values\r\n    \"\"\"\r\n    if not is_list_like(vals):\r\n        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n\r\n    from pandas import (\r\n        Categorical,\r\n        MultiIndex,\r\n    )\r\n\r\n    if not isinstance(vals, ABCMultiIndex):\r\n        mi = MultiIndex.from_tuples(vals)\r\n    else:\r\n        mi = vals\r\n\r\n    # create a list-of-Categoricals\r\n    cat_vals = [\r\n        Categorical._simple_new(\r\n            mi.codes[level],\r\n            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n        )\r\n        for level in range(mi.nlevels)\r\n    ]\r\n\r\n    # hash the list-of-ndarrays\r\n    hashes = (\r\n        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n        for cat in cat_vals\r\n    )\r\n    h = combine_hash_arrays(hashes, len(cat_vals))\r\n\r\n    return h\r\n\r\n\r\ndef hash_array(\r\n    vals: ArrayLike,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Given a 1d array, return an array of deterministic integers.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : ndarray or ExtensionArray\r\n        The input array to hash.\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64, ndim=1]\r\n        Hashed values, same length as the vals.\r\n\r\n"]
[110.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[110.002, "i", "grep -RIn --line-number --color=never -E 'drop_duplicates|duplicated' ../pandas/core | head -n 200\r"]
[110.004, "o", "grep -RIn --line-number --color=never -E 'drop_duplicates|duplicated' ../pandas/core | head -n 200\r\n"]
[110.006, "o", "\u001b[?2004l\r\n../pandas/core/arrays/masked.py:983:    @doc(ExtensionArray.duplicated)\r\n../pandas/core/arrays/masked.py:984:    def duplicated(\r\n../pandas/core/arrays/masked.py:989:        return algos.duplicated(values, keep=keep, mask=mask)\r\n../pandas/core/arrays/base.py:63:    duplicated,\r\n../pandas/core/arrays/base.py:132:    duplicated\r\n../pandas/core/arrays/base.py:1287:    def duplicated(\r\n../pandas/core/arrays/base.py:1303:            With true in indices where elements are duplicated and false otherwise.\r\n../pandas/core/arrays/base.py:1307:        DataFrame.duplicated : Return boolean Series denoting\r\n../pandas/core/arrays/base.py:1309:        Series.duplicated : Indicate duplicate Series values.\r\n../pandas/core/arrays/base.py:1315:        >>> pd.array([1, 1, 2, 3, 3], dtype=\"Int64\").duplicated()\r\n../pandas/core/arrays/base.py:1319:        return duplicated(values=self, keep=keep, mask=mask)\r\n../pandas/core/arrays/sparse/array.py:856:    @doc(ExtensionArray.duplicated)\r\n../pandas/core/arrays/sparse/array.py:857:    def duplicated(\r\n../pandas/core/arrays/sparse/array.py:862:        return algos.duplicated(values, keep=keep, mask=mask)\r\n../pandas/core/arrays/arrow/array.py:1489:    @doc(ExtensionArray.duplicated)\r\n../pandas/core/arrays/arrow/array.py:1490:    def duplicated(\r\n../pandas/core/arrays/arrow/array.py:1511:        return algos.duplicated(values, keep=keep, mask=mask)\r\n../pandas/core/arrays/categorical.py:1600:    # Validators; ideally these can be de-duplicated\r\n../pandas/core/generic.py:11200:            rs = rs.loc[~rs.index.duplicated()]\r\n../pandas/core/base.py:1161:        Series.drop_duplicates : Return Series with duplicate values removed.\r\n../pandas/core/base.py:1162:        Series.duplicated : Indicate duplicate Series values.\r\n../pandas/core/base.py:1458:    def drop_duplicates(self, *, keep: DropKeep = \"first\") -> Self:\r\n../pandas/core/base.py:1459:        duplicated = self._duplicated(keep=keep)\r\n../pandas/core/base.py:1461:        return self[~duplicated]  # type: ignore[index]\r\n../pandas/core/base.py:1464:    def _duplicated(self, keep: DropKeep = \"first\") -> npt.NDArray[np.bool_]:\r\n../pandas/core/base.py:1467:            return arr.duplicated(keep=keep)\r\n../pandas/core/base.py:1468:        return algorithms.duplicated(arr, keep=keep)\r\n../pandas/core/frame.py:49:from pandas._libs.hashtable import duplicated\r\n../pandas/core/frame.py:3945:            # GH#45316 Return view if key is not duplicated\r\n../pandas/core/frame.py:3946:            # Only use drop_duplicates with duplicates for performance\r\n../pandas/core/frame.py:3949:                or key in self.columns.drop_duplicates(keep=False)\r\n../pandas/core/frame.py:4181:            # Column to set is duplicated\r\n../pandas/core/frame.py:5333:        DataFrame.drop_duplicates : Return DataFrame with duplicate rows\r\n../pandas/core/frame.py:5645:        DataFrame.drop_duplicates: Return DataFrame with duplicate rows removed.\r\n../pandas/core/frame.py:6067:            duplicates = index[index.duplicated()].unique()\r\n../pandas/core/frame.py:6585:    def drop_duplicates(\r\n../pandas/core/frame.py:6595:    def drop_duplicates(\r\n../pandas/core/frame.py:6605:    def drop_duplicates(\r\n../pandas/core/frame.py:6614:    def drop_duplicates(\r\n../pandas/core/frame.py:6680:        >>> df.drop_duplicates()\r\n../pandas/core/frame.py:6689:        >>> df.drop_duplicates(subset=[\"brand\"])\r\n../pandas/core/frame.py:6696:        >>> df.drop_duplicates(subset=[\"brand\", \"style\"], keep=\"last\")\r\n../pandas/core/frame.py:6708:        result = self[-self.duplicated(subset, keep=keep)]\r\n../pandas/core/frame.py:6718:    def duplicated(\r\n../pandas/core/frame.py:6743:            Boolean series for each duplicated rows.\r\n../pandas/core/frame.py:6747:        Index.duplicated : Equivalent method on index.\r\n../pandas/core/frame.py:6748:        Series.duplicated : Equivalent method on Series.\r\n../pandas/core/frame.py:6749:        Series.drop_duplicates : Remove duplicate values from Series.\r\n../pandas/core/frame.py:6750:        DataFrame.drop_duplicates : Remove duplicate values from DataFrame.\r\n../pandas/core/frame.py:6771:        By default, for each set of duplicated values, the first occurrence\r\n../pandas/core/frame.py:6774:        >>> df.duplicated()\r\n../pandas/core/frame.py:6782:        By using 'last', the last occurrence of each set of duplicated values\r\n../pandas/core/frame.py:6785:        >>> df.duplicated(keep=\"last\")\r\n../pandas/core/frame.py:6795:        >>> df.duplicated(keep=False)\r\n../pandas/core/frame.py:6805:        >>> df.duplicated(subset=[\"brand\"])\r\n../pandas/core/frame.py:6842:            result = self[next(iter(subset))].duplicated(keep)\r\n../pandas/core/frame.py:6849:            result = self._constructor_sliced(duplicated(ids, keep), index=self.index)\r\n../pandas/core/frame.py:6850:        return result.__finalize__(self, method=\"duplicated\")\r\n../pandas/core/frame.py:9735:            index will be duplicated for these rows.\r\n../pandas/core/frame.py:9803:            duplicate_cols = self.columns[self.columns.duplicated()].tolist()\r\n../pandas/core/tools/datetimes.py:259:                cache_array = cache_array[~cache_array.index.duplicated()]\r\n../pandas/core/reshape/merge.py:3065:        # Only warn when duplicates are caused because of suffixes, already duplicated\r\n../pandas/core/reshape/merge.py:3067:        dups = llabels[(llabels.duplicated()) & (~left.duplicated())].tolist()\r\n../pandas/core/reshape/merge.py:3069:        dups.extend(rlabels[(rlabels.duplicated()) & (~right.duplicated())].tolist())\r\n../pandas/core/reshape/pivot.py:842:    # which might cause duplicated names because None is the default for\r\n../pandas/core/reshape/melt.py:650:    if df[i].duplicated().any():\r\n../pandas/core/reshape/concat.py:671:            overlap = concat_axis[concat_axis.duplicated()].unique()\r\n../pandas/core/reshape/concat.py:723:        overlap = concat_axis[concat_axis.duplicated()].unique()\r\n../pandas/core/reshape/reshape.py:964:        column_codes = ordered_stack_cols.drop_duplicates().codes\r\n../pandas/core/indexes/base.py:229:    \"duplicated\": \"np.ndarray\",\r\n../pandas/core/indexes/base.py:730:        duplicates = self[self.duplicated(keep=\"first\")].unique()\r\n../pandas/core/indexes/base.py:2803:    def drop_duplicates(self, *, keep: DropKeep = \"first\") -> Self:\r\n../pandas/core/indexes/base.py:2821:        Series.drop_duplicates : Equivalent method on Series.\r\n../pandas/core/indexes/base.py:2822:        DataFrame.drop_duplicates : Equivalent method on DataFrame.\r\n../pandas/core/indexes/base.py:2823:        Index.duplicated : Related method on Index, indicating duplicate\r\n../pandas/core/indexes/base.py:2834:        set of duplicated entries. The default value of keep is 'first'.\r\n../pandas/core/indexes/base.py:2836:        >>> idx.drop_duplicates(keep=\"first\")\r\n../pandas/core/indexes/base.py:2839:        The value 'last' keeps the last occurrence for each set of duplicated\r\n../pandas/core/indexes/base.py:2842:        >>> idx.drop_duplicates(keep=\"last\")\r\n../pandas/core/indexes/base.py:2845:        The value ``False`` discards all sets of duplicated entries.\r\n../pandas/core/indexes/base.py:2847:        >>> idx.drop_duplicates(keep=False)\r\n../pandas/core/indexes/base.py:2853:        return super().drop_duplicates(keep=keep)\r\n../pandas/core/indexes/base.py:2855:    def duplicated(self, keep: DropKeep = \"first\") -> npt.NDArray[np.bool_]:\r\n../pandas/core/indexes/base.py:2881:        Series.duplicated : Equivalent method on pandas.Series.\r\n../pandas/core/indexes/base.py:2882:        DataFrame.duplicated : Equivalent method on pandas.DataFrame.\r\n../pandas/core/indexes/base.py:2883:        Index.drop_duplicates : Remove duplicate values from Index.\r\n../pandas/core/indexes/base.py:2887:        By default, for each set of duplicated values, the first occurrence is\r\n../pandas/core/indexes/base.py:2891:        >>> idx.duplicated()\r\n../pandas/core/indexes/base.py:2896:        >>> idx.duplicated(keep=\"first\")\r\n../pandas/core/indexes/base.py:2899:        By using 'last', the last occurrence of each set of duplicated values\r\n../pandas/core/indexes/base.py:2902:        >>> idx.duplicated(keep=\"last\")\r\n../pandas/core/indexes/base.py:2907:        >>> idx.duplicated(keep=False)\r\n../pandas/core/indexes/base.py:2913:        return self._duplicated(keep=keep)\r\n../pandas/core/indexes/base.py:3133:            #  test_union_same_value_duplicated_in_both fails)\r\n../pandas/core/indexes/base.py:3303:                    res = result.drop_duplicates()\r\n../pandas/core/indexes/base.py:6989:        Index.drop_duplicates : Return Index with duplicate values removed.\r\n../pandas/core/indexes/interval.py:446:        check_idx = np.where(left.duplicated(keep=False))[0]\r\n../pandas/core/indexes/multi.py:31:from pandas._libs.hashtable import duplicated\r\n../pandas/core/indexes/multi.py:1746:    @doc(Index.duplicated)\r\n../pandas/core/indexes/multi.py:1747:    def duplicated(self, keep: DropKeep = \"first\") -> npt.NDArray[np.bool_]:\r\n../pandas/core/indexes/multi.py:1751:        return duplicated(ids, keep)\r\n../pandas/core/indexes/multi.py:1753:    # error: Cannot override final attribute \"_duplicated\"\r\n../pandas/core/indexes/multi.py:1755:    _duplicated = duplicated  # type: ignore[misc]\r\n../pandas/core/indexes/multi.py:1787:            if True, drop duplicated values\r\n../pandas/core/indexes/multi.py:1874:            return self.drop_duplicates()\r\n../pandas/core/indexes/multi.py:2620:        are present and no levels are duplicated. This method is helpful for aligning\r\n../pandas/core/series.py:214:    \"duplicated\": \"Series\",\r\n../pandas/core/series.py:2101:        Series.drop_duplicates : Return Series with duplicate values removed.\r\n../pandas/core/series.py:2155:    def drop_duplicates(\r\n../pandas/core/series.py:2164:    def drop_duplicates(\r\n../pandas/core/series.py:2169:    def drop_duplicates(\r\n../pandas/core/series.py:2173:    def drop_duplicates(\r\n../pandas/core/series.py:2207:        Index.drop_duplicates : Equivalent method on Index.\r\n../pandas/core/series.py:2208:        DataFrame.drop_duplicates : Equivalent method on DataFrame.\r\n../pandas/core/series.py:2209:        Series.duplicated : Related method on Series, indicating duplicate\r\n../pandas/core/series.py:2215:        Generate a Series with duplicated entries.\r\n../pandas/core/series.py:2229:        With the 'keep' parameter, the selection behavior of duplicated values\r\n../pandas/core/series.py:2231:        set of duplicated entries. The default value of keep is 'first'.\r\n../pandas/core/series.py:2233:        >>> s.drop_duplicates()\r\n../pandas/core/series.py:2241:        each set of duplicated entries.\r\n../pandas/core/series.py:2243:        >>> s.drop_duplicates(keep=\"last\")\r\n../pandas/core/series.py:2251:        duplicated entries.\r\n../pandas/core/series.py:2253:        >>> s.drop_duplicates(keep=False)\r\n../pandas/core/series.py:2260:        result = super().drop_duplicates(keep=keep)\r\n../pandas/core/series.py:2271:    def duplicated(self, keep: DropKeep = \"first\") -> Series:\r\n../pandas/core/series.py:2298:        Index.duplicated : Equivalent method on pandas.Index.\r\n../pandas/core/series.py:2299:        DataFrame.duplicated : Equivalent method on pandas.DataFrame.\r\n../pandas/core/series.py:2300:        Series.drop_duplicates : Remove duplicate values from Series.\r\n../pandas/core/series.py:2304:        By default, for each set of duplicated values, the first occurrence is\r\n../pandas/core/series.py:2308:        >>> animals.duplicated()\r\n../pandas/core/series.py:2318:        >>> animals.duplicated(keep=\"first\")\r\n../pandas/core/series.py:2326:        By using 'last', the last occurrence of each set of duplicated values\r\n../pandas/core/series.py:2329:        >>> animals.duplicated(keep=\"last\")\r\n../pandas/core/series.py:2339:        >>> animals.duplicated(keep=False)\r\n../pandas/core/series.py:2347:        res = self._duplicated(keep=keep)\r\n../pandas/core/series.py:2349:        return result.__finalize__(self, method=\"duplicated\")\r\n../pandas/core/series.py:4204:            Exploded lists to rows; index will be duplicated for these rows.\r\n../pandas/core/series.py:5040:        Series.drop_duplicates : Return Series with duplicate values removed.\r\n../pandas/core/series.py:5113:        Series.drop_duplicates: Return Series with duplicate values removed.\r\n../pandas/core/interchange/column.py:93:                \"after converting column names to string, resulted in duplicated \"\r\n../pandas/core/groupby/generic.py:29:from pandas._libs.hashtable import duplicated\r\n../pandas/core/groupby/generic.py:857:        mask = duplicated(group_index, \"first\")\r\n../pandas/core/groupby/indexing.py:83:        - If the index specification results in overlaps, the item is not duplicated.\r\n../pandas/core/apply.py:1749:            # GH 28426 will raise error if duplicated function names are used and\r\n../pandas/core/apply.py:1841:    # uniquify aggfunc name if duplicated in order list\r\n../pandas/core/algorithms.py:959:def duplicated(\r\n../pandas/core/algorithms.py:982:    duplicated : ndarray[bool]\r\n../pandas/core/algorithms.py:985:    return htable.duplicated(values, keep=keep, mask=mask)\r\n"]
[115.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[115.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[115.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[115.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                  7.86\u00b10.05ms\r\n\r\nWed Oct  1 17:34:27 2025    /tmp/tmphuzfyi3t\r\n\r\n         798 function calls (782 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n      3/2    0.000    0.000    0.007    0.004 hashing.py:235(hash_array)\r\n      3/2    0.001    0.000    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:2406(is_unique)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55907afc8640}\r\n        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n\r\n\r\n"]
[120.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[120.002, "i", "sed -n '1,260p' ../pandas/core/util/hashing.py\r"]
[120.004, "o", "sed -n '1,260p' ../pandas/core/util/hashing.py\r\n"]
[120.006, "o", "\u001b[?2004l\r\n\"\"\"\r\ndata hash pandas / numpy objects\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport itertools\r\nfrom typing import TYPE_CHECKING\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs.hashing import hash_object_array\r\n\r\nfrom pandas.core.dtypes.common import is_list_like\r\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCExtensionArray,\r\n    ABCIndex,\r\n    ABCMultiIndex,\r\n    ABCSeries,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterable,\r\n        Iterator,\r\n    )\r\n\r\n    from pandas._typing import (\r\n        ArrayLike,\r\n        npt,\r\n    )\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        Index,\r\n        MultiIndex,\r\n        Series,\r\n    )\r\n\r\n\r\n# 16 byte long hashing key\r\n_default_hash_key = \"0123456789123456\"\r\n\r\n\r\ndef combine_hash_arrays(\r\n    arrays: Iterator[np.ndarray], num_items: int\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Parameters\r\n    ----------\r\n    arrays : Iterator[np.ndarray]\r\n    num_items : int\r\n\r\n    Returns\r\n    -------\r\n    np.ndarray[uint64]\r\n\r\n    Should be the same as CPython's tupleobject.c\r\n    \"\"\"\r\n    try:\r\n        first = next(arrays)\r\n    except StopIteration:\r\n        return np.array([], dtype=np.uint64)\r\n\r\n    arrays = itertools.chain([first], arrays)\r\n\r\n    mult = np.uint64(1000003)\r\n    out = np.zeros_like(first) + np.uint64(0x345678)\r\n    last_i = 0\r\n    for i, a in enumerate(arrays):\r\n        inverse_i = num_items - i\r\n        out ^= a\r\n        out *= mult\r\n        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n        last_i = i\r\n    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n    out += np.uint64(97531)\r\n    return out\r\n\r\n\r\ndef hash_pandas_object(\r\n    obj: Index | DataFrame | Series,\r\n    index: bool = True,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str | None = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> Series:\r\n    \"\"\"\r\n    Return a data hash of the Index/Series/DataFrame.\r\n\r\n    Parameters\r\n    ----------\r\n    obj : Index, Series, or DataFrame\r\n    index : bool, default True\r\n        Include the index in the hash (if Series/DataFrame).\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    Series of uint64\r\n        Same length as the object.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n    0    14639053686158035780\r\n    1     3869563279212530728\r\n    2      393322362522515241\r\n    dtype: uint64\r\n    \"\"\"\r\n    from pandas import Series\r\n\r\n    if hash_key is None:\r\n        hash_key = _default_hash_key\r\n\r\n    if isinstance(obj, ABCMultiIndex):\r\n        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCIndex):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCSeries):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        if index:\r\n            index_iter = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            arrays = itertools.chain([h], index_iter)\r\n            h = combine_hash_arrays(arrays, 2)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCDataFrame):\r\n        hashes = (\r\n            hash_array(series._values, encoding, hash_key, categorize)\r\n            for _, series in obj.items()\r\n        )\r\n        num_items = len(obj.columns)\r\n        if index:\r\n            index_hash_generator = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            num_items += 1\r\n\r\n            # keep `hashes` specifically a generator to keep mypy happy\r\n            _hashes = itertools.chain(hashes, index_hash_generator)\r\n            hashes = (x for x in _hashes)\r\n        h = combine_hash_arrays(hashes, num_items)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n    else:\r\n        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n\r\n    return ser\r\n\r\n\r\ndef hash_tuples(\r\n    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : MultiIndex or listlike-of-tuples\r\n    encoding : str, default 'utf8'\r\n    hash_key : str, default _default_hash_key\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64] of hashed values\r\n    \"\"\"\r\n    if not is_list_like(vals):\r\n        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n\r\n    from pandas import (\r\n        Categorical,\r\n        MultiIndex,\r\n    )\r\n\r\n    if not isinstance(vals, ABCMultiIndex):\r\n        mi = MultiIndex.from_tuples(vals)\r\n    else:\r\n        mi = vals\r\n\r\n    # create a list-of-Categoricals\r\n    cat_vals = [\r\n        Categorical._simple_new(\r\n            mi.codes[level],\r\n            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n        )\r\n        for level in range(mi.nlevels)\r\n    ]\r\n\r\n    # hash the list-of-ndarrays\r\n    hashes = (\r\n        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n        for cat in cat_vals\r\n    )\r\n    h = combine_hash_arrays(hashes, len(cat_vals))\r\n\r\n    return h\r\n\r\n\r\ndef hash_array(\r\n    vals: ArrayLike,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Given a 1d array, return an array of deterministic integers.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : ndarray or ExtensionArray\r\n        The input array to hash.\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64, ndim=1]\r\n        Hashed values, same length as the vals.\r\n\r\n"]
[125.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[125.002, "i", "sed -n '260,520p' ../pandas/core/util/hashing.py\r"]
[125.004, "o", "sed -n '260,520p' ../pandas/core/util/hashing.py\r\n"]
[125.006, "o", "\u001b[?2004l\r\n\r\n    See Also\r\n    --------\r\n    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n      dtype=uint64)\r\n    \"\"\"\r\n    if not hasattr(vals, \"dtype\"):\r\n        raise TypeError(\"must pass a ndarray-like\")\r\n\r\n    if isinstance(vals, ABCExtensionArray):\r\n        return vals._hash_pandas_object(\r\n            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n        )\r\n\r\n    if not isinstance(vals, np.ndarray):\r\n        # GH#42003\r\n        raise TypeError(\r\n            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n        )\r\n\r\n    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n\r\n\r\ndef _hash_ndarray(\r\n    vals: np.ndarray,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    See hash_array.__doc__.\r\n    \"\"\"\r\n    dtype = vals.dtype\r\n\r\n    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n    if np.issubdtype(dtype, np.complex128):\r\n        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n        return hash_real + 23 * hash_imag\r\n\r\n    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n    # manage it.\r\n    if dtype == bool:\r\n        vals = vals.astype(\"u8\")\r\n    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n    else:\r\n        # With repeated values, its MUCH faster to categorize object dtypes,\r\n        # then hash and rename categories. We allow skipping the categorization\r\n        # when the values are known/likely to be unique.\r\n        if categorize:\r\n            from pandas import (\r\n                Categorical,\r\n                Index,\r\n                factorize,\r\n            )\r\n\r\n            codes, categories = factorize(vals, sort=False)\r\n            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n            cat = Categorical._simple_new(codes, dtype)\r\n            return cat._hash_pandas_object(\r\n                encoding=encoding, hash_key=hash_key, categorize=False\r\n            )\r\n\r\n        try:\r\n            vals = hash_object_array(vals, hash_key, encoding)\r\n        except TypeError:\r\n            # we have mixed types\r\n            vals = hash_object_array(\r\n                vals.astype(str).astype(object), hash_key, encoding\r\n            )\r\n\r\n    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n    vals ^= vals >> 30\r\n    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n    vals ^= vals >> 27\r\n    vals *= np.uint64(0x94D049BB133111EB)\r\n    vals ^= vals >> 31\r\n    return vals\r\n"]
[130.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[130.002, "i", "sed -n '1,240p' ../pandas/core/frame.py\r"]
[130.004, "o", "sed -n '1,240p' ../pandas/core/frame.py\r\n"]
[130.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nDataFrame\r\n---------\r\nAn efficient 2D container for potentially mixed-type time series or other\r\nlabeled data series.\r\n\r\nSimilar to its R counterpart, data.frame, except providing automatic data\r\nalignment and a host of useful data manipulation methods having to do with the\r\nlabeling information\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom collections import abc\r\nfrom collections.abc import (\r\n    Callable,\r\n    Hashable,\r\n    Iterable,\r\n    Iterator,\r\n    Mapping,\r\n    Sequence,\r\n)\r\nimport functools\r\nfrom io import StringIO\r\nimport itertools\r\nimport operator\r\nimport sys\r\nfrom textwrap import dedent\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\nfrom numpy import ma\r\n\r\nfrom pandas._config import get_option\r\n\r\nfrom pandas._libs import (\r\n    algos as libalgos,\r\n    lib,\r\n    properties,\r\n)\r\nfrom pandas._libs.hashtable import duplicated\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import (\r\n    _chained_assignment_method_msg,\r\n    _chained_assignment_msg,\r\n)\r\nfrom pandas.util._decorators import (\r\n    Appender,\r\n    Substitution,\r\n    deprecate_nonkeyword_arguments,\r\n    doc,\r\n    set_module,\r\n)\r\nfrom pandas.util._exceptions import (\r\n    find_stack_level,\r\n    rewrite_warning,\r\n)\r\nfrom pandas.util._validators import (\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_percentile,\r\n)\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    construct_1d_arraylike_from_scalar,\r\n    construct_2d_arraylike_from_scalar,\r\n    find_common_type,\r\n    infer_dtype_from_scalar,\r\n    invalidate_string_dtypes,\r\n    maybe_downcast_to_dtype,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    infer_dtype_from_object,\r\n    is_1d_only_ea_dtype,\r\n    is_array_like,\r\n    is_bool_dtype,\r\n    is_dataclass,\r\n    is_dict_like,\r\n    is_float,\r\n    is_float_dtype,\r\n    is_hashable,\r\n    is_integer,\r\n    is_integer_dtype,\r\n    is_iterator,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_sequence,\r\n    needs_i8_conversion,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.concat import concat_compat\r\nfrom pandas.core.dtypes.dtypes import (\r\n    ArrowDtype,\r\n    BaseMaskedDtype,\r\n    ExtensionDtype,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms,\r\n    common as com,\r\n    nanops,\r\n    ops,\r\n    roperator,\r\n)\r\nfrom pandas.core.accessor import Accessor\r\nfrom pandas.core.apply import reconstruct_and_relabel_result\r\nfrom pandas.core.array_algos.take import take_2d_multi\r\nfrom pandas.core.arraylike import OpsMixin\r\nfrom pandas.core.arrays import (\r\n    BaseMaskedArray,\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.sparse import SparseFrameAccessor\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    sanitize_array,\r\n    sanitize_masked_array,\r\n)\r\nfrom pandas.core.generic import (\r\n    NDFrame,\r\n    make_doc,\r\n)\r\nfrom pandas.core.indexers import check_key_length\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n    ensure_index_from_sequences,\r\n)\r\nfrom pandas.core.indexes.multi import (\r\n    MultiIndex,\r\n    maybe_droplevels,\r\n)\r\nfrom pandas.core.indexing import (\r\n    check_bool_indexer,\r\n    check_dict_or_set_indexers,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.internals.construction import (\r\n    arrays_to_mgr,\r\n    dataclasses_to_dicts,\r\n    dict_to_mgr,\r\n    ndarray_to_mgr,\r\n    nested_data_to_arrays,\r\n    rec_array_to_mgr,\r\n    reorder_arrays,\r\n    to_arrays,\r\n    treat_as_nested,\r\n)\r\nfrom pandas.core.methods import selectn\r\nfrom pandas.core.reshape.melt import melt\r\nfrom pandas.core.series import Series\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import (\r\n    get_group_index,\r\n    lexsort_indexer,\r\n    nargsort,\r\n)\r\n\r\nfrom pandas.io.common import get_handle\r\nfrom pandas.io.formats import (\r\n    console,\r\n    format as fmt,\r\n)\r\nfrom pandas.io.formats.info import (\r\n    INFO_DOCSTRING,\r\n    DataFrameInfo,\r\n    frame_sub_kwargs,\r\n)\r\nimport pandas.plotting\r\n\r\nif TYPE_CHECKING:\r\n    import datetime\r\n\r\n    from pandas._libs.internals import BlockValuesRefs\r\n    from pandas._typing import (\r\n        AggFuncType,\r\n        AnyAll,\r\n        AnyArrayLike,\r\n        ArrayLike,\r\n        Axes,\r\n        Axis,\r\n        AxisInt,\r\n        ColspaceArgType,\r\n        CompressionOptions,\r\n        CorrelationMethod,\r\n        DropKeep,\r\n        Dtype,\r\n        DtypeObj,\r\n        FilePath,\r\n        FloatFormatType,\r\n        FormattersType,\r\n        Frequency,\r\n        FromDictOrient,\r\n        HashableT,\r\n        HashableT2,\r\n        IgnoreRaise,\r\n        IndexKeyFunc,\r\n        IndexLabel,\r\n        JoinValidate,\r\n        Level,\r\n        ListLike,\r\n        MergeHow,\r\n        MergeValidate,\r\n        MutableMappingT,\r\n        NaPosition,\r\n        NsmallestNlargestKeep,\r\n        PythonFuncType,\r\n        QuantileInterpolation,\r\n        ReadBuffer,\r\n        ReindexMethod,\r\n        Renamer,\r\n        Scalar,\r\n"]
[135.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[135.002, "i", "grep -RIn --line-number --color=never -E '^def\\s+hash_pandas_object|_hash|hash_array|_combine_object_hash\r"]
[135.004, "o", "grep -RIn --line-number --color=never -E '^def\\s+hash_pandas_object|_hash|hash_array|_combine_object_hash\r\n"]
[135.006, "o", "h' ../pandas/core/util/hashing.py ../pandas/_libs/*.pyx 2>/dev/null\r\n\u001b[?2004l\r\n../pandas/core/util/hashing.py:45:_default_hash_key = \"0123456789123456\"\r\n../pandas/core/util/hashing.py:48:def combine_hash_arrays(\r\n../pandas/core/util/hashing.py:84:def hash_pandas_object(\r\n../pandas/core/util/hashing.py:88:    hash_key: str | None = _default_hash_key,\r\n../pandas/core/util/hashing.py:101:    hash_key : str, default _default_hash_key\r\n../pandas/core/util/hashing.py:123:        hash_key = _default_hash_key\r\n../pandas/core/util/hashing.py:129:        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n../pandas/core/util/hashing.py:135:        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n../pandas/core/util/hashing.py:150:            h = combine_hash_arrays(arrays, 2)\r\n../pandas/core/util/hashing.py:156:            hash_array(series._values, encoding, hash_key, categorize)\r\n../pandas/core/util/hashing.py:161:            index_hash_generator = (\r\n../pandas/core/util/hashing.py:174:            _hashes = itertools.chain(hashes, index_hash_generator)\r\n../pandas/core/util/hashing.py:175:            hashes = (x for x in _hashes)\r\n../pandas/core/util/hashing.py:176:        h = combine_hash_arrays(hashes, num_items)\r\n../pandas/core/util/hashing.py:188:    hash_key: str = _default_hash_key,\r\n../pandas/core/util/hashing.py:197:    hash_key : str, default _default_hash_key\r\n../pandas/core/util/hashing.py:227:        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n../pandas/core/util/hashing.py:230:    h = combine_hash_arrays(hashes, len(cat_vals))\r\n../pandas/core/util/hashing.py:235:def hash_array(\r\n../pandas/core/util/hashing.py:238:    hash_key: str = _default_hash_key,\r\n../pandas/core/util/hashing.py:250:    hash_key : str, default _default_hash_key\r\n../pandas/core/util/hashing.py:268:    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n../pandas/core/util/hashing.py:276:        return vals._hash_pandas_object(\r\n../pandas/core/util/hashing.py:283:            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n../pandas/core/util/hashing.py:287:    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n../pandas/core/util/hashing.py:290:def _hash_ndarray(\r\n../pandas/core/util/hashing.py:293:    hash_key: str = _default_hash_key,\r\n../pandas/core/util/hashing.py:297:    See hash_array.__doc__.\r\n../pandas/core/util/hashing.py:301:    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n../pandas/core/util/hashing.py:303:        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n../pandas/core/util/hashing.py:304:        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n../pandas/core/util/hashing.py:329:            return cat._hash_pandas_object(\r\n../pandas/_libs/hashtable.pyx:29:    kh_python_hash_equal,\r\n../pandas/_libs/hashtable.pyx:30:    kh_python_hash_func,\r\n../pandas/_libs/hashtable.pyx:39:def get_hashtable_trace_domain():\r\n../pandas/_libs/hashtable.pyx:43:def object_hash(obj):\r\n../pandas/_libs/hashtable.pyx:44:    return kh_python_hash_func(obj)\r\n../pandas/_libs/hashtable.pyx:48:    return kh_python_hash_equal(a, b)\r\n../pandas/_libs/index.pyx:35:    hashtable as _hash,\r\n../pandas/_libs/index.pyx:328:    cdef _make_hash_table(self, Py_ssize_t n):\r\n../pandas/_libs/index.pyx:347:            self.mapping = self._make_hash_table(len(values))\r\n../pandas/_libs/index.pyx:537:    cdef _make_hash_table(self, Py_ssize_t n):\r\n../pandas/_libs/index.pyx:538:        return _hash.PyObjectHashTable(n)\r\n../pandas/_libs/index.pyx:552:    cdef _make_hash_table(self, Py_ssize_t n):\r\n../pandas/_libs/index.pyx:553:        return _hash.StringHashTable(n)\r\n../pandas/_libs/interval.pyx:475:    def __hash__(self):\r\n../pandas/_libs/join.pyx:693:                                 bint use_hashtable=True):\r\n../pandas/_libs/join.pyx:714:    if use_hashtable:\r\n../pandas/_libs/join.pyx:727:                if use_hashtable:\r\n../pandas/_libs/join.pyx:733:                if use_hashtable:\r\n../pandas/_libs/join.pyx:739:        if use_hashtable:\r\n../pandas/_libs/join.pyx:764:                                bint use_hashtable=True):\r\n../pandas/_libs/join.pyx:785:    if use_hashtable:\r\n../pandas/_libs/join.pyx:798:                if use_hashtable:\r\n../pandas/_libs/join.pyx:804:                if use_hashtable:\r\n../pandas/_libs/join.pyx:810:        if use_hashtable:\r\n../pandas/_libs/join.pyx:836:                                bint use_hashtable=True):\r\n../pandas/_libs/join.pyx:853:        use_hashtable\r\n../pandas/_libs/join.pyx:862:        use_hashtable\r\n../pandas/_libs/lib.pyx:2379:        if val.__hash__ is not None and val in na_values:\r\n../pandas/_libs/missing.pyx:398:    def __hash__(self):\r\n../pandas/_libs/parsers.pyx:930:            kh_str_starts_t *na_hashset = NULL\r\n../pandas/_libs/parsers.pyx:1035:                    na_hashset = kset_from_list(na_list)\r\n../pandas/_libs/parsers.pyx:1043:                    i, start, end, name, na_filter, na_hashset,\r\n../pandas/_libs/parsers.pyx:1051:                    self._free_na_set(na_hashset)\r\n../pandas/_libs/parsers.pyx:1077:                         kh_str_starts_t *na_hashset,\r\n../pandas/_libs/parsers.pyx:1083:                1, na_hashset, na_flist)\r\n../pandas/_libs/parsers.pyx:1091:            return self._string_convert(i, start, end, na_filter, na_hashset)\r\n../pandas/_libs/parsers.pyx:1097:                        dt, i, start, end, na_filter, 0, na_hashset, na_flist)\r\n../pandas/_libs/parsers.pyx:1105:                        0, na_hashset, na_flist)\r\n../pandas/_libs/parsers.pyx:1109:                        0, na_hashset, na_flist)\r\n../pandas/_libs/parsers.pyx:1156:                             kh_str_starts_t *na_hashset,\r\n../pandas/_libs/parsers.pyx:1162:                self.parser, i, start, end, na_filter, na_hashset)\r\n../pandas/_libs/parsers.pyx:1173:                                                    na_hashset)\r\n../pandas/_libs/parsers.pyx:1199:                                              end, na_filter, na_hashset)\r\n../pandas/_libs/parsers.pyx:1205:                                     na_filter, na_hashset)\r\n../pandas/_libs/parsers.pyx:1215:                                           na_filter, na_hashset, na_flist)\r\n../pandas/_libs/parsers.pyx:1222:                                              na_filter, na_hashset,\r\n../pandas/_libs/parsers.pyx:1238:                                        na_hashset)\r\n../pandas/_libs/parsers.pyx:1246:                                        na_hashset)\r\n../pandas/_libs/parsers.pyx:1249:                                        na_hashset)\r\n../pandas/_libs/parsers.pyx:1259:                         bint na_filter, kh_str_starts_t *na_hashset):\r\n../pandas/_libs/parsers.pyx:1262:                                na_hashset, self.encoding_errors)\r\n../pandas/_libs/parsers.pyx:1471:                      bint na_filter, kh_str_starts_t *na_hashset,\r\n../pandas/_libs/parsers.pyx:1497:            if kh_get_str_starts_item(na_hashset, word):\r\n../pandas/_libs/parsers.pyx:1526:                          bint na_filter, kh_str_starts_t *na_hashset):\r\n../pandas/_libs/parsers.pyx:1555:                if kh_get_str_starts_item(na_hashset, word):\r\n../pandas/_libs/parsers.pyx:1625:                 bint na_filter, kh_str_starts_t *na_hashset, object na_flist):\r\n../pandas/_libs/parsers.pyx:1642:                                  na_filter, na_hashset, use_na_flist,\r\n../pandas/_libs/parsers.pyx:1656:                           bint na_filter, kh_str_starts_t *na_hashset,\r\n../pandas/_libs/parsers.pyx:1676:            if kh_get_str_starts_item(na_hashset, word):\r\n../pandas/_libs/parsers.pyx:1727:                 bint na_filter, kh_str_starts_t *na_hashset):\r\n../pandas/_libs/parsers.pyx:1744:                                  na_filter, na_hashset, data, &state)\r\n../pandas/_libs/parsers.pyx:1763:                           const kh_str_starts_t *na_hashset,\r\n../pandas/_libs/parsers.pyx:1776:            if kh_get_str_starts_item(na_hashset, word):\r\n../pandas/_libs/parsers.pyx:1799:                bint na_filter, kh_str_starts_t *na_hashset):\r\n../pandas/_libs/parsers.pyx:1814:                                 na_filter, na_hashset, NA, data, &na_count)\r\n../pandas/_libs/parsers.pyx:1827:                          const kh_str_starts_t *na_hashset, int64_t NA,\r\n../pandas/_libs/parsers.pyx:1841:            if kh_get_str_starts_item(na_hashset, word):\r\n../pandas/_libs/parsers.pyx:1865:                    bint na_filter, const kh_str_starts_t *na_hashset,\r\n../pandas/_libs/parsers.pyx:1866:                    const kh_str_starts_t *true_hashset,\r\n../pandas/_libs/parsers.pyx:1867:                    const kh_str_starts_t *false_hashset):\r\n../pandas/_libs/parsers.pyx:1880:                                     na_filter, na_hashset, true_hashset,\r\n../pandas/_libs/parsers.pyx:1881:                                     false_hashset, NA, data, &na_count)\r\n../pandas/_libs/parsers.pyx:1890:                              const kh_str_starts_t *na_hashset,\r\n../pandas/_libs/parsers.pyx:1891:                              const kh_str_starts_t *true_hashset,\r\n../pandas/_libs/parsers.pyx:1892:                              const kh_str_starts_t *false_hashset,\r\n../pandas/_libs/parsers.pyx:1908:            if kh_get_str_starts_item(na_hashset, word):\r\n../pandas/_libs/parsers.pyx:1915:            if kh_get_str_starts_item(true_hashset, word):\r\n../pandas/_libs/parsers.pyx:1919:            if kh_get_str_starts_item(false_hashset, word):\r\n../pandas/_libs/parsers.pyx:1932:            if kh_get_str_starts_item(true_hashset, word):\r\n../pandas/_libs/parsers.pyx:1937:            if kh_get_str_starts_item(false_hashset, word):\r\n"]
[140.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[140.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[140.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[140.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                  7.77\u00b10.08ms\r\n\r\nWed Oct  1 17:35:46 2025    /tmp/tmp3vf4eglk\r\n\r\n         798 function calls (782 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n      3/2    0.000    0.000    0.007    0.004 hashing.py:235(hash_array)\r\n      3/2    0.001    0.000    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:2406(is_unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55e77eff0640}\r\n        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n\r\n\r\n"]
[145.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[145.002, "i", "sed -n '1,260p' ../pandas/core/util/hashing.py\r"]
[145.004, "o", "sed -n '1,260p' ../pandas/core/util/hashing.py\r\n"]
[145.006, "o", "\u001b[?2004l\r\n\"\"\"\r\ndata hash pandas / numpy objects\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport itertools\r\nfrom typing import TYPE_CHECKING\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs.hashing import hash_object_array\r\n\r\nfrom pandas.core.dtypes.common import is_list_like\r\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCExtensionArray,\r\n    ABCIndex,\r\n    ABCMultiIndex,\r\n    ABCSeries,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterable,\r\n        Iterator,\r\n    )\r\n\r\n    from pandas._typing import (\r\n        ArrayLike,\r\n        npt,\r\n    )\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        Index,\r\n        MultiIndex,\r\n        Series,\r\n    )\r\n\r\n\r\n# 16 byte long hashing key\r\n_default_hash_key = \"0123456789123456\"\r\n\r\n\r\ndef combine_hash_arrays(\r\n    arrays: Iterator[np.ndarray], num_items: int\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Parameters\r\n    ----------\r\n    arrays : Iterator[np.ndarray]\r\n    num_items : int\r\n\r\n    Returns\r\n    -------\r\n    np.ndarray[uint64]\r\n\r\n    Should be the same as CPython's tupleobject.c\r\n    \"\"\"\r\n    try:\r\n        first = next(arrays)\r\n    except StopIteration:\r\n        return np.array([], dtype=np.uint64)\r\n\r\n    arrays = itertools.chain([first], arrays)\r\n\r\n    mult = np.uint64(1000003)\r\n    out = np.zeros_like(first) + np.uint64(0x345678)\r\n    last_i = 0\r\n    for i, a in enumerate(arrays):\r\n        inverse_i = num_items - i\r\n        out ^= a\r\n        out *= mult\r\n        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n        last_i = i\r\n    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n    out += np.uint64(97531)\r\n    return out\r\n\r\n\r\ndef hash_pandas_object(\r\n    obj: Index | DataFrame | Series,\r\n    index: bool = True,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str | None = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> Series:\r\n    \"\"\"\r\n    Return a data hash of the Index/Series/DataFrame.\r\n\r\n    Parameters\r\n    ----------\r\n    obj : Index, Series, or DataFrame\r\n    index : bool, default True\r\n        Include the index in the hash (if Series/DataFrame).\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    Series of uint64\r\n        Same length as the object.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n    0    14639053686158035780\r\n    1     3869563279212530728\r\n    2      393322362522515241\r\n    dtype: uint64\r\n    \"\"\"\r\n    from pandas import Series\r\n\r\n    if hash_key is None:\r\n        hash_key = _default_hash_key\r\n\r\n    if isinstance(obj, ABCMultiIndex):\r\n        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCIndex):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCSeries):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        if index:\r\n            index_iter = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            arrays = itertools.chain([h], index_iter)\r\n            h = combine_hash_arrays(arrays, 2)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCDataFrame):\r\n        hashes = (\r\n            hash_array(series._values, encoding, hash_key, categorize)\r\n            for _, series in obj.items()\r\n        )\r\n        num_items = len(obj.columns)\r\n        if index:\r\n            index_hash_generator = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            num_items += 1\r\n\r\n            # keep `hashes` specifically a generator to keep mypy happy\r\n            _hashes = itertools.chain(hashes, index_hash_generator)\r\n            hashes = (x for x in _hashes)\r\n        h = combine_hash_arrays(hashes, num_items)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n    else:\r\n        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n\r\n    return ser\r\n\r\n\r\ndef hash_tuples(\r\n    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : MultiIndex or listlike-of-tuples\r\n    encoding : str, default 'utf8'\r\n    hash_key : str, default _default_hash_key\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64] of hashed values\r\n    \"\"\"\r\n    if not is_list_like(vals):\r\n        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n\r\n    from pandas import (\r\n        Categorical,\r\n        MultiIndex,\r\n    )\r\n\r\n    if not isinstance(vals, ABCMultiIndex):\r\n        mi = MultiIndex.from_tuples(vals)\r\n    else:\r\n        mi = vals\r\n\r\n    # create a list-of-Categoricals\r\n    cat_vals = [\r\n        Categorical._simple_new(\r\n            mi.codes[level],\r\n            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n        )\r\n        for level in range(mi.nlevels)\r\n    ]\r\n\r\n    # hash the list-of-ndarrays\r\n    hashes = (\r\n        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n        for cat in cat_vals\r\n    )\r\n    h = combine_hash_arrays(hashes, len(cat_vals))\r\n\r\n    return h\r\n\r\n\r\ndef hash_array(\r\n    vals: ArrayLike,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Given a 1d array, return an array of deterministic integers.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : ndarray or ExtensionArray\r\n        The input array to hash.\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64, ndim=1]\r\n        Hashed values, same length as the vals.\r\n\r\n"]
[150.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[150.002, "i", "sed -n '260,520p' ../pandas/core/util/hashing.py\r"]
[150.004, "o", "sed -n '260,520p' ../pandas/core/util/hashing.py\r\n"]
[150.006, "o", "\u001b[?2004l\r\n\r\n    See Also\r\n    --------\r\n    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n      dtype=uint64)\r\n    \"\"\"\r\n    if not hasattr(vals, \"dtype\"):\r\n        raise TypeError(\"must pass a ndarray-like\")\r\n\r\n    if isinstance(vals, ABCExtensionArray):\r\n        return vals._hash_pandas_object(\r\n            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n        )\r\n\r\n    if not isinstance(vals, np.ndarray):\r\n        # GH#42003\r\n        raise TypeError(\r\n            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n        )\r\n\r\n    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n\r\n\r\ndef _hash_ndarray(\r\n    vals: np.ndarray,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    See hash_array.__doc__.\r\n    \"\"\"\r\n    dtype = vals.dtype\r\n\r\n    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n    if np.issubdtype(dtype, np.complex128):\r\n        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n        return hash_real + 23 * hash_imag\r\n\r\n    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n    # manage it.\r\n    if dtype == bool:\r\n        vals = vals.astype(\"u8\")\r\n    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n    else:\r\n        # With repeated values, its MUCH faster to categorize object dtypes,\r\n        # then hash and rename categories. We allow skipping the categorization\r\n        # when the values are known/likely to be unique.\r\n        if categorize:\r\n            from pandas import (\r\n                Categorical,\r\n                Index,\r\n                factorize,\r\n            )\r\n\r\n            codes, categories = factorize(vals, sort=False)\r\n            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n            cat = Categorical._simple_new(codes, dtype)\r\n            return cat._hash_pandas_object(\r\n                encoding=encoding, hash_key=hash_key, categorize=False\r\n            )\r\n\r\n        try:\r\n            vals = hash_object_array(vals, hash_key, encoding)\r\n        except TypeError:\r\n            # we have mixed types\r\n            vals = hash_object_array(\r\n                vals.astype(str).astype(object), hash_key, encoding\r\n            )\r\n\r\n    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n    vals ^= vals >> 30\r\n    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n    vals ^= vals >> 27\r\n    vals *= np.uint64(0x94D049BB133111EB)\r\n    vals ^= vals >> 31\r\n    return vals\r\n"]
[155.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[155.002, "i", "grep -RIn --line-number --color=never -E 'hash_array|hash_object_array|hash_pandas_object' ../pandas/core\r"]
[155.004, "o", "grep -RIn --line-number --color=never -E 'hash_array|hash_object_array|hash_pandas_object' ../pandas/core\r\n"]
[155.006, "o", "e/util/hashing.py\r\n\u001b[?2004l\r\n12:from pandas._libs.hashing import hash_object_array\r\n48:def combine_hash_arrays(\r\n84:def hash_pandas_object(\r\n114:    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n129:        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n135:        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n140:                hash_pandas_object(\r\n150:            h = combine_hash_arrays(arrays, 2)\r\n156:            hash_array(series._values, encoding, hash_key, categorize)\r\n162:                hash_pandas_object(\r\n176:        h = combine_hash_arrays(hashes, num_items)\r\n227:        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n230:    h = combine_hash_arrays(hashes, len(cat_vals))\r\n235:def hash_array(\r\n263:    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n268:    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n276:        return vals._hash_pandas_object(\r\n283:            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n284:            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n297:    See hash_array.__doc__.\r\n329:            return cat._hash_pandas_object(\r\n334:            vals = hash_object_array(vals, hash_key, encoding)\r\n337:            vals = hash_object_array(\r\n"]
[160.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[160.002, "i", "grep -RIn --line-number --color=never -E 'hash(ing)?\\.' ../pandas/_libs | head -n 50\r"]
[160.004, "o", "grep -RIn --line-number --color=never -E 'hash(ing)?\\.' ../pandas/_libs | head -n 50\r\n"]
[160.006, "o", "\u001b[?2004l\r\n../pandas/_libs/src/parser/tokenizer.c:28:#include \"pandas/vendored/klib/khash.h\" // for kh_int64_t, kh_destroy_int64\r\n../pandas/_libs/hashtable_class_helper.pxi.in:56:# are_equivalent_{{c_type}} is cimported via khash.pxd\r\n../pandas/_libs/meson.build:77:    'hashing': {'sources': ['hashing.pyx']},\r\n../pandas/_libs/meson.build:170:    'hashing.pyi',\r\n../pandas/_libs/index.pyx:538:        return _hash.PyObjectHashTable(n)\r\n../pandas/_libs/index.pyx:553:        return _hash.StringHashTable(n)\r\n../pandas/_libs/index_class_helper.pxi.in:40:        return _hash.{{name}}HashTable(n, uses_mask=True)\r\n../pandas/_libs/index_class_helper.pxi.in:42:        return _hash.{{name}}HashTable(n)\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:56:#include \"khash.h\"\r\n../pandas/_libs/include/pandas/vendored/klib/khash_python.h:60:// python 3.5 https://github.com/python/cpython/blob/3.5/Python/pyhash.c#L85\r\n../pandas/_libs/include/pandas/vendored/klib/khash.h:6:#include \"khash.h\"\r\n../pandas/_libs/tslibs/timedeltas.pyx:1330:            #  have the same hash.  So we try downcasting to the next-lowest\r\n"]
[165.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[165.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[165.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[165.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                  7.76\u00b10.04ms\r\n\r\nWed Oct  1 17:37:00 2025    /tmp/tmpmhgp9vaf\r\n\r\n         798 function calls (782 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n      3/2    0.000    0.000    0.008    0.004 hashing.py:235(hash_array)\r\n      3/2    0.001    0.000    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:2406(is_unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x560c0d7f8640}\r\n        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[170.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[170.002, "i", "sed -n '1,200p' ../pandas/core/util/hashing.py\r"]
[170.004, "o", "sed -n '1,200p' ../pandas/core/util/hashing.py\r\n"]
[170.006, "o", "\u001b[?2004l\r\n\"\"\"\r\ndata hash pandas / numpy objects\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport itertools\r\nfrom typing import TYPE_CHECKING\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs.hashing import hash_object_array\r\n\r\nfrom pandas.core.dtypes.common import is_list_like\r\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCExtensionArray,\r\n    ABCIndex,\r\n    ABCMultiIndex,\r\n    ABCSeries,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterable,\r\n        Iterator,\r\n    )\r\n\r\n    from pandas._typing import (\r\n        ArrayLike,\r\n        npt,\r\n    )\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        Index,\r\n        MultiIndex,\r\n        Series,\r\n    )\r\n\r\n\r\n# 16 byte long hashing key\r\n_default_hash_key = \"0123456789123456\"\r\n\r\n\r\ndef combine_hash_arrays(\r\n    arrays: Iterator[np.ndarray], num_items: int\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Parameters\r\n    ----------\r\n    arrays : Iterator[np.ndarray]\r\n    num_items : int\r\n\r\n    Returns\r\n    -------\r\n    np.ndarray[uint64]\r\n\r\n    Should be the same as CPython's tupleobject.c\r\n    \"\"\"\r\n    try:\r\n        first = next(arrays)\r\n    except StopIteration:\r\n        return np.array([], dtype=np.uint64)\r\n\r\n    arrays = itertools.chain([first], arrays)\r\n\r\n    mult = np.uint64(1000003)\r\n    out = np.zeros_like(first) + np.uint64(0x345678)\r\n    last_i = 0\r\n    for i, a in enumerate(arrays):\r\n        inverse_i = num_items - i\r\n        out ^= a\r\n        out *= mult\r\n        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n        last_i = i\r\n    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n    out += np.uint64(97531)\r\n    return out\r\n\r\n\r\ndef hash_pandas_object(\r\n    obj: Index | DataFrame | Series,\r\n    index: bool = True,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str | None = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> Series:\r\n    \"\"\"\r\n    Return a data hash of the Index/Series/DataFrame.\r\n\r\n    Parameters\r\n    ----------\r\n    obj : Index, Series, or DataFrame\r\n    index : bool, default True\r\n        Include the index in the hash (if Series/DataFrame).\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    Series of uint64\r\n        Same length as the object.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n    0    14639053686158035780\r\n    1     3869563279212530728\r\n    2      393322362522515241\r\n    dtype: uint64\r\n    \"\"\"\r\n    from pandas import Series\r\n\r\n    if hash_key is None:\r\n        hash_key = _default_hash_key\r\n\r\n    if isinstance(obj, ABCMultiIndex):\r\n        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCIndex):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCSeries):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        if index:\r\n            index_iter = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            arrays = itertools.chain([h], index_iter)\r\n            h = combine_hash_arrays(arrays, 2)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCDataFrame):\r\n        hashes = (\r\n            hash_array(series._values, encoding, hash_key, categorize)\r\n            for _, series in obj.items()\r\n        )\r\n        num_items = len(obj.columns)\r\n        if index:\r\n            index_hash_generator = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            num_items += 1\r\n\r\n            # keep `hashes` specifically a generator to keep mypy happy\r\n            _hashes = itertools.chain(hashes, index_hash_generator)\r\n            hashes = (x for x in _hashes)\r\n        h = combine_hash_arrays(hashes, num_items)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n    else:\r\n        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n\r\n    return ser\r\n\r\n\r\ndef hash_tuples(\r\n    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : MultiIndex or listlike-of-tuples\r\n    encoding : str, default 'utf8'\r\n    hash_key : str, default _default_hash_key\r\n\r\n    Returns\r\n    -------\r\n"]
[175.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[175.002, "i", "sed -n '200,400p' ../pandas/core/util/hashing.py\r"]
[175.004, "o", "sed -n '200,400p' ../pandas/core/util/hashing.py\r\n"]
[175.006, "o", "\u001b[?2004l\r\n    -------\r\n    ndarray[np.uint64] of hashed values\r\n    \"\"\"\r\n    if not is_list_like(vals):\r\n        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n\r\n    from pandas import (\r\n        Categorical,\r\n        MultiIndex,\r\n    )\r\n\r\n    if not isinstance(vals, ABCMultiIndex):\r\n        mi = MultiIndex.from_tuples(vals)\r\n    else:\r\n        mi = vals\r\n\r\n    # create a list-of-Categoricals\r\n    cat_vals = [\r\n        Categorical._simple_new(\r\n            mi.codes[level],\r\n            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n        )\r\n        for level in range(mi.nlevels)\r\n    ]\r\n\r\n    # hash the list-of-ndarrays\r\n    hashes = (\r\n        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n        for cat in cat_vals\r\n    )\r\n    h = combine_hash_arrays(hashes, len(cat_vals))\r\n\r\n    return h\r\n\r\n\r\ndef hash_array(\r\n    vals: ArrayLike,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Given a 1d array, return an array of deterministic integers.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : ndarray or ExtensionArray\r\n        The input array to hash.\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64, ndim=1]\r\n        Hashed values, same length as the vals.\r\n\r\n    See Also\r\n    --------\r\n    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n      dtype=uint64)\r\n    \"\"\"\r\n    if not hasattr(vals, \"dtype\"):\r\n        raise TypeError(\"must pass a ndarray-like\")\r\n\r\n    if isinstance(vals, ABCExtensionArray):\r\n        return vals._hash_pandas_object(\r\n            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n        )\r\n\r\n    if not isinstance(vals, np.ndarray):\r\n        # GH#42003\r\n        raise TypeError(\r\n            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n        )\r\n\r\n    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n\r\n\r\ndef _hash_ndarray(\r\n    vals: np.ndarray,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    See hash_array.__doc__.\r\n    \"\"\"\r\n    dtype = vals.dtype\r\n\r\n    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n    if np.issubdtype(dtype, np.complex128):\r\n        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n        return hash_real + 23 * hash_imag\r\n\r\n    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n    # manage it.\r\n    if dtype == bool:\r\n        vals = vals.astype(\"u8\")\r\n    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n    else:\r\n        # With repeated values, its MUCH faster to categorize object dtypes,\r\n        # then hash and rename categories. We allow skipping the categorization\r\n        # when the values are known/likely to be unique.\r\n        if categorize:\r\n            from pandas import (\r\n                Categorical,\r\n                Index,\r\n                factorize,\r\n            )\r\n\r\n            codes, categories = factorize(vals, sort=False)\r\n            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n            cat = Categorical._simple_new(codes, dtype)\r\n            return cat._hash_pandas_object(\r\n                encoding=encoding, hash_key=hash_key, categorize=False\r\n            )\r\n\r\n        try:\r\n            vals = hash_object_array(vals, hash_key, encoding)\r\n        except TypeError:\r\n            # we have mixed types\r\n            vals = hash_object_array(\r\n                vals.astype(str).astype(object), hash_key, encoding\r\n            )\r\n\r\n    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n    vals ^= vals >> 30\r\n    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n    vals ^= vals >> 27\r\n    vals *= np.uint64(0x94D049BB133111EB)\r\n    vals ^= vals >> 31\r\n    return vals\r\n"]
[180.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[180.002, "i", "sed -n '400,800p' ../pandas/core/util/hashing.py\r"]
[180.004, "o", "sed -n '400,800p' ../pandas/core/util/hashing.py\r\n"]
[180.006, "o", "\u001b[?2004l\r\n"]
[185.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[185.002, "i", "sed -n '1,260p' ../pandas/core/util/hashing.py\r"]
[185.004, "o", "sed -n '1,260p' ../pandas/core/util/hashing.py\r\n"]
[185.006, "o", "\u001b[?2004l\r\n\"\"\"\r\ndata hash pandas / numpy objects\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport itertools\r\nfrom typing import TYPE_CHECKING\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs.hashing import hash_object_array\r\n\r\nfrom pandas.core.dtypes.common import is_list_like\r\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCExtensionArray,\r\n    ABCIndex,\r\n    ABCMultiIndex,\r\n    ABCSeries,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterable,\r\n        Iterator,\r\n    )\r\n\r\n    from pandas._typing import (\r\n        ArrayLike,\r\n        npt,\r\n    )\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        Index,\r\n        MultiIndex,\r\n        Series,\r\n    )\r\n\r\n\r\n# 16 byte long hashing key\r\n_default_hash_key = \"0123456789123456\"\r\n\r\n\r\ndef combine_hash_arrays(\r\n    arrays: Iterator[np.ndarray], num_items: int\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Parameters\r\n    ----------\r\n    arrays : Iterator[np.ndarray]\r\n    num_items : int\r\n\r\n    Returns\r\n    -------\r\n    np.ndarray[uint64]\r\n\r\n    Should be the same as CPython's tupleobject.c\r\n    \"\"\"\r\n    try:\r\n        first = next(arrays)\r\n    except StopIteration:\r\n        return np.array([], dtype=np.uint64)\r\n\r\n    arrays = itertools.chain([first], arrays)\r\n\r\n    mult = np.uint64(1000003)\r\n    out = np.zeros_like(first) + np.uint64(0x345678)\r\n    last_i = 0\r\n    for i, a in enumerate(arrays):\r\n        inverse_i = num_items - i\r\n        out ^= a\r\n        out *= mult\r\n        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n        last_i = i\r\n    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n    out += np.uint64(97531)\r\n    return out\r\n\r\n\r\ndef hash_pandas_object(\r\n    obj: Index | DataFrame | Series,\r\n    index: bool = True,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str | None = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> Series:\r\n    \"\"\"\r\n    Return a data hash of the Index/Series/DataFrame.\r\n\r\n    Parameters\r\n    ----------\r\n    obj : Index, Series, or DataFrame\r\n    index : bool, default True\r\n        Include the index in the hash (if Series/DataFrame).\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    Series of uint64\r\n        Same length as the object.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n    0    14639053686158035780\r\n    1     3869563279212530728\r\n    2      393322362522515241\r\n    dtype: uint64\r\n    \"\"\"\r\n    from pandas import Series\r\n\r\n    if hash_key is None:\r\n        hash_key = _default_hash_key\r\n\r\n    if isinstance(obj, ABCMultiIndex):\r\n        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCIndex):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCSeries):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        if index:\r\n            index_iter = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            arrays = itertools.chain([h], index_iter)\r\n            h = combine_hash_arrays(arrays, 2)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCDataFrame):\r\n        hashes = (\r\n            hash_array(series._values, encoding, hash_key, categorize)\r\n            for _, series in obj.items()\r\n        )\r\n        num_items = len(obj.columns)\r\n        if index:\r\n            index_hash_generator = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            num_items += 1\r\n\r\n            # keep `hashes` specifically a generator to keep mypy happy\r\n            _hashes = itertools.chain(hashes, index_hash_generator)\r\n            hashes = (x for x in _hashes)\r\n        h = combine_hash_arrays(hashes, num_items)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n    else:\r\n        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n\r\n    return ser\r\n\r\n\r\ndef hash_tuples(\r\n    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : MultiIndex or listlike-of-tuples\r\n    encoding : str, default 'utf8'\r\n    hash_key : str, default _default_hash_key\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64] of hashed values\r\n    \"\"\"\r\n    if not is_list_like(vals):\r\n        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n\r\n    from pandas import (\r\n        Categorical,\r\n        MultiIndex,\r\n    )\r\n\r\n    if not isinstance(vals, ABCMultiIndex):\r\n        mi = MultiIndex.from_tuples(vals)\r\n    else:\r\n        mi = vals\r\n\r\n    # create a list-of-Categoricals\r\n    cat_vals = [\r\n        Categorical._simple_new(\r\n            mi.codes[level],\r\n            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n        )\r\n        for level in range(mi.nlevels)\r\n    ]\r\n\r\n    # hash the list-of-ndarrays\r\n    hashes = (\r\n        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n        for cat in cat_vals\r\n    )\r\n    h = combine_hash_arrays(hashes, len(cat_vals))\r\n\r\n    return h\r\n\r\n\r\ndef hash_array(\r\n    vals: ArrayLike,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Given a 1d array, return an array of deterministic integers.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : ndarray or ExtensionArray\r\n        The input array to hash.\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64, ndim=1]\r\n        Hashed values, same length as the vals.\r\n\r\n"]
[190.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[190.002, "i", "grep -RIn --line-number --color=never \"def _hash_pandas_object\" ../pandas/core/arrays/categorical.py\r"]
[190.004, "o", "grep -RIn --line-number --color=never \"def _hash_pandas_object\" ../pandas/core/arrays/categorical.py\r\n"]
[190.006, "o", "\u001b[?2004l\r\n2133:    def _hash_pandas_object(\r\n"]
[195.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[195.002, "i", "sed -n '1,260p' ../pandas/core/arrays/categorical.py\r"]
[195.004, "o", "sed -n '1,260p' ../pandas/core/arrays/categorical.py\r\n"]
[195.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nfrom csv import QUOTE_NONNUMERIC\r\nfrom functools import partial\r\nimport operator\r\nfrom shutil import get_terminal_size\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Literal,\r\n    cast,\r\n    overload,\r\n)\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import get_option\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    algos as libalgos,\r\n    lib,\r\n)\r\nfrom pandas._libs.arrays import NDArrayBacked\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.util._validators import validate_bool_kwarg\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    coerce_indexer_dtype,\r\n    find_common_type,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_int64,\r\n    ensure_platform_int,\r\n    is_any_real_numeric_dtype,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_hashable,\r\n    is_integer_dtype,\r\n    is_list_like,\r\n    is_scalar,\r\n    needs_i8_conversion,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    ArrowDtype,\r\n    CategoricalDtype,\r\n    CategoricalDtypeType,\r\n    ExtensionDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCIndex,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms,\r\n    arraylike,\r\n    ops,\r\n)\r\nfrom pandas.core.accessor import (\r\n    PandasDelegate,\r\n    delegate_names,\r\n)\r\nfrom pandas.core.algorithms import (\r\n    factorize,\r\n    take_nd,\r\n)\r\nfrom pandas.core.arrays._mixins import (\r\n    NDArrayBackedExtensionArray,\r\n    ravel_compat,\r\n)\r\nfrom pandas.core.base import (\r\n    ExtensionArray,\r\n    NoNewAttributesMixin,\r\n    PandasObject,\r\n)\r\nimport pandas.core.common as com\r\nfrom pandas.core.construction import (\r\n    extract_array,\r\n    sanitize_array,\r\n)\r\nfrom pandas.core.ops.common import unpack_zerodim_and_defer\r\nfrom pandas.core.sorting import nargsort\r\nfrom pandas.core.strings.object_array import ObjectStringArrayMixin\r\n\r\nfrom pandas.io.formats import console\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Callable,\r\n        Hashable,\r\n        Iterator,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._typing import (\r\n        ArrayLike,\r\n        AstypeArg,\r\n        AxisInt,\r\n        Dtype,\r\n        DtypeObj,\r\n        NpDtype,\r\n        Ordered,\r\n        Self,\r\n        Shape,\r\n        SortKind,\r\n        npt,\r\n    )\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        Index,\r\n        Series,\r\n    )\r\n\r\n\r\ndef _cat_compare_op(op):\r\n    opname = f\"__{op.__name__}__\"\r\n    fill_value = op is operator.ne\r\n\r\n    @unpack_zerodim_and_defer(opname)\r\n    def func(self, other):\r\n        hashable = is_hashable(other)\r\n        if is_list_like(other) and len(other) != len(self) and not hashable:\r\n            # in hashable case we may have a tuple that is itself a category\r\n            raise ValueError(\"Lengths must match.\")\r\n\r\n        if not self.ordered:\r\n            if opname in [\"__lt__\", \"__gt__\", \"__le__\", \"__ge__\"]:\r\n                raise TypeError(\r\n                    \"Unordered Categoricals can only compare equality or not\"\r\n                )\r\n        if isinstance(other, Categorical):\r\n            # Two Categoricals can only be compared if the categories are\r\n            # the same (maybe up to ordering, depending on ordered)\r\n\r\n            msg = \"Categoricals can only be compared if 'categories' are the same.\"\r\n            if not self._categories_match_up_to_permutation(other):\r\n                raise TypeError(msg)\r\n\r\n            if not self.ordered and not self.categories.equals(other.categories):\r\n                # both unordered and different order\r\n                other_codes = recode_for_categories(\r\n                    other.codes, other.categories, self.categories, copy=False\r\n                )\r\n            else:\r\n                other_codes = other._codes\r\n\r\n            ret = op(self._codes, other_codes)\r\n            mask = (self._codes == -1) | (other_codes == -1)\r\n            if mask.any():\r\n                ret[mask] = fill_value\r\n            return ret\r\n\r\n        if hashable:\r\n            if other in self.categories:\r\n                i = self._unbox_scalar(other)\r\n                ret = op(self._codes, i)\r\n\r\n                if opname not in {\"__eq__\", \"__ge__\", \"__gt__\"}:\r\n                    # GH#29820 performance trick; get_loc will always give i>=0,\r\n                    #  so in the cases (__ne__, __le__, __lt__) the setting\r\n                    #  here is a no-op, so can be skipped.\r\n                    mask = self._codes == -1\r\n                    ret[mask] = fill_value\r\n                return ret\r\n            else:\r\n                return ops.invalid_comparison(self, other, op)\r\n        else:\r\n            # allow categorical vs object dtype array comparisons for equality\r\n            # these are only positional comparisons\r\n            if opname not in [\"__eq__\", \"__ne__\"]:\r\n                raise TypeError(\r\n                    f\"Cannot compare a Categorical for op {opname} with \"\r\n                    f\"type {type(other)}.\\nIf you want to compare values, \"\r\n                    \"use 'np.asarray(cat) <op> other'.\"\r\n                )\r\n\r\n            if isinstance(other, ExtensionArray) and needs_i8_conversion(other.dtype):\r\n                # We would return NotImplemented here, but that messes up\r\n                #  ExtensionIndex's wrapped methods\r\n                return op(other, self)\r\n            return getattr(np.array(self), opname)(np.array(other))\r\n\r\n    func.__name__ = opname\r\n\r\n    return func\r\n\r\n\r\ndef contains(cat, key, container) -> bool:\r\n    \"\"\"\r\n    Helper for membership check for ``key`` in ``cat``.\r\n\r\n    This is a helper method for :method:`__contains__`\r\n    and :class:`CategoricalIndex.__contains__`.\r\n\r\n    Returns True if ``key`` is in ``cat.categories`` and the\r\n    location of ``key`` in ``categories`` is in ``container``.\r\n\r\n    Parameters\r\n    ----------\r\n    cat : :class:`Categorical`or :class:`categoricalIndex`\r\n    key : a hashable object\r\n        The key to check membership for.\r\n    container : Container (e.g. list-like or mapping)\r\n        The container to check for membership in.\r\n\r\n    Returns\r\n    -------\r\n    is_in : bool\r\n        True if ``key`` is in ``self.categories`` and location of\r\n        ``key`` in ``categories`` is in ``container``, else False.\r\n\r\n    Notes\r\n    -----\r\n    This method does not check for NaN values. Do that separately\r\n    before calling this method.\r\n    \"\"\"\r\n    hash(key)\r\n\r\n    # get location of key in categories.\r\n    # If a KeyError, the key isn't in categories, so logically\r\n    #  can't be in container either.\r\n    try:\r\n        loc = cat.categories.get_loc(key)\r\n    except (KeyError, TypeError):\r\n        return False\r\n\r\n    # loc is the location of key in categories, but also the *value*\r\n    # for key in container. So, `key` may be in categories,\r\n    # but still not in `container`. Example ('b' in categories,\r\n    # but not in values):\r\n    # 'b' in Categorical(['a'], categories=['a', 'b'])  # False\r\n    if is_scalar(loc):\r\n        return loc in container\r\n    else:\r\n        # if categories is an IntervalIndex, loc is an array.\r\n        return any(loc_ in container for loc_ in loc)\r\n\r\n\r\n# error: Definition of \"delete/ravel/T/repeat/copy\" in base class \"NDArrayBacked\"\r\n# is incompatible with definition in base class \"ExtensionArray\"\r\nclass Categorical(NDArrayBackedExtensionArray, PandasObject, ObjectStringArrayMixin):  # type: ignore[misc]\r\n    \"\"\"\r\n    Represent a categorical variable in classic R / S-plus fashion.\r\n\r\n    `Categoricals` can only take on a limited, and usually fixed, number\r\n    of possible values (`categories`). In contrast to statistical categorical\r\n    variables, a `Categorical` might have an order, but numerical operations\r\n    (additions, divisions, ...) are not possible.\r\n\r\n    All values of the `Categorical` are either in `categories` or `np.nan`.\r\n    Assigning values outside of `categories` will raise a `ValueError`. Order\r\n    is defined by the order of the `categories`, not lexical order of the\r\n    values.\r\n\r\n"]
[200.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[200.002, "i", "applypatch << 'PATCH'\r"]
[200.004, "o", "applypatch << 'PATCH'\r\n"]
[200.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> *** Begin Patch\r\n\u001b[?2004l\r\n\u001b[?2004h> *** Update File: pandas/core/util/hashing.py\r\n\u001b[?2004l\r\n\u001b[?2004h> @@\r\n\u001b[?2004l\r\n\u001b[?2004h> -        if categorize:\r\n\u001b[?2004l\r\n\u001b[?2004h> -            from pandas import (\r\n\u001b[?2004l\r\n\u001b[?2004h> -                Categorical,\r\n\u001b[?2004l\r\n\u001b[?2004h> -                Index,\r\n\u001b[?2004l\r\n\u001b[?2004h> -                factorize,\r\n\u001b[?2004l\r\n\u001b[?2004h> -            )\r\n\u001b[?2004l\r\n\u001b[?2004h> -\r\n\u001b[?2004l\r\n\u001b[?2004h> -            codes, categories = factorize(vals, sort=False)\r\n\u001b[?2004l\r\n\u001b[?2004h> -            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n\u001b[?2004l\r\n\u001b[?2004h> -            cat = Categorical._simple_new(codes, dtype)\r\n\u001b[?2004l\r\n\u001b[?2004h> -            return cat._hash_pandas_object(\r\n\u001b[?2004l\r\n\u001b[?2004h> -                encoding=encoding, hash_key=hash_key, categorize=False\r\n\u001b[?2004l\r\n\u001b[?2004h> -            )\r\n\u001b[?2004l\r\n\u001b[?2004h> +        if categorize:\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # Fast-path: avoid constructing a full Categorical object.\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # We factorize once, hash the unique categories, and then\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # gather via codes. This mirrors Categorical._hash_pandas_object\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # logic while avoiding Python-level object construction overhead.\r\n\u001b[?2004l\r\n\u001b[?2004h> +            from pandas import factorize\r\n\u001b[?2004l\r\n\u001b[?2004h> +\r\n\u001b[?2004l\r\n\u001b[?2004h> +            codes, categories = factorize(vals, sort=False)\r\n\u001b[?2004l\r\n\u001b[?2004h> +\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # Hash the categories once. Ensure we operate on object-dtype\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # for the hashing routine which expects Python objects.\r\n\u001b[?2004l\r\n\u001b[?2004h> +            try:\r\n\u001b[?2004l\r\n\u001b[?2004h> +                cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\r\n\u001b[?2004l\r\n\u001b[?2004h> +            except TypeError:\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # Mixed categories that fail direct hashing: fall back to string\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # conversion similar to the non-categorized case.\r\n\u001b[?2004l\r\n\u001b[?2004h> +                cat_hashes = hash_object_array(\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    np.asarray(categories, dtype=object).astype(str).astype(object),\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    hash_key,\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    encoding,\r\n\u001b[?2004l\r\n\u001b[?2004h> +                )\r\n\u001b[?2004l\r\n\u001b[?2004h> +\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # Map codes to their corresponding category hash. Codes == -1 are NAs;\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # follow existing semantics by assigning 0 for NA slots before the\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # final bit-mixing below.\r\n\u001b[?2004l\r\n\u001b[?2004h> +            out = np.zeros(codes.size, dtype=np.uint64)\r\n\u001b[?2004l\r\n\u001b[?2004h> +            mask = codes != -1\r\n\u001b[?2004l\r\n\u001b[?2004h> +            if mask.any():\r\n\u001b[?2004l\r\n\u001b[?2004h> +                out[mask] = cat_hashes[codes[mask]]\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # Continue with post-processing (bit-mixing) below.\r\n\u001b[?2004l\r\n\u001b[?2004h> +            vals = out\r\n\u001b[?2004l\r\n\u001b[?2004h> *** End Patch\r\n\u001b[?2004l\r\n\u001b[?2004h> PATCH\r\n\u001b[?2004l\r\n-bash: applypatch: command not found\r\n"]
[205.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[205.002, "i", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[205.004, "o", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[205.006, "o", "\u001b[?2004l\r\n"]
[210.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[210.002, "i", "cd .. && asv_bench/asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[210.004, "o", "cd .. && asv_bench/asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[210.006, "o", "\u001b[?2004l\r\n-bash: asv_bench/asv: No such file or directory\r\n"]
[215.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[215.002, "i", "cd asv_bench && asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[215.004, "o", "cd asv_bench && asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[215.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                  7.78\u00b10.04ms\r\n\r\nWed Oct  1 17:39:49 2025    /tmp/tmpf1gz8e81\r\n\r\n         798 function calls (782 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n      3/2    0.000    0.000    0.008    0.004 hashing.py:235(hash_array)\r\n      3/2    0.001    0.000    0.008    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:2406(is_unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55ec96e6c640}\r\n        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n\r\n\r\n"]
[220.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[220.002, "i", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[220.004, "o", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[220.006, "o", "\u001b[?2004l\r\n"]
[225.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[225.002, "i", "grep -RIn --line-number --color=never \"def _hash_pandas_object\" ../pandas/core/arrays/categorical.py\r"]
[225.004, "o", "grep -RIn --line-number --color=never \"def _hash_pandas_object\" ../pandas/core/arrays/categorical.py\r\n"]
[225.006, "o", "\u001b[?2004l\r\n2133:    def _hash_pandas_object(\r\n"]
[230.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[230.002, "i", "sed -n '1,320p' ../pandas/core/arrays/categorical.py\r"]
[230.004, "o", "sed -n '1,320p' ../pandas/core/arrays/categorical.py\r\n"]
[230.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nfrom csv import QUOTE_NONNUMERIC\r\nfrom functools import partial\r\nimport operator\r\nfrom shutil import get_terminal_size\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Literal,\r\n    cast,\r\n    overload,\r\n)\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import get_option\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    algos as libalgos,\r\n    lib,\r\n)\r\nfrom pandas._libs.arrays import NDArrayBacked\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.util._validators import validate_bool_kwarg\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    coerce_indexer_dtype,\r\n    find_common_type,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_int64,\r\n    ensure_platform_int,\r\n    is_any_real_numeric_dtype,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_hashable,\r\n    is_integer_dtype,\r\n    is_list_like,\r\n    is_scalar,\r\n    needs_i8_conversion,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    ArrowDtype,\r\n    CategoricalDtype,\r\n    CategoricalDtypeType,\r\n    ExtensionDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCIndex,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms,\r\n    arraylike,\r\n    ops,\r\n)\r\nfrom pandas.core.accessor import (\r\n    PandasDelegate,\r\n    delegate_names,\r\n)\r\nfrom pandas.core.algorithms import (\r\n    factorize,\r\n    take_nd,\r\n)\r\nfrom pandas.core.arrays._mixins import (\r\n    NDArrayBackedExtensionArray,\r\n    ravel_compat,\r\n)\r\nfrom pandas.core.base import (\r\n    ExtensionArray,\r\n    NoNewAttributesMixin,\r\n    PandasObject,\r\n)\r\nimport pandas.core.common as com\r\nfrom pandas.core.construction import (\r\n    extract_array,\r\n    sanitize_array,\r\n)\r\nfrom pandas.core.ops.common import unpack_zerodim_and_defer\r\nfrom pandas.core.sorting import nargsort\r\nfrom pandas.core.strings.object_array import ObjectStringArrayMixin\r\n\r\nfrom pandas.io.formats import console\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Callable,\r\n        Hashable,\r\n        Iterator,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._typing import (\r\n        ArrayLike,\r\n        AstypeArg,\r\n        AxisInt,\r\n        Dtype,\r\n        DtypeObj,\r\n        NpDtype,\r\n        Ordered,\r\n        Self,\r\n        Shape,\r\n        SortKind,\r\n        npt,\r\n    )\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        Index,\r\n        Series,\r\n    )\r\n\r\n\r\ndef _cat_compare_op(op):\r\n    opname = f\"__{op.__name__}__\"\r\n    fill_value = op is operator.ne\r\n\r\n    @unpack_zerodim_and_defer(opname)\r\n    def func(self, other):\r\n        hashable = is_hashable(other)\r\n        if is_list_like(other) and len(other) != len(self) and not hashable:\r\n            # in hashable case we may have a tuple that is itself a category\r\n            raise ValueError(\"Lengths must match.\")\r\n\r\n        if not self.ordered:\r\n            if opname in [\"__lt__\", \"__gt__\", \"__le__\", \"__ge__\"]:\r\n                raise TypeError(\r\n                    \"Unordered Categoricals can only compare equality or not\"\r\n                )\r\n        if isinstance(other, Categorical):\r\n            # Two Categoricals can only be compared if the categories are\r\n            # the same (maybe up to ordering, depending on ordered)\r\n\r\n            msg = \"Categoricals can only be compared if 'categories' are the same.\"\r\n            if not self._categories_match_up_to_permutation(other):\r\n                raise TypeError(msg)\r\n\r\n            if not self.ordered and not self.categories.equals(other.categories):\r\n                # both unordered and different order\r\n                other_codes = recode_for_categories(\r\n                    other.codes, other.categories, self.categories, copy=False\r\n                )\r\n            else:\r\n                other_codes = other._codes\r\n\r\n            ret = op(self._codes, other_codes)\r\n            mask = (self._codes == -1) | (other_codes == -1)\r\n            if mask.any():\r\n                ret[mask] = fill_value\r\n            return ret\r\n\r\n        if hashable:\r\n            if other in self.categories:\r\n                i = self._unbox_scalar(other)\r\n                ret = op(self._codes, i)\r\n\r\n                if opname not in {\"__eq__\", \"__ge__\", \"__gt__\"}:\r\n                    # GH#29820 performance trick; get_loc will always give i>=0,\r\n                    #  so in the cases (__ne__, __le__, __lt__) the setting\r\n                    #  here is a no-op, so can be skipped.\r\n                    mask = self._codes == -1\r\n                    ret[mask] = fill_value\r\n                return ret\r\n            else:\r\n                return ops.invalid_comparison(self, other, op)\r\n        else:\r\n            # allow categorical vs object dtype array comparisons for equality\r\n            # these are only positional comparisons\r\n            if opname not in [\"__eq__\", \"__ne__\"]:\r\n                raise TypeError(\r\n                    f\"Cannot compare a Categorical for op {opname} with \"\r\n                    f\"type {type(other)}.\\nIf you want to compare values, \"\r\n                    \"use 'np.asarray(cat) <op> other'.\"\r\n                )\r\n\r\n            if isinstance(other, ExtensionArray) and needs_i8_conversion(other.dtype):\r\n                # We would return NotImplemented here, but that messes up\r\n                #  ExtensionIndex's wrapped methods\r\n                return op(other, self)\r\n            return getattr(np.array(self), opname)(np.array(other))\r\n\r\n    func.__name__ = opname\r\n\r\n    return func\r\n\r\n\r\ndef contains(cat, key, container) -> bool:\r\n    \"\"\"\r\n    Helper for membership check for ``key`` in ``cat``.\r\n\r\n    This is a helper method for :method:`__contains__`\r\n    and :class:`CategoricalIndex.__contains__`.\r\n\r\n    Returns True if ``key`` is in ``cat.categories`` and the\r\n    location of ``key`` in ``categories`` is in ``container``.\r\n\r\n    Parameters\r\n    ----------\r\n    cat : :class:`Categorical`or :class:`categoricalIndex`\r\n    key : a hashable object\r\n        The key to check membership for.\r\n    container : Container (e.g. list-like or mapping)\r\n        The container to check for membership in.\r\n\r\n    Returns\r\n    -------\r\n    is_in : bool\r\n        True if ``key`` is in ``self.categories`` and location of\r\n        ``key`` in ``categories`` is in ``container``, else False.\r\n\r\n    Notes\r\n    -----\r\n    This method does not check for NaN values. Do that separately\r\n    before calling this method.\r\n    \"\"\"\r\n    hash(key)\r\n\r\n    # get location of key in categories.\r\n    # If a KeyError, the key isn't in categories, so logically\r\n    #  can't be in container either.\r\n    try:\r\n        loc = cat.categories.get_loc(key)\r\n    except (KeyError, TypeError):\r\n        return False\r\n\r\n    # loc is the location of key in categories, but also the *value*\r\n    # for key in container. So, `key` may be in categories,\r\n    # but still not in `container`. Example ('b' in categories,\r\n    # but not in values):\r\n    # 'b' in Categorical(['a'], categories=['a', 'b'])  # False\r\n    if is_scalar(loc):\r\n        return loc in container\r\n    else:\r\n        # if categories is an IntervalIndex, loc is an array.\r\n        return any(loc_ in container for loc_ in loc)\r\n\r\n\r\n# error: Definition of \"delete/ravel/T/repeat/copy\" in base class \"NDArrayBacked\"\r\n# is incompatible with definition in base class \"ExtensionArray\"\r\nclass Categorical(NDArrayBackedExtensionArray, PandasObject, ObjectStringArrayMixin):  # type: ignore[misc]\r\n    \"\"\"\r\n    Represent a categorical variable in classic R / S-plus fashion.\r\n\r\n    `Categoricals` can only take on a limited, and usually fixed, number\r\n    of possible values (`categories`). In contrast to statistical categorical\r\n    variables, a `Categorical` might have an order, but numerical operations\r\n    (additions, divisions, ...) are not possible.\r\n\r\n    All values of the `Categorical` are either in `categories` or `np.nan`.\r\n    Assigning values outside of `categories` will raise a `ValueError`. Order\r\n    is defined by the order of the `categories`, not lexical order of the\r\n    values.\r\n\r\n    Parameters\r\n    ----------\r\n    values : list-like\r\n        The values of the categorical. If categories are given, values not in\r\n        categories will be replaced with NaN.\r\n    categories : Index-like (unique), optional\r\n        The unique categories for this categorical. If not given, the\r\n        categories are assumed to be the unique values of `values` (sorted, if\r\n        possible, otherwise in the order in which they appear).\r\n    ordered : bool, default False\r\n        Whether or not this categorical is treated as a ordered categorical.\r\n        If True, the resulting categorical will be ordered.\r\n        An ordered categorical respects, when sorted, the order of its\r\n        `categories` attribute (which in turn is the `categories` argument, if\r\n        provided).\r\n    dtype : CategoricalDtype\r\n        An instance of ``CategoricalDtype`` to use for this categorical.\r\n    copy : bool, default True\r\n        Whether to copy if the codes are unchanged.\r\n\r\n    Attributes\r\n    ----------\r\n    categories : Index\r\n        The categories of this categorical.\r\n    codes : ndarray\r\n        The codes (integer positions, which point to the categories) of this\r\n        categorical, read only.\r\n    ordered : bool\r\n        Whether or not this Categorical is ordered.\r\n    dtype : CategoricalDtype\r\n        The instance of ``CategoricalDtype`` storing the ``categories``\r\n        and ``ordered``.\r\n\r\n    Methods\r\n    -------\r\n    from_codes\r\n    as_ordered\r\n    as_unordered\r\n    set_categories\r\n    rename_categories\r\n    reorder_categories\r\n    add_categories\r\n    remove_categories\r\n    remove_unused_categories\r\n    map\r\n    __array__\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        If the categories do not validate.\r\n    TypeError\r\n        If an explicit ``ordered=True`` is given but no `categories` and the\r\n        `values` are not sortable.\r\n\r\n    See Also\r\n    --------\r\n    CategoricalDtype : Type for categorical data.\r\n    CategoricalIndex : An Index with an underlying ``Categorical``.\r\n\r\n"]
[235.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[235.002, "i", "cd .. && asv_bench/asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[235.004, "o", "cd .. && asv_bench/asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[235.006, "o", "\u001b[?2004l\r\n-bash: asv_bench/asv: No such file or directory\r\n"]
[240.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[240.002, "i", "cd asv_bench && asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[240.004, "o", "cd asv_bench && asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[240.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   8.73\u00b10.1ms\r\n\r\nWed Oct  1 17:42:02 2025    /tmp/tmppf2sq063\r\n\r\n         798 function calls (782 primitive calls) in 0.009 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.009    0.009 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.009    0.009 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.009    0.009 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.009    0.009 hashing.py:84(hash_pandas_object)\r\n      3/2    0.000    0.000    0.008    0.004 hashing.py:235(hash_array)\r\n      3/2    0.001    0.000    0.008    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.006    0.006 algorithms.py:639(factorize)\r\n        1    0.006    0.006    0.006    0.006 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        1    0.000    0.000    0.001    0.001 base.py:2406(is_unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55af174de640}\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n\r\n\r\n"]
[245.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[245.002, "i", "sed -n '1,360p' ../pandas/core/util/hashing.py\r"]
[245.004, "o", "sed -n '1,360p' ../pandas/core/util/hashing.py\r\n"]
[245.006, "o", "\u001b[?2004l\r\n\"\"\"\r\ndata hash pandas / numpy objects\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport itertools\r\nfrom typing import TYPE_CHECKING\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs.hashing import hash_object_array\r\n\r\nfrom pandas.core.dtypes.common import is_list_like\r\nfrom pandas.core.dtypes.dtypes import CategoricalDtype\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCExtensionArray,\r\n    ABCIndex,\r\n    ABCMultiIndex,\r\n    ABCSeries,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterable,\r\n        Iterator,\r\n    )\r\n\r\n    from pandas._typing import (\r\n        ArrayLike,\r\n        npt,\r\n    )\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        Index,\r\n        MultiIndex,\r\n        Series,\r\n    )\r\n\r\n\r\n# 16 byte long hashing key\r\n_default_hash_key = \"0123456789123456\"\r\n\r\n\r\ndef combine_hash_arrays(\r\n    arrays: Iterator[np.ndarray], num_items: int\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Parameters\r\n    ----------\r\n    arrays : Iterator[np.ndarray]\r\n    num_items : int\r\n\r\n    Returns\r\n    -------\r\n    np.ndarray[uint64]\r\n\r\n    Should be the same as CPython's tupleobject.c\r\n    \"\"\"\r\n    try:\r\n        first = next(arrays)\r\n    except StopIteration:\r\n        return np.array([], dtype=np.uint64)\r\n\r\n    arrays = itertools.chain([first], arrays)\r\n\r\n    mult = np.uint64(1000003)\r\n    out = np.zeros_like(first) + np.uint64(0x345678)\r\n    last_i = 0\r\n    for i, a in enumerate(arrays):\r\n        inverse_i = num_items - i\r\n        out ^= a\r\n        out *= mult\r\n        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n        last_i = i\r\n    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n    out += np.uint64(97531)\r\n    return out\r\n\r\n\r\ndef hash_pandas_object(\r\n    obj: Index | DataFrame | Series,\r\n    index: bool = True,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str | None = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> Series:\r\n    \"\"\"\r\n    Return a data hash of the Index/Series/DataFrame.\r\n\r\n    Parameters\r\n    ----------\r\n    obj : Index, Series, or DataFrame\r\n    index : bool, default True\r\n        Include the index in the hash (if Series/DataFrame).\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    Series of uint64\r\n        Same length as the object.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n    0    14639053686158035780\r\n    1     3869563279212530728\r\n    2      393322362522515241\r\n    dtype: uint64\r\n    \"\"\"\r\n    from pandas import Series\r\n\r\n    if hash_key is None:\r\n        hash_key = _default_hash_key\r\n\r\n    if isinstance(obj, ABCMultiIndex):\r\n        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCIndex):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCSeries):\r\n        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n            \"uint64\", copy=False\r\n        )\r\n        if index:\r\n            index_iter = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            arrays = itertools.chain([h], index_iter)\r\n            h = combine_hash_arrays(arrays, 2)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n\r\n    elif isinstance(obj, ABCDataFrame):\r\n        hashes = (\r\n            hash_array(series._values, encoding, hash_key, categorize)\r\n            for _, series in obj.items()\r\n        )\r\n        num_items = len(obj.columns)\r\n        if index:\r\n            index_hash_generator = (\r\n                hash_pandas_object(\r\n                    obj.index,\r\n                    index=False,\r\n                    encoding=encoding,\r\n                    hash_key=hash_key,\r\n                    categorize=categorize,\r\n                )._values\r\n                for _ in [None]\r\n            )\r\n            num_items += 1\r\n\r\n            # keep `hashes` specifically a generator to keep mypy happy\r\n            _hashes = itertools.chain(hashes, index_hash_generator)\r\n            hashes = (x for x in _hashes)\r\n        h = combine_hash_arrays(hashes, num_items)\r\n\r\n        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n    else:\r\n        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n\r\n    return ser\r\n\r\n\r\ndef hash_tuples(\r\n    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : MultiIndex or listlike-of-tuples\r\n    encoding : str, default 'utf8'\r\n    hash_key : str, default _default_hash_key\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64] of hashed values\r\n    \"\"\"\r\n    if not is_list_like(vals):\r\n        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n\r\n    from pandas import (\r\n        Categorical,\r\n        MultiIndex,\r\n    )\r\n\r\n    if not isinstance(vals, ABCMultiIndex):\r\n        mi = MultiIndex.from_tuples(vals)\r\n    else:\r\n        mi = vals\r\n\r\n    # create a list-of-Categoricals\r\n    cat_vals = [\r\n        Categorical._simple_new(\r\n            mi.codes[level],\r\n            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n        )\r\n        for level in range(mi.nlevels)\r\n    ]\r\n\r\n    # hash the list-of-ndarrays\r\n    hashes = (\r\n        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n        for cat in cat_vals\r\n    )\r\n    h = combine_hash_arrays(hashes, len(cat_vals))\r\n\r\n    return h\r\n\r\n\r\ndef hash_array(\r\n    vals: ArrayLike,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Given a 1d array, return an array of deterministic integers.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : ndarray or ExtensionArray\r\n        The input array to hash.\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64, ndim=1]\r\n        Hashed values, same length as the vals.\r\n\r\n    See Also\r\n    --------\r\n    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n      dtype=uint64)\r\n    \"\"\"\r\n    if not hasattr(vals, \"dtype\"):\r\n        raise TypeError(\"must pass a ndarray-like\")\r\n\r\n    if isinstance(vals, ABCExtensionArray):\r\n        return vals._hash_pandas_object(\r\n            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n        )\r\n\r\n    if not isinstance(vals, np.ndarray):\r\n        # GH#42003\r\n        raise TypeError(\r\n            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n        )\r\n\r\n    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n\r\n\r\ndef _hash_ndarray(\r\n    vals: np.ndarray,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    See hash_array.__doc__.\r\n    \"\"\"\r\n    dtype = vals.dtype\r\n\r\n    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n    if np.issubdtype(dtype, np.complex128):\r\n        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n        return hash_real + 23 * hash_imag\r\n\r\n    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n    # manage it.\r\n    if dtype == bool:\r\n        vals = vals.astype(\"u8\")\r\n    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n    else:\r\n        # With repeated values, its MUCH faster to categorize object dtypes,\r\n        # then hash and rename categories. We allow skipping the categorization\r\n        # when the values are known/likely to be unique.\r\n        if categorize:\r\n            from pandas import (\r\n                Categorical,\r\n                Index,\r\n                factorize,\r\n            )\r\n\r\n            codes, categories = factorize(vals, sort=False)\r\n            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n            cat = Categorical._simple_new(codes, dtype)\r\n            return cat._hash_pandas_object(\r\n                encoding=encoding, hash_key=hash_key, categorize=False\r\n            )\r\n\r\n        try:\r\n            vals = hash_object_array(vals, hash_key, encoding)\r\n        except TypeError:\r\n            # we have mixed types\r\n            vals = hash_object_array(\r\n                vals.astype(str).astype(object), hash_key, encoding\r\n            )\r\n\r\n    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n    vals ^= vals >> 30\r\n    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n    vals ^= vals >> 27\r\n    vals *= np.uint64(0x94D049BB133111EB)\r\n    vals ^= vals >> 31\r\n    return vals\r\n"]
[250.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[250.002, "i", "git status -sb\r"]
[250.004, "o", "git status -sb\r\n"]
[250.006, "o", "\u001b[?2004l\r\n## \u001b[32mmain\u001b[m\r\n"]
[255.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[255.002, "i", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[255.004, "o", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[255.006, "o", "\u001b[?2004l\r\n"]
[260.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[260.002, "i", "python - << 'PY'\r"]
[260.004, "o", "python - << 'PY'\r\n"]
[260.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/util/hashing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> old = '''        if categorize:\r\n\u001b[?2004l\r\n\u001b[?2004h>             from pandas import (\r\n\u001b[?2004l\r\n\u001b[?2004h>                 Categorical,\r\n\u001b[?2004l\r\n\u001b[?2004h>                 Index,\r\n\u001b[?2004l\r\n\u001b[?2004h>                 factorize,\r\n\u001b[?2004l\r\n\u001b[?2004h>             )\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h>             codes, categories = factorize(vals, sort=False)\r\n\u001b[?2004l\r\n\u001b[?2004h>             dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n\u001b[?2004l\r\n\u001b[?2004h>             cat = Categorical._simple_new(codes, dtype)\r\n\u001b[?2004l\r\n\u001b[?2004h>             return cat._hash_pandas_object(\r\n\u001b[?2004l\r\n\u001b[?2004h>                 encoding=encoding, hash_key=hash_key, categorize=False\r\n\u001b[?2004l\r\n\u001b[?2004h>             )\r\n\u001b[?2004l\r\n\u001b[?2004h> '''\r\n\u001b[?2004l\r\n\u001b[?2004h> new = '''        if categorize:\r\n\u001b[?2004l\r\n\u001b[?2004h>             # Fast-path: avoid constructing a full Categorical object.\r\n\u001b[?2004l\r\n\u001b[?2004h>             # Factorize once, hash unique categories, then gather via codes.\r\n\u001b[?2004l\r\n\u001b[?2004h>             from pandas import factorize\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h>             codes, categories = factorize(vals, sort=False)\r\n\u001b[?2004l\r\n\u001b[?2004h>             try:\r\n\u001b[?2004l\r\n\u001b[?2004h>                 cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\r\n\u001b[?2004l\r\n\u001b[?2004h>             except TypeError:\r\n\u001b[?2004l\r\n\u001b[?2004h>                 cat_hashes = hash_object_array(\r\n\u001b[?2004l\r\n\u001b[?2004h>                     np.asarray(categories, dtype=object).astype(str).astype(object),\r\n\u001b[?2004l\r\n\u001b[?2004h>                     hash_key,\r\n\u001b[?2004l\r\n\u001b[?2004h>                     encoding,\r\n\u001b[?2004l\r\n\u001b[?2004h>                 )\r\n\u001b[?2004l\r\n\u001b[?2004h>             out = np.zeros(codes.size, dtype=np.uint64)\r\n\u001b[?2004l\r\n\u001b[?2004h>             mask = codes != -1\r\n\u001b[?2004l\r\n\u001b[?2004h>             if mask.any():\r\n\u001b[?2004l\r\n\u001b[?2004h>                 out[mask] = cat_hashes[codes[mask]]\r\n\u001b[?2004l\r\n\u001b[?2004h>             vals = out\r\n\u001b[?2004l\r\n\u001b[?2004h> '''\r\n\u001b[?2004l\r\n\u001b[?2004h> if old in s:\r\n\u001b[?2004l\r\n\u001b[?2004h>     s = s.replace(old, new)\r\n\u001b[?2004l\r\n\u001b[?2004h>     p.write_text(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('PATCH_APPLIED')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('PATCH_NOT_FOUND')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nPATCH_APPLIED\r\n"]
[265.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[265.002, "i", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[265.004, "o", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[265.006, "o", "\u001b[?2004l\r\n"]
[270.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[270.002, "i", "cd .. && asv_bench/asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[270.004, "o", "cd .. && asv_bench/asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[270.006, "o", "\u001b[?2004l\r\n-bash: asv_bench/asv: No such file or directory\r\n"]
[275.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[275.002, "i", "cd asv_bench && asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[275.004, "o", "cd asv_bench && asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[275.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                       failed\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mTraceback (most recent call last):\u001b[0m\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/server.py\", line 179, in _run_server\r\n         _run(run_args)\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/run.py\", line 72, in _run\r\n         result = benchmark.do_run()\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/benchmarks/_base.py\", line 661, in do_run\r\n         return self.run(*self._current_params)\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/benchmarks/time.py\", line 165, in run\r\n         samples, number = self.benchmark_timing(\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/benchmarks/time.py\", line 258, in benchmark_timing\r\n         timing = timer.timeit(number)\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/timeit.py\", line 178, in timeit\r\n         timing = self.inner(it, self.timer)\r\n       File \"<timeit-src>\", line 6, in inner\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/benchmarks/time.py\", line 90, in func\r\n         self.func(*param)\r\n       File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 161, in time_series_string\r\n         hashing.hash_pandas_object(df[\"strings\"])\r\n       File \"/workspace/repo/pandas/core/util/hashing.py\", line 135, in hash_pandas_object\r\n         h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n       File \"/workspace/repo/pandas/core/util/hashing.py\", line 287, in hash_array\r\n         return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n       File \"/workspace/repo/pandas/core/util/hashing.py\", line 340, in _hash_ndarray\r\n         vals = hash_object_array(vals, hash_key, encoding)\r\n       File \"pandas/_libs/hashing.pyx\", line 24, in pandas._libs.hashing.hash_object_array\r\n     ValueError: Buffer dtype mismatch, expected 'Python object' but got 'unsigned long'\r\n     asv: benchmark failed (exit status 1)\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/asv_3.10/bin/asv\", line 7, in <module>\r\n    sys.exit(main())\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/main.py\", line 28, in main\r\n    result = args.func(args)\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/commands/__init__.py\", line 48, in run_from_args\r\n    return cls.run_from_conf_args(conf, args)\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/commands/profiling.py\", line 84, in run_from_conf_args\r\n    return cls.run(\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/commands/profiling.py\", line 207, in run\r\n    profile_data = results.get_profile(benchmark_name)\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/results.py\", line 561, in get_profile\r\n    profile_data = self._profiles[benchmark_name]\r\nKeyError: 'algorithms.Hashing.time_series_string'\r\n"]
[280.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[280.002, "i", "python - << 'PY'\r"]
[280.004, "o", "python - << 'PY'\r\n"]
[280.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/util/hashing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Insert 'else:' before the try: block that follows our categorize fast-path\r\n\u001b[?2004l\r\n\u001b[?2004h> pattern = r\"(if categorize:\\n(?:(?:    ).*\\n)+\\s*vals = out\\n)(\\s*try:)\"\r\n\u001b[?2004l\r\n\u001b[?2004h> new_s, n = re.subn(pattern, r\"\\1else:\\n\\2\", s)\r\n\u001b[?2004l\r\n\u001b[?2004h> if n:\r\n\u001b[?2004l\r\n\u001b[?2004h>     p.write_text(new_s)\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('ELSE_INSERTED')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('NO_CHANGE_APPLIED')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nNO_CHANGE_APPLIED\r\n"]
[285.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[285.002, "i", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[285.004, "o", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[285.006, "o", "\u001b[?2004l\r\n"]
[290.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[290.002, "i", "cd .. && asv_bench/asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[290.004, "o", "cd .. && asv_bench/asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[290.006, "o", "\u001b[?2004l\r\n-bash: asv_bench/asv: No such file or directory\r\n"]
[295.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[295.002, "i", "cd asv_bench && asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[295.004, "o", "cd asv_bench && asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[295.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                       failed\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mTraceback (most recent call last):\u001b[0m\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/server.py\", line 179, in _run_server\r\n         _run(run_args)\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/run.py\", line 72, in _run\r\n         result = benchmark.do_run()\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/benchmarks/_base.py\", line 661, in do_run\r\n         return self.run(*self._current_params)\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/benchmarks/time.py\", line 165, in run\r\n         samples, number = self.benchmark_timing(\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/benchmarks/time.py\", line 258, in benchmark_timing\r\n         timing = timer.timeit(number)\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/timeit.py\", line 178, in timeit\r\n         timing = self.inner(it, self.timer)\r\n       File \"<timeit-src>\", line 6, in inner\r\n       File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/benchmarks/time.py\", line 90, in func\r\n         self.func(*param)\r\n       File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 161, in time_series_string\r\n         hashing.hash_pandas_object(df[\"strings\"])\r\n       File \"/workspace/repo/pandas/core/util/hashing.py\", line 135, in hash_pandas_object\r\n         h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n       File \"/workspace/repo/pandas/core/util/hashing.py\", line 287, in hash_array\r\n         return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n       File \"/workspace/repo/pandas/core/util/hashing.py\", line 340, in _hash_ndarray\r\n         vals = hash_object_array(vals, hash_key, encoding)\r\n       File \"pandas/_libs/hashing.pyx\", line 24, in pandas._libs.hashing.hash_object_array\r\n     ValueError: Buffer dtype mismatch, expected 'Python object' but got 'unsigned long'\r\n     asv: benchmark failed (exit status 1)\r\n\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/asv_3.10/bin/asv\", line 7, in <module>\r\n    sys.exit(main())\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/main.py\", line 28, in main\r\n    result = args.func(args)\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/commands/__init__.py\", line 48, in run_from_args\r\n    return cls.run_from_conf_args(conf, args)\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/commands/profiling.py\", line 84, in run_from_conf_args\r\n    return cls.run(\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/commands/profiling.py\", line 207, in run\r\n    profile_data = results.get_profile(benchmark_name)\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/results.py\", line 561, in get_profile\r\n    profile_data = self._profiles[benchmark_name]\r\nKeyError: 'algorithms.Hashing.time_series_string'\r\n"]
[300.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[300.002, "i", "sed -n '300,380p' ../pandas/core/util/hashing.py\r"]
[300.004, "o", "sed -n '300,380p' ../pandas/core/util/hashing.py\r\n"]
[300.006, "o", "\u001b[?2004l\r\n\r\n    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n    if np.issubdtype(dtype, np.complex128):\r\n        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n        return hash_real + 23 * hash_imag\r\n\r\n    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n    # manage it.\r\n    if dtype == bool:\r\n        vals = vals.astype(\"u8\")\r\n    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n    else:\r\n        # With repeated values, its MUCH faster to categorize object dtypes,\r\n        # then hash and rename categories. We allow skipping the categorization\r\n        # when the values are known/likely to be unique.\r\n        if categorize:\r\n            # Fast-path: avoid constructing a full Categorical object.\r\n            # Factorize once, hash unique categories, then gather via codes.\r\n            from pandas import factorize\r\n\r\n            codes, categories = factorize(vals, sort=False)\r\n            try:\r\n                cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\r\n            except TypeError:\r\n                cat_hashes = hash_object_array(\r\n                    np.asarray(categories, dtype=object).astype(str).astype(object),\r\n                    hash_key,\r\n                    encoding,\r\n                )\r\n            out = np.zeros(codes.size, dtype=np.uint64)\r\n            mask = codes != -1\r\n            if mask.any():\r\n                out[mask] = cat_hashes[codes[mask]]\r\n            vals = out\r\n\r\n        try:\r\n            vals = hash_object_array(vals, hash_key, encoding)\r\n        except TypeError:\r\n            # we have mixed types\r\n            vals = hash_object_array(\r\n                vals.astype(str).astype(object), hash_key, encoding\r\n            )\r\n\r\n    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n    vals ^= vals >> 30\r\n    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n    vals ^= vals >> 27\r\n    vals *= np.uint64(0x94D049BB133111EB)\r\n    vals ^= vals >> 31\r\n    return vals\r\n"]
[305.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[305.002, "i", "python - << 'PY'\r"]
[305.004, "o", "python - << 'PY'\r\n"]
[305.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/util/hashing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> start = s.find('        if categorize:')\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find the end of our fast-path block by locating the line setting 'vals = out'\r\n\u001b[?2004l\r\n\u001b[?2004h> end = s.find('\\n            vals = out', start)\r\n\u001b[?2004l\r\n\u001b[?2004h> if start != -1 and end != -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Position after 'vals = out' line\r\n\u001b[?2004l\r\n\u001b[?2004h>     insert_pos = s.find('\\n', end + 1) + 1\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Ensure the next non-empty, non-comment line starts with 'try:'; if so, insert 'else:' before it.\r\n\u001b[?2004l\r\n\u001b[?2004h>     rest = s[insert_pos:]\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Skip blank/comment lines while preserving them\r\n\u001b[?2004l\r\n\u001b[?2004h>     lines = rest.splitlines(True)\r\n\u001b[?2004l\r\n\u001b[?2004h>     idx = 0\r\n\u001b[?2004l\r\n\u001b[?2004h>     while idx < len(lines) and (lines[idx].strip() == '' or lines[idx].lstrip().startswith('#')):\r\n\u001b[?2004l\r\n\u001b[?2004h>         idx += 1\r\n\u001b[?2004l\r\n\u001b[?2004h>     if idx < len(lines) and lines[idx].lstrip().startswith('try:'):\r\n\u001b[?2004l\r\n\u001b[?2004h>         lines[idx] = '        else:\\n' + lines[idx]\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_rest = ''.join(lines)\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_s = s[:insert_pos] + new_rest\r\n\u001b[?2004l\r\n\u001b[?2004h>         p.write_text(new_s)\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('ELSE_INSERTED')\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('TRY_NOT_FOUND_AFTER_FASTPATH')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('FASTPATH_NOT_FOUND')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nELSE_INSERTED\r\n"]
[310.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[310.002, "i", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[310.004, "o", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[310.006, "o", "\u001b[?2004l\r\n"]
[315.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[315.002, "i", "cd .. && asv_bench/asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[315.004, "o", "cd .. && asv_bench/asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[315.006, "o", "\u001b[?2004l\r\n-bash: asv_bench/asv: No such file or directory\r\n"]
[320.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[320.002, "i", "cd asv_bench && asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[320.004, "o", "cd asv_bench && asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[320.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmprvp4a6rx/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n   [1/1] Generating write_version_file with a custom command\r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 47, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n       from pandas.core.arrays import Categorical\r\n     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n       from pandas.core.arrays.masked import BaseMaskedArray\r\n     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n       from pandas.core.util.hashing import hash_array\r\n     File \"/workspace/repo/pandas/core/util/hashing.py\", line 340\r\n       try:\r\n       ^\r\n   IndentationError: expected an indented block after 'else' statement on line 339\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmprvp4a6rx/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[325.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[325.002, "i", "sed -n '300,380p' ../pandas/core/util/hashing.py\r"]
[325.004, "o", "sed -n '300,380p' ../pandas/core/util/hashing.py\r\n"]
[325.006, "o", "\u001b[?2004l\r\n\r\n    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n    if np.issubdtype(dtype, np.complex128):\r\n        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n        return hash_real + 23 * hash_imag\r\n\r\n    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n    # manage it.\r\n    if dtype == bool:\r\n        vals = vals.astype(\"u8\")\r\n    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n    else:\r\n        # With repeated values, its MUCH faster to categorize object dtypes,\r\n        # then hash and rename categories. We allow skipping the categorization\r\n        # when the values are known/likely to be unique.\r\n        if categorize:\r\n            # Fast-path: avoid constructing a full Categorical object.\r\n            # Factorize once, hash unique categories, then gather via codes.\r\n            from pandas import factorize\r\n\r\n            codes, categories = factorize(vals, sort=False)\r\n            try:\r\n                cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\r\n            except TypeError:\r\n                cat_hashes = hash_object_array(\r\n                    np.asarray(categories, dtype=object).astype(str).astype(object),\r\n                    hash_key,\r\n                    encoding,\r\n                )\r\n            out = np.zeros(codes.size, dtype=np.uint64)\r\n            mask = codes != -1\r\n            if mask.any():\r\n                out[mask] = cat_hashes[codes[mask]]\r\n            vals = out\r\n\r\n        else:\r\n        try:\r\n            vals = hash_object_array(vals, hash_key, encoding)\r\n        except TypeError:\r\n            # we have mixed types\r\n            vals = hash_object_array(\r\n                vals.astype(str).astype(object), hash_key, encoding\r\n            )\r\n\r\n    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n    vals ^= vals >> 30\r\n    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n    vals ^= vals >> 27\r\n    vals *= np.uint64(0x94D049BB133111EB)\r\n    vals ^= vals >> 31\r\n    return vals\r\n"]
[330.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[330.002, "i", "nl -ba ../pandas/core/util/hashing.py | sed -n '320,360p'\r"]
[330.004, "o", "nl -ba ../pandas/core/util/hashing.py | sed -n '320,360p'\r\n"]
[330.006, "o", "\u001b[?2004l\r\n   320\t            # Fast-path: avoid constructing a full Categorical object.\r\n   321\t            # Factorize once, hash unique categories, then gather via codes.\r\n   322\t            from pandas import factorize\r\n   323\t\r\n   324\t            codes, categories = factorize(vals, sort=False)\r\n   325\t            try:\r\n   326\t                cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\r\n   327\t            except TypeError:\r\n   328\t                cat_hashes = hash_object_array(\r\n   329\t                    np.asarray(categories, dtype=object).astype(str).astype(object),\r\n   330\t                    hash_key,\r\n   331\t                    encoding,\r\n   332\t                )\r\n   333\t            out = np.zeros(codes.size, dtype=np.uint64)\r\n   334\t            mask = codes != -1\r\n   335\t            if mask.any():\r\n   336\t                out[mask] = cat_hashes[codes[mask]]\r\n   337\t            vals = out\r\n   338\t\r\n   339\t        else:\r\n   340\t        try:\r\n   341\t            vals = hash_object_array(vals, hash_key, encoding)\r\n   342\t        except TypeError:\r\n   343\t            # we have mixed types\r\n   344\t            vals = hash_object_array(\r\n   345\t                vals.astype(str).astype(object), hash_key, encoding\r\n   346\t            )\r\n   347\t\r\n   348\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n   349\t    vals ^= vals >> 30\r\n   350\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n   351\t    vals ^= vals >> 27\r\n   352\t    vals *= np.uint64(0x94D049BB133111EB)\r\n   353\t    vals ^= vals >> 31\r\n   354\t    return vals\r\n"]
[335.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[335.002, "i", "python - << 'PY'\r"]
[335.004, "o", "python - << 'PY'\r\n"]
[335.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/util/hashing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find the object-dtype branch\r\n\u001b[?2004l\r\n\u001b[?2004h> obj_branch = s.find('\\n    else:\\n        # With repeated values')\r\n\u001b[?2004l\r\n\u001b[?2004h> if obj_branch == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Fallback: locate 'if categorize' within object branch\r\n\u001b[?2004l\r\n\u001b[?2004h>     obj_branch = s.find('if categorize:', s.find('With repeated values'))\r\n\u001b[?2004l\r\n\u001b[?2004h> start = s.find('if categorize:', obj_branch)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find the end of fast-path by locating 'vals = out' line\r\n\u001b[?2004l\r\n\u001b[?2004h> vals_out = s.find('vals = out', start)\r\n\u001b[?2004l\r\n\u001b[?2004h> line_after = s.find('\\n', vals_out)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Ensure the next non-empty line starts with 'try:' and fix indentation by inserting 'else:' before it and indenting the try block\r\n\u001b[?2004l\r\n\u001b[?2004h> rest = s[line_after+1:]\r\n\u001b[?2004l\r\n\u001b[?2004h> lines = rest.splitlines(True)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find first non-empty, non-comment line index\r\n\u001b[?2004l\r\n\u001b[?2004h> idx = 0\r\n\u001b[?2004l\r\n\u001b[?2004h> while idx < len(lines) and (lines[idx].strip() == '' or lines[idx].lstrip().startswith('#')):\r\n\u001b[?2004l\r\n\u001b[?2004h>     idx += 1\r\n\u001b[?2004l\r\n\u001b[?2004h> changed = False\r\n\u001b[?2004l\r\n\u001b[?2004h> if idx < len(lines) and lines[idx].lstrip().startswith('try:'):\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Insert 'else:' with correct indentation (8 spaces to align with 'if categorize:')\r\n\u001b[?2004l\r\n\u001b[?2004h>     lines[idx] = '        else:\\n' + '            ' + lines[idx].lstrip()\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Also indent the corresponding except block one level deeper if needed\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Find the next lines that start with 'except' at the same indentation and indent them\r\n\u001b[?2004l\r\n\u001b[?2004h>     for j in range(idx+1, min(idx+20, len(lines))):\r\n\u001b[?2004l\r\n\u001b[?2004h>         stripped = lines[j].lstrip()\r\n\u001b[?2004l\r\n\u001b[?2004h>         if stripped.startswith('except '):\r\n\u001b[?2004l\r\n\u001b[?2004h>             lines[j] = '            ' + stripped\r\n\u001b[?2004l\r\n\u001b[?2004h>             break\r\n\u001b[?2004l\r\n\u001b[?2004h>     s = s[:line_after+1] + ''.join(lines)\r\n\u001b[?2004l\r\n\u001b[?2004h>     p.write_text(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>     changed = True\r\n\u001b[?2004l\r\n\u001b[?2004h> print('FIX_APPLIED' if changed else 'NO_FIX_APPLIED')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nNO_FIX_APPLIED\r\n"]
[340.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[340.002, "i", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[340.004, "o", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[340.006, "o", "\u001b[?2004l\r\n"]
[345.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[345.002, "i", "cd asv_bench\r"]
[345.004, "o", "cd asv_bench\r\n"]
[345.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[350.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[350.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[350.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[350.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpt1ecibi9/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n   [1/1] Generating write_version_file with a custom command\r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 47, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n       from pandas.core.arrays import Categorical\r\n     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n       from pandas.core.arrays.masked import BaseMaskedArray\r\n     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n       from pandas.core.util.hashing import hash_array\r\n     File \"/workspace/repo/pandas/core/util/hashing.py\", line 340\r\n       try:\r\n       ^\r\n   IndentationError: expected an indented block after 'else' statement on line 339\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpt1ecibi9/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[355.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[355.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[355.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[355.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpnjxnpe5b/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n   [1/1] Generating write_version_file with a custom command\r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 47, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n       from pandas.core.arrays import Categorical\r\n     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n       from pandas.core.arrays.masked import BaseMaskedArray\r\n     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n       from pandas.core.util.hashing import hash_array\r\n     File \"/workspace/repo/pandas/core/util/hashing.py\", line 340\r\n       try:\r\n       ^\r\n   IndentationError: expected an indented block after 'else' statement on line 339\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpnjxnpe5b/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[360.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[360.002, "i", "nl -ba ../pandas/core/util/hashing.py | sed -n '320,360p'\r"]
[360.004, "o", "nl -ba ../pandas/core/util/hashing.py | sed -n '320,360p'\r\n"]
[360.006, "o", "\u001b[?2004l\r\n   320\t            # Fast-path: avoid constructing a full Categorical object.\r\n   321\t            # Factorize once, hash unique categories, then gather via codes.\r\n   322\t            from pandas import factorize\r\n   323\t\r\n   324\t            codes, categories = factorize(vals, sort=False)\r\n   325\t            try:\r\n   326\t                cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\r\n   327\t            except TypeError:\r\n   328\t                cat_hashes = hash_object_array(\r\n   329\t                    np.asarray(categories, dtype=object).astype(str).astype(object),\r\n   330\t                    hash_key,\r\n   331\t                    encoding,\r\n   332\t                )\r\n   333\t            out = np.zeros(codes.size, dtype=np.uint64)\r\n   334\t            mask = codes != -1\r\n   335\t            if mask.any():\r\n   336\t                out[mask] = cat_hashes[codes[mask]]\r\n   337\t            vals = out\r\n   338\t\r\n   339\t        else:\r\n   340\t        try:\r\n   341\t            vals = hash_object_array(vals, hash_key, encoding)\r\n   342\t        except TypeError:\r\n   343\t            # we have mixed types\r\n   344\t            vals = hash_object_array(\r\n   345\t                vals.astype(str).astype(object), hash_key, encoding\r\n   346\t            )\r\n   347\t\r\n   348\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n   349\t    vals ^= vals >> 30\r\n   350\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n   351\t    vals ^= vals >> 27\r\n   352\t    vals *= np.uint64(0x94D049BB133111EB)\r\n   353\t    vals ^= vals >> 31\r\n   354\t    return vals\r\n"]
[365.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[365.002, "i", "python - << 'PY'\r"]
[365.004, "o", "python - << 'PY'\r\n"]
[365.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/util/hashing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Fix indentation of try/except after our inserted else\r\n\u001b[?2004l\r\n\u001b[?2004h> s = s.replace('\\n        else:\\ntry:', '\\n        else:\\n            try:')\r\n\u001b[?2004l\r\n\u001b[?2004h> # Also ensure the corresponding except in this block is indented\r\n\u001b[?2004l\r\n\u001b[?2004h> s = s.replace('\\nexcept TypeError:', '\\n            except TypeError:')\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(s)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('INDENT_FIXED')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nINDENT_FIXED\r\n"]
[370.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[370.002, "i", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[370.004, "o", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[370.006, "o", "\u001b[?2004l\r\n"]
[375.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[375.002, "i", "cd asv_bench\r"]
[375.004, "o", "cd asv_bench\r\n"]
[375.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[380.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[380.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[380.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[380.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpv22lrm2o/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n   [1/1] Generating write_version_file with a custom command\r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 47, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n       from pandas.core.arrays import Categorical\r\n     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n       from pandas.core.arrays.masked import BaseMaskedArray\r\n     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n       from pandas.core.util.hashing import hash_array\r\n     File \"/workspace/repo/pandas/core/util/hashing.py\", line 340\r\n       try:\r\n       ^\r\n   IndentationError: expected an indented block after 'else' statement on line 339\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpv22lrm2o/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[385.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[385.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[385.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[385.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpcuhnmzwq/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n   [1/1] Generating write_version_file with a custom command\r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 47, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n       from pandas.core.arrays import Categorical\r\n     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n       from pandas.core.arrays.masked import BaseMaskedArray\r\n     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n       from pandas.core.util.hashing import hash_array\r\n     File \"/workspace/repo/pandas/core/util/hashing.py\", line 340\r\n       try:\r\n       ^\r\n   IndentationError: expected an indented block after 'else' statement on line 339\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpcuhnmzwq/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[390.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[390.002, "i", "nl -ba ../pandas/core/util/hashing.py | sed -n '320,360p'\r"]
[390.004, "o", "nl -ba ../pandas/core/util/hashing.py | sed -n '320,360p'\r\n"]
[390.006, "o", "\u001b[?2004l\r\n   320\t            # Fast-path: avoid constructing a full Categorical object.\r\n   321\t            # Factorize once, hash unique categories, then gather via codes.\r\n   322\t            from pandas import factorize\r\n   323\t\r\n   324\t            codes, categories = factorize(vals, sort=False)\r\n   325\t            try:\r\n   326\t                cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\r\n   327\t            except TypeError:\r\n   328\t                cat_hashes = hash_object_array(\r\n   329\t                    np.asarray(categories, dtype=object).astype(str).astype(object),\r\n   330\t                    hash_key,\r\n   331\t                    encoding,\r\n   332\t                )\r\n   333\t            out = np.zeros(codes.size, dtype=np.uint64)\r\n   334\t            mask = codes != -1\r\n   335\t            if mask.any():\r\n   336\t                out[mask] = cat_hashes[codes[mask]]\r\n   337\t            vals = out\r\n   338\t\r\n   339\t        else:\r\n   340\t        try:\r\n   341\t            vals = hash_object_array(vals, hash_key, encoding)\r\n   342\t        except TypeError:\r\n   343\t            # we have mixed types\r\n   344\t            vals = hash_object_array(\r\n   345\t                vals.astype(str).astype(object), hash_key, encoding\r\n   346\t            )\r\n   347\t\r\n   348\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n   349\t    vals ^= vals >> 30\r\n   350\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n   351\t    vals ^= vals >> 27\r\n   352\t    vals *= np.uint64(0x94D049BB133111EB)\r\n   353\t    vals ^= vals >> 31\r\n   354\t    return vals\r\n"]
[395.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[395.002, "i", "python - << 'PY'\r"]
[395.004, "o", "python - << 'PY'\r\n"]
[395.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/util/hashing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> lines = p.read_text().splitlines(True)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Fix indentation: ensure 'try:' after an 'else:' line is indented inside the else block,\r\n\u001b[?2004l\r\n\u001b[?2004h> # and indent the matching 'except TypeError:' accordingly.\r\n\u001b[?2004l\r\n\u001b[?2004h> for i, line in enumerate(lines[:-1]):\r\n\u001b[?2004l\r\n\u001b[?2004h>     if line.lstrip() == 'else:\\n' and line.startswith('        '):\r\n\u001b[?2004l\r\n\u001b[?2004h>         # Find next non-empty/comment line\r\n\u001b[?2004l\r\n\u001b[?2004h>         j = i + 1\r\n\u001b[?2004l\r\n\u001b[?2004h>         while j < len(lines) and (lines[j].strip() == '' or lines[j].lstrip().startswith('#')):\r\n\u001b[?2004l\r\n\u001b[?2004h>             j += 1\r\n\u001b[?2004l\r\n\u001b[?2004h>         if j < len(lines) and lines[j].lstrip().startswith('try:'):\r\n\u001b[?2004l\r\n\u001b[?2004h>             # Indent try under else (12 spaces)\r\n\u001b[?2004l\r\n\u001b[?2004h>             lines[j] = '            ' + lines[j].lstrip()\r\n\u001b[?2004l\r\n\u001b[?2004h>             # Also indent the corresponding except TypeError in following lines\r\n\u001b[?2004l\r\n\u001b[?2004h>             k = j + 1\r\n\u001b[?2004l\r\n\u001b[?2004h>             while k < len(lines):\r\n\u001b[?2004l\r\n\u001b[?2004h>                 if lines[k].lstrip().startswith('except TypeError'):\r\n\u001b[?2004l\r\n\u001b[?2004h>                     lines[k] = '            ' + lines[k].lstrip()\r\n\u001b[?2004l\r\n\u001b[?2004h>                     break\r\n\u001b[?2004l\r\n\u001b[?2004h>                 # stop if we hit a new block at same or less indent as else\r\n\u001b[?2004l\r\n\u001b[?2004h>                 if lines[k].startswith('        ') and not lines[k].startswith('            '):\r\n\u001b[?2004l\r\n\u001b[?2004h>                     break\r\n\u001b[?2004l\r\n\u001b[?2004h>                 k += 1\r\n\u001b[?2004l\r\n\u001b[?2004h>             break\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(''.join(lines))\r\n\u001b[?2004l\r\n\u001b[?2004h> print('INDENTATION_FIX_APPLIED')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nINDENTATION_FIX_APPLIED\r\n"]
[400.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[400.002, "i", "nl -ba ../pandas/core/util/hashing.py | sed -n '332,350p'\r"]
[400.004, "o", "nl -ba ../pandas/core/util/hashing.py | sed -n '332,350p'\r\n"]
[400.006, "o", "\u001b[?2004l\r\n   332\t                )\r\n   333\t            out = np.zeros(codes.size, dtype=np.uint64)\r\n   334\t            mask = codes != -1\r\n   335\t            if mask.any():\r\n   336\t                out[mask] = cat_hashes[codes[mask]]\r\n   337\t            vals = out\r\n   338\t\r\n   339\t        else:\r\n   340\t            try:\r\n   341\t            vals = hash_object_array(vals, hash_key, encoding)\r\n   342\t            except TypeError:\r\n   343\t            # we have mixed types\r\n   344\t            vals = hash_object_array(\r\n   345\t                vals.astype(str).astype(object), hash_key, encoding\r\n   346\t            )\r\n   347\t\r\n   348\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n   349\t    vals ^= vals >> 30\r\n   350\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[405.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[405.002, "i", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[405.004, "o", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[405.006, "o", "\u001b[?2004l\r\n"]
[410.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[410.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[410.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[410.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpl__4kr0n/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n   [1/1] Generating write_version_file with a custom command\r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 47, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n       from pandas.core.arrays import Categorical\r\n     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n       from pandas.core.arrays.masked import BaseMaskedArray\r\n     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n       from pandas.core.util.hashing import hash_array\r\n     File \"/workspace/repo/pandas/core/util/hashing.py\", line 341\r\n       vals = hash_object_array(vals, hash_key, encoding)\r\n       ^\r\n   IndentationError: expected an indented block after 'try' statement on line 340\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpl__4kr0n/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[415.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[415.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[415.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[415.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp2_4qtiko/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n   [1/1] Generating write_version_file with a custom command\r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 47, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n       from pandas.core.arrays import Categorical\r\n     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n       from pandas.core.arrays.masked import BaseMaskedArray\r\n     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n       from pandas.core.util.hashing import hash_array\r\n     File \"/workspace/repo/pandas/core/util/hashing.py\", line 341\r\n       vals = hash_object_array(vals, hash_key, encoding)\r\n       ^\r\n   IndentationError: expected an indented block after 'try' statement on line 340\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp2_4qtiko/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[420.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[420.002, "i", "nl -ba ../pandas/core/util/hashing.py | sed -n '250,380p'\r"]
[420.004, "o", "nl -ba ../pandas/core/util/hashing.py | sed -n '250,380p'\r\n"]
[420.006, "o", "\u001b[?2004l\r\n   250\t    hash_key : str, default _default_hash_key\r\n   251\t        Hash_key for string key to encode.\r\n   252\t    categorize : bool, default True\r\n   253\t        Whether to first categorize object arrays before hashing. This is more\r\n   254\t        efficient when the array contains duplicate values.\r\n   255\t\r\n   256\t    Returns\r\n   257\t    -------\r\n   258\t    ndarray[np.uint64, ndim=1]\r\n   259\t        Hashed values, same length as the vals.\r\n   260\t\r\n   261\t    See Also\r\n   262\t    --------\r\n   263\t    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n   264\t    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n   265\t\r\n   266\t    Examples\r\n   267\t    --------\r\n   268\t    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n   269\t    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n   270\t      dtype=uint64)\r\n   271\t    \"\"\"\r\n   272\t    if not hasattr(vals, \"dtype\"):\r\n   273\t        raise TypeError(\"must pass a ndarray-like\")\r\n   274\t\r\n   275\t    if isinstance(vals, ABCExtensionArray):\r\n   276\t        return vals._hash_pandas_object(\r\n   277\t            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n   278\t        )\r\n   279\t\r\n   280\t    if not isinstance(vals, np.ndarray):\r\n   281\t        # GH#42003\r\n   282\t        raise TypeError(\r\n   283\t            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n   284\t            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n   285\t        )\r\n   286\t\r\n   287\t    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n   288\t\r\n   289\t\r\n   290\tdef _hash_ndarray(\r\n   291\t    vals: np.ndarray,\r\n   292\t    encoding: str = \"utf8\",\r\n   293\t    hash_key: str = _default_hash_key,\r\n   294\t    categorize: bool = True,\r\n   295\t) -> npt.NDArray[np.uint64]:\r\n   296\t    \"\"\"\r\n   297\t    See hash_array.__doc__.\r\n   298\t    \"\"\"\r\n   299\t    dtype = vals.dtype\r\n   300\t\r\n   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n   302\t    if np.issubdtype(dtype, np.complex128):\r\n   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n   305\t        return hash_real + 23 * hash_imag\r\n   306\t\r\n   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n   308\t    # manage it.\r\n   309\t    if dtype == bool:\r\n   310\t        vals = vals.astype(\"u8\")\r\n   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n   315\t    else:\r\n   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n   317\t        # then hash and rename categories. We allow skipping the categorization\r\n   318\t        # when the values are known/likely to be unique.\r\n   319\t        if categorize:\r\n   320\t            # Fast-path: avoid constructing a full Categorical object.\r\n   321\t            # Factorize once, hash unique categories, then gather via codes.\r\n   322\t            from pandas import factorize\r\n   323\t\r\n   324\t            codes, categories = factorize(vals, sort=False)\r\n   325\t            try:\r\n   326\t                cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\r\n   327\t            except TypeError:\r\n   328\t                cat_hashes = hash_object_array(\r\n   329\t                    np.asarray(categories, dtype=object).astype(str).astype(object),\r\n   330\t                    hash_key,\r\n   331\t                    encoding,\r\n   332\t                )\r\n   333\t            out = np.zeros(codes.size, dtype=np.uint64)\r\n   334\t            mask = codes != -1\r\n   335\t            if mask.any():\r\n   336\t                out[mask] = cat_hashes[codes[mask]]\r\n   337\t            vals = out\r\n   338\t\r\n   339\t        else:\r\n   340\t            try:\r\n   341\t            vals = hash_object_array(vals, hash_key, encoding)\r\n   342\t            except TypeError:\r\n   343\t            # we have mixed types\r\n   344\t            vals = hash_object_array(\r\n   345\t                vals.astype(str).astype(object), hash_key, encoding\r\n   346\t            )\r\n   347\t\r\n   348\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n   349\t    vals ^= vals >> 30\r\n   350\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n   351\t    vals ^= vals >> 27\r\n   352\t    vals *= np.uint64(0x94D049BB133111EB)\r\n   353\t    vals ^= vals >> 31\r\n   354\t    return vals\r\n"]
[425.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[425.002, "i", "python - << 'PY'\r"]
[425.004, "o", "python - << 'PY'\r\n"]
[425.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/util/hashing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # We will reconstruct the object-dtype branch cleanly.\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find the start of the object dtype comment line to anchor replacement.\r\n\u001b[?2004l\r\n\u001b[?2004h> anchor = s.find('# With repeated values, its MUCH faster to categorize object dtypes,')\r\n\u001b[?2004l\r\n\u001b[?2004h> if anchor == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('ANCHOR_NOT_FOUND')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Find beginning of that if/else block by locating preceding 'else:' from dtype checks\r\n\u001b[?2004l\r\n\u001b[?2004h>     pre = s.rfind('\\n', 0, anchor)\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Now find the end of the try/except/object handling before the mixing step\r\n\u001b[?2004l\r\n\u001b[?2004h>     mix_idx = s.find('\\n    # Then, redistribute these 64-bit ints within the space of 64-bit ints', anchor)\r\n\u001b[?2004l\r\n\u001b[?2004h>     if mix_idx == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('MIX_ANCHOR_NOT_FOUND')\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         head = s[:pre+1]\r\n\u001b[?2004l\r\n\u001b[?2004h>         tail = s[mix_idx:]\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_block = (\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        # With repeated values, its MUCH faster to categorize object dtypes,\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        # then hash and rename categories. We allow skipping the categorization\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        # when the values are known/likely to be unique.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        if categorize:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            from pandas import factorize\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            codes, categories = factorize(vals, sort=False)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            try:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            except TypeError:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                # Mixed categories that fail direct hashing: fall back to string conversion.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                cat_hashes = hash_object_array(\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    np.asarray(categories, dtype=object).astype(str).astype(object),\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    hash_key,\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    encoding,\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                )\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            out = np.zeros(codes.size, dtype=np.uint64)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            mask = codes != -1\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            if mask.any():\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                out[mask] = cat_hashes[codes[mask]]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            vals = out\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        else:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            try:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                vals = hash_object_array(vals, hash_key, encoding)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            except TypeError:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                # we have mixed types\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                vals = hash_object_array(\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    vals.astype(str).astype(object), hash_key, encoding\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                )\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>         )\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_s = head + new_block + tail\r\n\u001b[?2004l\r\n\u001b[?2004h>         p.write_text(new_s)\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('OBJECT_BRANCH_REWRITTEN')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nOBJECT_BRANCH_REWRITTEN\r\n"]
[430.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[430.002, "i", "nl -ba ../pandas/core/util/hashing.py | sed -n '250,380p'\r"]
[430.004, "o", "nl -ba ../pandas/core/util/hashing.py | sed -n '250,380p'\r\n"]
[430.006, "o", "\u001b[?2004l\r\n   250\t    hash_key : str, default _default_hash_key\r\n   251\t        Hash_key for string key to encode.\r\n   252\t    categorize : bool, default True\r\n   253\t        Whether to first categorize object arrays before hashing. This is more\r\n   254\t        efficient when the array contains duplicate values.\r\n   255\t\r\n   256\t    Returns\r\n   257\t    -------\r\n   258\t    ndarray[np.uint64, ndim=1]\r\n   259\t        Hashed values, same length as the vals.\r\n   260\t\r\n   261\t    See Also\r\n   262\t    --------\r\n   263\t    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n   264\t    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n   265\t\r\n   266\t    Examples\r\n   267\t    --------\r\n   268\t    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n   269\t    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n   270\t      dtype=uint64)\r\n   271\t    \"\"\"\r\n   272\t    if not hasattr(vals, \"dtype\"):\r\n   273\t        raise TypeError(\"must pass a ndarray-like\")\r\n   274\t\r\n   275\t    if isinstance(vals, ABCExtensionArray):\r\n   276\t        return vals._hash_pandas_object(\r\n   277\t            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n   278\t        )\r\n   279\t\r\n   280\t    if not isinstance(vals, np.ndarray):\r\n   281\t        # GH#42003\r\n   282\t        raise TypeError(\r\n   283\t            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n   284\t            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n   285\t        )\r\n   286\t\r\n   287\t    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n   288\t\r\n   289\t\r\n   290\tdef _hash_ndarray(\r\n   291\t    vals: np.ndarray,\r\n   292\t    encoding: str = \"utf8\",\r\n   293\t    hash_key: str = _default_hash_key,\r\n   294\t    categorize: bool = True,\r\n   295\t) -> npt.NDArray[np.uint64]:\r\n   296\t    \"\"\"\r\n   297\t    See hash_array.__doc__.\r\n   298\t    \"\"\"\r\n   299\t    dtype = vals.dtype\r\n   300\t\r\n   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n   302\t    if np.issubdtype(dtype, np.complex128):\r\n   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n   305\t        return hash_real + 23 * hash_imag\r\n   306\t\r\n   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n   308\t    # manage it.\r\n   309\t    if dtype == bool:\r\n   310\t        vals = vals.astype(\"u8\")\r\n   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n   315\t    else:\r\n   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n   317\t        # then hash and rename categories. We allow skipping the categorization\r\n   318\t        # when the values are known/likely to be unique.\r\n   319\t        if categorize:\r\n   320\t            from pandas import factorize\r\n   321\t\r\n   322\t            codes, categories = factorize(vals, sort=False)\r\n   323\t            try:\r\n   324\t                cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\r\n   325\t            except TypeError:\r\n   326\t                # Mixed categories that fail direct hashing: fall back to string conversion.\r\n   327\t                cat_hashes = hash_object_array(\r\n   328\t                    np.asarray(categories, dtype=object).astype(str).astype(object),\r\n   329\t                    hash_key,\r\n   330\t                    encoding,\r\n   331\t                )\r\n   332\t\r\n   333\t            out = np.zeros(codes.size, dtype=np.uint64)\r\n   334\t            mask = codes != -1\r\n   335\t            if mask.any():\r\n   336\t                out[mask] = cat_hashes[codes[mask]]\r\n   337\t            vals = out\r\n   338\t        else:\r\n   339\t            try:\r\n   340\t                vals = hash_object_array(vals, hash_key, encoding)\r\n   341\t            except TypeError:\r\n   342\t                # we have mixed types\r\n   343\t                vals = hash_object_array(\r\n   344\t                    vals.astype(str).astype(object), hash_key, encoding\r\n   345\t                )\r\n   346\t\r\n   347\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n   348\t    vals ^= vals >> 30\r\n   349\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n   350\t    vals ^= vals >> 27\r\n   351\t    vals *= np.uint64(0x94D049BB133111EB)\r\n   352\t    vals ^= vals >> 31\r\n   353\t    return vals\r\n"]
[435.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[435.002, "i", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[435.004, "o", "git diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[435.006, "o", "\u001b[?2004l\r\n"]
[440.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[440.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[440.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[440.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             13.4\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                4.02\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.17\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.16\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.26\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.5\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.14\u00b10ms\r\n"]
[445.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[445.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[445.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[445.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                  7.62\u00b10.03ms\r\n\r\nWed Oct  1 17:58:02 2025    /tmp/tmp3y8dvtum\r\n\r\n         574 function calls (563 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n        2    0.000    0.000    0.007    0.004 hashing.py:235(hash_array)\r\n        2    0.002    0.001    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n  167/165    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n       25    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n       25    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n    24/16    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        7    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        4    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        2    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n       18    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        2    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        2    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        2    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        1    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55dde887b640}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        1    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[450.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[450.002, "i", "sed -n '200,380p' ../pandas/core/util/hashing.py\r"]
[450.004, "o", "sed -n '200,380p' ../pandas/core/util/hashing.py\r\n"]
[450.006, "o", "\u001b[?2004l\r\n    -------\r\n    ndarray[np.uint64] of hashed values\r\n    \"\"\"\r\n    if not is_list_like(vals):\r\n        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n\r\n    from pandas import (\r\n        Categorical,\r\n        MultiIndex,\r\n    )\r\n\r\n    if not isinstance(vals, ABCMultiIndex):\r\n        mi = MultiIndex.from_tuples(vals)\r\n    else:\r\n        mi = vals\r\n\r\n    # create a list-of-Categoricals\r\n    cat_vals = [\r\n        Categorical._simple_new(\r\n            mi.codes[level],\r\n            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n        )\r\n        for level in range(mi.nlevels)\r\n    ]\r\n\r\n    # hash the list-of-ndarrays\r\n    hashes = (\r\n        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n        for cat in cat_vals\r\n    )\r\n    h = combine_hash_arrays(hashes, len(cat_vals))\r\n\r\n    return h\r\n\r\n\r\ndef hash_array(\r\n    vals: ArrayLike,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    Given a 1d array, return an array of deterministic integers.\r\n\r\n    Parameters\r\n    ----------\r\n    vals : ndarray or ExtensionArray\r\n        The input array to hash.\r\n    encoding : str, default 'utf8'\r\n        Encoding for data & key when strings.\r\n    hash_key : str, default _default_hash_key\r\n        Hash_key for string key to encode.\r\n    categorize : bool, default True\r\n        Whether to first categorize object arrays before hashing. This is more\r\n        efficient when the array contains duplicate values.\r\n\r\n    Returns\r\n    -------\r\n    ndarray[np.uint64, ndim=1]\r\n        Hashed values, same length as the vals.\r\n\r\n    See Also\r\n    --------\r\n    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n      dtype=uint64)\r\n    \"\"\"\r\n    if not hasattr(vals, \"dtype\"):\r\n        raise TypeError(\"must pass a ndarray-like\")\r\n\r\n    if isinstance(vals, ABCExtensionArray):\r\n        return vals._hash_pandas_object(\r\n            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n        )\r\n\r\n    if not isinstance(vals, np.ndarray):\r\n        # GH#42003\r\n        raise TypeError(\r\n            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n        )\r\n\r\n    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n\r\n\r\ndef _hash_ndarray(\r\n    vals: np.ndarray,\r\n    encoding: str = \"utf8\",\r\n    hash_key: str = _default_hash_key,\r\n    categorize: bool = True,\r\n) -> npt.NDArray[np.uint64]:\r\n    \"\"\"\r\n    See hash_array.__doc__.\r\n    \"\"\"\r\n    dtype = vals.dtype\r\n\r\n    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n    if np.issubdtype(dtype, np.complex128):\r\n        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n        return hash_real + 23 * hash_imag\r\n\r\n    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n    # manage it.\r\n    if dtype == bool:\r\n        vals = vals.astype(\"u8\")\r\n    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n    else:\r\n        # With repeated values, its MUCH faster to categorize object dtypes,\r\n        # then hash and rename categories. We allow skipping the categorization\r\n        # when the values are known/likely to be unique.\r\n        if categorize:\r\n            from pandas import factorize\r\n\r\n            codes, categories = factorize(vals, sort=False)\r\n            try:\r\n                cat_hashes = hash_object_array(np.asarray(categories, dtype=object), hash_key, encoding)\r\n            except TypeError:\r\n                # Mixed categories that fail direct hashing: fall back to string conversion.\r\n                cat_hashes = hash_object_array(\r\n                    np.asarray(categories, dtype=object).astype(str).astype(object),\r\n                    hash_key,\r\n                    encoding,\r\n                )\r\n\r\n            out = np.zeros(codes.size, dtype=np.uint64)\r\n            mask = codes != -1\r\n            if mask.any():\r\n                out[mask] = cat_hashes[codes[mask]]\r\n            vals = out\r\n        else:\r\n            try:\r\n                vals = hash_object_array(vals, hash_key, encoding)\r\n            except TypeError:\r\n                # we have mixed types\r\n                vals = hash_object_array(\r\n                    vals.astype(str).astype(object), hash_key, encoding\r\n                )\r\n\r\n    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n    vals ^= vals >> 30\r\n    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n    vals ^= vals >> 27\r\n    vals *= np.uint64(0x94D049BB133111EB)\r\n    vals ^= vals >> 31\r\n    return vals\r\n"]
[455.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[455.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[455.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[455.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             13.3\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                3.92\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.17\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.04\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.08\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     9.63\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.16\u00b10ms\r\n"]
[460.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[460.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[460.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[460.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                  7.43\u00b10.01ms\r\n\r\nWed Oct  1 18:00:02 2025    /tmp/tmpn14rcr0k\r\n\r\n         574 function calls (563 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n        2    0.000    0.000    0.007    0.004 hashing.py:235(hash_array)\r\n        2    0.002    0.001    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n  167/165    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n       25    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n       25    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n    24/16    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        2    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        7    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        4    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        1    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        2    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n       18    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        1    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        1    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55e1f74b9640}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        2    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[465.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[465.002, "i", "asv run --python=same --quick --bench=\"arithmetic.Ops2.*|reindex.DropDuplicates.*\"\r"]
[465.004, "o", "asv run --python=same --quick --bench=\"arithmetic.Ops2.*|reindex.DropDuplicates.*\"\r\n"]
[465.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 15 total benchmarks (1 commits * 1 environments * 15 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 3.33%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_dot\u001b[0m                                                                                                            46.2\u00b10ms\r\n[ 6.67%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_div\u001b[0m                                                                                                      28.9\u00b10ms\r\n[10.00%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_div_by_zero\u001b[0m                                                                                              1.16\u00b10ms\r\n[13.33%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_floor_by_zero\u001b[0m                                                                                            21.6\u00b10ms\r\n[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_mod\u001b[0m                                                                                                      24.9\u00b10ms\r\n[20.00%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_int_div_by_zero\u001b[0m                                                                                                1.85\u00b10ms\r\n[23.33%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_int_mod\u001b[0m                                                                                                        11.9\u00b10ms\r\n[26.67%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_series_dot\u001b[0m                                                                                                     1.24\u00b10ms\r\n[30.00%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_series_dot\u001b[0m                                                                                                            353\u00b10\u03bcs\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups\u001b[0m                                                                                                     ok\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    8.95\u00b10ms \r\n               False    8.73\u00b10ms \r\n             ========= ==========\r\n\r\n[36.67%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_bool\u001b[0m                                                                                                ok\r\n[36.67%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    2.54\u00b10ms \r\n               False    2.53\u00b10ms \r\n             ========= ==========\r\n\r\n[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_int\u001b[0m                                                                                                 ok\r\n[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    12.3\u00b10ms \r\n               False    12.2\u00b10ms \r\n             ========= ==========\r\n\r\n[43.33%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_na\u001b[0m                                                                                                  ok\r\n[43.33%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    11.9\u00b10ms \r\n               False    12.6\u00b10ms \r\n             ========= ==========\r\n\r\n[46.67%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_series_drop_dups_int\u001b[0m                                                                                                ok\r\n[46.67%] \u00b7\u00b7\u00b7 \u001b[0;39m========= =========\u001b[0m\r\n              inplace           \r\n             --------- ---------\r\n                True    513\u00b10\u03bcs \r\n               False    542\u00b10\u03bcs \r\n             ========= =========\r\n\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_series_drop_dups_string\u001b[0m                                                                                             ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========= =========\u001b[0m\r\n              inplace           \r\n             --------- ---------\r\n                True    582\u00b10\u03bcs \r\n               False    565\u00b10\u03bcs \r\n             ========= =========\r\n\r\n"]
[470.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[470.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[470.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[470.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             13.3\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                3.90\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.09\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.04\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.11\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     9.65\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.13\u00b10ms\r\n"]
[475.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[475.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[475.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[475.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                  7.58\u00b10.04ms\r\n\r\nWed Oct  1 18:02:26 2025    /tmp/tmp_qq272l4\r\n\r\n         574 function calls (563 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n        2    0.000    0.000    0.007    0.004 hashing.py:235(hash_array)\r\n        2    0.002    0.001    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n  167/165    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n       25    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n       25    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n    24/16    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        7    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        4    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        1    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        2    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n       18    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        2    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55db78936640}\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        1    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        2    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n\r\n\r\n"]
[480.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[480.002, "i", "git add ../pandas/core/util/hashing.py && git commit -m \"opt(hash_pandas_object): fast-path object hashin\r"]
[480.004, "o", "git add ../pandas/core/util/hashing.py && git commit -m \"opt(hash_pandas_object): fast-path object hashin\r\n"]
[480.006, "o", "ng with categorize=True by factorize+map to avoid Categorical construction; reduces overhead in algorithms.Hashing benchmarks\"\r\n\u001b[?2004l\r\nAuthor identity unknown\r\n\r\n*** Please tell me who you are.\r\n\r\nRun\r\n\r\n  git config --global user.email \"you@example.com\"\r\n  git config --global user.name \"Your Name\"\r\n\r\nto set your account's default identity.\r\nOmit --global to set the identity only in this repository.\r\n\r\nfatal: unable to auto-detect email address (got 'root@9fa129b0bc16.(none)')\r\n"]
[485.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[485.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[485.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[485.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             14.7\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                4.01\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.25\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.16\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.24\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.3\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.31\u00b10ms\r\n"]
[490.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[490.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[490.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[490.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                  7.65\u00b10.07ms\r\n\r\nWed Oct  1 18:04:24 2025    /tmp/tmp3eowmq3b\r\n\r\n         574 function calls (563 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n        2    0.000    0.000    0.007    0.004 hashing.py:235(hash_array)\r\n        2    0.002    0.001    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n  167/165    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n       25    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n       25    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n    24/16    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        7    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        4    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        1    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        2    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n       18    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        1    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        2    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        2    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        1    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55fda676f640}\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        1    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        2    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[495.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[495.002, "i", "cd ..\r"]
[495.004, "o", "cd ..\r\n"]
[495.006, "o", "\u001b[?2004l\r\n"]
[500.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[500.002, "i", "git config --local user.email \"devnull@example.com\"\r"]
[500.004, "o", "git config --local user.email \"devnull@example.com\"\r\n"]
[500.006, "o", "\u001b[?2004l\r\n"]
[505.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[505.002, "i", "git config --local user.name \"ASV Optimizer\"\r"]
[505.004, "o", "git config --local user.name \"ASV Optimizer\"\r\n"]
[505.006, "o", "\u001b[?2004l\r\n"]
[510.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[510.002, "i", "git add pandas/core/util/hashing.py\r"]
[510.004, "o", "git add pandas/core/util/hashing.py\r\n"]
[510.006, "o", "\u001b[?2004l\r\n"]
[515.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[515.002, "i", "git commit -m \"opt(hash_pandas_object): fast-path object hashing with categorize=True via factorize+map to avoid Ca\r"]
[515.004, "o", "git commit -m \"opt(hash_pandas_object): fast-path object hashing with categorize=True via factorize+map to avoid Ca\r\n"]
[515.006, "o", "ategorical construction; improves algorithms.Hashing.* benchmarks\"\r\n\u001b[?2004l\r\n[main f4459cfd4e] opt(hash_pandas_object): fast-path object hashing with categorize=True via factorize+map to avoid Categorical construction; improves algorithms.Hashing.* benchmarks\r\n 1 file changed, 24 insertions(+), 18 deletions(-)\r\n"]
[520.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo# "]
[520.002, "i", "cd asv_bench\r"]
[520.004, "o", "cd asv_bench\r\n"]
[520.006, "o", "\u001b[?2004l\r\n"]
[525.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[525.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[525.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[525.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             14.0\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                3.98\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.24\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.33\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.67\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     9.88\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.18\u00b10ms\r\n"]
[530.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[530.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[530.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[530.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   8.36\u00b10.1ms\r\n\r\nWed Oct  1 18:06:37 2025    /tmp/tmp_ln06k77\r\n\r\n         574 function calls (563 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n        2    0.000    0.000    0.008    0.004 hashing.py:235(hash_array)\r\n        2    0.002    0.001    0.008    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n  167/165    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n       25    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n       25    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n    24/16    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        4    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        7    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n       18    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        2    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        1    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        2    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55c208684640}\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[535.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[535.002, "i", "cd asv_bench\r"]
[535.004, "o", "cd asv_bench\r\n"]
[535.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[540.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[540.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[540.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[540.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             14.8\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                4.01\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.30\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.17\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.24\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     9.92\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.36\u00b10ms\r\n"]
[545.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[545.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[545.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[545.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   7.87\u00b10.2ms\r\n\r\nWed Oct  1 18:08:26 2025    /tmp/tmpm7k57k9h\r\n\r\n         574 function calls (563 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n        2    0.000    0.000    0.007    0.004 hashing.py:235(hash_array)\r\n        2    0.002    0.001    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n  167/165    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n       25    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n       25    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n    24/16    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        4    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        7    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n       18    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        1    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        2    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        2    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        2    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x5585785fd640}\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[550.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[550.002, "i", "asv run --python=same --quick --bench=\"arithmetic.Ops2.*|reindex.DropDuplicates.*\"\r"]
[550.004, "o", "asv run --python=same --quick --bench=\"arithmetic.Ops2.*|reindex.DropDuplicates.*\"\r\n"]
[550.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 15 total benchmarks (1 commits * 1 environments * 15 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 3.33%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_dot\u001b[0m                                                                                                            47.2\u00b10ms\r\n[ 6.67%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_div\u001b[0m                                                                                                      29.3\u00b10ms\r\n[10.00%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_div_by_zero\u001b[0m                                                                                              1.34\u00b10ms\r\n[13.33%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_floor_by_zero\u001b[0m                                                                                            21.4\u00b10ms\r\n[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_mod\u001b[0m                                                                                                      25.0\u00b10ms\r\n[20.00%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_int_div_by_zero\u001b[0m                                                                                                1.89\u00b10ms\r\n[23.33%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_int_mod\u001b[0m                                                                                                        12.1\u00b10ms\r\n[26.67%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_series_dot\u001b[0m                                                                                                     1.24\u00b10ms\r\n[30.00%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_series_dot\u001b[0m                                                                                                            417\u00b10\u03bcs\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups\u001b[0m                                                                                                     ok\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    9.53\u00b10ms \r\n               False    9.22\u00b10ms \r\n             ========= ==========\r\n\r\n[36.67%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_bool\u001b[0m                                                                                                ok\r\n[36.67%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    2.68\u00b10ms \r\n               False    2.55\u00b10ms \r\n             ========= ==========\r\n\r\n[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_int\u001b[0m                                                                                                 ok\r\n[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    12.3\u00b10ms \r\n               False    13.3\u00b10ms \r\n             ========= ==========\r\n\r\n[43.33%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_na\u001b[0m                                                                                                  ok\r\n[43.33%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    12.9\u00b10ms \r\n               False    12.6\u00b10ms \r\n             ========= ==========\r\n\r\n[46.67%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_series_drop_dups_int\u001b[0m                                                                                                ok\r\n[46.67%] \u00b7\u00b7\u00b7 \u001b[0;39m========= =========\u001b[0m\r\n              inplace           \r\n             --------- ---------\r\n                True    674\u00b10\u03bcs \r\n               False    547\u00b10\u03bcs \r\n             ========= =========\r\n\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_series_drop_dups_string\u001b[0m                                                                                             ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========= =========\u001b[0m\r\n              inplace           \r\n             --------- ---------\r\n                True    607\u00b10\u03bcs \r\n               False    594\u00b10\u03bcs \r\n             ========= =========\r\n\r\n"]
[555.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[555.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[555.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[555.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             13.9\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                3.92\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.20\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.29\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.26\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.2\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.19\u00b10ms\r\n"]
[560.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[560.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[560.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[560.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   7.85\u00b10.2ms\r\n\r\nWed Oct  1 18:10:41 2025    /tmp/tmpshlejphl\r\n\r\n         574 function calls (563 primitive calls) in 0.008 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n        2    0.000    0.000    0.007    0.004 hashing.py:235(hash_array)\r\n        2    0.002    0.001    0.007    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        2    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n  167/165    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n       25    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n       25    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        4    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n    24/16    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        7    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        1    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n       18    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        2    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        2    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        1    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55e1d4fc6640}\r\n        2    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[565.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[565.002, "i", "pwd\r"]
[565.004, "o", "pwd\r\n"]
[565.006, "o", "\u001b[?2004l\r\n/workspace/repo/asv_bench\r\n"]
[570.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[570.002, "i", "cd asv_bench\r"]
[570.004, "o", "cd asv_bench\r\n"]
[570.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[575.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[575.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[575.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[575.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             13.8\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                3.87\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.27\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.19\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.08\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     9.72\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.22\u00b10ms\r\n"]
[580.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[580.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[580.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[580.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   8.53\u00b10.3ms\r\n\r\nWed Oct  1 18:12:28 2025    /tmp/tmp0u1yo4ti\r\n\r\n         574 function calls (563 primitive calls) in 0.009 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.009    0.009 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.009    0.009 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.009    0.009 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.009    0.009 hashing.py:84(hash_pandas_object)\r\n        2    0.000    0.000    0.008    0.004 hashing.py:235(hash_array)\r\n        2    0.002    0.001    0.008    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n  167/165    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        2    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n       25    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n       25    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n    24/16    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n       18    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        7    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        1    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        2    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        2    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x56317008a640}\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        2    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[585.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[585.002, "i", "asv run --python=same --quick --bench=\"arithmetic.Ops2.*|reindex.DropDuplicates.*\"\r"]
[585.004, "o", "asv run --python=same --quick --bench=\"arithmetic.Ops2.*|reindex.DropDuplicates.*\"\r\n"]
[585.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 15 total benchmarks (1 commits * 1 environments * 15 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 3.33%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_dot\u001b[0m                                                                                                            50.2\u00b10ms\r\n[ 6.67%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_div\u001b[0m                                                                                                      30.1\u00b10ms\r\n[10.00%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_div_by_zero\u001b[0m                                                                                              1.30\u00b10ms\r\n[13.33%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_floor_by_zero\u001b[0m                                                                                            23.3\u00b10ms\r\n[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_float_mod\u001b[0m                                                                                                      26.1\u00b10ms\r\n[20.00%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_int_div_by_zero\u001b[0m                                                                                                2.22\u00b10ms\r\n[23.33%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_int_mod\u001b[0m                                                                                                        12.5\u00b10ms\r\n[26.67%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_frame_series_dot\u001b[0m                                                                                                     1.23\u00b10ms\r\n[30.00%] \u00b7\u00b7\u00b7 \u001b[0;39marithmetic.Ops2.time_series_dot\u001b[0m                                                                                                            366\u00b10\u03bcs\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups\u001b[0m                                                                                                     ok\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    10.6\u00b10ms \r\n               False    9.96\u00b10ms \r\n             ========= ==========\r\n\r\n[36.67%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_bool\u001b[0m                                                                                                ok\r\n[36.67%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    2.74\u00b10ms \r\n               False    2.79\u00b10ms \r\n             ========= ==========\r\n\r\n[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_int\u001b[0m                                                                                                 ok\r\n[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    12.6\u00b10ms \r\n               False    12.9\u00b10ms \r\n             ========= ==========\r\n\r\n[43.33%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_frame_drop_dups_na\u001b[0m                                                                                                  ok\r\n[43.33%] \u00b7\u00b7\u00b7 \u001b[0;39m========= ==========\u001b[0m\r\n              inplace            \r\n             --------- ----------\r\n                True    13.0\u00b10ms \r\n               False    13.3\u00b10ms \r\n             ========= ==========\r\n\r\n[46.67%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_series_drop_dups_int\u001b[0m                                                                                                ok\r\n[46.67%] \u00b7\u00b7\u00b7 \u001b[0;39m========= =========\u001b[0m\r\n              inplace           \r\n             --------- ---------\r\n                True    668\u00b10\u03bcs \r\n               False    591\u00b10\u03bcs \r\n             ========= =========\r\n\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.DropDuplicates.time_series_drop_dups_string\u001b[0m                                                                                             ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========= =========\u001b[0m\r\n              inplace           \r\n             --------- ---------\r\n                True    706\u00b10\u03bcs \r\n               False    676\u00b10\u03bcs \r\n             ========= =========\r\n\r\n"]
[590.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[590.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[590.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[590.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             15.1\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                4.36\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.63\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.28\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.14\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.1\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.32\u00b10ms\r\n"]
[595.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[595.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[595.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[595.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   8.25\u00b10.1ms\r\n\r\nWed Oct  1 18:14:51 2025    /tmp/tmpusda3v68\r\n\r\n         574 function calls (563 primitive calls) in 0.009 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.009    0.009 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.009    0.009 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.009    0.009 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.009    0.009 hashing.py:84(hash_pandas_object)\r\n        2    0.000    0.000    0.008    0.004 hashing.py:235(hash_array)\r\n        2    0.002    0.001    0.008    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.006    0.006 algorithms.py:639(factorize)\r\n        1    0.006    0.006    0.006    0.006 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        2    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n  167/165    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n       25    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n       25    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        2    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n    24/16    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        7    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        4    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n       18    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        2    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        2    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55b7f7f9e640}\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        2    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[600.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[600.002, "i", "cd asv_bench\r"]
[600.004, "o", "cd asv_bench\r\n"]
[600.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[605.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[605.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[605.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[605.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             14.6\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                4.11\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.32\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.29\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.27\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.1\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.36\u00b10ms\r\n"]
[610.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[610.002, "i", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r"]
[610.004, "o", "asv profile --python=same --config=asv.conf.json algorithms.Hashing.time_series_string\r\n"]
[610.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   8.57\u00b10.7ms\r\n\r\nWed Oct  1 18:16:52 2025    /tmp/tmpa_lylr8j\r\n\r\n         574 function calls (563 primitive calls) in 0.010 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.010    0.010 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.010    0.010 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.010    0.010 algorithms.py:160(time_series_string)\r\n      2/1    0.000    0.000    0.010    0.010 hashing.py:84(hash_pandas_object)\r\n        2    0.000    0.000    0.009    0.004 hashing.py:235(hash_array)\r\n        2    0.002    0.001    0.009    0.004 hashing.py:290(_hash_ndarray)\r\n        1    0.000    0.000    0.006    0.006 algorithms.py:639(factorize)\r\n        1    0.006    0.006    0.006    0.006 algorithms.py:577(factorize_array)\r\n        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n        2    0.000    0.000    0.001    0.000 series.py:366(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n        2    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n  167/165    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n       25    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n       25    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2228(new_block)\r\n        2    0.000    0.000    0.000    0.000 series.py:734(name)\r\n    24/16    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n        2    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        2    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n        4    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2157(maybe_coerce_values)\r\n        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n        7    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n       18    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n        2    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        4    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:2186(get_block_type)\r\n        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n       30    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2750(check_dict_or_set_indexers)\r\n        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n        1    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n       12    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        2    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n        2    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        2    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n        2    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x56153f9b7640}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[615.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[615.002, "i", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r"]
[615.004, "o", "asv run --python=same --quick --bench=\"algorithms.Hashing.*\"\r\n"]
[615.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             14.5\u00b10ms\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                4.13\u00b10ms\r\n[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.57\u00b10ms\r\n[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.31\u00b10ms\r\n[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.26\u00b10ms\r\n[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.1\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.55\u00b10ms\r\n"]
[620.0, "o", "(asv_3.10) root@9fa129b0bc16:/workspace/repo/asv_bench# "]
[620.002, "i", "\u001b[?2004l\r"]
[620.004, "o", "\u001b[?2004l\r\n"]
[620.006, "o", "\r\nlogout\r\n"]
