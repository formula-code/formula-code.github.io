{"version": 2, "width": 160, "height": 40, "timestamp": 1762942267, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[0.006, "o", "\u001b[?2004l\r\n\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n\u001b[0;31masciinema: use --append option if you want to append to existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[5.006, "o", "\u001b[?2004l\r\n\u001b[H\u001b[J\r\n"]
[10.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.006, "o", "\u001b[?2004l\r\ntotal 216\r\ndrwxr-xr-x 1 root root  4096 Oct  1 17:04 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 15 17:17 \u001b[01;34m..\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 13 21:47 \u001b[01;34m.circleci\u001b[0m\r\n-rw-r--r-- 1 root root  1021 Sep 13 21:47 .devcontainer.json\r\ndrwxr-xr-x 1 root root  4096 Oct  1 16:57 \u001b[01;34m.git\u001b[0m\r\n-rw-r--r-- 1 root root  1670 Sep 13 21:47 .gitattributes\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34m.github\u001b[0m\r\n-rw-r--r-- 1 root root  1919 Sep 13 21:47 .gitignore\r\n-rw-r--r-- 1 root root  2296 Sep 13 21:47 .gitpod.yml\r\n-rw-r--r-- 1 root root 10674 Sep 13 21:47 .pre-commit-config.yaml\r\n-rw-r--r-- 1 root root  2284 Sep 13 21:47 AUTHORS.md\r\n-rw-r--r-- 1 root root  1541 Sep 13 21:47 CITATION.cff\r\n-rw-r--r-- 1 root root   455 Sep 13 21:47 Dockerfile\r\n-rw-r--r-- 1 root root  1634 Sep 13 21:47 LICENSE\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mLICENSES\u001b[0m\r\n-rw-r--r-- 1 root root  1335 Sep 13 21:47 MANIFEST.in\r\n-rw-r--r-- 1 root root 11670 Sep 13 21:47 README.md\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34masv_bench\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:48 \u001b[01;34mbuild\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mci\u001b[0m\r\n-rw-r--r-- 1 root root   256 Sep 13 21:47 codecov.yml\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mdoc\u001b[0m\r\n-rw-r--r-- 1 root root  2612 Sep 13 21:47 environment.yml\r\n-rw-r--r-- 1 root root   866 Sep 13 21:47 generate_pxi.py\r\n-rw-r--r-- 1 root root  1715 Sep 13 21:47 generate_version.py\r\ndrwxr-xr-x 2 root root  4096 Sep 13 21:47 \u001b[01;34mgitpod\u001b[0m\r\n-rw-r--r-- 1 root root  1646 Sep 13 21:47 meson.build\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mpandas\u001b[0m\r\n-rw-r--r-- 1 root root 21652 Sep 13 21:47 pyproject.toml\r\n-rw-r--r-- 1 root root  4307 Sep 13 21:47 pyright_reportGeneralTypeIssues.json\r\n-rw-r--r-- 1 root root  1398 Sep 13 21:47 requirements-dev.txt\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mscripts\u001b[0m\r\n-rwxr-xr-x 1 root root 21960 Sep 13 21:47 \u001b[01;32msetup.py\u001b[0m\r\ndrwxr-xr-x 3 root root  4096 Sep 13 21:47 \u001b[01;34mtooling\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 13 21:47 \u001b[01;34mtypings\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mweb\u001b[0m\r\n"]
[15.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[15.002, "i", "ls -la asv.conf.json asv.conf.* 2>/dev/null || true\r"]
[15.004, "o", "ls -la asv.conf.json asv.conf.* 2>/dev/null || true\r\n"]
[15.006, "o", "\u001b[?2004l\r\n"]
[20.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[20.002, "i", "git status -sb\r"]
[20.004, "o", "git status -sb\r\n"]
[20.006, "o", "\u001b[?2004l\r\n## \u001b[32mmain\u001b[m\r\n"]
[25.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[25.002, "i", "grep -R \"class .*DataFrameStringIndexing\" -n . || true\r"]
[25.004, "o", "grep -R \"class .*DataFrameStringIndexing\" -n . || true\r\n"]
[25.006, "o", "\u001b[?2004l\r\n\u001b[35m\u001b[K./asv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K154\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass DataFrameStringIndexing\u001b[m\u001b[K:\r\n"]
[30.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[30.002, "i", "grep -R \"indexing\\.DataFrameStringIndexing\" -n . || true\r"]
[30.004, "o", "grep -R \"indexing\\.DataFrameStringIndexing\" -n . || true\r\n"]
[30.006, "o", "\u001b[?2004l\r\n"]
[35.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[35.002, "i", "fd -H \"asv\" . 2>/dev/null || (apt-get update && apt-get install -y fd-find && ln -s $(command -v fdfind) /usr/local\r"]
[35.004, "o", "fd -H \"asv\" . 2>/dev/null || (apt-get update && apt-get install -y fd-find && ln -s $(command -v fdfind) /usr/local\r\n"]
[35.006, "o", "l/bin/fd && fd -H \"asv\" .)\r\n\u001b[?2004l\r\n\r\n0% [Working]\r\n            \r\nHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\r\n\r\n0% [Waiting for headers]\r\n                        \r\nHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\r\n\r\n0% [Waiting for headers]\r\n                        \r\nHit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\r\n\r\n                        \r\n0% [Working]\r\n            \r\nHit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\r\n\r\n0% [Working]\r\n0% [Working]\r\n0% [Working]\r\n0% [Working]\r\n20% [Working]\r\n             \r\n\r\nReading package lists... 0%\r\n\r\nReading package lists... 0%\r\n\r\nReading package lists... 0%\r\n\r\nReading package lists... 3%\r\n\r\nReading package lists... 3%\r\n\r\nReading package lists... 4%\r\n\r\nReading package lists... 4%\r\n\r\nReading package lists... 41%\r\n\r\nReading package lists... 41%\r\n\r\nReading package lists... 41%\r\n\r\nReading package lists... 41%\r\n\r\nReading package lists... 51%\r\n\r\nReading package lists... 51%\r\n\r\nReading package lists... 57%\r\n\r\nReading package lists... 67%\r\n\r\nReading package lists... 67%\r\n\r\nReading package lists... 71%\r\n\r\nReading package lists... 71%\r\n\r\nReading package lists... 71%\r\n\r\nReading package lists... 71%\r\n\r\nReading package lists... 72%\r\n\r\nReading package lists... 72%\r\n\r\nReading package lists... 72%\r\n\r\nReading package lists... 72%\r\n\r\nReading package lists... 80%\r\n\r\nReading package lists... 80%\r\n\r\nReading package lists... 96%\r\n\r\nReading package lists... 96%\r\n\r\nReading package lists... 99%\r\n\r\nReading package lists... 99%\r\n\r\nReading package lists... 99%\r\n\r\nReading package lists... 99%\r\n\r\nReading package lists... Done\r\n\r\n\r\nReading package lists... 0%\r\n\r\nReading package lists... 0%\r\n\r\nReading package lists... 0%\r\n\r\nReading package lists... 3%\r\n\r\nReading package lists... 3%\r\n\r\nReading package lists... 4%\r\n\r\nReading package lists... 4%\r\n\r\nReading package lists... 41%\r\n\r\nReading package lists... 41%\r\n\r\nReading package lists... 41%\r\n\r\nReading package lists... 41%\r\n\r\nReading package lists... 51%\r\n\r\nReading package lists... 51%\r\n\r\nReading package lists... 55%\r\n\r\nReading package lists... 67%\r\n\r\nReading package lists... 67%\r\n\r\nReading package lists... 71%\r\n\r\nReading package lists... 71%\r\n\r\nReading package lists... 71%\r\n\r\nReading package lists... 71%\r\n\r\nReading package lists... 72%\r\n\r\nReading package lists... 72%\r\n\r\nReading package lists... 72%\r\n\r\nReading package lists... 72%\r\n\r\nReading package lists... 80%\r\n\r\nReading package lists... 80%\r\n\r\nReading package lists... 96%\r\n\r\nReading package lists... 96%\r\n\r\nReading package lists... 99%\r\n\r\nReading package lists... 99%\r\n\r\nReading package lists... 99%\r\n\r\nReading package lists... 99%\r\n\r\nReading package lists... Done\r\n\r\n\r\nBuilding dependency tree... 0%\r\n\r\nBuilding dependency tree... 0%\r\n\r\nBuilding dependency tree... 50%\r\n\r\nBuilding dependency tree... 50%\r\n\r\nBuilding dependency tree... Done\r\n\r\n\r\nReading state information... 0% \r\n\r\nReading state information... 0%\r\n\r\nReading state information... Done\r\n\r\nThe following NEW packages will be installed:\r\n  fd-find\r\n0 upgraded, 1 newly installed, 0 to remove and 26 not upgraded.\r\nNeed to get 832 kB of archives.\r\nAfter this operation, 2570 kB of additional disk space will be used.\r\n\r\n0% [Working]\r\n            \r\nGet:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 fd-find amd64 8.3.1-1ubuntu0.1 [832 kB]\r\n\r\n1% [1 fd-find 14.2 kB/832 kB 2%]\r\n                                \r\n100% [Working]\r\n              \r\nFetched 832 kB in 1s (1325 kB/s)\r\ndebconf: delaying package configuration, since apt-utils is not installed\r\nSelecting previously unselected package fd-find.\r\n(Reading database ... \r\n(Reading database ... 5%\r\n(Reading database ... 10%\r\n(Reading database ... 15%\r\n(Reading database ... 20%\r\n(Reading database ... 25%\r\n(Reading database ... 30%\r\n(Reading database ... 35%\r\n(Reading database ... 40%\r\n(Reading database ... 45%\r\n(Reading database ... 50%\r\n(Reading database ... 55%\r\n(Reading database ... 60%\r\n(Reading database ... 65%\r\n(Reading database ... 70%\r\n(Reading database ... 75%\r\n(Reading database ... 80%\r\n(Reading database ... 85%\r\n(Reading database ... 90%\r\n(Reading database ... 95%\r\n(Reading database ... 100%\r\n(Reading database ... 25084 files and directories currently installed.)\r\nPreparing to unpack .../fd-find_8.3.1-1ubuntu0.1_amd64.deb ...\r\nUnpacking fd-find (8.3.1-1ubuntu0.1) ...\r\nSetting up fd-find (8.3.1-1ubuntu0.1) ...\r\n\u001b[1;34m./\u001b[0m\u001b[1;34masv_bench\u001b[0m\r\n\u001b[1;34m./asv_bench/\u001b[0masv.conf.json\r\n\u001b[1;34m./web/pandas/community/blog/\u001b[0masv-pandas-grant.md\r\n"]
[40.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[40.002, "i", "find . -maxdepth 3 -type d -iname \"bench*\" -o -iname \"asv*\"\r"]
[40.004, "o", "find . -maxdepth 3 -type d -iname \"bench*\" -o -iname \"asv*\"\r\n"]
[40.006, "o", "\u001b[?2004l\r\n./asv_bench\r\n./asv_bench/benchmarks\r\n./asv_bench/asv.conf.json\r\n"]
[45.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[45.002, "i", "git grep -n \"asv\" -- :/ || true\r"]
[45.004, "o", "git grep -n \"asv\" -- :/ || true\r\n"]
[45.006, "o", "\u001b[?2004l\r\nerror: cannot run less: No such file or directory\r\nfatal: unable to execute pager 'less'\r\n"]
[50.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[50.002, "i", "ls -la benchmarks bench asv_bench asv_benchmarks 2>/dev/null || true\r"]
[50.004, "o", "ls -la benchmarks bench asv_bench asv_benchmarks 2>/dev/null || true\r\n"]
[50.006, "o", "\u001b[?2004l\r\nasv_bench:\r\ntotal 24\r\ndrwxr-xr-x 1 root root 4096 Sep 13 21:47 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root 4096 Oct  1 17:04 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root 5194 Sep 13 21:47 asv.conf.json\r\ndrwxr-xr-x 1 root root 4096 Sep 13 21:47 \u001b[01;34mbenchmarks\u001b[0m\r\n"]
[55.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[55.002, "i", "grep -R \"class .*Indexing\" -n benchmarks asv_bench asv_benchmarks 2>/dev/null || true\r"]
[55.004, "o", "grep -R \"class .*Indexing\" -n benchmarks asv_bench asv_benchmarks 2>/dev/null || true\r\n"]
[55.006, "o", "\u001b[?2004l\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/categoricals.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K291\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass Indexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/timedelta.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K35\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass TimedeltaIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/index_object.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K154\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass Indexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/period.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K85\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass Indexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing_engines.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K58\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass NumericEngineIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing_engines.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K105\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass MaskedNumericEngineIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing_engines.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K158\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass ObjectEngineIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/hash_functions.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K57\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass NumericSeriesIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/hash_functions.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K74\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass NumericSeriesIndexing\u001b[m\u001b[KShuffled:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K27\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass NumericSeriesIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K86\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass NumericMaskedIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K114\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass NonNumericSeriesIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K154\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass DataFrameStringIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K188\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass DataFrameNumericIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K242\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass MultiIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K323\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass IntervalIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K342\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass DatetimeIndexIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K374\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass CategoricalIndexIndexing\u001b[m\u001b[K:\r\n\u001b[35m\u001b[Kasv_bench/benchmarks/indexing.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K531\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass ChainIndexing\u001b[m\u001b[K:\r\n"]
[60.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[60.002, "i", "sed -n '1,200p' asv.conf.json 2>/dev/null || true\r"]
[60.004, "o", "sed -n '1,200p' asv.conf.json 2>/dev/null || true\r\n"]
[60.006, "o", "\u001b[?2004l\r\n"]
[65.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[65.002, "i", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[65.004, "o", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[65.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mNo `asv.conf` file found for valid extensions: ['.json', '.jsonc'].\u001b[0m\r\n"]
[70.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[70.002, "i", "sed -n '1,260p' asv_bench/benchmarks/indexing.py\r"]
[70.004, "o", "sed -n '1,260p' asv_bench/benchmarks/indexing.py\r\n"]
[70.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nThese benchmarks are for Series and DataFrame indexing methods.  For the\r\nlower-level methods directly on Index and subclasses, see index_object.py,\r\nindexing_engine.py, and index_cached.py\r\n\"\"\"\r\n\r\nfrom datetime import datetime\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas import (\r\n    NA,\r\n    CategoricalIndex,\r\n    DataFrame,\r\n    Index,\r\n    IntervalIndex,\r\n    MultiIndex,\r\n    Series,\r\n    concat,\r\n    date_range,\r\n    option_context,\r\n    period_range,\r\n)\r\n\r\n\r\nclass NumericSeriesIndexing:\r\n    params = [\r\n        (np.int64, np.uint64, np.float64),\r\n        (\"unique_monotonic_inc\", \"nonunique_monotonic_inc\"),\r\n    ]\r\n    param_names = [\"dtype\", \"index_structure\"]\r\n\r\n    def setup(self, dtype, index_structure):\r\n        N = 10**6\r\n        indices = {\r\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\r\n            \"nonunique_monotonic_inc\": Index(\r\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\r\n            ),\r\n        }\r\n        self.data = Series(np.random.rand(N), index=indices[index_structure])\r\n        self.array = np.arange(10000)\r\n        self.array_list = self.array.tolist()\r\n\r\n    def time_getitem_scalar(self, index, index_structure):\r\n        self.data[800000]\r\n\r\n    def time_getitem_slice(self, index, index_structure):\r\n        self.data[:800000]\r\n\r\n    def time_getitem_list_like(self, index, index_structure):\r\n        self.data[[800000]]\r\n\r\n    def time_getitem_array(self, index, index_structure):\r\n        self.data[self.array]\r\n\r\n    def time_getitem_lists(self, index, index_structure):\r\n        self.data[self.array_list]\r\n\r\n    def time_iloc_array(self, index, index_structure):\r\n        self.data.iloc[self.array]\r\n\r\n    def time_iloc_list_like(self, index, index_structure):\r\n        self.data.iloc[[800000]]\r\n\r\n    def time_iloc_scalar(self, index, index_structure):\r\n        self.data.iloc[800000]\r\n\r\n    def time_iloc_slice(self, index, index_structure):\r\n        self.data.iloc[:800000]\r\n\r\n    def time_loc_array(self, index, index_structure):\r\n        self.data.loc[self.array]\r\n\r\n    def time_loc_list_like(self, index, index_structure):\r\n        self.data.loc[[800000]]\r\n\r\n    def time_loc_scalar(self, index, index_structure):\r\n        self.data.loc[800000]\r\n\r\n    def time_loc_slice(self, index, index_structure):\r\n        self.data.loc[:800000]\r\n\r\n\r\nclass NumericMaskedIndexing:\r\n    monotonic_list = list(range(10**6))\r\n    non_monotonic_list = list(range(50)) + [54, 53, 52, 51] + list(range(55, 10**6 - 1))\r\n\r\n    params = [\r\n        (\"Int64\", \"UInt64\", \"Float64\"),\r\n        (True, False),\r\n    ]\r\n    param_names = [\"dtype\", \"monotonic\"]\r\n\r\n    def setup(self, dtype, monotonic):\r\n        indices = {\r\n            True: Index(self.monotonic_list, dtype=dtype),\r\n            False: Index(self.non_monotonic_list, dtype=dtype).append(\r\n                Index([NA], dtype=dtype)\r\n            ),\r\n        }\r\n        self.data = indices[monotonic]\r\n        self.indexer = np.arange(300, 1_000)\r\n        self.data_dups = self.data.append(self.data)\r\n\r\n    def time_get_indexer(self, dtype, monotonic):\r\n        self.data.get_indexer(self.indexer)\r\n\r\n    def time_get_indexer_dups(self, dtype, monotonic):\r\n        self.data.get_indexer_for(self.indexer)\r\n\r\n\r\nclass NonNumericSeriesIndexing:\r\n    params = [\r\n        (\"string\", \"datetime\", \"period\"),\r\n        (\"unique_monotonic_inc\", \"nonunique_monotonic_inc\", \"non_monotonic\"),\r\n    ]\r\n    param_names = [\"index_dtype\", \"index_structure\"]\r\n\r\n    def setup(self, index, index_structure):\r\n        N = 10**6\r\n        if index == \"string\":\r\n            index = Index([f\"i-{i}\" for i in range(N)], dtype=object)\r\n        elif index == \"datetime\":\r\n            index = date_range(\"1900\", periods=N, freq=\"s\")\r\n        elif index == \"period\":\r\n            index = period_range(\"1900\", periods=N, freq=\"s\")\r\n        index = index.sort_values()\r\n        assert index.is_unique and index.is_monotonic_increasing\r\n        if index_structure == \"nonunique_monotonic_inc\":\r\n            index = index.insert(item=index[2], loc=2)[:-1]\r\n        elif index_structure == \"non_monotonic\":\r\n            index = index[::2].append(index[1::2])\r\n            assert len(index) == N\r\n        self.s = Series(np.random.rand(N), index=index)\r\n        self.lbl = index[80000]\r\n        # warm up index mapping\r\n        self.s[self.lbl]\r\n\r\n    def time_getitem_label_slice(self, index, index_structure):\r\n        self.s[: self.lbl]\r\n\r\n    def time_getitem_pos_slice(self, index, index_structure):\r\n        self.s[:80000]\r\n\r\n    def time_getitem_scalar(self, index, index_structure):\r\n        self.s[self.lbl]\r\n\r\n    def time_getitem_list_like(self, index, index_structure):\r\n        self.s[[self.lbl]]\r\n\r\n\r\nclass DataFrameStringIndexing:\r\n    def setup(self):\r\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\r\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\r\n        with warnings.catch_warnings(record=True):\r\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\r\n        self.idx_scalar = index[100]\r\n        self.col_scalar = columns[10]\r\n        self.bool_indexer = self.df[self.col_scalar] > 0\r\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\r\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")\r\n\r\n    def time_loc(self):\r\n        self.df.loc[self.idx_scalar, self.col_scalar]\r\n\r\n    def time_at(self):\r\n        self.df.at[self.idx_scalar, self.col_scalar]\r\n\r\n    def time_at_setitem(self):\r\n        self.df.at[self.idx_scalar, self.col_scalar] = 0.0\r\n\r\n    def time_getitem_scalar(self):\r\n        self.df[self.col_scalar][self.idx_scalar]\r\n\r\n    def time_boolean_rows(self):\r\n        self.df[self.bool_indexer]\r\n\r\n    def time_boolean_rows_object(self):\r\n        self.df[self.bool_obj_indexer]\r\n\r\n    def time_boolean_rows_boolean(self):\r\n        self.df[self.boolean_indexer]\r\n\r\n\r\nclass DataFrameNumericIndexing:\r\n    params = [\r\n        (np.int64, np.uint64, np.float64),\r\n        (\"unique_monotonic_inc\", \"nonunique_monotonic_inc\"),\r\n    ]\r\n    param_names = [\"dtype\", \"index_structure\"]\r\n\r\n    def setup(self, dtype, index_structure):\r\n        N = 10**5\r\n        indices = {\r\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\r\n            \"nonunique_monotonic_inc\": Index(\r\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\r\n            ),\r\n        }\r\n        self.idx_dupe = np.array(range(30)) * 99\r\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\r\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\r\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)\r\n\r\n    def time_iloc_dups(self, index, index_structure):\r\n        self.df_dup.iloc[self.idx_dupe]\r\n\r\n    def time_loc_dups(self, index, index_structure):\r\n        self.df_dup.loc[self.idx_dupe]\r\n\r\n    def time_iloc(self, index, index_structure):\r\n        self.df.iloc[:100, 0]\r\n\r\n    def time_loc(self, index, index_structure):\r\n        self.df.loc[:100, 0]\r\n\r\n    def time_bool_indexer(self, index, index_structure):\r\n        self.df[self.bool_indexer]\r\n\r\n\r\nclass Take:\r\n    params = [\"int\", \"datetime\"]\r\n    param_names = [\"index\"]\r\n\r\n    def setup(self, index):\r\n        N = 100000\r\n        indexes = {\r\n            \"int\": Index(np.arange(N), dtype=np.int64),\r\n            \"datetime\": date_range(\"2011-01-01\", freq=\"s\", periods=N),\r\n        }\r\n        index = indexes[index]\r\n        self.s = Series(np.random.rand(N), index=index)\r\n        self.indexer = np.random.randint(0, N, size=N)\r\n\r\n    def time_take(self, index):\r\n        self.s.take(self.indexer)\r\n\r\n\r\nclass MultiIndexing:\r\n    params = [True, False]\r\n    param_names = [\"unique_levels\"]\r\n\r\n    def setup(self, unique_levels):\r\n        self.nlevels = 2\r\n        if unique_levels:\r\n            mi = MultiIndex.from_arrays([range(1000000)] * self.nlevels)\r\n        else:\r\n            mi = MultiIndex.from_product([range(1000)] * self.nlevels)\r\n        self.df = DataFrame(np.random.randn(len(mi)), index=mi)\r\n\r\n        self.tgt_slice = slice(200, 800)\r\n        self.tgt_null_slice = slice(None)\r\n        self.tgt_list = list(range(0, 1000, 10))\r\n        self.tgt_scalar = 500\r\n\r\n        bool_indexer = np.zeros(len(mi), dtype=np.bool_)\r\n        bool_indexer[slice(0, len(mi), 100)] = True\r\n"]
[75.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[75.002, "i", "sed -n '1,200p' asv_bench/asv.conf.json\r"]
[75.004, "o", "sed -n '1,200p' asv_bench/asv.conf.json\r\n"]
[75.006, "o", "\u001b[?2004l\r\n{\r\n    // The version of the config file format.  Do not change, unless\r\n    // you know what you are doing.\r\n    \"version\": 1,\r\n\r\n    // The name of the project being benchmarked\r\n    \"project\": \"pandas\",\r\n\r\n    // The project's homepage\r\n    \"project_url\": \"https://pandas.pydata.org/\",\r\n\r\n    // The URL of the source code repository for the project being\r\n    // benchmarked\r\n    \"repo\": \"..\",\r\n\r\n    // List of branches to benchmark. If not provided, defaults to \"master\"\r\n    // (for git) or \"default\" (for mercurial).\r\n    \"branches\": [\"main\"],\r\n\r\n    // The tool to use to create environments.  May be \"conda\",\r\n    // \"virtualenv\" or other value depending on the plugins in use.\r\n    // If missing or the empty string, the tool will be automatically\r\n    // determined by looking for tools on the PATH environment\r\n    // variable.\r\n    \"environment_type\": \"conda\",\r\n\r\n    // the base URL to show a commit for the project.\r\n    \"show_commit_url\": \"https://github.com/pandas-dev/pandas/commit/\",\r\n\r\n    // The Pythons you'd like to test against.  If not provided, defaults\r\n    // to the current version of Python used to run `asv`.\r\n    \"pythons\": [\"3.10\"],\r\n\r\n    // The matrix of dependencies to test.  Each key is the name of a\r\n    // package (in PyPI) and the values are version numbers.  An empty\r\n    // list or empty string indicates to just test against the default\r\n    // (latest) version. null indicates that the package is to not be\r\n    // installed. If the package to be tested is only available from\r\n    // PyPi, and the 'environment_type' is conda, then you can preface\r\n    // the package name by 'pip+', and the package will be installed via\r\n    // pip (with all the conda available packages installed first,\r\n    // followed by the pip installed packages).\r\n    \"matrix\": {\r\n        \"pip+build\": [],\r\n        \"Cython\": [\"3.0\"],\r\n        \"matplotlib\": [],\r\n        \"sqlalchemy\": [],\r\n        \"scipy\": [],\r\n        \"numba\": [],\r\n        \"numexpr\": [],\r\n        \"pytables\": [null, \"\"],  // platform dependent, see excludes below\r\n        \"pyarrow\": [],\r\n        \"tables\": [null, \"\"],\r\n        \"openpyxl\": [],\r\n        \"xlsxwriter\": [],\r\n        \"xlrd\": [],\r\n        \"odfpy\": [],\r\n        \"jinja2\": [],\r\n        \"meson\": [],\r\n        \"meson-python\": [],\r\n        \"python-build\": [],\r\n    },\r\n    \"conda_channels\": [\"conda-forge\"],\r\n    // Combinations of libraries/python versions can be excluded/included\r\n    // from the set to test. Each entry is a dictionary containing additional\r\n    // key-value pairs to include/exclude.\r\n    //\r\n    // An exclude entry excludes entries where all values match. The\r\n    // values are regexps that should match the whole string.\r\n    //\r\n    // An include entry adds an environment. Only the packages listed\r\n    // are installed. The 'python' key is required. The exclude rules\r\n    // do not apply to includes.\r\n    //\r\n    // In addition to package names, the following keys are available:\r\n    //\r\n    // - python\r\n    //     Python version, as in the *pythons* variable above.\r\n    // - environment_type\r\n    //     Environment type, as above.\r\n    // - sys_platform\r\n    //     Platform, as in sys.platform. Possible values for the common\r\n    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.\r\n    \"exclude\": [\r\n        // On conda install pytables, otherwise tables\r\n        {\"environment_type\": \"conda\", \"tables\": \"\"},\r\n        {\"environment_type\": \"conda\", \"pytables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"tables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"pytables\": \"\"},\r\n    ],\r\n    \"include\": [],\r\n\r\n    // The directory (relative to the current directory) that benchmarks are\r\n    // stored in.  If not provided, defaults to \"benchmarks\"\r\n    // \"benchmark_dir\": \"benchmarks\",\r\n\r\n    // The directory (relative to the current directory) to cache the Python\r\n    // environments in.  If not provided, defaults to \"env\"\r\n    // \"env_dir\": \"env\",\r\n\r\n    // The directory (relative to the current directory) that raw benchmark\r\n    // results are stored in.  If not provided, defaults to \"results\".\r\n    // \"results_dir\": \"results\",\r\n\r\n    // The directory (relative to the current directory) that the html tree\r\n    // should be written to.  If not provided, defaults to \"html\".\r\n    // \"html_dir\": \"html\",\r\n\r\n    // The number of characters to retain in the commit hashes.\r\n    // \"hash_length\": 8,\r\n\r\n    // `asv` will cache wheels of the recent builds in each\r\n    // environment, making them faster to install next time.  This is\r\n    // number of builds to keep, per environment.\r\n    \"build_cache_size\": 8,\r\n\r\n    // The commits after which the regression search in `asv publish`\r\n    // should start looking for regressions. Dictionary whose keys are\r\n    // regexps matching to benchmark names, and values corresponding to\r\n    // the commit (exclusive) after which to start looking for\r\n    // regressions.  The default is to start from the first commit\r\n    // with results. If the commit is `null`, regression detection is\r\n    // skipped for the matching benchmark.\r\n    //\r\n    \"regressions_first_commits\": {\r\n        \".*\": \"0409521665\"\r\n    },\r\n    \"regression_thresholds\": {\r\n    },\r\n    \"build_command\":\r\n    [\"python -m build -Cbuilddir=builddir --wheel --outdir {build_cache_dir} {build_dir}\"]\r\n}\r\n"]
[80.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[80.002, "i", "asv run --python=same --config=asv_bench/asv.conf.json --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[80.004, "o", "asv run --python=same --config=asv_bench/asv.conf.json --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[80.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mConfig file asv_bench/asv.conf.json not found.\u001b[0m\r\n"]
[85.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[85.002, "i", "ls -la pandas\r"]
[85.004, "o", "ls -la pandas\r\n"]
[85.006, "o", "\u001b[?2004l\r\ntotal 176\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Oct  1 17:04 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root  8202 Sep 13 21:47 __init__.py\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34m_config\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34m_libs\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34m_testing\u001b[0m\r\n-rw-r--r-- 1 root root 14590 Sep 13 21:47 _typing.py\r\n-rw-r--r-- 1 root root 23611 Sep 13 21:47 _version.py\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mapi\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 13 21:47 \u001b[01;34marrays\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mcompat\u001b[0m\r\n-rw-r--r-- 1 root root 49704 Sep 13 21:47 conftest.py\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mcore\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34merrors\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mio\u001b[0m\r\n-rw-r--r-- 1 root root   994 Sep 13 21:47 meson.build\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mplotting\u001b[0m\r\n-rw-r--r-- 1 root root   312 Sep 13 21:47 testing.py\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mtests\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mtseries\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:47 \u001b[01;34mutil\u001b[0m\r\n"]
[90.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[90.002, "i", "find pandas -maxdepth 2 -type d -name \"core\" -o -name \"_libs\"\r"]
[90.004, "o", "find pandas -maxdepth 2 -type d -name \"core\" -o -name \"_libs\"\r\n"]
[90.006, "o", "\u001b[?2004l\r\npandas/core\r\npandas/_libs\r\n"]
[95.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[95.002, "i", "sed -n '140,230p' asv_bench/benchmarks/indexing.py\r"]
[95.004, "o", "sed -n '140,230p' asv_bench/benchmarks/indexing.py\r\n"]
[95.006, "o", "\u001b[?2004l\r\n\r\n    def time_getitem_label_slice(self, index, index_structure):\r\n        self.s[: self.lbl]\r\n\r\n    def time_getitem_pos_slice(self, index, index_structure):\r\n        self.s[:80000]\r\n\r\n    def time_getitem_scalar(self, index, index_structure):\r\n        self.s[self.lbl]\r\n\r\n    def time_getitem_list_like(self, index, index_structure):\r\n        self.s[[self.lbl]]\r\n\r\n\r\nclass DataFrameStringIndexing:\r\n    def setup(self):\r\n        index = Index([f\"i-{i}\" for i in range(1000)], dtype=object)\r\n        columns = Index([f\"i-{i}\" for i in range(30)], dtype=object)\r\n        with warnings.catch_warnings(record=True):\r\n            self.df = DataFrame(np.random.randn(1000, 30), index=index, columns=columns)\r\n        self.idx_scalar = index[100]\r\n        self.col_scalar = columns[10]\r\n        self.bool_indexer = self.df[self.col_scalar] > 0\r\n        self.bool_obj_indexer = self.bool_indexer.astype(object)\r\n        self.boolean_indexer = (self.df[self.col_scalar] > 0).astype(\"boolean\")\r\n\r\n    def time_loc(self):\r\n        self.df.loc[self.idx_scalar, self.col_scalar]\r\n\r\n    def time_at(self):\r\n        self.df.at[self.idx_scalar, self.col_scalar]\r\n\r\n    def time_at_setitem(self):\r\n        self.df.at[self.idx_scalar, self.col_scalar] = 0.0\r\n\r\n    def time_getitem_scalar(self):\r\n        self.df[self.col_scalar][self.idx_scalar]\r\n\r\n    def time_boolean_rows(self):\r\n        self.df[self.bool_indexer]\r\n\r\n    def time_boolean_rows_object(self):\r\n        self.df[self.bool_obj_indexer]\r\n\r\n    def time_boolean_rows_boolean(self):\r\n        self.df[self.boolean_indexer]\r\n\r\n\r\nclass DataFrameNumericIndexing:\r\n    params = [\r\n        (np.int64, np.uint64, np.float64),\r\n        (\"unique_monotonic_inc\", \"nonunique_monotonic_inc\"),\r\n    ]\r\n    param_names = [\"dtype\", \"index_structure\"]\r\n\r\n    def setup(self, dtype, index_structure):\r\n        N = 10**5\r\n        indices = {\r\n            \"unique_monotonic_inc\": Index(range(N), dtype=dtype),\r\n            \"nonunique_monotonic_inc\": Index(\r\n                list(range(55)) + [54] + list(range(55, N - 1)), dtype=dtype\r\n            ),\r\n        }\r\n        self.idx_dupe = np.array(range(30)) * 99\r\n        self.df = DataFrame(np.random.randn(N, 5), index=indices[index_structure])\r\n        self.df_dup = concat([self.df, 2 * self.df, 3 * self.df])\r\n        self.bool_indexer = [True] * (N // 2) + [False] * (N - N // 2)\r\n\r\n    def time_iloc_dups(self, index, index_structure):\r\n        self.df_dup.iloc[self.idx_dupe]\r\n\r\n    def time_loc_dups(self, index, index_structure):\r\n        self.df_dup.loc[self.idx_dupe]\r\n\r\n    def time_iloc(self, index, index_structure):\r\n        self.df.iloc[:100, 0]\r\n\r\n    def time_loc(self, index, index_structure):\r\n        self.df.loc[:100, 0]\r\n\r\n    def time_bool_indexer(self, index, index_structure):\r\n        self.df[self.bool_indexer]\r\n\r\n\r\nclass Take:\r\n    params = [\"int\", \"datetime\"]\r\n    param_names = [\"index\"]\r\n\r\n    def setup(self, index):\r\n        N = 100000\r\n        indexes = {\r\n"]
[100.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo# "]
[100.002, "i", "cd asv_bench\r"]
[100.004, "o", "cd asv_bench\r\n"]
[100.006, "o", "\u001b[?2004l\r\n"]
[105.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[105.002, "i", "ls -la\r"]
[105.004, "o", "ls -la\r\n"]
[105.006, "o", "\u001b[?2004l\r\ntotal 24\r\ndrwxr-xr-x 1 root root 4096 Sep 13 21:47 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root 4096 Oct  1 17:04 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root 5194 Sep 13 21:47 asv.conf.json\r\ndrwxr-xr-x 1 root root 4096 Sep 13 21:47 \u001b[01;34mbenchmarks\u001b[0m\r\n"]
[110.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[110.002, "i", "sed -n '1,120p' asv.conf.json\r"]
[110.004, "o", "sed -n '1,120p' asv.conf.json\r\n"]
[110.006, "o", "\u001b[?2004l\r\n{\r\n    // The version of the config file format.  Do not change, unless\r\n    // you know what you are doing.\r\n    \"version\": 1,\r\n\r\n    // The name of the project being benchmarked\r\n    \"project\": \"pandas\",\r\n\r\n    // The project's homepage\r\n    \"project_url\": \"https://pandas.pydata.org/\",\r\n\r\n    // The URL of the source code repository for the project being\r\n    // benchmarked\r\n    \"repo\": \"..\",\r\n\r\n    // List of branches to benchmark. If not provided, defaults to \"master\"\r\n    // (for git) or \"default\" (for mercurial).\r\n    \"branches\": [\"main\"],\r\n\r\n    // The tool to use to create environments.  May be \"conda\",\r\n    // \"virtualenv\" or other value depending on the plugins in use.\r\n    // If missing or the empty string, the tool will be automatically\r\n    // determined by looking for tools on the PATH environment\r\n    // variable.\r\n    \"environment_type\": \"conda\",\r\n\r\n    // the base URL to show a commit for the project.\r\n    \"show_commit_url\": \"https://github.com/pandas-dev/pandas/commit/\",\r\n\r\n    // The Pythons you'd like to test against.  If not provided, defaults\r\n    // to the current version of Python used to run `asv`.\r\n    \"pythons\": [\"3.10\"],\r\n\r\n    // The matrix of dependencies to test.  Each key is the name of a\r\n    // package (in PyPI) and the values are version numbers.  An empty\r\n    // list or empty string indicates to just test against the default\r\n    // (latest) version. null indicates that the package is to not be\r\n    // installed. If the package to be tested is only available from\r\n    // PyPi, and the 'environment_type' is conda, then you can preface\r\n    // the package name by 'pip+', and the package will be installed via\r\n    // pip (with all the conda available packages installed first,\r\n    // followed by the pip installed packages).\r\n    \"matrix\": {\r\n        \"pip+build\": [],\r\n        \"Cython\": [\"3.0\"],\r\n        \"matplotlib\": [],\r\n        \"sqlalchemy\": [],\r\n        \"scipy\": [],\r\n        \"numba\": [],\r\n        \"numexpr\": [],\r\n        \"pytables\": [null, \"\"],  // platform dependent, see excludes below\r\n        \"pyarrow\": [],\r\n        \"tables\": [null, \"\"],\r\n        \"openpyxl\": [],\r\n        \"xlsxwriter\": [],\r\n        \"xlrd\": [],\r\n        \"odfpy\": [],\r\n        \"jinja2\": [],\r\n        \"meson\": [],\r\n        \"meson-python\": [],\r\n        \"python-build\": [],\r\n    },\r\n    \"conda_channels\": [\"conda-forge\"],\r\n    // Combinations of libraries/python versions can be excluded/included\r\n    // from the set to test. Each entry is a dictionary containing additional\r\n    // key-value pairs to include/exclude.\r\n    //\r\n    // An exclude entry excludes entries where all values match. The\r\n    // values are regexps that should match the whole string.\r\n    //\r\n    // An include entry adds an environment. Only the packages listed\r\n    // are installed. The 'python' key is required. The exclude rules\r\n    // do not apply to includes.\r\n    //\r\n    // In addition to package names, the following keys are available:\r\n    //\r\n    // - python\r\n    //     Python version, as in the *pythons* variable above.\r\n    // - environment_type\r\n    //     Environment type, as above.\r\n    // - sys_platform\r\n    //     Platform, as in sys.platform. Possible values for the common\r\n    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.\r\n    \"exclude\": [\r\n        // On conda install pytables, otherwise tables\r\n        {\"environment_type\": \"conda\", \"tables\": \"\"},\r\n        {\"environment_type\": \"conda\", \"pytables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"tables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"pytables\": \"\"},\r\n    ],\r\n    \"include\": [],\r\n\r\n    // The directory (relative to the current directory) that benchmarks are\r\n    // stored in.  If not provided, defaults to \"benchmarks\"\r\n    // \"benchmark_dir\": \"benchmarks\",\r\n\r\n    // The directory (relative to the current directory) to cache the Python\r\n    // environments in.  If not provided, defaults to \"env\"\r\n    // \"env_dir\": \"env\",\r\n\r\n    // The directory (relative to the current directory) that raw benchmark\r\n    // results are stored in.  If not provided, defaults to \"results\".\r\n    // \"results_dir\": \"results\",\r\n\r\n    // The directory (relative to the current directory) that the html tree\r\n    // should be written to.  If not provided, defaults to \"html\".\r\n    // \"html_dir\": \"html\",\r\n\r\n    // The number of characters to retain in the commit hashes.\r\n    // \"hash_length\": 8,\r\n\r\n    // `asv` will cache wheels of the recent builds in each\r\n    // environment, making them faster to install next time.  This is\r\n    // number of builds to keep, per environment.\r\n    \"build_cache_size\": 8,\r\n\r\n    // The commits after which the regression search in `asv publish`\r\n    // should start looking for regressions. Dictionary whose keys are\r\n    // regexps matching to benchmark names, and values corresponding to\r\n    // the commit (exclusive) after which to start looking for\r\n"]
[115.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[115.002, "i", "asv dev -b \"indexing.DataFrameStringIndexing.*\"\r"]
[115.004, "o", "asv dev -b \"indexing.DataFrameStringIndexing.*\"\r\n"]
[115.006, "o", "\u001b[?2004l\r\nusage: asv [-h] [--verbose] [--config CONFIG] [--version]\r\n           {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages} ...\r\nasv: error: argument {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages}: invalid choice: 'dev' (choose from 'help', 'quickstart', 'machine', 'setup', 'run', 'continuous', 'find', 'rm', 'publish', 'preview', 'profile', 'update', 'show', 'compare', 'check', 'gh-pages')\r\n"]
[120.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[120.002, "i", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[120.004, "o", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[120.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (indexing.DataFrameStringIndexing.time_at--)\u001b[0m.......\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at\u001b[0m                                                                                                12.6\u00b10.2\u03bcs\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at_setitem\u001b[0m                                                                                        12.3\u00b10.5\u03bcs\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows\u001b[0m                                                                                         120\u00b12\u03bcs\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_boolean\u001b[0m                                                                               116\u00b10.6\u03bcs\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_object\u001b[0m                                                                                  170\u00b11\u03bcs\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_getitem_scalar\u001b[0m                                                                                    14.2\u00b10.2\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_loc\u001b[0m                                                                                               17.4\u00b10.4\u03bcs\r\n"]
[125.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[125.002, "i", "asv profile --python=same indexing.DataFrameStringIndexing.time_boolean_rows_object\r"]
[125.004, "o", "asv profile --python=same indexing.DataFrameStringIndexing.time_boolean_rows_object\r\n"]
[125.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31m[1/1] Generating write_version_file with a custom command\u001b[0m\r\n     + /opt/conda/envs/asv_3.10/bin/ninja\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (indexing.DataFrameStringIndexing.time_boolean_rows_object--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_object\u001b[0m                                                                                  169\u00b12\u03bcs\r\n\r\nWed Oct  1 17:11:58 2025    /tmp/tmp7pjmy_pp\r\n\r\n         280 function calls (266 primitive calls) in 0.000 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.000    0.000 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:181(time_boolean_rows_object)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3861(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:3931(_getitem_bool_array)\r\n      7/5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        1    0.000    0.000    0.000    0.000 generic.py:3870(take)\r\n        1    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1013(take)\r\n        4    0.000    0.000    0.000    0.000 generic.py:6022(__getattr__)\r\n        4    0.000    0.000    0.000    0.000 base.py:5058(_can_hold_identifiers_and_holds_name)\r\n        4    0.000    0.000    0.000    0.000 base.py:4944(__contains__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2612(check_bool_indexer)\r\n        1    0.000    0.000    0.000    0.000 managers.py:775(reindex_indexer)\r\n        1    0.000    0.000    0.000    0.000 base.py:1138(take)\r\n        1    0.000    0.000    0.000    0.000 managers.py:828(<listcomp>)\r\n        2    0.000    0.000    0.000    0.000 series.py:799(__array__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:988(take_nd)\r\n        1    0.000    0.000    0.000    0.000 take.py:57(take_nd)\r\n        1    0.000    0.000    0.000    0.000 take.py:118(_take_nd_ndarray)\r\n        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n        1    0.000    0.000    0.000    0.000 base.py:644(_simple_new)\r\n    51/49    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        6    0.000    0.000    0.000    0.000 common.py:137(is_object_dtype)\r\n        1    0.000    0.000    0.000    0.000 utils.py:240(maybe_convert_indices)\r\n        6    0.000    0.000    0.000    0.000 common.py:1438(_is_dtype_type)\r\n        1    0.000    0.000    0.000    0.000 utils.py:420(check_array_indexer)\r\n        1    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 _methods.py:68(_all)\r\n        3    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     19/9    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 algorithms.py:1074(take)\r\n        1    0.000    0.000    0.000    0.000 base.py:4790(_get_engine_target)\r\n        1    0.000    0.000    0.000    0.000 take.py:516(_take_preprocess_indexer_and_fill_value)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5974(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 cast.py:549(maybe_promote)\r\n        4    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 frame.py:658(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 managers.py:212(shape)\r\n        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n        3    0.000    0.000    0.000    0.000 series.py:619(dtype)\r\n        1    0.000    0.000    0.000    0.000 generic.py:290(_from_mgr)\r\n        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n        1    0.000    0.000    0.000    0.000 common.py:536(is_string_dtype)\r\n        1    0.000    0.000    0.000    0.000 common.py:1202(is_bool_dtype)\r\n        2    0.000    0.000    0.000    0.000 astype.py:246(astype_is_view)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2124(dtype)\r\n        1    0.000    0.000    0.000    0.000 generic.py:254(__init__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:204(fill_value)\r\n        4    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n        1    0.000    0.000    0.000    0.000 inference.py:333(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 series.py:791(__len__)\r\n        4    0.000    0.000    0.000    0.000 generic.py:609(_info_axis)\r\n        6    0.000    0.000    0.000    0.000 common.py:123(<lambda>)\r\n        7    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2745(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 common.py:1379(_is_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:451(_engine_type)\r\n        3    0.000    0.000    0.000    0.000 managers.py:214(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:208(__len__)\r\n        1    0.000    0.000    0.000    0.000 base.py:2401(_na_value)\r\n        2    0.000    0.000    0.000    0.000 series.py:747(_values)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:243(make_block_same_class)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1091(from_blocks)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        1    0.000    0.000    0.000    0.000 generic.py:534(_get_block_manager_axis)\r\n        3    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        6    0.000    0.000    0.000    0.000 common.py:121(classes)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1589(__len__)\r\n        2    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 common.py:1403(_get_dtype)\r\n        1    0.000    0.000    0.000    0.000 common.py:1600(pandas_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:5173(equals)\r\n        1    0.000    0.000    0.000    0.000 missing.py:600(na_value_for_dtype)\r\n        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 managers.py:2135(internal_values)\r\n        2    0.000    0.000    0.000    0.000 blocks.py:565(dtype)\r\n        1    0.000    0.000    0.000    0.000 common.py:1044(needs_i8_conversion)\r\n        1    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 common.py:375(apply_if_callable)\r\n        5    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 common.py:572(condition)\r\n        7    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 take.py:265(_get_take_nd_function)\r\n        4    0.000    0.000    0.000    0.000 base.py:4764(_values)\r\n        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55f519bb5640}\r\n        1    0.000    0.000    0.000    0.000 inference.py:193(is_array_like)\r\n        1    0.000    0.000    0.000    0.000 base.py:826(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 generic.py:512(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 function.py:65(__call__)\r\n        1    0.000    0.000    0.000    0.000 base.py:1640(name)\r\n        1    0.000    0.000    0.000    0.000 base.py:1171(_maybe_disallow_fill)\r\n        2    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:297(items)\r\n        1    0.000    0.000    0.000    0.000 base.py:687(_constructor)\r\n        2    0.000    0.000    0.000    0.000 base.py:786(is_)\r\n        1    0.000    0.000    0.000    0.000 common.py:529(is_string_or_object_np_dtype)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2061(_block)\r\n        1    0.000    0.000    0.000    0.000 managers.py:220(blknos)\r\n        2    0.000    0.000    0.000    0.000 generic.py:356(flags)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:236(blklocs)\r\n        1    0.000    0.000    0.000    0.000 base.py:974(dtype)\r\n        1    0.000    0.000    0.000    0.000 generic.py:314(attrs)\r\n        1    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1056(__init__)\r\n        1    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n\r\n\r\n"]
[130.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[130.002, "i", "sed -n '3800,3980p' ../pandas/core/frame.py\r"]
[130.004, "o", "sed -n '3800,3980p' ../pandas/core/frame.py\r\n"]
[130.006, "o", "\u001b[?2004l\r\n        >>> df = pd.DataFrame({\"col1\": [1, 2], \"col2\": [3, 4]})\r\n        >>> df\r\n           col1  col2\r\n        0     1     3\r\n        1     2     4\r\n\r\n        >>> df.T\r\n              0  1\r\n        col1  1  2\r\n        col2  3  4\r\n        \"\"\"\r\n        return self.transpose()\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Indexing Methods\r\n\r\n    def _ixs(self, i: int, axis: AxisInt = 0) -> Series:\r\n        \"\"\"\r\n        Parameters\r\n        ----------\r\n        i : int\r\n        axis : int\r\n\r\n        Returns\r\n        -------\r\n        Series\r\n        \"\"\"\r\n        # irow\r\n        if axis == 0:\r\n            new_mgr = self._mgr.fast_xs(i)\r\n\r\n            result = self._constructor_sliced_from_mgr(new_mgr, axes=new_mgr.axes)\r\n            result._name = self.index[i]\r\n            return result.__finalize__(self)\r\n\r\n        # icol\r\n        else:\r\n            col_mgr = self._mgr.iget(i)\r\n            return self._box_col_values(col_mgr, i)\r\n\r\n    def _get_column_array(self, i: int) -> ArrayLike:\r\n        \"\"\"\r\n        Get the values of the i'th column (ndarray or ExtensionArray, as stored\r\n        in the Block)\r\n\r\n        Warning! The returned array is a view but doesn't handle Copy-on-Write,\r\n        so this should be used with caution (for read-only purposes).\r\n        \"\"\"\r\n        return self._mgr.iget_values(i)\r\n\r\n    def _iter_column_arrays(self) -> Iterator[ArrayLike]:\r\n        \"\"\"\r\n        Iterate over the arrays of all columns in order.\r\n        This returns the values as stored in the Block (ndarray or ExtensionArray).\r\n\r\n        Warning! The returned array is a view but doesn't handle Copy-on-Write,\r\n        so this should be used with caution (for read-only purposes).\r\n        \"\"\"\r\n        for i in range(len(self.columns)):\r\n            yield self._get_column_array(i)\r\n\r\n    def __getitem__(self, key):\r\n        check_dict_or_set_indexers(key)\r\n        key = lib.item_from_zerodim(key)\r\n        key = com.apply_if_callable(key, self)\r\n\r\n        if is_hashable(key) and not is_iterator(key) and not isinstance(key, slice):\r\n            # is_iterator to exclude generator e.g. test_getitem_listlike\r\n            # As of Python 3.12, slice is hashable which breaks MultiIndex (GH#57500)\r\n\r\n            # shortcut if the key is in columns\r\n            is_mi = isinstance(self.columns, MultiIndex)\r\n            # GH#45316 Return view if key is not duplicated\r\n            # Only use drop_duplicates with duplicates for performance\r\n            if not is_mi and (\r\n                self.columns.is_unique\r\n                and key in self.columns\r\n                or key in self.columns.drop_duplicates(keep=False)\r\n            ):\r\n                return self._get_item(key)\r\n\r\n            elif is_mi and self.columns.is_unique and key in self.columns:\r\n                return self._getitem_multilevel(key)\r\n\r\n        # Do we have a slicer (on rows)?\r\n        if isinstance(key, slice):\r\n            return self._getitem_slice(key)\r\n\r\n        # Do we have a (boolean) DataFrame?\r\n        if isinstance(key, DataFrame):\r\n            return self.where(key)\r\n\r\n        # Do we have a (boolean) 1d indexer?\r\n        if com.is_bool_indexer(key):\r\n            return self._getitem_bool_array(key)\r\n\r\n        # We are left with two options: a single key, and a collection of keys,\r\n        # We interpret tuples as collections only for non-MultiIndex\r\n        is_single_key = isinstance(key, tuple) or not is_list_like(key)\r\n\r\n        if is_single_key:\r\n            if self.columns.nlevels > 1:\r\n                return self._getitem_multilevel(key)\r\n            indexer = self.columns.get_loc(key)\r\n            if is_integer(indexer):\r\n                indexer = [indexer]\r\n        else:\r\n            if is_iterator(key):\r\n                key = list(key)\r\n            indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n\r\n        # take() does not accept boolean indexers\r\n        if getattr(indexer, \"dtype\", None) == bool:\r\n            indexer = np.where(indexer)[0]\r\n\r\n        if isinstance(indexer, slice):\r\n            return self._slice(indexer, axis=1)\r\n\r\n        data = self.take(indexer, axis=1)\r\n\r\n        if is_single_key:\r\n            # What does looking for a single key in a non-unique index return?\r\n            # The behavior is inconsistent. It returns a Series, except when\r\n            # - the key itself is repeated (test on data.shape, #9519), or\r\n            # - we have a MultiIndex on columns (test on self.columns, #21309)\r\n            if data.shape[1] == 1 and not isinstance(self.columns, MultiIndex):\r\n                # GH#26490 using data[key] can cause RecursionError\r\n                return data._get_item(key)\r\n\r\n        return data\r\n\r\n    def _getitem_bool_array(self, key):\r\n        # also raises Exception if object array with NA values\r\n        # warning here just in case -- previously __setitem__ was\r\n        # reindexing but __getitem__ was not; it seems more reasonable to\r\n        # go with the __setitem__ behavior since that is more consistent\r\n        # with all other indexing behavior\r\n        if isinstance(key, Series) and not key.index.equals(self.index):\r\n            warnings.warn(\r\n                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n                UserWarning,\r\n                stacklevel=find_stack_level(),\r\n            )\r\n        elif len(key) != len(self.index):\r\n            raise ValueError(\r\n                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n            )\r\n\r\n        # check_bool_indexer will throw exception if Series key cannot\r\n        # be reindexed to match DataFrame rows\r\n        key = check_bool_indexer(self.index, key)\r\n\r\n        if key.all():\r\n            return self.copy(deep=False)\r\n\r\n        indexer = key.nonzero()[0]\r\n        return self.take(indexer, axis=0)\r\n\r\n    def _getitem_multilevel(self, key):\r\n        # self.columns is a MultiIndex\r\n        loc = self.columns.get_loc(key)\r\n        if isinstance(loc, (slice, np.ndarray)):\r\n            new_columns = self.columns[loc]\r\n            result_columns = maybe_droplevels(new_columns, key)\r\n            result = self.iloc[:, loc]\r\n            result.columns = result_columns\r\n\r\n            # If there is only one column being returned, and its name is\r\n            # either an empty string, or a tuple with an empty string as its\r\n            # first element, then treat the empty string as a placeholder\r\n            # and return the column as if the user had provided that empty\r\n            # string in the key. If the result is a Series, exclude the\r\n            # implied empty string from its name.\r\n            if len(result.columns) == 1:\r\n                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n                top = result.columns[0]\r\n                if isinstance(top, tuple):\r\n                    top = top[0]\r\n                if top == \"\":\r\n                    result = result[\"\"]\r\n"]
[135.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[135.002, "i", "sed -n '2550,2660p' ../pandas/core/indexing.py\r"]
[135.004, "o", "sed -n '2550,2660p' ../pandas/core/indexing.py\r\n"]
[135.006, "o", "\u001b[?2004l\r\n            # GH#33041 fall back to .loc\r\n            if not isinstance(key, tuple) or not all(is_scalar(x) for x in key):\r\n                raise ValueError(\"Invalid call for scalar access (getting)!\")\r\n            return self.obj.loc[key]\r\n\r\n        return super().__getitem__(key)\r\n\r\n    def __setitem__(self, key, value) -> None:\r\n        if self.ndim == 2 and not self._axes_are_unique:\r\n            # GH#33041 fall back to .loc\r\n            if not isinstance(key, tuple) or not all(is_scalar(x) for x in key):\r\n                raise ValueError(\"Invalid call for scalar access (setting)!\")\r\n\r\n            self.obj.loc[key] = value\r\n            return\r\n\r\n        return super().__setitem__(key, value)\r\n\r\n\r\n@doc(IndexingMixin.iat)\r\nclass _iAtIndexer(_ScalarAccessIndexer):\r\n    _takeable = True\r\n\r\n    def _convert_key(self, key):\r\n        \"\"\"\r\n        Require integer args. (and convert to label arguments)\r\n        \"\"\"\r\n        for i in key:\r\n            if not is_integer(i):\r\n                raise ValueError(\"iAt based indexing can only have integer indexers\")\r\n        return key\r\n\r\n\r\ndef _tuplify(ndim: int, loc: Hashable) -> tuple[Hashable | slice, ...]:\r\n    \"\"\"\r\n    Given an indexer for the first dimension, create an equivalent tuple\r\n    for indexing over all dimensions.\r\n\r\n    Parameters\r\n    ----------\r\n    ndim : int\r\n    loc : object\r\n\r\n    Returns\r\n    -------\r\n    tuple\r\n    \"\"\"\r\n    _tup: list[Hashable | slice]\r\n    _tup = [slice(None, None) for _ in range(ndim)]\r\n    _tup[0] = loc\r\n    return tuple(_tup)\r\n\r\n\r\ndef _tupleize_axis_indexer(ndim: int, axis: AxisInt, key) -> tuple:\r\n    \"\"\"\r\n    If we have an axis, adapt the given key to be axis-independent.\r\n    \"\"\"\r\n    new_key = [slice(None)] * ndim\r\n    new_key[axis] = key\r\n    return tuple(new_key)\r\n\r\n\r\ndef check_bool_indexer(index: Index, key) -> np.ndarray:\r\n    \"\"\"\r\n    Check if key is a valid boolean indexer for an object with such index and\r\n    perform reindexing or conversion if needed.\r\n\r\n    This function assumes that is_bool_indexer(key) == True.\r\n\r\n    Parameters\r\n    ----------\r\n    index : Index\r\n        Index of the object on which the indexing is done.\r\n    key : list-like\r\n        Boolean indexer to check.\r\n\r\n    Returns\r\n    -------\r\n    np.array\r\n        Resulting key.\r\n\r\n    Raises\r\n    ------\r\n    IndexError\r\n        If the key does not have the same length as index.\r\n    IndexingError\r\n        If the index of the key is unalignable to index.\r\n    \"\"\"\r\n    result = key\r\n    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n        indexer = result.index.get_indexer_for(index)\r\n        if -1 in indexer:\r\n            raise IndexingError(\r\n                \"Unalignable boolean Series provided as \"\r\n                \"indexer (index of the boolean Series and of \"\r\n                \"the indexed object do not match).\"\r\n            )\r\n\r\n        result = result.take(indexer)\r\n\r\n        # fall through for boolean\r\n        if not isinstance(result.dtype, ExtensionDtype):\r\n            return result.astype(bool)._values\r\n\r\n    if is_object_dtype(key):\r\n        # key might be object-dtype bool, check_array_indexer needs bool array\r\n        result = np.asarray(result, dtype=bool)\r\n    elif not is_array_like(result):\r\n        # GH 33924\r\n        # key may contain nan elements, check_array_indexer needs bool array\r\n        result = pd_array(result, dtype=bool)\r\n"]
[140.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[140.002, "i", "sed -n '1,240p' ../pandas/core/common.py\r"]
[140.004, "o", "sed -n '1,240p' ../pandas/core/common.py\r\n"]
[140.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nMisc tools for implementing data structures\r\n\r\nNote: pandas.core.common is *not* part of the public API.\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport builtins\r\nfrom collections import (\r\n    abc,\r\n    defaultdict,\r\n)\r\nfrom collections.abc import (\r\n    Collection,\r\n    Generator,\r\n    Hashable,\r\n    Iterable,\r\n    Sequence,\r\n)\r\nimport contextlib\r\nfrom functools import partial\r\nimport inspect\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Callable,\r\n    TypeVar,\r\n    cast,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas.compat.numpy import np_version_gte1p24\r\n\r\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\r\nfrom pandas.core.dtypes.common import (\r\n    is_bool_dtype,\r\n    is_integer,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCExtensionArray,\r\n    ABCIndex,\r\n    ABCMultiIndex,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import iterable_not_string\r\n\r\nif TYPE_CHECKING:\r\n    from pandas._typing import (\r\n        AnyArrayLike,\r\n        ArrayLike,\r\n        Concatenate,\r\n        NpDtype,\r\n        P,\r\n        RandomState,\r\n        T,\r\n    )\r\n\r\n    from pandas import Index\r\n\r\n\r\ndef flatten(line):\r\n    \"\"\"\r\n    Flatten an arbitrarily nested sequence.\r\n\r\n    Parameters\r\n    ----------\r\n    line : sequence\r\n        The non string sequence to flatten\r\n\r\n    Notes\r\n    -----\r\n    This doesn't consider strings sequences.\r\n\r\n    Returns\r\n    -------\r\n    flattened : generator\r\n    \"\"\"\r\n    for element in line:\r\n        if iterable_not_string(element):\r\n            yield from flatten(element)\r\n        else:\r\n            yield element\r\n\r\n\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is not None.\r\n    \"\"\"\r\n    return any(arg is not None for arg in args)\r\n\r\n\r\ndef all_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are not None.\r\n    \"\"\"\r\n    return all(arg is not None for arg in args)\r\n\r\n\r\ndef count_not_none(*args) -> int:\r\n    \"\"\"\r\n    Returns the count of arguments that are not None.\r\n    \"\"\"\r\n    return sum(x is not None for x in args)\r\n\r\n\r\n@overload\r\ndef asarray_tuplesafe(\r\n    values: ArrayLike | list | tuple | zip, dtype: NpDtype | None = ...\r\n) -> np.ndarray:\r\n    # ExtensionArray can only be returned when values is an Index, all other iterables\r\n    # will return np.ndarray. Unfortunately \"all other\" cannot be encoded in a type\r\n    # signature, so instead we special-case some common types.\r\n    ...\r\n\r\n\r\n@overload\r\ndef asarray_tuplesafe(values: Iterable, dtype: NpDtype | None = ...) -> ArrayLike: ...\r\n\r\n\r\ndef asarray_tuplesafe(values: Iterable, dtype: NpDtype | None = None) -> ArrayLike:\r\n    if not (isinstance(values, (list, tuple)) or hasattr(values, \"__array__\")):\r\n        values = list(values)\r\n    elif isinstance(values, ABCIndex):\r\n        return values._values\r\n    elif isinstance(values, ABCSeries):\r\n        return values._values\r\n"]
[145.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[145.002, "i", "sed -n '240,420p' ../pandas/core/common.py\r"]
[145.004, "o", "sed -n '240,420p' ../pandas/core/common.py\r\n"]
[145.006, "o", "\u001b[?2004l\r\n        return values._values\r\n\r\n    if isinstance(values, list) and dtype in [np.object_, object]:\r\n        return construct_1d_object_array_from_listlike(values)\r\n\r\n    try:\r\n        with warnings.catch_warnings():\r\n            # Can remove warning filter once NumPy 1.24 is min version\r\n            if not np_version_gte1p24:\r\n                warnings.simplefilter(\"ignore\", np.VisibleDeprecationWarning)\r\n            result = np.asarray(values, dtype=dtype)\r\n    except ValueError:\r\n        # Using try/except since it's more performant than checking is_list_like\r\n        # over each element\r\n        # error: Argument 1 to \"construct_1d_object_array_from_listlike\"\r\n        # has incompatible type \"Iterable[Any]\"; expected \"Sized\"\r\n        return construct_1d_object_array_from_listlike(values)  # type: ignore[arg-type]\r\n\r\n    if issubclass(result.dtype.type, str):\r\n        result = np.asarray(values, dtype=object)\r\n\r\n    if result.ndim == 2:\r\n        # Avoid building an array of arrays:\r\n        values = [tuple(x) for x in values]\r\n        result = construct_1d_object_array_from_listlike(values)\r\n\r\n    return result\r\n\r\n\r\ndef index_labels_to_array(\r\n    labels: np.ndarray | Iterable, dtype: NpDtype | None = None\r\n) -> np.ndarray:\r\n    \"\"\"\r\n    Transform label or iterable of labels to array, for use in Index.\r\n\r\n    Parameters\r\n    ----------\r\n    dtype : dtype\r\n        If specified, use as dtype of the resulting array, otherwise infer.\r\n\r\n    Returns\r\n    -------\r\n    array\r\n    \"\"\"\r\n    if isinstance(labels, (str, tuple)):\r\n        labels = [labels]\r\n\r\n    if not isinstance(labels, (list, np.ndarray)):\r\n        try:\r\n            labels = list(labels)\r\n        except TypeError:  # non-iterable\r\n            labels = [labels]\r\n\r\n    labels = asarray_tuplesafe(labels, dtype=dtype)\r\n\r\n    return labels\r\n\r\n\r\ndef maybe_make_list(obj):\r\n    if obj is not None and not isinstance(obj, (tuple, list)):\r\n        return [obj]\r\n    return obj\r\n\r\n\r\ndef maybe_iterable_to_list(obj: Iterable[T] | T) -> Collection[T] | T:\r\n    \"\"\"\r\n    If obj is Iterable but not list-like, consume into list.\r\n    \"\"\"\r\n    if isinstance(obj, abc.Iterable) and not isinstance(obj, abc.Sized):\r\n        return list(obj)\r\n    obj = cast(Collection, obj)\r\n    return obj\r\n\r\n\r\ndef is_null_slice(obj) -> bool:\r\n    \"\"\"\r\n    We have a null slice.\r\n    \"\"\"\r\n    return (\r\n        isinstance(obj, slice)\r\n        and obj.start is None\r\n        and obj.stop is None\r\n        and obj.step is None\r\n    )\r\n\r\n\r\ndef is_empty_slice(obj) -> bool:\r\n    \"\"\"\r\n    We have an empty slice, e.g. no values are selected.\r\n    \"\"\"\r\n    return (\r\n        isinstance(obj, slice)\r\n        and obj.start is not None\r\n        and obj.stop is not None\r\n        and obj.start == obj.stop\r\n    )\r\n\r\n\r\ndef is_true_slices(line) -> list[bool]:\r\n    \"\"\"\r\n    Find non-trivial slices in \"line\": return a list of booleans with same length.\r\n    \"\"\"\r\n    return [isinstance(k, slice) and not is_null_slice(k) for k in line]\r\n\r\n\r\n# TODO: used only once in indexing; belongs elsewhere?\r\ndef is_full_slice(obj, line: int) -> bool:\r\n    \"\"\"\r\n    We have a full length slice.\r\n    \"\"\"\r\n    return (\r\n        isinstance(obj, slice)\r\n        and obj.start == 0\r\n        and obj.stop == line\r\n        and obj.step is None\r\n    )\r\n\r\n\r\ndef get_callable_name(obj):\r\n    # typical case has name\r\n    if hasattr(obj, \"__name__\"):\r\n        return getattr(obj, \"__name__\")\r\n    # some objects don't; could recurse\r\n    if isinstance(obj, partial):\r\n        return get_callable_name(obj.func)\r\n    # fall back to class name\r\n    if callable(obj):\r\n        return type(obj).__name__\r\n    # everything failed (probably because the argument\r\n    # wasn't actually callable); we return None\r\n    # instead of the empty string in this case to allow\r\n    # distinguishing between no name and a name of ''\r\n    return None\r\n\r\n\r\ndef apply_if_callable(maybe_callable, obj, **kwargs):\r\n    \"\"\"\r\n    Evaluate possibly callable input using obj and kwargs if it is callable,\r\n    otherwise return as it is.\r\n\r\n    Parameters\r\n    ----------\r\n    maybe_callable : possibly a callable\r\n    obj : NDFrame\r\n    **kwargs\r\n    \"\"\"\r\n    if callable(maybe_callable):\r\n        return maybe_callable(obj, **kwargs)\r\n\r\n    return maybe_callable\r\n\r\n\r\ndef standardize_mapping(into):\r\n    \"\"\"\r\n    Helper function to standardize a supplied mapping.\r\n\r\n    Parameters\r\n    ----------\r\n    into : instance or subclass of collections.abc.Mapping\r\n        Must be a class, an initialized collections.defaultdict,\r\n        or an instance of a collections.abc.Mapping subclass.\r\n\r\n    Returns\r\n    -------\r\n    mapping : a collections.abc.Mapping subclass or other constructor\r\n        a callable object that can accept an iterator to create\r\n        the desired Mapping.\r\n\r\n    See Also\r\n    --------\r\n    DataFrame.to_dict\r\n    Series.to_dict\r\n    \"\"\"\r\n    if not inspect.isclass(into):\r\n        if isinstance(into, defaultdict):\r\n            return partial(defaultdict, into.default_factory)\r\n        into = type(into)\r\n    if not issubclass(into, abc.Mapping):\r\n        raise TypeError(f\"unsupported type: {into}\")\r\n    if into == defaultdict:\r\n        raise TypeError(\"to_dict() only accepts initialized defaultdicts\")\r\n"]
[150.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[150.002, "i", "sed -n '3920,4080p' ../pandas/core/frame.py\r"]
[150.004, "o", "sed -n '3920,4080p' ../pandas/core/frame.py\r\n"]
[150.006, "o", "\u001b[?2004l\r\n        if is_single_key:\r\n            # What does looking for a single key in a non-unique index return?\r\n            # The behavior is inconsistent. It returns a Series, except when\r\n            # - the key itself is repeated (test on data.shape, #9519), or\r\n            # - we have a MultiIndex on columns (test on self.columns, #21309)\r\n            if data.shape[1] == 1 and not isinstance(self.columns, MultiIndex):\r\n                # GH#26490 using data[key] can cause RecursionError\r\n                return data._get_item(key)\r\n\r\n        return data\r\n\r\n    def _getitem_bool_array(self, key):\r\n        # also raises Exception if object array with NA values\r\n        # warning here just in case -- previously __setitem__ was\r\n        # reindexing but __getitem__ was not; it seems more reasonable to\r\n        # go with the __setitem__ behavior since that is more consistent\r\n        # with all other indexing behavior\r\n        if isinstance(key, Series) and not key.index.equals(self.index):\r\n            warnings.warn(\r\n                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n                UserWarning,\r\n                stacklevel=find_stack_level(),\r\n            )\r\n        elif len(key) != len(self.index):\r\n            raise ValueError(\r\n                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n            )\r\n\r\n        # check_bool_indexer will throw exception if Series key cannot\r\n        # be reindexed to match DataFrame rows\r\n        key = check_bool_indexer(self.index, key)\r\n\r\n        if key.all():\r\n            return self.copy(deep=False)\r\n\r\n        indexer = key.nonzero()[0]\r\n        return self.take(indexer, axis=0)\r\n\r\n    def _getitem_multilevel(self, key):\r\n        # self.columns is a MultiIndex\r\n        loc = self.columns.get_loc(key)\r\n        if isinstance(loc, (slice, np.ndarray)):\r\n            new_columns = self.columns[loc]\r\n            result_columns = maybe_droplevels(new_columns, key)\r\n            result = self.iloc[:, loc]\r\n            result.columns = result_columns\r\n\r\n            # If there is only one column being returned, and its name is\r\n            # either an empty string, or a tuple with an empty string as its\r\n            # first element, then treat the empty string as a placeholder\r\n            # and return the column as if the user had provided that empty\r\n            # string in the key. If the result is a Series, exclude the\r\n            # implied empty string from its name.\r\n            if len(result.columns) == 1:\r\n                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n                top = result.columns[0]\r\n                if isinstance(top, tuple):\r\n                    top = top[0]\r\n                if top == \"\":\r\n                    result = result[\"\"]\r\n                    if isinstance(result, Series):\r\n                        result = self._constructor_sliced(\r\n                            result, index=self.index, name=key\r\n                        )\r\n\r\n            return result\r\n        else:\r\n            # loc is neither a slice nor ndarray, so must be an int\r\n            return self._ixs(loc, axis=1)\r\n\r\n    def _get_value(self, index, col, takeable: bool = False) -> Scalar:\r\n        \"\"\"\r\n        Quickly retrieve single value at passed column and index.\r\n\r\n        Parameters\r\n        ----------\r\n        index : row label\r\n        col : column label\r\n        takeable : interpret the index/col as indexers, default False\r\n\r\n        Returns\r\n        -------\r\n        scalar\r\n\r\n        Notes\r\n        -----\r\n        Assumes that both `self.index._index_as_unique` and\r\n        `self.columns._index_as_unique`; Caller is responsible for checking.\r\n        \"\"\"\r\n        if takeable:\r\n            series = self._ixs(col, axis=1)\r\n            return series._values[index]\r\n\r\n        series = self._get_item(col)\r\n        engine = self.index._engine\r\n\r\n        if not isinstance(self.index, MultiIndex):\r\n            # CategoricalIndex: Trying to use the engine fastpath may give incorrect\r\n            #  results if our categories are integers that dont match our codes\r\n            # IntervalIndex: IntervalTree has no get_loc\r\n            row = self.index.get_loc(index)\r\n            return series._values[row]\r\n\r\n        # For MultiIndex going through engine effectively restricts us to\r\n        #  same-length tuples; see test_get_set_value_no_partial_indexing\r\n        loc = engine.get_loc(index)\r\n        return series._values[loc]\r\n\r\n    def isetitem(self, loc, value) -> None:\r\n        \"\"\"\r\n        Set the given value in the column with position `loc`.\r\n\r\n        This is a positional analogue to ``__setitem__``.\r\n\r\n        Parameters\r\n        ----------\r\n        loc : int or sequence of ints\r\n            Index position for the column.\r\n        value : scalar or arraylike\r\n            Value(s) for the column.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.iloc : Purely integer-location based indexing for selection by\r\n            position.\r\n\r\n        Notes\r\n        -----\r\n        ``frame.isetitem(loc, value)`` is an in-place method as it will\r\n        modify the DataFrame in place (not returning a new object). In contrast to\r\n        ``frame.iloc[:, i] = value`` which will try to update the existing values in\r\n        place, ``frame.isetitem(loc, value)`` will not update the values of the column\r\n        itself in place, it will instead insert a new array.\r\n\r\n        In cases where ``frame.columns`` is unique, this is equivalent to\r\n        ``frame[frame.columns[i]] = value``.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n        >>> df.isetitem(1, [5, 6])\r\n        >>> df\r\n              A  B\r\n        0     1  5\r\n        1     2  6\r\n        \"\"\"\r\n        if isinstance(value, DataFrame):\r\n            if is_integer(loc):\r\n                loc = [loc]\r\n\r\n            if len(loc) != len(value.columns):\r\n                raise ValueError(\r\n                    f\"Got {len(loc)} positions but value has {len(value.columns)} \"\r\n                    f\"columns.\"\r\n                )\r\n\r\n            for i, idx in enumerate(loc):\r\n                arraylike, refs = self._sanitize_column(value.iloc[:, i])\r\n                self._iset_item_mgr(idx, arraylike, inplace=False, refs=refs)\r\n            return\r\n"]
[155.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[155.002, "i", "sed -n '4080,4280p' ../pandas/core/frame.py\r"]
[155.004, "o", "sed -n '4080,4280p' ../pandas/core/frame.py\r\n"]
[155.006, "o", "\u001b[?2004l\r\n            return\r\n\r\n        arraylike, refs = self._sanitize_column(value)\r\n        self._iset_item_mgr(loc, arraylike, inplace=False, refs=refs)\r\n\r\n    def __setitem__(self, key, value) -> None:\r\n        if not PYPY:\r\n            if sys.getrefcount(self) <= 3:\r\n                warnings.warn(\r\n                    _chained_assignment_msg, ChainedAssignmentError, stacklevel=2\r\n                )\r\n\r\n        key = com.apply_if_callable(key, self)\r\n\r\n        # see if we can slice the rows\r\n        if isinstance(key, slice):\r\n            slc = self.index._convert_slice_indexer(key, kind=\"getitem\")\r\n            return self._setitem_slice(slc, value)\r\n\r\n        if isinstance(key, DataFrame) or getattr(key, \"ndim\", None) == 2:\r\n            self._setitem_frame(key, value)\r\n        elif isinstance(key, (Series, np.ndarray, list, Index)):\r\n            self._setitem_array(key, value)\r\n        elif isinstance(value, DataFrame):\r\n            self._set_item_frame_value(key, value)\r\n        elif (\r\n            is_list_like(value)\r\n            and not self.columns.is_unique\r\n            and 1 < len(self.columns.get_indexer_for([key])) == len(value)\r\n        ):\r\n            # Column to set is duplicated\r\n            self._setitem_array([key], value)\r\n        else:\r\n            # set column\r\n            self._set_item(key, value)\r\n\r\n    def _setitem_slice(self, key: slice, value) -> None:\r\n        # NB: we can't just use self.loc[key] = value because that\r\n        #  operates on labels and we need to operate positional for\r\n        #  backwards-compat, xref GH#31469\r\n        self.iloc[key] = value\r\n\r\n    def _setitem_array(self, key, value) -> None:\r\n        # also raises Exception if object array with NA values\r\n        if com.is_bool_indexer(key):\r\n            # bool indexer is indexing along rows\r\n            if len(key) != len(self.index):\r\n                raise ValueError(\r\n                    f\"Item wrong length {len(key)} instead of {len(self.index)}!\"\r\n                )\r\n            key = check_bool_indexer(self.index, key)\r\n            indexer = key.nonzero()[0]\r\n            if isinstance(value, DataFrame):\r\n                # GH#39931 reindex since iloc does not align\r\n                value = value.reindex(self.index.take(indexer))\r\n            self.iloc[indexer] = value\r\n\r\n        else:\r\n            # Note: unlike self.iloc[:, indexer] = value, this will\r\n            #  never try to overwrite values inplace\r\n\r\n            if isinstance(value, DataFrame):\r\n                check_key_length(self.columns, key, value)\r\n                for k1, k2 in zip(key, value.columns):\r\n                    self[k1] = value[k2]\r\n\r\n            elif not is_list_like(value):\r\n                for col in key:\r\n                    self[col] = value\r\n\r\n            elif isinstance(value, np.ndarray) and value.ndim == 2:\r\n                self._iset_not_inplace(key, value)\r\n\r\n            elif np.ndim(value) > 1:\r\n                # list of lists\r\n                value = DataFrame(value).values\r\n                self._setitem_array(key, value)\r\n\r\n            else:\r\n                self._iset_not_inplace(key, value)\r\n\r\n    def _iset_not_inplace(self, key, value) -> None:\r\n        # GH#39510 when setting with df[key] = obj with a list-like key and\r\n        #  list-like value, we iterate over those listlikes and set columns\r\n        #  one at a time.  This is different from dispatching to\r\n        #  `self.loc[:, key]= value`  because loc.__setitem__ may overwrite\r\n        #  data inplace, whereas this will insert new arrays.\r\n\r\n        def igetitem(obj, i: int):\r\n            # Note: we catch DataFrame obj before getting here, but\r\n            #  hypothetically would return obj.iloc[:, i]\r\n            if isinstance(obj, np.ndarray):\r\n                return obj[..., i]\r\n            else:\r\n                return obj[i]\r\n\r\n        if self.columns.is_unique:\r\n            if np.shape(value)[-1] != len(key):\r\n                raise ValueError(\"Columns must be same length as key\")\r\n\r\n            for i, col in enumerate(key):\r\n                self[col] = igetitem(value, i)\r\n\r\n        else:\r\n            ilocs = self.columns.get_indexer_non_unique(key)[0]\r\n            if (ilocs < 0).any():\r\n                # key entries not in self.columns\r\n                raise NotImplementedError\r\n\r\n            if np.shape(value)[-1] != len(ilocs):\r\n                raise ValueError(\"Columns must be same length as key\")\r\n\r\n            assert np.ndim(value) <= 2\r\n\r\n            orig_columns = self.columns\r\n\r\n            # Using self.iloc[:, i] = ... may set values inplace, which\r\n            #  by convention we do not do in __setitem__\r\n            try:\r\n                self.columns = Index(range(len(self.columns)))\r\n                for i, iloc in enumerate(ilocs):\r\n                    self[iloc] = igetitem(value, i)\r\n            finally:\r\n                self.columns = orig_columns\r\n\r\n    def _setitem_frame(self, key, value) -> None:\r\n        # support boolean setting with DataFrame input, e.g.\r\n        # df[df > df2] = 0\r\n        if isinstance(key, np.ndarray):\r\n            if key.shape != self.shape:\r\n                raise ValueError(\"Array conditional must be same shape as self\")\r\n            key = self._constructor(key, **self._construct_axes_dict(), copy=False)\r\n\r\n        if key.size and not all(is_bool_dtype(dtype) for dtype in key.dtypes):\r\n            raise TypeError(\r\n                \"Must pass DataFrame or 2-d ndarray with boolean values only\"\r\n            )\r\n\r\n        self._where(-key, value, inplace=True)\r\n\r\n    def _set_item_frame_value(self, key, value: DataFrame) -> None:\r\n        self._ensure_valid_index(value)\r\n\r\n        # align columns\r\n        if key in self.columns:\r\n            loc = self.columns.get_loc(key)\r\n            cols = self.columns[loc]\r\n            len_cols = 1 if is_scalar(cols) or isinstance(cols, tuple) else len(cols)\r\n            if len_cols != len(value.columns):\r\n                raise ValueError(\"Columns must be same length as key\")\r\n\r\n            # align right-hand-side columns if self.columns\r\n            # is multi-index and self[key] is a sub-frame\r\n            if isinstance(self.columns, MultiIndex) and isinstance(\r\n                loc, (slice, Series, np.ndarray, Index)\r\n            ):\r\n                cols_droplevel = maybe_droplevels(cols, key)\r\n                if len(cols_droplevel) and not cols_droplevel.equals(value.columns):\r\n                    value = value.reindex(cols_droplevel, axis=1)\r\n\r\n                for col, col_droplevel in zip(cols, cols_droplevel):\r\n                    self[col] = value[col_droplevel]\r\n                return\r\n\r\n            if is_scalar(cols):\r\n                self[cols] = value[value.columns[0]]\r\n                return\r\n\r\n            locs: np.ndarray | list\r\n            if isinstance(loc, slice):\r\n                locs = np.arange(loc.start, loc.stop, loc.step)\r\n            elif is_scalar(loc):\r\n                locs = [loc]\r\n            else:\r\n                locs = loc.nonzero()[0]\r\n\r\n            return self.isetitem(locs, value)\r\n\r\n        if len(value.columns) > 1:\r\n            raise ValueError(\r\n                \"Cannot set a DataFrame with multiple columns to the single \"\r\n                f\"column {key}\"\r\n            )\r\n        elif len(value.columns) == 0:\r\n            raise ValueError(\r\n                f\"Cannot set a DataFrame without columns to the column {key}\"\r\n            )\r\n\r\n        self[key] = value[value.columns[0]]\r\n\r\n    def _iset_item_mgr(\r\n        self,\r\n        loc: int | slice | np.ndarray,\r\n        value,\r\n        inplace: bool = False,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> None:\r\n        # when called from _set_item_mgr loc can be anything returned from get_loc\r\n        self._mgr.iset(loc, value, inplace=inplace, refs=refs)\r\n\r\n    def _set_item_mgr(\r\n"]
[160.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[160.002, "i", "sed -n '1,260p' ../pandas/core/common.py\r"]
[160.004, "o", "sed -n '1,260p' ../pandas/core/common.py\r\n"]
[160.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nMisc tools for implementing data structures\r\n\r\nNote: pandas.core.common is *not* part of the public API.\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport builtins\r\nfrom collections import (\r\n    abc,\r\n    defaultdict,\r\n)\r\nfrom collections.abc import (\r\n    Collection,\r\n    Generator,\r\n    Hashable,\r\n    Iterable,\r\n    Sequence,\r\n)\r\nimport contextlib\r\nfrom functools import partial\r\nimport inspect\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Callable,\r\n    TypeVar,\r\n    cast,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas.compat.numpy import np_version_gte1p24\r\n\r\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\r\nfrom pandas.core.dtypes.common import (\r\n    is_bool_dtype,\r\n    is_integer,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCExtensionArray,\r\n    ABCIndex,\r\n    ABCMultiIndex,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import iterable_not_string\r\n\r\nif TYPE_CHECKING:\r\n    from pandas._typing import (\r\n        AnyArrayLike,\r\n        ArrayLike,\r\n        Concatenate,\r\n        NpDtype,\r\n        P,\r\n        RandomState,\r\n        T,\r\n    )\r\n\r\n    from pandas import Index\r\n\r\n\r\ndef flatten(line):\r\n    \"\"\"\r\n    Flatten an arbitrarily nested sequence.\r\n\r\n    Parameters\r\n    ----------\r\n    line : sequence\r\n        The non string sequence to flatten\r\n\r\n    Notes\r\n    -----\r\n    This doesn't consider strings sequences.\r\n\r\n    Returns\r\n    -------\r\n    flattened : generator\r\n    \"\"\"\r\n    for element in line:\r\n        if iterable_not_string(element):\r\n            yield from flatten(element)\r\n        else:\r\n            yield element\r\n\r\n\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is not None.\r\n    \"\"\"\r\n    return any(arg is not None for arg in args)\r\n\r\n\r\ndef all_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are not None.\r\n    \"\"\"\r\n    return all(arg is not None for arg in args)\r\n\r\n\r\ndef count_not_none(*args) -> int:\r\n    \"\"\"\r\n    Returns the count of arguments that are not None.\r\n    \"\"\"\r\n    return sum(x is not None for x in args)\r\n\r\n\r\n@overload\r\ndef asarray_tuplesafe(\r\n    values: ArrayLike | list | tuple | zip, dtype: NpDtype | None = ...\r\n) -> np.ndarray:\r\n    # ExtensionArray can only be returned when values is an Index, all other iterables\r\n    # will return np.ndarray. Unfortunately \"all other\" cannot be encoded in a type\r\n    # signature, so instead we special-case some common types.\r\n    ...\r\n\r\n\r\n@overload\r\ndef asarray_tuplesafe(values: Iterable, dtype: NpDtype | None = ...) -> ArrayLike: ...\r\n\r\n\r\ndef asarray_tuplesafe(values: Iterable, dtype: NpDtype | None = None) -> ArrayLike:\r\n    if not (isinstance(values, (list, tuple)) or hasattr(values, \"__array__\")):\r\n        values = list(values)\r\n    elif isinstance(values, ABCIndex):\r\n        return values._values\r\n    elif isinstance(values, ABCSeries):\r\n        return values._values\r\n\r\n    if isinstance(values, list) and dtype in [np.object_, object]:\r\n        return construct_1d_object_array_from_listlike(values)\r\n\r\n    try:\r\n        with warnings.catch_warnings():\r\n            # Can remove warning filter once NumPy 1.24 is min version\r\n            if not np_version_gte1p24:\r\n                warnings.simplefilter(\"ignore\", np.VisibleDeprecationWarning)\r\n            result = np.asarray(values, dtype=dtype)\r\n    except ValueError:\r\n        # Using try/except since it's more performant than checking is_list_like\r\n        # over each element\r\n        # error: Argument 1 to \"construct_1d_object_array_from_listlike\"\r\n        # has incompatible type \"Iterable[Any]\"; expected \"Sized\"\r\n        return construct_1d_object_array_from_listlike(values)  # type: ignore[arg-type]\r\n\r\n    if issubclass(result.dtype.type, str):\r\n        result = np.asarray(values, dtype=object)\r\n\r\n"]
[165.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[165.002, "i", "sed -n '260,520p' ../pandas/core/common.py\r"]
[165.004, "o", "sed -n '260,520p' ../pandas/core/common.py\r\n"]
[165.006, "o", "\u001b[?2004l\r\n\r\n    if result.ndim == 2:\r\n        # Avoid building an array of arrays:\r\n        values = [tuple(x) for x in values]\r\n        result = construct_1d_object_array_from_listlike(values)\r\n\r\n    return result\r\n\r\n\r\ndef index_labels_to_array(\r\n    labels: np.ndarray | Iterable, dtype: NpDtype | None = None\r\n) -> np.ndarray:\r\n    \"\"\"\r\n    Transform label or iterable of labels to array, for use in Index.\r\n\r\n    Parameters\r\n    ----------\r\n    dtype : dtype\r\n        If specified, use as dtype of the resulting array, otherwise infer.\r\n\r\n    Returns\r\n    -------\r\n    array\r\n    \"\"\"\r\n    if isinstance(labels, (str, tuple)):\r\n        labels = [labels]\r\n\r\n    if not isinstance(labels, (list, np.ndarray)):\r\n        try:\r\n            labels = list(labels)\r\n        except TypeError:  # non-iterable\r\n            labels = [labels]\r\n\r\n    labels = asarray_tuplesafe(labels, dtype=dtype)\r\n\r\n    return labels\r\n\r\n\r\ndef maybe_make_list(obj):\r\n    if obj is not None and not isinstance(obj, (tuple, list)):\r\n        return [obj]\r\n    return obj\r\n\r\n\r\ndef maybe_iterable_to_list(obj: Iterable[T] | T) -> Collection[T] | T:\r\n    \"\"\"\r\n    If obj is Iterable but not list-like, consume into list.\r\n    \"\"\"\r\n    if isinstance(obj, abc.Iterable) and not isinstance(obj, abc.Sized):\r\n        return list(obj)\r\n    obj = cast(Collection, obj)\r\n    return obj\r\n\r\n\r\ndef is_null_slice(obj) -> bool:\r\n    \"\"\"\r\n    We have a null slice.\r\n    \"\"\"\r\n    return (\r\n        isinstance(obj, slice)\r\n        and obj.start is None\r\n        and obj.stop is None\r\n        and obj.step is None\r\n    )\r\n\r\n\r\ndef is_empty_slice(obj) -> bool:\r\n    \"\"\"\r\n    We have an empty slice, e.g. no values are selected.\r\n    \"\"\"\r\n    return (\r\n        isinstance(obj, slice)\r\n        and obj.start is not None\r\n        and obj.stop is not None\r\n        and obj.start == obj.stop\r\n    )\r\n\r\n\r\ndef is_true_slices(line) -> list[bool]:\r\n    \"\"\"\r\n    Find non-trivial slices in \"line\": return a list of booleans with same length.\r\n    \"\"\"\r\n    return [isinstance(k, slice) and not is_null_slice(k) for k in line]\r\n\r\n\r\n# TODO: used only once in indexing; belongs elsewhere?\r\ndef is_full_slice(obj, line: int) -> bool:\r\n    \"\"\"\r\n    We have a full length slice.\r\n    \"\"\"\r\n    return (\r\n        isinstance(obj, slice)\r\n        and obj.start == 0\r\n        and obj.stop == line\r\n        and obj.step is None\r\n    )\r\n\r\n\r\ndef get_callable_name(obj):\r\n    # typical case has name\r\n    if hasattr(obj, \"__name__\"):\r\n        return getattr(obj, \"__name__\")\r\n    # some objects don't; could recurse\r\n    if isinstance(obj, partial):\r\n        return get_callable_name(obj.func)\r\n    # fall back to class name\r\n    if callable(obj):\r\n        return type(obj).__name__\r\n    # everything failed (probably because the argument\r\n    # wasn't actually callable); we return None\r\n    # instead of the empty string in this case to allow\r\n    # distinguishing between no name and a name of ''\r\n    return None\r\n\r\n\r\ndef apply_if_callable(maybe_callable, obj, **kwargs):\r\n    \"\"\"\r\n    Evaluate possibly callable input using obj and kwargs if it is callable,\r\n    otherwise return as it is.\r\n\r\n    Parameters\r\n    ----------\r\n    maybe_callable : possibly a callable\r\n    obj : NDFrame\r\n    **kwargs\r\n    \"\"\"\r\n    if callable(maybe_callable):\r\n        return maybe_callable(obj, **kwargs)\r\n\r\n    return maybe_callable\r\n\r\n\r\ndef standardize_mapping(into):\r\n    \"\"\"\r\n    Helper function to standardize a supplied mapping.\r\n\r\n    Parameters\r\n    ----------\r\n    into : instance or subclass of collections.abc.Mapping\r\n        Must be a class, an initialized collections.defaultdict,\r\n        or an instance of a collections.abc.Mapping subclass.\r\n\r\n    Returns\r\n    -------\r\n    mapping : a collections.abc.Mapping subclass or other constructor\r\n        a callable object that can accept an iterator to create\r\n        the desired Mapping.\r\n\r\n    See Also\r\n    --------\r\n    DataFrame.to_dict\r\n    Series.to_dict\r\n    \"\"\"\r\n    if not inspect.isclass(into):\r\n        if isinstance(into, defaultdict):\r\n            return partial(defaultdict, into.default_factory)\r\n        into = type(into)\r\n    if not issubclass(into, abc.Mapping):\r\n        raise TypeError(f\"unsupported type: {into}\")\r\n    if into == defaultdict:\r\n        raise TypeError(\"to_dict() only accepts initialized defaultdicts\")\r\n    return into\r\n\r\n\r\n@overload\r\ndef random_state(state: np.random.Generator) -> np.random.Generator: ...\r\n\r\n\r\n@overload\r\ndef random_state(\r\n    state: int | np.ndarray | np.random.BitGenerator | np.random.RandomState | None,\r\n) -> np.random.RandomState: ...\r\n\r\n\r\ndef random_state(state: RandomState | None = None):\r\n    \"\"\"\r\n    Helper function for processing random_state arguments.\r\n\r\n    Parameters\r\n    ----------\r\n    state : int, array-like, BitGenerator, Generator, np.random.RandomState, None.\r\n        If receives an int, array-like, or BitGenerator, passes to\r\n        np.random.RandomState() as seed.\r\n        If receives an np.random RandomState or Generator, just returns that unchanged.\r\n        If receives `None`, returns np.random.\r\n        If receives anything else, raises an informative ValueError.\r\n\r\n        Default None.\r\n\r\n    Returns\r\n    -------\r\n    np.random.RandomState or np.random.Generator. If state is None, returns np.random\r\n\r\n    \"\"\"\r\n    if is_integer(state) or isinstance(state, (np.ndarray, np.random.BitGenerator)):\r\n        return np.random.RandomState(state)\r\n    elif isinstance(state, np.random.RandomState):\r\n        return state\r\n    elif isinstance(state, np.random.Generator):\r\n        return state\r\n    elif state is None:\r\n        return np.random\r\n    else:\r\n        raise ValueError(\r\n            \"random_state must be an integer, array-like, a BitGenerator, Generator, \"\r\n            \"a numpy RandomState, or None\"\r\n        )\r\n\r\n\r\n_T = TypeVar(\"_T\")  # Secondary TypeVar for use in pipe's type hints\r\n\r\n\r\n@overload\r\ndef pipe(\r\n    obj: _T,\r\n    func: Callable[Concatenate[_T, P], T],\r\n    *args: P.args,\r\n    **kwargs: P.kwargs,\r\n) -> T: ...\r\n\r\n\r\n@overload\r\ndef pipe(\r\n    obj: Any,\r\n    func: tuple[Callable[..., T], str],\r\n    *args: Any,\r\n    **kwargs: Any,\r\n) -> T: ...\r\n\r\n\r\ndef pipe(\r\n    obj: _T,\r\n    func: Callable[Concatenate[_T, P], T] | tuple[Callable[..., T], str],\r\n    *args: Any,\r\n    **kwargs: Any,\r\n) -> T:\r\n    \"\"\"\r\n    Apply a function ``func`` to object ``obj`` either by passing obj as the\r\n    first argument to the function or, in the case that the func is a tuple,\r\n    interpret the first element of the tuple as a function and pass the obj to\r\n    that function as a keyword argument whose key is the value of the second\r\n    element of the tuple.\r\n\r\n    Parameters\r\n    ----------\r\n    func : callable or tuple of (callable, str)\r\n        Function to apply to this object or, alternatively, a\r\n        ``(callable, data_keyword)`` tuple where ``data_keyword`` is a\r\n        string indicating the keyword of ``callable`` that expects the\r\n        object.\r\n    *args : iterable, optional\r\n        Positional arguments passed into ``func``.\r\n    **kwargs : dict, optional\r\n        A dictionary of keyword arguments passed into ``func``.\r\n\r\n    Returns\r\n    -------\r\n    object : the return type of ``func``.\r\n    \"\"\"\r\n    if isinstance(func, tuple):\r\n        # Assigning to func_ so pyright understands that it's a callable\r\n"]
[170.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[170.002, "i", "grep -n \"def _getitem_bool_array\" -n ../pandas/core/frame.py\r"]
[170.004, "o", "grep -n \"def _getitem_bool_array\" -n ../pandas/core/frame.py\r\n"]
[170.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K3931\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef _getitem_bool_array\u001b[m\u001b[K(self, key):\r\n"]
[175.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[175.002, "i", "grep -n \"def is_bool_indexer\" ../pandas/core/common.py\r"]
[175.004, "o", "grep -n \"def is_bool_indexer\" ../pandas/core/common.py\r\n"]
[175.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K101\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kdef is_bool_indexer\u001b[m\u001b[K(key: Any) -> bool:\r\n"]
[180.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[180.002, "i", "grep -n \"def check_bool_indexer\" ../pandas/core/indexing.py\r"]
[180.004, "o", "grep -n \"def check_bool_indexer\" ../pandas/core/indexing.py\r\n"]
[180.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K2612\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kdef check_bool_indexer\u001b[m\u001b[K(index: Index, key) -> np.ndarray:\r\n"]
[185.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[185.002, "i", "sed -n '1,500p' ../pandas/core/indexing.py | sed -n '2400,2700p'\r"]
[185.004, "o", "sed -n '1,500p' ../pandas/core/indexing.py | sed -n '2400,2700p'\r\n"]
[185.006, "o", "\u001b[?2004l\r\n"]
[190.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[190.002, "i", "awk 'NR>=1 && NR<=12000 && /def _getitem_bool_array/{start=NR-5} NR>=start && NR<=start+120 {print NR\":\"$\r"]
[190.004, "o", "awk 'NR>=1 && NR<=12000 && /def _getitem_bool_array/{start=NR-5} NR>=start && NR<=start+120 {print NR\":\"$\r\n"]
[190.006, "o", "$0}' ../pandas/core/frame.py\r\n\u001b[?2004l\r\n1:\"\"\"\r\n2:DataFrame\r\n3:---------\r\n4:An efficient 2D container for potentially mixed-type time series or other\r\n5:labeled data series.\r\n6:\r\n7:Similar to its R counterpart, data.frame, except providing automatic data\r\n8:alignment and a host of useful data manipulation methods having to do with the\r\n9:labeling information\r\n10:\"\"\"\r\n11:\r\n12:from __future__ import annotations\r\n13:\r\n14:import collections\r\n15:from collections import abc\r\n16:from collections.abc import (\r\n17:    Hashable,\r\n18:    Iterable,\r\n19:    Iterator,\r\n20:    Mapping,\r\n21:    Sequence,\r\n22:)\r\n23:import functools\r\n24:from inspect import signature\r\n25:from io import StringIO\r\n26:import itertools\r\n27:import operator\r\n28:import sys\r\n29:from textwrap import dedent\r\n30:from typing import (\r\n31:    TYPE_CHECKING,\r\n32:    Any,\r\n33:    Callable,\r\n34:    Literal,\r\n35:    cast,\r\n36:    overload,\r\n37:)\r\n38:import warnings\r\n39:\r\n40:import numpy as np\r\n41:from numpy import ma\r\n42:\r\n43:from pandas._config import get_option\r\n44:\r\n45:from pandas._libs import (\r\n46:    algos as libalgos,\r\n47:    lib,\r\n48:    properties,\r\n49:)\r\n50:from pandas._libs.hashtable import duplicated\r\n51:from pandas._libs.lib import is_range_indexer\r\n52:from pandas.compat import PYPY\r\n53:from pandas.compat._constants import REF_COUNT\r\n54:from pandas.compat._optional import import_optional_dependency\r\n55:from pandas.compat.numpy import function as nv\r\n56:from pandas.errors import (\r\n57:    ChainedAssignmentError,\r\n58:    InvalidIndexError,\r\n59:)\r\n60:from pandas.errors.cow import (\r\n61:    _chained_assignment_method_msg,\r\n62:    _chained_assignment_msg,\r\n63:)\r\n64:from pandas.util._decorators import (\r\n65:    Appender,\r\n66:    Substitution,\r\n67:    deprecate_nonkeyword_arguments,\r\n68:    doc,\r\n69:    set_module,\r\n70:)\r\n71:from pandas.util._exceptions import (\r\n72:    find_stack_level,\r\n73:    rewrite_warning,\r\n74:)\r\n75:from pandas.util._validators import (\r\n76:    validate_ascending,\r\n77:    validate_bool_kwarg,\r\n78:    validate_percentile,\r\n79:)\r\n80:\r\n81:from pandas.core.dtypes.cast import (\r\n82:    LossySetitemError,\r\n83:    can_hold_element,\r\n84:    construct_1d_arraylike_from_scalar,\r\n85:    construct_2d_arraylike_from_scalar,\r\n86:    find_common_type,\r\n87:    infer_dtype_from_scalar,\r\n88:    invalidate_string_dtypes,\r\n89:    maybe_downcast_to_dtype,\r\n90:)\r\n91:from pandas.core.dtypes.common import (\r\n92:    infer_dtype_from_object,\r\n93:    is_1d_only_ea_dtype,\r\n94:    is_array_like,\r\n95:    is_bool_dtype,\r\n96:    is_dataclass,\r\n97:    is_dict_like,\r\n98:    is_float,\r\n99:    is_float_dtype,\r\n100:    is_hashable,\r\n101:    is_integer,\r\n102:    is_integer_dtype,\r\n103:    is_iterator,\r\n104:    is_list_like,\r\n105:    is_scalar,\r\n106:    is_sequence,\r\n107:    needs_i8_conversion,\r\n108:    pandas_dtype,\r\n109:)\r\n110:from pandas.core.dtypes.concat import concat_compat\r\n111:from pandas.core.dtypes.dtypes import (\r\n112:    ArrowDtype,\r\n113:    BaseMaskedDtype,\r\n114:    ExtensionDtype,\r\n115:)\r\n116:from pandas.core.dtypes.missing import (\r\n117:    isna,\r\n118:    notna,\r\n119:)\r\n120:\r\n3931:    def _getitem_bool_array(self, key):\r\n3932:        # also raises Exception if object array with NA values\r\n3933:        # warning here just in case -- previously __setitem__ was\r\n3934:        # reindexing but __getitem__ was not; it seems more reasonable to\r\n3935:        # go with the __setitem__ behavior since that is more consistent\r\n3936:        # with all other indexing behavior\r\n3937:        if isinstance(key, Series) and not key.index.equals(self.index):\r\n3938:            warnings.warn(\r\n3939:                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n3940:                UserWarning,\r\n3941:                stacklevel=find_stack_level(),\r\n3942:            )\r\n3943:        elif len(key) != len(self.index):\r\n3944:            raise ValueError(\r\n3945:                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n3946:            )\r\n3947:\r\n3948:        # check_bool_indexer will throw exception if Series key cannot\r\n3949:        # be reindexed to match DataFrame rows\r\n3950:        key = check_bool_indexer(self.index, key)\r\n3951:\r\n3952:        if key.all():\r\n3953:            return self.copy(deep=False)\r\n3954:\r\n3955:        indexer = key.nonzero()[0]\r\n3956:        return self.take(indexer, axis=0)\r\n3957:\r\n3958:    def _getitem_multilevel(self, key):\r\n3959:        # self.columns is a MultiIndex\r\n3960:        loc = self.columns.get_loc(key)\r\n3961:        if isinstance(loc, (slice, np.ndarray)):\r\n3962:            new_columns = self.columns[loc]\r\n3963:            result_columns = maybe_droplevels(new_columns, key)\r\n3964:            result = self.iloc[:, loc]\r\n3965:            result.columns = result_columns\r\n3966:\r\n3967:            # If there is only one column being returned, and its name is\r\n3968:            # either an empty string, or a tuple with an empty string as its\r\n3969:            # first element, then treat the empty string as a placeholder\r\n3970:            # and return the column as if the user had provided that empty\r\n3971:            # string in the key. If the result is a Series, exclude the\r\n3972:            # implied empty string from its name.\r\n3973:            if len(result.columns) == 1:\r\n3974:                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n3975:                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n3976:                top = result.columns[0]\r\n3977:                if isinstance(top, tuple):\r\n3978:                    top = top[0]\r\n3979:                if top == \"\":\r\n3980:                    result = result[\"\"]\r\n3981:                    if isinstance(result, Series):\r\n3982:                        result = self._constructor_sliced(\r\n3983:                            result, index=self.index, name=key\r\n3984:                        )\r\n3985:\r\n3986:            return result\r\n3987:        else:\r\n3988:            # loc is neither a slice nor ndarray, so must be an int\r\n3989:            return self._ixs(loc, axis=1)\r\n3990:\r\n3991:    def _get_value(self, index, col, takeable: bool = False) -> Scalar:\r\n3992:        \"\"\"\r\n3993:        Quickly retrieve single value at passed column and index.\r\n3994:\r\n3995:        Parameters\r\n3996:        ----------\r\n3997:        index : row label\r\n3998:        col : column label\r\n3999:        takeable : interpret the index/col as indexers, default False\r\n4000:\r\n4001:        Returns\r\n4002:        -------\r\n4003:        scalar\r\n4004:\r\n4005:        Notes\r\n4006:        -----\r\n4007:        Assumes that both `self.index._index_as_unique` and\r\n4008:        `self.columns._index_as_unique`; Caller is responsible for checking.\r\n4009:        \"\"\"\r\n4010:        if takeable:\r\n4011:            series = self._ixs(col, axis=1)\r\n4012:            return series._values[index]\r\n4013:\r\n4014:        series = self._get_item(col)\r\n4015:        engine = self.index._engine\r\n4016:\r\n4017:        if not isinstance(self.index, MultiIndex):\r\n4018:            # CategoricalIndex: Trying to use the engine fastpath may give incorrect\r\n4019:            #  results if our categories are integers that dont match our codes\r\n4020:            # IntervalIndex: IntervalTree has no get_loc\r\n4021:            row = self.index.get_loc(index)\r\n4022:            return series._values[row]\r\n4023:\r\n4024:        # For MultiIndex going through engine effectively restricts us to\r\n4025:        #  same-length tuples; see test_get_set_value_no_partial_indexing\r\n4026:        loc = engine.get_loc(index)\r\n4027:        return series._values[loc]\r\n4028:\r\n4029:    def isetitem(self, loc, value) -> None:\r\n4030:        \"\"\"\r\n4031:        Set the given value in the column with position `loc`.\r\n4032:\r\n4033:        This is a positional analogue to ``__setitem__``.\r\n4034:\r\n4035:        Parameters\r\n4036:        ----------\r\n4037:        loc : int or sequence of ints\r\n4038:            Index position for the column.\r\n4039:        value : scalar or arraylike\r\n4040:            Value(s) for the column.\r\n4041:\r\n4042:        See Also\r\n4043:        --------\r\n4044:        DataFrame.iloc : Purely integer-location based indexing for selection by\r\n4045:            position.\r\n4046:\r\n"]
[195.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[195.002, "i", "sed -n '1,600p' ../pandas/core/common.py | sed -n '80,220p'\r"]
[195.004, "o", "sed -n '1,600p' ../pandas/core/common.py | sed -n '80,220p'\r\n"]
[195.006, "o", "\u001b[?2004l\r\n    -------\r\n    flattened : generator\r\n    \"\"\"\r\n    for element in line:\r\n        if iterable_not_string(element):\r\n            yield from flatten(element)\r\n        else:\r\n            yield element\r\n\r\n\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is not None.\r\n    \"\"\"\r\n    return any(arg is not None for arg in args)\r\n\r\n\r\ndef all_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are not None.\r\n    \"\"\"\r\n    return all(arg is not None for arg in args)\r\n\r\n\r\ndef count_not_none(*args) -> int:\r\n    \"\"\"\r\n    Returns the count of arguments that are not None.\r\n    \"\"\"\r\n    return sum(x is not None for x in args)\r\n\r\n\r\n@overload\r\n"]
[200.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[200.002, "i", "grep -n \"def _getitem_bool_array\" ../pandas/core/frame.py\r"]
[200.004, "o", "grep -n \"def _getitem_bool_array\" ../pandas/core/frame.py\r\n"]
[200.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K3931\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef _getitem_bool_array\u001b[m\u001b[K(self, key):\r\n"]
[205.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[205.002, "i", "grep -n \"def is_bool_indexer\" ../pandas/core/common.py\r"]
[205.004, "o", "grep -n \"def is_bool_indexer\" ../pandas/core/common.py\r\n"]
[205.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K101\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kdef is_bool_indexer\u001b[m\u001b[K(key: Any) -> bool:\r\n"]
[210.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[210.002, "i", "grep -n \"def check_bool_indexer\" ../pandas/core/indexing.py\r"]
[210.004, "o", "grep -n \"def check_bool_indexer\" ../pandas/core/indexing.py\r\n"]
[210.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K2612\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kdef check_bool_indexer\u001b[m\u001b[K(index: Index, key) -> np.ndarray:\r\n"]
[215.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[215.002, "i", "nl -ba ../pandas/core/frame.py | sed -n '1,9999p' | awk -F: '/def _getitem_bool_array/{ln=$1; print ln-10\r"]
[215.004, "o", "nl -ba ../pandas/core/frame.py | sed -n '1,9999p' | awk -F: '/def _getitem_bool_array/{ln=$1; print ln-10\r\n"]
[215.006, "o", "0\":\"; exit}' | xargs -I{} sh -lc 'start={}; end=$((start+160)); sed -n \"${start},${end}p\" ../pandas/core/frame.py'\r\n\u001b[?2004l\r\nsh: 97: eval: Syntax error: \"(\" unexpected (expecting \"}\")\r\n"]
[220.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[220.002, "i", "nl -ba ../pandas/core/common.py | sed -n '1,9999p' | awk -F: '/def is_bool_indexer/{ln=$1; print ln-20\":\"\r"]
[220.004, "o", "nl -ba ../pandas/core/common.py | sed -n '1,9999p' | awk -F: '/def is_bool_indexer/{ln=$1; print ln-20\":\"\r\n"]
[220.006, "o", "\"; exit}' | xargs -I{} sh -lc 'start={}; end=$((start+200)); sed -n \"${start},${end}p\" ../pandas/core/common.py'\r\n\u001b[?2004l\r\nsh: 97: eval: Syntax error: \"(\" unexpected (expecting \"}\")\r\n"]
[225.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[225.002, "i", "nl -ba ../pandas/core/indexing.py | sed -n '1,9999p' | awk -F: '/def check_bool_indexer/{ln=$1; print ln-\r"]
[225.004, "o", "nl -ba ../pandas/core/indexing.py | sed -n '1,9999p' | awk -F: '/def check_bool_indexer/{ln=$1; print ln-\r\n"]
[225.006, "o", "-20\":\"; exit}' | xargs -I{} sh -lc 'start={}; end=$((start+220)); sed -n \"${start},${end}p\" ../pandas/core/indexing.py'\r\n\u001b[?2004l\r\nsh: 97: eval: Syntax error: \"(\" unexpected (expecting \"}\")\r\n"]
[230.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[230.002, "i", "sed -n '3920,4060p' ../pandas/core/frame.py\r"]
[230.004, "o", "sed -n '3920,4060p' ../pandas/core/frame.py\r\n"]
[230.006, "o", "\u001b[?2004l\r\n        if is_single_key:\r\n            # What does looking for a single key in a non-unique index return?\r\n            # The behavior is inconsistent. It returns a Series, except when\r\n            # - the key itself is repeated (test on data.shape, #9519), or\r\n            # - we have a MultiIndex on columns (test on self.columns, #21309)\r\n            if data.shape[1] == 1 and not isinstance(self.columns, MultiIndex):\r\n                # GH#26490 using data[key] can cause RecursionError\r\n                return data._get_item(key)\r\n\r\n        return data\r\n\r\n    def _getitem_bool_array(self, key):\r\n        # also raises Exception if object array with NA values\r\n        # warning here just in case -- previously __setitem__ was\r\n        # reindexing but __getitem__ was not; it seems more reasonable to\r\n        # go with the __setitem__ behavior since that is more consistent\r\n        # with all other indexing behavior\r\n        if isinstance(key, Series) and not key.index.equals(self.index):\r\n            warnings.warn(\r\n                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n                UserWarning,\r\n                stacklevel=find_stack_level(),\r\n            )\r\n        elif len(key) != len(self.index):\r\n            raise ValueError(\r\n                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n            )\r\n\r\n        # check_bool_indexer will throw exception if Series key cannot\r\n        # be reindexed to match DataFrame rows\r\n        key = check_bool_indexer(self.index, key)\r\n\r\n        if key.all():\r\n            return self.copy(deep=False)\r\n\r\n        indexer = key.nonzero()[0]\r\n        return self.take(indexer, axis=0)\r\n\r\n    def _getitem_multilevel(self, key):\r\n        # self.columns is a MultiIndex\r\n        loc = self.columns.get_loc(key)\r\n        if isinstance(loc, (slice, np.ndarray)):\r\n            new_columns = self.columns[loc]\r\n            result_columns = maybe_droplevels(new_columns, key)\r\n            result = self.iloc[:, loc]\r\n            result.columns = result_columns\r\n\r\n            # If there is only one column being returned, and its name is\r\n            # either an empty string, or a tuple with an empty string as its\r\n            # first element, then treat the empty string as a placeholder\r\n            # and return the column as if the user had provided that empty\r\n            # string in the key. If the result is a Series, exclude the\r\n            # implied empty string from its name.\r\n            if len(result.columns) == 1:\r\n                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n                top = result.columns[0]\r\n                if isinstance(top, tuple):\r\n                    top = top[0]\r\n                if top == \"\":\r\n                    result = result[\"\"]\r\n                    if isinstance(result, Series):\r\n                        result = self._constructor_sliced(\r\n                            result, index=self.index, name=key\r\n                        )\r\n\r\n            return result\r\n        else:\r\n            # loc is neither a slice nor ndarray, so must be an int\r\n            return self._ixs(loc, axis=1)\r\n\r\n    def _get_value(self, index, col, takeable: bool = False) -> Scalar:\r\n        \"\"\"\r\n        Quickly retrieve single value at passed column and index.\r\n\r\n        Parameters\r\n        ----------\r\n        index : row label\r\n        col : column label\r\n        takeable : interpret the index/col as indexers, default False\r\n\r\n        Returns\r\n        -------\r\n        scalar\r\n\r\n        Notes\r\n        -----\r\n        Assumes that both `self.index._index_as_unique` and\r\n        `self.columns._index_as_unique`; Caller is responsible for checking.\r\n        \"\"\"\r\n        if takeable:\r\n            series = self._ixs(col, axis=1)\r\n            return series._values[index]\r\n\r\n        series = self._get_item(col)\r\n        engine = self.index._engine\r\n\r\n        if not isinstance(self.index, MultiIndex):\r\n            # CategoricalIndex: Trying to use the engine fastpath may give incorrect\r\n            #  results if our categories are integers that dont match our codes\r\n            # IntervalIndex: IntervalTree has no get_loc\r\n            row = self.index.get_loc(index)\r\n            return series._values[row]\r\n\r\n        # For MultiIndex going through engine effectively restricts us to\r\n        #  same-length tuples; see test_get_set_value_no_partial_indexing\r\n        loc = engine.get_loc(index)\r\n        return series._values[loc]\r\n\r\n    def isetitem(self, loc, value) -> None:\r\n        \"\"\"\r\n        Set the given value in the column with position `loc`.\r\n\r\n        This is a positional analogue to ``__setitem__``.\r\n\r\n        Parameters\r\n        ----------\r\n        loc : int or sequence of ints\r\n            Index position for the column.\r\n        value : scalar or arraylike\r\n            Value(s) for the column.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.iloc : Purely integer-location based indexing for selection by\r\n            position.\r\n\r\n        Notes\r\n        -----\r\n        ``frame.isetitem(loc, value)`` is an in-place method as it will\r\n        modify the DataFrame in place (not returning a new object). In contrast to\r\n        ``frame.iloc[:, i] = value`` which will try to update the existing values in\r\n        place, ``frame.isetitem(loc, value)`` will not update the values of the column\r\n        itself in place, it will instead insert a new array.\r\n\r\n        In cases where ``frame.columns`` is unique, this is equivalent to\r\n        ``frame[frame.columns[i]] = value``.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n"]
[235.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[235.002, "i", "sed -n '80,180p' ../pandas/core/common.py\r"]
[235.004, "o", "sed -n '80,180p' ../pandas/core/common.py\r\n"]
[235.006, "o", "\u001b[?2004l\r\n    -------\r\n    flattened : generator\r\n    \"\"\"\r\n    for element in line:\r\n        if iterable_not_string(element):\r\n            yield from flatten(element)\r\n        else:\r\n            yield element\r\n\r\n\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n"]
[240.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[240.002, "i", "sed -n '2590,2660p' ../pandas/core/indexing.py\r"]
[240.004, "o", "sed -n '2590,2660p' ../pandas/core/indexing.py\r\n"]
[240.006, "o", "\u001b[?2004l\r\n    ndim : int\r\n    loc : object\r\n\r\n    Returns\r\n    -------\r\n    tuple\r\n    \"\"\"\r\n    _tup: list[Hashable | slice]\r\n    _tup = [slice(None, None) for _ in range(ndim)]\r\n    _tup[0] = loc\r\n    return tuple(_tup)\r\n\r\n\r\ndef _tupleize_axis_indexer(ndim: int, axis: AxisInt, key) -> tuple:\r\n    \"\"\"\r\n    If we have an axis, adapt the given key to be axis-independent.\r\n    \"\"\"\r\n    new_key = [slice(None)] * ndim\r\n    new_key[axis] = key\r\n    return tuple(new_key)\r\n\r\n\r\ndef check_bool_indexer(index: Index, key) -> np.ndarray:\r\n    \"\"\"\r\n    Check if key is a valid boolean indexer for an object with such index and\r\n    perform reindexing or conversion if needed.\r\n\r\n    This function assumes that is_bool_indexer(key) == True.\r\n\r\n    Parameters\r\n    ----------\r\n    index : Index\r\n        Index of the object on which the indexing is done.\r\n    key : list-like\r\n        Boolean indexer to check.\r\n\r\n    Returns\r\n    -------\r\n    np.array\r\n        Resulting key.\r\n\r\n    Raises\r\n    ------\r\n    IndexError\r\n        If the key does not have the same length as index.\r\n    IndexingError\r\n        If the index of the key is unalignable to index.\r\n    \"\"\"\r\n    result = key\r\n    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n        indexer = result.index.get_indexer_for(index)\r\n        if -1 in indexer:\r\n            raise IndexingError(\r\n                \"Unalignable boolean Series provided as \"\r\n                \"indexer (index of the boolean Series and of \"\r\n                \"the indexed object do not match).\"\r\n            )\r\n\r\n        result = result.take(indexer)\r\n\r\n        # fall through for boolean\r\n        if not isinstance(result.dtype, ExtensionDtype):\r\n            return result.astype(bool)._values\r\n\r\n    if is_object_dtype(key):\r\n        # key might be object-dtype bool, check_array_indexer needs bool array\r\n        result = np.asarray(result, dtype=bool)\r\n    elif not is_array_like(result):\r\n        # GH 33924\r\n        # key may contain nan elements, check_array_indexer needs bool array\r\n        result = pd_array(result, dtype=bool)\r\n"]
[245.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[245.002, "i", "sed -n '3920,3985p' ../pandas/core/frame.py\r"]
[245.004, "o", "sed -n '3920,3985p' ../pandas/core/frame.py\r\n"]
[245.006, "o", "\u001b[?2004l\r\n        if is_single_key:\r\n            # What does looking for a single key in a non-unique index return?\r\n            # The behavior is inconsistent. It returns a Series, except when\r\n            # - the key itself is repeated (test on data.shape, #9519), or\r\n            # - we have a MultiIndex on columns (test on self.columns, #21309)\r\n            if data.shape[1] == 1 and not isinstance(self.columns, MultiIndex):\r\n                # GH#26490 using data[key] can cause RecursionError\r\n                return data._get_item(key)\r\n\r\n        return data\r\n\r\n    def _getitem_bool_array(self, key):\r\n        # also raises Exception if object array with NA values\r\n        # warning here just in case -- previously __setitem__ was\r\n        # reindexing but __getitem__ was not; it seems more reasonable to\r\n        # go with the __setitem__ behavior since that is more consistent\r\n        # with all other indexing behavior\r\n        if isinstance(key, Series) and not key.index.equals(self.index):\r\n            warnings.warn(\r\n                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n                UserWarning,\r\n                stacklevel=find_stack_level(),\r\n            )\r\n        elif len(key) != len(self.index):\r\n            raise ValueError(\r\n                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n            )\r\n\r\n        # check_bool_indexer will throw exception if Series key cannot\r\n        # be reindexed to match DataFrame rows\r\n        key = check_bool_indexer(self.index, key)\r\n\r\n        if key.all():\r\n            return self.copy(deep=False)\r\n\r\n        indexer = key.nonzero()[0]\r\n        return self.take(indexer, axis=0)\r\n\r\n    def _getitem_multilevel(self, key):\r\n        # self.columns is a MultiIndex\r\n        loc = self.columns.get_loc(key)\r\n        if isinstance(loc, (slice, np.ndarray)):\r\n            new_columns = self.columns[loc]\r\n            result_columns = maybe_droplevels(new_columns, key)\r\n            result = self.iloc[:, loc]\r\n            result.columns = result_columns\r\n\r\n            # If there is only one column being returned, and its name is\r\n            # either an empty string, or a tuple with an empty string as its\r\n            # first element, then treat the empty string as a placeholder\r\n            # and return the column as if the user had provided that empty\r\n            # string in the key. If the result is a Series, exclude the\r\n            # implied empty string from its name.\r\n            if len(result.columns) == 1:\r\n                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n                top = result.columns[0]\r\n                if isinstance(top, tuple):\r\n                    top = top[0]\r\n                if top == \"\":\r\n                    result = result[\"\"]\r\n                    if isinstance(result, Series):\r\n                        result = self._constructor_sliced(\r\n                            result, index=self.index, name=key\r\n                        )\r\n\r\n"]
[250.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[250.002, "i", "sed -n '3985,4060p' ../pandas/core/frame.py\r"]
[250.004, "o", "sed -n '3985,4060p' ../pandas/core/frame.py\r\n"]
[250.006, "o", "\u001b[?2004l\r\n\r\n            return result\r\n        else:\r\n            # loc is neither a slice nor ndarray, so must be an int\r\n            return self._ixs(loc, axis=1)\r\n\r\n    def _get_value(self, index, col, takeable: bool = False) -> Scalar:\r\n        \"\"\"\r\n        Quickly retrieve single value at passed column and index.\r\n\r\n        Parameters\r\n        ----------\r\n        index : row label\r\n        col : column label\r\n        takeable : interpret the index/col as indexers, default False\r\n\r\n        Returns\r\n        -------\r\n        scalar\r\n\r\n        Notes\r\n        -----\r\n        Assumes that both `self.index._index_as_unique` and\r\n        `self.columns._index_as_unique`; Caller is responsible for checking.\r\n        \"\"\"\r\n        if takeable:\r\n            series = self._ixs(col, axis=1)\r\n            return series._values[index]\r\n\r\n        series = self._get_item(col)\r\n        engine = self.index._engine\r\n\r\n        if not isinstance(self.index, MultiIndex):\r\n            # CategoricalIndex: Trying to use the engine fastpath may give incorrect\r\n            #  results if our categories are integers that dont match our codes\r\n            # IntervalIndex: IntervalTree has no get_loc\r\n            row = self.index.get_loc(index)\r\n            return series._values[row]\r\n\r\n        # For MultiIndex going through engine effectively restricts us to\r\n        #  same-length tuples; see test_get_set_value_no_partial_indexing\r\n        loc = engine.get_loc(index)\r\n        return series._values[loc]\r\n\r\n    def isetitem(self, loc, value) -> None:\r\n        \"\"\"\r\n        Set the given value in the column with position `loc`.\r\n\r\n        This is a positional analogue to ``__setitem__``.\r\n\r\n        Parameters\r\n        ----------\r\n        loc : int or sequence of ints\r\n            Index position for the column.\r\n        value : scalar or arraylike\r\n            Value(s) for the column.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.iloc : Purely integer-location based indexing for selection by\r\n            position.\r\n\r\n        Notes\r\n        -----\r\n        ``frame.isetitem(loc, value)`` is an in-place method as it will\r\n        modify the DataFrame in place (not returning a new object). In contrast to\r\n        ``frame.iloc[:, i] = value`` which will try to update the existing values in\r\n        place, ``frame.isetitem(loc, value)`` will not update the values of the column\r\n        itself in place, it will instead insert a new array.\r\n\r\n        In cases where ``frame.columns`` is unique, this is equivalent to\r\n        ``frame[frame.columns[i]] = value``.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n"]
[255.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[255.002, "i", "sed -n '90,150p' ../pandas/core/common.py\r"]
[255.004, "o", "sed -n '90,150p' ../pandas/core/common.py\r\n"]
[255.006, "o", "\u001b[?2004l\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n"]
[260.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[260.002, "i", "sed -n '150,230p' ../pandas/core/common.py\r"]
[260.004, "o", "sed -n '150,230p' ../pandas/core/common.py\r\n"]
[260.006, "o", "\u001b[?2004l\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is not None.\r\n    \"\"\"\r\n    return any(arg is not None for arg in args)\r\n\r\n\r\ndef all_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are not None.\r\n    \"\"\"\r\n    return all(arg is not None for arg in args)\r\n\r\n\r\ndef count_not_none(*args) -> int:\r\n    \"\"\"\r\n    Returns the count of arguments that are not None.\r\n    \"\"\"\r\n    return sum(x is not None for x in args)\r\n\r\n\r\n@overload\r\ndef asarray_tuplesafe(\r\n    values: ArrayLike | list | tuple | zip, dtype: NpDtype | None = ...\r\n) -> np.ndarray:\r\n    # ExtensionArray can only be returned when values is an Index, all other iterables\r\n    # will return np.ndarray. Unfortunately \"all other\" cannot be encoded in a type\r\n    # signature, so instead we special-case some common types.\r\n    ...\r\n\r\n\r\n@overload\r\n"]
[265.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[265.002, "i", "sed -n '3925,3995p' ../pandas/core/frame.py\r"]
[265.004, "o", "sed -n '3925,3995p' ../pandas/core/frame.py\r\n"]
[265.006, "o", "\u001b[?2004l\r\n            if data.shape[1] == 1 and not isinstance(self.columns, MultiIndex):\r\n                # GH#26490 using data[key] can cause RecursionError\r\n                return data._get_item(key)\r\n\r\n        return data\r\n\r\n    def _getitem_bool_array(self, key):\r\n        # also raises Exception if object array with NA values\r\n        # warning here just in case -- previously __setitem__ was\r\n        # reindexing but __getitem__ was not; it seems more reasonable to\r\n        # go with the __setitem__ behavior since that is more consistent\r\n        # with all other indexing behavior\r\n        if isinstance(key, Series) and not key.index.equals(self.index):\r\n            warnings.warn(\r\n                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n                UserWarning,\r\n                stacklevel=find_stack_level(),\r\n            )\r\n        elif len(key) != len(self.index):\r\n            raise ValueError(\r\n                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n            )\r\n\r\n        # check_bool_indexer will throw exception if Series key cannot\r\n        # be reindexed to match DataFrame rows\r\n        key = check_bool_indexer(self.index, key)\r\n\r\n        if key.all():\r\n            return self.copy(deep=False)\r\n\r\n        indexer = key.nonzero()[0]\r\n        return self.take(indexer, axis=0)\r\n\r\n    def _getitem_multilevel(self, key):\r\n        # self.columns is a MultiIndex\r\n        loc = self.columns.get_loc(key)\r\n        if isinstance(loc, (slice, np.ndarray)):\r\n            new_columns = self.columns[loc]\r\n            result_columns = maybe_droplevels(new_columns, key)\r\n            result = self.iloc[:, loc]\r\n            result.columns = result_columns\r\n\r\n            # If there is only one column being returned, and its name is\r\n            # either an empty string, or a tuple with an empty string as its\r\n            # first element, then treat the empty string as a placeholder\r\n            # and return the column as if the user had provided that empty\r\n            # string in the key. If the result is a Series, exclude the\r\n            # implied empty string from its name.\r\n            if len(result.columns) == 1:\r\n                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n                top = result.columns[0]\r\n                if isinstance(top, tuple):\r\n                    top = top[0]\r\n                if top == \"\":\r\n                    result = result[\"\"]\r\n                    if isinstance(result, Series):\r\n                        result = self._constructor_sliced(\r\n                            result, index=self.index, name=key\r\n                        )\r\n\r\n            return result\r\n        else:\r\n            # loc is neither a slice nor ndarray, so must be an int\r\n            return self._ixs(loc, axis=1)\r\n\r\n    def _get_value(self, index, col, takeable: bool = False) -> Scalar:\r\n        \"\"\"\r\n        Quickly retrieve single value at passed column and index.\r\n\r\n        Parameters\r\n"]
[270.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[270.002, "i", "sed -n '3995,4070p' ../pandas/core/frame.py\r"]
[270.004, "o", "sed -n '3995,4070p' ../pandas/core/frame.py\r\n"]
[270.006, "o", "\u001b[?2004l\r\n        Parameters\r\n        ----------\r\n        index : row label\r\n        col : column label\r\n        takeable : interpret the index/col as indexers, default False\r\n\r\n        Returns\r\n        -------\r\n        scalar\r\n\r\n        Notes\r\n        -----\r\n        Assumes that both `self.index._index_as_unique` and\r\n        `self.columns._index_as_unique`; Caller is responsible for checking.\r\n        \"\"\"\r\n        if takeable:\r\n            series = self._ixs(col, axis=1)\r\n            return series._values[index]\r\n\r\n        series = self._get_item(col)\r\n        engine = self.index._engine\r\n\r\n        if not isinstance(self.index, MultiIndex):\r\n            # CategoricalIndex: Trying to use the engine fastpath may give incorrect\r\n            #  results if our categories are integers that dont match our codes\r\n            # IntervalIndex: IntervalTree has no get_loc\r\n            row = self.index.get_loc(index)\r\n            return series._values[row]\r\n\r\n        # For MultiIndex going through engine effectively restricts us to\r\n        #  same-length tuples; see test_get_set_value_no_partial_indexing\r\n        loc = engine.get_loc(index)\r\n        return series._values[loc]\r\n\r\n    def isetitem(self, loc, value) -> None:\r\n        \"\"\"\r\n        Set the given value in the column with position `loc`.\r\n\r\n        This is a positional analogue to ``__setitem__``.\r\n\r\n        Parameters\r\n        ----------\r\n        loc : int or sequence of ints\r\n            Index position for the column.\r\n        value : scalar or arraylike\r\n            Value(s) for the column.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.iloc : Purely integer-location based indexing for selection by\r\n            position.\r\n\r\n        Notes\r\n        -----\r\n        ``frame.isetitem(loc, value)`` is an in-place method as it will\r\n        modify the DataFrame in place (not returning a new object). In contrast to\r\n        ``frame.iloc[:, i] = value`` which will try to update the existing values in\r\n        place, ``frame.isetitem(loc, value)`` will not update the values of the column\r\n        itself in place, it will instead insert a new array.\r\n\r\n        In cases where ``frame.columns`` is unique, this is equivalent to\r\n        ``frame[frame.columns[i]] = value``.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n        >>> df.isetitem(1, [5, 6])\r\n        >>> df\r\n              A  B\r\n        0     1  5\r\n        1     2  6\r\n        \"\"\"\r\n        if isinstance(value, DataFrame):\r\n            if is_integer(loc):\r\n                loc = [loc]\r\n\r\n"]
[275.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[275.002, "i", "sed -n '90,130p' ../pandas/core/common.py\r"]
[275.004, "o", "sed -n '90,130p' ../pandas/core/common.py\r\n"]
[275.006, "o", "\u001b[?2004l\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n"]
[280.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[280.002, "i", "sed -n '130,200p' ../pandas/core/common.py\r"]
[280.004, "o", "sed -n '130,200p' ../pandas/core/common.py\r\n"]
[280.006, "o", "\u001b[?2004l\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n"]
[285.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[285.002, "i", "sed -n '3925,4065p' ../pandas/core/frame.py\r"]
[285.004, "o", "sed -n '3925,4065p' ../pandas/core/frame.py\r\n"]
[285.006, "o", "\u001b[?2004l\r\n            if data.shape[1] == 1 and not isinstance(self.columns, MultiIndex):\r\n                # GH#26490 using data[key] can cause RecursionError\r\n                return data._get_item(key)\r\n\r\n        return data\r\n\r\n    def _getitem_bool_array(self, key):\r\n        # also raises Exception if object array with NA values\r\n        # warning here just in case -- previously __setitem__ was\r\n        # reindexing but __getitem__ was not; it seems more reasonable to\r\n        # go with the __setitem__ behavior since that is more consistent\r\n        # with all other indexing behavior\r\n        if isinstance(key, Series) and not key.index.equals(self.index):\r\n            warnings.warn(\r\n                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n                UserWarning,\r\n                stacklevel=find_stack_level(),\r\n            )\r\n        elif len(key) != len(self.index):\r\n            raise ValueError(\r\n                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n            )\r\n\r\n        # check_bool_indexer will throw exception if Series key cannot\r\n        # be reindexed to match DataFrame rows\r\n        key = check_bool_indexer(self.index, key)\r\n\r\n        if key.all():\r\n            return self.copy(deep=False)\r\n\r\n        indexer = key.nonzero()[0]\r\n        return self.take(indexer, axis=0)\r\n\r\n    def _getitem_multilevel(self, key):\r\n        # self.columns is a MultiIndex\r\n        loc = self.columns.get_loc(key)\r\n        if isinstance(loc, (slice, np.ndarray)):\r\n            new_columns = self.columns[loc]\r\n            result_columns = maybe_droplevels(new_columns, key)\r\n            result = self.iloc[:, loc]\r\n            result.columns = result_columns\r\n\r\n            # If there is only one column being returned, and its name is\r\n            # either an empty string, or a tuple with an empty string as its\r\n            # first element, then treat the empty string as a placeholder\r\n            # and return the column as if the user had provided that empty\r\n            # string in the key. If the result is a Series, exclude the\r\n            # implied empty string from its name.\r\n            if len(result.columns) == 1:\r\n                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n                top = result.columns[0]\r\n                if isinstance(top, tuple):\r\n                    top = top[0]\r\n                if top == \"\":\r\n                    result = result[\"\"]\r\n                    if isinstance(result, Series):\r\n                        result = self._constructor_sliced(\r\n                            result, index=self.index, name=key\r\n                        )\r\n\r\n            return result\r\n        else:\r\n            # loc is neither a slice nor ndarray, so must be an int\r\n            return self._ixs(loc, axis=1)\r\n\r\n    def _get_value(self, index, col, takeable: bool = False) -> Scalar:\r\n        \"\"\"\r\n        Quickly retrieve single value at passed column and index.\r\n\r\n        Parameters\r\n        ----------\r\n        index : row label\r\n        col : column label\r\n        takeable : interpret the index/col as indexers, default False\r\n\r\n        Returns\r\n        -------\r\n        scalar\r\n\r\n        Notes\r\n        -----\r\n        Assumes that both `self.index._index_as_unique` and\r\n        `self.columns._index_as_unique`; Caller is responsible for checking.\r\n        \"\"\"\r\n        if takeable:\r\n            series = self._ixs(col, axis=1)\r\n            return series._values[index]\r\n\r\n        series = self._get_item(col)\r\n        engine = self.index._engine\r\n\r\n        if not isinstance(self.index, MultiIndex):\r\n            # CategoricalIndex: Trying to use the engine fastpath may give incorrect\r\n            #  results if our categories are integers that dont match our codes\r\n            # IntervalIndex: IntervalTree has no get_loc\r\n            row = self.index.get_loc(index)\r\n            return series._values[row]\r\n\r\n        # For MultiIndex going through engine effectively restricts us to\r\n        #  same-length tuples; see test_get_set_value_no_partial_indexing\r\n        loc = engine.get_loc(index)\r\n        return series._values[loc]\r\n\r\n    def isetitem(self, loc, value) -> None:\r\n        \"\"\"\r\n        Set the given value in the column with position `loc`.\r\n\r\n        This is a positional analogue to ``__setitem__``.\r\n\r\n        Parameters\r\n        ----------\r\n        loc : int or sequence of ints\r\n            Index position for the column.\r\n        value : scalar or arraylike\r\n            Value(s) for the column.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.iloc : Purely integer-location based indexing for selection by\r\n            position.\r\n\r\n        Notes\r\n        -----\r\n        ``frame.isetitem(loc, value)`` is an in-place method as it will\r\n        modify the DataFrame in place (not returning a new object). In contrast to\r\n        ``frame.iloc[:, i] = value`` which will try to update the existing values in\r\n        place, ``frame.isetitem(loc, value)`` will not update the values of the column\r\n        itself in place, it will instead insert a new array.\r\n\r\n        In cases where ``frame.columns`` is unique, this is equivalent to\r\n        ``frame[frame.columns[i]] = value``.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n        >>> df.isetitem(1, [5, 6])\r\n        >>> df\r\n              A  B\r\n        0     1  5\r\n        1     2  6\r\n"]
[290.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[290.002, "i", "sed -n '90,140p' ../pandas/core/common.py\r"]
[290.004, "o", "sed -n '90,140p' ../pandas/core/common.py\r\n"]
[290.006, "o", "\u001b[?2004l\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n"]
[295.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[295.002, "i", "sed -n '140,200p' ../pandas/core/common.py\r"]
[295.004, "o", "sed -n '140,200p' ../pandas/core/common.py\r\n"]
[295.006, "o", "\u001b[?2004l\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n"]
[300.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[300.002, "i", "sed -n '2590,2665p' ../pandas/core/indexing.py\r"]
[300.004, "o", "sed -n '2590,2665p' ../pandas/core/indexing.py\r\n"]
[300.006, "o", "\u001b[?2004l\r\n    ndim : int\r\n    loc : object\r\n\r\n    Returns\r\n    -------\r\n    tuple\r\n    \"\"\"\r\n    _tup: list[Hashable | slice]\r\n    _tup = [slice(None, None) for _ in range(ndim)]\r\n    _tup[0] = loc\r\n    return tuple(_tup)\r\n\r\n\r\ndef _tupleize_axis_indexer(ndim: int, axis: AxisInt, key) -> tuple:\r\n    \"\"\"\r\n    If we have an axis, adapt the given key to be axis-independent.\r\n    \"\"\"\r\n    new_key = [slice(None)] * ndim\r\n    new_key[axis] = key\r\n    return tuple(new_key)\r\n\r\n\r\ndef check_bool_indexer(index: Index, key) -> np.ndarray:\r\n    \"\"\"\r\n    Check if key is a valid boolean indexer for an object with such index and\r\n    perform reindexing or conversion if needed.\r\n\r\n    This function assumes that is_bool_indexer(key) == True.\r\n\r\n    Parameters\r\n    ----------\r\n    index : Index\r\n        Index of the object on which the indexing is done.\r\n    key : list-like\r\n        Boolean indexer to check.\r\n\r\n    Returns\r\n    -------\r\n    np.array\r\n        Resulting key.\r\n\r\n    Raises\r\n    ------\r\n    IndexError\r\n        If the key does not have the same length as index.\r\n    IndexingError\r\n        If the index of the key is unalignable to index.\r\n    \"\"\"\r\n    result = key\r\n    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n        indexer = result.index.get_indexer_for(index)\r\n        if -1 in indexer:\r\n            raise IndexingError(\r\n                \"Unalignable boolean Series provided as \"\r\n                \"indexer (index of the boolean Series and of \"\r\n                \"the indexed object do not match).\"\r\n            )\r\n\r\n        result = result.take(indexer)\r\n\r\n        # fall through for boolean\r\n        if not isinstance(result.dtype, ExtensionDtype):\r\n            return result.astype(bool)._values\r\n\r\n    if is_object_dtype(key):\r\n        # key might be object-dtype bool, check_array_indexer needs bool array\r\n        result = np.asarray(result, dtype=bool)\r\n    elif not is_array_like(result):\r\n        # GH 33924\r\n        # key may contain nan elements, check_array_indexer needs bool array\r\n        result = pd_array(result, dtype=bool)\r\n    return check_array_indexer(index, result)\r\n\r\n\r\ndef convert_missing_indexer(indexer):\r\n    \"\"\"\r\n"]
[305.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[305.002, "i", "sed -n '3925,4065p' ../pandas/core/frame.py\r"]
[305.004, "o", "sed -n '3925,4065p' ../pandas/core/frame.py\r\n"]
[305.006, "o", "\u001b[?2004l\r\n            if data.shape[1] == 1 and not isinstance(self.columns, MultiIndex):\r\n                # GH#26490 using data[key] can cause RecursionError\r\n                return data._get_item(key)\r\n\r\n        return data\r\n\r\n    def _getitem_bool_array(self, key):\r\n        # also raises Exception if object array with NA values\r\n        # warning here just in case -- previously __setitem__ was\r\n        # reindexing but __getitem__ was not; it seems more reasonable to\r\n        # go with the __setitem__ behavior since that is more consistent\r\n        # with all other indexing behavior\r\n        if isinstance(key, Series) and not key.index.equals(self.index):\r\n            warnings.warn(\r\n                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n                UserWarning,\r\n                stacklevel=find_stack_level(),\r\n            )\r\n        elif len(key) != len(self.index):\r\n            raise ValueError(\r\n                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n            )\r\n\r\n        # check_bool_indexer will throw exception if Series key cannot\r\n        # be reindexed to match DataFrame rows\r\n        key = check_bool_indexer(self.index, key)\r\n\r\n        if key.all():\r\n            return self.copy(deep=False)\r\n\r\n        indexer = key.nonzero()[0]\r\n        return self.take(indexer, axis=0)\r\n\r\n    def _getitem_multilevel(self, key):\r\n        # self.columns is a MultiIndex\r\n        loc = self.columns.get_loc(key)\r\n        if isinstance(loc, (slice, np.ndarray)):\r\n            new_columns = self.columns[loc]\r\n            result_columns = maybe_droplevels(new_columns, key)\r\n            result = self.iloc[:, loc]\r\n            result.columns = result_columns\r\n\r\n            # If there is only one column being returned, and its name is\r\n            # either an empty string, or a tuple with an empty string as its\r\n            # first element, then treat the empty string as a placeholder\r\n            # and return the column as if the user had provided that empty\r\n            # string in the key. If the result is a Series, exclude the\r\n            # implied empty string from its name.\r\n            if len(result.columns) == 1:\r\n                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n                top = result.columns[0]\r\n                if isinstance(top, tuple):\r\n                    top = top[0]\r\n                if top == \"\":\r\n                    result = result[\"\"]\r\n                    if isinstance(result, Series):\r\n                        result = self._constructor_sliced(\r\n                            result, index=self.index, name=key\r\n                        )\r\n\r\n            return result\r\n        else:\r\n            # loc is neither a slice nor ndarray, so must be an int\r\n            return self._ixs(loc, axis=1)\r\n\r\n    def _get_value(self, index, col, takeable: bool = False) -> Scalar:\r\n        \"\"\"\r\n        Quickly retrieve single value at passed column and index.\r\n\r\n        Parameters\r\n        ----------\r\n        index : row label\r\n        col : column label\r\n        takeable : interpret the index/col as indexers, default False\r\n\r\n        Returns\r\n        -------\r\n        scalar\r\n\r\n        Notes\r\n        -----\r\n        Assumes that both `self.index._index_as_unique` and\r\n        `self.columns._index_as_unique`; Caller is responsible for checking.\r\n        \"\"\"\r\n        if takeable:\r\n            series = self._ixs(col, axis=1)\r\n            return series._values[index]\r\n\r\n        series = self._get_item(col)\r\n        engine = self.index._engine\r\n\r\n        if not isinstance(self.index, MultiIndex):\r\n            # CategoricalIndex: Trying to use the engine fastpath may give incorrect\r\n            #  results if our categories are integers that dont match our codes\r\n            # IntervalIndex: IntervalTree has no get_loc\r\n            row = self.index.get_loc(index)\r\n            return series._values[row]\r\n\r\n        # For MultiIndex going through engine effectively restricts us to\r\n        #  same-length tuples; see test_get_set_value_no_partial_indexing\r\n        loc = engine.get_loc(index)\r\n        return series._values[loc]\r\n\r\n    def isetitem(self, loc, value) -> None:\r\n        \"\"\"\r\n        Set the given value in the column with position `loc`.\r\n\r\n        This is a positional analogue to ``__setitem__``.\r\n\r\n        Parameters\r\n        ----------\r\n        loc : int or sequence of ints\r\n            Index position for the column.\r\n        value : scalar or arraylike\r\n            Value(s) for the column.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.iloc : Purely integer-location based indexing for selection by\r\n            position.\r\n\r\n        Notes\r\n        -----\r\n        ``frame.isetitem(loc, value)`` is an in-place method as it will\r\n        modify the DataFrame in place (not returning a new object). In contrast to\r\n        ``frame.iloc[:, i] = value`` which will try to update the existing values in\r\n        place, ``frame.isetitem(loc, value)`` will not update the values of the column\r\n        itself in place, it will instead insert a new array.\r\n\r\n        In cases where ``frame.columns`` is unique, this is equivalent to\r\n        ``frame[frame.columns[i]] = value``.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n        >>> df.isetitem(1, [5, 6])\r\n        >>> df\r\n              A  B\r\n        0     1  5\r\n        1     2  6\r\n"]
[310.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[310.002, "i", "sed -n '95,115p' ../pandas/core/common.py\r"]
[310.004, "o", "sed -n '95,115p' ../pandas/core/common.py\r\n"]
[310.006, "o", "\u001b[?2004l\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n"]
[315.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[315.002, "i", "sed -n '100,140p' ../pandas/core/common.py\r"]
[315.004, "o", "sed -n '100,140p' ../pandas/core/common.py\r\n"]
[315.006, "o", "\u001b[?2004l\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n"]
[320.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[320.002, "i", "sed -n '140,220p' ../pandas/core/common.py\r"]
[320.004, "o", "sed -n '140,220p' ../pandas/core/common.py\r\n"]
[320.006, "o", "\u001b[?2004l\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is not None.\r\n    \"\"\"\r\n    return any(arg is not None for arg in args)\r\n\r\n\r\ndef all_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are not None.\r\n    \"\"\"\r\n    return all(arg is not None for arg in args)\r\n\r\n\r\ndef count_not_none(*args) -> int:\r\n    \"\"\"\r\n    Returns the count of arguments that are not None.\r\n    \"\"\"\r\n    return sum(x is not None for x in args)\r\n\r\n\r\n@overload\r\n"]
[325.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[325.002, "i", "sed -n '2590,2680p' ../pandas/core/indexing.py\r"]
[325.004, "o", "sed -n '2590,2680p' ../pandas/core/indexing.py\r\n"]
[325.006, "o", "\u001b[?2004l\r\n    ndim : int\r\n    loc : object\r\n\r\n    Returns\r\n    -------\r\n    tuple\r\n    \"\"\"\r\n    _tup: list[Hashable | slice]\r\n    _tup = [slice(None, None) for _ in range(ndim)]\r\n    _tup[0] = loc\r\n    return tuple(_tup)\r\n\r\n\r\ndef _tupleize_axis_indexer(ndim: int, axis: AxisInt, key) -> tuple:\r\n    \"\"\"\r\n    If we have an axis, adapt the given key to be axis-independent.\r\n    \"\"\"\r\n    new_key = [slice(None)] * ndim\r\n    new_key[axis] = key\r\n    return tuple(new_key)\r\n\r\n\r\ndef check_bool_indexer(index: Index, key) -> np.ndarray:\r\n    \"\"\"\r\n    Check if key is a valid boolean indexer for an object with such index and\r\n    perform reindexing or conversion if needed.\r\n\r\n    This function assumes that is_bool_indexer(key) == True.\r\n\r\n    Parameters\r\n    ----------\r\n    index : Index\r\n        Index of the object on which the indexing is done.\r\n    key : list-like\r\n        Boolean indexer to check.\r\n\r\n    Returns\r\n    -------\r\n    np.array\r\n        Resulting key.\r\n\r\n    Raises\r\n    ------\r\n    IndexError\r\n        If the key does not have the same length as index.\r\n    IndexingError\r\n        If the index of the key is unalignable to index.\r\n    \"\"\"\r\n    result = key\r\n    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n        indexer = result.index.get_indexer_for(index)\r\n        if -1 in indexer:\r\n            raise IndexingError(\r\n                \"Unalignable boolean Series provided as \"\r\n                \"indexer (index of the boolean Series and of \"\r\n                \"the indexed object do not match).\"\r\n            )\r\n\r\n        result = result.take(indexer)\r\n\r\n        # fall through for boolean\r\n        if not isinstance(result.dtype, ExtensionDtype):\r\n            return result.astype(bool)._values\r\n\r\n    if is_object_dtype(key):\r\n        # key might be object-dtype bool, check_array_indexer needs bool array\r\n        result = np.asarray(result, dtype=bool)\r\n    elif not is_array_like(result):\r\n        # GH 33924\r\n        # key may contain nan elements, check_array_indexer needs bool array\r\n        result = pd_array(result, dtype=bool)\r\n    return check_array_indexer(index, result)\r\n\r\n\r\ndef convert_missing_indexer(indexer):\r\n    \"\"\"\r\n    Reverse convert a missing indexer, which is a dict\r\n    return the scalar indexer and a boolean indicating if we converted\r\n    \"\"\"\r\n    if isinstance(indexer, dict):\r\n        # a missing key (but not a tuple indexer)\r\n        indexer = indexer[\"key\"]\r\n\r\n        if isinstance(indexer, bool):\r\n            raise KeyError(\"cannot use a single bool to index into setitem\")\r\n        return indexer, True\r\n\r\n    return indexer, False\r\n\r\n\r\ndef convert_from_missing_indexer_tuple(indexer, axes):\r\n"]
[330.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[330.002, "i", "sed -n '3920,4060p' ../pandas/core/frame.py\r"]
[330.004, "o", "sed -n '3920,4060p' ../pandas/core/frame.py\r\n"]
[330.006, "o", "\u001b[?2004l\r\n        if is_single_key:\r\n            # What does looking for a single key in a non-unique index return?\r\n            # The behavior is inconsistent. It returns a Series, except when\r\n            # - the key itself is repeated (test on data.shape, #9519), or\r\n            # - we have a MultiIndex on columns (test on self.columns, #21309)\r\n            if data.shape[1] == 1 and not isinstance(self.columns, MultiIndex):\r\n                # GH#26490 using data[key] can cause RecursionError\r\n                return data._get_item(key)\r\n\r\n        return data\r\n\r\n    def _getitem_bool_array(self, key):\r\n        # also raises Exception if object array with NA values\r\n        # warning here just in case -- previously __setitem__ was\r\n        # reindexing but __getitem__ was not; it seems more reasonable to\r\n        # go with the __setitem__ behavior since that is more consistent\r\n        # with all other indexing behavior\r\n        if isinstance(key, Series) and not key.index.equals(self.index):\r\n            warnings.warn(\r\n                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n                UserWarning,\r\n                stacklevel=find_stack_level(),\r\n            )\r\n        elif len(key) != len(self.index):\r\n            raise ValueError(\r\n                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n            )\r\n\r\n        # check_bool_indexer will throw exception if Series key cannot\r\n        # be reindexed to match DataFrame rows\r\n        key = check_bool_indexer(self.index, key)\r\n\r\n        if key.all():\r\n            return self.copy(deep=False)\r\n\r\n        indexer = key.nonzero()[0]\r\n        return self.take(indexer, axis=0)\r\n\r\n    def _getitem_multilevel(self, key):\r\n        # self.columns is a MultiIndex\r\n        loc = self.columns.get_loc(key)\r\n        if isinstance(loc, (slice, np.ndarray)):\r\n            new_columns = self.columns[loc]\r\n            result_columns = maybe_droplevels(new_columns, key)\r\n            result = self.iloc[:, loc]\r\n            result.columns = result_columns\r\n\r\n            # If there is only one column being returned, and its name is\r\n            # either an empty string, or a tuple with an empty string as its\r\n            # first element, then treat the empty string as a placeholder\r\n            # and return the column as if the user had provided that empty\r\n            # string in the key. If the result is a Series, exclude the\r\n            # implied empty string from its name.\r\n            if len(result.columns) == 1:\r\n                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n                top = result.columns[0]\r\n                if isinstance(top, tuple):\r\n                    top = top[0]\r\n                if top == \"\":\r\n                    result = result[\"\"]\r\n                    if isinstance(result, Series):\r\n                        result = self._constructor_sliced(\r\n                            result, index=self.index, name=key\r\n                        )\r\n\r\n            return result\r\n        else:\r\n            # loc is neither a slice nor ndarray, so must be an int\r\n            return self._ixs(loc, axis=1)\r\n\r\n    def _get_value(self, index, col, takeable: bool = False) -> Scalar:\r\n        \"\"\"\r\n        Quickly retrieve single value at passed column and index.\r\n\r\n        Parameters\r\n        ----------\r\n        index : row label\r\n        col : column label\r\n        takeable : interpret the index/col as indexers, default False\r\n\r\n        Returns\r\n        -------\r\n        scalar\r\n\r\n        Notes\r\n        -----\r\n        Assumes that both `self.index._index_as_unique` and\r\n        `self.columns._index_as_unique`; Caller is responsible for checking.\r\n        \"\"\"\r\n        if takeable:\r\n            series = self._ixs(col, axis=1)\r\n            return series._values[index]\r\n\r\n        series = self._get_item(col)\r\n        engine = self.index._engine\r\n\r\n        if not isinstance(self.index, MultiIndex):\r\n            # CategoricalIndex: Trying to use the engine fastpath may give incorrect\r\n            #  results if our categories are integers that dont match our codes\r\n            # IntervalIndex: IntervalTree has no get_loc\r\n            row = self.index.get_loc(index)\r\n            return series._values[row]\r\n\r\n        # For MultiIndex going through engine effectively restricts us to\r\n        #  same-length tuples; see test_get_set_value_no_partial_indexing\r\n        loc = engine.get_loc(index)\r\n        return series._values[loc]\r\n\r\n    def isetitem(self, loc, value) -> None:\r\n        \"\"\"\r\n        Set the given value in the column with position `loc`.\r\n\r\n        This is a positional analogue to ``__setitem__``.\r\n\r\n        Parameters\r\n        ----------\r\n        loc : int or sequence of ints\r\n            Index position for the column.\r\n        value : scalar or arraylike\r\n            Value(s) for the column.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.iloc : Purely integer-location based indexing for selection by\r\n            position.\r\n\r\n        Notes\r\n        -----\r\n        ``frame.isetitem(loc, value)`` is an in-place method as it will\r\n        modify the DataFrame in place (not returning a new object). In contrast to\r\n        ``frame.iloc[:, i] = value`` which will try to update the existing values in\r\n        place, ``frame.isetitem(loc, value)`` will not update the values of the column\r\n        itself in place, it will instead insert a new array.\r\n\r\n        In cases where ``frame.columns`` is unique, this is equivalent to\r\n        ``frame[frame.columns[i]] = value``.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n"]
[335.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[335.002, "i", "sed -n '80,140p' ../pandas/core/common.py\r"]
[335.004, "o", "sed -n '80,140p' ../pandas/core/common.py\r\n"]
[335.006, "o", "\u001b[?2004l\r\n    -------\r\n    flattened : generator\r\n    \"\"\"\r\n    for element in line:\r\n        if iterable_not_string(element):\r\n            yield from flatten(element)\r\n        else:\r\n            yield element\r\n\r\n\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n"]
[340.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[340.002, "i", "sed -n '140,220p' ../pandas/core/common.py\r"]
[340.004, "o", "sed -n '140,220p' ../pandas/core/common.py\r\n"]
[340.006, "o", "\u001b[?2004l\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is not None.\r\n    \"\"\"\r\n    return any(arg is not None for arg in args)\r\n\r\n\r\ndef all_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are not None.\r\n    \"\"\"\r\n    return all(arg is not None for arg in args)\r\n\r\n\r\ndef count_not_none(*args) -> int:\r\n    \"\"\"\r\n    Returns the count of arguments that are not None.\r\n    \"\"\"\r\n    return sum(x is not None for x in args)\r\n\r\n\r\n@overload\r\n"]
[345.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[345.002, "i", "sed -n '2590,2680p' ../pandas/core/indexing.py\r"]
[345.004, "o", "sed -n '2590,2680p' ../pandas/core/indexing.py\r\n"]
[345.006, "o", "\u001b[?2004l\r\n    ndim : int\r\n    loc : object\r\n\r\n    Returns\r\n    -------\r\n    tuple\r\n    \"\"\"\r\n    _tup: list[Hashable | slice]\r\n    _tup = [slice(None, None) for _ in range(ndim)]\r\n    _tup[0] = loc\r\n    return tuple(_tup)\r\n\r\n\r\ndef _tupleize_axis_indexer(ndim: int, axis: AxisInt, key) -> tuple:\r\n    \"\"\"\r\n    If we have an axis, adapt the given key to be axis-independent.\r\n    \"\"\"\r\n    new_key = [slice(None)] * ndim\r\n    new_key[axis] = key\r\n    return tuple(new_key)\r\n\r\n\r\ndef check_bool_indexer(index: Index, key) -> np.ndarray:\r\n    \"\"\"\r\n    Check if key is a valid boolean indexer for an object with such index and\r\n    perform reindexing or conversion if needed.\r\n\r\n    This function assumes that is_bool_indexer(key) == True.\r\n\r\n    Parameters\r\n    ----------\r\n    index : Index\r\n        Index of the object on which the indexing is done.\r\n    key : list-like\r\n        Boolean indexer to check.\r\n\r\n    Returns\r\n    -------\r\n    np.array\r\n        Resulting key.\r\n\r\n    Raises\r\n    ------\r\n    IndexError\r\n        If the key does not have the same length as index.\r\n    IndexingError\r\n        If the index of the key is unalignable to index.\r\n    \"\"\"\r\n    result = key\r\n    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n        indexer = result.index.get_indexer_for(index)\r\n        if -1 in indexer:\r\n            raise IndexingError(\r\n                \"Unalignable boolean Series provided as \"\r\n                \"indexer (index of the boolean Series and of \"\r\n                \"the indexed object do not match).\"\r\n            )\r\n\r\n        result = result.take(indexer)\r\n\r\n        # fall through for boolean\r\n        if not isinstance(result.dtype, ExtensionDtype):\r\n            return result.astype(bool)._values\r\n\r\n    if is_object_dtype(key):\r\n        # key might be object-dtype bool, check_array_indexer needs bool array\r\n        result = np.asarray(result, dtype=bool)\r\n    elif not is_array_like(result):\r\n        # GH 33924\r\n        # key may contain nan elements, check_array_indexer needs bool array\r\n        result = pd_array(result, dtype=bool)\r\n    return check_array_indexer(index, result)\r\n\r\n\r\ndef convert_missing_indexer(indexer):\r\n    \"\"\"\r\n    Reverse convert a missing indexer, which is a dict\r\n    return the scalar indexer and a boolean indicating if we converted\r\n    \"\"\"\r\n    if isinstance(indexer, dict):\r\n        # a missing key (but not a tuple indexer)\r\n        indexer = indexer[\"key\"]\r\n\r\n        if isinstance(indexer, bool):\r\n            raise KeyError(\"cannot use a single bool to index into setitem\")\r\n        return indexer, True\r\n\r\n    return indexer, False\r\n\r\n\r\ndef convert_from_missing_indexer_tuple(indexer, axes):\r\n"]
[350.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[350.002, "i", "python - << 'PY'\r"]
[350.004, "o", "python - << 'PY'\r\n"]
[350.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import io, sys, re\r\n\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/indexing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> old = '    result = key\\n    if isinstance(key, ABCSeries) and not key.index.equals(index):'\r\n\u001b[?2004l\r\n\u001b[?2004h> new = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     '    result = key\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     '    if isinstance(key, ABCSeries):\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     '        # Fastpath: avoid expensive equals() when index objects are identical\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     '        if result.index is not index and not result.index.equals(index):'\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> if old in s:\r\n\u001b[?2004l\r\n\u001b[?2004h>     s2 = s.replace(old, new)\r\n\u001b[?2004l\r\n\u001b[?2004h>     p.write_text(s2)\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Patched check_bool_indexer fastpath added')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Expected pattern not found; aborting', file=sys.stderr)\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nPatched check_bool_indexer fastpath added\r\n"]
[355.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[355.002, "i", "git diff -- ../pandas/core/indexing.py | sed -n '1,200p'\r"]
[355.004, "o", "git diff -- ../pandas/core/indexing.py | sed -n '1,200p'\r\n"]
[355.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/indexing.py b/pandas/core/indexing.py\r\nindex b3ae53272c..291c56230c 100644\r\n--- a/pandas/core/indexing.py\r\n+++ b/pandas/core/indexing.py\r\n@@ -2636,7 +2636,9 @@ def check_bool_indexer(index: Index, key) -> np.ndarray:\r\n         If the index of the key is unalignable to index.\r\n     \"\"\"\r\n     result = key\r\n-    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n+    if isinstance(key, ABCSeries):\r\n+        # Fastpath: avoid expensive equals() when index objects are identical\r\n+        if result.index is not index and not result.index.equals(index):\r\n         indexer = result.index.get_indexer_for(index)\r\n         if -1 in indexer:\r\n             raise IndexingError(\r\n"]
[360.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[360.002, "i", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[360.004, "o", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[360.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpl4x5tnwy/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   [1/1] Generating write_version_file with a custom command\r\n   + /opt/conda/envs/asv_3.10/bin/ninja\r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 47, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 46, in <module>\r\n       from pandas.core.groupby import (\r\n     File \"/workspace/repo/pandas/core/groupby/__init__.py\", line 1, in <module>\r\n       from pandas.core.groupby.generic import (\r\n     File \"/workspace/repo/pandas/core/groupby/generic.py\", line 63, in <module>\r\n       from pandas.core.frame import DataFrame\r\n     File \"/workspace/repo/pandas/core/frame.py\", line 145, in <module>\r\n       from pandas.core.generic import (\r\n     File \"/workspace/repo/pandas/core/generic.py\", line 139, in <module>\r\n       from pandas.core import (\r\n     File \"/workspace/repo/pandas/core/indexing.py\", line 2642\r\n       indexer = result.index.get_indexer_for(index)\r\n       ^\r\n   IndentationError: expected an indented block after 'if' statement on line 2641\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpl4x5tnwy/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[365.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[365.002, "i", "sed -n '2628,2660p' ../pandas/core/indexing.py\r"]
[365.004, "o", "sed -n '2628,2660p' ../pandas/core/indexing.py\r\n"]
[365.006, "o", "\u001b[?2004l\r\n    np.array\r\n        Resulting key.\r\n\r\n    Raises\r\n    ------\r\n    IndexError\r\n        If the key does not have the same length as index.\r\n    IndexingError\r\n        If the index of the key is unalignable to index.\r\n    \"\"\"\r\n    result = key\r\n    if isinstance(key, ABCSeries):\r\n        # Fastpath: avoid expensive equals() when index objects are identical\r\n        if result.index is not index and not result.index.equals(index):\r\n        indexer = result.index.get_indexer_for(index)\r\n        if -1 in indexer:\r\n            raise IndexingError(\r\n                \"Unalignable boolean Series provided as \"\r\n                \"indexer (index of the boolean Series and of \"\r\n                \"the indexed object do not match).\"\r\n            )\r\n\r\n        result = result.take(indexer)\r\n\r\n        # fall through for boolean\r\n        if not isinstance(result.dtype, ExtensionDtype):\r\n            return result.astype(bool)._values\r\n\r\n    if is_object_dtype(key):\r\n        # key might be object-dtype bool, check_array_indexer needs bool array\r\n        result = np.asarray(result, dtype=bool)\r\n    elif not is_array_like(result):\r\n        # GH 33924\r\n"]
[370.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[370.002, "i", "python - << 'PY'\r"]
[370.004, "o", "python - << 'PY'\r\n"]
[370.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/indexing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> start = s.find('def check_bool_indexer')\r\n\u001b[?2004l\r\n\u001b[?2004h> chunk = s[start:s.find('\\n\\n', start)]\r\n\u001b[?2004l\r\n\u001b[?2004h> # Fix indentation by ensuring the reindexing block is indented under the inner if\r\n\u001b[?2004l\r\n\u001b[?2004h> s = s.replace(\r\n\u001b[?2004l\r\n\u001b[?2004h>     '    if isinstance(key, ABCSeries):\\n        # Fastpath: avoid expensive equals() when index objects are identical\\n        if result.index is not index an\r\nnd not result.index.equals(index):\\n        indexer = result.index.get_indexer_for(index)\\n        if -1 in indexer:\\n            raise IndexingError(\\n',\r\n\u001b[?2004l\r\n\u001b[?2004h>     '    if isinstance(key, ABCSeries):\\n        # Fastpath: avoid expensive equals() when index objects are identical\\n        if result.index is not index an\r\nnd not result.index.equals(index):\\n            indexer = result.index.get_indexer_for(index)\\n            if -1 in indexer:\\n                raise IndexingError\r\nr(\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> # Also indent the subsequent lines in that block if needed\r\n\u001b[?2004l\r\n\u001b[?2004h> s = s.replace(\r\n\u001b[?2004l\r\n\u001b[?2004h>     '        result = result.take(indexer)\\n\\n        # fall through for boolean\\n        if not isinstance(result.dtype, ExtensionDtype):\\n            return \r\n result.astype(bool)._values\\n',\r\n\u001b[?2004l\r\n\u001b[?2004h>     '            result = result.take(indexer)\\n\\n            # fall through for boolean\\n            if not isinstance(result.dtype, ExtensionDtype):\\n       \r\n          return result.astype(bool)._values\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(s)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Indentation fixed')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nIndentation fixed\r\n"]
[375.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[375.002, "i", "git diff -- ../pandas/core/indexing.py | sed -n '1,200p'\r"]
[375.004, "o", "git diff -- ../pandas/core/indexing.py | sed -n '1,200p'\r\n"]
[375.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/indexing.py b/pandas/core/indexing.py\r\nindex b3ae53272c..8556b56555 100644\r\n--- a/pandas/core/indexing.py\r\n+++ b/pandas/core/indexing.py\r\n@@ -2636,20 +2636,22 @@ def check_bool_indexer(index: Index, key) -> np.ndarray:\r\n         If the index of the key is unalignable to index.\r\n     \"\"\"\r\n     result = key\r\n-    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n-        indexer = result.index.get_indexer_for(index)\r\n-        if -1 in indexer:\r\n-            raise IndexingError(\r\n+    if isinstance(key, ABCSeries):\r\n+        # Fastpath: avoid expensive equals() when index objects are identical\r\n+        if result.index is not index and not result.index.equals(index):\r\n+            indexer = result.index.get_indexer_for(index)\r\n+            if -1 in indexer:\r\n+                raise IndexingError(\r\n                 \"Unalignable boolean Series provided as \"\r\n                 \"indexer (index of the boolean Series and of \"\r\n                 \"the indexed object do not match).\"\r\n             )\r\n \r\n-        result = result.take(indexer)\r\n+            result = result.take(indexer)\r\n \r\n-        # fall through for boolean\r\n-        if not isinstance(result.dtype, ExtensionDtype):\r\n-            return result.astype(bool)._values\r\n+            # fall through for boolean\r\n+            if not isinstance(result.dtype, ExtensionDtype):\r\n+                return result.astype(bool)._values\r\n \r\n     if is_object_dtype(key):\r\n         # key might be object-dtype bool, check_array_indexer needs bool array\r\n"]
[380.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[380.002, "i", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[380.004, "o", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[380.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (indexing.DataFrameStringIndexing.time_at--)\u001b[0m.......\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at\u001b[0m                                                                                                12.9\u00b10.2\u03bcs\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at_setitem\u001b[0m                                                                                        12.4\u00b10.2\u03bcs\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows\u001b[0m                                                                                         118\u00b11\u03bcs\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_boolean\u001b[0m                                                                                 115\u00b11\u03bcs\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_object\u001b[0m                                                                                  166\u00b11\u03bcs\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_getitem_scalar\u001b[0m                                                                                    13.0\u00b10.2\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_loc\u001b[0m                                                                                               18.1\u00b10.3\u03bcs\r\n"]
[385.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[385.002, "i", "sed -n '80,160p' ../pandas/core/common.py\r"]
[385.004, "o", "sed -n '80,160p' ../pandas/core/common.py\r\n"]
[385.006, "o", "\u001b[?2004l\r\n    -------\r\n    flattened : generator\r\n    \"\"\"\r\n    for element in line:\r\n        if iterable_not_string(element):\r\n            yield from flatten(element)\r\n        else:\r\n            yield element\r\n\r\n\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n"]
[390.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[390.002, "i", "sed -n '160,260p' ../pandas/core/common.py\r"]
[390.004, "o", "sed -n '160,260p' ../pandas/core/common.py\r\n"]
[390.006, "o", "\u001b[?2004l\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is not None.\r\n    \"\"\"\r\n    return any(arg is not None for arg in args)\r\n\r\n\r\ndef all_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are not None.\r\n    \"\"\"\r\n    return all(arg is not None for arg in args)\r\n\r\n\r\ndef count_not_none(*args) -> int:\r\n    \"\"\"\r\n    Returns the count of arguments that are not None.\r\n    \"\"\"\r\n    return sum(x is not None for x in args)\r\n\r\n\r\n@overload\r\ndef asarray_tuplesafe(\r\n    values: ArrayLike | list | tuple | zip, dtype: NpDtype | None = ...\r\n) -> np.ndarray:\r\n    # ExtensionArray can only be returned when values is an Index, all other iterables\r\n    # will return np.ndarray. Unfortunately \"all other\" cannot be encoded in a type\r\n    # signature, so instead we special-case some common types.\r\n    ...\r\n\r\n\r\n@overload\r\ndef asarray_tuplesafe(values: Iterable, dtype: NpDtype | None = ...) -> ArrayLike: ...\r\n\r\n\r\ndef asarray_tuplesafe(values: Iterable, dtype: NpDtype | None = None) -> ArrayLike:\r\n    if not (isinstance(values, (list, tuple)) or hasattr(values, \"__array__\")):\r\n        values = list(values)\r\n    elif isinstance(values, ABCIndex):\r\n        return values._values\r\n    elif isinstance(values, ABCSeries):\r\n        return values._values\r\n\r\n    if isinstance(values, list) and dtype in [np.object_, object]:\r\n        return construct_1d_object_array_from_listlike(values)\r\n\r\n    try:\r\n        with warnings.catch_warnings():\r\n            # Can remove warning filter once NumPy 1.24 is min version\r\n            if not np_version_gte1p24:\r\n                warnings.simplefilter(\"ignore\", np.VisibleDeprecationWarning)\r\n            result = np.asarray(values, dtype=dtype)\r\n    except ValueError:\r\n        # Using try/except since it's more performant than checking is_list_like\r\n        # over each element\r\n        # error: Argument 1 to \"construct_1d_object_array_from_listlike\"\r\n        # has incompatible type \"Iterable[Any]\"; expected \"Sized\"\r\n        return construct_1d_object_array_from_listlike(values)  # type: ignore[arg-type]\r\n\r\n    if issubclass(result.dtype.type, str):\r\n        result = np.asarray(values, dtype=object)\r\n\r\n"]
[395.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[395.002, "i", "sed -n '1,260p' ../pandas/core/common.py\r"]
[395.004, "o", "sed -n '1,260p' ../pandas/core/common.py\r\n"]
[395.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nMisc tools for implementing data structures\r\n\r\nNote: pandas.core.common is *not* part of the public API.\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport builtins\r\nfrom collections import (\r\n    abc,\r\n    defaultdict,\r\n)\r\nfrom collections.abc import (\r\n    Collection,\r\n    Generator,\r\n    Hashable,\r\n    Iterable,\r\n    Sequence,\r\n)\r\nimport contextlib\r\nfrom functools import partial\r\nimport inspect\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Callable,\r\n    TypeVar,\r\n    cast,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas.compat.numpy import np_version_gte1p24\r\n\r\nfrom pandas.core.dtypes.cast import construct_1d_object_array_from_listlike\r\nfrom pandas.core.dtypes.common import (\r\n    is_bool_dtype,\r\n    is_integer,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCExtensionArray,\r\n    ABCIndex,\r\n    ABCMultiIndex,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import iterable_not_string\r\n\r\nif TYPE_CHECKING:\r\n    from pandas._typing import (\r\n        AnyArrayLike,\r\n        ArrayLike,\r\n        Concatenate,\r\n        NpDtype,\r\n        P,\r\n        RandomState,\r\n        T,\r\n    )\r\n\r\n    from pandas import Index\r\n\r\n\r\ndef flatten(line):\r\n    \"\"\"\r\n    Flatten an arbitrarily nested sequence.\r\n\r\n    Parameters\r\n    ----------\r\n    line : sequence\r\n        The non string sequence to flatten\r\n\r\n    Notes\r\n    -----\r\n    This doesn't consider strings sequences.\r\n\r\n    Returns\r\n    -------\r\n    flattened : generator\r\n    \"\"\"\r\n    for element in line:\r\n        if iterable_not_string(element):\r\n            yield from flatten(element)\r\n        else:\r\n            yield element\r\n\r\n\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is not None.\r\n    \"\"\"\r\n    return any(arg is not None for arg in args)\r\n\r\n\r\ndef all_not_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are not None.\r\n    \"\"\"\r\n    return all(arg is not None for arg in args)\r\n\r\n\r\ndef count_not_none(*args) -> int:\r\n    \"\"\"\r\n    Returns the count of arguments that are not None.\r\n    \"\"\"\r\n    return sum(x is not None for x in args)\r\n\r\n\r\n@overload\r\ndef asarray_tuplesafe(\r\n    values: ArrayLike | list | tuple | zip, dtype: NpDtype | None = ...\r\n) -> np.ndarray:\r\n    # ExtensionArray can only be returned when values is an Index, all other iterables\r\n    # will return np.ndarray. Unfortunately \"all other\" cannot be encoded in a type\r\n    # signature, so instead we special-case some common types.\r\n    ...\r\n\r\n\r\n@overload\r\ndef asarray_tuplesafe(values: Iterable, dtype: NpDtype | None = ...) -> ArrayLike: ...\r\n\r\n\r\ndef asarray_tuplesafe(values: Iterable, dtype: NpDtype | None = None) -> ArrayLike:\r\n    if not (isinstance(values, (list, tuple)) or hasattr(values, \"__array__\")):\r\n        values = list(values)\r\n    elif isinstance(values, ABCIndex):\r\n        return values._values\r\n    elif isinstance(values, ABCSeries):\r\n        return values._values\r\n\r\n    if isinstance(values, list) and dtype in [np.object_, object]:\r\n        return construct_1d_object_array_from_listlike(values)\r\n\r\n    try:\r\n        with warnings.catch_warnings():\r\n            # Can remove warning filter once NumPy 1.24 is min version\r\n            if not np_version_gte1p24:\r\n                warnings.simplefilter(\"ignore\", np.VisibleDeprecationWarning)\r\n            result = np.asarray(values, dtype=dtype)\r\n    except ValueError:\r\n        # Using try/except since it's more performant than checking is_list_like\r\n        # over each element\r\n        # error: Argument 1 to \"construct_1d_object_array_from_listlike\"\r\n        # has incompatible type \"Iterable[Any]\"; expected \"Sized\"\r\n        return construct_1d_object_array_from_listlike(values)  # type: ignore[arg-type]\r\n\r\n    if issubclass(result.dtype.type, str):\r\n        result = np.asarray(values, dtype=object)\r\n\r\n"]
[400.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[400.002, "i", "grep -n \"def is_bool_indexer\\(\" ../pandas/core/common.py\r"]
[400.004, "o", "grep -n \"def is_bool_indexer\\(\" ../pandas/core/common.py\r\n"]
[400.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[405.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[405.002, "i", "sed -n '90,180p' ../pandas/core/common.py\r"]
[405.004, "o", "sed -n '90,180p' ../pandas/core/common.py\r\n"]
[405.006, "o", "\u001b[?2004l\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n"]
[410.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[410.002, "i", "sed -n '80,140p' ../pandas/core/common.py\r"]
[410.004, "o", "sed -n '80,140p' ../pandas/core/common.py\r\n"]
[410.006, "o", "\u001b[?2004l\r\n    -------\r\n    flattened : generator\r\n    \"\"\"\r\n    for element in line:\r\n        if iterable_not_string(element):\r\n            yield from flatten(element)\r\n        else:\r\n            yield element\r\n\r\n\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n"]
[415.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[415.002, "i", "sed -n '100,170p' ../pandas/core/common.py\r"]
[415.004, "o", "sed -n '100,170p' ../pandas/core/common.py\r\n"]
[415.006, "o", "\u001b[?2004l\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n"]
[420.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[420.002, "i", "sed -n '1,120p' ../pandas/core/common.py | sed -n '90,130p'\r"]
[420.004, "o", "sed -n '1,120p' ../pandas/core/common.py | sed -n '90,130p'\r\n"]
[420.006, "o", "\u001b[?2004l\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n"]
[425.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[425.002, "i", "sed -n '90,200p' ../pandas/core/common.py\r"]
[425.004, "o", "sed -n '90,200p' ../pandas/core/common.py\r\n"]
[425.006, "o", "\u001b[?2004l\r\ndef consensus_name_attr(objs):\r\n    name = objs[0].name\r\n    for obj in objs[1:]:\r\n        try:\r\n            if obj.name != name:\r\n                name = None\r\n        except ValueError:\r\n            name = None\r\n    return name\r\n\r\n\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n    \"\"\"\r\n    Disallow indexing with a float key, even if that key is a round number.\r\n\r\n    Parameters\r\n    ----------\r\n    val : scalar\r\n\r\n    Returns\r\n    -------\r\n    outval : scalar\r\n    \"\"\"\r\n    # assumes lib.is_scalar(val)\r\n    if lib.is_float(val) and val.is_integer():\r\n        raise IndexError(\r\n            # GH#34193\r\n            \"Indexing with a float is no longer supported. Manually convert \"\r\n            \"to an integer key instead.\"\r\n        )\r\n    return val\r\n\r\n\r\ndef not_none(*args):\r\n    \"\"\"\r\n    Returns a generator consisting of the arguments that are not None.\r\n    \"\"\"\r\n    return (arg for arg in args if arg is not None)\r\n\r\n\r\ndef any_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if any argument is None.\r\n    \"\"\"\r\n    return any(arg is None for arg in args)\r\n\r\n\r\ndef all_none(*args) -> bool:\r\n    \"\"\"\r\n    Returns a boolean indicating if all arguments are None.\r\n    \"\"\"\r\n    return all(arg is None for arg in args)\r\n\r\n\r\ndef any_not_none(*args) -> bool:\r\n    \"\"\"\r\n"]
[430.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[430.002, "i", "sed -n '3925,4005p' ../pandas/core/frame.py\r"]
[430.004, "o", "sed -n '3925,4005p' ../pandas/core/frame.py\r\n"]
[430.006, "o", "\u001b[?2004l\r\n            if data.shape[1] == 1 and not isinstance(self.columns, MultiIndex):\r\n                # GH#26490 using data[key] can cause RecursionError\r\n                return data._get_item(key)\r\n\r\n        return data\r\n\r\n    def _getitem_bool_array(self, key):\r\n        # also raises Exception if object array with NA values\r\n        # warning here just in case -- previously __setitem__ was\r\n        # reindexing but __getitem__ was not; it seems more reasonable to\r\n        # go with the __setitem__ behavior since that is more consistent\r\n        # with all other indexing behavior\r\n        if isinstance(key, Series) and not key.index.equals(self.index):\r\n            warnings.warn(\r\n                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n                UserWarning,\r\n                stacklevel=find_stack_level(),\r\n            )\r\n        elif len(key) != len(self.index):\r\n            raise ValueError(\r\n                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n            )\r\n\r\n        # check_bool_indexer will throw exception if Series key cannot\r\n        # be reindexed to match DataFrame rows\r\n        key = check_bool_indexer(self.index, key)\r\n\r\n        if key.all():\r\n            return self.copy(deep=False)\r\n\r\n        indexer = key.nonzero()[0]\r\n        return self.take(indexer, axis=0)\r\n\r\n    def _getitem_multilevel(self, key):\r\n        # self.columns is a MultiIndex\r\n        loc = self.columns.get_loc(key)\r\n        if isinstance(loc, (slice, np.ndarray)):\r\n            new_columns = self.columns[loc]\r\n            result_columns = maybe_droplevels(new_columns, key)\r\n            result = self.iloc[:, loc]\r\n            result.columns = result_columns\r\n\r\n            # If there is only one column being returned, and its name is\r\n            # either an empty string, or a tuple with an empty string as its\r\n            # first element, then treat the empty string as a placeholder\r\n            # and return the column as if the user had provided that empty\r\n            # string in the key. If the result is a Series, exclude the\r\n            # implied empty string from its name.\r\n            if len(result.columns) == 1:\r\n                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n                top = result.columns[0]\r\n                if isinstance(top, tuple):\r\n                    top = top[0]\r\n                if top == \"\":\r\n                    result = result[\"\"]\r\n                    if isinstance(result, Series):\r\n                        result = self._constructor_sliced(\r\n                            result, index=self.index, name=key\r\n                        )\r\n\r\n            return result\r\n        else:\r\n            # loc is neither a slice nor ndarray, so must be an int\r\n            return self._ixs(loc, axis=1)\r\n\r\n    def _get_value(self, index, col, takeable: bool = False) -> Scalar:\r\n        \"\"\"\r\n        Quickly retrieve single value at passed column and index.\r\n\r\n        Parameters\r\n        ----------\r\n        index : row label\r\n        col : column label\r\n        takeable : interpret the index/col as indexers, default False\r\n\r\n        Returns\r\n        -------\r\n        scalar\r\n\r\n        Notes\r\n"]
[435.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[435.002, "i", "sed -n '4005,4085p' ../pandas/core/frame.py\r"]
[435.004, "o", "sed -n '4005,4085p' ../pandas/core/frame.py\r\n"]
[435.006, "o", "\u001b[?2004l\r\n        Notes\r\n        -----\r\n        Assumes that both `self.index._index_as_unique` and\r\n        `self.columns._index_as_unique`; Caller is responsible for checking.\r\n        \"\"\"\r\n        if takeable:\r\n            series = self._ixs(col, axis=1)\r\n            return series._values[index]\r\n\r\n        series = self._get_item(col)\r\n        engine = self.index._engine\r\n\r\n        if not isinstance(self.index, MultiIndex):\r\n            # CategoricalIndex: Trying to use the engine fastpath may give incorrect\r\n            #  results if our categories are integers that dont match our codes\r\n            # IntervalIndex: IntervalTree has no get_loc\r\n            row = self.index.get_loc(index)\r\n            return series._values[row]\r\n\r\n        # For MultiIndex going through engine effectively restricts us to\r\n        #  same-length tuples; see test_get_set_value_no_partial_indexing\r\n        loc = engine.get_loc(index)\r\n        return series._values[loc]\r\n\r\n    def isetitem(self, loc, value) -> None:\r\n        \"\"\"\r\n        Set the given value in the column with position `loc`.\r\n\r\n        This is a positional analogue to ``__setitem__``.\r\n\r\n        Parameters\r\n        ----------\r\n        loc : int or sequence of ints\r\n            Index position for the column.\r\n        value : scalar or arraylike\r\n            Value(s) for the column.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.iloc : Purely integer-location based indexing for selection by\r\n            position.\r\n\r\n        Notes\r\n        -----\r\n        ``frame.isetitem(loc, value)`` is an in-place method as it will\r\n        modify the DataFrame in place (not returning a new object). In contrast to\r\n        ``frame.iloc[:, i] = value`` which will try to update the existing values in\r\n        place, ``frame.isetitem(loc, value)`` will not update the values of the column\r\n        itself in place, it will instead insert a new array.\r\n\r\n        In cases where ``frame.columns`` is unique, this is equivalent to\r\n        ``frame[frame.columns[i]] = value``.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n        >>> df.isetitem(1, [5, 6])\r\n        >>> df\r\n              A  B\r\n        0     1  5\r\n        1     2  6\r\n        \"\"\"\r\n        if isinstance(value, DataFrame):\r\n            if is_integer(loc):\r\n                loc = [loc]\r\n\r\n            if len(loc) != len(value.columns):\r\n                raise ValueError(\r\n                    f\"Got {len(loc)} positions but value has {len(value.columns)} \"\r\n                    f\"columns.\"\r\n                )\r\n\r\n            for i, idx in enumerate(loc):\r\n                arraylike, refs = self._sanitize_column(value.iloc[:, i])\r\n                self._iset_item_mgr(idx, arraylike, inplace=False, refs=refs)\r\n            return\r\n\r\n        arraylike, refs = self._sanitize_column(value)\r\n        self._iset_item_mgr(loc, arraylike, inplace=False, refs=refs)\r\n\r\n    def __setitem__(self, key, value) -> None:\r\n"]
[440.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[440.002, "i", "grep -n \"is_bool_dtype\" ../pandas/core/indexing.py || true\r"]
[440.004, "o", "grep -n \"is_bool_dtype\" ../pandas/core/indexing.py || true\r\n"]
[440.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K36\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kis_bool_dtype\u001b[m\u001b[K,\r\n\u001b[32m\u001b[K1236\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kis_bool_dtype\u001b[m\u001b[K(ax.dtype)\r\n\u001b[32m\u001b[K1239\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            and \u001b[01;31m\u001b[Kis_bool_dtype\u001b[m\u001b[K(ax.get_level_values(0).dtype)\r\n"]
[445.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[445.002, "i", "python - << 'PY'\r"]
[445.004, "o", "python - << 'PY'\r\n"]
[445.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/indexing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Ensure is_bool_dtype is imported if not already\r\n\u001b[?2004l\r\n\u001b[?2004h> if 'is_bool_dtype' not in s.split('\\n',1)[0] and 'is_bool_dtype' not in s:\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Try to add import from dtypes.common near other imports\r\n\u001b[?2004l\r\n\u001b[?2004h>     if 'from pandas.core.dtypes.common import (' in s:\r\n\u001b[?2004l\r\n\u001b[?2004h>         s = s.replace(\r\n\u001b[?2004l\r\n\u001b[?2004h>             'from pandas.core.dtypes.common import (',\r\n\u001b[?2004l\r\n\u001b[?2004h>             'from pandas.core.dtypes.common import ('\r\n\u001b[?2004l\r\n\u001b[?2004h>         )\r\n\u001b[?2004l\r\n\u001b[?2004h>     # append is_bool_dtype to the import list if a block exists\r\n\u001b[?2004l\r\n\u001b[?2004h>     s = s.replace(\r\n\u001b[?2004l\r\n\u001b[?2004h>         'from pandas.core.dtypes.common import (',\r\n\u001b[?2004l\r\n\u001b[?2004h>         'from pandas.core.dtypes.common import (\r\n\u001b[?2004l\r\n\u001b[?2004h>     is_bool_dtype,')\r\n\u001b[?2004l\r\n\u001b[?2004h> # Inject early-return for identical-index boolean Series\r\n\u001b[?2004l\r\n\u001b[?2004h> needle = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     '    if isinstance(key, ABCSeries):\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     '        # Fastpath: avoid expensive equals() when index objects are identical\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     '        if result.index is not index and not result.index.equals(index):\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> if needle in s:\r\n\u001b[?2004l\r\n\u001b[?2004h>     insert_after = needle + '            '\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Find position just after the inner-if block ends; we add an else branch before the next top-level if\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Simpler: replace the subsequent block start to include an else branch\r\n\u001b[?2004l\r\n\u001b[?2004h>     s = s.replace(\r\n\u001b[?2004l\r\n\u001b[?2004h>         needle + '',\r\n\u001b[?2004l\r\n\u001b[?2004h>         needle + '        else:\\n            if not isinstance(result.dtype, ExtensionDtype):\\n                # If dtype is boolean numpy, we can return under\r\nrlying array directly\\n                try:\\n                    from pandas.core.dtypes.common import is_bool_dtype\\n                except Exception:\\n        \r\n             pass\\n                if hasattr(result, \"dtype\") and getattr(result, \"dtype\", None) is not None and getattr(result.dtype, \"kind\", None) == \"b\":\\n  \r\n                   return result._values\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     )\r\n\u001b[?2004l\r\n\u001b[?2004h>     Path('../pandas/core/indexing.py').write_text(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Patched early-return for boolean Series with identical index')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Patch anchor not found; skipping',)\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n  File \"<stdin>\", line 15\r\n    'from pandas.core.dtypes.common import (\r\n    ^\r\nSyntaxError: unterminated string literal (detected at line 15)\r\n"]
[450.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[450.002, "i", "git diff -- ../pandas/core/indexing.py | sed -n '1,240p'\r"]
[450.004, "o", "git diff -- ../pandas/core/indexing.py | sed -n '1,240p'\r\n"]
[450.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/indexing.py b/pandas/core/indexing.py\r\nindex b3ae53272c..8556b56555 100644\r\n--- a/pandas/core/indexing.py\r\n+++ b/pandas/core/indexing.py\r\n@@ -2636,20 +2636,22 @@ def check_bool_indexer(index: Index, key) -> np.ndarray:\r\n         If the index of the key is unalignable to index.\r\n     \"\"\"\r\n     result = key\r\n-    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n-        indexer = result.index.get_indexer_for(index)\r\n-        if -1 in indexer:\r\n-            raise IndexingError(\r\n+    if isinstance(key, ABCSeries):\r\n+        # Fastpath: avoid expensive equals() when index objects are identical\r\n+        if result.index is not index and not result.index.equals(index):\r\n+            indexer = result.index.get_indexer_for(index)\r\n+            if -1 in indexer:\r\n+                raise IndexingError(\r\n                 \"Unalignable boolean Series provided as \"\r\n                 \"indexer (index of the boolean Series and of \"\r\n                 \"the indexed object do not match).\"\r\n             )\r\n \r\n-        result = result.take(indexer)\r\n+            result = result.take(indexer)\r\n \r\n-        # fall through for boolean\r\n-        if not isinstance(result.dtype, ExtensionDtype):\r\n-            return result.astype(bool)._values\r\n+            # fall through for boolean\r\n+            if not isinstance(result.dtype, ExtensionDtype):\r\n+                return result.astype(bool)._values\r\n \r\n     if is_object_dtype(key):\r\n         # key might be object-dtype bool, check_array_indexer needs bool array\r\n"]
[455.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[455.002, "i", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[455.004, "o", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[455.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (indexing.DataFrameStringIndexing.time_at--)\u001b[0m.......\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at\u001b[0m                                                                                                13.2\u00b10.4\u03bcs\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at_setitem\u001b[0m                                                                                        12.5\u00b10.3\u03bcs\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows\u001b[0m                                                                                       117\u00b10.8\u03bcs\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_boolean\u001b[0m                                                                               115\u00b10.8\u03bcs\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_object\u001b[0m                                                                                165\u00b10.6\u03bcs\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_getitem_scalar\u001b[0m                                                                                    13.5\u00b10.2\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_loc\u001b[0m                                                                                               19.5\u00b10.5\u03bcs\r\n"]
[460.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[460.002, "i", "sed -n '2628,2660p' ../pandas/core/indexing.py\r"]
[460.004, "o", "sed -n '2628,2660p' ../pandas/core/indexing.py\r\n"]
[460.006, "o", "\u001b[?2004l\r\n    np.array\r\n        Resulting key.\r\n\r\n    Raises\r\n    ------\r\n    IndexError\r\n        If the key does not have the same length as index.\r\n    IndexingError\r\n        If the index of the key is unalignable to index.\r\n    \"\"\"\r\n    result = key\r\n    if isinstance(key, ABCSeries):\r\n        # Fastpath: avoid expensive equals() when index objects are identical\r\n        if result.index is not index and not result.index.equals(index):\r\n            indexer = result.index.get_indexer_for(index)\r\n            if -1 in indexer:\r\n                raise IndexingError(\r\n                \"Unalignable boolean Series provided as \"\r\n                \"indexer (index of the boolean Series and of \"\r\n                \"the indexed object do not match).\"\r\n            )\r\n\r\n            result = result.take(indexer)\r\n\r\n            # fall through for boolean\r\n            if not isinstance(result.dtype, ExtensionDtype):\r\n                return result.astype(bool)._values\r\n\r\n    if is_object_dtype(key):\r\n        # key might be object-dtype bool, check_array_indexer needs bool array\r\n        result = np.asarray(result, dtype=bool)\r\n    elif not is_array_like(result):\r\n        # GH 33924\r\n"]
[465.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[465.002, "i", "python - << 'PY'\r"]
[465.004, "o", "python - << 'PY'\r\n"]
[465.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/indexing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> anchor = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     '        if result.index is not index and not result.index.equals(index):\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     '            indexer = result.index.get_indexer_for(index)\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     '            if -1 in indexer:\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     '                raise IndexingError('\\n)\r\n\u001b[?2004l\r\n\u001b[?2004h> # We will insert an else-block after the existing fastpath block that returns early\r\n\u001b[?2004l\r\n\u001b[?2004h> insertion_point = s.find('\\n    if is_object_dtype(key):')\r\n\u001b[?2004l\r\n\u001b[?2004h> block_start = s.rfind('if isinstance(key, ABCSeries):', 0, insertion_point)\r\n\u001b[?2004l\r\n\u001b[?2004h> inner_if = s.find('if result.index is not index and not result.index.equals(index):', block_start, insertion_point)\r\n\u001b[?2004l\r\n\u001b[?2004h> block_end = s.find('\\n\\n    if is_object_dtype(key):', block_start)\r\n\u001b[?2004l\r\n\u001b[?2004h> if inner_if != -1 and block_end != -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Craft the else branch to return early when index objects are identical\r\n\u001b[?2004l\r\n\u001b[?2004h>     insertion = (\r\n\u001b[?2004l\r\n\u001b[?2004h>         '\\n        else:\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>         '            if not isinstance(result.dtype, ExtensionDtype):\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>         '                return result.astype(bool)._values\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     )\r\n\u001b[?2004l\r\n\u001b[?2004h>     s = s.replace('\\n\\n    if is_object_dtype(key):', insertion + '\\n    if is_object_dtype(key):', 1)\r\n\u001b[?2004l\r\n\u001b[?2004h>     p.write_text(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Added else early-return for identical-index boolean Series')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Could not locate patch positions; no changes made')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n  File \"<stdin>\", line 8\r\n    '                raise IndexingError('\\n)\r\n                                           ^\r\nSyntaxError: unexpected character after line continuation character\r\n"]
[470.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[470.002, "i", "git diff -- ../pandas/core/indexing.py | sed -n '1,240p'\r"]
[470.004, "o", "git diff -- ../pandas/core/indexing.py | sed -n '1,240p'\r\n"]
[470.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/indexing.py b/pandas/core/indexing.py\r\nindex b3ae53272c..8556b56555 100644\r\n--- a/pandas/core/indexing.py\r\n+++ b/pandas/core/indexing.py\r\n@@ -2636,20 +2636,22 @@ def check_bool_indexer(index: Index, key) -> np.ndarray:\r\n         If the index of the key is unalignable to index.\r\n     \"\"\"\r\n     result = key\r\n-    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n-        indexer = result.index.get_indexer_for(index)\r\n-        if -1 in indexer:\r\n-            raise IndexingError(\r\n+    if isinstance(key, ABCSeries):\r\n+        # Fastpath: avoid expensive equals() when index objects are identical\r\n+        if result.index is not index and not result.index.equals(index):\r\n+            indexer = result.index.get_indexer_for(index)\r\n+            if -1 in indexer:\r\n+                raise IndexingError(\r\n                 \"Unalignable boolean Series provided as \"\r\n                 \"indexer (index of the boolean Series and of \"\r\n                 \"the indexed object do not match).\"\r\n             )\r\n \r\n-        result = result.take(indexer)\r\n+            result = result.take(indexer)\r\n \r\n-        # fall through for boolean\r\n-        if not isinstance(result.dtype, ExtensionDtype):\r\n-            return result.astype(bool)._values\r\n+            # fall through for boolean\r\n+            if not isinstance(result.dtype, ExtensionDtype):\r\n+                return result.astype(bool)._values\r\n \r\n     if is_object_dtype(key):\r\n         # key might be object-dtype bool, check_array_indexer needs bool array\r\n"]
[475.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[475.002, "i", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[475.004, "o", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[475.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (indexing.DataFrameStringIndexing.time_at--)\u001b[0m.......\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at\u001b[0m                                                                                                12.2\u00b10.5\u03bcs\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at_setitem\u001b[0m                                                                                        12.9\u00b10.2\u03bcs\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows\u001b[0m                                                                                       118\u00b10.8\u03bcs\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_boolean\u001b[0m                                                                                 115\u00b11\u03bcs\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_object\u001b[0m                                                                                  165\u00b14\u03bcs\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_getitem_scalar\u001b[0m                                                                                    12.7\u00b10.2\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_loc\u001b[0m                                                                                               18.3\u00b10.2\u03bcs\r\n"]
[480.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[480.002, "i", "sed -n '2628,2675p' ../pandas/core/indexing.py\r"]
[480.004, "o", "sed -n '2628,2675p' ../pandas/core/indexing.py\r\n"]
[480.006, "o", "\u001b[?2004l\r\n    np.array\r\n        Resulting key.\r\n\r\n    Raises\r\n    ------\r\n    IndexError\r\n        If the key does not have the same length as index.\r\n    IndexingError\r\n        If the index of the key is unalignable to index.\r\n    \"\"\"\r\n    result = key\r\n    if isinstance(key, ABCSeries):\r\n        # Fastpath: avoid expensive equals() when index objects are identical\r\n        if result.index is not index and not result.index.equals(index):\r\n            indexer = result.index.get_indexer_for(index)\r\n            if -1 in indexer:\r\n                raise IndexingError(\r\n                \"Unalignable boolean Series provided as \"\r\n                \"indexer (index of the boolean Series and of \"\r\n                \"the indexed object do not match).\"\r\n            )\r\n\r\n            result = result.take(indexer)\r\n\r\n            # fall through for boolean\r\n            if not isinstance(result.dtype, ExtensionDtype):\r\n                return result.astype(bool)._values\r\n\r\n    if is_object_dtype(key):\r\n        # key might be object-dtype bool, check_array_indexer needs bool array\r\n        result = np.asarray(result, dtype=bool)\r\n    elif not is_array_like(result):\r\n        # GH 33924\r\n        # key may contain nan elements, check_array_indexer needs bool array\r\n        result = pd_array(result, dtype=bool)\r\n    return check_array_indexer(index, result)\r\n\r\n\r\ndef convert_missing_indexer(indexer):\r\n    \"\"\"\r\n    Reverse convert a missing indexer, which is a dict\r\n    return the scalar indexer and a boolean indicating if we converted\r\n    \"\"\"\r\n    if isinstance(indexer, dict):\r\n        # a missing key (but not a tuple indexer)\r\n        indexer = indexer[\"key\"]\r\n\r\n        if isinstance(indexer, bool):\r\n"]
[485.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[485.002, "i", "python - << 'PY'\r"]
[485.004, "o", "python - << 'PY'\r\n"]
[485.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/indexing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> needle = '\\n    if is_object_dtype(key):'\r\n\u001b[?2004l\r\n\u001b[?2004h> abc_start = s.rfind('if isinstance(key, ABCSeries):', 0, s.find(needle))\r\n\u001b[?2004l\r\n\u001b[?2004h> inner_if = s.find('if result.index is not index and not result.index.equals(index):', abc_start)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Only insert if the else block is not already present\r\n\u001b[?2004l\r\n\u001b[?2004h> if abc_start != -1 and inner_if != -1 and 'else:\\n            if not isinstance(result.dtype, ExtensionDtype):' not in s[abc_start:s.find(needle)]:\r\n\u001b[?2004l\r\n\u001b[?2004h>     insertion = (\r\n\u001b[?2004l\r\n\u001b[?2004h>         '        else:\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>         '            if not isinstance(result.dtype, ExtensionDtype):\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>         '                return result.astype(bool)._values\\n\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     )\r\n\u001b[?2004l\r\n\u001b[?2004h>     s = s.replace(needle, insertion + '    if is_object_dtype(key):', 1)\r\n\u001b[?2004l\r\n\u001b[?2004h>     p.write_text(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Inserted early-return else block for identical-index boolean Series')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Skip insertion (not found or already present)')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nInserted early-return else block for identical-index boolean Series\r\n"]
[490.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[490.002, "i", "git diff -- ../pandas/core/indexing.py | sed -n '1,240p'\r"]
[490.004, "o", "git diff -- ../pandas/core/indexing.py | sed -n '1,240p'\r\n"]
[490.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/indexing.py b/pandas/core/indexing.py\r\nindex b3ae53272c..8fde1a2f4a 100644\r\n--- a/pandas/core/indexing.py\r\n+++ b/pandas/core/indexing.py\r\n@@ -2636,20 +2636,25 @@ def check_bool_indexer(index: Index, key) -> np.ndarray:\r\n         If the index of the key is unalignable to index.\r\n     \"\"\"\r\n     result = key\r\n-    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n-        indexer = result.index.get_indexer_for(index)\r\n-        if -1 in indexer:\r\n-            raise IndexingError(\r\n+    if isinstance(key, ABCSeries):\r\n+        # Fastpath: avoid expensive equals() when index objects are identical\r\n+        if result.index is not index and not result.index.equals(index):\r\n+            indexer = result.index.get_indexer_for(index)\r\n+            if -1 in indexer:\r\n+                raise IndexingError(\r\n                 \"Unalignable boolean Series provided as \"\r\n                 \"indexer (index of the boolean Series and of \"\r\n                 \"the indexed object do not match).\"\r\n             )\r\n \r\n-        result = result.take(indexer)\r\n+            result = result.take(indexer)\r\n \r\n-        # fall through for boolean\r\n-        if not isinstance(result.dtype, ExtensionDtype):\r\n-            return result.astype(bool)._values\r\n+            # fall through for boolean\r\n+            if not isinstance(result.dtype, ExtensionDtype):\r\n+                return result.astype(bool)._values\r\n+        else:\r\n+            if not isinstance(result.dtype, ExtensionDtype):\r\n+                return result.astype(bool)._values\r\n \r\n     if is_object_dtype(key):\r\n         # key might be object-dtype bool, check_array_indexer needs bool array\r\n"]
[495.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[495.002, "i", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[495.004, "o", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[495.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (indexing.DataFrameStringIndexing.time_at--)\u001b[0m.......\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at\u001b[0m                                                                                                12.7\u00b10.3\u03bcs\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at_setitem\u001b[0m                                                                                        12.9\u00b10.2\u03bcs\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows\u001b[0m                                                                                         128\u00b12\u03bcs\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_boolean\u001b[0m                                                                                 115\u00b11\u03bcs\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_object\u001b[0m                                                                                  193\u00b11\u03bcs\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_getitem_scalar\u001b[0m                                                                                    13.4\u00b10.1\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_loc\u001b[0m                                                                                                 18.9\u00b11\u03bcs\r\n"]
[500.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[500.002, "i", "python - << 'PY'\r"]
[500.004, "o", "python - << 'PY'\r\n"]
[500.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/indexing.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> added = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     '        else:\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     '            if not isinstance(result.dtype, ExtensionDtype):\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h>     '                return result.astype(bool)._values\\n\\n'\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> if added in s:\r\n\u001b[?2004l\r\n\u001b[?2004h>     s = s.replace(added, '')\r\n\u001b[?2004l\r\n\u001b[?2004h>     p.write_text(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Reverted early-return else block')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Early-return else block not found; nothing to revert')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nReverted early-return else block\r\n"]
[505.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[505.002, "i", "git diff -- ../pandas/core/indexing.py | sed -n '1,200p'\r"]
[505.004, "o", "git diff -- ../pandas/core/indexing.py | sed -n '1,200p'\r\n"]
[505.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/indexing.py b/pandas/core/indexing.py\r\nindex b3ae53272c..4d114175c9 100644\r\n--- a/pandas/core/indexing.py\r\n+++ b/pandas/core/indexing.py\r\n@@ -2636,21 +2636,22 @@ def check_bool_indexer(index: Index, key) -> np.ndarray:\r\n         If the index of the key is unalignable to index.\r\n     \"\"\"\r\n     result = key\r\n-    if isinstance(key, ABCSeries) and not key.index.equals(index):\r\n-        indexer = result.index.get_indexer_for(index)\r\n-        if -1 in indexer:\r\n-            raise IndexingError(\r\n+    if isinstance(key, ABCSeries):\r\n+        # Fastpath: avoid expensive equals() when index objects are identical\r\n+        if result.index is not index and not result.index.equals(index):\r\n+            indexer = result.index.get_indexer_for(index)\r\n+            if -1 in indexer:\r\n+                raise IndexingError(\r\n                 \"Unalignable boolean Series provided as \"\r\n                 \"indexer (index of the boolean Series and of \"\r\n                 \"the indexed object do not match).\"\r\n             )\r\n \r\n-        result = result.take(indexer)\r\n-\r\n-        # fall through for boolean\r\n-        if not isinstance(result.dtype, ExtensionDtype):\r\n-            return result.astype(bool)._values\r\n+            result = result.take(indexer)\r\n \r\n+            # fall through for boolean\r\n+            if not isinstance(result.dtype, ExtensionDtype):\r\n+                return result.astype(bool)._values\r\n     if is_object_dtype(key):\r\n         # key might be object-dtype bool, check_array_indexer needs bool array\r\n         result = np.asarray(result, dtype=bool)\r\n"]
[510.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[510.002, "i", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[510.004, "o", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[510.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (indexing.DataFrameStringIndexing.time_at--)\u001b[0m.......\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at\u001b[0m                                                                                                12.8\u00b10.6\u03bcs\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at_setitem\u001b[0m                                                                                        13.5\u00b10.8\u03bcs\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows\u001b[0m                                                                                       116\u00b10.9\u03bcs\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_boolean\u001b[0m                                                                               114\u00b10.7\u03bcs\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_object\u001b[0m                                                                                  169\u00b12\u03bcs\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_getitem_scalar\u001b[0m                                                                                    13.4\u00b10.2\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_loc\u001b[0m                                                                                               18.2\u00b10.3\u03bcs\r\n"]
[515.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[515.002, "i", "sed -n '/def is_bool_indexer(/,/^def /p' ../pandas/core/common.py\r"]
[515.004, "o", "sed -n '/def is_bool_indexer(/,/^def /p' ../pandas/core/common.py\r\n"]
[515.006, "o", "\u001b[?2004l\r\ndef is_bool_indexer(key: Any) -> bool:\r\n    \"\"\"\r\n    Check whether `key` is a valid boolean indexer.\r\n\r\n    Parameters\r\n    ----------\r\n    key : Any\r\n        Only list-likes may be considered boolean indexers.\r\n        All other types are not considered a boolean indexer.\r\n        For array-like input, boolean ndarrays or ExtensionArrays\r\n        with ``_is_boolean`` set are considered boolean indexers.\r\n\r\n    Returns\r\n    -------\r\n    bool\r\n        Whether `key` is a valid boolean indexer.\r\n\r\n    Raises\r\n    ------\r\n    ValueError\r\n        When the array is an object-dtype ndarray or ExtensionArray\r\n        and contains missing values.\r\n\r\n    See Also\r\n    --------\r\n    check_array_indexer : Check that `key` is a valid array to index,\r\n        and convert to an ndarray.\r\n    \"\"\"\r\n    if isinstance(\r\n        key, (ABCSeries, np.ndarray, ABCIndex, ABCExtensionArray)\r\n    ) and not isinstance(key, ABCMultiIndex):\r\n        if key.dtype == np.object_:\r\n            key_array = np.asarray(key)\r\n\r\n            if not lib.is_bool_array(key_array):\r\n                na_msg = \"Cannot mask with non-boolean array containing NA / NaN values\"\r\n                if lib.is_bool_array(key_array, skipna=True):\r\n                    # Don't raise on e.g. [\"A\", \"B\", np.nan], see\r\n                    #  test_loc_getitem_list_of_labels_categoricalindex_with_na\r\n                    raise ValueError(na_msg)\r\n                return False\r\n            return True\r\n        elif is_bool_dtype(key.dtype):\r\n            return True\r\n    elif isinstance(key, list):\r\n        # check if np.array(key).dtype would be bool\r\n        if len(key) > 0:\r\n            if type(key) is not list:  # noqa: E721\r\n                # GH#42461 cython will raise TypeError if we pass a subclass\r\n                key = list(key)\r\n            return lib.is_bool_list(key)\r\n\r\n    return False\r\n\r\n\r\ndef cast_scalar_indexer(val):\r\n"]
[520.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[520.002, "i", "sed -n '3920,4020p' ../pandas/core/frame.py\r"]
[520.004, "o", "sed -n '3920,4020p' ../pandas/core/frame.py\r\n"]
[520.006, "o", "\u001b[?2004l\r\n        if is_single_key:\r\n            # What does looking for a single key in a non-unique index return?\r\n            # The behavior is inconsistent. It returns a Series, except when\r\n            # - the key itself is repeated (test on data.shape, #9519), or\r\n            # - we have a MultiIndex on columns (test on self.columns, #21309)\r\n            if data.shape[1] == 1 and not isinstance(self.columns, MultiIndex):\r\n                # GH#26490 using data[key] can cause RecursionError\r\n                return data._get_item(key)\r\n\r\n        return data\r\n\r\n    def _getitem_bool_array(self, key):\r\n        # also raises Exception if object array with NA values\r\n        # warning here just in case -- previously __setitem__ was\r\n        # reindexing but __getitem__ was not; it seems more reasonable to\r\n        # go with the __setitem__ behavior since that is more consistent\r\n        # with all other indexing behavior\r\n        if isinstance(key, Series) and not key.index.equals(self.index):\r\n            warnings.warn(\r\n                \"Boolean Series key will be reindexed to match DataFrame index.\",\r\n                UserWarning,\r\n                stacklevel=find_stack_level(),\r\n            )\r\n        elif len(key) != len(self.index):\r\n            raise ValueError(\r\n                f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\r\n            )\r\n\r\n        # check_bool_indexer will throw exception if Series key cannot\r\n        # be reindexed to match DataFrame rows\r\n        key = check_bool_indexer(self.index, key)\r\n\r\n        if key.all():\r\n            return self.copy(deep=False)\r\n\r\n        indexer = key.nonzero()[0]\r\n        return self.take(indexer, axis=0)\r\n\r\n    def _getitem_multilevel(self, key):\r\n        # self.columns is a MultiIndex\r\n        loc = self.columns.get_loc(key)\r\n        if isinstance(loc, (slice, np.ndarray)):\r\n            new_columns = self.columns[loc]\r\n            result_columns = maybe_droplevels(new_columns, key)\r\n            result = self.iloc[:, loc]\r\n            result.columns = result_columns\r\n\r\n            # If there is only one column being returned, and its name is\r\n            # either an empty string, or a tuple with an empty string as its\r\n            # first element, then treat the empty string as a placeholder\r\n            # and return the column as if the user had provided that empty\r\n            # string in the key. If the result is a Series, exclude the\r\n            # implied empty string from its name.\r\n            if len(result.columns) == 1:\r\n                # e.g. test_frame_getitem_multicolumn_empty_level,\r\n                #  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\r\n                top = result.columns[0]\r\n                if isinstance(top, tuple):\r\n                    top = top[0]\r\n                if top == \"\":\r\n                    result = result[\"\"]\r\n                    if isinstance(result, Series):\r\n                        result = self._constructor_sliced(\r\n                            result, index=self.index, name=key\r\n                        )\r\n\r\n            return result\r\n        else:\r\n            # loc is neither a slice nor ndarray, so must be an int\r\n            return self._ixs(loc, axis=1)\r\n\r\n    def _get_value(self, index, col, takeable: bool = False) -> Scalar:\r\n        \"\"\"\r\n        Quickly retrieve single value at passed column and index.\r\n\r\n        Parameters\r\n        ----------\r\n        index : row label\r\n        col : column label\r\n        takeable : interpret the index/col as indexers, default False\r\n\r\n        Returns\r\n        -------\r\n        scalar\r\n\r\n        Notes\r\n        -----\r\n        Assumes that both `self.index._index_as_unique` and\r\n        `self.columns._index_as_unique`; Caller is responsible for checking.\r\n        \"\"\"\r\n        if takeable:\r\n            series = self._ixs(col, axis=1)\r\n            return series._values[index]\r\n\r\n        series = self._get_item(col)\r\n        engine = self.index._engine\r\n\r\n        if not isinstance(self.index, MultiIndex):\r\n            # CategoricalIndex: Trying to use the engine fastpath may give incorrect\r\n            #  results if our categories are integers that dont match our codes\r\n            # IntervalIndex: IntervalTree has no get_loc\r\n"]
[525.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[525.002, "i", "git add ../pandas/core/indexing.py && git commit -m \"perf(indexing): fast-path in check_bool_indexer to s\r"]
[525.004, "o", "git add ../pandas/core/indexing.py && git commit -m \"perf(indexing): fast-path in check_bool_indexer to s\r\n"]
[525.006, "o", "skip Index.equals when index objects are identical for boolean Series masks\"\r\n\u001b[?2004l\r\nAuthor identity unknown\r\n\r\n*** Please tell me who you are.\r\n\r\nRun\r\n\r\n  git config --global user.email \"you@example.com\"\r\n  git config --global user.name \"Your Name\"\r\n\r\nto set your account's default identity.\r\nOmit --global to set the identity only in this repository.\r\n\r\nfatal: unable to auto-detect email address (got 'root@a3191d0fdab3.(none)')\r\n"]
[530.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[530.002, "i", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[530.004, "o", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[530.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (indexing.DataFrameStringIndexing.time_at--)\u001b[0m.......\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at\u001b[0m                                                                                                12.9\u00b10.1\u03bcs\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at_setitem\u001b[0m                                                                                        12.9\u00b10.5\u03bcs\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows\u001b[0m                                                                                         117\u00b12\u03bcs\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_boolean\u001b[0m                                                                               116\u00b10.8\u03bcs\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_object\u001b[0m                                                                                  172\u00b11\u03bcs\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_getitem_scalar\u001b[0m                                                                                    13.9\u00b10.1\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_loc\u001b[0m                                                                                                 18.3\u00b11\u03bcs\r\n"]
[535.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[535.002, "i", "python - << 'PY'\r"]
[535.004, "o", "python - << 'PY'\r\n"]
[535.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('../pandas/core/frame.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> old = '        if isinstance(key, Series) and not key.index.equals(self.index):'\r\n\u001b[?2004l\r\n\u001b[?2004h> new = '        if isinstance(key, Series) and (key.index is not self.index) and not key.index.equals(self.index):'\r\n\u001b[?2004l\r\n\u001b[?2004h> if old in s:\r\n\u001b[?2004l\r\n\u001b[?2004h>     s = s.replace(old, new)\r\n\u001b[?2004l\r\n\u001b[?2004h>     p.write_text(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Patched DataFrame._getitem_bool_array to avoid unnecessary equals on identical index objects')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Pattern not found; no changes made')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nPatched DataFrame._getitem_bool_array to avoid unnecessary equals on identical index objects\r\n"]
[540.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[540.002, "i", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r"]
[540.004, "o", "asv run --python=same --bench=\"indexing.DataFrameStringIndexing.*\"\r\n"]
[540.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (indexing.DataFrameStringIndexing.time_at--)\u001b[0m.......\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at\u001b[0m                                                                                                12.9\u00b10.4\u03bcs\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_at_setitem\u001b[0m                                                                                        12.3\u00b10.6\u03bcs\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows\u001b[0m                                                                                         120\u00b11\u03bcs\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_boolean\u001b[0m                                                                                 119\u00b11\u03bcs\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_boolean_rows_object\u001b[0m                                                                                  173\u00b14\u03bcs\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_getitem_scalar\u001b[0m                                                                                    13.3\u00b10.3\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindexing.DataFrameStringIndexing.time_loc\u001b[0m                                                                                               18.8\u00b10.4\u03bcs\r\n"]
[545.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[545.002, "i", "git status -sb\r"]
[545.004, "o", "git status -sb\r\n"]
[545.006, "o", "\u001b[?2004l\r\n## \u001b[32mmain\u001b[m\r\n \u001b[31mM\u001b[m ../pandas/core/frame.py\r\n\u001b[32mM\u001b[m  ../pandas/core/indexing.py\r\n"]
[550.0, "o", "(asv_3.10) root@a3191d0fdab3:/workspace/repo/asv_bench# "]
[550.002, "i", "\u001b[?2004l\r"]
[550.004, "o", "\u001b[?2004l\r\n"]
[550.006, "o", "\r\nlogout\r\n"]
