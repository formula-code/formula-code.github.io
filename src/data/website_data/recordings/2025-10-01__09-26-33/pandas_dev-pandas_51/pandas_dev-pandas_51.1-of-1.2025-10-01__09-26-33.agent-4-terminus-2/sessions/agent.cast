{"version": 2, "width": 160, "height": 40, "timestamp": 1762995183, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[1.242, "o", "\u001b[?2004l\r\n"]
[2.478, "o", "\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n"]
[3.714, "o", "\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[7.478, "o", "\u001b[?2004l\r\n"]
[10.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.136105, "o", "\u001b[?2004l\r\n"]
[10.266211, "o", "total 220\r\n"]
[10.396316, "o", "drwxr-xr-x 1 root root  4096 Oct  1 16:20 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[10.526421, "o", "drwxr-xr-x 1 root root  4096 Sep 15 17:52 \u001b[01;34m..\u001b[0m\r\n"]
[10.656526, "o", "drwxr-xr-x 2 root root  4096 Sep 12 21:44 \u001b[01;34m.circleci\u001b[0m\r\n"]
[10.786632, "o", "-rw-r--r-- 1 root root  1021 Sep 12 21:44 .devcontainer.json\r\n"]
[10.916737, "o", "drwxr-xr-x 1 root root  4096 Oct  1 16:20 \u001b[01;34m.git\u001b[0m\r\n"]
[11.046842, "o", "-rw-r--r-- 1 root root  1670 Sep 12 21:44 .gitattributes\r\n"]
[11.176947, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34m.github\u001b[0m\r\n"]
[11.307053, "o", "-rw-r--r-- 1 root root  1919 Sep 12 21:44 .gitignore\r\n"]
[11.437158, "o", "-rw-r--r-- 1 root root  2296 Sep 12 21:44 .gitpod.yml\r\n"]
[11.567263, "o", "-rw-r--r-- 1 root root 13648 Sep 12 21:44 .pre-commit-config.yaml\r\n"]
[11.697368, "o", "-rw-r--r-- 1 root root  2284 Sep 12 21:44 AUTHORS.md\r\n"]
[11.827474, "o", "-rw-r--r-- 1 root root  1541 Sep 12 21:43 CITATION.cff\r\n"]
[11.957579, "o", "-rw-r--r-- 1 root root   369 Sep 12 21:44 Dockerfile\r\n"]
[12.087684, "o", "-rw-r--r-- 1 root root  1634 Sep 12 21:44 LICENSE\r\n"]
[12.217789, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mLICENSES\u001b[0m\r\n"]
[12.347895, "o", "-rw-r--r-- 1 root root  1335 Sep 12 21:44 MANIFEST.in\r\n"]
[12.478, "o", "-rw-r--r-- 1 root root 11537 Sep 12 21:44 README.md\r\n"]
[12.608105, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34masv_bench\u001b[0m\r\n"]
[12.738211, "o", "drwxr-xr-x 1 root root  4096 Sep 15 17:46 \u001b[01;34mbuild\u001b[0m\r\n"]
[12.868316, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mci\u001b[0m\r\n"]
[12.998421, "o", "-rw-r--r-- 1 root root   256 Sep 12 21:43 codecov.yml\r\n"]
[13.128526, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mdoc\u001b[0m\r\n"]
[13.258632, "o", "-rw-r--r-- 1 root root  2550 Sep 12 21:44 environment.yml\r\n"]
[13.388737, "o", "-rw-r--r-- 1 root root   866 Sep 12 21:43 generate_pxi.py\r\n"]
[13.518842, "o", "-rw-r--r-- 1 root root  1715 Sep 12 21:43 generate_version.py\r\n"]
[13.648947, "o", "drwxr-xr-x 2 root root  4096 Sep 12 21:43 \u001b[01;34mgitpod\u001b[0m\r\n"]
[13.779053, "o", "-rw-r--r-- 1 root root  1646 Sep 12 21:44 meson.build\r\n"]
[13.909158, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mpandas\u001b[0m\r\n"]
[14.039263, "o", "-rw-r--r-- 1 root root 23914 Sep 12 21:44 pyproject.toml\r\n"]
[14.169368, "o", "-rw-r--r-- 1 root root  4129 Sep 12 21:44 pyright_reportGeneralTypeIssues.json\r\n"]
[14.299474, "o", "-rw-r--r-- 1 root root  1390 Sep 12 21:44 requirements-dev.txt\r\n"]
[14.429579, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mscripts\u001b[0m\r\n"]
[14.559684, "o", "-rwxr-xr-x 1 root root 21962 Sep 12 21:44 \u001b[01;32msetup.py\u001b[0m\r\n"]
[14.689789, "o", "drwxr-xr-x 3 root root  4096 Sep 12 21:43 \u001b[01;34mtooling\u001b[0m\r\n"]
[14.819895, "o", "drwxr-xr-x 2 root root  4096 Sep 12 21:43 \u001b[01;34mtypings\u001b[0m\r\n"]
[15.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[15.002, "i", "git status -s\r"]
[15.004, "o", "git status -s\r\n"]
[15.006, "o", "\u001b[?2004l\r\n"]
[20.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[20.002, "i", "find . -maxdepth 2 -type f -name \"asv*.json\" -o -name \"asv.conf.json\" -o -name \"asv*.cfg\"\r"]
[20.004, "o", "find . -maxdepth 2 -type f -name \"asv*.json\" -o -name \"asv.conf.json\" -o -name \"asv*.cfg\"\r\n"]
[22.478, "o", "\u001b[?2004l\r\n"]
[25.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[25.002, "i", "grep -RIn \"GetItemMask\" . || true\r"]
[25.004, "o", "grep -RIn \"GetItemMask\" . || true\r\n"]
[27.478, "o", "\u001b[?2004l\r\n"]
[30.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[30.002, "i", "grep -RIn \"sparse.GetItemMask\" . || true\r"]
[30.004, "o", "grep -RIn \"sparse.GetItemMask\" . || true\r\n"]
[30.006, "o", "\u001b[?2004l\r\n"]
[35.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[35.002, "i", "ls -la asv_bench || true\r"]
[35.004, "o", "ls -la asv_bench || true\r\n"]
[35.83, "o", "\u001b[?2004l\r\n"]
[36.654, "o", "total 24\r\n"]
[37.478, "o", "drwxr-xr-x 1 root root 4096 Sep 12 21:44 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[38.302, "o", "drwxr-xr-x 1 root root 4096 Oct  1 16:20 \u001b[01;34m..\u001b[0m\r\n"]
[39.126, "o", "-rw-r--r-- 1 root root 5171 Sep 12 21:44 asv.conf.json\r\n"]
[40.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[40.002, "i", "rg -n \"class .*GetItemMask|def .*GetItemMask|GetItemMask\" asv* bench* benchmarks* asv_bench 2>/dev/null || true\r"]
[40.004, "o", "rg -n \"class .*GetItemMask|def .*GetItemMask|GetItemMask\" asv* bench* benchmarks* asv_bench 2>/dev/null || true\r\n"]
[40.006, "o", "\u001b[?2004l\r\n"]
[45.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[45.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[45.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[47.478, "o", "\u001b[?2004l\r\n"]
[50.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[50.002, "i", "sed -n '1,240p' asv_bench/benchmarks/sparse.py\r"]
[50.004, "o", "sed -n '1,240p' asv_bench/benchmarks/sparse.py\r\n"]
[50.027684, "o", "\u001b[?2004l\r\n"]
[50.049368, "o", "import numpy as np\r\n"]
[50.071053, "o", "import scipy.sparse\r\n"]
[50.092737, "o", "\r\n"]
[50.114421, "o", "import pandas as pd\r\n"]
[50.136105, "o", "from pandas import (\r\n"]
[50.157789, "o", "    MultiIndex,\r\n"]
[50.179474, "o", "    Series,\r\n"]
[50.201158, "o", "    date_range,\r\n"]
[50.222842, "o", ")\r\n"]
[50.244526, "o", "from pandas.arrays import SparseArray\r\n"]
[50.266211, "o", "\r\n"]
[50.287895, "o", "\r\n"]
[50.309579, "o", "def make_array(size, dense_proportion, fill_value, dtype):\r\n"]
[50.331263, "o", "    dense_size = int(size * dense_proportion)\r\n"]
[50.352947, "o", "    arr = np.full(size, fill_value, dtype)\r\n"]
[50.374632, "o", "    indexer = np.random.choice(np.arange(size), dense_size, replace=False)\r\n"]
[50.396316, "o", "    arr[indexer] = np.random.choice(np.arange(100, dtype=dtype), dense_size)\r\n"]
[50.418, "o", "    return arr\r\n"]
[50.439684, "o", "\r\n"]
[50.461368, "o", "\r\n"]
[50.483053, "o", "class SparseSeriesToFrame:\r\n"]
[50.504737, "o", "    def setup(self):\r\n"]
[50.526421, "o", "        K = 50\r\n"]
[50.548105, "o", "        N = 50001\r\n"]
[50.569789, "o", "        rng = date_range(\"1/1/2000\", periods=N, freq=\"min\")\r\n"]
[50.591474, "o", "        self.series = {}\r\n"]
[50.613158, "o", "        for i in range(1, K):\r\n"]
[50.634842, "o", "            data = np.random.randn(N)[:-i]\r\n"]
[50.656526, "o", "            idx = rng[:-i]\r\n"]
[50.678211, "o", "            data[100:] = np.nan\r\n"]
[50.699895, "o", "            self.series[i] = Series(SparseArray(data), index=idx)\r\n"]
[50.721579, "o", "\r\n"]
[50.743263, "o", "    def time_series_to_frame(self):\r\n"]
[50.764947, "o", "        pd.DataFrame(self.series)\r\n"]
[50.786632, "o", "\r\n"]
[50.808316, "o", "\r\n"]
[50.83, "o", "class SparseArrayConstructor:\r\n"]
[50.851684, "o", "    params = ([0.1, 0.01], [0, np.nan], [np.int64, np.float64, object])\r\n"]
[50.873368, "o", "    param_names = [\"dense_proportion\", \"fill_value\", \"dtype\"]\r\n"]
[50.895053, "o", "\r\n"]
[50.916737, "o", "    def setup(self, dense_proportion, fill_value, dtype):\r\n"]
[50.938421, "o", "        N = 10**6\r\n"]
[50.960105, "o", "        self.array = make_array(N, dense_proportion, fill_value, dtype)\r\n"]
[50.981789, "o", "\r\n"]
[51.003474, "o", "    def time_sparse_array(self, dense_proportion, fill_value, dtype):\r\n"]
[51.025158, "o", "        SparseArray(self.array, fill_value=fill_value, dtype=dtype)\r\n"]
[51.046842, "o", "\r\n"]
[51.068526, "o", "\r\n"]
[51.090211, "o", "class SparseDataFrameConstructor:\r\n"]
[51.111895, "o", "    def setup(self):\r\n"]
[51.133579, "o", "        N = 1000\r\n"]
[51.155263, "o", "        self.sparse = scipy.sparse.rand(N, N, 0.005)\r\n"]
[51.176947, "o", "\r\n"]
[51.198632, "o", "    def time_from_scipy(self):\r\n"]
[51.220316, "o", "        pd.DataFrame.sparse.from_spmatrix(self.sparse)\r\n"]
[51.242, "o", "\r\n"]
[51.263684, "o", "\r\n"]
[51.285368, "o", "class FromCoo:\r\n"]
[51.307053, "o", "    def setup(self):\r\n"]
[51.328737, "o", "        self.matrix = scipy.sparse.coo_matrix(\r\n"]
[51.350421, "o", "            ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(100, 100)\r\n"]
[51.372105, "o", "        )\r\n"]
[51.393789, "o", "\r\n"]
[51.415474, "o", "    def time_sparse_series_from_coo(self):\r\n"]
[51.437158, "o", "        Series.sparse.from_coo(self.matrix)\r\n"]
[51.458842, "o", "\r\n"]
[51.480526, "o", "\r\n"]
[51.502211, "o", "class ToCoo:\r\n"]
[51.523895, "o", "    params = [True, False]\r\n"]
[51.545579, "o", "    param_names = [\"sort_labels\"]\r\n"]
[51.567263, "o", "\r\n"]
[51.588947, "o", "    def setup(self, sort_labels):\r\n"]
[51.610632, "o", "        s = Series([np.nan] * 10000)\r\n"]
[51.632316, "o", "        s[0] = 3.0\r\n"]
[51.654, "o", "        s[100] = -1.0\r\n"]
[51.675684, "o", "        s[999] = 12.1\r\n"]
[51.697368, "o", "\r\n"]
[51.719053, "o", "        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\r\n"]
[51.740737, "o", "        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\r\n"]
[51.762421, "o", "\r\n"]
[51.784105, "o", "        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\r\n"]
[51.805789, "o", "        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")\r\n"]
[51.827474, "o", "\r\n"]
[51.849158, "o", "    def time_sparse_series_to_coo(self, sort_labels):\r\n"]
[51.870842, "o", "        self.ss_mult_lvl.sparse.to_coo(\r\n"]
[51.892526, "o", "            row_levels=[0, 1], column_levels=[2, 3], sort_labels=sort_labels\r\n"]
[51.914211, "o", "        )\r\n"]
[51.935895, "o", "\r\n"]
[51.957579, "o", "    def time_sparse_series_to_coo_single_level(self, sort_labels):\r\n"]
[51.979263, "o", "        self.ss_two_lvl.sparse.to_coo(sort_labels=sort_labels)\r\n"]
[52.000947, "o", "\r\n"]
[52.022632, "o", "\r\n"]
[52.044316, "o", "class ToCooFrame:\r\n"]
[52.066, "o", "    def setup(self):\r\n"]
[52.087684, "o", "        N = 10000\r\n"]
[52.109368, "o", "        k = 10\r\n"]
[52.131053, "o", "        arr = np.zeros((N, k), dtype=float)\r\n"]
[52.152737, "o", "        arr[0, 0] = 3.0\r\n"]
[52.174421, "o", "        arr[12, 7] = -1.0\r\n"]
[52.196105, "o", "        arr[0, 9] = 11.2\r\n"]
[52.217789, "o", "        self.df = pd.DataFrame(arr, dtype=pd.SparseDtype(\"float\", fill_value=0.0))\r\n"]
[52.239474, "o", "\r\n"]
[52.261158, "o", "    def time_to_coo(self):\r\n"]
[52.282842, "o", "        self.df.sparse.to_coo()\r\n"]
[52.304526, "o", "\r\n"]
[52.326211, "o", "\r\n"]
[52.347895, "o", "class Arithmetic:\r\n"]
[52.369579, "o", "    params = ([0.1, 0.01], [0, np.nan])\r\n"]
[52.391263, "o", "    param_names = [\"dense_proportion\", \"fill_value\"]\r\n"]
[52.412947, "o", "\r\n"]
[52.434632, "o", "    def setup(self, dense_proportion, fill_value):\r\n"]
[52.456316, "o", "        N = 10**6\r\n"]
[52.478, "o", "        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\r\n"]
[52.499684, "o", "        self.array1 = SparseArray(arr1, fill_value=fill_value)\r\n"]
[52.521368, "o", "        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\r\n"]
[52.543053, "o", "        self.array2 = SparseArray(arr2, fill_value=fill_value)\r\n"]
[52.564737, "o", "\r\n"]
[52.586421, "o", "    def time_make_union(self, dense_proportion, fill_value):\r\n"]
[52.608105, "o", "        self.array1.sp_index.make_union(self.array2.sp_index)\r\n"]
[52.629789, "o", "\r\n"]
[52.651474, "o", "    def time_intersect(self, dense_proportion, fill_value):\r\n"]
[52.673158, "o", "        self.array1.sp_index.intersect(self.array2.sp_index)\r\n"]
[52.694842, "o", "\r\n"]
[52.716526, "o", "    def time_add(self, dense_proportion, fill_value):\r\n"]
[52.738211, "o", "        self.array1 + self.array2\r\n"]
[52.759895, "o", "\r\n"]
[52.781579, "o", "    def time_divide(self, dense_proportion, fill_value):\r\n"]
[52.803263, "o", "        self.array1 / self.array2\r\n"]
[52.824947, "o", "\r\n"]
[52.846632, "o", "\r\n"]
[52.868316, "o", "class ArithmeticBlock:\r\n"]
[52.89, "o", "    params = [np.nan, 0]\r\n"]
[52.911684, "o", "    param_names = [\"fill_value\"]\r\n"]
[52.933368, "o", "\r\n"]
[52.955053, "o", "    def setup(self, fill_value):\r\n"]
[52.976737, "o", "        N = 10**6\r\n"]
[52.998421, "o", "        self.arr1 = self.make_block_array(\r\n"]
[53.020105, "o", "            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\r\n"]
[53.041789, "o", "        )\r\n"]
[53.063474, "o", "        self.arr2 = self.make_block_array(\r\n"]
[53.085158, "o", "            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\r\n"]
[53.106842, "o", "        )\r\n"]
[53.128526, "o", "\r\n"]
[53.150211, "o", "    def make_block_array(self, length, num_blocks, block_size, fill_value):\r\n"]
[53.171895, "o", "        arr = np.full(length, fill_value)\r\n"]
[53.193579, "o", "        indices = np.random.choice(\r\n"]
[53.215263, "o", "            np.arange(0, length, block_size), num_blocks, replace=False\r\n"]
[53.236947, "o", "        )\r\n"]
[53.258632, "o", "        for ind in indices:\r\n"]
[53.280316, "o", "            arr[ind : ind + block_size] = np.random.randint(0, 100, block_size)\r\n"]
[53.302, "o", "        return SparseArray(arr, fill_value=fill_value)\r\n"]
[53.323684, "o", "\r\n"]
[53.345368, "o", "    def time_make_union(self, fill_value):\r\n"]
[53.367053, "o", "        self.arr1.sp_index.make_union(self.arr2.sp_index)\r\n"]
[53.388737, "o", "\r\n"]
[53.410421, "o", "    def time_intersect(self, fill_value):\r\n"]
[53.432105, "o", "        self.arr2.sp_index.intersect(self.arr2.sp_index)\r\n"]
[53.453789, "o", "\r\n"]
[53.475474, "o", "    def time_addition(self, fill_value):\r\n"]
[53.497158, "o", "        self.arr1 + self.arr2\r\n"]
[53.518842, "o", "\r\n"]
[53.540526, "o", "    def time_division(self, fill_value):\r\n"]
[53.562211, "o", "        self.arr1 / self.arr2\r\n"]
[53.583895, "o", "\r\n"]
[53.605579, "o", "\r\n"]
[53.627263, "o", "class MinMax:\r\n"]
[53.648947, "o", "    params = ([\"min\", \"max\"], [0.0, np.nan])\r\n"]
[53.670632, "o", "    param_names = [\"func\", \"fill_value\"]\r\n"]
[53.692316, "o", "\r\n"]
[53.714, "o", "    def setup(self, func, fill_value):\r\n"]
[53.735684, "o", "        N = 1_000_000\r\n"]
[53.757368, "o", "        arr = make_array(N, 1e-5, fill_value, np.float64)\r\n"]
[53.779053, "o", "        self.sp_arr = SparseArray(arr, fill_value=fill_value)\r\n"]
[53.800737, "o", "\r\n"]
[53.822421, "o", "    def time_min_max(self, func, fill_value):\r\n"]
[53.844105, "o", "        getattr(self.sp_arr, func)()\r\n"]
[53.865789, "o", "\r\n"]
[53.887474, "o", "\r\n"]
[53.909158, "o", "class Take:\r\n"]
[53.930842, "o", "    params = ([np.array([0]), np.arange(100_000), np.full(100_000, -1)], [True, False])\r\n"]
[53.952526, "o", "    param_names = [\"indices\", \"allow_fill\"]\r\n"]
[53.974211, "o", "\r\n"]
[53.995895, "o", "    def setup(self, indices, allow_fill):\r\n"]
[54.017579, "o", "        N = 1_000_000\r\n"]
[54.039263, "o", "        fill_value = 0.0\r\n"]
[54.060947, "o", "        arr = make_array(N, 1e-5, fill_value, np.float64)\r\n"]
[54.082632, "o", "        self.sp_arr = SparseArray(arr, fill_value=fill_value)\r\n"]
[54.104316, "o", "\r\n"]
[54.126, "o", "    def time_take(self, indices, allow_fill):\r\n"]
[54.147684, "o", "        self.sp_arr.take(indices, allow_fill=allow_fill)\r\n"]
[54.169368, "o", "\r\n"]
[54.191053, "o", "\r\n"]
[54.212737, "o", "class GetItem:\r\n"]
[54.234421, "o", "    def setup(self):\r\n"]
[54.256105, "o", "        N = 1_000_000\r\n"]
[54.277789, "o", "        d = 1e-5\r\n"]
[54.299474, "o", "        arr = make_array(N, d, np.nan, np.float64)\r\n"]
[54.321158, "o", "        self.sp_arr = SparseArray(arr)\r\n"]
[54.342842, "o", "\r\n"]
[54.364526, "o", "    def time_integer_indexing(self):\r\n"]
[54.386211, "o", "        self.sp_arr[78]\r\n"]
[54.407895, "o", "\r\n"]
[54.429579, "o", "    def time_slice(self):\r\n"]
[54.451263, "o", "        self.sp_arr[1:]\r\n"]
[54.472947, "o", "\r\n"]
[54.494632, "o", "\r\n"]
[54.516316, "o", "class GetItemMask:\r\n"]
[54.538, "o", "    params = [True, False, np.nan]\r\n"]
[54.559684, "o", "    param_names = [\"fill_value\"]\r\n"]
[54.581368, "o", "\r\n"]
[54.603053, "o", "    def setup(self, fill_value):\r\n"]
[54.624737, "o", "        N = 1_000_000\r\n"]
[54.646421, "o", "        d = 1e-5\r\n"]
[54.668105, "o", "        arr = make_array(N, d, np.nan, np.float64)\r\n"]
[54.689789, "o", "        self.sp_arr = SparseArray(arr)\r\n"]
[54.711474, "o", "        b_arr = np.full(shape=N, fill_value=fill_value, dtype=np.bool_)\r\n"]
[54.733158, "o", "        fv_inds = np.unique(\r\n"]
[54.754842, "o", "            np.random.randint(low=0, high=N - 1, size=int(N * d), dtype=np.int32)\r\n"]
[54.776526, "o", "        )\r\n"]
[54.798211, "o", "        b_arr[fv_inds] = True if pd.isna(fill_value) else not fill_value\r\n"]
[54.819895, "o", "        self.sp_b_arr = SparseArray(b_arr, dtype=np.bool_, fill_value=fill_value)\r\n"]
[54.841579, "o", "\r\n"]
[54.863263, "o", "    def time_mask(self, fill_value):\r\n"]
[54.884947, "o", "        self.sp_arr[self.sp_b_arr]\r\n"]
[54.906632, "o", "\r\n"]
[54.928316, "o", "\r\n"]
[55.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[55.002, "i", "sed -n '240,520p' asv_bench/benchmarks/sparse.py\r"]
[55.004, "o", "sed -n '240,520p' asv_bench/benchmarks/sparse.py\r\n"]
[55.006, "o", "\u001b[?2004l\r\n"]
[60.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[60.002, "i", "asv run --config=asv_bench/asv.conf.json --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[60.004, "o", "asv run --config=asv_bench/asv.conf.json --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[62.478, "o", "\u001b[?2004l\r\n"]
[65.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[65.002, "i", "cd asv_bench\r"]
[65.004, "o", "cd asv_bench\r\n"]
[65.006, "o", "\u001b[?2004l\r\n"]
[70.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo/asv_bench# "]
[70.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\" --quick\r"]
[70.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\" --quick\r\n"]
[70.386308, "o", "\u001b[?2004l\r\n"]
[70.766615, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[71.146923, "o", "\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n"]
[71.527231, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[71.907538, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39msparse.GetItemMask.time_mask\u001b[0m                                                                                                                    ok\r\n"]
[72.287846, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ==========\u001b[0m\r\n"]
[72.668154, "o", "              fill_value            \r\n"]
[73.048462, "o", "             ------------ ----------\r\n"]
[73.428769, "o", "                 True      12.8\u00b10ms \r\n"]
[73.809077, "o", "                False      187\u00b10\u03bcs  \r\n"]
[74.189385, "o", "                 nan       8.63\u00b10ms \r\n"]
[74.569692, "o", "             ============ ==========\r\n"]
[75.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo/asv_bench# "]
[75.002, "i", "asv profile --python=same sparse.GetItemMask.time_mask\r"]
[75.004, "o", "asv profile --python=same sparse.GetItemMask.time_mask\r\n"]
[76.654, "o", "\u001b[?2004l\r\n"]
[78.302, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[80.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo/asv_bench# "]
[80.002, "i", "cd ..\r"]
[80.004, "o", "cd ..\r\n"]
[80.006, "o", "\u001b[?2004l\r\n"]
[85.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[85.002, "i", "rg -n \"class SparseArray|def __getitem__|def take\\(|mask|boolean\" pandas/arrays/sparse -S || true\r"]
[85.004, "o", "rg -n \"class SparseArray|def __getitem__|def take\\(|mask|boolean\" pandas/arrays/sparse -S || true\r\n"]
[87.478, "o", "\u001b[?2004l\r\n"]
[90.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[90.002, "i", "sed -n '1,260p' pandas/arrays/sparse/array.py\r"]
[90.004, "o", "sed -n '1,260p' pandas/arrays/sparse/array.py\r\n"]
[92.478, "o", "\u001b[?2004l\r\n"]
[95.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[95.002, "i", "sed -n '260,640p' pandas/arrays/sparse/array.py\r"]
[95.004, "o", "sed -n '260,640p' pandas/arrays/sparse/array.py\r\n"]
[97.478, "o", "\u001b[?2004l\r\n"]
[100.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[100.002, "i", "ls -la pandas\r"]
[100.004, "o", "ls -la pandas\r\n"]
[100.220957, "o", "\u001b[?2004l\r\n"]
[100.435913, "o", "total 172\r\n"]
[100.65087, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[100.865826, "o", "drwxr-xr-x 1 root root  4096 Oct  1 16:20 \u001b[01;34m..\u001b[0m\r\n"]
[101.080783, "o", "-rw-r--r-- 1 root root  8713 Sep 12 21:44 __init__.py\r\n"]
[101.295739, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34m_config\u001b[0m\r\n"]
[101.510696, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34m_libs\u001b[0m\r\n"]
[101.725652, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34m_testing\u001b[0m\r\n"]
[101.940609, "o", "-rw-r--r-- 1 root root 14037 Sep 12 21:44 _typing.py\r\n"]
[102.155565, "o", "-rw-r--r-- 1 root root 23612 Sep 12 21:44 _version.py\r\n"]
[102.370522, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mapi\u001b[0m\r\n"]
[102.585478, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34marrays\u001b[0m\r\n"]
[102.800435, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mcompat\u001b[0m\r\n"]
[103.015391, "o", "-rw-r--r-- 1 root root 47613 Sep 12 21:44 conftest.py\r\n"]
[103.230348, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mcore\u001b[0m\r\n"]
[103.445304, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34merrors\u001b[0m\r\n"]
[103.660261, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mio\u001b[0m\r\n"]
[103.875217, "o", "-rw-r--r-- 1 root root   994 Sep 12 21:44 meson.build\r\n"]
[104.090174, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mplotting\u001b[0m\r\n"]
[104.30513, "o", "-rw-r--r-- 1 root root   313 Sep 12 21:44 testing.py\r\n"]
[104.520087, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mtests\u001b[0m\r\n"]
[104.735043, "o", "drwxr-xr-x 1 root root  4096 Sep 12 21:44 \u001b[01;34mtseries\u001b[0m\r\n"]
[105.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[105.002, "i", "find pandas -maxdepth 3 -type f -name \"*sparse*\" -o -name \"*array*.py\" | sed -n '1,200p'\r"]
[105.004, "o", "find pandas -maxdepth 3 -type f -name \"*sparse*\" -o -name \"*array*.py\" | sed -n '1,200p'\r\n"]
[105.2532, "o", "\u001b[?2004l\r\n"]
[105.5004, "o", "pandas/tests/construction/test_extract_array.py\r\n"]
[105.7476, "o", "pandas/tests/util/test_assert_extension_array_equal.py\r\n"]
[105.9948, "o", "pandas/tests/util/test_assert_interval_array_equal.py\r\n"]
[106.242, "o", "pandas/tests/util/test_assert_numpy_array_equal.py\r\n"]
[106.4892, "o", "pandas/tests/arrays/test_array.py\r\n"]
[106.7364, "o", "pandas/tests/arrays/test_ndarray_backed.py\r\n"]
[106.9836, "o", "pandas/tests/copy_view/test_array.py\r\n"]
[107.2308, "o", "pandas/tests/generic/test_to_xarray.py\r\n"]
[107.478, "o", "pandas/tests/tslibs/test_array_to_datetime.py\r\n"]
[107.7252, "o", "pandas/tests/arithmetic/test_array_ops.py\r\n"]
[107.9724, "o", "pandas/tests/extension/test_sparse.py\r\n"]
[108.2196, "o", "pandas/tests/strings/test_string_array.py\r\n"]
[108.4668, "o", "pandas/_libs/sparse.pyi\r\n"]
[108.714, "o", "pandas/_libs/sparse.pyx\r\n"]
[108.9612, "o", "pandas/_libs/sparse_op_helper.pxi.in\r\n"]
[109.2084, "o", "pandas/core/internals/array_manager.py\r\n"]
[109.4556, "o", "pandas/core/ops/array_ops.py\r\n"]
[109.7028, "o", "pandas/core/strings/object_array.py\r\n"]
[110.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[110.002, "i", "grep -RIn \"class SparseArray|def __getitem__|def take\\(|def _getitem|boolean|mask\" pandas 2>/dev/null | sed -n '1,2\r"]
[110.004, "o", "grep -RIn \"class SparseArray|def __getitem__|def take\\(|def _getitem|boolean|mask\" pandas 2>/dev/null | sed -n '1,2\r\n"]
[112.478, "o", "200p'\r\n"]
[115.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[115.002, "i", "python - << 'PY'\r"]
[115.004, "o", "python - << 'PY'\r\n"]
[115.094286, "o", "\u001b[?2004l\r\n"]
[115.182571, "o", "\u001b[?2004h> import numpy as np\r\n"]
[115.270857, "o", "\u001b[?2004l\r\n"]
[115.359143, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[115.447429, "o", "\u001b[?2004l\r\n"]
[115.535714, "o", "\u001b[?2004h> from pandas.arrays import SparseArray\r\n"]
[115.624, "o", "\u001b[?2004l\r\n"]
[115.712286, "o", "\u001b[?2004h> \r\n"]
[115.800571, "o", "\u001b[?2004l\r\n"]
[115.888857, "o", "\u001b[?2004h> N = 1_000_00\r\n"]
[115.977143, "o", "\u001b[?2004l\r\n"]
[116.065429, "o", "\u001b[?2004h> N = 1_000_000\r\n"]
[116.153714, "o", "\u001b[?2004l\r\n"]
[116.242, "o", "\u001b[?2004h> # prepare data and masks similar to benchmark\r\n"]
[116.330286, "o", "\u001b[?2004l\r\n"]
[116.418571, "o", "\u001b[?2004h> arr = np.full(N, np.nan, dtype=float)\r\n"]
[116.506857, "o", "\u001b[?2004l\r\n"]
[116.595143, "o", "\u001b[?2004h> # make a small proportion dense\r\n"]
[116.683429, "o", "\u001b[?2004l\r\n"]
[116.771714, "o", "\u001b[?2004h> idx = np.random.choice(np.arange(N), int(N*1e-5), replace=False)\r\n"]
[116.86, "o", "\u001b[?2004l\r\n"]
[116.948286, "o", "\u001b[?2004h> arr[idx] = np.random.rand(idx.size)\r\n"]
[117.036571, "o", "\u001b[?2004l\r\n"]
[117.124857, "o", "\u001b[?2004h> sp_arr = SparseArray(arr)\r\n"]
[117.213143, "o", "\u001b[?2004l\r\n"]
[117.301429, "o", "\u001b[?2004h> \r\n"]
[117.389714, "o", "\u001b[?2004l\r\n"]
[117.478, "o", "\u001b[?2004h> for fv in [True, False, np.nan]:\r\n"]
[117.566286, "o", "\u001b[?2004l\r\n"]
[117.654571, "o", "\u001b[?2004h>     b_arr = np.full(shape=N, fill_value=fv, dtype=bool)\r\n"]
[117.742857, "o", "\u001b[?2004l\r\n"]
[117.831143, "o", "\u001b[?2004h>     fv_inds = np.unique(np.random.randint(low=0, high=N - 1, size=int(N * 1e-5), dtype=np.int32))\r\n"]
[117.919429, "o", "\u001b[?2004l\r\n"]
[118.007714, "o", "\u001b[?2004h>     b_arr[fv_inds] = True if pd.isna(fv) else (not fv)\r\n"]
[118.096, "o", "\u001b[?2004l\r\n"]
[118.184286, "o", "\u001b[?2004h>     sp_b_arr = SparseArray(b_arr, dtype=bool, fill_value=fv)\r\n"]
[118.272571, "o", "\u001b[?2004l\r\n"]
[118.360857, "o", "\u001b[?2004h>     import time\r\n"]
[118.449143, "o", "\u001b[?2004l\r\n"]
[118.537429, "o", "\u001b[?2004h>     t0 = time.perf_counter()\r\n"]
[118.625714, "o", "\u001b[?2004l\r\n"]
[118.714, "o", "\u001b[?2004h>     _ = sp_arr[sp_b_arr]\r\n"]
[118.802286, "o", "\u001b[?2004l\r\n"]
[118.890571, "o", "\u001b[?2004h>     dt = (time.perf_counter() - t0)*1e3\r\n"]
[118.978857, "o", "\u001b[?2004l\r\n"]
[119.067143, "o", "\u001b[?2004h>     print(f\"fill_value={fv!r} -> {dt:.3f} ms, result len={len(_)}\")\r\n"]
[119.155429, "o", "\u001b[?2004l\r\n"]
[119.243714, "o", "\u001b[?2004h> PY\r\n"]
[119.332, "o", "\u001b[?2004l\r\n"]
[119.420286, "o", "+ /opt/conda/envs/asv_3.10/bin/ninja\r\n"]
[119.508571, "o", "\r\n"]
[119.596857, "o", "[0/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[119.685143, "o", "[1/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[119.773429, "o", "fill_value=True -> 14.444 ms, result len=999990\r\n"]
[119.861714, "o", "fill_value=False -> 0.081 ms, result len=10\r\n"]
[120.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[120.002, "i", "python - << 'PY'\r"]
[120.004, "o", "python - << 'PY'\r\n"]
[120.060933, "o", "\u001b[?2004l\r\n"]
[120.115867, "o", "\u001b[?2004h> import cProfile, pstats, io\r\n"]
[120.1708, "o", "\u001b[?2004l\r\n"]
[120.225733, "o", "\u001b[?2004h> import numpy as np\r\n"]
[120.280667, "o", "\u001b[?2004l\r\n"]
[120.3356, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[120.390533, "o", "\u001b[?2004l\r\n"]
[120.445467, "o", "\u001b[?2004h> from pandas.arrays import SparseArray\r\n"]
[120.5004, "o", "\u001b[?2004l\r\n"]
[120.555333, "o", "\u001b[?2004h> N=1_000_000\r\n"]
[120.610267, "o", "\u001b[?2004l\r\n"]
[120.6652, "o", "\u001b[?2004h> arr=np.full(N, np.nan, dtype=float)\r\n"]
[120.720133, "o", "\u001b[?2004l\r\n"]
[120.775067, "o", "\u001b[?2004h> idx=np.random.choice(np.arange(N), int(N*1e-5), replace=False)\r\n"]
[120.83, "o", "\u001b[?2004l\r\n"]
[120.884933, "o", "\u001b[?2004h> arr[idx]=np.random.rand(idx.size)\r\n"]
[120.939867, "o", "\u001b[?2004l\r\n"]
[120.9948, "o", "\u001b[?2004h> sp_arr=SparseArray(arr)\r\n"]
[121.049733, "o", "\u001b[?2004l\r\n"]
[121.104667, "o", "\u001b[?2004h> fv=True\r\n"]
[121.1596, "o", "\u001b[?2004l\r\n"]
[121.214533, "o", "\u001b[?2004h> b_arr=np.full(shape=N, fill_value=fv, dtype=bool)\r\n"]
[121.269467, "o", "\u001b[?2004l\r\n"]
[121.3244, "o", "\u001b[?2004h> fv_inds=np.unique(np.random.randint(low=0, high=N-1, size=int(N*1e-5), dtype=np.int32))\r\n"]
[121.379333, "o", "\u001b[?2004l\r\n"]
[121.434267, "o", "\u001b[?2004h> b_arr[fv_inds]=True if pd.isna(fv) else (not fv)\r\n"]
[121.4892, "o", "\u001b[?2004l\r\n"]
[121.544133, "o", "\u001b[?2004h> sp_b_arr=SparseArray(b_arr, dtype=bool, fill_value=fv)\r\n"]
[121.599067, "o", "\u001b[?2004l\r\n"]
[121.654, "o", "\u001b[?2004h> pr=cProfile.Profile()\r\n"]
[121.708933, "o", "\u001b[?2004l\r\n"]
[121.763867, "o", "\u001b[?2004h> pr.enable()\r\n"]
[121.8188, "o", "\u001b[?2004l\r\n"]
[121.873733, "o", "\u001b[?2004h> _ = sp_arr[sp_b_arr]\r\n"]
[121.928667, "o", "\u001b[?2004l\r\n"]
[121.9836, "o", "\u001b[?2004h> pr.disable()\r\n"]
[122.038533, "o", "\u001b[?2004l\r\n"]
[122.093467, "o", "\u001b[?2004h> s=io.StringIO()\r\n"]
[122.1484, "o", "\u001b[?2004l\r\n"]
[122.203333, "o", "\u001b[?2004h> ps=pstats.Stats(pr, stream=s).sort_stats('cumtime')\r\n"]
[122.258267, "o", "\u001b[?2004l\r\n"]
[122.3132, "o", "\u001b[?2004h> ps.print_stats(30)\r\n"]
[122.368133, "o", "\u001b[?2004l\r\n"]
[122.423067, "o", "\u001b[?2004h> print(s.getvalue())\r\n"]
[122.478, "o", "\u001b[?2004l\r\n"]
[122.532933, "o", "\u001b[?2004h> PY\r\n"]
[122.587867, "o", "\u001b[?2004l\r\n"]
[122.6428, "o", "+ /opt/conda/envs/asv_3.10/bin/ninja\r\n"]
[122.697733, "o", "\r\n"]
[122.752667, "o", "[0/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[122.8076, "o", "[1/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[122.862533, "o", "         91 function calls in 0.015 seconds\r\n"]
[122.917467, "o", "\r\n"]
[122.9724, "o", "   Ordered by: cumulative time\r\n"]
[123.027333, "o", "   List reduced from 56 to 30 due to restriction <30>\r\n"]
[123.082267, "o", "\r\n"]
[123.1372, "o", "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n"]
[123.192133, "o", "        1    0.001    0.001    0.015    0.015 /workspace/repo/pandas/core/arrays/sparse/array.py:929(__getitem__)\r\n"]
[123.247067, "o", "        1    0.000    0.000    0.012    0.012 /workspace/repo/pandas/core/arrays/sparse/array.py:1034(take)\r\n"]
[123.302, "o", "        1    0.011    0.011    0.011    0.011 /workspace/repo/pandas/core/arrays/sparse/array.py:1118(_take_without_fill)\r\n"]
[123.356933, "o", "        1    0.001    0.001    0.001    0.001 {built-in method numpy.arange}\r\n"]
[123.411867, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n"]
[123.4668, "o", "        6    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n"]
[123.521733, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/numeric.py:615(flatnonzero)\r\n"]
[123.576667, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1881(nonzero)\r\n"]
[123.6316, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:53(_wrapfunc)\r\n"]
[123.686533, "o", "        1    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\r\n"]
[123.741467, "o", "        2    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/_methods.py:39(_amax)\r\n"]
[123.7964, "o", "        1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}\r\n"]
[123.851333, "o", "        2    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/_methods.py:43(_amin)\r\n"]
[123.906267, "o", "        1    0.000    0.000    0.000    0.000 {method 'min' of 'numpy.ndarray' objects}\r\n"]
[123.9612, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/sparse/array.py:1913(make_sparse_index)\r\n"]
[124.016133, "o", "        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n"]
[124.071067, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/_methods.py:55(_any)\r\n"]
[124.126, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/numeric.py:274(full)\r\n"]
[124.180933, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1768(ravel)\r\n"]
[124.235867, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2421(all)\r\n"]
[124.2908, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/common.py:1183(is_bool_dtype)\r\n"]
[124.345733, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:71(_wrapreduction)\r\n"]
[124.400667, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/sparse/array.py:497(_simple_new)\r\n"]
[124.4556, "o", "        3    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n"]
[124.510533, "o", "       13    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n"]
[124.565467, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/common.py:1384(_get_dtype)\r\n"]
[124.6204, "o", "        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/sparse/array.py:661(__len__)\r\n"]
[124.675333, "o", "        1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\r\n"]
[124.730267, "o", "        3    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n"]
[124.7852, "o", "        1    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n"]
[124.840133, "o", "\r\n"]
[124.895067, "o", "\r\n"]
[125.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[125.002, "i", "python - << 'PY'\r"]
[125.004, "o", "python - << 'PY'\r\n"]
[125.062182, "o", "\u001b[?2004l\r\n"]
[125.118364, "o", "\u001b[?2004h> import cProfile, pstats, io\r\n"]
[125.174545, "o", "\u001b[?2004l\r\n"]
[125.230727, "o", "\u001b[?2004h> import numpy as np\r\n"]
[125.286909, "o", "\u001b[?2004l\r\n"]
[125.343091, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[125.399273, "o", "\u001b[?2004l\r\n"]
[125.455455, "o", "\u001b[?2004h> from pandas.arrays import SparseArray\r\n"]
[125.511636, "o", "\u001b[?2004l\r\n"]
[125.567818, "o", "\u001b[?2004h> N=1_000_000\r\n"]
[125.624, "o", "\u001b[?2004l\r\n"]
[125.680182, "o", "\u001b[?2004h> arr=np.full(N, np.nan, dtype=float)\r\n"]
[125.736364, "o", "\u001b[?2004l\r\n"]
[125.792545, "o", "\u001b[?2004h> idx=np.random.choice(np.arange(N), int(N*1e-5), replace=False)\r\n"]
[125.848727, "o", "\u001b[?2004l\r\n"]
[125.904909, "o", "\u001b[?2004h> arr[idx]=np.random.rand(idx.size)\r\n"]
[125.961091, "o", "\u001b[?2004l\r\n"]
[126.017273, "o", "\u001b[?2004h> sp_arr=SparseArray(arr)\r\n"]
[126.073455, "o", "\u001b[?2004l\r\n"]
[126.129636, "o", "\u001b[?2004h> fv=float('nan')\r\n"]
[126.185818, "o", "\u001b[?2004l\r\n"]
[126.242, "o", "\u001b[?2004h> b_arr=np.full(shape=N, fill_value=fv, dtype=bool)\r\n"]
[126.298182, "o", "\u001b[?2004l\r\n"]
[126.354364, "o", "\u001b[?2004h> fv_inds=np.unique(np.random.randint(low=0, high=N-1), axis=None)\r\n"]
[126.410545, "o", "\u001b[?2004l\r\n"]
[126.466727, "o", "\u001b[?2004h> # fix: for nan case, pandas benchmark sets True on sparse positions; mirror logic\r\n"]
[126.522909, "o", "\u001b[?2004l\r\n"]
[126.579091, "o", "\u001b[?2004h> b_arr=np.zeros(N, dtype=bool)\r\n"]
[126.635273, "o", "\u001b[?2004l\r\n"]
[126.691455, "o", "\u001b[?2004h> # produce sparse True values\r\n"]
[126.747636, "o", "\u001b[?2004l\r\n"]
[126.803818, "o", "\u001b[?2004h> inds=np.unique(np.random.randint(0, N-1, int(N*1e-5), dtype=np.int32))\r\n"]
[126.86, "o", "\u001b[?2004l\r\n"]
[126.916182, "o", "\u001b[?2004h> b_arr[inds]=True\r\n"]
[126.972364, "o", "\u001b[?2004l\r\n"]
[127.028545, "o", "\u001b[?2004h> sp_b_arr=SparseArray(b_arr, dtype=bool, fill_value=float('nan'))\r\n"]
[127.084727, "o", "\u001b[?2004l\r\n"]
[127.140909, "o", "\u001b[?2004h> pr=cProfile.Profile(); pr.enable()\r\n"]
[127.197091, "o", "\u001b[?2004l\r\n"]
[127.253273, "o", "\u001b[?2004h> _ = sp_arr[sp_b_arr]\r\n"]
[127.309455, "o", "\u001b[?2004l\r\n"]
[127.365636, "o", "\u001b[?2004h> pr.disable(); s=io.StringIO(); p=pstats.Stats(pr, stream=s).sort_stats('cumtime'); p.print_stats(30); print(s.getvalue())\r\n"]
[127.421818, "o", "\u001b[?2004l\r\n"]
[127.478, "o", "\u001b[?2004h> PY\r\n"]
[127.534182, "o", "\u001b[?2004l\r\n"]
[127.590364, "o", "+ /opt/conda/envs/asv_3.10/bin/ninja\r\n"]
[127.646545, "o", "\r\n"]
[127.702727, "o", "[0/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[127.758909, "o", "[1/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[127.815091, "o", "         72 function calls in 0.000 seconds\r\n"]
[127.871273, "o", "\r\n"]
[127.927455, "o", "   Ordered by: cumulative time\r\n"]
[127.983636, "o", "   List reduced from 47 to 30 due to restriction <30>\r\n"]
[128.039818, "o", "\r\n"]
[128.096, "o", "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n"]
[128.152182, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/sparse/array.py:929(__getitem__)\r\n"]
[128.208364, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/sparse/array.py:1034(take)\r\n"]
[128.264545, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/sparse/array.py:1118(_take_without_fill)\r\n"]
[128.320727, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/common.py:1183(is_bool_dtype)\r\n"]
[128.376909, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/numeric.py:615(flatnonzero)\r\n"]
[128.433091, "o", "        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n"]
[128.489273, "o", "        3    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n"]
[128.545455, "o", "       13    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n"]
[128.601636, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/sparse/array.py:497(_simple_new)\r\n"]
[128.657818, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/common.py:1384(_get_dtype)\r\n"]
[128.714, "o", "        1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}\r\n"]
[128.770182, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1768(ravel)\r\n"]
[128.826364, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/_methods.py:39(_amax)\r\n"]
[128.882545, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/_methods.py:55(_any)\r\n"]
[128.938727, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/generic.py:42(_instancecheck)\r\n"]
[128.994909, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1881(nonzero)\r\n"]
[129.051091, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:53(_wrapfunc)\r\n"]
[129.107273, "o", "        2    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n"]
[129.163455, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n"]
[129.219636, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/generic.py:37(_check)\r\n"]
[129.275818, "o", "        3    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n"]
[129.332, "o", "        1    0.000    0.000    0.000    0.000 {method 'min' of 'numpy.ndarray' objects}\r\n"]
[129.388182, "o", "        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/numpy/core/_methods.py:43(_amin)\r\n"]
[129.444364, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/sparse/array.py:622(fill_value)\r\n"]
[129.500545, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/common.py:1581(pandas_dtype)\r\n"]
[129.556727, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/sparse/array.py:1913(make_sparse_index)\r\n"]
[129.612909, "o", "        1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\r\n"]
[129.669091, "o", "        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/sparse/array.py:661(__len__)\r\n"]
[129.725273, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n"]
[129.781455, "o", "        1    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\r\n"]
[129.837636, "o", "\r\n"]
[129.893818, "o", "\r\n"]
[130.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[130.002, "i", "sed -n '860,1160p' pandas/core/arrays/sparse/array.py\r"]
[130.004, "o", "sed -n '860,1160p' pandas/core/arrays/sparse/array.py\r\n"]
[130.022371, "o", "\u001b[?2004l\r\n"]
[130.038742, "o", "    def factorize(\r\n"]
[130.055113, "o", "        self,\r\n"]
[130.071483, "o", "        use_na_sentinel: bool = True,\r\n"]
[130.087854, "o", "    ) -> tuple[np.ndarray, SparseArray]:\r\n"]
[130.104225, "o", "        # Currently, ExtensionArray.factorize -> Tuple[ndarray, EA]\r\n"]
[130.120596, "o", "        # The sparsity on this is backwards from what Sparse would want. Want\r\n"]
[130.136967, "o", "        # ExtensionArray.factorize -> Tuple[EA, EA]\r\n"]
[130.153338, "o", "        # Given that we have to return a dense array of codes, why bother\r\n"]
[130.169709, "o", "        # implementing an efficient factorize?\r\n"]
[130.186079, "o", "        codes, uniques = algos.factorize(\r\n"]
[130.20245, "o", "            np.asarray(self), use_na_sentinel=use_na_sentinel\r\n"]
[130.218821, "o", "        )\r\n"]
[130.235192, "o", "        uniques_sp = SparseArray(uniques, dtype=self.dtype)\r\n"]
[130.251563, "o", "        return codes, uniques_sp\r\n"]
[130.267934, "o", "\r\n"]
[130.284305, "o", "    def value_counts(self, dropna: bool = True) -> Series:\r\n"]
[130.300675, "o", "        \"\"\"\r\n"]
[130.317046, "o", "        Returns a Series containing counts of unique values.\r\n"]
[130.333417, "o", "\r\n"]
[130.349788, "o", "        Parameters\r\n"]
[130.366159, "o", "        ----------\r\n"]
[130.38253, "o", "        dropna : bool, default True\r\n"]
[130.398901, "o", "            Don't include counts of NaN, even if NaN is in sp_values.\r\n"]
[130.415272, "o", "\r\n"]
[130.431642, "o", "        Returns\r\n"]
[130.448013, "o", "        -------\r\n"]
[130.464384, "o", "        counts : Series\r\n"]
[130.480755, "o", "        \"\"\"\r\n"]
[130.497126, "o", "        from pandas import (\r\n"]
[130.513497, "o", "            Index,\r\n"]
[130.529868, "o", "            Series,\r\n"]
[130.546238, "o", "        )\r\n"]
[130.562609, "o", "\r\n"]
[130.57898, "o", "        keys, counts, _ = algos.value_counts_arraylike(self.sp_values, dropna=dropna)\r\n"]
[130.595351, "o", "        fcounts = self.sp_index.ngaps\r\n"]
[130.611722, "o", "        if fcounts > 0 and (not self._null_fill_value or not dropna):\r\n"]
[130.628093, "o", "            mask = isna(keys) if self._null_fill_value else keys == self.fill_value\r\n"]
[130.644464, "o", "            if mask.any():\r\n"]
[130.660834, "o", "                counts[mask] += fcounts\r\n"]
[130.677205, "o", "            else:\r\n"]
[130.693576, "o", "                # error: Argument 1 to \"insert\" has incompatible type \"Union[\r\n"]
[130.709947, "o", "                # ExtensionArray,ndarray[Any, Any]]\"; expected \"Union[\r\n"]
[130.726318, "o", "                # _SupportsArray[dtype[Any]], Sequence[_SupportsArray[dtype\r\n"]
[130.742689, "o", "                # [Any]]], Sequence[Sequence[_SupportsArray[dtype[Any]]]],\r\n"]
[130.75906, "o", "                # Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]], Sequence\r\n"]
[130.77543, "o", "                # [Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]]]]\"\r\n"]
[130.791801, "o", "                keys = np.insert(keys, 0, self.fill_value)  # type: ignore[arg-type]\r\n"]
[130.808172, "o", "                counts = np.insert(counts, 0, fcounts)\r\n"]
[130.824543, "o", "\r\n"]
[130.840914, "o", "        if not isinstance(keys, ABCIndex):\r\n"]
[130.857285, "o", "            index = Index(keys)\r\n"]
[130.873656, "o", "        else:\r\n"]
[130.890026, "o", "            index = keys\r\n"]
[130.906397, "o", "        return Series(counts, index=index, copy=False)\r\n"]
[130.922768, "o", "\r\n"]
[130.939139, "o", "    # --------\r\n"]
[130.95551, "o", "    # Indexing\r\n"]
[130.971881, "o", "    # --------\r\n"]
[130.988252, "o", "    @overload\r\n"]
[131.004623, "o", "    def __getitem__(self, key: ScalarIndexer) -> Any:\r\n"]
[131.020993, "o", "        ...\r\n"]
[131.037364, "o", "\r\n"]
[131.053735, "o", "    @overload\r\n"]
[131.070106, "o", "    def __getitem__(\r\n"]
[131.086477, "o", "        self,\r\n"]
[131.102848, "o", "        key: SequenceIndexer | tuple[int | ellipsis, ...],\r\n"]
[131.119219, "o", "    ) -> Self:\r\n"]
[131.135589, "o", "        ...\r\n"]
[131.15196, "o", "\r\n"]
[131.168331, "o", "    def __getitem__(\r\n"]
[131.184702, "o", "        self,\r\n"]
[131.201073, "o", "        key: PositionalIndexer | tuple[int | ellipsis, ...],\r\n"]
[131.217444, "o", "    ) -> Self | Any:\r\n"]
[131.233815, "o", "        if isinstance(key, tuple):\r\n"]
[131.250185, "o", "            key = unpack_tuple_and_ellipses(key)\r\n"]
[131.266556, "o", "            if key is Ellipsis:\r\n"]
[131.282927, "o", "                raise ValueError(\"Cannot slice with Ellipsis\")\r\n"]
[131.299298, "o", "\r\n"]
[131.315669, "o", "        if is_integer(key):\r\n"]
[131.33204, "o", "            return self._get_val_at(key)\r\n"]
[131.348411, "o", "        elif isinstance(key, tuple):\r\n"]
[131.364781, "o", "            # error: Invalid index type \"Tuple[Union[int, ellipsis], ...]\"\r\n"]
[131.381152, "o", "            # for \"ndarray[Any, Any]\"; expected type\r\n"]
[131.397523, "o", "            # \"Union[SupportsIndex, _SupportsArray[dtype[Union[bool_,\r\n"]
[131.413894, "o", "            # integer[Any]]]], _NestedSequence[_SupportsArray[dtype[\r\n"]
[131.430265, "o", "            # Union[bool_, integer[Any]]]]], _NestedSequence[Union[\r\n"]
[131.446636, "o", "            # bool, int]], Tuple[Union[SupportsIndex, _SupportsArray[\r\n"]
[131.463007, "o", "            # dtype[Union[bool_, integer[Any]]]], _NestedSequence[\r\n"]
[131.479377, "o", "            # _SupportsArray[dtype[Union[bool_, integer[Any]]]]],\r\n"]
[131.495748, "o", "            # _NestedSequence[Union[bool, int]]], ...]]\"\r\n"]
[131.512119, "o", "            data_slice = self.to_dense()[key]  # type: ignore[index]\r\n"]
[131.52849, "o", "        elif isinstance(key, slice):\r\n"]
[131.544861, "o", "            # Avoid densifying when handling contiguous slices\r\n"]
[131.561232, "o", "            if key.step is None or key.step == 1:\r\n"]
[131.577603, "o", "                start = 0 if key.start is None else key.start\r\n"]
[131.593974, "o", "                if start < 0:\r\n"]
[131.610344, "o", "                    start += len(self)\r\n"]
[131.626715, "o", "\r\n"]
[131.643086, "o", "                end = len(self) if key.stop is None else key.stop\r\n"]
[131.659457, "o", "                if end < 0:\r\n"]
[131.675828, "o", "                    end += len(self)\r\n"]
[131.692199, "o", "\r\n"]
[131.70857, "o", "                indices = self.sp_index.indices\r\n"]
[131.72494, "o", "                keep_inds = np.flatnonzero((indices >= start) & (indices < end))\r\n"]
[131.741311, "o", "                sp_vals = self.sp_values[keep_inds]\r\n"]
[131.757682, "o", "\r\n"]
[131.774053, "o", "                sp_index = indices[keep_inds].copy()\r\n"]
[131.790424, "o", "\r\n"]
[131.806795, "o", "                # If we've sliced to not include the start of the array, all our indices\r\n"]
[131.823166, "o", "                # should be shifted. NB: here we are careful to also not shift by a\r\n"]
[131.839536, "o", "                # negative value for a case like [0, 1][-100:] where the start index\r\n"]
[131.855907, "o", "                # should be treated like 0\r\n"]
[131.872278, "o", "                if start > 0:\r\n"]
[131.888649, "o", "                    sp_index -= start\r\n"]
[131.90502, "o", "\r\n"]
[131.921391, "o", "                # Length of our result should match applying this slice to a range\r\n"]
[131.937762, "o", "                # of the length of our original array\r\n"]
[131.954132, "o", "                new_len = len(range(len(self))[key])\r\n"]
[131.970503, "o", "                new_sp_index = make_sparse_index(new_len, sp_index, self.kind)\r\n"]
[131.986874, "o", "                return type(self)._simple_new(sp_vals, new_sp_index, self.dtype)\r\n"]
[132.003245, "o", "            else:\r\n"]
[132.019616, "o", "                indices = np.arange(len(self), dtype=np.int32)[key]\r\n"]
[132.035987, "o", "                return self.take(indices)\r\n"]
[132.052358, "o", "\r\n"]
[132.068728, "o", "        elif not is_list_like(key):\r\n"]
[132.085099, "o", "            # e.g. \"foo\" or 2.5\r\n"]
[132.10147, "o", "            # exception message copied from numpy\r\n"]
[132.117841, "o", "            raise IndexError(\r\n"]
[132.134212, "o", "                r\"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis \"\r\n"]
[132.150583, "o", "                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[132.166954, "o", "            )\r\n"]
[132.183325, "o", "\r\n"]
[132.199695, "o", "        else:\r\n"]
[132.216066, "o", "            if isinstance(key, SparseArray):\r\n"]
[132.232437, "o", "                # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[132.248808, "o", "                # has only fill_value - true, false or nan\r\n"]
[132.265179, "o", "                # (see GH PR 44955)\r\n"]
[132.28155, "o", "                # we can apply mask very fast:\r\n"]
[132.297921, "o", "                if is_bool_dtype(key):\r\n"]
[132.314291, "o", "                    if isna(key.fill_value):\r\n"]
[132.330662, "o", "                        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[132.347033, "o", "                    if not key.fill_value:\r\n"]
[132.363404, "o", "                        return self.take(key.sp_index.indices)\r\n"]
[132.379775, "o", "                    n = len(self)\r\n"]
[132.396146, "o", "                    mask = np.full(n, True, dtype=np.bool_)\r\n"]
[132.412517, "o", "                    mask[key.sp_index.indices] = False\r\n"]
[132.428887, "o", "                    return self.take(np.arange(n)[mask])\r\n"]
[132.445258, "o", "                else:\r\n"]
[132.461629, "o", "                    key = np.asarray(key)\r\n"]
[132.478, "o", "\r\n"]
[132.494371, "o", "            key = check_array_indexer(self, key)\r\n"]
[132.510742, "o", "\r\n"]
[132.527113, "o", "            if com.is_bool_indexer(key):\r\n"]
[132.543483, "o", "                # mypy doesn't know we have an array here\r\n"]
[132.559854, "o", "                key = cast(np.ndarray, key)\r\n"]
[132.576225, "o", "                return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[132.592596, "o", "            elif hasattr(key, \"__len__\"):\r\n"]
[132.608967, "o", "                return self.take(key)\r\n"]
[132.625338, "o", "            else:\r\n"]
[132.641709, "o", "                raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[132.658079, "o", "\r\n"]
[132.67445, "o", "        return type(self)(data_slice, kind=self.kind)\r\n"]
[132.690821, "o", "\r\n"]
[132.707192, "o", "    def _get_val_at(self, loc):\r\n"]
[132.723563, "o", "        loc = validate_insert_loc(loc, len(self))\r\n"]
[132.739934, "o", "\r\n"]
[132.756305, "o", "        sp_loc = self.sp_index.lookup(loc)\r\n"]
[132.772675, "o", "        if sp_loc == -1:\r\n"]
[132.789046, "o", "            return self.fill_value\r\n"]
[132.805417, "o", "        else:\r\n"]
[132.821788, "o", "            val = self.sp_values[sp_loc]\r\n"]
[132.838159, "o", "            val = maybe_box_datetimelike(val, self.sp_values.dtype)\r\n"]
[132.85453, "o", "            return val\r\n"]
[132.870901, "o", "\r\n"]
[132.887272, "o", "    def take(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[132.903642, "o", "        if is_scalar(indices):\r\n"]
[132.920013, "o", "            raise ValueError(f\"'indices' must be an array, not a scalar '{indices}'.\")\r\n"]
[132.936384, "o", "        indices = np.asarray(indices, dtype=np.int32)\r\n"]
[132.952755, "o", "\r\n"]
[132.969126, "o", "        dtype = None\r\n"]
[132.985497, "o", "        if indices.size == 0:\r\n"]
[133.001868, "o", "            result = np.array([], dtype=\"object\")\r\n"]
[133.018238, "o", "            dtype = self.dtype\r\n"]
[133.034609, "o", "        elif allow_fill:\r\n"]
[133.05098, "o", "            result = self._take_with_fill(indices, fill_value=fill_value)\r\n"]
[133.067351, "o", "        else:\r\n"]
[133.083722, "o", "            return self._take_without_fill(indices)\r\n"]
[133.100093, "o", "\r\n"]
[133.116464, "o", "        return type(self)(\r\n"]
[133.132834, "o", "            result, fill_value=self.fill_value, kind=self.kind, dtype=dtype\r\n"]
[133.149205, "o", "        )\r\n"]
[133.165576, "o", "\r\n"]
[133.181947, "o", "    def _take_with_fill(self, indices, fill_value=None) -> np.ndarray:\r\n"]
[133.198318, "o", "        if fill_value is None:\r\n"]
[133.214689, "o", "            fill_value = self.dtype.na_value\r\n"]
[133.23106, "o", "\r\n"]
[133.24743, "o", "        if indices.min() < -1:\r\n"]
[133.263801, "o", "            raise ValueError(\r\n"]
[133.280172, "o", "                \"Invalid value in 'indices'. Must be between -1 \"\r\n"]
[133.296543, "o", "                \"and the length of the array.\"\r\n"]
[133.312914, "o", "            )\r\n"]
[133.329285, "o", "\r\n"]
[133.345656, "o", "        if indices.max() >= len(self):\r\n"]
[133.362026, "o", "            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[133.378397, "o", "\r\n"]
[133.394768, "o", "        if len(self) == 0:\r\n"]
[133.411139, "o", "            # Empty... Allow taking only if all empty\r\n"]
[133.42751, "o", "            if (indices == -1).all():\r\n"]
[133.443881, "o", "                dtype = np.result_type(self.sp_values, type(fill_value))\r\n"]
[133.460252, "o", "                taken = np.empty_like(indices, dtype=dtype)\r\n"]
[133.476623, "o", "                taken.fill(fill_value)\r\n"]
[133.492993, "o", "                return taken\r\n"]
[133.509364, "o", "            else:\r\n"]
[133.525735, "o", "                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[133.542106, "o", "\r\n"]
[133.558477, "o", "        # sp_indexer may be -1 for two reasons\r\n"]
[133.574848, "o", "        # 1.) we took for an index of -1 (new)\r\n"]
[133.591219, "o", "        # 2.) we took a value that was self.fill_value (old)\r\n"]
[133.607589, "o", "        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[133.62396, "o", "        new_fill_indices = indices == -1\r\n"]
[133.640331, "o", "        old_fill_indices = (sp_indexer == -1) & ~new_fill_indices\r\n"]
[133.656702, "o", "\r\n"]
[133.673073, "o", "        if self.sp_index.npoints == 0 and old_fill_indices.all():\r\n"]
[133.689444, "o", "            # We've looked up all valid points on an all-sparse array.\r\n"]
[133.705815, "o", "            taken = np.full(\r\n"]
[133.722185, "o", "                sp_indexer.shape, fill_value=self.fill_value, dtype=self.dtype.subtype\r\n"]
[133.738556, "o", "            )\r\n"]
[133.754927, "o", "\r\n"]
[133.771298, "o", "        elif self.sp_index.npoints == 0:\r\n"]
[133.787669, "o", "            # Use the old fill_value unless we took for an index of -1\r\n"]
[133.80404, "o", "            _dtype = np.result_type(self.dtype.subtype, type(fill_value))\r\n"]
[133.820411, "o", "            taken = np.full(sp_indexer.shape, fill_value=fill_value, dtype=_dtype)\r\n"]
[133.836781, "o", "            taken[old_fill_indices] = self.fill_value\r\n"]
[133.853152, "o", "        else:\r\n"]
[133.869523, "o", "            taken = self.sp_values.take(sp_indexer)\r\n"]
[133.885894, "o", "\r\n"]
[133.902265, "o", "            # Fill in two steps.\r\n"]
[133.918636, "o", "            # Old fill values\r\n"]
[133.935007, "o", "            # New fill values\r\n"]
[133.951377, "o", "            # potentially coercing to a new dtype at each stage.\r\n"]
[133.967748, "o", "\r\n"]
[133.984119, "o", "            m0 = sp_indexer[old_fill_indices] < 0\r\n"]
[134.00049, "o", "            m1 = sp_indexer[new_fill_indices] < 0\r\n"]
[134.016861, "o", "\r\n"]
[134.033232, "o", "            result_type = taken.dtype\r\n"]
[134.049603, "o", "\r\n"]
[134.065974, "o", "            if m0.any():\r\n"]
[134.082344, "o", "                result_type = np.result_type(result_type, type(self.fill_value))\r\n"]
[134.098715, "o", "                taken = taken.astype(result_type)\r\n"]
[134.115086, "o", "                taken[old_fill_indices] = self.fill_value\r\n"]
[134.131457, "o", "\r\n"]
[134.147828, "o", "            if m1.any():\r\n"]
[134.164199, "o", "                result_type = np.result_type(result_type, type(fill_value))\r\n"]
[134.18057, "o", "                taken = taken.astype(result_type)\r\n"]
[134.19694, "o", "                taken[new_fill_indices] = fill_value\r\n"]
[134.213311, "o", "\r\n"]
[134.229682, "o", "        return taken\r\n"]
[134.246053, "o", "\r\n"]
[134.262424, "o", "    def _take_without_fill(self, indices) -> Self:\r\n"]
[134.278795, "o", "        to_shift = indices < 0\r\n"]
[134.295166, "o", "\r\n"]
[134.311536, "o", "        n = len(self)\r\n"]
[134.327907, "o", "\r\n"]
[134.344278, "o", "        if (indices.max() >= n) or (indices.min() < -n):\r\n"]
[134.360649, "o", "            if n == 0:\r\n"]
[134.37702, "o", "                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[134.393391, "o", "            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[134.409762, "o", "\r\n"]
[134.426132, "o", "        if to_shift.any():\r\n"]
[134.442503, "o", "            indices = indices.copy()\r\n"]
[134.458874, "o", "            indices[to_shift] += n\r\n"]
[134.475245, "o", "\r\n"]
[134.491616, "o", "        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[134.507987, "o", "        value_mask = sp_indexer != -1\r\n"]
[134.524358, "o", "        new_sp_values = self.sp_values[sp_indexer[value_mask]]\r\n"]
[134.540728, "o", "\r\n"]
[134.557099, "o", "        value_indices = np.flatnonzero(value_mask).astype(np.int32, copy=False)\r\n"]
[134.57347, "o", "\r\n"]
[134.589841, "o", "        new_sp_index = make_sparse_index(len(indices), value_indices, kind=self.kind)\r\n"]
[134.606212, "o", "        return type(self)._simple_new(new_sp_values, new_sp_index, dtype=self.dtype)\r\n"]
[134.622583, "o", "\r\n"]
[134.638954, "o", "    def searchsorted(\r\n"]
[134.655325, "o", "        self,\r\n"]
[134.671695, "o", "        v: ArrayLike | object,\r\n"]
[134.688066, "o", "        side: Literal[\"left\", \"right\"] = \"left\",\r\n"]
[134.704437, "o", "        sorter: NumpySorter | None = None,\r\n"]
[134.720808, "o", "    ) -> npt.NDArray[np.intp] | np.intp:\r\n"]
[134.737179, "o", "        msg = \"searchsorted requires high memory usage.\"\r\n"]
[134.75355, "o", "        warnings.warn(msg, PerformanceWarning, stacklevel=find_stack_level())\r\n"]
[134.769921, "o", "        v = np.asarray(v)\r\n"]
[134.786291, "o", "        return np.asarray(self, dtype=self.dtype.subtype).searchsorted(v, side, sorter)\r\n"]
[134.802662, "o", "\r\n"]
[134.819033, "o", "    def copy(self) -> Self:\r\n"]
[134.835404, "o", "        values = self.sp_values.copy()\r\n"]
[134.851775, "o", "        return self._simple_new(values, self.sp_index, self.dtype)\r\n"]
[134.868146, "o", "\r\n"]
[134.884517, "o", "    @classmethod\r\n"]
[134.900887, "o", "    def _concat_same_type(cls, to_concat: Sequence[Self]) -> Self:\r\n"]
[134.917258, "o", "        fill_value = to_concat[0].fill_value\r\n"]
[134.933629, "o", "\r\n"]
[135.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[135.002, "i", "sed -n '1160,1400p' pandas/core/arrays/sparse/array.py\r"]
[135.004, "o", "sed -n '1160,1400p' pandas/core/arrays/sparse/array.py\r\n"]
[135.02643, "o", "\u001b[?2004l\r\n"]
[135.04686, "o", "        values = []\r\n"]
[135.067289, "o", "        length = 0\r\n"]
[135.087719, "o", "\r\n"]
[135.108149, "o", "        if to_concat:\r\n"]
[135.128579, "o", "            sp_kind = to_concat[0].kind\r\n"]
[135.149008, "o", "        else:\r\n"]
[135.169438, "o", "            sp_kind = \"integer\"\r\n"]
[135.189868, "o", "\r\n"]
[135.210298, "o", "        sp_index: SparseIndex\r\n"]
[135.230727, "o", "        if sp_kind == \"integer\":\r\n"]
[135.251157, "o", "            indices = []\r\n"]
[135.271587, "o", "\r\n"]
[135.292017, "o", "            for arr in to_concat:\r\n"]
[135.312446, "o", "                int_idx = arr.sp_index.indices.copy()\r\n"]
[135.332876, "o", "                int_idx += length  # TODO: wraparound\r\n"]
[135.353306, "o", "                length += arr.sp_index.length\r\n"]
[135.373736, "o", "\r\n"]
[135.394165, "o", "                values.append(arr.sp_values)\r\n"]
[135.414595, "o", "                indices.append(int_idx)\r\n"]
[135.435025, "o", "\r\n"]
[135.455455, "o", "            data = np.concatenate(values)\r\n"]
[135.475884, "o", "            indices_arr = np.concatenate(indices)\r\n"]
[135.496314, "o", "            # error: Argument 2 to \"IntIndex\" has incompatible type\r\n"]
[135.516744, "o", "            # \"ndarray[Any, dtype[signedinteger[_32Bit]]]\";\r\n"]
[135.537174, "o", "            # expected \"Sequence[int]\"\r\n"]
[135.557603, "o", "            sp_index = IntIndex(length, indices_arr)  # type: ignore[arg-type]\r\n"]
[135.578033, "o", "\r\n"]
[135.598463, "o", "        else:\r\n"]
[135.618893, "o", "            # when concatenating block indices, we don't claim that you'll\r\n"]
[135.639322, "o", "            # get an identical index as concatenating the values and then\r\n"]
[135.659752, "o", "            # creating a new index. We don't want to spend the time trying\r\n"]
[135.680182, "o", "            # to merge blocks across arrays in `to_concat`, so the resulting\r\n"]
[135.700612, "o", "            # BlockIndex may have more blocks.\r\n"]
[135.721041, "o", "            blengths = []\r\n"]
[135.741471, "o", "            blocs = []\r\n"]
[135.761901, "o", "\r\n"]
[135.782331, "o", "            for arr in to_concat:\r\n"]
[135.80276, "o", "                block_idx = arr.sp_index.to_block_index()\r\n"]
[135.82319, "o", "\r\n"]
[135.84362, "o", "                values.append(arr.sp_values)\r\n"]
[135.86405, "o", "                blocs.append(block_idx.blocs.copy() + length)\r\n"]
[135.884479, "o", "                blengths.append(block_idx.blengths)\r\n"]
[135.904909, "o", "                length += arr.sp_index.length\r\n"]
[135.925339, "o", "\r\n"]
[135.945769, "o", "            data = np.concatenate(values)\r\n"]
[135.966198, "o", "            blocs_arr = np.concatenate(blocs)\r\n"]
[135.986628, "o", "            blengths_arr = np.concatenate(blengths)\r\n"]
[136.007058, "o", "\r\n"]
[136.027488, "o", "            sp_index = BlockIndex(length, blocs_arr, blengths_arr)\r\n"]
[136.047917, "o", "\r\n"]
[136.068347, "o", "        return cls(data, sparse_index=sp_index, fill_value=fill_value)\r\n"]
[136.088777, "o", "\r\n"]
[136.109207, "o", "    def astype(self, dtype: AstypeArg | None = None, copy: bool = True):\r\n"]
[136.129636, "o", "        \"\"\"\r\n"]
[136.150066, "o", "        Change the dtype of a SparseArray.\r\n"]
[136.170496, "o", "\r\n"]
[136.190926, "o", "        The output will always be a SparseArray. To convert to a dense\r\n"]
[136.211355, "o", "        ndarray with a certain dtype, use :meth:`numpy.asarray`.\r\n"]
[136.231785, "o", "\r\n"]
[136.252215, "o", "        Parameters\r\n"]
[136.272645, "o", "        ----------\r\n"]
[136.293074, "o", "        dtype : np.dtype or ExtensionDtype\r\n"]
[136.313504, "o", "            For SparseDtype, this changes the dtype of\r\n"]
[136.333934, "o", "            ``self.sp_values`` and the ``self.fill_value``.\r\n"]
[136.354364, "o", "\r\n"]
[136.374793, "o", "            For other dtypes, this only changes the dtype of\r\n"]
[136.395223, "o", "            ``self.sp_values``.\r\n"]
[136.415653, "o", "\r\n"]
[136.436083, "o", "        copy : bool, default True\r\n"]
[136.456512, "o", "            Whether to ensure a copy is made, even if not necessary.\r\n"]
[136.476942, "o", "\r\n"]
[136.497372, "o", "        Returns\r\n"]
[136.517802, "o", "        -------\r\n"]
[136.538231, "o", "        SparseArray\r\n"]
[136.558661, "o", "\r\n"]
[136.579091, "o", "        Examples\r\n"]
[136.599521, "o", "        --------\r\n"]
[136.61995, "o", "        >>> arr = pd.arrays.SparseArray([0, 0, 1, 2])\r\n"]
[136.64038, "o", "        >>> arr\r\n"]
[136.66081, "o", "        [0, 0, 1, 2]\r\n"]
[136.68124, "o", "        Fill: 0\r\n"]
[136.701669, "o", "        IntIndex\r\n"]
[136.722099, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[136.742529, "o", "\r\n"]
[136.762959, "o", "        >>> arr.astype(SparseDtype(np.dtype('int32')))\r\n"]
[136.783388, "o", "        [0, 0, 1, 2]\r\n"]
[136.803818, "o", "        Fill: 0\r\n"]
[136.824248, "o", "        IntIndex\r\n"]
[136.844678, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[136.865107, "o", "\r\n"]
[136.885537, "o", "        Using a NumPy dtype with a different kind (e.g. float) will coerce\r\n"]
[136.905967, "o", "        just ``self.sp_values``.\r\n"]
[136.926397, "o", "\r\n"]
[136.946826, "o", "        >>> arr.astype(SparseDtype(np.dtype('float64')))\r\n"]
[136.967256, "o", "        ... # doctest: +NORMALIZE_WHITESPACE\r\n"]
[136.987686, "o", "        [nan, nan, 1.0, 2.0]\r\n"]
[137.008116, "o", "        Fill: nan\r\n"]
[137.028545, "o", "        IntIndex\r\n"]
[137.048975, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[137.069405, "o", "\r\n"]
[137.089835, "o", "        Using a SparseDtype, you can also change the fill value as well.\r\n"]
[137.110264, "o", "\r\n"]
[137.130694, "o", "        >>> arr.astype(SparseDtype(\"float64\", fill_value=0.0))\r\n"]
[137.151124, "o", "        ... # doctest: +NORMALIZE_WHITESPACE\r\n"]
[137.171554, "o", "        [0.0, 0.0, 1.0, 2.0]\r\n"]
[137.191983, "o", "        Fill: 0.0\r\n"]
[137.212413, "o", "        IntIndex\r\n"]
[137.232843, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[137.253273, "o", "        \"\"\"\r\n"]
[137.273702, "o", "        if dtype == self._dtype:\r\n"]
[137.294132, "o", "            if not copy:\r\n"]
[137.314562, "o", "                return self\r\n"]
[137.334992, "o", "            else:\r\n"]
[137.355421, "o", "                return self.copy()\r\n"]
[137.375851, "o", "\r\n"]
[137.396281, "o", "        future_dtype = pandas_dtype(dtype)\r\n"]
[137.416711, "o", "        if not isinstance(future_dtype, SparseDtype):\r\n"]
[137.43714, "o", "            # GH#34457\r\n"]
[137.45757, "o", "            values = np.asarray(self)\r\n"]
[137.478, "o", "            values = ensure_wrapped_if_datetimelike(values)\r\n"]
[137.49843, "o", "            return astype_array(values, dtype=future_dtype, copy=False)\r\n"]
[137.51886, "o", "\r\n"]
[137.539289, "o", "        dtype = self.dtype.update_dtype(dtype)\r\n"]
[137.559719, "o", "        subtype = pandas_dtype(dtype._subtype_with_str)\r\n"]
[137.580149, "o", "        subtype = cast(np.dtype, subtype)  # ensured by update_dtype\r\n"]
[137.600579, "o", "        values = ensure_wrapped_if_datetimelike(self.sp_values)\r\n"]
[137.621008, "o", "        sp_values = astype_array(values, subtype, copy=copy)\r\n"]
[137.641438, "o", "        sp_values = np.asarray(sp_values)\r\n"]
[137.661868, "o", "\r\n"]
[137.682298, "o", "        return self._simple_new(sp_values, self.sp_index, dtype)\r\n"]
[137.702727, "o", "\r\n"]
[137.723157, "o", "    def map(self, mapper, na_action=None) -> Self:\r\n"]
[137.743587, "o", "        \"\"\"\r\n"]
[137.764017, "o", "        Map categories using an input mapping or function.\r\n"]
[137.784446, "o", "\r\n"]
[137.804876, "o", "        Parameters\r\n"]
[137.825306, "o", "        ----------\r\n"]
[137.845736, "o", "        mapper : dict, Series, callable\r\n"]
[137.866165, "o", "            The correspondence from old values to new.\r\n"]
[137.886595, "o", "        na_action : {None, 'ignore'}, default None\r\n"]
[137.907025, "o", "            If 'ignore', propagate NA values, without passing them to the\r\n"]
[137.927455, "o", "            mapping correspondence.\r\n"]
[137.947884, "o", "\r\n"]
[137.968314, "o", "        Returns\r\n"]
[137.988744, "o", "        -------\r\n"]
[138.009174, "o", "        SparseArray\r\n"]
[138.029603, "o", "            The output array will have the same density as the input.\r\n"]
[138.050033, "o", "            The output fill value will be the result of applying the\r\n"]
[138.070463, "o", "            mapping to ``self.fill_value``\r\n"]
[138.090893, "o", "\r\n"]
[138.111322, "o", "        Examples\r\n"]
[138.131752, "o", "        --------\r\n"]
[138.152182, "o", "        >>> arr = pd.arrays.SparseArray([0, 1, 2])\r\n"]
[138.172612, "o", "        >>> arr.map(lambda x: x + 10)\r\n"]
[138.193041, "o", "        [10, 11, 12]\r\n"]
[138.213471, "o", "        Fill: 10\r\n"]
[138.233901, "o", "        IntIndex\r\n"]
[138.254331, "o", "        Indices: array([1, 2], dtype=int32)\r\n"]
[138.27476, "o", "\r\n"]
[138.29519, "o", "        >>> arr.map({0: 10, 1: 11, 2: 12})\r\n"]
[138.31562, "o", "        [10, 11, 12]\r\n"]
[138.33605, "o", "        Fill: 10\r\n"]
[138.356479, "o", "        IntIndex\r\n"]
[138.376909, "o", "        Indices: array([1, 2], dtype=int32)\r\n"]
[138.397339, "o", "\r\n"]
[138.417769, "o", "        >>> arr.map(pd.Series([10, 11, 12], index=[0, 1, 2]))\r\n"]
[138.438198, "o", "        [10, 11, 12]\r\n"]
[138.458628, "o", "        Fill: 10\r\n"]
[138.479058, "o", "        IntIndex\r\n"]
[138.499488, "o", "        Indices: array([1, 2], dtype=int32)\r\n"]
[138.519917, "o", "        \"\"\"\r\n"]
[138.540347, "o", "        is_map = isinstance(mapper, (abc.Mapping, ABCSeries))\r\n"]
[138.560777, "o", "\r\n"]
[138.581207, "o", "        fill_val = self.fill_value\r\n"]
[138.601636, "o", "\r\n"]
[138.622066, "o", "        if na_action is None or notna(fill_val):\r\n"]
[138.642496, "o", "            fill_val = mapper.get(fill_val, fill_val) if is_map else mapper(fill_val)\r\n"]
[138.662926, "o", "\r\n"]
[138.683355, "o", "        def func(sp_val):\r\n"]
[138.703785, "o", "            new_sp_val = mapper.get(sp_val, None) if is_map else mapper(sp_val)\r\n"]
[138.724215, "o", "            # check identity and equality because nans are not equal to each other\r\n"]
[138.744645, "o", "            if new_sp_val is fill_val or new_sp_val == fill_val:\r\n"]
[138.765074, "o", "                msg = \"fill value in the sparse values not supported\"\r\n"]
[138.785504, "o", "                raise ValueError(msg)\r\n"]
[138.805934, "o", "            return new_sp_val\r\n"]
[138.826364, "o", "\r\n"]
[138.846793, "o", "        sp_values = [func(x) for x in self.sp_values]\r\n"]
[138.867223, "o", "\r\n"]
[138.887653, "o", "        return type(self)(sp_values, sparse_index=self.sp_index, fill_value=fill_val)\r\n"]
[138.908083, "o", "\r\n"]
[138.928512, "o", "    def to_dense(self) -> np.ndarray:\r\n"]
[138.948942, "o", "        \"\"\"\r\n"]
[138.969372, "o", "        Convert SparseArray to a NumPy array.\r\n"]
[138.989802, "o", "\r\n"]
[139.010231, "o", "        Returns\r\n"]
[139.030661, "o", "        -------\r\n"]
[139.051091, "o", "        arr : NumPy array\r\n"]
[139.071521, "o", "        \"\"\"\r\n"]
[139.09195, "o", "        return np.asarray(self, dtype=self.sp_values.dtype)\r\n"]
[139.11238, "o", "\r\n"]
[139.13281, "o", "    def _where(self, mask, value):\r\n"]
[139.15324, "o", "        # NB: may not preserve dtype, e.g. result may be Sparse[float64]\r\n"]
[139.173669, "o", "        #  while self is Sparse[int64]\r\n"]
[139.194099, "o", "        naive_implementation = np.where(mask, self, value)\r\n"]
[139.214529, "o", "        dtype = SparseDtype(naive_implementation.dtype, fill_value=self.fill_value)\r\n"]
[139.234959, "o", "        result = type(self)._from_sequence(naive_implementation, dtype=dtype)\r\n"]
[139.255388, "o", "        return result\r\n"]
[139.275818, "o", "\r\n"]
[139.296248, "o", "    # ------------------------------------------------------------------------\r\n"]
[139.316678, "o", "    # IO\r\n"]
[139.337107, "o", "    # ------------------------------------------------------------------------\r\n"]
[139.357537, "o", "    def __setstate__(self, state) -> None:\r\n"]
[139.377967, "o", "        \"\"\"Necessary for making this object picklable\"\"\"\r\n"]
[139.398397, "o", "        if isinstance(state, tuple):\r\n"]
[139.418826, "o", "            # Compat for pandas < 0.24.0\r\n"]
[139.439256, "o", "            nd_state, (fill_value, sp_index) = state\r\n"]
[139.459686, "o", "            sparse_values = np.array([])\r\n"]
[139.480116, "o", "            sparse_values.__setstate__(nd_state)\r\n"]
[139.500545, "o", "\r\n"]
[139.520975, "o", "            self._sparse_values = sparse_values\r\n"]
[139.541405, "o", "            self._sparse_index = sp_index\r\n"]
[139.561835, "o", "            self._dtype = SparseDtype(sparse_values.dtype, fill_value)\r\n"]
[139.582264, "o", "        else:\r\n"]
[139.602694, "o", "            self.__dict__.update(state)\r\n"]
[139.623124, "o", "\r\n"]
[139.643554, "o", "    def nonzero(self) -> tuple[npt.NDArray[np.int32]]:\r\n"]
[139.663983, "o", "        if self.fill_value == 0:\r\n"]
[139.684413, "o", "            return (self.sp_index.indices,)\r\n"]
[139.704843, "o", "        else:\r\n"]
[139.725273, "o", "            return (self.sp_index.indices[self.sp_values != 0],)\r\n"]
[139.745702, "o", "\r\n"]
[139.766132, "o", "    # ------------------------------------------------------------------------\r\n"]
[139.786562, "o", "    # Reductions\r\n"]
[139.806992, "o", "    # ------------------------------------------------------------------------\r\n"]
[139.827421, "o", "\r\n"]
[139.847851, "o", "    def _reduce(\r\n"]
[139.868281, "o", "        self, name: str, *, skipna: bool = True, keepdims: bool = False, **kwargs\r\n"]
[139.888711, "o", "    ):\r\n"]
[139.90914, "o", "        method = getattr(self, name, None)\r\n"]
[139.92957, "o", "\r\n"]
[140.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[140.002, "i", "grep -n \"def __getitem__\\|def take\\|is_bool_dtype\\|nonzero\\|mask\" pandas/core/arrays/sparse/array.py\r"]
[140.004, "o", "grep -n \"def __getitem__\\|def take\\|is_bool_dtype\\|nonzero\\|mask\" pandas/core/arrays/sparse/array.py\r\n"]
[140.132769, "o", "\u001b[?2004l\r\n"]
[140.259538, "o", "\u001b[32m\u001b[K45\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kis_bool_dtype\u001b[m\u001b[K,\r\n"]
[140.386308, "o", "\u001b[32m\u001b[K279\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    if \u001b[01;31m\u001b[Kis_bool_dtype\u001b[m\u001b[K(dtype):\r\n"]
[140.513077, "o", "\u001b[32m\u001b[K658\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = notna(sp_vals)\r\n"]
[140.639846, "o", "\u001b[32m\u001b[K659\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        return sp_vals[\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K]\r\n"]
[140.766615, "o", "\u001b[32m\u001b[K714\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = np.full(len(self), False, dtype=np.bool_)\r\n"]
[140.893385, "o", "\u001b[32m\u001b[K715\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K[self.sp_index.indices] = isna(self.sp_values)\r\n"]
[141.020154, "o", "\u001b[32m\u001b[K716\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        return type(self)(\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K, fill_value=False, dtype=dtype)\r\n"]
[141.146923, "o", "\u001b[32m\u001b[K839\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = np.asarray(self.isna())\r\n"]
[141.273692, "o", "\u001b[32m\u001b[K840\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        return algos.duplicated(values, keep=keep, \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K=\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K)\r\n"]
[141.400462, "o", "\u001b[32m\u001b[K896\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = isna(keys) if self._null_fill_value else keys == self.fill_value\r\n"]
[141.527231, "o", "\u001b[32m\u001b[K897\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            if \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K.any():\r\n"]
[141.654, "o", "\u001b[32m\u001b[K898\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                counts[\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K] += fcounts\r\n"]
[141.780769, "o", "\u001b[32m\u001b[K919\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef __getitem__\u001b[m\u001b[K(self, key: ScalarIndexer) -> Any:\r\n"]
[141.907538, "o", "\u001b[32m\u001b[K923\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef __getitem__\u001b[m\u001b[K(\r\n"]
[142.034308, "o", "\u001b[32m\u001b[K929\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef __getitem__\u001b[m\u001b[K(\r\n"]
[142.161077, "o", "\u001b[32m\u001b[K963\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                keep_inds = np.flat\u001b[01;31m\u001b[Knonzero\u001b[m\u001b[K((indices >= start) & (indices < end))\r\n"]
[142.287846, "o", "\u001b[32m\u001b[K997\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                # we can apply \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K very fast:\r\n"]
[142.414615, "o", "\u001b[32m\u001b[K998\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                if \u001b[01;31m\u001b[Kis_bool_dtype\u001b[m\u001b[K(key):\r\n"]
[142.541385, "o", "\u001b[32m\u001b[K1004\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                    \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = np.full(n, True, dtype=np.bool_)\r\n"]
[142.668154, "o", "\u001b[32m\u001b[K1005\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                    \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K[key.sp_index.indices] = False\r\n"]
[142.794923, "o", "\u001b[32m\u001b[K1006\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                    return self.take(np.arange(n)[\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K])\r\n"]
[142.921692, "o", "\u001b[32m\u001b[K1034\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef take\u001b[m\u001b[K(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[143.048462, "o", "\u001b[32m\u001b[K1133\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        value_\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = sp_indexer != -1\r\n"]
[143.175231, "o", "\u001b[32m\u001b[K1134\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        new_sp_values = self.sp_values[sp_indexer[value_\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K]]\r\n"]
[143.302, "o", "\u001b[32m\u001b[K1136\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        value_indices = np.flat\u001b[01;31m\u001b[Knonzero\u001b[m\u001b[K(value_\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K).astype(np.int32, copy=False)\r\n"]
[143.428769, "o", "\u001b[32m\u001b[K1360\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def _where(self, \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K, value):\r\n"]
[143.555538, "o", "\u001b[32m\u001b[K1363\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        naive_implementation = np.where(\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K, self, value)\r\n"]
[143.682308, "o", "\u001b[32m\u001b[K1385\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[Knonzero\u001b[m\u001b[K(self) -> tuple[npt.NDArray[np.int32]]:\r\n"]
[143.809077, "o", "\u001b[32m\u001b[K1626\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = np.asarray(isna(values))\r\n"]
[143.935846, "o", "\u001b[32m\u001b[K1630\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        non_nans = values[~\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K]\r\n"]
[144.062615, "o", "\u001b[32m\u001b[K1631\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        non_nan_idx = idx[~\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K]\r\n"]
[144.189385, "o", "\u001b[32m\u001b[K1871\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = notna(arr)\r\n"]
[144.316154, "o", "\u001b[32m\u001b[K1881\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = splib.make_\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K_object_ndarray(arr, fill_value)\r\n"]
[144.442923, "o", "\u001b[32m\u001b[K1883\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = arr != fill_value\r\n"]
[144.569692, "o", "\u001b[32m\u001b[K1886\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    if length != len(\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K):\r\n"]
[144.696462, "o", "\u001b[32m\u001b[K1888\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        indices = \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K.sp_index.indices\r\n"]
[144.823231, "o", "\u001b[32m\u001b[K1890\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        indices = \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K.\u001b[01;31m\u001b[Knonzero\u001b[m\u001b[K()[0].astype(np.int32)\r\n"]
[145.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[145.002, "i", "sed -n '900,1250p' pandas/core/arrays/sparse/array.py\r"]
[145.004, "o", "sed -n '900,1250p' pandas/core/arrays/sparse/array.py\r\n"]
[145.020045, "o", "\u001b[?2004l\r\n"]
[145.034091, "o", "                # error: Argument 1 to \"insert\" has incompatible type \"Union[\r\n"]
[145.048136, "o", "                # ExtensionArray,ndarray[Any, Any]]\"; expected \"Union[\r\n"]
[145.062182, "o", "                # _SupportsArray[dtype[Any]], Sequence[_SupportsArray[dtype\r\n"]
[145.076227, "o", "                # [Any]]], Sequence[Sequence[_SupportsArray[dtype[Any]]]],\r\n"]
[145.090273, "o", "                # Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]], Sequence\r\n"]
[145.104318, "o", "                # [Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]]]]\"\r\n"]
[145.118364, "o", "                keys = np.insert(keys, 0, self.fill_value)  # type: ignore[arg-type]\r\n"]
[145.132409, "o", "                counts = np.insert(counts, 0, fcounts)\r\n"]
[145.146455, "o", "\r\n"]
[145.1605, "o", "        if not isinstance(keys, ABCIndex):\r\n"]
[145.174545, "o", "            index = Index(keys)\r\n"]
[145.188591, "o", "        else:\r\n"]
[145.202636, "o", "            index = keys\r\n"]
[145.216682, "o", "        return Series(counts, index=index, copy=False)\r\n"]
[145.230727, "o", "\r\n"]
[145.244773, "o", "    # --------\r\n"]
[145.258818, "o", "    # Indexing\r\n"]
[145.272864, "o", "    # --------\r\n"]
[145.286909, "o", "    @overload\r\n"]
[145.300955, "o", "    def __getitem__(self, key: ScalarIndexer) -> Any:\r\n"]
[145.315, "o", "        ...\r\n"]
[145.329045, "o", "\r\n"]
[145.343091, "o", "    @overload\r\n"]
[145.357136, "o", "    def __getitem__(\r\n"]
[145.371182, "o", "        self,\r\n"]
[145.385227, "o", "        key: SequenceIndexer | tuple[int | ellipsis, ...],\r\n"]
[145.399273, "o", "    ) -> Self:\r\n"]
[145.413318, "o", "        ...\r\n"]
[145.427364, "o", "\r\n"]
[145.441409, "o", "    def __getitem__(\r\n"]
[145.455455, "o", "        self,\r\n"]
[145.4695, "o", "        key: PositionalIndexer | tuple[int | ellipsis, ...],\r\n"]
[145.483545, "o", "    ) -> Self | Any:\r\n"]
[145.497591, "o", "        if isinstance(key, tuple):\r\n"]
[145.511636, "o", "            key = unpack_tuple_and_ellipses(key)\r\n"]
[145.525682, "o", "            if key is Ellipsis:\r\n"]
[145.539727, "o", "                raise ValueError(\"Cannot slice with Ellipsis\")\r\n"]
[145.553773, "o", "\r\n"]
[145.567818, "o", "        if is_integer(key):\r\n"]
[145.581864, "o", "            return self._get_val_at(key)\r\n"]
[145.595909, "o", "        elif isinstance(key, tuple):\r\n"]
[145.609955, "o", "            # error: Invalid index type \"Tuple[Union[int, ellipsis], ...]\"\r\n"]
[145.624, "o", "            # for \"ndarray[Any, Any]\"; expected type\r\n"]
[145.638045, "o", "            # \"Union[SupportsIndex, _SupportsArray[dtype[Union[bool_,\r\n"]
[145.652091, "o", "            # integer[Any]]]], _NestedSequence[_SupportsArray[dtype[\r\n"]
[145.666136, "o", "            # Union[bool_, integer[Any]]]]], _NestedSequence[Union[\r\n"]
[145.680182, "o", "            # bool, int]], Tuple[Union[SupportsIndex, _SupportsArray[\r\n"]
[145.694227, "o", "            # dtype[Union[bool_, integer[Any]]]], _NestedSequence[\r\n"]
[145.708273, "o", "            # _SupportsArray[dtype[Union[bool_, integer[Any]]]]],\r\n"]
[145.722318, "o", "            # _NestedSequence[Union[bool, int]]], ...]]\"\r\n"]
[145.736364, "o", "            data_slice = self.to_dense()[key]  # type: ignore[index]\r\n"]
[145.750409, "o", "        elif isinstance(key, slice):\r\n"]
[145.764455, "o", "            # Avoid densifying when handling contiguous slices\r\n"]
[145.7785, "o", "            if key.step is None or key.step == 1:\r\n"]
[145.792545, "o", "                start = 0 if key.start is None else key.start\r\n"]
[145.806591, "o", "                if start < 0:\r\n"]
[145.820636, "o", "                    start += len(self)\r\n"]
[145.834682, "o", "\r\n"]
[145.848727, "o", "                end = len(self) if key.stop is None else key.stop\r\n"]
[145.862773, "o", "                if end < 0:\r\n"]
[145.876818, "o", "                    end += len(self)\r\n"]
[145.890864, "o", "\r\n"]
[145.904909, "o", "                indices = self.sp_index.indices\r\n"]
[145.918955, "o", "                keep_inds = np.flatnonzero((indices >= start) & (indices < end))\r\n"]
[145.933, "o", "                sp_vals = self.sp_values[keep_inds]\r\n"]
[145.947045, "o", "\r\n"]
[145.961091, "o", "                sp_index = indices[keep_inds].copy()\r\n"]
[145.975136, "o", "\r\n"]
[145.989182, "o", "                # If we've sliced to not include the start of the array, all our indices\r\n"]
[146.003227, "o", "                # should be shifted. NB: here we are careful to also not shift by a\r\n"]
[146.017273, "o", "                # negative value for a case like [0, 1][-100:] where the start index\r\n"]
[146.031318, "o", "                # should be treated like 0\r\n"]
[146.045364, "o", "                if start > 0:\r\n"]
[146.059409, "o", "                    sp_index -= start\r\n"]
[146.073455, "o", "\r\n"]
[146.0875, "o", "                # Length of our result should match applying this slice to a range\r\n"]
[146.101545, "o", "                # of the length of our original array\r\n"]
[146.115591, "o", "                new_len = len(range(len(self))[key])\r\n"]
[146.129636, "o", "                new_sp_index = make_sparse_index(new_len, sp_index, self.kind)\r\n"]
[146.143682, "o", "                return type(self)._simple_new(sp_vals, new_sp_index, self.dtype)\r\n"]
[146.157727, "o", "            else:\r\n"]
[146.171773, "o", "                indices = np.arange(len(self), dtype=np.int32)[key]\r\n"]
[146.185818, "o", "                return self.take(indices)\r\n"]
[146.199864, "o", "\r\n"]
[146.213909, "o", "        elif not is_list_like(key):\r\n"]
[146.227955, "o", "            # e.g. \"foo\" or 2.5\r\n"]
[146.242, "o", "            # exception message copied from numpy\r\n"]
[146.256045, "o", "            raise IndexError(\r\n"]
[146.270091, "o", "                r\"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis \"\r\n"]
[146.284136, "o", "                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[146.298182, "o", "            )\r\n"]
[146.312227, "o", "\r\n"]
[146.326273, "o", "        else:\r\n"]
[146.340318, "o", "            if isinstance(key, SparseArray):\r\n"]
[146.354364, "o", "                # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[146.368409, "o", "                # has only fill_value - true, false or nan\r\n"]
[146.382455, "o", "                # (see GH PR 44955)\r\n"]
[146.3965, "o", "                # we can apply mask very fast:\r\n"]
[146.410545, "o", "                if is_bool_dtype(key):\r\n"]
[146.424591, "o", "                    if isna(key.fill_value):\r\n"]
[146.438636, "o", "                        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[146.452682, "o", "                    if not key.fill_value:\r\n"]
[146.466727, "o", "                        return self.take(key.sp_index.indices)\r\n"]
[146.480773, "o", "                    n = len(self)\r\n"]
[146.494818, "o", "                    mask = np.full(n, True, dtype=np.bool_)\r\n"]
[146.508864, "o", "                    mask[key.sp_index.indices] = False\r\n"]
[146.522909, "o", "                    return self.take(np.arange(n)[mask])\r\n"]
[146.536955, "o", "                else:\r\n"]
[146.551, "o", "                    key = np.asarray(key)\r\n"]
[146.565045, "o", "\r\n"]
[146.579091, "o", "            key = check_array_indexer(self, key)\r\n"]
[146.593136, "o", "\r\n"]
[146.607182, "o", "            if com.is_bool_indexer(key):\r\n"]
[146.621227, "o", "                # mypy doesn't know we have an array here\r\n"]
[146.635273, "o", "                key = cast(np.ndarray, key)\r\n"]
[146.649318, "o", "                return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[146.663364, "o", "            elif hasattr(key, \"__len__\"):\r\n"]
[146.677409, "o", "                return self.take(key)\r\n"]
[146.691455, "o", "            else:\r\n"]
[146.7055, "o", "                raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[146.719545, "o", "\r\n"]
[146.733591, "o", "        return type(self)(data_slice, kind=self.kind)\r\n"]
[146.747636, "o", "\r\n"]
[146.761682, "o", "    def _get_val_at(self, loc):\r\n"]
[146.775727, "o", "        loc = validate_insert_loc(loc, len(self))\r\n"]
[146.789773, "o", "\r\n"]
[146.803818, "o", "        sp_loc = self.sp_index.lookup(loc)\r\n"]
[146.817864, "o", "        if sp_loc == -1:\r\n"]
[146.831909, "o", "            return self.fill_value\r\n"]
[146.845955, "o", "        else:\r\n"]
[146.86, "o", "            val = self.sp_values[sp_loc]\r\n"]
[146.874045, "o", "            val = maybe_box_datetimelike(val, self.sp_values.dtype)\r\n"]
[146.888091, "o", "            return val\r\n"]
[146.902136, "o", "\r\n"]
[146.916182, "o", "    def take(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[146.930227, "o", "        if is_scalar(indices):\r\n"]
[146.944273, "o", "            raise ValueError(f\"'indices' must be an array, not a scalar '{indices}'.\")\r\n"]
[146.958318, "o", "        indices = np.asarray(indices, dtype=np.int32)\r\n"]
[146.972364, "o", "\r\n"]
[146.986409, "o", "        dtype = None\r\n"]
[147.000455, "o", "        if indices.size == 0:\r\n"]
[147.0145, "o", "            result = np.array([], dtype=\"object\")\r\n"]
[147.028545, "o", "            dtype = self.dtype\r\n"]
[147.042591, "o", "        elif allow_fill:\r\n"]
[147.056636, "o", "            result = self._take_with_fill(indices, fill_value=fill_value)\r\n"]
[147.070682, "o", "        else:\r\n"]
[147.084727, "o", "            return self._take_without_fill(indices)\r\n"]
[147.098773, "o", "\r\n"]
[147.112818, "o", "        return type(self)(\r\n"]
[147.126864, "o", "            result, fill_value=self.fill_value, kind=self.kind, dtype=dtype\r\n"]
[147.140909, "o", "        )\r\n"]
[147.154955, "o", "\r\n"]
[147.169, "o", "    def _take_with_fill(self, indices, fill_value=None) -> np.ndarray:\r\n"]
[147.183045, "o", "        if fill_value is None:\r\n"]
[147.197091, "o", "            fill_value = self.dtype.na_value\r\n"]
[147.211136, "o", "\r\n"]
[147.225182, "o", "        if indices.min() < -1:\r\n"]
[147.239227, "o", "            raise ValueError(\r\n"]
[147.253273, "o", "                \"Invalid value in 'indices'. Must be between -1 \"\r\n"]
[147.267318, "o", "                \"and the length of the array.\"\r\n"]
[147.281364, "o", "            )\r\n"]
[147.295409, "o", "\r\n"]
[147.309455, "o", "        if indices.max() >= len(self):\r\n"]
[147.3235, "o", "            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[147.337545, "o", "\r\n"]
[147.351591, "o", "        if len(self) == 0:\r\n"]
[147.365636, "o", "            # Empty... Allow taking only if all empty\r\n"]
[147.379682, "o", "            if (indices == -1).all():\r\n"]
[147.393727, "o", "                dtype = np.result_type(self.sp_values, type(fill_value))\r\n"]
[147.407773, "o", "                taken = np.empty_like(indices, dtype=dtype)\r\n"]
[147.421818, "o", "                taken.fill(fill_value)\r\n"]
[147.435864, "o", "                return taken\r\n"]
[147.449909, "o", "            else:\r\n"]
[147.463955, "o", "                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[147.478, "o", "\r\n"]
[147.492045, "o", "        # sp_indexer may be -1 for two reasons\r\n"]
[147.506091, "o", "        # 1.) we took for an index of -1 (new)\r\n"]
[147.520136, "o", "        # 2.) we took a value that was self.fill_value (old)\r\n"]
[147.534182, "o", "        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[147.548227, "o", "        new_fill_indices = indices == -1\r\n"]
[147.562273, "o", "        old_fill_indices = (sp_indexer == -1) & ~new_fill_indices\r\n"]
[147.576318, "o", "\r\n"]
[147.590364, "o", "        if self.sp_index.npoints == 0 and old_fill_indices.all():\r\n"]
[147.604409, "o", "            # We've looked up all valid points on an all-sparse array.\r\n"]
[147.618455, "o", "            taken = np.full(\r\n"]
[147.6325, "o", "                sp_indexer.shape, fill_value=self.fill_value, dtype=self.dtype.subtype\r\n"]
[147.646545, "o", "            )\r\n"]
[147.660591, "o", "\r\n"]
[147.674636, "o", "        elif self.sp_index.npoints == 0:\r\n"]
[147.688682, "o", "            # Use the old fill_value unless we took for an index of -1\r\n"]
[147.702727, "o", "            _dtype = np.result_type(self.dtype.subtype, type(fill_value))\r\n"]
[147.716773, "o", "            taken = np.full(sp_indexer.shape, fill_value=fill_value, dtype=_dtype)\r\n"]
[147.730818, "o", "            taken[old_fill_indices] = self.fill_value\r\n"]
[147.744864, "o", "        else:\r\n"]
[147.758909, "o", "            taken = self.sp_values.take(sp_indexer)\r\n"]
[147.772955, "o", "\r\n"]
[147.787, "o", "            # Fill in two steps.\r\n"]
[147.801045, "o", "            # Old fill values\r\n"]
[147.815091, "o", "            # New fill values\r\n"]
[147.829136, "o", "            # potentially coercing to a new dtype at each stage.\r\n"]
[147.843182, "o", "\r\n"]
[147.857227, "o", "            m0 = sp_indexer[old_fill_indices] < 0\r\n"]
[147.871273, "o", "            m1 = sp_indexer[new_fill_indices] < 0\r\n"]
[147.885318, "o", "\r\n"]
[147.899364, "o", "            result_type = taken.dtype\r\n"]
[147.913409, "o", "\r\n"]
[147.927455, "o", "            if m0.any():\r\n"]
[147.9415, "o", "                result_type = np.result_type(result_type, type(self.fill_value))\r\n"]
[147.955545, "o", "                taken = taken.astype(result_type)\r\n"]
[147.969591, "o", "                taken[old_fill_indices] = self.fill_value\r\n"]
[147.983636, "o", "\r\n"]
[147.997682, "o", "            if m1.any():\r\n"]
[148.011727, "o", "                result_type = np.result_type(result_type, type(fill_value))\r\n"]
[148.025773, "o", "                taken = taken.astype(result_type)\r\n"]
[148.039818, "o", "                taken[new_fill_indices] = fill_value\r\n"]
[148.053864, "o", "\r\n"]
[148.067909, "o", "        return taken\r\n"]
[148.081955, "o", "\r\n"]
[148.096, "o", "    def _take_without_fill(self, indices) -> Self:\r\n"]
[148.110045, "o", "        to_shift = indices < 0\r\n"]
[148.124091, "o", "\r\n"]
[148.138136, "o", "        n = len(self)\r\n"]
[148.152182, "o", "\r\n"]
[148.166227, "o", "        if (indices.max() >= n) or (indices.min() < -n):\r\n"]
[148.180273, "o", "            if n == 0:\r\n"]
[148.194318, "o", "                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[148.208364, "o", "            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[148.222409, "o", "\r\n"]
[148.236455, "o", "        if to_shift.any():\r\n"]
[148.2505, "o", "            indices = indices.copy()\r\n"]
[148.264545, "o", "            indices[to_shift] += n\r\n"]
[148.278591, "o", "\r\n"]
[148.292636, "o", "        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[148.306682, "o", "        value_mask = sp_indexer != -1\r\n"]
[148.320727, "o", "        new_sp_values = self.sp_values[sp_indexer[value_mask]]\r\n"]
[148.334773, "o", "\r\n"]
[148.348818, "o", "        value_indices = np.flatnonzero(value_mask).astype(np.int32, copy=False)\r\n"]
[148.362864, "o", "\r\n"]
[148.376909, "o", "        new_sp_index = make_sparse_index(len(indices), value_indices, kind=self.kind)\r\n"]
[148.390955, "o", "        return type(self)._simple_new(new_sp_values, new_sp_index, dtype=self.dtype)\r\n"]
[148.405, "o", "\r\n"]
[148.419045, "o", "    def searchsorted(\r\n"]
[148.433091, "o", "        self,\r\n"]
[148.447136, "o", "        v: ArrayLike | object,\r\n"]
[148.461182, "o", "        side: Literal[\"left\", \"right\"] = \"left\",\r\n"]
[148.475227, "o", "        sorter: NumpySorter | None = None,\r\n"]
[148.489273, "o", "    ) -> npt.NDArray[np.intp] | np.intp:\r\n"]
[148.503318, "o", "        msg = \"searchsorted requires high memory usage.\"\r\n"]
[148.517364, "o", "        warnings.warn(msg, PerformanceWarning, stacklevel=find_stack_level())\r\n"]
[148.531409, "o", "        v = np.asarray(v)\r\n"]
[148.545455, "o", "        return np.asarray(self, dtype=self.dtype.subtype).searchsorted(v, side, sorter)\r\n"]
[148.5595, "o", "\r\n"]
[148.573545, "o", "    def copy(self) -> Self:\r\n"]
[148.587591, "o", "        values = self.sp_values.copy()\r\n"]
[148.601636, "o", "        return self._simple_new(values, self.sp_index, self.dtype)\r\n"]
[148.615682, "o", "\r\n"]
[148.629727, "o", "    @classmethod\r\n"]
[148.643773, "o", "    def _concat_same_type(cls, to_concat: Sequence[Self]) -> Self:\r\n"]
[148.657818, "o", "        fill_value = to_concat[0].fill_value\r\n"]
[148.671864, "o", "\r\n"]
[148.685909, "o", "        values = []\r\n"]
[148.699955, "o", "        length = 0\r\n"]
[148.714, "o", "\r\n"]
[148.728045, "o", "        if to_concat:\r\n"]
[148.742091, "o", "            sp_kind = to_concat[0].kind\r\n"]
[148.756136, "o", "        else:\r\n"]
[148.770182, "o", "            sp_kind = \"integer\"\r\n"]
[148.784227, "o", "\r\n"]
[148.798273, "o", "        sp_index: SparseIndex\r\n"]
[148.812318, "o", "        if sp_kind == \"integer\":\r\n"]
[148.826364, "o", "            indices = []\r\n"]
[148.840409, "o", "\r\n"]
[148.854455, "o", "            for arr in to_concat:\r\n"]
[148.8685, "o", "                int_idx = arr.sp_index.indices.copy()\r\n"]
[148.882545, "o", "                int_idx += length  # TODO: wraparound\r\n"]
[148.896591, "o", "                length += arr.sp_index.length\r\n"]
[148.910636, "o", "\r\n"]
[148.924682, "o", "                values.append(arr.sp_values)\r\n"]
[148.938727, "o", "                indices.append(int_idx)\r\n"]
[148.952773, "o", "\r\n"]
[148.966818, "o", "            data = np.concatenate(values)\r\n"]
[148.980864, "o", "            indices_arr = np.concatenate(indices)\r\n"]
[148.994909, "o", "            # error: Argument 2 to \"IntIndex\" has incompatible type\r\n"]
[149.008955, "o", "            # \"ndarray[Any, dtype[signedinteger[_32Bit]]]\";\r\n"]
[149.023, "o", "            # expected \"Sequence[int]\"\r\n"]
[149.037045, "o", "            sp_index = IntIndex(length, indices_arr)  # type: ignore[arg-type]\r\n"]
[149.051091, "o", "\r\n"]
[149.065136, "o", "        else:\r\n"]
[149.079182, "o", "            # when concatenating block indices, we don't claim that you'll\r\n"]
[149.093227, "o", "            # get an identical index as concatenating the values and then\r\n"]
[149.107273, "o", "            # creating a new index. We don't want to spend the time trying\r\n"]
[149.121318, "o", "            # to merge blocks across arrays in `to_concat`, so the resulting\r\n"]
[149.135364, "o", "            # BlockIndex may have more blocks.\r\n"]
[149.149409, "o", "            blengths = []\r\n"]
[149.163455, "o", "            blocs = []\r\n"]
[149.1775, "o", "\r\n"]
[149.191545, "o", "            for arr in to_concat:\r\n"]
[149.205591, "o", "                block_idx = arr.sp_index.to_block_index()\r\n"]
[149.219636, "o", "\r\n"]
[149.233682, "o", "                values.append(arr.sp_values)\r\n"]
[149.247727, "o", "                blocs.append(block_idx.blocs.copy() + length)\r\n"]
[149.261773, "o", "                blengths.append(block_idx.blengths)\r\n"]
[149.275818, "o", "                length += arr.sp_index.length\r\n"]
[149.289864, "o", "\r\n"]
[149.303909, "o", "            data = np.concatenate(values)\r\n"]
[149.317955, "o", "            blocs_arr = np.concatenate(blocs)\r\n"]
[149.332, "o", "            blengths_arr = np.concatenate(blengths)\r\n"]
[149.346045, "o", "\r\n"]
[149.360091, "o", "            sp_index = BlockIndex(length, blocs_arr, blengths_arr)\r\n"]
[149.374136, "o", "\r\n"]
[149.388182, "o", "        return cls(data, sparse_index=sp_index, fill_value=fill_value)\r\n"]
[149.402227, "o", "\r\n"]
[149.416273, "o", "    def astype(self, dtype: AstypeArg | None = None, copy: bool = True):\r\n"]
[149.430318, "o", "        \"\"\"\r\n"]
[149.444364, "o", "        Change the dtype of a SparseArray.\r\n"]
[149.458409, "o", "\r\n"]
[149.472455, "o", "        The output will always be a SparseArray. To convert to a dense\r\n"]
[149.4865, "o", "        ndarray with a certain dtype, use :meth:`numpy.asarray`.\r\n"]
[149.500545, "o", "\r\n"]
[149.514591, "o", "        Parameters\r\n"]
[149.528636, "o", "        ----------\r\n"]
[149.542682, "o", "        dtype : np.dtype or ExtensionDtype\r\n"]
[149.556727, "o", "            For SparseDtype, this changes the dtype of\r\n"]
[149.570773, "o", "            ``self.sp_values`` and the ``self.fill_value``.\r\n"]
[149.584818, "o", "\r\n"]
[149.598864, "o", "            For other dtypes, this only changes the dtype of\r\n"]
[149.612909, "o", "            ``self.sp_values``.\r\n"]
[149.626955, "o", "\r\n"]
[149.641, "o", "        copy : bool, default True\r\n"]
[149.655045, "o", "            Whether to ensure a copy is made, even if not necessary.\r\n"]
[149.669091, "o", "\r\n"]
[149.683136, "o", "        Returns\r\n"]
[149.697182, "o", "        -------\r\n"]
[149.711227, "o", "        SparseArray\r\n"]
[149.725273, "o", "\r\n"]
[149.739318, "o", "        Examples\r\n"]
[149.753364, "o", "        --------\r\n"]
[149.767409, "o", "        >>> arr = pd.arrays.SparseArray([0, 0, 1, 2])\r\n"]
[149.781455, "o", "        >>> arr\r\n"]
[149.7955, "o", "        [0, 0, 1, 2]\r\n"]
[149.809545, "o", "        Fill: 0\r\n"]
[149.823591, "o", "        IntIndex\r\n"]
[149.837636, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[149.851682, "o", "\r\n"]
[149.865727, "o", "        >>> arr.astype(SparseDtype(np.dtype('int32')))\r\n"]
[149.879773, "o", "        [0, 0, 1, 2]\r\n"]
[149.893818, "o", "        Fill: 0\r\n"]
[149.907864, "o", "        IntIndex\r\n"]
[149.921909, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[149.935955, "o", "\r\n"]
[150.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[150.002, "i", "sed -n '1250,1500p' pandas/core/arrays/sparse/array.py\r"]
[150.004, "o", "sed -n '1250,1500p' pandas/core/arrays/sparse/array.py\r\n"]
[150.025619, "o", "\u001b[?2004l\r\n"]
[150.045238, "o", "        Using a NumPy dtype with a different kind (e.g. float) will coerce\r\n"]
[150.064857, "o", "        just ``self.sp_values``.\r\n"]
[150.084476, "o", "\r\n"]
[150.104095, "o", "        >>> arr.astype(SparseDtype(np.dtype('float64')))\r\n"]
[150.123714, "o", "        ... # doctest: +NORMALIZE_WHITESPACE\r\n"]
[150.143333, "o", "        [nan, nan, 1.0, 2.0]\r\n"]
[150.162952, "o", "        Fill: nan\r\n"]
[150.182571, "o", "        IntIndex\r\n"]
[150.20219, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[150.22181, "o", "\r\n"]
[150.241429, "o", "        Using a SparseDtype, you can also change the fill value as well.\r\n"]
[150.261048, "o", "\r\n"]
[150.280667, "o", "        >>> arr.astype(SparseDtype(\"float64\", fill_value=0.0))\r\n"]
[150.300286, "o", "        ... # doctest: +NORMALIZE_WHITESPACE\r\n"]
[150.319905, "o", "        [0.0, 0.0, 1.0, 2.0]\r\n"]
[150.339524, "o", "        Fill: 0.0\r\n"]
[150.359143, "o", "        IntIndex\r\n"]
[150.378762, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[150.398381, "o", "        \"\"\"\r\n"]
[150.418, "o", "        if dtype == self._dtype:\r\n"]
[150.437619, "o", "            if not copy:\r\n"]
[150.457238, "o", "                return self\r\n"]
[150.476857, "o", "            else:\r\n"]
[150.496476, "o", "                return self.copy()\r\n"]
[150.516095, "o", "\r\n"]
[150.535714, "o", "        future_dtype = pandas_dtype(dtype)\r\n"]
[150.555333, "o", "        if not isinstance(future_dtype, SparseDtype):\r\n"]
[150.574952, "o", "            # GH#34457\r\n"]
[150.594571, "o", "            values = np.asarray(self)\r\n"]
[150.61419, "o", "            values = ensure_wrapped_if_datetimelike(values)\r\n"]
[150.63381, "o", "            return astype_array(values, dtype=future_dtype, copy=False)\r\n"]
[150.653429, "o", "\r\n"]
[150.673048, "o", "        dtype = self.dtype.update_dtype(dtype)\r\n"]
[150.692667, "o", "        subtype = pandas_dtype(dtype._subtype_with_str)\r\n"]
[150.712286, "o", "        subtype = cast(np.dtype, subtype)  # ensured by update_dtype\r\n"]
[150.731905, "o", "        values = ensure_wrapped_if_datetimelike(self.sp_values)\r\n"]
[150.751524, "o", "        sp_values = astype_array(values, subtype, copy=copy)\r\n"]
[150.771143, "o", "        sp_values = np.asarray(sp_values)\r\n"]
[150.790762, "o", "\r\n"]
[150.810381, "o", "        return self._simple_new(sp_values, self.sp_index, dtype)\r\n"]
[150.83, "o", "\r\n"]
[150.849619, "o", "    def map(self, mapper, na_action=None) -> Self:\r\n"]
[150.869238, "o", "        \"\"\"\r\n"]
[150.888857, "o", "        Map categories using an input mapping or function.\r\n"]
[150.908476, "o", "\r\n"]
[150.928095, "o", "        Parameters\r\n"]
[150.947714, "o", "        ----------\r\n"]
[150.967333, "o", "        mapper : dict, Series, callable\r\n"]
[150.986952, "o", "            The correspondence from old values to new.\r\n"]
[151.006571, "o", "        na_action : {None, 'ignore'}, default None\r\n"]
[151.02619, "o", "            If 'ignore', propagate NA values, without passing them to the\r\n"]
[151.04581, "o", "            mapping correspondence.\r\n"]
[151.065429, "o", "\r\n"]
[151.085048, "o", "        Returns\r\n"]
[151.104667, "o", "        -------\r\n"]
[151.124286, "o", "        SparseArray\r\n"]
[151.143905, "o", "            The output array will have the same density as the input.\r\n"]
[151.163524, "o", "            The output fill value will be the result of applying the\r\n"]
[151.183143, "o", "            mapping to ``self.fill_value``\r\n"]
[151.202762, "o", "\r\n"]
[151.222381, "o", "        Examples\r\n"]
[151.242, "o", "        --------\r\n"]
[151.261619, "o", "        >>> arr = pd.arrays.SparseArray([0, 1, 2])\r\n"]
[151.281238, "o", "        >>> arr.map(lambda x: x + 10)\r\n"]
[151.300857, "o", "        [10, 11, 12]\r\n"]
[151.320476, "o", "        Fill: 10\r\n"]
[151.340095, "o", "        IntIndex\r\n"]
[151.359714, "o", "        Indices: array([1, 2], dtype=int32)\r\n"]
[151.379333, "o", "\r\n"]
[151.398952, "o", "        >>> arr.map({0: 10, 1: 11, 2: 12})\r\n"]
[151.418571, "o", "        [10, 11, 12]\r\n"]
[151.43819, "o", "        Fill: 10\r\n"]
[151.45781, "o", "        IntIndex\r\n"]
[151.477429, "o", "        Indices: array([1, 2], dtype=int32)\r\n"]
[151.497048, "o", "\r\n"]
[151.516667, "o", "        >>> arr.map(pd.Series([10, 11, 12], index=[0, 1, 2]))\r\n"]
[151.536286, "o", "        [10, 11, 12]\r\n"]
[151.555905, "o", "        Fill: 10\r\n"]
[151.575524, "o", "        IntIndex\r\n"]
[151.595143, "o", "        Indices: array([1, 2], dtype=int32)\r\n"]
[151.614762, "o", "        \"\"\"\r\n"]
[151.634381, "o", "        is_map = isinstance(mapper, (abc.Mapping, ABCSeries))\r\n"]
[151.654, "o", "\r\n"]
[151.673619, "o", "        fill_val = self.fill_value\r\n"]
[151.693238, "o", "\r\n"]
[151.712857, "o", "        if na_action is None or notna(fill_val):\r\n"]
[151.732476, "o", "            fill_val = mapper.get(fill_val, fill_val) if is_map else mapper(fill_val)\r\n"]
[151.752095, "o", "\r\n"]
[151.771714, "o", "        def func(sp_val):\r\n"]
[151.791333, "o", "            new_sp_val = mapper.get(sp_val, None) if is_map else mapper(sp_val)\r\n"]
[151.810952, "o", "            # check identity and equality because nans are not equal to each other\r\n"]
[151.830571, "o", "            if new_sp_val is fill_val or new_sp_val == fill_val:\r\n"]
[151.85019, "o", "                msg = \"fill value in the sparse values not supported\"\r\n"]
[151.86981, "o", "                raise ValueError(msg)\r\n"]
[151.889429, "o", "            return new_sp_val\r\n"]
[151.909048, "o", "\r\n"]
[151.928667, "o", "        sp_values = [func(x) for x in self.sp_values]\r\n"]
[151.948286, "o", "\r\n"]
[151.967905, "o", "        return type(self)(sp_values, sparse_index=self.sp_index, fill_value=fill_val)\r\n"]
[151.987524, "o", "\r\n"]
[152.007143, "o", "    def to_dense(self) -> np.ndarray:\r\n"]
[152.026762, "o", "        \"\"\"\r\n"]
[152.046381, "o", "        Convert SparseArray to a NumPy array.\r\n"]
[152.066, "o", "\r\n"]
[152.085619, "o", "        Returns\r\n"]
[152.105238, "o", "        -------\r\n"]
[152.124857, "o", "        arr : NumPy array\r\n"]
[152.144476, "o", "        \"\"\"\r\n"]
[152.164095, "o", "        return np.asarray(self, dtype=self.sp_values.dtype)\r\n"]
[152.183714, "o", "\r\n"]
[152.203333, "o", "    def _where(self, mask, value):\r\n"]
[152.222952, "o", "        # NB: may not preserve dtype, e.g. result may be Sparse[float64]\r\n"]
[152.242571, "o", "        #  while self is Sparse[int64]\r\n"]
[152.26219, "o", "        naive_implementation = np.where(mask, self, value)\r\n"]
[152.28181, "o", "        dtype = SparseDtype(naive_implementation.dtype, fill_value=self.fill_value)\r\n"]
[152.301429, "o", "        result = type(self)._from_sequence(naive_implementation, dtype=dtype)\r\n"]
[152.321048, "o", "        return result\r\n"]
[152.340667, "o", "\r\n"]
[152.360286, "o", "    # ------------------------------------------------------------------------\r\n"]
[152.379905, "o", "    # IO\r\n"]
[152.399524, "o", "    # ------------------------------------------------------------------------\r\n"]
[152.419143, "o", "    def __setstate__(self, state) -> None:\r\n"]
[152.438762, "o", "        \"\"\"Necessary for making this object picklable\"\"\"\r\n"]
[152.458381, "o", "        if isinstance(state, tuple):\r\n"]
[152.478, "o", "            # Compat for pandas < 0.24.0\r\n"]
[152.497619, "o", "            nd_state, (fill_value, sp_index) = state\r\n"]
[152.517238, "o", "            sparse_values = np.array([])\r\n"]
[152.536857, "o", "            sparse_values.__setstate__(nd_state)\r\n"]
[152.556476, "o", "\r\n"]
[152.576095, "o", "            self._sparse_values = sparse_values\r\n"]
[152.595714, "o", "            self._sparse_index = sp_index\r\n"]
[152.615333, "o", "            self._dtype = SparseDtype(sparse_values.dtype, fill_value)\r\n"]
[152.634952, "o", "        else:\r\n"]
[152.654571, "o", "            self.__dict__.update(state)\r\n"]
[152.67419, "o", "\r\n"]
[152.69381, "o", "    def nonzero(self) -> tuple[npt.NDArray[np.int32]]:\r\n"]
[152.713429, "o", "        if self.fill_value == 0:\r\n"]
[152.733048, "o", "            return (self.sp_index.indices,)\r\n"]
[152.752667, "o", "        else:\r\n"]
[152.772286, "o", "            return (self.sp_index.indices[self.sp_values != 0],)\r\n"]
[152.791905, "o", "\r\n"]
[152.811524, "o", "    # ------------------------------------------------------------------------\r\n"]
[152.831143, "o", "    # Reductions\r\n"]
[152.850762, "o", "    # ------------------------------------------------------------------------\r\n"]
[152.870381, "o", "\r\n"]
[152.89, "o", "    def _reduce(\r\n"]
[152.909619, "o", "        self, name: str, *, skipna: bool = True, keepdims: bool = False, **kwargs\r\n"]
[152.929238, "o", "    ):\r\n"]
[152.948857, "o", "        method = getattr(self, name, None)\r\n"]
[152.968476, "o", "\r\n"]
[152.988095, "o", "        if method is None:\r\n"]
[153.007714, "o", "            raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\r\n"]
[153.027333, "o", "\r\n"]
[153.046952, "o", "        if skipna:\r\n"]
[153.066571, "o", "            arr = self\r\n"]
[153.08619, "o", "        else:\r\n"]
[153.10581, "o", "            arr = self.dropna()\r\n"]
[153.125429, "o", "\r\n"]
[153.145048, "o", "        result = getattr(arr, name)(**kwargs)\r\n"]
[153.164667, "o", "\r\n"]
[153.184286, "o", "        if keepdims:\r\n"]
[153.203905, "o", "            return type(self)([result], dtype=self.dtype)\r\n"]
[153.223524, "o", "        else:\r\n"]
[153.243143, "o", "            return result\r\n"]
[153.262762, "o", "\r\n"]
[153.282381, "o", "    def all(self, axis=None, *args, **kwargs):\r\n"]
[153.302, "o", "        \"\"\"\r\n"]
[153.321619, "o", "        Tests whether all elements evaluate True\r\n"]
[153.341238, "o", "\r\n"]
[153.360857, "o", "        Returns\r\n"]
[153.380476, "o", "        -------\r\n"]
[153.400095, "o", "        all : bool\r\n"]
[153.419714, "o", "\r\n"]
[153.439333, "o", "        See Also\r\n"]
[153.458952, "o", "        --------\r\n"]
[153.478571, "o", "        numpy.all\r\n"]
[153.49819, "o", "        \"\"\"\r\n"]
[153.51781, "o", "        nv.validate_all(args, kwargs)\r\n"]
[153.537429, "o", "\r\n"]
[153.557048, "o", "        values = self.sp_values\r\n"]
[153.576667, "o", "\r\n"]
[153.596286, "o", "        if len(values) != len(self) and not np.all(self.fill_value):\r\n"]
[153.615905, "o", "            return False\r\n"]
[153.635524, "o", "\r\n"]
[153.655143, "o", "        return values.all()\r\n"]
[153.674762, "o", "\r\n"]
[153.694381, "o", "    def any(self, axis: AxisInt = 0, *args, **kwargs) -> bool:\r\n"]
[153.714, "o", "        \"\"\"\r\n"]
[153.733619, "o", "        Tests whether at least one of elements evaluate True\r\n"]
[153.753238, "o", "\r\n"]
[153.772857, "o", "        Returns\r\n"]
[153.792476, "o", "        -------\r\n"]
[153.812095, "o", "        any : bool\r\n"]
[153.831714, "o", "\r\n"]
[153.851333, "o", "        See Also\r\n"]
[153.870952, "o", "        --------\r\n"]
[153.890571, "o", "        numpy.any\r\n"]
[153.91019, "o", "        \"\"\"\r\n"]
[153.92981, "o", "        nv.validate_any(args, kwargs)\r\n"]
[153.949429, "o", "\r\n"]
[153.969048, "o", "        values = self.sp_values\r\n"]
[153.988667, "o", "\r\n"]
[154.008286, "o", "        if len(values) != len(self) and np.any(self.fill_value):\r\n"]
[154.027905, "o", "            return True\r\n"]
[154.047524, "o", "\r\n"]
[154.067143, "o", "        return values.any().item()\r\n"]
[154.086762, "o", "\r\n"]
[154.106381, "o", "    def sum(\r\n"]
[154.126, "o", "        self,\r\n"]
[154.145619, "o", "        axis: AxisInt = 0,\r\n"]
[154.165238, "o", "        min_count: int = 0,\r\n"]
[154.184857, "o", "        skipna: bool = True,\r\n"]
[154.204476, "o", "        *args,\r\n"]
[154.224095, "o", "        **kwargs,\r\n"]
[154.243714, "o", "    ) -> Scalar:\r\n"]
[154.263333, "o", "        \"\"\"\r\n"]
[154.282952, "o", "        Sum of non-NA/null values\r\n"]
[154.302571, "o", "\r\n"]
[154.32219, "o", "        Parameters\r\n"]
[154.34181, "o", "        ----------\r\n"]
[154.361429, "o", "        axis : int, default 0\r\n"]
[154.381048, "o", "            Not Used. NumPy compatibility.\r\n"]
[154.400667, "o", "        min_count : int, default 0\r\n"]
[154.420286, "o", "            The required number of valid values to perform the summation. If fewer\r\n"]
[154.439905, "o", "            than ``min_count`` valid values are present, the result will be the missing\r\n"]
[154.459524, "o", "            value indicator for subarray type.\r\n"]
[154.479143, "o", "        *args, **kwargs\r\n"]
[154.498762, "o", "            Not Used. NumPy compatibility.\r\n"]
[154.518381, "o", "\r\n"]
[154.538, "o", "        Returns\r\n"]
[154.557619, "o", "        -------\r\n"]
[154.577238, "o", "        scalar\r\n"]
[154.596857, "o", "        \"\"\"\r\n"]
[154.616476, "o", "        nv.validate_sum(args, kwargs)\r\n"]
[154.636095, "o", "        valid_vals = self._valid_sp_values\r\n"]
[154.655714, "o", "        sp_sum = valid_vals.sum()\r\n"]
[154.675333, "o", "        has_na = self.sp_index.ngaps > 0 and not self._null_fill_value\r\n"]
[154.694952, "o", "\r\n"]
[154.714571, "o", "        if has_na and not skipna:\r\n"]
[154.73419, "o", "            return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[154.75381, "o", "\r\n"]
[154.773429, "o", "        if self._null_fill_value:\r\n"]
[154.793048, "o", "            if check_below_min_count(valid_vals.shape, None, min_count):\r\n"]
[154.812667, "o", "                return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[154.832286, "o", "            return sp_sum\r\n"]
[154.851905, "o", "        else:\r\n"]
[154.871524, "o", "            nsparse = self.sp_index.ngaps\r\n"]
[154.891143, "o", "            if check_below_min_count(valid_vals.shape, None, min_count - nsparse):\r\n"]
[154.910762, "o", "                return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[154.930381, "o", "            return sp_sum + self.fill_value * nsparse\r\n"]
[155.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[155.002, "i", "sed -n '980,1045p' pandas/core/arrays/sparse/array.py\r"]
[155.004, "o", "sed -n '980,1045p' pandas/core/arrays/sparse/array.py\r\n"]
[155.079791, "o", "\u001b[?2004l\r\n"]
[155.153582, "o", "            else:\r\n"]
[155.227373, "o", "                indices = np.arange(len(self), dtype=np.int32)[key]\r\n"]
[155.301164, "o", "                return self.take(indices)\r\n"]
[155.374955, "o", "\r\n"]
[155.448746, "o", "        elif not is_list_like(key):\r\n"]
[155.522537, "o", "            # e.g. \"foo\" or 2.5\r\n"]
[155.596328, "o", "            # exception message copied from numpy\r\n"]
[155.670119, "o", "            raise IndexError(\r\n"]
[155.74391, "o", "                r\"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis \"\r\n"]
[155.817701, "o", "                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[155.891493, "o", "            )\r\n"]
[155.965284, "o", "\r\n"]
[156.039075, "o", "        else:\r\n"]
[156.112866, "o", "            if isinstance(key, SparseArray):\r\n"]
[156.186657, "o", "                # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[156.260448, "o", "                # has only fill_value - true, false or nan\r\n"]
[156.334239, "o", "                # (see GH PR 44955)\r\n"]
[156.40803, "o", "                # we can apply mask very fast:\r\n"]
[156.481821, "o", "                if is_bool_dtype(key):\r\n"]
[156.555612, "o", "                    if isna(key.fill_value):\r\n"]
[156.629403, "o", "                        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[156.703194, "o", "                    if not key.fill_value:\r\n"]
[156.776985, "o", "                        return self.take(key.sp_index.indices)\r\n"]
[156.850776, "o", "                    n = len(self)\r\n"]
[156.924567, "o", "                    mask = np.full(n, True, dtype=np.bool_)\r\n"]
[156.998358, "o", "                    mask[key.sp_index.indices] = False\r\n"]
[157.072149, "o", "                    return self.take(np.arange(n)[mask])\r\n"]
[157.14594, "o", "                else:\r\n"]
[157.219731, "o", "                    key = np.asarray(key)\r\n"]
[157.293522, "o", "\r\n"]
[157.367313, "o", "            key = check_array_indexer(self, key)\r\n"]
[157.441104, "o", "\r\n"]
[157.514896, "o", "            if com.is_bool_indexer(key):\r\n"]
[157.588687, "o", "                # mypy doesn't know we have an array here\r\n"]
[157.662478, "o", "                key = cast(np.ndarray, key)\r\n"]
[157.736269, "o", "                return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[157.81006, "o", "            elif hasattr(key, \"__len__\"):\r\n"]
[157.883851, "o", "                return self.take(key)\r\n"]
[157.957642, "o", "            else:\r\n"]
[158.031433, "o", "                raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[158.105224, "o", "\r\n"]
[158.179015, "o", "        return type(self)(data_slice, kind=self.kind)\r\n"]
[158.252806, "o", "\r\n"]
[158.326597, "o", "    def _get_val_at(self, loc):\r\n"]
[158.400388, "o", "        loc = validate_insert_loc(loc, len(self))\r\n"]
[158.474179, "o", "\r\n"]
[158.54797, "o", "        sp_loc = self.sp_index.lookup(loc)\r\n"]
[158.621761, "o", "        if sp_loc == -1:\r\n"]
[158.695552, "o", "            return self.fill_value\r\n"]
[158.769343, "o", "        else:\r\n"]
[158.843134, "o", "            val = self.sp_values[sp_loc]\r\n"]
[158.916925, "o", "            val = maybe_box_datetimelike(val, self.sp_values.dtype)\r\n"]
[158.990716, "o", "            return val\r\n"]
[159.064507, "o", "\r\n"]
[159.138299, "o", "    def take(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[159.21209, "o", "        if is_scalar(indices):\r\n"]
[159.285881, "o", "            raise ValueError(f\"'indices' must be an array, not a scalar '{indices}'.\")\r\n"]
[159.359672, "o", "        indices = np.asarray(indices, dtype=np.int32)\r\n"]
[159.433463, "o", "\r\n"]
[159.507254, "o", "        dtype = None\r\n"]
[159.581045, "o", "        if indices.size == 0:\r\n"]
[159.654836, "o", "            result = np.array([], dtype=\"object\")\r\n"]
[159.728627, "o", "            dtype = self.dtype\r\n"]
[159.802418, "o", "        elif allow_fill:\r\n"]
[159.876209, "o", "            result = self._take_with_fill(indices, fill_value=fill_value)\r\n"]
[160.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[160.002, "i", "applypatch << 'PATCH'\r"]
[160.004, "o", "applypatch << 'PATCH'\r\n"]
[160.051778, "o", "\u001b[?2004l\r\n"]
[160.097556, "o", "\u001b[?2004h> *** Begin Patch\r\n"]
[160.143333, "o", "\u001b[?2004l\r\n"]
[160.189111, "o", "\u001b[?2004h> *** Update File: pandas/core/arrays/sparse/array.py\r\n"]
[160.234889, "o", "\u001b[?2004l\r\n"]
[160.280667, "o", "\u001b[?2004h> @@\r\n"]
[160.326444, "o", "\u001b[?2004l\r\n"]
[160.372222, "o", "\u001b[?2004h> -        elif isinstance(key, slice):\r\n"]
[160.418, "o", "\u001b[?2004l\r\n"]
[160.463778, "o", "\u001b[?2004h> +        elif isinstance(key, slice):\r\n"]
[160.509556, "o", "\u001b[?2004l\r\n"]
[160.555333, "o", "\u001b[?2004h> @@\r\n"]
[160.601111, "o", "\u001b[?2004l\r\n"]
[160.646889, "o", "\u001b[?2004h> -        else:\r\n"]
[160.692667, "o", "\u001b[?2004l\r\n"]
[160.738444, "o", "\u001b[?2004h> +        else:\r\n"]
[160.784222, "o", "\u001b[?2004l\r\n"]
[160.83, "o", "\u001b[?2004h>              # we can apply mask very fast:\r\n"]
[160.875778, "o", "\u001b[?2004l\r\n"]
[160.921556, "o", "\u001b[?2004h>              if is_bool_dtype(key):\r\n"]
[160.967333, "o", "\u001b[?2004l\r\n"]
[161.013111, "o", "\u001b[?2004h>                  # not a boolean sparse array, but just a list\r\n"]
[161.058889, "o", "\u001b[?2004l\r\n"]
[161.104667, "o", "\u001b[?2004h>                  # of booleans\r\n"]
[161.150444, "o", "\u001b[?2004l\r\n"]
[161.196222, "o", "\u001b[?2004h>                  if not isinstance(key, SparseArray):\r\n"]
[161.242, "o", "\u001b[?2004l\r\n"]
[161.287778, "o", "\u001b[?2004h>                      key = np.asarray(key, dtype=np.bool_)\r\n"]
[161.333556, "o", "\u001b[?2004l\r\n"]
[161.379333, "o", "\u001b[?2004h>                      if len(key) != len(self):\r\n"]
[161.425111, "o", "\u001b[?2004l\r\n"]
[161.470889, "o", "\u001b[?2004h>                          raise IndexError(\"incorrect length for boolean indexing\")\r\n"]
[161.516667, "o", "\u001b[?2004l\r\n"]
[161.562444, "o", "\u001b[?2004h>                      return self.take(np.nonzero(key)[0])\r\n"]
[161.608222, "o", "\u001b[?2004l\r\n"]
[161.654, "o", "\u001b[?2004h>  \r\n"]
[161.699778, "o", "\u001b[?2004l\r\n"]
[161.745556, "o", "\u001b[?2004h>                  # GH 27119: For boolean SparseArray, avoid densifying\r\n"]
[161.791333, "o", "\u001b[?2004l\r\n"]
[161.837111, "o", "\u001b[?2004h>                  n = len(self)\r\n"]
[161.882889, "o", "\u001b[?2004l\r\n"]
[161.928667, "o", "\u001b[?2004h> -                mask = np.full(n, True, dtype=np.bool_)\r\n"]
[161.974444, "o", "\u001b[?2004l\r\n"]
[162.020222, "o", "\u001b[?2004h> -                mask[key.sp_index.indices] = False\r\n"]
[162.066, "o", "\u001b[?2004l\r\n"]
[162.111778, "o", "\u001b[?2004h> -                return self.take(np.arange(n)[mask])\r\n"]
[162.157556, "o", "\u001b[?2004l\r\n"]
[162.203333, "o", "\u001b[?2004h> +                # Previous implementation defaulted to selecting positions where\r\n"]
[162.249111, "o", "\u001b[?2004l\r\n"]
[162.294889, "o", "\u001b[?2004h> +                # the sparse mask is True with a default False fill_value.\r\n"]
[162.340667, "o", "\u001b[?2004l\r\n"]
[162.386444, "o", "\u001b[?2004h> +                # However, when the boolean mask has fill_value=True (or NaN),\r\n"]
[162.432222, "o", "\u001b[?2004l\r\n"]
[162.478, "o", "\u001b[?2004h> +                # the selection becomes \"almost all\" positions and building a\r\n"]
[162.523778, "o", "\u001b[?2004l\r\n"]
[162.569556, "o", "\u001b[?2004h> +                # dense boolean mask and arange(n) is unnecessarily expensive.\r\n"]
[162.615333, "o", "\u001b[?2004l\r\n"]
[162.661111, "o", "\u001b[?2004h> +\r\n"]
[162.706889, "o", "\u001b[?2004l\r\n"]
[162.752667, "o", "\u001b[?2004h> +                # We handle both cases without constructing a large dense array:\r\n"]
[162.798444, "o", "\u001b[?2004l\r\n"]
[162.844222, "o", "\u001b[?2004h> +                # - If mask.fill_value is falsy (False), the explicit True\r\n"]
[162.89, "o", "\u001b[?2004l\r\n"]
[162.935778, "o", "\u001b[?2004h> +                #   positions are in key.sp_index.indices -> take those directly.\r\n"]
[162.981556, "o", "\u001b[?2004l\r\n"]
[163.027333, "o", "\u001b[?2004h> +                # - If mask.fill_value is truthy (True or NaN treated as True),\r\n"]
[163.073111, "o", "\u001b[?2004l\r\n"]
[163.118889, "o", "\u001b[?2004h> +                #   most positions are selected by default and only explicit\r\n"]
[163.164667, "o", "\u001b[?2004l\r\n"]
[163.210444, "o", "\u001b[?2004h> +                #   False entries should be dropped. In this representation,\r\n"]
[163.256222, "o", "\u001b[?2004l\r\n"]
[163.302, "o", "\u001b[?2004h> +                #   explicit entries differ from fill_value. For boolean dtype,\r\n"]
[163.347778, "o", "\u001b[?2004l\r\n"]
[163.393556, "o", "\u001b[?2004h> +                #   explicit values are 1 for True and 0 for False. When\r\n"]
[163.439333, "o", "\u001b[?2004l\r\n"]
[163.485111, "o", "\u001b[?2004h> +                #   fill_value is True, explicit entries must be False (0).\r\n"]
[163.530889, "o", "\u001b[?2004l\r\n"]
[163.576667, "o", "\u001b[?2004h> +                #   Therefore we can compute the complement efficiently by\r\n"]
[163.622444, "o", "\u001b[?2004l\r\n"]
[163.668222, "o", "\u001b[?2004h> +                #   removing these explicit indices from the full range.\r\n"]
[163.714, "o", "\u001b[?2004l\r\n"]
[163.759778, "o", "\u001b[?2004h> +\r\n"]
[163.805556, "o", "\u001b[?2004l\r\n"]
[163.851333, "o", "\u001b[?2004h> +                if getattr(key, \"fill_value\", False) is True or (isinstance(key.fill_value, float) and np.isnan(key.fill_value)):\r\n"]
[163.897111, "o", "\u001b[?2004l\r\n"]
[163.942889, "o", "\u001b[?2004h> +                    # select all indices except explicit stored values (which are False)\r\n"]
[163.988667, "o", "\u001b[?2004l\r\n"]
[164.034444, "o", "\u001b[?2004h> +                    # Build a boolean drop mask only for the explicit indices\r\n"]
[164.080222, "o", "\u001b[?2004l\r\n"]
[164.126, "o", "\u001b[?2004h> +                    drop = np.zeros(n, dtype=np.bool_)\r\n"]
[164.171778, "o", "\u001b[?2004l\r\n"]
[164.217556, "o", "\u001b[?2004h> +                    drop[key.sp_index.indices] = True\r\n"]
[164.263333, "o", "\u001b[?2004l\r\n"]
[164.309111, "o", "\u001b[?2004h> +                    keep = np.nonzero(~drop)[0]\r\n"]
[164.354889, "o", "\u001b[?2004l\r\n"]
[164.400667, "o", "\u001b[?2004h> +                    return self.take(keep)\r\n"]
[164.446444, "o", "\u001b[?2004l\r\n"]
[164.492222, "o", "\u001b[?2004h> +                else:\r\n"]
[164.538, "o", "\u001b[?2004l\r\n"]
[164.583778, "o", "\u001b[?2004h> +                    # fill_value is False (or falsy): take the explicit True indices\r\n"]
[164.629556, "o", "\u001b[?2004l\r\n"]
[164.675333, "o", "\u001b[?2004h> +                    return self.take(key.sp_index.indices.astype(np.int64, copy=False))\r\n"]
[164.721111, "o", "\u001b[?2004l\r\n"]
[164.766889, "o", "\u001b[?2004h> *** End Patch\r\n"]
[164.812667, "o", "\u001b[?2004l\r\n"]
[164.858444, "o", "\u001b[?2004h> PATCH\r\n"]
[164.904222, "o", "\u001b[?2004l\r\n"]
[165.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[165.002, "i", "pytest -q pandas/tests/extension/test_sparse.py::TestGetitem --maxfail=1 -q 2>/dev/null || true\r"]
[165.004, "o", "pytest -q pandas/tests/extension/test_sparse.py::TestGetitem --maxfail=1 -q 2>/dev/null || true\r\n"]
[165.712286, "o", "\u001b[?2004l\r\n"]
[166.418571, "o", "+ /opt/conda/envs/asv_3.10/bin/ninja\r\n"]
[167.124857, "o", "\r\n"]
[167.831143, "o", "[0/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[168.537429, "o", "[1/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[169.243714, "o", "\r\n"]
[170.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[170.002, "i", "python - << 'PY'\r"]
[170.004, "o", "python - << 'PY'\r\n"]
[170.123714, "o", "\u001b[?2004l\r\n"]
[170.241429, "o", "\u001b[?2004h> import numpy as np\r\n"]
[170.359143, "o", "\u001b[?2004l\r\n"]
[170.476857, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[170.594571, "o", "\u001b[?2004l\r\n"]
[170.712286, "o", "\u001b[?2004h> from pandas.arrays import SparseArray\r\n"]
[170.83, "o", "\u001b[?2004l\r\n"]
[170.947714, "o", "\u001b[?2004h> N=1_000_000\r\n"]
[171.065429, "o", "\u001b[?2004l\r\n"]
[171.183143, "o", "\u001b[?2004h> arr=np.full(N, np.nan, dtype=float)\r\n"]
[171.300857, "o", "\u001b[?2004l\r\n"]
[171.418571, "o", "\u001b[?2004h> idx=np.random.choice(np.arange(N), int(N*1e-5), replace=False)\r\n"]
[171.536286, "o", "\u001b[?2004l\r\n"]
[171.654, "o", "\u001b[?2004h> arr[idx]=np.random.rand(idx.size)\r\n"]
[171.771714, "o", "\u001b[?2004l\r\n"]
[171.889429, "o", "\u001b[?2004h> sp_arr=SparseArray(arr)\r\n"]
[172.007143, "o", "\u001b[?2004l\r\n"]
[172.124857, "o", "\u001b[?2004h> for fv in [True, False, np.nan]:\r\n"]
[172.242571, "o", "\u001b[?2004l\r\n"]
[172.360286, "o", "\u001b[?2004h>     b_arr = np.full(shape=N, fill_value=fv, dtype=bool)\r\n"]
[172.478, "o", "\u001b[?2004l\r\n"]
[172.595714, "o", "\u001b[?2004h>     fv_inds = np.unique(np.random.randint(low=0, high=N - 1, size=int(N * 1e-5), dtype=np.int32))\r\n"]
[172.713429, "o", "\u001b[?2004l\r\n"]
[172.831143, "o", "\u001b[?2004h>     b_arr[fv_inds] = True if pd.isna(fv) else (not fv)\r\n"]
[172.948857, "o", "\u001b[?2004l\r\n"]
[173.066571, "o", "\u001b[?2004h>     sp_b_arr = SparseArray(b_arr, dtype=bool, fill_value=fv)\r\n"]
[173.184286, "o", "\u001b[?2004l\r\n"]
[173.302, "o", "\u001b[?2004h>     import time\r\n"]
[173.419714, "o", "\u001b[?2004l\r\n"]
[173.537429, "o", "\u001b[?2004h>     t0 = time.perf_counter(); _ = sp_arr[sp_b_arr]; dt=(time.perf_counter()-t0)*1e3\r\n"]
[173.655143, "o", "\u001b[?2004l\r\n"]
[173.772857, "o", "\u001b[?2004h>     print(f\"fill_value={fv!r} -> {dt:.3f} ms, result len={len(_)}\")\r\n"]
[173.890571, "o", "\u001b[?2004l\r\n"]
[174.008286, "o", "\u001b[?2004h> PY\r\n"]
[174.126, "o", "\u001b[?2004l\r\n"]
[174.243714, "o", "+ /opt/conda/envs/asv_3.10/bin/ninja\r\n"]
[174.361429, "o", "\r\n"]
[174.479143, "o", "[0/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[174.596857, "o", "[1/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[174.714571, "o", "fill_value=True -> 15.817 ms, result len=999990\r\n"]
[174.832286, "o", "fill_value=False -> 0.081 ms, result len=10\r\n"]
[175.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[175.002, "i", "cd asv_bench\r"]
[175.004, "o", "cd asv_bench\r\n"]
[175.006, "o", "\u001b[?2004l\r\n"]
[180.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo/asv_bench# "]
[180.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\" --quick\r"]
[180.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\" --quick\r\n"]
[180.386308, "o", "\u001b[?2004l\r\n"]
[180.766615, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[181.146923, "o", "\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n"]
[181.527231, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[181.907538, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39msparse.GetItemMask.time_mask\u001b[0m                                                                                                                    ok\r\n"]
[182.287846, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ==========\u001b[0m\r\n"]
[182.668154, "o", "              fill_value            \r\n"]
[183.048462, "o", "             ------------ ----------\r\n"]
[183.428769, "o", "                 True      13.4\u00b10ms \r\n"]
[183.809077, "o", "                False      207\u00b10\u03bcs  \r\n"]
[184.189385, "o", "                 nan       9.13\u00b10ms \r\n"]
[184.569692, "o", "             ============ ==========\r\n"]
[185.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo/asv_bench# "]
[185.002, "i", "cd ..\r"]
[185.004, "o", "cd ..\r\n"]
[185.006, "o", "\u001b[?2004l\r\n"]
[190.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[190.002, "i", "python - << 'PY'\r"]
[190.004, "o", "python - << 'PY'\r\n"]
[190.047546, "o", "\u001b[?2004l\r\n"]
[190.089092, "o", "\u001b[?2004h> import io, re, sys, pathlib\r\n"]
[190.130639, "o", "\u001b[?2004l\r\n"]
[190.172185, "o", "\u001b[?2004h> p = pathlib.Path('pandas/core/arrays/sparse/array.py')\r\n"]
[190.213731, "o", "\u001b[?2004l\r\n"]
[190.255277, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[190.296824, "o", "\u001b[?2004l\r\n"]
[190.33837, "o", "\u001b[?2004h> pattern = re.compile(r\"(if\\s+isinstance\\(key,\\s*SparseArray\\):\\n\\s*# NOTE:.*?if\\s+is_bool_dtype\\(key\\):)(.*?)(\\n\\s*else:\\n\\s*key\\s*=\\s*np\\.asarray\\(key\\)\\n)\", \r\n"]
[190.379916, "o", " re.S)\r\n"]
[190.421462, "o", "\u001b[?2004l\r\n"]
[190.463008, "o", "\u001b[?2004h> match = pattern.search(s)\r\n"]
[190.504555, "o", "\u001b[?2004l\r\n"]
[190.546101, "o", "\u001b[?2004h> if not match:\r\n"]
[190.587647, "o", "\u001b[?2004l\r\n"]
[190.629193, "o", "\u001b[?2004h>     print('PATCH_PATTERN_NOT_FOUND'); sys.exit(1)\r\n"]
[190.670739, "o", "\u001b[?2004l\r\n"]
[190.712286, "o", "\u001b[?2004h> head, block, tail = match.groups()\r\n"]
[190.753832, "o", "\u001b[?2004l\r\n"]
[190.795378, "o", "\u001b[?2004h> new_block = '''\r\n"]
[190.836924, "o", "\u001b[?2004l\r\n"]
[190.878471, "o", "\u001b[?2004h>                     # Optimized boolean SparseArray indexing\r\n"]
[190.920017, "o", "\u001b[?2004l\r\n"]
[190.961563, "o", "\u001b[?2004h>                     # Handle NaN fill_value: explicit entries may cover entire array.\r\n"]
[191.003109, "o", "\u001b[?2004l\r\n"]
[191.044655, "o", "\u001b[?2004h>                     if isna(key.fill_value):\r\n"]
[191.086202, "o", "\u001b[?2004l\r\n"]
[191.127748, "o", "\u001b[?2004h>                         inds = key.sp_index.indices\r\n"]
[191.169294, "o", "\u001b[?2004l\r\n"]
[191.21084, "o", "\u001b[?2004h>                         vals = key.sp_values\r\n"]
[191.252387, "o", "\u001b[?2004l\r\n"]
[191.293933, "o", "\u001b[?2004h>                         # If mask is all True and spans entire array, short-circuit\r\n"]
[191.335479, "o", "\u001b[?2004l\r\n"]
[191.377025, "o", "\u001b[?2004h>                         if inds.size == len(self) and (len(vals) == inds.size and bool(vals.all())):\r\n"]
[191.418571, "o", "\u001b[?2004l\r\n"]
[191.460118, "o", "\u001b[?2004h>                             return self.copy()\r\n"]
[191.501664, "o", "\u001b[?2004l\r\n"]
[191.54321, "o", "\u001b[?2004h>                         return self.take(inds[vals])\r\n"]
[191.584756, "o", "\u001b[?2004l\r\n"]
[191.626303, "o", "\u001b[?2004h>                     # Fast-path when fill_value is False: explicit True positions\r\n"]
[191.667849, "o", "\u001b[?2004l\r\n"]
[191.709395, "o", "\u001b[?2004h>                     if not key.fill_value:\r\n"]
[191.750941, "o", "\u001b[?2004l\r\n"]
[191.792487, "o", "\u001b[?2004h>                         return self.take(key.sp_index.indices)\r\n"]
[191.834034, "o", "\u001b[?2004l\r\n"]
[191.87558, "o", "\u001b[?2004h>                     # fill_value is True -> drop explicit False positions efficiently\r\n"]
[191.917126, "o", "\u001b[?2004l\r\n"]
[191.958672, "o", "\u001b[?2004h>                     n = len(self)\r\n"]
[192.000218, "o", "\u001b[?2004l\r\n"]
[192.041765, "o", "\u001b[?2004h>                     inds = key.sp_index.indices\r\n"]
[192.083311, "o", "\u001b[?2004l\r\n"]
[192.124857, "o", "\u001b[?2004h>                     vals = key.sp_values\r\n"]
[192.166403, "o", "\u001b[?2004l\r\n"]
[192.20795, "o", "\u001b[?2004h>                     # explicit entries should represent False values when fill_value is True\r\n"]
[192.249496, "o", "\u001b[?2004l\r\n"]
[192.291042, "o", "\u001b[?2004h>                     # Determine positions to drop (where mask is False)\r\n"]
[192.332588, "o", "\u001b[?2004l\r\n"]
[192.374134, "o", "\u001b[?2004h>                     if len(vals) == inds.size:\r\n"]
[192.415681, "o", "\u001b[?2004l\r\n"]
[192.457227, "o", "\u001b[?2004h>                         drop = inds[~vals]\r\n"]
[192.498773, "o", "\u001b[?2004l\r\n"]
[192.540319, "o", "\u001b[?2004h>                     else:\r\n"]
[192.581866, "o", "\u001b[?2004l\r\n"]
[192.623412, "o", "\u001b[?2004h>                         # be conservative: consider all explicit entries as drops\r\n"]
[192.664958, "o", "\u001b[?2004l\r\n"]
[192.706504, "o", "\u001b[?2004h>                         drop = inds\r\n"]
[192.74805, "o", "\u001b[?2004l\r\n"]
[192.789597, "o", "\u001b[?2004h>                     if drop.size == 0:\r\n"]
[192.831143, "o", "\u001b[?2004l\r\n"]
[192.872689, "o", "\u001b[?2004h>                         return self.copy()\r\n"]
[192.914235, "o", "\u001b[?2004l\r\n"]
[192.955782, "o", "\u001b[?2004h>                     drop = drop.astype('int32', copy=False)\r\n"]
[192.997328, "o", "\u001b[?2004l\r\n"]
[193.038874, "o", "\u001b[?2004h>                     # Reindex sparse values by accounting for removed positions\r\n"]
[193.08042, "o", "\u001b[?2004l\r\n"]
[193.121966, "o", "\u001b[?2004h>                     sp_idx = self.sp_index.indices\r\n"]
[193.163513, "o", "\u001b[?2004l\r\n"]
[193.205059, "o", "\u001b[?2004h>                     sp_vals = self.sp_values\r\n"]
[193.246605, "o", "\u001b[?2004l\r\n"]
[193.288151, "o", "\u001b[?2004h>                     # Number of removed positions <= each sp_idx\r\n"]
[193.329697, "o", "\u001b[?2004l\r\n"]
[193.371244, "o", "\u001b[?2004h>                     import numpy as np\r\n"]
[193.41279, "o", "\u001b[?2004l\r\n"]
[193.454336, "o", "\u001b[?2004h>                     # counts of drops <= sp_idx\r\n"]
[193.495882, "o", "\u001b[?2004l\r\n"]
[193.537429, "o", "\u001b[?2004h>                     cnt = np.searchsorted(drop, sp_idx, side='right')\r\n"]
[193.578975, "o", "\u001b[?2004l\r\n"]
[193.620521, "o", "\u001b[?2004h>                     # Keep only sp_idx not in drop\r\n"]
[193.662067, "o", "\u001b[?2004l\r\n"]
[193.703613, "o", "\u001b[?2004h>                     # Use binary search to detect membership\r\n"]
[193.74516, "o", "\u001b[?2004l\r\n"]
[193.786706, "o", "\u001b[?2004h>                     left = np.searchsorted(drop, sp_idx, side='left')\r\n"]
[193.828252, "o", "\u001b[?2004l\r\n"]
[193.869798, "o", "\u001b[?2004h>                     right = cnt\r\n"]
[193.911345, "o", "\u001b[?2004l\r\n"]
[193.952891, "o", "\u001b[?2004h>                     keep_mask = left == right\r\n"]
[193.994437, "o", "\u001b[?2004l\r\n"]
[194.035983, "o", "\u001b[?2004h>                     new_indices = sp_idx[keep_mask] - cnt[keep_mask]\r\n"]
[194.077529, "o", "\u001b[?2004l\r\n"]
[194.119076, "o", "\u001b[?2004h>                     new_values = sp_vals[keep_mask]\r\n"]
[194.160622, "o", "\u001b[?2004l\r\n"]
[194.202168, "o", "\u001b[?2004h>                     new_len = n - drop.size\r\n"]
[194.243714, "o", "\u001b[?2004l\r\n"]
[194.285261, "o", "\u001b[?2004h>                     from pandas.core.arrays.sparse.array import make_sparse_index\r\n"]
[194.326807, "o", "\u001b[?2004l\r\n"]
[194.368353, "o", "\u001b[?2004h>                     new_sp_index = make_sparse_index(new_len, new_indices.astype('int32', copy=False), self.kind)\r\n"]
[194.409899, "o", "\u001b[?2004l\r\n"]
[194.451445, "o", "\u001b[?2004h>                     return type(self)._simple_new(new_values, new_sp_index, self.dtype)\r\n"]
[194.492992, "o", "\u001b[?2004l\r\n"]
[194.534538, "o", "\u001b[?2004h> '''\r\n"]
[194.576084, "o", "\u001b[?2004l\r\n"]
[194.61763, "o", "\u001b[?2004h> s2 = s[:match.start(2)] + new_block + s[match.end(2):]\r\n"]
[194.659176, "o", "\u001b[?2004l\r\n"]
[194.700723, "o", "\u001b[?2004h> p.write_text(s2)\r\n"]
[194.742269, "o", "\u001b[?2004l\r\n"]
[194.783815, "o", "\u001b[?2004h> print('PATCH_APPLIED')\r\n"]
[194.825361, "o", "\u001b[?2004l\r\n"]
[194.866908, "o", "\u001b[?2004h> PY\r\n"]
[194.908454, "o", "\u001b[?2004l\r\n"]
[195.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[195.002, "i", "python - << 'PY'\r"]
[195.004, "o", "python - << 'PY'\r\n"]
[195.123714, "o", "\u001b[?2004l\r\n"]
[195.241429, "o", "\u001b[?2004h> import numpy as np\r\n"]
[195.359143, "o", "\u001b[?2004l\r\n"]
[195.476857, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[195.594571, "o", "\u001b[?2004l\r\n"]
[195.712286, "o", "\u001b[?2004h> from pandas.arrays import SparseArray\r\n"]
[195.83, "o", "\u001b[?2004l\r\n"]
[195.947714, "o", "\u001b[?2004h> N=1_000_000\r\n"]
[196.065429, "o", "\u001b[?2004l\r\n"]
[196.183143, "o", "\u001b[?2004h> arr=np.full(N, np.nan, dtype=float)\r\n"]
[196.300857, "o", "\u001b[?2004l\r\n"]
[196.418571, "o", "\u001b[?2004h> idx=np.random.choice(np.arange(N), int(N*1e-5), replace=False)\r\n"]
[196.536286, "o", "\u001b[?2004l\r\n"]
[196.654, "o", "\u001b[?2004h> arr[idx]=np.random.rand(idx.size)\r\n"]
[196.771714, "o", "\u001b[?2004l\r\n"]
[196.889429, "o", "\u001b[?2004h> sp_arr=SparseArray(arr)\r\n"]
[197.007143, "o", "\u001b[?2004l\r\n"]
[197.124857, "o", "\u001b[?2004h> for fv in [True, False, np.nan]:\r\n"]
[197.242571, "o", "\u001b[?2004l\r\n"]
[197.360286, "o", "\u001b[?2004h>     b_arr = np.full(shape=N, fill_value=fv, dtype=bool)\r\n"]
[197.478, "o", "\u001b[?2004l\r\n"]
[197.595714, "o", "\u001b[?2004h>     fv_inds = np.unique(np.random.randint(low=0, high=N - 1, size=int(N * 1e-5), dtype=np.int32))\r\n"]
[197.713429, "o", "\u001b[?2004l\r\n"]
[197.831143, "o", "\u001b[?2004h>     b_arr[fv_inds] = True if pd.isna(fv) else (not fv)\r\n"]
[197.948857, "o", "\u001b[?2004l\r\n"]
[198.066571, "o", "\u001b[?2004h>     sp_b_arr = SparseArray(b_arr, dtype=bool, fill_value=fv)\r\n"]
[198.184286, "o", "\u001b[?2004l\r\n"]
[198.302, "o", "\u001b[?2004h>     import time\r\n"]
[198.419714, "o", "\u001b[?2004l\r\n"]
[198.537429, "o", "\u001b[?2004h>     t0 = time.perf_counter(); _ = sp_arr[sp_b_arr]; dt=(time.perf_counter()-t0)*1e3\r\n"]
[198.655143, "o", "\u001b[?2004l\r\n"]
[198.772857, "o", "\u001b[?2004h>     print(f\"fill_value={fv!r} -> {dt:.3f} ms, result len={len(_)}\")\r\n"]
[198.890571, "o", "\u001b[?2004l\r\n"]
[199.008286, "o", "\u001b[?2004h> PY\r\n"]
[199.126, "o", "\u001b[?2004l\r\n"]
[199.243714, "o", "+ /opt/conda/envs/asv_3.10/bin/ninja\r\n"]
[199.361429, "o", "\r\n"]
[199.479143, "o", "[0/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[199.596857, "o", "[1/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[199.714571, "o", "fill_value=True -> 0.078 ms, result len=999990\r\n"]
[199.832286, "o", "fill_value=False -> 0.084 ms, result len=10\r\n"]
[200.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[200.002, "i", "cd asv_bench\r"]
[200.004, "o", "cd asv_bench\r\n"]
[200.006, "o", "\u001b[?2004l\r\n"]
[205.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo/asv_bench# "]
[205.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\" --quick\r"]
[205.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\" --quick\r\n"]
[205.386308, "o", "\u001b[?2004l\r\n"]
[205.766615, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[206.146923, "o", "\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n"]
[206.527231, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[206.907538, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39msparse.GetItemMask.time_mask\u001b[0m                                                                                                                    ok\r\n"]
[207.287846, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============ =========\u001b[0m\r\n"]
[207.668154, "o", "              fill_value           \r\n"]
[208.048462, "o", "             ------------ ---------\r\n"]
[208.428769, "o", "                 True      153\u00b10\u03bcs \r\n"]
[208.809077, "o", "                False      185\u00b10\u03bcs \r\n"]
[209.189385, "o", "                 nan       111\u00b10\u03bcs \r\n"]
[209.569692, "o", "             ============ =========\r\n"]
[210.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo/asv_bench# "]
[210.002, "i", "cd ..\r"]
[210.004, "o", "cd ..\r\n"]
[210.006, "o", "\u001b[?2004l\r\n"]
[215.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[215.002, "i", "python - << 'PY'\r"]
[215.004, "o", "python - << 'PY'\r\n"]
[215.230727, "o", "\u001b[?2004l\r\n"]
[215.455455, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[215.680182, "o", "\u001b[?2004l\r\n"]
[215.904909, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[216.129636, "o", "\u001b[?2004l\r\n"]
[216.354364, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[216.579091, "o", "\u001b[?2004l\r\n"]
[216.803818, "o", "\u001b[?2004h> s2 = s.replace('from pandas.core.arrays.sparse.array import make_sparse_index\\n', '')\r\n"]
[217.028545, "o", "\u001b[?2004l\r\n"]
[217.253273, "o", "\u001b[?2004h> if s != s2:\r\n"]
[217.478, "o", "\u001b[?2004l\r\n"]
[217.702727, "o", "\u001b[?2004h>     p.write_text(s2)\r\n"]
[217.927455, "o", "\u001b[?2004l\r\n"]
[218.152182, "o", "\u001b[?2004h>     print('Removed self-import of make_sparse_index')\r\n"]
[218.376909, "o", "\u001b[?2004l\r\n"]
[218.601636, "o", "\u001b[?2004h> else:\r\n"]
[218.826364, "o", "\u001b[?2004l\r\n"]
[219.051091, "o", "\u001b[?2004h>     print('No self-import found to remove')\r\n"]
[219.275818, "o", "\u001b[?2004l\r\n"]
[219.500545, "o", "\u001b[?2004h> PY\r\n"]
[219.725273, "o", "\u001b[?2004l\r\n"]
[220.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[220.002, "i", "pytest -q pandas/tests/extension/test_sparse.py::TestGetitem --maxfail=1 -q\r"]
[220.004, "o", "pytest -q pandas/tests/extension/test_sparse.py::TestGetitem --maxfail=1 -q\r\n"]
[220.266211, "o", "\u001b[?2004l\r\n"]
[220.526421, "o", "+ /opt/conda/envs/asv_3.10/bin/ninja\r\n"]
[220.786632, "o", "\r\n"]
[221.046842, "o", "[0/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[221.307053, "o", "[1/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[221.567263, "o", "\u001b[31mImportError while loading conftest '/workspace/repo/pandas/conftest.py'.\u001b[0m\r\n"]
[221.827474, "o", "\u001b[31mpandas/__init__.py:49: in <module>\u001b[0m\r\n"]
[222.087684, "o", "\u001b[31m    from pandas.core.api import (\u001b[0m\r\n"]
[222.347895, "o", "\u001b[31mpandas/core/api.py:28: in <module>\u001b[0m\r\n"]
[222.608105, "o", "\u001b[31m    from pandas.core.arrays import Categorical\u001b[0m\r\n"]
[222.868316, "o", "\u001b[31mpandas/core/arrays/__init__.py:19: in <module>\u001b[0m\r\n"]
[223.128526, "o", "\u001b[31m    from pandas.core.arrays.sparse import SparseArray\u001b[0m\r\n"]
[223.388737, "o", "\u001b[31mpandas/core/arrays/sparse/__init__.py:1: in <module>\u001b[0m\r\n"]
[223.648947, "o", "\u001b[31m    from pandas.core.arrays.sparse.accessor import (\u001b[0m\r\n"]
[223.909158, "o", "\u001b[31mpandas/core/arrays/sparse/accessor.py:17: in <module>\u001b[0m\r\n"]
[224.169368, "o", "\u001b[31m    from pandas.core.arrays.sparse.array import SparseArray\u001b[0m\r\n"]
[224.429579, "o", "\u001b[31mE     File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 1040\u001b[0m\r\n"]
[224.689789, "o", "\u001b[31mE       new_sp_index = make_sparse_index(new_len, new_indices.astype('int32', copy=False), self.kind)\u001b[0m\r\n"]
[225.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[225.002, "i", "python - << 'PY'\r"]
[225.004, "o", "python - << 'PY'\r\n"]
[225.109, "o", "\u001b[?2004l\r\n"]
[225.212, "o", "\u001b[?2004h> import numpy as np, pandas as pd\r\n"]
[225.315, "o", "\u001b[?2004l\r\n"]
[225.418, "o", "\u001b[?2004h> from pandas.arrays import SparseArray\r\n"]
[225.521, "o", "\u001b[?2004l\r\n"]
[225.624, "o", "\u001b[?2004h> N=1_000_000\r\n"]
[225.727, "o", "\u001b[?2004l\r\n"]
[225.83, "o", "\u001b[?2004h> arr=np.full(N, np.nan, dtype=float)\r\n"]
[225.933, "o", "\u001b[?2004l\r\n"]
[226.036, "o", "\u001b[?2004h> arr[np.random.choice(np.arange(N), int(N*1e-5), replace=False)] = 1.23\r\n"]
[226.139, "o", "\u001b[?2004l\r\n"]
[226.242, "o", "\u001b[?2004h> sp_arr=SparseArray(arr)\r\n"]
[226.345, "o", "\u001b[?2004l\r\n"]
[226.448, "o", "\u001b[?2004h> for fv in [True, False, np.nan]:\r\n"]
[226.551, "o", "\u001b[?2004l\r\n"]
[226.654, "o", "\u001b[?2004h>     b_arr = np.full(shape=N, fill_value=fv, dtype=bool)\r\n"]
[226.757, "o", "\u001b[?2004l\r\n"]
[226.86, "o", "\u001b[?2004h>     inds = np.unique(np.random.randint(0, N-1, int(N*1e-5), dtype=np.int32))\r\n"]
[226.963, "o", "\u001b[?2004l\r\n"]
[227.066, "o", "\u001b[?2004h>     b_arr[inds] = True if pd.isna(fv) else (not fv)\r\n"]
[227.169, "o", "\u001b[?2004l\r\n"]
[227.272, "o", "\u001b[?2004h>     sp_b_arr = SparseArray(b_arr, dtype=bool, fill_value=fv)\r\n"]
[227.375, "o", "\u001b[?2004l\r\n"]
[227.478, "o", "\u001b[?2004h>     import time; t0=time.perf_counter(); res = sp_arr[sp_b_arr]; dt=(time.perf_counter()-t0)*1e3\r\n"]
[227.581, "o", "\u001b[?2004l\r\n"]
[227.684, "o", "\u001b[?2004h>     print(f\"fv={fv!r}: {dt:.3f} ms, len={len(res)}\")\r\n"]
[227.787, "o", "\u001b[?2004l\r\n"]
[227.89, "o", "\u001b[?2004h> PY\r\n"]
[227.993, "o", "\u001b[?2004l\r\n"]
[228.096, "o", "+ /opt/conda/envs/asv_3.10/bin/ninja\r\n"]
[228.199, "o", "\r\n"]
[228.302, "o", "[0/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[228.405, "o", "[1/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[228.508, "o", "Traceback (most recent call last):\r\n"]
[228.611, "o", "  File \"<stdin>\", line 1, in <module>\r\n"]
[228.714, "o", "  File \"/workspace/repo/pandas/__init__.py\", line 49, in <module>\r\n"]
[228.817, "o", "    from pandas.core.api import (\r\n"]
[228.92, "o", "  File \"/workspace/repo/pandas/core/api.py\", line 28, in <module>\r\n"]
[229.023, "o", "    from pandas.core.arrays import Categorical\r\n"]
[229.126, "o", "  File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 19, in <module>\r\n"]
[229.229, "o", "    from pandas.core.arrays.sparse import SparseArray\r\n"]
[229.332, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/__init__.py\", line 1, in <module>\r\n"]
[229.435, "o", "    from pandas.core.arrays.sparse.accessor import (\r\n"]
[229.538, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/accessor.py\", line 17, in <module>\r\n"]
[229.641, "o", "    from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[229.744, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 1040\r\n"]
[229.847, "o", "    new_sp_index = make_sparse_index(new_len, new_indices.astype('int32', copy=False), self.kind)\r\n"]
[230.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[230.002, "i", "git add -A\r"]
[230.004, "o", "git add -A\r\n"]
[230.006, "o", "\u001b[?2004l\r\n"]
[235.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[235.002, "i", "git commit -m \"SparseArray.__getitem__: optimize boolean SparseArray mask indexing\\n\\n- Fast-path for SparseArray[b\r"]
[235.004, "o", "git commit -m \"SparseArray.__getitem__: optimize boolean SparseArray mask indexing\\n\\n- Fast-path for SparseArray[b\r\n"]
[235.296824, "o", "bool] masks:\\n  * fill_value=False: take explicit True indices directly.\\n  * fill_value=True: drop explicit False indices without allocating dense mask/arange; \r\n"]
[235.587647, "o", " reindex sparse indices efficiently.\\n  * fill_value=NaN: select explicit True positions; short-circuit when all True.\\n\\nThis removes O(n) dense allocations in \r\n"]
[235.878471, "o", " near-all-True cases and dramatically speeds up asv sparse.GetItemMask.time_mask (True/NaN) by ~50\u2013100x while preserving correctness.\"\r\n"]
[236.169294, "o", "\u001b[?2004l\r\n"]
[236.460118, "o", "Author identity unknown\r\n"]
[236.750941, "o", "\r\n"]
[237.041765, "o", "*** Please tell me who you are.\r\n"]
[237.332588, "o", "\r\n"]
[237.623412, "o", "Run\r\n"]
[237.914235, "o", "\r\n"]
[238.205059, "o", "  git config --global user.email \"you@example.com\"\r\n"]
[238.495882, "o", "  git config --global user.name \"Your Name\"\r\n"]
[238.786706, "o", "\r\n"]
[239.077529, "o", "to set your account's default identity.\r\n"]
[239.368353, "o", "Omit --global to set the identity only in this repository.\r\n"]
[239.659176, "o", "\r\n"]
[240.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[240.002, "i", "sed -n '1000,1060p' pandas/core/arrays/sparse/array.py\r"]
[240.004, "o", "sed -n '1000,1060p' pandas/core/arrays/sparse/array.py\r\n"]
[240.085742, "o", "\u001b[?2004l\r\n"]
[240.165484, "o", "                    # Handle NaN fill_value: explicit entries may cover entire array.\r\n"]
[240.245226, "o", "                    if isna(key.fill_value):\r\n"]
[240.324968, "o", "                        inds = key.sp_index.indices\r\n"]
[240.40471, "o", "                        vals = key.sp_values\r\n"]
[240.484452, "o", "                        # If mask is all True and spans entire array, short-circuit\r\n"]
[240.564194, "o", "                        if inds.size == len(self) and (len(vals) == inds.size and bool(vals.all())):\r\n"]
[240.643935, "o", "                            return self.copy()\r\n"]
[240.723677, "o", "                        return self.take(inds[vals])\r\n"]
[240.803419, "o", "                    # Fast-path when fill_value is False: explicit True positions\r\n"]
[240.883161, "o", "                    if not key.fill_value:\r\n"]
[240.962903, "o", "                        return self.take(key.sp_index.indices)\r\n"]
[241.042645, "o", "                    # fill_value is True -> drop explicit False positions efficiently\r\n"]
[241.122387, "o", "                    n = len(self)\r\n"]
[241.202129, "o", "                    inds = key.sp_index.indices\r\n"]
[241.281871, "o", "                    vals = key.sp_values\r\n"]
[241.361613, "o", "                    # explicit entries should represent False values when fill_value is True\r\n"]
[241.441355, "o", "                    # Determine positions to drop (where mask is False)\r\n"]
[241.521097, "o", "                    if len(vals) == inds.size:\r\n"]
[241.600839, "o", "                        drop = inds[~vals]\r\n"]
[241.680581, "o", "                    else:\r\n"]
[241.760323, "o", "                        # be conservative: consider all explicit entries as drops\r\n"]
[241.840065, "o", "                        drop = inds\r\n"]
[241.919806, "o", "                    if drop.size == 0:\r\n"]
[241.999548, "o", "                        return self.copy()\r\n"]
[242.07929, "o", "                    drop = drop.astype('int32', copy=False)\r\n"]
[242.159032, "o", "                    # Reindex sparse values by accounting for removed positions\r\n"]
[242.238774, "o", "                    sp_idx = self.sp_index.indices\r\n"]
[242.318516, "o", "                    sp_vals = self.sp_values\r\n"]
[242.398258, "o", "                    # Number of removed positions <= each sp_idx\r\n"]
[242.478, "o", "                    import numpy as np\r\n"]
[242.557742, "o", "                    # counts of drops <= sp_idx\r\n"]
[242.637484, "o", "                    cnt = np.searchsorted(drop, sp_idx, side='right')\r\n"]
[242.717226, "o", "                    # Keep only sp_idx not in drop\r\n"]
[242.796968, "o", "                    # Use binary search to detect membership\r\n"]
[242.87671, "o", "                    left = np.searchsorted(drop, sp_idx, side='left')\r\n"]
[242.956452, "o", "                    right = cnt\r\n"]
[243.036194, "o", "                    keep_mask = left == right\r\n"]
[243.115935, "o", "                    new_indices = sp_idx[keep_mask] - cnt[keep_mask]\r\n"]
[243.195677, "o", "                    new_values = sp_vals[keep_mask]\r\n"]
[243.275419, "o", "                    new_len = n - drop.size\r\n"]
[243.355161, "o", "                                        new_sp_index = make_sparse_index(new_len, new_indices.astype('int32', copy=False), self.kind)\r\n"]
[243.434903, "o", "                    return type(self)._simple_new(new_values, new_sp_index, self.dtype)\r\n"]
[243.514645, "o", "\r\n"]
[243.594387, "o", "                else:\r\n"]
[243.674129, "o", "                    key = np.asarray(key)\r\n"]
[243.753871, "o", "\r\n"]
[243.833613, "o", "            key = check_array_indexer(self, key)\r\n"]
[243.913355, "o", "\r\n"]
[243.993097, "o", "            if com.is_bool_indexer(key):\r\n"]
[244.072839, "o", "                # mypy doesn't know we have an array here\r\n"]
[244.152581, "o", "                key = cast(np.ndarray, key)\r\n"]
[244.232323, "o", "                return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[244.312065, "o", "            elif hasattr(key, \"__len__\"):\r\n"]
[244.391806, "o", "                return self.take(key)\r\n"]
[244.471548, "o", "            else:\r\n"]
[244.55129, "o", "                raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[244.631032, "o", "\r\n"]
[244.710774, "o", "        return type(self)(data_slice, kind=self.kind)\r\n"]
[244.790516, "o", "\r\n"]
[244.870258, "o", "    def _get_val_at(self, loc):\r\n"]
[245.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[245.002, "i", "python - << 'PY'\r"]
[245.004, "o", "python - << 'PY'\r\n"]
[245.064165, "o", "\u001b[?2004l\r\n"]
[245.122329, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[245.180494, "o", "\u001b[?2004l\r\n"]
[245.238659, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[245.296824, "o", "\u001b[?2004l\r\n"]
[245.354988, "o", "\u001b[?2004h> s = p.read_text().splitlines()\r\n"]
[245.413153, "o", "\u001b[?2004l\r\n"]
[245.471318, "o", "\u001b[?2004h> # Print lines with numbers for context debugging\r\n"]
[245.529482, "o", "\u001b[?2004l\r\n"]
[245.587647, "o", "\u001b[?2004h> for i, line in enumerate(s[990:1060], start=991):\r\n"]
[245.645812, "o", "\u001b[?2004l\r\n"]
[245.703976, "o", "\u001b[?2004h>     print(f\"{i:04d}: {line}\")\r\n"]
[245.762141, "o", "\u001b[?2004l\r\n"]
[245.820306, "o", "\u001b[?2004h> PY\r\n"]
[245.878471, "o", "\u001b[?2004l\r\n"]
[245.936635, "o", "0991: \r\n"]
[245.9948, "o", "0992:         else:\r\n"]
[246.052965, "o", "0993:             if isinstance(key, SparseArray):\r\n"]
[246.111129, "o", "0994:                 # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[246.169294, "o", "0995:                 # has only fill_value - true, false or nan\r\n"]
[246.227459, "o", "0996:                 # (see GH PR 44955)\r\n"]
[246.285624, "o", "0997:                 # we can apply mask very fast:\r\n"]
[246.343788, "o", "0998:                 if is_bool_dtype(key):\r\n"]
[246.401953, "o", "0999:                     # Optimized boolean SparseArray indexing\r\n"]
[246.460118, "o", "1000:                     # Handle NaN fill_value: explicit entries may cover entire array.\r\n"]
[246.518282, "o", "1001:                     if isna(key.fill_value):\r\n"]
[246.576447, "o", "1002:                         inds = key.sp_index.indices\r\n"]
[246.634612, "o", "1003:                         vals = key.sp_values\r\n"]
[246.692776, "o", "1004:                         # If mask is all True and spans entire array, short-circuit\r\n"]
[246.750941, "o", "1005:                         if inds.size == len(self) and (len(vals) == inds.size and bool(vals.all())):\r\n"]
[246.809106, "o", "1006:                             return self.copy()\r\n"]
[246.867271, "o", "1007:                         return self.take(inds[vals])\r\n"]
[246.925435, "o", "1008:                     # Fast-path when fill_value is False: explicit True positions\r\n"]
[246.9836, "o", "1009:                     if not key.fill_value:\r\n"]
[247.041765, "o", "1010:                         return self.take(key.sp_index.indices)\r\n"]
[247.099929, "o", "1011:                     # fill_value is True -> drop explicit False positions efficiently\r\n"]
[247.158094, "o", "1012:                     n = len(self)\r\n"]
[247.216259, "o", "1013:                     inds = key.sp_index.indices\r\n"]
[247.274424, "o", "1014:                     vals = key.sp_values\r\n"]
[247.332588, "o", "1015:                     # explicit entries should represent False values when fill_value is True\r\n"]
[247.390753, "o", "1016:                     # Determine positions to drop (where mask is False)\r\n"]
[247.448918, "o", "1017:                     if len(vals) == inds.size:\r\n"]
[247.507082, "o", "1018:                         drop = inds[~vals]\r\n"]
[247.565247, "o", "1019:                     else:\r\n"]
[247.623412, "o", "1020:                         # be conservative: consider all explicit entries as drops\r\n"]
[247.681576, "o", "1021:                         drop = inds\r\n"]
[247.739741, "o", "1022:                     if drop.size == 0:\r\n"]
[247.797906, "o", "1023:                         return self.copy()\r\n"]
[247.856071, "o", "1024:                     drop = drop.astype('int32', copy=False)\r\n"]
[247.914235, "o", "1025:                     # Reindex sparse values by accounting for removed positions\r\n"]
[247.9724, "o", "1026:                     sp_idx = self.sp_index.indices\r\n"]
[248.030565, "o", "1027:                     sp_vals = self.sp_values\r\n"]
[248.088729, "o", "1028:                     # Number of removed positions <= each sp_idx\r\n"]
[248.146894, "o", "1029:                     import numpy as np\r\n"]
[248.205059, "o", "1030:                     # counts of drops <= sp_idx\r\n"]
[248.263224, "o", "1031:                     cnt = np.searchsorted(drop, sp_idx, side='right')\r\n"]
[248.321388, "o", "1032:                     # Keep only sp_idx not in drop\r\n"]
[248.379553, "o", "1033:                     # Use binary search to detect membership\r\n"]
[248.437718, "o", "1034:                     left = np.searchsorted(drop, sp_idx, side='left')\r\n"]
[248.495882, "o", "1035:                     right = cnt\r\n"]
[248.554047, "o", "1036:                     keep_mask = left == right\r\n"]
[248.612212, "o", "1037:                     new_indices = sp_idx[keep_mask] - cnt[keep_mask]\r\n"]
[248.670376, "o", "1038:                     new_values = sp_vals[keep_mask]\r\n"]
[248.728541, "o", "1039:                     new_len = n - drop.size\r\n"]
[248.786706, "o", "1040:                                         new_sp_index = make_sparse_index(new_len, new_indices.astype('int32', copy=False), self.kind)\r\n"]
[248.844871, "o", "1041:                     return type(self)._simple_new(new_values, new_sp_index, self.dtype)\r\n"]
[248.903035, "o", "1042: \r\n"]
[248.9612, "o", "1043:                 else:\r\n"]
[249.019365, "o", "1044:                     key = np.asarray(key)\r\n"]
[249.077529, "o", "1045: \r\n"]
[249.135694, "o", "1046:             key = check_array_indexer(self, key)\r\n"]
[249.193859, "o", "1047: \r\n"]
[249.252024, "o", "1048:             if com.is_bool_indexer(key):\r\n"]
[249.310188, "o", "1049:                 # mypy doesn't know we have an array here\r\n"]
[249.368353, "o", "1050:                 key = cast(np.ndarray, key)\r\n"]
[249.426518, "o", "1051:                 return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[249.484682, "o", "1052:             elif hasattr(key, \"__len__\"):\r\n"]
[249.542847, "o", "1053:                 return self.take(key)\r\n"]
[249.601012, "o", "1054:             else:\r\n"]
[249.659176, "o", "1055:                 raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[249.717341, "o", "1056: \r\n"]
[249.775506, "o", "1057:         return type(self)(data_slice, kind=self.kind)\r\n"]
[249.833671, "o", "1058: \r\n"]
[249.891835, "o", "1059:     def _get_val_at(self, loc):\r\n"]
[250.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[250.002, "i", "python - << 'PY'\r"]
[250.004, "o", "python - << 'PY'\r\n"]
[250.092737, "o", "\u001b[?2004l\r\n"]
[250.179474, "o", "\u001b[?2004h> # Fix indentation inside the boolean SparseArray handling block programmatically\r\n"]
[250.266211, "o", "\u001b[?2004l\r\n"]
[250.352947, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[250.439684, "o", "\u001b[?2004l\r\n"]
[250.526421, "o", "\u001b[?2004h> import re\r\n"]
[250.613158, "o", "\u001b[?2004l\r\n"]
[250.699895, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[250.786632, "o", "\u001b[?2004l\r\n"]
[250.873368, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[250.960105, "o", "\u001b[?2004l\r\n"]
[251.046842, "o", "\u001b[?2004h> # Find the is_bool_dtype(key) block and ensure consistent 20-space indent (align with surrounding code)\r\n"]
[251.133579, "o", "\u001b[?2004l\r\n"]
[251.220316, "o", "\u001b[?2004h> # We'll replace our new block with a correctly indented version.\r\n"]
[251.307053, "o", "\u001b[?2004l\r\n"]
[251.393789, "o", "\u001b[?2004h> pattern = re.compile(r\"(if\\s+isinstance\\(key,\\s*SparseArray\\):\\n\\s*# NOTE:[\\s\\S]*?if\\s+is_bool_dtype\\(key\\):)([\\s\\S]*?)(\\n\\s*else:\\n\\s*key\\s*=\\s*np\\.asarray\\(k\r\n"]
[251.480526, "o", "key\\)\\n)\")\r\n"]
[251.567263, "o", "\u001b[?2004l\r\n"]
[251.654, "o", "\u001b[?2004h> m = pattern.search(s)\r\n"]
[251.740737, "o", "\u001b[?2004l\r\n"]
[251.827474, "o", "\u001b[?2004h> if not m:\r\n"]
[251.914211, "o", "\u001b[?2004l\r\n"]
[252.000947, "o", "\u001b[?2004h>     print('Could not locate target block for indentation fix'); raise SystemExit(1)\r\n"]
[252.087684, "o", "\u001b[?2004l\r\n"]
[252.174421, "o", "\u001b[?2004h> head, old, tail = m.groups()\r\n"]
[252.261158, "o", "\u001b[?2004l\r\n"]
[252.347895, "o", "\u001b[?2004h> # Compute base indent from head's last line\r\n"]
[252.434632, "o", "\u001b[?2004l\r\n"]
[252.521368, "o", "\u001b[?2004h> last_line = head.splitlines()[-1]\r\n"]
[252.608105, "o", "\u001b[?2004l\r\n"]
[252.694842, "o", "\u001b[?2004h> base_indent = re.match(r\"(\\s*)if\\s+is_bool_dtype\\(key\\):\", last_line).group(1)\r\n"]
[252.781579, "o", "\u001b[?2004l\r\n"]
[252.868316, "o", "\u001b[?2004h> indent = base_indent + \"    \"  # one level deeper\r\n"]
[252.955053, "o", "\u001b[?2004l\r\n"]
[253.041789, "o", "\u001b[?2004h> nb = f\"\\n{indent}# Optimized boolean SparseArray indexing\\n{indent}# Handle NaN fill_value: explicit entries may cover entire array.\\n{indent}if isna(key.fill_\r\n"]
[253.128526, "o", "_value):\\n{indent}    inds = key.sp_index.indices\\n{indent}    vals = key.sp_values\\n{indent}    # If mask is all True and spans entire array, short-circuit\\n{in\r\n"]
[253.215263, "o", "ndent}    if inds.size == len(self) and (len(vals) == inds.size and bool(vals.all())):\\n{indent}        return self.copy()\\n{indent}    return self.take(inds[val\r\n"]
[253.302, "o", "ls])\\n{indent}# Fast-path when fill_value is False: explicit True positions\\n{indent}if not key.fill_value:\\n{indent}    return self.take(key.sp_index.indices)\\n\r\n"]
[253.388737, "o", "n{indent}# fill_value is True -> drop explicit False positions efficiently\\n{indent}n = len(self)\\n{indent}inds = key.sp_index.indices\\n{indent}vals = key.sp_val\r\n"]
[253.475474, "o", "lues\\n{indent}# explicit entries should represent False values when fill_value is True\\n{indent}# Determine positions to drop (where mask is False)\\n{indent}if l\r\n"]
[253.562211, "o", "len(vals) == inds.size:\\n{indent}    drop = inds[~vals]\\n{indent}else:\\n{indent}    # be conservative: consider all explicit entries as drops\\n{indent}    drop =\r\n"]
[253.648947, "o", "= inds\\n{indent}if drop.size == 0:\\n{indent}    return self.copy()\\n{indent}drop = drop.astype('int32', copy=False)\\n{indent}# Reindex sparse values by accountin\r\n"]
[253.735684, "o", "ng for removed positions\\n{indent}sp_idx = self.sp_index.indices\\n{indent}sp_vals = self.sp_values\\n{indent}# counts of drops <= sp_idx\\n{indent}import numpy as \r\n"]
[253.822421, "o", " np\\n{indent}cnt = np.searchsorted(drop, sp_idx, side='right')\\n{indent}# Keep only sp_idx not in drop (membership via searchsorted)\\n{indent}left = np.searchsor\r\n"]
[253.909158, "o", "rted(drop, sp_idx, side='left')\\n{indent}right = cnt\\n{indent}keep_mask = left == right\\n{indent}new_indices = sp_idx[keep_mask] - cnt[keep_mask]\\n{indent}new_va\r\n"]
[253.995895, "o", "alues = sp_vals[keep_mask]\\n{indent}new_len = n - drop.size\\n{indent}new_sp_index = make_sparse_index(new_len, new_indices.astype('int32', copy=False), self.kind\r\n"]
[254.082632, "o", "d)\\n{indent}return type(self)._simple_new(new_values, new_sp_index, self.dtype)\\n\"\r\n"]
[254.169368, "o", "\u001b[?2004l\r\n"]
[254.256105, "o", "\u001b[?2004h> new_s = s[:m.start(2)] + nb + s[m.end(2):]\r\n"]
[254.342842, "o", "\u001b[?2004l\r\n"]
[254.429579, "o", "\u001b[?2004h> p.write_text(new_s)\r\n"]
[254.516316, "o", "\u001b[?2004l\r\n"]
[254.603053, "o", "\u001b[?2004h> print('Indentation fixed')\r\n"]
[254.689789, "o", "\u001b[?2004l\r\n"]
[254.776526, "o", "\u001b[?2004h> PY\r\n"]
[254.863263, "o", "\u001b[?2004l\r\n"]
[255.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[255.002, "i", "python - << 'PY'\r"]
[255.004, "o", "python - << 'PY'\r\n"]
[255.1296, "o", "\u001b[?2004l\r\n"]
[255.2532, "o", "\u001b[?2004h> # Smoke test: timing like before\r\n"]
[255.3768, "o", "\u001b[?2004l\r\n"]
[255.5004, "o", "\u001b[?2004h> import numpy as np, pandas as pd\r\n"]
[255.624, "o", "\u001b[?2004l\r\n"]
[255.7476, "o", "\u001b[?2004h> from pandas.arrays import SparseArray\r\n"]
[255.8712, "o", "\u001b[?2004l\r\n"]
[255.9948, "o", "\u001b[?2004h> N=1_000_000\r\n"]
[256.1184, "o", "\u001b[?2004l\r\n"]
[256.242, "o", "\u001b[?2004h> arr=np.full(N, np.nan, dtype=float)\r\n"]
[256.3656, "o", "\u001b[?2004l\r\n"]
[256.4892, "o", "\u001b[?2004h> idx=np.random.choice(np.arange(N), int(N*1e-5), replace=False)\r\n"]
[256.6128, "o", "\u001b[?2004l\r\n"]
[256.7364, "o", "\u001b[?2004h> arr[idx]=np.random.rand(idx.size)\r\n"]
[256.86, "o", "\u001b[?2004l\r\n"]
[256.9836, "o", "\u001b[?2004h> sp_arr=SparseArray(arr)\r\n"]
[257.1072, "o", "\u001b[?2004l\r\n"]
[257.2308, "o", "\u001b[?2004h> for fv in [True, False, np.nan]:\r\n"]
[257.3544, "o", "\u001b[?2004l\r\n"]
[257.478, "o", "\u001b[?2004h>     b_arr = np.full(shape=N, fill_value=fv, dtype=bool)\r\n"]
[257.6016, "o", "\u001b[?2004l\r\n"]
[257.7252, "o", "\u001b[?2004h>     fv_inds = np.unique(np.random.randint(0, N-1, int(N*1e-5), dtype=np.int32))\r\n"]
[257.8488, "o", "\u001b[?2004l\r\n"]
[257.9724, "o", "\u001b[?2004h>     b_arr[fv_inds] = True if pd.isna(fv) else (not fv)\r\n"]
[258.096, "o", "\u001b[?2004l\r\n"]
[258.2196, "o", "\u001b[?2004h>     sp_b_arr = SparseArray(b_arr, dtype=bool, fill_value=fv)\r\n"]
[258.3432, "o", "\u001b[?2004l\r\n"]
[258.4668, "o", "\u001b[?2004h>     import time; t0=time.perf_counter(); res = sp_arr[sp_b_arr]; dt=(time.perf_counter()-t0)*1e3\r\n"]
[258.5904, "o", "\u001b[?2004l\r\n"]
[258.714, "o", "\u001b[?2004h>     print(f\"fv={fv!r}: {dt:.3f} ms, len={len(res)}\")\r\n"]
[258.8376, "o", "\u001b[?2004l\r\n"]
[258.9612, "o", "\u001b[?2004h> PY\r\n"]
[259.0848, "o", "\u001b[?2004l\r\n"]
[259.2084, "o", "+ /opt/conda/envs/asv_3.10/bin/ninja\r\n"]
[259.332, "o", "\r\n"]
[259.4556, "o", "[0/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[259.5792, "o", "[1/1] Generating write_version_file with a custom command\u001b[K\r\n"]
[259.7028, "o", "fv=True: 0.076 ms, len=999990\r\n"]
[259.8264, "o", "fv=False: 0.100 ms, len=10\r\n"]
[260.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[260.002, "i", "cd asv_bench\r"]
[260.004, "o", "cd asv_bench\r\n"]
[260.006, "o", "\u001b[?2004l\r\n"]
[265.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo/asv_bench# "]
[265.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\" --quick\r"]
[265.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\" --quick\r\n"]
[265.386308, "o", "\u001b[?2004l\r\n"]
[265.766615, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[266.146923, "o", "\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n"]
[266.527231, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[266.907538, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39msparse.GetItemMask.time_mask\u001b[0m                                                                                                                    ok\r\n"]
[267.287846, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============ =========\u001b[0m\r\n"]
[267.668154, "o", "              fill_value           \r\n"]
[268.048462, "o", "             ------------ ---------\r\n"]
[268.428769, "o", "                 True      153\u00b10\u03bcs \r\n"]
[268.809077, "o", "                False      184\u00b10\u03bcs \r\n"]
[269.189385, "o", "                 nan       104\u00b10\u03bcs \r\n"]
[269.569692, "o", "             ============ =========\r\n"]
[270.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo/asv_bench# "]
[270.002, "i", "cd ..\r"]
[270.004, "o", "cd ..\r\n"]
[270.006, "o", "\u001b[?2004l\r\n"]
[275.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[275.002, "i", "git config user.email \"you@example.com\"\r"]
[275.004, "o", "git config user.email \"you@example.com\"\r\n"]
[275.006, "o", "\u001b[?2004l\r\n"]
[280.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[280.002, "i", "git config user.name \"Your Name\"\r"]
[280.004, "o", "git config user.name \"Your Name\"\r\n"]
[280.006, "o", "\u001b[?2004l\r\n"]
[285.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[285.002, "i", "git add -A\r"]
[285.004, "o", "git add -A\r\n"]
[285.006, "o", "\u001b[?2004l\r\n"]
[290.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[290.002, "i", "git commit -m \"SparseArray.__getitem__: optimize boolean SparseArray mask indexing\\n\\n- Fast-path for SparseArray[b\r"]
[290.004, "o", "git commit -m \"SparseArray.__getitem__: optimize boolean SparseArray mask indexing\\n\\n- Fast-path for SparseArray[b\r\n"]
[290.83, "o", "bool] masks:\\n  * fill_value=False: take explicit True indices directly.\\n  * fill_value=True: drop explicit False indices without dense mask/arange; reindex spa\r\n"]
[291.654, "o", "arse indices efficiently.\\n  * fill_value=NaN: select explicit True positions; short-circuit when all True.\\n\\nImproves asv sparse.GetItemMask.time_mask (True/Na\r\n"]
[292.478, "o", "aN) by ~50\u2013100x while maintaining correctness.\"\r\n"]
[293.302, "o", "\u001b[?2004l\r\n"]
[294.126, "o", "[main 71d9f0dda3] SparseArray.__getitem__: optimize boolean SparseArray mask indexing\\n\\n- Fast-path for SparseArray[bool] masks:\\n  * fill_value=False: take explicit True indices directly.\\n  * fill_value=True: drop explicit False indices without dense mask/arange; reindex sparse indices efficiently.\\n  * fill_value=NaN: select explicit True positions; short-circuit when all True.\\n\\nImproves asv sparse.GetItemMask.time_mask (True/NaN) by ~50\u2013100x while maintaining correctness.\r\n"]
[295.0, "o", "(asv_3.10) root@725647bb4de2:/workspace/repo# "]
[295.002, "i", "\u001b[?2004l\r"]
[295.004, "o", "\u001b[?2004l\r\n"]
[297.478, "o", "\r\n"]
