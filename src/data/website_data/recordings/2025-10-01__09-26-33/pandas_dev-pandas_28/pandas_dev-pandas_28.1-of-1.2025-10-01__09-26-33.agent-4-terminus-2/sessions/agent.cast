{"version": 2, "width": 160, "height": 40, "timestamp": 1762995167, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[1.242, "o", "\u001b[?2004l\r\n"]
[2.478, "o", "\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n"]
[3.714, "o", "\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[7.478, "o", "\u001b[?2004l\r\n"]
[10.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.139622, "o", "\u001b[?2004l\r\n"]
[10.273243, "o", "total 212\r\n"]
[10.406865, "o", "drwxr-xr-x 1 root root  4096 Oct  1 17:58 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[10.540486, "o", "drwxr-xr-x 1 root root  4096 Sep 15 17:16 \u001b[01;34m..\u001b[0m\r\n"]
[10.674108, "o", "drwxr-xr-x 2 root root  4096 Sep 12 22:25 \u001b[01;34m.circleci\u001b[0m\r\n"]
[10.80773, "o", "-rw-r--r-- 1 root root  1021 Sep 12 22:25 .devcontainer.json\r\n"]
[10.941351, "o", "drwxr-xr-x 1 root root  4096 Oct  1 17:58 \u001b[01;34m.git\u001b[0m\r\n"]
[11.074973, "o", "-rw-r--r-- 1 root root   229 Sep 12 22:25 .gitattributes\r\n"]
[11.208595, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34m.github\u001b[0m\r\n"]
[11.342216, "o", "-rw-r--r-- 1 root root  1765 Sep 12 22:25 .gitignore\r\n"]
[11.475838, "o", "-rw-r--r-- 1 root root  2322 Sep 12 22:25 .gitpod.yml\r\n"]
[11.609459, "o", "-rw-r--r-- 1 root root   761 Sep 12 22:25 .libcst.codemod.yaml\r\n"]
[11.743081, "o", "-rw-r--r-- 1 root root 15546 Sep 12 22:25 .pre-commit-config.yaml\r\n"]
[11.876703, "o", "-rw-r--r-- 1 root root  2284 Sep 12 22:25 AUTHORS.md\r\n"]
[12.010324, "o", "-rw-r--r-- 1 root root   372 Sep 12 22:25 CITATION.cff\r\n"]
[12.143946, "o", "-rw-r--r-- 1 root root   369 Sep 12 22:25 Dockerfile\r\n"]
[12.277568, "o", "-rw-r--r-- 1 root root  1634 Sep 12 22:25 LICENSE\r\n"]
[12.411189, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mLICENSES\u001b[0m\r\n"]
[12.544811, "o", "-rw-r--r-- 1 root root  1294 Sep 12 22:25 MANIFEST.in\r\n"]
[12.678432, "o", "-rw-r--r-- 1 root root 10387 Sep 12 22:25 README.md\r\n"]
[12.812054, "o", "-rw-r--r-- 1 root root   246 Sep 12 22:25 RELEASE.md\r\n"]
[12.945676, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34masv_bench\u001b[0m\r\n"]
[13.079297, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mci\u001b[0m\r\n"]
[13.212919, "o", "-rw-r--r-- 1 root root   256 Sep 12 22:25 codecov.yml\r\n"]
[13.346541, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mdoc\u001b[0m\r\n"]
[13.480162, "o", "-rw-r--r-- 1 root root  2405 Sep 12 22:25 environment.yml\r\n"]
[13.613784, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mgitpod\u001b[0m\r\n"]
[13.747405, "o", "drwxr-xr-x 1 root root  4096 Sep 13 21:58 \u001b[01;34mpandas\u001b[0m\r\n"]
[13.881027, "o", "drwxr-xr-x 2 root root  4096 Sep 13 21:43 \u001b[01;34mpandas.egg-info\u001b[0m\r\n"]
[14.014649, "o", "-rw-r--r-- 1 root root 17415 Sep 12 22:25 pyproject.toml\r\n"]
[14.14827, "o", "-rw-r--r-- 1 root root  4429 Sep 12 22:25 pyright_reportGeneralTypeIssues.json\r\n"]
[14.281892, "o", "-rw-r--r-- 1 root root  1355 Sep 12 22:25 requirements-dev.txt\r\n"]
[14.415514, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mscripts\u001b[0m\r\n"]
[14.549135, "o", "-rw-r--r-- 1 root root   645 Sep 12 22:25 setup.cfg\r\n"]
[14.682757, "o", "-rwxr-xr-x 1 root root 22455 Sep 12 22:25 \u001b[01;32msetup.py\u001b[0m\r\n"]
[14.816378, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mtypings\u001b[0m\r\n"]
[15.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[15.002, "i", "git status -sb\r"]
[15.004, "o", "git status -sb\r\n"]
[17.478, "o", "\u001b[?2004l\r\n"]
[20.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[20.002, "i", "grep -RIl \"asv.conf.json\" . || true\r"]
[20.004, "o", "grep -RIl \"asv.conf.json\" . || true\r\n"]
[20.9948, "o", "\u001b[?2004l\r\n"]
[21.9836, "o", "\u001b[35m\u001b[K./scripts/tests/data/deps_minimum.toml\u001b[m\u001b[K\r\n"]
[22.9724, "o", "\u001b[35m\u001b[K./pyproject.toml\u001b[m\u001b[K\r\n"]
[23.9612, "o", "\u001b[35m\u001b[K./setup.py\u001b[m\u001b[K\r\n"]
[25.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[25.002, "i", "ls -la | sed -n '1,200p'\r"]
[25.004, "o", "ls -la | sed -n '1,200p'\r\n"]
[25.139622, "o", "\u001b[?2004l\r\n"]
[25.273243, "o", "total 212\r\n"]
[25.406865, "o", "drwxr-xr-x 1 root root  4096 Oct  1 17:58 .\r\n"]
[25.540486, "o", "drwxr-xr-x 1 root root  4096 Sep 15 17:16 ..\r\n"]
[25.674108, "o", "drwxr-xr-x 2 root root  4096 Sep 12 22:25 .circleci\r\n"]
[25.80773, "o", "-rw-r--r-- 1 root root  1021 Sep 12 22:25 .devcontainer.json\r\n"]
[25.941351, "o", "drwxr-xr-x 1 root root  4096 Oct  1 18:00 .git\r\n"]
[26.074973, "o", "-rw-r--r-- 1 root root   229 Sep 12 22:25 .gitattributes\r\n"]
[26.208595, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 .github\r\n"]
[26.342216, "o", "-rw-r--r-- 1 root root  1765 Sep 12 22:25 .gitignore\r\n"]
[26.475838, "o", "-rw-r--r-- 1 root root  2322 Sep 12 22:25 .gitpod.yml\r\n"]
[26.609459, "o", "-rw-r--r-- 1 root root   761 Sep 12 22:25 .libcst.codemod.yaml\r\n"]
[26.743081, "o", "-rw-r--r-- 1 root root 15546 Sep 12 22:25 .pre-commit-config.yaml\r\n"]
[26.876703, "o", "-rw-r--r-- 1 root root  2284 Sep 12 22:25 AUTHORS.md\r\n"]
[27.010324, "o", "-rw-r--r-- 1 root root   372 Sep 12 22:25 CITATION.cff\r\n"]
[27.143946, "o", "-rw-r--r-- 1 root root   369 Sep 12 22:25 Dockerfile\r\n"]
[27.277568, "o", "-rw-r--r-- 1 root root  1634 Sep 12 22:25 LICENSE\r\n"]
[27.411189, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 LICENSES\r\n"]
[27.544811, "o", "-rw-r--r-- 1 root root  1294 Sep 12 22:25 MANIFEST.in\r\n"]
[27.678432, "o", "-rw-r--r-- 1 root root 10387 Sep 12 22:25 README.md\r\n"]
[27.812054, "o", "-rw-r--r-- 1 root root   246 Sep 12 22:25 RELEASE.md\r\n"]
[27.945676, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 asv_bench\r\n"]
[28.079297, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 ci\r\n"]
[28.212919, "o", "-rw-r--r-- 1 root root   256 Sep 12 22:25 codecov.yml\r\n"]
[28.346541, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 doc\r\n"]
[28.480162, "o", "-rw-r--r-- 1 root root  2405 Sep 12 22:25 environment.yml\r\n"]
[28.613784, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 gitpod\r\n"]
[28.747405, "o", "drwxr-xr-x 1 root root  4096 Sep 13 21:58 pandas\r\n"]
[28.881027, "o", "drwxr-xr-x 2 root root  4096 Sep 13 21:43 pandas.egg-info\r\n"]
[29.014649, "o", "-rw-r--r-- 1 root root 17415 Sep 12 22:25 pyproject.toml\r\n"]
[29.14827, "o", "-rw-r--r-- 1 root root  4429 Sep 12 22:25 pyright_reportGeneralTypeIssues.json\r\n"]
[29.281892, "o", "-rw-r--r-- 1 root root  1355 Sep 12 22:25 requirements-dev.txt\r\n"]
[29.415514, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 scripts\r\n"]
[29.549135, "o", "-rw-r--r-- 1 root root   645 Sep 12 22:25 setup.cfg\r\n"]
[29.682757, "o", "-rwxr-xr-x 1 root root 22455 Sep 12 22:25 setup.py\r\n"]
[29.816378, "o", "drwxr-xr-x 1 root root  4096 Sep 12 22:25 typings\r\n"]
[30.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[30.002, "i", "test -f asv.conf.json && cat asv.conf.json | sed -n '1,200p' || true\r"]
[30.004, "o", "test -f asv.conf.json && cat asv.conf.json | sed -n '1,200p' || true\r\n"]
[30.006, "o", "\u001b[?2004l\r\n"]
[35.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[35.002, "i", "rg -n \"GetItemMask\" -S || true\r"]
[35.004, "o", "rg -n \"GetItemMask\" -S || true\r\n"]
[37.478, "o", "\u001b[?2004l\r\n"]
[40.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[40.002, "i", "rg -n \"sparse\\.GetItemMask\" -S asv* benchmarks* bench* || true\r"]
[40.004, "o", "rg -n \"sparse\\.GetItemMask\" -S asv* benchmarks* bench* || true\r\n"]
[42.478, "o", "\u001b[?2004l\r\n"]
[45.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[45.002, "i", "test -f asv_benchmarks.txt && cat asv_benchmarks.txt | sed -n '1,200p' || true\r"]
[45.004, "o", "test -f asv_benchmarks.txt && cat asv_benchmarks.txt | sed -n '1,200p' || true\r\n"]
[45.006, "o", "\u001b[?2004l\r\n"]
[50.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[50.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[50.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[52.478, "o", "\u001b[?2004l\r\n"]
[55.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[55.002, "i", "ls -la asv_bench\r"]
[55.004, "o", "ls -la asv_bench\r\n"]
[55.83, "o", "\u001b[?2004l\r\n"]
[56.654, "o", "total 24\r\n"]
[57.478, "o", "drwxr-xr-x 1 root root 4096 Sep 12 22:25 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[58.302, "o", "drwxr-xr-x 1 root root 4096 Oct  1 17:58 \u001b[01;34m..\u001b[0m\r\n"]
[59.126, "o", "-rw-r--r-- 1 root root 5217 Sep 12 22:25 asv.conf.json\r\n"]
[60.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[60.002, "i", "find asv_bench -maxdepth 2 -type f -name \"asv.conf.json\" -print -exec sed -n '1,200p' {} \\;\r"]
[60.004, "o", "find asv_bench -maxdepth 2 -type f -name \"asv.conf.json\" -print -exec sed -n '1,200p' {} \\;\r\n"]
[60.043173, "o", "\u001b[?2004l\r\n"]
[60.080346, "o", "asv_bench/asv.conf.json\r\n"]
[60.117519, "o", "{\r\n"]
[60.154692, "o", "    // The version of the config file format.  Do not change, unless\r\n"]
[60.191865, "o", "    // you know what you are doing.\r\n"]
[60.229038, "o", "    \"version\": 1,\r\n"]
[60.266211, "o", "\r\n"]
[60.303383, "o", "    // The name of the project being benchmarked\r\n"]
[60.340556, "o", "    \"project\": \"pandas\",\r\n"]
[60.377729, "o", "\r\n"]
[60.414902, "o", "    // The project's homepage\r\n"]
[60.452075, "o", "    \"project_url\": \"https://pandas.pydata.org/\",\r\n"]
[60.489248, "o", "\r\n"]
[60.526421, "o", "    // The URL of the source code repository for the project being\r\n"]
[60.563594, "o", "    // benchmarked\r\n"]
[60.600767, "o", "    \"repo\": \"..\",\r\n"]
[60.63794, "o", "\r\n"]
[60.675113, "o", "    // List of branches to benchmark. If not provided, defaults to \"master\"\r\n"]
[60.712286, "o", "    // (for git) or \"default\" (for mercurial).\r\n"]
[60.749459, "o", "    \"branches\": [\"main\"],\r\n"]
[60.786632, "o", "\r\n"]
[60.823805, "o", "    // The tool to use to create environments.  May be \"conda\",\r\n"]
[60.860977, "o", "    // \"virtualenv\" or other value depending on the plugins in use.\r\n"]
[60.89815, "o", "    // If missing or the empty string, the tool will be automatically\r\n"]
[60.935323, "o", "    // determined by looking for tools on the PATH environment\r\n"]
[60.972496, "o", "    // variable.\r\n"]
[61.009669, "o", "    \"environment_type\": \"conda\",\r\n"]
[61.046842, "o", "\r\n"]
[61.084015, "o", "    // the base URL to show a commit for the project.\r\n"]
[61.121188, "o", "    \"show_commit_url\": \"https://github.com/pandas-dev/pandas/commit/\",\r\n"]
[61.158361, "o", "\r\n"]
[61.195534, "o", "    // The Pythons you'd like to test against.  If not provided, defaults\r\n"]
[61.232707, "o", "    // to the current version of Python used to run `asv`.\r\n"]
[61.26988, "o", "    \"pythons\": [\"3.8\"],\r\n"]
[61.307053, "o", "\r\n"]
[61.344226, "o", "    // The matrix of dependencies to test.  Each key is the name of a\r\n"]
[61.381398, "o", "    // package (in PyPI) and the values are version numbers.  An empty\r\n"]
[61.418571, "o", "    // list or empty string indicates to just test against the default\r\n"]
[61.455744, "o", "    // (latest) version. null indicates that the package is to not be\r\n"]
[61.492917, "o", "    // installed. If the package to be tested is only available from\r\n"]
[61.53009, "o", "    // PyPi, and the 'environment_type' is conda, then you can preface\r\n"]
[61.567263, "o", "    // the package name by 'pip+', and the package will be installed via\r\n"]
[61.604436, "o", "    // pip (with all the conda available packages installed first,\r\n"]
[61.641609, "o", "    // followed by the pip installed packages).\r\n"]
[61.678782, "o", "    \"matrix\": {\r\n"]
[61.715955, "o", "        \"numpy\": [],\r\n"]
[61.753128, "o", "        \"Cython\": [\"0.29.33\"],\r\n"]
[61.790301, "o", "        \"matplotlib\": [],\r\n"]
[61.827474, "o", "        \"sqlalchemy\": [],\r\n"]
[61.864647, "o", "        \"scipy\": [],\r\n"]
[61.90182, "o", "        \"numba\": [],\r\n"]
[61.938992, "o", "        \"numexpr\": [],\r\n"]
[61.976165, "o", "        \"pytables\": [null, \"\"],  // platform dependent, see excludes below\r\n"]
[62.013338, "o", "        \"pyarrow\": [],\r\n"]
[62.050511, "o", "        \"tables\": [null, \"\"],\r\n"]
[62.087684, "o", "        \"openpyxl\": [],\r\n"]
[62.124857, "o", "        \"xlsxwriter\": [],\r\n"]
[62.16203, "o", "        \"xlrd\": [],\r\n"]
[62.199203, "o", "        \"odfpy\": [],\r\n"]
[62.236376, "o", "        \"jinja2\": [],\r\n"]
[62.273549, "o", "    },\r\n"]
[62.310722, "o", "    \"conda_channels\": [\"conda-forge\"],\r\n"]
[62.347895, "o", "    // Combinations of libraries/python versions can be excluded/included\r\n"]
[62.385068, "o", "    // from the set to test. Each entry is a dictionary containing additional\r\n"]
[62.422241, "o", "    // key-value pairs to include/exclude.\r\n"]
[62.459414, "o", "    //\r\n"]
[62.496586, "o", "    // An exclude entry excludes entries where all values match. The\r\n"]
[62.533759, "o", "    // values are regexps that should match the whole string.\r\n"]
[62.570932, "o", "    //\r\n"]
[62.608105, "o", "    // An include entry adds an environment. Only the packages listed\r\n"]
[62.645278, "o", "    // are installed. The 'python' key is required. The exclude rules\r\n"]
[62.682451, "o", "    // do not apply to includes.\r\n"]
[62.719624, "o", "    //\r\n"]
[62.756797, "o", "    // In addition to package names, the following keys are available:\r\n"]
[62.79397, "o", "    //\r\n"]
[62.831143, "o", "    // - python\r\n"]
[62.868316, "o", "    //     Python version, as in the *pythons* variable above.\r\n"]
[62.905489, "o", "    // - environment_type\r\n"]
[62.942662, "o", "    //     Environment type, as above.\r\n"]
[62.979835, "o", "    // - sys_platform\r\n"]
[63.017008, "o", "    //     Platform, as in sys.platform. Possible values for the common\r\n"]
[63.05418, "o", "    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.\r\n"]
[63.091353, "o", "    \"exclude\": [\r\n"]
[63.128526, "o", "        // On conda install pytables, otherwise tables\r\n"]
[63.165699, "o", "        {\"environment_type\": \"conda\", \"tables\": \"\"},\r\n"]
[63.202872, "o", "        {\"environment_type\": \"conda\", \"pytables\": null},\r\n"]
[63.240045, "o", "        {\"environment_type\": \"(?!conda).*\", \"tables\": null},\r\n"]
[63.277218, "o", "        {\"environment_type\": \"(?!conda).*\", \"pytables\": \"\"},\r\n"]
[63.314391, "o", "    ],\r\n"]
[63.351564, "o", "    \"include\": [],\r\n"]
[63.388737, "o", "\r\n"]
[63.42591, "o", "    // The directory (relative to the current directory) that benchmarks are\r\n"]
[63.463083, "o", "    // stored in.  If not provided, defaults to \"benchmarks\"\r\n"]
[63.500256, "o", "    // \"benchmark_dir\": \"benchmarks\",\r\n"]
[63.537429, "o", "\r\n"]
[63.574602, "o", "    // The directory (relative to the current directory) to cache the Python\r\n"]
[63.611774, "o", "    // environments in.  If not provided, defaults to \"env\"\r\n"]
[63.648947, "o", "    // \"env_dir\": \"env\",\r\n"]
[63.68612, "o", "\r\n"]
[63.723293, "o", "    // The directory (relative to the current directory) that raw benchmark\r\n"]
[63.760466, "o", "    // results are stored in.  If not provided, defaults to \"results\".\r\n"]
[63.797639, "o", "    // \"results_dir\": \"results\",\r\n"]
[63.834812, "o", "\r\n"]
[63.871985, "o", "    // The directory (relative to the current directory) that the html tree\r\n"]
[63.909158, "o", "    // should be written to.  If not provided, defaults to \"html\".\r\n"]
[63.946331, "o", "    // \"html_dir\": \"html\",\r\n"]
[63.983504, "o", "\r\n"]
[64.020677, "o", "    // The number of characters to retain in the commit hashes.\r\n"]
[64.05785, "o", "    // \"hash_length\": 8,\r\n"]
[64.095023, "o", "\r\n"]
[64.132195, "o", "    // `asv` will cache wheels of the recent builds in each\r\n"]
[64.169368, "o", "    // environment, making them faster to install next time.  This is\r\n"]
[64.206541, "o", "    // number of builds to keep, per environment.\r\n"]
[64.243714, "o", "    \"build_cache_size\": 8,\r\n"]
[64.280887, "o", "\r\n"]
[64.31806, "o", "    // The commits after which the regression search in `asv publish`\r\n"]
[64.355233, "o", "    // should start looking for regressions. Dictionary whose keys are\r\n"]
[64.392406, "o", "    // regexps matching to benchmark names, and values corresponding to\r\n"]
[64.429579, "o", "    // the commit (exclusive) after which to start looking for\r\n"]
[64.466752, "o", "    // regressions.  The default is to start from the first commit\r\n"]
[64.503925, "o", "    // with results. If the commit is `null`, regression detection is\r\n"]
[64.541098, "o", "    // skipped for the matching benchmark.\r\n"]
[64.578271, "o", "    //\r\n"]
[64.615444, "o", "    \"regressions_first_commits\": {\r\n"]
[64.652617, "o", "        \".*\": \"0409521665\"\r\n"]
[64.689789, "o", "    },\r\n"]
[64.726962, "o", "    \"regression_thresholds\": {\r\n"]
[64.764135, "o", "    },\r\n"]
[64.801308, "o", "    \"build_command\":\r\n"]
[64.838481, "o", "    [\"python -m pip install versioneer[toml]\",\r\n"]
[64.875654, "o", "     \"python setup.py build -j4\",\r\n"]
[64.912827, "o", "     \"PIP_NO_BUILD_ISOLATION=false python -mpip wheel --no-deps --no-index -w {build_cache_dir} {build_dir}\"],\r\n"]
[65.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[65.002, "i", "grep -RIn \"GetItemMask\" asv_bench || true\r"]
[65.004, "o", "grep -RIn \"GetItemMask\" asv_bench || true\r\n"]
[67.478, "o", "\u001b[?2004l\r\n"]
[70.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[70.002, "i", "grep -RIn \"sparse\" asv_bench/benchmarks | sed -n '1,200p'\r"]
[70.004, "o", "grep -RIn \"sparse\" asv_bench/benchmarks | sed -n '1,200p'\r\n"]
[70.266211, "o", "\u001b[?2004l\r\n"]
[70.526421, "o", "asv_bench/benchmarks/frame_ctor.py:167:        self.sparse_arrays = [\r\n"]
[70.786632, "o", "asv_bench/benchmarks/frame_ctor.py:194:    def time_frame_from_arrays_sparse(self):\r\n"]
[71.046842, "o", "asv_bench/benchmarks/frame_ctor.py:196:            self.sparse_arrays,\r\n"]
[71.307053, "o", "asv_bench/benchmarks/sparse.py:2:import scipy.sparse\r\n"]
[71.567263, "o", "asv_bench/benchmarks/sparse.py:45:    def time_sparse_array(self, dense_proportion, fill_value, dtype):\r\n"]
[71.827474, "o", "asv_bench/benchmarks/sparse.py:52:        self.sparse = scipy.sparse.rand(N, N, 0.005)\r\n"]
[72.087684, "o", "asv_bench/benchmarks/sparse.py:55:        pd.DataFrame.sparse.from_spmatrix(self.sparse)\r\n"]
[72.347895, "o", "asv_bench/benchmarks/sparse.py:60:        self.matrix = scipy.sparse.coo_matrix(\r\n"]
[72.608105, "o", "asv_bench/benchmarks/sparse.py:64:    def time_sparse_series_from_coo(self):\r\n"]
[72.868316, "o", "asv_bench/benchmarks/sparse.py:65:        Series.sparse.from_coo(self.matrix)\r\n"]
[73.128526, "o", "asv_bench/benchmarks/sparse.py:84:    def time_sparse_series_to_coo(self, sort_labels):\r\n"]
[73.388737, "o", "asv_bench/benchmarks/sparse.py:85:        self.ss_mult_lvl.sparse.to_coo(\r\n"]
[73.648947, "o", "asv_bench/benchmarks/sparse.py:89:    def time_sparse_series_to_coo_single_level(self, sort_labels):\r\n"]
[73.909158, "o", "asv_bench/benchmarks/sparse.py:90:        self.ss_two_lvl.sparse.to_coo(sort_labels=sort_labels)\r\n"]
[74.169368, "o", "asv_bench/benchmarks/sparse.py:104:        self.df.sparse.to_coo()\r\n"]
[74.429579, "o", "asv_bench/benchmarks/reshape.py:252:        pd.get_dummies(self.s, sparse=False)\r\n"]
[74.689789, "o", "asv_bench/benchmarks/reshape.py:254:    def time_get_dummies_1d_sparse(self):\r\n"]
[75.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[75.002, "i", "asv run --config asv_bench/asv.conf.json --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[75.004, "o", "asv run --config asv_bench/asv.conf.json --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[77.478, "o", "\u001b[?2004l\r\n"]
[80.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[80.002, "i", "sed -n '1,260p' asv_bench/benchmarks/sparse.py\r"]
[80.004, "o", "sed -n '1,260p' asv_bench/benchmarks/sparse.py\r\n"]
[80.027684, "o", "\u001b[?2004l\r\n"]
[80.049368, "o", "import numpy as np\r\n"]
[80.071053, "o", "import scipy.sparse\r\n"]
[80.092737, "o", "\r\n"]
[80.114421, "o", "import pandas as pd\r\n"]
[80.136105, "o", "from pandas import (\r\n"]
[80.157789, "o", "    MultiIndex,\r\n"]
[80.179474, "o", "    Series,\r\n"]
[80.201158, "o", "    date_range,\r\n"]
[80.222842, "o", ")\r\n"]
[80.244526, "o", "from pandas.arrays import SparseArray\r\n"]
[80.266211, "o", "\r\n"]
[80.287895, "o", "\r\n"]
[80.309579, "o", "def make_array(size, dense_proportion, fill_value, dtype):\r\n"]
[80.331263, "o", "    dense_size = int(size * dense_proportion)\r\n"]
[80.352947, "o", "    arr = np.full(size, fill_value, dtype)\r\n"]
[80.374632, "o", "    indexer = np.random.choice(np.arange(size), dense_size, replace=False)\r\n"]
[80.396316, "o", "    arr[indexer] = np.random.choice(np.arange(100, dtype=dtype), dense_size)\r\n"]
[80.418, "o", "    return arr\r\n"]
[80.439684, "o", "\r\n"]
[80.461368, "o", "\r\n"]
[80.483053, "o", "class SparseSeriesToFrame:\r\n"]
[80.504737, "o", "    def setup(self):\r\n"]
[80.526421, "o", "        K = 50\r\n"]
[80.548105, "o", "        N = 50001\r\n"]
[80.569789, "o", "        rng = date_range(\"1/1/2000\", periods=N, freq=\"T\")\r\n"]
[80.591474, "o", "        self.series = {}\r\n"]
[80.613158, "o", "        for i in range(1, K):\r\n"]
[80.634842, "o", "            data = np.random.randn(N)[:-i]\r\n"]
[80.656526, "o", "            idx = rng[:-i]\r\n"]
[80.678211, "o", "            data[100:] = np.nan\r\n"]
[80.699895, "o", "            self.series[i] = Series(SparseArray(data), index=idx)\r\n"]
[80.721579, "o", "\r\n"]
[80.743263, "o", "    def time_series_to_frame(self):\r\n"]
[80.764947, "o", "        pd.DataFrame(self.series)\r\n"]
[80.786632, "o", "\r\n"]
[80.808316, "o", "\r\n"]
[80.83, "o", "class SparseArrayConstructor:\r\n"]
[80.851684, "o", "    params = ([0.1, 0.01], [0, np.nan], [np.int64, np.float64, object])\r\n"]
[80.873368, "o", "    param_names = [\"dense_proportion\", \"fill_value\", \"dtype\"]\r\n"]
[80.895053, "o", "\r\n"]
[80.916737, "o", "    def setup(self, dense_proportion, fill_value, dtype):\r\n"]
[80.938421, "o", "        N = 10**6\r\n"]
[80.960105, "o", "        self.array = make_array(N, dense_proportion, fill_value, dtype)\r\n"]
[80.981789, "o", "\r\n"]
[81.003474, "o", "    def time_sparse_array(self, dense_proportion, fill_value, dtype):\r\n"]
[81.025158, "o", "        SparseArray(self.array, fill_value=fill_value, dtype=dtype)\r\n"]
[81.046842, "o", "\r\n"]
[81.068526, "o", "\r\n"]
[81.090211, "o", "class SparseDataFrameConstructor:\r\n"]
[81.111895, "o", "    def setup(self):\r\n"]
[81.133579, "o", "        N = 1000\r\n"]
[81.155263, "o", "        self.sparse = scipy.sparse.rand(N, N, 0.005)\r\n"]
[81.176947, "o", "\r\n"]
[81.198632, "o", "    def time_from_scipy(self):\r\n"]
[81.220316, "o", "        pd.DataFrame.sparse.from_spmatrix(self.sparse)\r\n"]
[81.242, "o", "\r\n"]
[81.263684, "o", "\r\n"]
[81.285368, "o", "class FromCoo:\r\n"]
[81.307053, "o", "    def setup(self):\r\n"]
[81.328737, "o", "        self.matrix = scipy.sparse.coo_matrix(\r\n"]
[81.350421, "o", "            ([3.0, 1.0, 2.0], ([1, 0, 0], [0, 2, 3])), shape=(100, 100)\r\n"]
[81.372105, "o", "        )\r\n"]
[81.393789, "o", "\r\n"]
[81.415474, "o", "    def time_sparse_series_from_coo(self):\r\n"]
[81.437158, "o", "        Series.sparse.from_coo(self.matrix)\r\n"]
[81.458842, "o", "\r\n"]
[81.480526, "o", "\r\n"]
[81.502211, "o", "class ToCoo:\r\n"]
[81.523895, "o", "    params = [True, False]\r\n"]
[81.545579, "o", "    param_names = [\"sort_labels\"]\r\n"]
[81.567263, "o", "\r\n"]
[81.588947, "o", "    def setup(self, sort_labels):\r\n"]
[81.610632, "o", "        s = Series([np.nan] * 10000)\r\n"]
[81.632316, "o", "        s[0] = 3.0\r\n"]
[81.654, "o", "        s[100] = -1.0\r\n"]
[81.675684, "o", "        s[999] = 12.1\r\n"]
[81.697368, "o", "\r\n"]
[81.719053, "o", "        s_mult_lvl = s.set_axis(MultiIndex.from_product([range(10)] * 4))\r\n"]
[81.740737, "o", "        self.ss_mult_lvl = s_mult_lvl.astype(\"Sparse\")\r\n"]
[81.762421, "o", "\r\n"]
[81.784105, "o", "        s_two_lvl = s.set_axis(MultiIndex.from_product([range(100)] * 2))\r\n"]
[81.805789, "o", "        self.ss_two_lvl = s_two_lvl.astype(\"Sparse\")\r\n"]
[81.827474, "o", "\r\n"]
[81.849158, "o", "    def time_sparse_series_to_coo(self, sort_labels):\r\n"]
[81.870842, "o", "        self.ss_mult_lvl.sparse.to_coo(\r\n"]
[81.892526, "o", "            row_levels=[0, 1], column_levels=[2, 3], sort_labels=sort_labels\r\n"]
[81.914211, "o", "        )\r\n"]
[81.935895, "o", "\r\n"]
[81.957579, "o", "    def time_sparse_series_to_coo_single_level(self, sort_labels):\r\n"]
[81.979263, "o", "        self.ss_two_lvl.sparse.to_coo(sort_labels=sort_labels)\r\n"]
[82.000947, "o", "\r\n"]
[82.022632, "o", "\r\n"]
[82.044316, "o", "class ToCooFrame:\r\n"]
[82.066, "o", "    def setup(self):\r\n"]
[82.087684, "o", "        N = 10000\r\n"]
[82.109368, "o", "        k = 10\r\n"]
[82.131053, "o", "        arr = np.zeros((N, k), dtype=float)\r\n"]
[82.152737, "o", "        arr[0, 0] = 3.0\r\n"]
[82.174421, "o", "        arr[12, 7] = -1.0\r\n"]
[82.196105, "o", "        arr[0, 9] = 11.2\r\n"]
[82.217789, "o", "        self.df = pd.DataFrame(arr, dtype=pd.SparseDtype(\"float\", fill_value=0.0))\r\n"]
[82.239474, "o", "\r\n"]
[82.261158, "o", "    def time_to_coo(self):\r\n"]
[82.282842, "o", "        self.df.sparse.to_coo()\r\n"]
[82.304526, "o", "\r\n"]
[82.326211, "o", "\r\n"]
[82.347895, "o", "class Arithmetic:\r\n"]
[82.369579, "o", "    params = ([0.1, 0.01], [0, np.nan])\r\n"]
[82.391263, "o", "    param_names = [\"dense_proportion\", \"fill_value\"]\r\n"]
[82.412947, "o", "\r\n"]
[82.434632, "o", "    def setup(self, dense_proportion, fill_value):\r\n"]
[82.456316, "o", "        N = 10**6\r\n"]
[82.478, "o", "        arr1 = make_array(N, dense_proportion, fill_value, np.int64)\r\n"]
[82.499684, "o", "        self.array1 = SparseArray(arr1, fill_value=fill_value)\r\n"]
[82.521368, "o", "        arr2 = make_array(N, dense_proportion, fill_value, np.int64)\r\n"]
[82.543053, "o", "        self.array2 = SparseArray(arr2, fill_value=fill_value)\r\n"]
[82.564737, "o", "\r\n"]
[82.586421, "o", "    def time_make_union(self, dense_proportion, fill_value):\r\n"]
[82.608105, "o", "        self.array1.sp_index.make_union(self.array2.sp_index)\r\n"]
[82.629789, "o", "\r\n"]
[82.651474, "o", "    def time_intersect(self, dense_proportion, fill_value):\r\n"]
[82.673158, "o", "        self.array1.sp_index.intersect(self.array2.sp_index)\r\n"]
[82.694842, "o", "\r\n"]
[82.716526, "o", "    def time_add(self, dense_proportion, fill_value):\r\n"]
[82.738211, "o", "        self.array1 + self.array2\r\n"]
[82.759895, "o", "\r\n"]
[82.781579, "o", "    def time_divide(self, dense_proportion, fill_value):\r\n"]
[82.803263, "o", "        self.array1 / self.array2\r\n"]
[82.824947, "o", "\r\n"]
[82.846632, "o", "\r\n"]
[82.868316, "o", "class ArithmeticBlock:\r\n"]
[82.89, "o", "    params = [np.nan, 0]\r\n"]
[82.911684, "o", "    param_names = [\"fill_value\"]\r\n"]
[82.933368, "o", "\r\n"]
[82.955053, "o", "    def setup(self, fill_value):\r\n"]
[82.976737, "o", "        N = 10**6\r\n"]
[82.998421, "o", "        self.arr1 = self.make_block_array(\r\n"]
[83.020105, "o", "            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\r\n"]
[83.041789, "o", "        )\r\n"]
[83.063474, "o", "        self.arr2 = self.make_block_array(\r\n"]
[83.085158, "o", "            length=N, num_blocks=1000, block_size=10, fill_value=fill_value\r\n"]
[83.106842, "o", "        )\r\n"]
[83.128526, "o", "\r\n"]
[83.150211, "o", "    def make_block_array(self, length, num_blocks, block_size, fill_value):\r\n"]
[83.171895, "o", "        arr = np.full(length, fill_value)\r\n"]
[83.193579, "o", "        indices = np.random.choice(\r\n"]
[83.215263, "o", "            np.arange(0, length, block_size), num_blocks, replace=False\r\n"]
[83.236947, "o", "        )\r\n"]
[83.258632, "o", "        for ind in indices:\r\n"]
[83.280316, "o", "            arr[ind : ind + block_size] = np.random.randint(0, 100, block_size)\r\n"]
[83.302, "o", "        return SparseArray(arr, fill_value=fill_value)\r\n"]
[83.323684, "o", "\r\n"]
[83.345368, "o", "    def time_make_union(self, fill_value):\r\n"]
[83.367053, "o", "        self.arr1.sp_index.make_union(self.arr2.sp_index)\r\n"]
[83.388737, "o", "\r\n"]
[83.410421, "o", "    def time_intersect(self, fill_value):\r\n"]
[83.432105, "o", "        self.arr2.sp_index.intersect(self.arr2.sp_index)\r\n"]
[83.453789, "o", "\r\n"]
[83.475474, "o", "    def time_addition(self, fill_value):\r\n"]
[83.497158, "o", "        self.arr1 + self.arr2\r\n"]
[83.518842, "o", "\r\n"]
[83.540526, "o", "    def time_division(self, fill_value):\r\n"]
[83.562211, "o", "        self.arr1 / self.arr2\r\n"]
[83.583895, "o", "\r\n"]
[83.605579, "o", "\r\n"]
[83.627263, "o", "class MinMax:\r\n"]
[83.648947, "o", "    params = ([\"min\", \"max\"], [0.0, np.nan])\r\n"]
[83.670632, "o", "    param_names = [\"func\", \"fill_value\"]\r\n"]
[83.692316, "o", "\r\n"]
[83.714, "o", "    def setup(self, func, fill_value):\r\n"]
[83.735684, "o", "        N = 1_000_000\r\n"]
[83.757368, "o", "        arr = make_array(N, 1e-5, fill_value, np.float64)\r\n"]
[83.779053, "o", "        self.sp_arr = SparseArray(arr, fill_value=fill_value)\r\n"]
[83.800737, "o", "\r\n"]
[83.822421, "o", "    def time_min_max(self, func, fill_value):\r\n"]
[83.844105, "o", "        getattr(self.sp_arr, func)()\r\n"]
[83.865789, "o", "\r\n"]
[83.887474, "o", "\r\n"]
[83.909158, "o", "class Take:\r\n"]
[83.930842, "o", "    params = ([np.array([0]), np.arange(100_000), np.full(100_000, -1)], [True, False])\r\n"]
[83.952526, "o", "    param_names = [\"indices\", \"allow_fill\"]\r\n"]
[83.974211, "o", "\r\n"]
[83.995895, "o", "    def setup(self, indices, allow_fill):\r\n"]
[84.017579, "o", "        N = 1_000_000\r\n"]
[84.039263, "o", "        fill_value = 0.0\r\n"]
[84.060947, "o", "        arr = make_array(N, 1e-5, fill_value, np.float64)\r\n"]
[84.082632, "o", "        self.sp_arr = SparseArray(arr, fill_value=fill_value)\r\n"]
[84.104316, "o", "\r\n"]
[84.126, "o", "    def time_take(self, indices, allow_fill):\r\n"]
[84.147684, "o", "        self.sp_arr.take(indices, allow_fill=allow_fill)\r\n"]
[84.169368, "o", "\r\n"]
[84.191053, "o", "\r\n"]
[84.212737, "o", "class GetItem:\r\n"]
[84.234421, "o", "    def setup(self):\r\n"]
[84.256105, "o", "        N = 1_000_000\r\n"]
[84.277789, "o", "        d = 1e-5\r\n"]
[84.299474, "o", "        arr = make_array(N, d, np.nan, np.float64)\r\n"]
[84.321158, "o", "        self.sp_arr = SparseArray(arr)\r\n"]
[84.342842, "o", "\r\n"]
[84.364526, "o", "    def time_integer_indexing(self):\r\n"]
[84.386211, "o", "        self.sp_arr[78]\r\n"]
[84.407895, "o", "\r\n"]
[84.429579, "o", "    def time_slice(self):\r\n"]
[84.451263, "o", "        self.sp_arr[1:]\r\n"]
[84.472947, "o", "\r\n"]
[84.494632, "o", "\r\n"]
[84.516316, "o", "class GetItemMask:\r\n"]
[84.538, "o", "    params = [True, False, np.nan]\r\n"]
[84.559684, "o", "    param_names = [\"fill_value\"]\r\n"]
[84.581368, "o", "\r\n"]
[84.603053, "o", "    def setup(self, fill_value):\r\n"]
[84.624737, "o", "        N = 1_000_000\r\n"]
[84.646421, "o", "        d = 1e-5\r\n"]
[84.668105, "o", "        arr = make_array(N, d, np.nan, np.float64)\r\n"]
[84.689789, "o", "        self.sp_arr = SparseArray(arr)\r\n"]
[84.711474, "o", "        b_arr = np.full(shape=N, fill_value=fill_value, dtype=np.bool_)\r\n"]
[84.733158, "o", "        fv_inds = np.unique(\r\n"]
[84.754842, "o", "            np.random.randint(low=0, high=N - 1, size=int(N * d), dtype=np.int32)\r\n"]
[84.776526, "o", "        )\r\n"]
[84.798211, "o", "        b_arr[fv_inds] = True if pd.isna(fill_value) else not fill_value\r\n"]
[84.819895, "o", "        self.sp_b_arr = SparseArray(b_arr, dtype=np.bool_, fill_value=fill_value)\r\n"]
[84.841579, "o", "\r\n"]
[84.863263, "o", "    def time_mask(self, fill_value):\r\n"]
[84.884947, "o", "        self.sp_arr[self.sp_b_arr]\r\n"]
[84.906632, "o", "\r\n"]
[84.928316, "o", "\r\n"]
[85.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[85.002, "i", "cd asv_bench\r"]
[85.004, "o", "cd asv_bench\r\n"]
[85.006, "o", "\u001b[?2004l\r\n"]
[90.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[90.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[90.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[90.359143, "o", "\u001b[?2004l\r\n"]
[90.712286, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[91.065429, "o", "\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n"]
[91.418571, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[91.771714, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (sparse.GetItemMask.time_mask--)\u001b[0m.\r\n"]
[92.124857, "o", "[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39msparse.GetItemMask.time_mask\u001b[0m                                                                                                                    ok\r\n"]
[92.478, "o", "[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ============\u001b[0m\r\n"]
[92.831143, "o", "               fill_value              \r\n"]
[93.184286, "o", "              ------------ ------------\r\n"]
[93.537429, "o", "                  True      12.1\u00b10.3ms \r\n"]
[93.890571, "o", "                 False      48.6\u00b10.4\u03bcs \r\n"]
[94.243714, "o", "                  nan       7.03\u00b10.1ms \r\n"]
[94.596857, "o", "              ============ ============\r\n"]
[95.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[95.002, "i", "asv profile --python=same sparse.GetItemMask.time_mask\r"]
[95.004, "o", "asv profile --python=same sparse.GetItemMask.time_mask\r\n"]
[96.654, "o", "\u001b[?2004l\r\n"]
[98.302, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[100.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[100.002, "i", "cd ..\r"]
[100.004, "o", "cd ..\r\n"]
[100.006, "o", "\u001b[?2004l\r\n"]
[105.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[105.002, "i", "grep -RIn \"class SparseArray\" pandas | sed -n '1,200p'\r"]
[105.004, "o", "grep -RIn \"class SparseArray\" pandas | sed -n '1,200p'\r\n"]
[107.478, "o", "\u001b[?2004l\r\n"]
[110.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[110.002, "i", "grep -RIn \"__getitem__\" pandas/core/arrays | sed -n '1,200p'\r"]
[110.004, "o", "grep -RIn \"__getitem__\" pandas/core/arrays | sed -n '1,200p'\r\n"]
[110.189111, "o", "\u001b[?2004l\r\n"]
[110.372222, "o", "pandas/core/arrays/_mixins.py:259:    def __getitem__(self, key: ScalarIndexer) -> Any:\r\n"]
[110.555333, "o", "pandas/core/arrays/_mixins.py:263:    def __getitem__(\r\n"]
[110.738444, "o", "pandas/core/arrays/_mixins.py:269:    def __getitem__(\r\n"]
[110.921556, "o", "pandas/core/arrays/sparse/array.py:895:    def __getitem__(self, key: ScalarIndexer) -> Any:\r\n"]
[111.104667, "o", "pandas/core/arrays/sparse/array.py:899:    def __getitem__(\r\n"]
[111.287778, "o", "pandas/core/arrays/sparse/array.py:905:    def __getitem__(\r\n"]
[111.470889, "o", "pandas/core/arrays/arrow/array.py:331:    def __getitem__(self, item: PositionalIndexer):\r\n"]
[111.654, "o", "pandas/core/arrays/arrow/array.py:981:        ExtensionArray.take is called by ``Series.__getitem__``, ``.loc``,\r\n"]
[111.837111, "o", "pandas/core/arrays/masked.py:144:    def __getitem__(self, item: ScalarIndexer) -> Any:\r\n"]
[112.020222, "o", "pandas/core/arrays/masked.py:148:    def __getitem__(self, item: SequenceIndexer) -> Self:\r\n"]
[112.203333, "o", "pandas/core/arrays/masked.py:151:    def __getitem__(self, item: PositionalIndexer) -> Self | Any:\r\n"]
[112.386444, "o", "pandas/core/arrays/base.py:152:    * __getitem__\r\n"]
[112.569556, "o", "pandas/core/arrays/base.py:315:    def __getitem__(self, item: ScalarIndexer) -> Any:\r\n"]
[112.752667, "o", "pandas/core/arrays/base.py:319:    def __getitem__(self, item: SequenceIndexer) -> Self:\r\n"]
[112.935778, "o", "pandas/core/arrays/base.py:322:    def __getitem__(self, item: PositionalIndexer) -> Self | Any:\r\n"]
[113.118889, "o", "pandas/core/arrays/base.py:416:        # calls to ``__getitem__``, which may be slower than necessary.\r\n"]
[113.302, "o", "pandas/core/arrays/base.py:1176:        ExtensionArray.take is called by ``Series.__getitem__``, ``.loc``,\r\n"]
[113.485111, "o", "pandas/core/arrays/interval.py:702:    def __getitem__(self, key: ScalarIndexer) -> IntervalOrNA:\r\n"]
[113.668222, "o", "pandas/core/arrays/interval.py:706:    def __getitem__(self, key: SequenceIndexer) -> Self:\r\n"]
[113.851333, "o", "pandas/core/arrays/interval.py:709:    def __getitem__(self, key: PositionalIndexer) -> Self | IntervalOrNA:\r\n"]
[114.034444, "o", "pandas/core/arrays/interval.py:1742:        # No overload variant of \"__getitem__\" of \"ExtensionArray\" matches argument\r\n"]
[114.217556, "o", "pandas/core/arrays/datetimelike.py:352:    def __getitem__(self, item: ScalarIndexer) -> DTScalarOrNaT:\r\n"]
[114.400667, "o", "pandas/core/arrays/datetimelike.py:356:    def __getitem__(\r\n"]
[114.583778, "o", "pandas/core/arrays/datetimelike.py:362:    def __getitem__(self, key: PositionalIndexer2D) -> Self | DTScalarOrNaT:\r\n"]
[114.766889, "o", "pandas/core/arrays/datetimelike.py:370:        result = cast(\"Union[Self, DTScalarOrNaT]\", super().__getitem__(key))\r\n"]
[115.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[115.002, "i", "grep -RIn \"boolean\" pandas/core/arrays/sparse | sed -n '1,200p'\r"]
[115.004, "o", "grep -RIn \"boolean\" pandas/core/arrays/sparse | sed -n '1,200p'\r\n"]
[115.712286, "o", "\u001b[?2004l\r\n"]
[116.418571, "o", "pandas/core/arrays/sparse/accessor.py:321:            If the caller is heterogeneous and contains booleans or objects,\r\n"]
[117.124857, "o", "pandas/core/arrays/sparse/array.py:965:                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[117.831143, "o", "pandas/core/arrays/sparse/dtype.py:164:        # TODO: Right now we can use Sparse boolean array\r\n"]
[118.537429, "o", "pandas/core/arrays/sparse/dtype.py:169:        # if self._is_boolean and not (\r\n"]
[119.243714, "o", "pandas/core/arrays/sparse/dtype.py:174:        #        f\"for boolean type. Got {self._fill_value} instead\"\r\n"]
[120.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[120.002, "i", "sed -n '1,240p' pandas/core/arrays/sparse/array.py\r"]
[120.004, "o", "sed -n '1,240p' pandas/core/arrays/sparse/array.py\r\n"]
[120.026515, "o", "\u001b[?2004l\r\n"]
[120.047029, "o", "\"\"\"\r\n"]
[120.067544, "o", "SparseArray data structure\r\n"]
[120.088058, "o", "\"\"\"\r\n"]
[120.108573, "o", "from __future__ import annotations\r\n"]
[120.129087, "o", "\r\n"]
[120.149602, "o", "from collections import abc\r\n"]
[120.170116, "o", "import numbers\r\n"]
[120.190631, "o", "import operator\r\n"]
[120.211145, "o", "from typing import (\r\n"]
[120.23166, "o", "    TYPE_CHECKING,\r\n"]
[120.252174, "o", "    Any,\r\n"]
[120.272689, "o", "    Callable,\r\n"]
[120.293203, "o", "    Literal,\r\n"]
[120.313718, "o", "    Sequence,\r\n"]
[120.334232, "o", "    cast,\r\n"]
[120.354747, "o", "    overload,\r\n"]
[120.375261, "o", ")\r\n"]
[120.395776, "o", "import warnings\r\n"]
[120.41629, "o", "\r\n"]
[120.436805, "o", "import numpy as np\r\n"]
[120.45732, "o", "\r\n"]
[120.477834, "o", "from pandas._libs import lib\r\n"]
[120.498349, "o", "import pandas._libs.sparse as splib\r\n"]
[120.518863, "o", "from pandas._libs.sparse import (\r\n"]
[120.539378, "o", "    BlockIndex,\r\n"]
[120.559892, "o", "    IntIndex,\r\n"]
[120.580407, "o", "    SparseIndex,\r\n"]
[120.600921, "o", ")\r\n"]
[120.621436, "o", "from pandas._libs.tslibs import NaT\r\n"]
[120.64195, "o", "from pandas.compat.numpy import function as nv\r\n"]
[120.662465, "o", "from pandas.errors import PerformanceWarning\r\n"]
[120.682979, "o", "from pandas.util._exceptions import find_stack_level\r\n"]
[120.703494, "o", "from pandas.util._validators import (\r\n"]
[120.724008, "o", "    validate_bool_kwarg,\r\n"]
[120.744523, "o", "    validate_insert_loc,\r\n"]
[120.765037, "o", ")\r\n"]
[120.785552, "o", "\r\n"]
[120.806066, "o", "from pandas.core.dtypes.astype import astype_array\r\n"]
[120.826581, "o", "from pandas.core.dtypes.cast import (\r\n"]
[120.847095, "o", "    construct_1d_arraylike_from_scalar,\r\n"]
[120.86761, "o", "    find_common_type,\r\n"]
[120.888124, "o", "    maybe_box_datetimelike,\r\n"]
[120.908639, "o", ")\r\n"]
[120.929154, "o", "from pandas.core.dtypes.common import (\r\n"]
[120.949668, "o", "    is_array_like,\r\n"]
[120.970183, "o", "    is_bool_dtype,\r\n"]
[120.990697, "o", "    is_datetime64_any_dtype,\r\n"]
[121.011212, "o", "    is_dtype_equal,\r\n"]
[121.031726, "o", "    is_integer,\r\n"]
[121.052241, "o", "    is_list_like,\r\n"]
[121.072755, "o", "    is_object_dtype,\r\n"]
[121.09327, "o", "    is_scalar,\r\n"]
[121.113784, "o", "    is_string_dtype,\r\n"]
[121.134299, "o", "    pandas_dtype,\r\n"]
[121.154813, "o", ")\r\n"]
[121.175328, "o", "from pandas.core.dtypes.dtypes import DatetimeTZDtype\r\n"]
[121.195842, "o", "from pandas.core.dtypes.generic import (\r\n"]
[121.216357, "o", "    ABCIndex,\r\n"]
[121.236871, "o", "    ABCSeries,\r\n"]
[121.257386, "o", ")\r\n"]
[121.2779, "o", "from pandas.core.dtypes.missing import (\r\n"]
[121.298415, "o", "    isna,\r\n"]
[121.318929, "o", "    na_value_for_dtype,\r\n"]
[121.339444, "o", "    notna,\r\n"]
[121.359959, "o", ")\r\n"]
[121.380473, "o", "\r\n"]
[121.400988, "o", "from pandas.core import arraylike\r\n"]
[121.421502, "o", "import pandas.core.algorithms as algos\r\n"]
[121.442017, "o", "from pandas.core.arraylike import OpsMixin\r\n"]
[121.462531, "o", "from pandas.core.arrays import ExtensionArray\r\n"]
[121.483046, "o", "from pandas.core.arrays.sparse.dtype import SparseDtype\r\n"]
[121.50356, "o", "from pandas.core.base import PandasObject\r\n"]
[121.524075, "o", "import pandas.core.common as com\r\n"]
[121.544589, "o", "from pandas.core.construction import (\r\n"]
[121.565104, "o", "    ensure_wrapped_if_datetimelike,\r\n"]
[121.585618, "o", "    extract_array,\r\n"]
[121.606133, "o", "    sanitize_array,\r\n"]
[121.626647, "o", ")\r\n"]
[121.647162, "o", "from pandas.core.indexers import (\r\n"]
[121.667676, "o", "    check_array_indexer,\r\n"]
[121.688191, "o", "    unpack_tuple_and_ellipses,\r\n"]
[121.708705, "o", ")\r\n"]
[121.72922, "o", "from pandas.core.missing import interpolate_2d\r\n"]
[121.749734, "o", "from pandas.core.nanops import check_below_min_count\r\n"]
[121.770249, "o", "\r\n"]
[121.790763, "o", "from pandas.io.formats import printing\r\n"]
[121.811278, "o", "\r\n"]
[121.831793, "o", "# See https://github.com/python/typing/issues/684\r\n"]
[121.852307, "o", "if TYPE_CHECKING:\r\n"]
[121.872822, "o", "    from enum import Enum\r\n"]
[121.893336, "o", "\r\n"]
[121.913851, "o", "    class ellipsis(Enum):\r\n"]
[121.934365, "o", "        Ellipsis = \"...\"\r\n"]
[121.95488, "o", "\r\n"]
[121.975394, "o", "    Ellipsis = ellipsis.Ellipsis\r\n"]
[121.995909, "o", "\r\n"]
[122.016423, "o", "    from scipy.sparse import spmatrix\r\n"]
[122.036938, "o", "\r\n"]
[122.057452, "o", "    from pandas._typing import (\r\n"]
[122.077967, "o", "        FillnaOptions,\r\n"]
[122.098481, "o", "        NumpySorter,\r\n"]
[122.118996, "o", "    )\r\n"]
[122.13951, "o", "\r\n"]
[122.160025, "o", "    SparseIndexKind = Literal[\"integer\", \"block\"]\r\n"]
[122.180539, "o", "\r\n"]
[122.201054, "o", "    from pandas._typing import (\r\n"]
[122.221568, "o", "        ArrayLike,\r\n"]
[122.242083, "o", "        AstypeArg,\r\n"]
[122.262598, "o", "        Axis,\r\n"]
[122.283112, "o", "        AxisInt,\r\n"]
[122.303627, "o", "        Dtype,\r\n"]
[122.324141, "o", "        NpDtype,\r\n"]
[122.344656, "o", "        PositionalIndexer,\r\n"]
[122.36517, "o", "        Scalar,\r\n"]
[122.385685, "o", "        ScalarIndexer,\r\n"]
[122.406199, "o", "        Self,\r\n"]
[122.426714, "o", "        SequenceIndexer,\r\n"]
[122.447228, "o", "        npt,\r\n"]
[122.467743, "o", "    )\r\n"]
[122.488257, "o", "\r\n"]
[122.508772, "o", "    from pandas import Series\r\n"]
[122.529286, "o", "\r\n"]
[122.549801, "o", "else:\r\n"]
[122.570315, "o", "    ellipsis = type(Ellipsis)\r\n"]
[122.59083, "o", "\r\n"]
[122.611344, "o", "\r\n"]
[122.631859, "o", "# ----------------------------------------------------------------------------\r\n"]
[122.652373, "o", "# Array\r\n"]
[122.672888, "o", "\r\n"]
[122.693402, "o", "_sparray_doc_kwargs = {\"klass\": \"SparseArray\"}\r\n"]
[122.713917, "o", "\r\n"]
[122.734432, "o", "\r\n"]
[122.754946, "o", "def _get_fill(arr: SparseArray) -> np.ndarray:\r\n"]
[122.775461, "o", "    \"\"\"\r\n"]
[122.795975, "o", "    Create a 0-dim ndarray containing the fill value\r\n"]
[122.81649, "o", "\r\n"]
[122.837004, "o", "    Parameters\r\n"]
[122.857519, "o", "    ----------\r\n"]
[122.878033, "o", "    arr : SparseArray\r\n"]
[122.898548, "o", "\r\n"]
[122.919062, "o", "    Returns\r\n"]
[122.939577, "o", "    -------\r\n"]
[122.960091, "o", "    fill_value : ndarray\r\n"]
[122.980606, "o", "        0-dim ndarray with just the fill value.\r\n"]
[123.00112, "o", "\r\n"]
[123.021635, "o", "    Notes\r\n"]
[123.042149, "o", "    -----\r\n"]
[123.062664, "o", "    coerce fill_value to arr dtype if possible\r\n"]
[123.083178, "o", "    int64 SparseArray can have NaN as fill_value if there is no missing\r\n"]
[123.103693, "o", "    \"\"\"\r\n"]
[123.124207, "o", "    try:\r\n"]
[123.144722, "o", "        return np.asarray(arr.fill_value, dtype=arr.dtype.subtype)\r\n"]
[123.165237, "o", "    except ValueError:\r\n"]
[123.185751, "o", "        return np.asarray(arr.fill_value)\r\n"]
[123.206266, "o", "\r\n"]
[123.22678, "o", "\r\n"]
[123.247295, "o", "def _sparse_array_op(\r\n"]
[123.267809, "o", "    left: SparseArray, right: SparseArray, op: Callable, name: str\r\n"]
[123.288324, "o", ") -> SparseArray:\r\n"]
[123.308838, "o", "    \"\"\"\r\n"]
[123.329353, "o", "    Perform a binary operation between two arrays.\r\n"]
[123.349867, "o", "\r\n"]
[123.370382, "o", "    Parameters\r\n"]
[123.390896, "o", "    ----------\r\n"]
[123.411411, "o", "    left : Union[SparseArray, ndarray]\r\n"]
[123.431925, "o", "    right : Union[SparseArray, ndarray]\r\n"]
[123.45244, "o", "    op : Callable\r\n"]
[123.472954, "o", "        The binary operation to perform\r\n"]
[123.493469, "o", "    name str\r\n"]
[123.513983, "o", "        Name of the callable.\r\n"]
[123.534498, "o", "\r\n"]
[123.555012, "o", "    Returns\r\n"]
[123.575527, "o", "    -------\r\n"]
[123.596041, "o", "    SparseArray\r\n"]
[123.616556, "o", "    \"\"\"\r\n"]
[123.637071, "o", "    if name.startswith(\"__\"):\r\n"]
[123.657585, "o", "        # For lookups in _libs.sparse we need non-dunder op name\r\n"]
[123.6781, "o", "        name = name[2:-2]\r\n"]
[123.698614, "o", "\r\n"]
[123.719129, "o", "    # dtype used to find corresponding sparse method\r\n"]
[123.739643, "o", "    ltype = left.dtype.subtype\r\n"]
[123.760158, "o", "    rtype = right.dtype.subtype\r\n"]
[123.780672, "o", "\r\n"]
[123.801187, "o", "    if not is_dtype_equal(ltype, rtype):\r\n"]
[123.821701, "o", "        subtype = find_common_type([ltype, rtype])\r\n"]
[123.842216, "o", "        ltype = SparseDtype(subtype, left.fill_value)\r\n"]
[123.86273, "o", "        rtype = SparseDtype(subtype, right.fill_value)\r\n"]
[123.883245, "o", "\r\n"]
[123.903759, "o", "        left = left.astype(ltype, copy=False)\r\n"]
[123.924274, "o", "        right = right.astype(rtype, copy=False)\r\n"]
[123.944788, "o", "        dtype = ltype.subtype\r\n"]
[123.965303, "o", "    else:\r\n"]
[123.985817, "o", "        dtype = ltype\r\n"]
[124.006332, "o", "\r\n"]
[124.026846, "o", "    # dtype the result must have\r\n"]
[124.047361, "o", "    result_dtype = None\r\n"]
[124.067876, "o", "\r\n"]
[124.08839, "o", "    if left.sp_index.ngaps == 0 or right.sp_index.ngaps == 0:\r\n"]
[124.108905, "o", "        with np.errstate(all=\"ignore\"):\r\n"]
[124.129419, "o", "            result = op(left.to_dense(), right.to_dense())\r\n"]
[124.149934, "o", "            fill = op(_get_fill(left), _get_fill(right))\r\n"]
[124.170448, "o", "\r\n"]
[124.190963, "o", "        if left.sp_index.ngaps == 0:\r\n"]
[124.211477, "o", "            index = left.sp_index\r\n"]
[124.231992, "o", "        else:\r\n"]
[124.252506, "o", "            index = right.sp_index\r\n"]
[124.273021, "o", "    elif left.sp_index.equals(right.sp_index):\r\n"]
[124.293535, "o", "        with np.errstate(all=\"ignore\"):\r\n"]
[124.31405, "o", "            result = op(left.sp_values, right.sp_values)\r\n"]
[124.334564, "o", "            fill = op(_get_fill(left), _get_fill(right))\r\n"]
[124.355079, "o", "        index = left.sp_index\r\n"]
[124.375593, "o", "    else:\r\n"]
[124.396108, "o", "        if name[0] == \"r\":\r\n"]
[124.416622, "o", "            left, right = right, left\r\n"]
[124.437137, "o", "            name = name[1:]\r\n"]
[124.457651, "o", "\r\n"]
[124.478166, "o", "        if name in (\"and\", \"or\", \"xor\") and dtype == \"bool\":\r\n"]
[124.49868, "o", "            opname = f\"sparse_{name}_uint8\"\r\n"]
[124.519195, "o", "            # to make template simple, cast here\r\n"]
[124.53971, "o", "            left_sp_values = left.sp_values.view(np.uint8)\r\n"]
[124.560224, "o", "            right_sp_values = right.sp_values.view(np.uint8)\r\n"]
[124.580739, "o", "            result_dtype = bool\r\n"]
[124.601253, "o", "        else:\r\n"]
[124.621768, "o", "            opname = f\"sparse_{name}_{dtype}\"\r\n"]
[124.642282, "o", "            left_sp_values = left.sp_values\r\n"]
[124.662797, "o", "            right_sp_values = right.sp_values\r\n"]
[124.683311, "o", "\r\n"]
[124.703826, "o", "        if (\r\n"]
[124.72434, "o", "            name in [\"floordiv\", \"mod\"]\r\n"]
[124.744855, "o", "            and (right == 0).any()\r\n"]
[124.765369, "o", "            and left.dtype.kind in \"iu\"\r\n"]
[124.785884, "o", "        ):\r\n"]
[124.806398, "o", "            # Match the non-Sparse Series behavior\r\n"]
[124.826913, "o", "            opname = f\"sparse_{name}_float64\"\r\n"]
[124.847427, "o", "            left_sp_values = left_sp_values.astype(\"float64\")\r\n"]
[124.867942, "o", "            right_sp_values = right_sp_values.astype(\"float64\")\r\n"]
[124.888456, "o", "\r\n"]
[124.908971, "o", "        sparse_op = getattr(splib, opname)\r\n"]
[124.929485, "o", "\r\n"]
[125.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[125.002, "i", "sed -n '240,1160p' pandas/core/arrays/sparse/array.py\r"]
[125.004, "o", "sed -n '240,1160p' pandas/core/arrays/sparse/array.py\r\n"]
[125.016, "o", "\u001b[?2004l\r\n"]
[125.026, "o", "        with np.errstate(all=\"ignore\"):\r\n"]
[125.036, "o", "            result, index, fill = sparse_op(\r\n"]
[125.046, "o", "                left_sp_values,\r\n"]
[125.056, "o", "                left.sp_index,\r\n"]
[125.066, "o", "                left.fill_value,\r\n"]
[125.076, "o", "                right_sp_values,\r\n"]
[125.086, "o", "                right.sp_index,\r\n"]
[125.096, "o", "                right.fill_value,\r\n"]
[125.106, "o", "            )\r\n"]
[125.116, "o", "\r\n"]
[125.126, "o", "    if name == \"divmod\":\r\n"]
[125.136, "o", "        # result is a 2-tuple\r\n"]
[125.146, "o", "        # error: Incompatible return value type (got \"Tuple[SparseArray,\r\n"]
[125.156, "o", "        # SparseArray]\", expected \"SparseArray\")\r\n"]
[125.166, "o", "        return (  # type: ignore[return-value]\r\n"]
[125.176, "o", "            _wrap_result(name, result[0], index, fill[0], dtype=result_dtype),\r\n"]
[125.186, "o", "            _wrap_result(name, result[1], index, fill[1], dtype=result_dtype),\r\n"]
[125.196, "o", "        )\r\n"]
[125.206, "o", "\r\n"]
[125.216, "o", "    if result_dtype is None:\r\n"]
[125.226, "o", "        result_dtype = result.dtype\r\n"]
[125.236, "o", "\r\n"]
[125.246, "o", "    return _wrap_result(name, result, index, fill, dtype=result_dtype)\r\n"]
[125.256, "o", "\r\n"]
[125.266, "o", "\r\n"]
[125.276, "o", "def _wrap_result(\r\n"]
[125.286, "o", "    name: str, data, sparse_index, fill_value, dtype: Dtype | None = None\r\n"]
[125.296, "o", ") -> SparseArray:\r\n"]
[125.306, "o", "    \"\"\"\r\n"]
[125.316, "o", "    wrap op result to have correct dtype\r\n"]
[125.326, "o", "    \"\"\"\r\n"]
[125.336, "o", "    if name.startswith(\"__\"):\r\n"]
[125.346, "o", "        # e.g. __eq__ --> eq\r\n"]
[125.356, "o", "        name = name[2:-2]\r\n"]
[125.366, "o", "\r\n"]
[125.376, "o", "    if name in (\"eq\", \"ne\", \"lt\", \"gt\", \"le\", \"ge\"):\r\n"]
[125.386, "o", "        dtype = bool\r\n"]
[125.396, "o", "\r\n"]
[125.406, "o", "    fill_value = lib.item_from_zerodim(fill_value)\r\n"]
[125.416, "o", "\r\n"]
[125.426, "o", "    if is_bool_dtype(dtype):\r\n"]
[125.436, "o", "        # fill_value may be np.bool_\r\n"]
[125.446, "o", "        fill_value = bool(fill_value)\r\n"]
[125.456, "o", "    return SparseArray(\r\n"]
[125.466, "o", "        data, sparse_index=sparse_index, fill_value=fill_value, dtype=dtype\r\n"]
[125.476, "o", "    )\r\n"]
[125.486, "o", "\r\n"]
[125.496, "o", "\r\n"]
[125.506, "o", "class SparseArray(OpsMixin, PandasObject, ExtensionArray):\r\n"]
[125.516, "o", "    \"\"\"\r\n"]
[125.526, "o", "    An ExtensionArray for storing sparse data.\r\n"]
[125.536, "o", "\r\n"]
[125.546, "o", "    Parameters\r\n"]
[125.556, "o", "    ----------\r\n"]
[125.566, "o", "    data : array-like or scalar\r\n"]
[125.576, "o", "        A dense array of values to store in the SparseArray. This may contain\r\n"]
[125.586, "o", "        `fill_value`.\r\n"]
[125.596, "o", "    sparse_index : SparseIndex, optional\r\n"]
[125.606, "o", "    fill_value : scalar, optional\r\n"]
[125.616, "o", "        Elements in data that are ``fill_value`` are not stored in the\r\n"]
[125.626, "o", "        SparseArray. For memory savings, this should be the most common value\r\n"]
[125.636, "o", "        in `data`. By default, `fill_value` depends on the dtype of `data`:\r\n"]
[125.646, "o", "\r\n"]
[125.656, "o", "        =========== ==========\r\n"]
[125.666, "o", "        data.dtype  na_value\r\n"]
[125.676, "o", "        =========== ==========\r\n"]
[125.686, "o", "        float       ``np.nan``\r\n"]
[125.696, "o", "        int         ``0``\r\n"]
[125.706, "o", "        bool        False\r\n"]
[125.716, "o", "        datetime64  ``pd.NaT``\r\n"]
[125.726, "o", "        timedelta64 ``pd.NaT``\r\n"]
[125.736, "o", "        =========== ==========\r\n"]
[125.746, "o", "\r\n"]
[125.756, "o", "        The fill value is potentially specified in three ways. In order of\r\n"]
[125.766, "o", "        precedence, these are\r\n"]
[125.776, "o", "\r\n"]
[125.786, "o", "        1. The `fill_value` argument\r\n"]
[125.796, "o", "        2. ``dtype.fill_value`` if `fill_value` is None and `dtype` is\r\n"]
[125.806, "o", "           a ``SparseDtype``\r\n"]
[125.816, "o", "        3. ``data.dtype.fill_value`` if `fill_value` is None and `dtype`\r\n"]
[125.826, "o", "           is not a ``SparseDtype`` and `data` is a ``SparseArray``.\r\n"]
[125.836, "o", "\r\n"]
[125.846, "o", "    kind : str\r\n"]
[125.856, "o", "        Can be 'integer' or 'block', default is 'integer'.\r\n"]
[125.866, "o", "        The type of storage for sparse locations.\r\n"]
[125.876, "o", "\r\n"]
[125.886, "o", "        * 'block': Stores a `block` and `block_length` for each\r\n"]
[125.896, "o", "          contiguous *span* of sparse values. This is best when\r\n"]
[125.906, "o", "          sparse data tends to be clumped together, with large\r\n"]
[125.916, "o", "          regions of ``fill-value`` values between sparse values.\r\n"]
[125.926, "o", "        * 'integer': uses an integer to store the location of\r\n"]
[125.936, "o", "          each sparse value.\r\n"]
[125.946, "o", "\r\n"]
[125.956, "o", "    dtype : np.dtype or SparseDtype, optional\r\n"]
[125.966, "o", "        The dtype to use for the SparseArray. For numpy dtypes, this\r\n"]
[125.976, "o", "        determines the dtype of ``self.sp_values``. For SparseDtype,\r\n"]
[125.986, "o", "        this determines ``self.sp_values`` and ``self.fill_value``.\r\n"]
[125.996, "o", "    copy : bool, default False\r\n"]
[126.006, "o", "        Whether to explicitly copy the incoming `data` array.\r\n"]
[126.016, "o", "\r\n"]
[126.026, "o", "    Attributes\r\n"]
[126.036, "o", "    ----------\r\n"]
[126.046, "o", "    None\r\n"]
[126.056, "o", "\r\n"]
[126.066, "o", "    Methods\r\n"]
[126.076, "o", "    -------\r\n"]
[126.086, "o", "    None\r\n"]
[126.096, "o", "\r\n"]
[126.106, "o", "    Examples\r\n"]
[126.116, "o", "    --------\r\n"]
[126.126, "o", "    >>> from pandas.arrays import SparseArray\r\n"]
[126.136, "o", "    >>> arr = SparseArray([0, 0, 1, 2])\r\n"]
[126.146, "o", "    >>> arr\r\n"]
[126.156, "o", "    [0, 0, 1, 2]\r\n"]
[126.166, "o", "    Fill: 0\r\n"]
[126.176, "o", "    IntIndex\r\n"]
[126.186, "o", "    Indices: array([2, 3], dtype=int32)\r\n"]
[126.196, "o", "    \"\"\"\r\n"]
[126.206, "o", "\r\n"]
[126.216, "o", "    _subtyp = \"sparse_array\"  # register ABCSparseArray\r\n"]
[126.226, "o", "    _hidden_attrs = PandasObject._hidden_attrs | frozenset([])\r\n"]
[126.236, "o", "    _sparse_index: SparseIndex\r\n"]
[126.246, "o", "    _sparse_values: np.ndarray\r\n"]
[126.256, "o", "    _dtype: SparseDtype\r\n"]
[126.266, "o", "\r\n"]
[126.276, "o", "    def __init__(\r\n"]
[126.286, "o", "        self,\r\n"]
[126.296, "o", "        data,\r\n"]
[126.306, "o", "        sparse_index=None,\r\n"]
[126.316, "o", "        fill_value=None,\r\n"]
[126.326, "o", "        kind: SparseIndexKind = \"integer\",\r\n"]
[126.336, "o", "        dtype: Dtype | None = None,\r\n"]
[126.346, "o", "        copy: bool = False,\r\n"]
[126.356, "o", "    ) -> None:\r\n"]
[126.366, "o", "        if fill_value is None and isinstance(dtype, SparseDtype):\r\n"]
[126.376, "o", "            fill_value = dtype.fill_value\r\n"]
[126.386, "o", "\r\n"]
[126.396, "o", "        if isinstance(data, type(self)):\r\n"]
[126.406, "o", "            # disable normal inference on dtype, sparse_index, & fill_value\r\n"]
[126.416, "o", "            if sparse_index is None:\r\n"]
[126.426, "o", "                sparse_index = data.sp_index\r\n"]
[126.436, "o", "            if fill_value is None:\r\n"]
[126.446, "o", "                fill_value = data.fill_value\r\n"]
[126.456, "o", "            if dtype is None:\r\n"]
[126.466, "o", "                dtype = data.dtype\r\n"]
[126.476, "o", "            # TODO: make kind=None, and use data.kind?\r\n"]
[126.486, "o", "            data = data.sp_values\r\n"]
[126.496, "o", "\r\n"]
[126.506, "o", "        # Handle use-provided dtype\r\n"]
[126.516, "o", "        if isinstance(dtype, str):\r\n"]
[126.526, "o", "            # Two options: dtype='int', regular numpy dtype\r\n"]
[126.536, "o", "            # or dtype='Sparse[int]', a sparse dtype\r\n"]
[126.546, "o", "            try:\r\n"]
[126.556, "o", "                dtype = SparseDtype.construct_from_string(dtype)\r\n"]
[126.566, "o", "            except TypeError:\r\n"]
[126.576, "o", "                dtype = pandas_dtype(dtype)\r\n"]
[126.586, "o", "\r\n"]
[126.596, "o", "        if isinstance(dtype, SparseDtype):\r\n"]
[126.606, "o", "            if fill_value is None:\r\n"]
[126.616, "o", "                fill_value = dtype.fill_value\r\n"]
[126.626, "o", "            dtype = dtype.subtype\r\n"]
[126.636, "o", "\r\n"]
[126.646, "o", "        if is_scalar(data):\r\n"]
[126.656, "o", "            if sparse_index is None:\r\n"]
[126.666, "o", "                npoints = 1\r\n"]
[126.676, "o", "            else:\r\n"]
[126.686, "o", "                npoints = sparse_index.length\r\n"]
[126.696, "o", "\r\n"]
[126.706, "o", "            data = construct_1d_arraylike_from_scalar(data, npoints, dtype=None)\r\n"]
[126.716, "o", "            dtype = data.dtype\r\n"]
[126.726, "o", "\r\n"]
[126.736, "o", "        if dtype is not None:\r\n"]
[126.746, "o", "            dtype = pandas_dtype(dtype)\r\n"]
[126.756, "o", "\r\n"]
[126.766, "o", "        # TODO: disentangle the fill_value dtype inference from\r\n"]
[126.776, "o", "        # dtype inference\r\n"]
[126.786, "o", "        if data is None:\r\n"]
[126.796, "o", "            # TODO: What should the empty dtype be? Object or float?\r\n"]
[126.806, "o", "\r\n"]
[126.816, "o", "            # error: Argument \"dtype\" to \"array\" has incompatible type\r\n"]
[126.826, "o", "            # \"Union[ExtensionDtype, dtype[Any], None]\"; expected \"Union[dtype[Any],\r\n"]
[126.836, "o", "            # None, type, _SupportsDType, str, Union[Tuple[Any, int], Tuple[Any,\r\n"]
[126.846, "o", "            # Union[int, Sequence[int]]], List[Any], _DTypeDict, Tuple[Any, Any]]]\"\r\n"]
[126.856, "o", "            data = np.array([], dtype=dtype)  # type: ignore[arg-type]\r\n"]
[126.866, "o", "\r\n"]
[126.876, "o", "        if not is_array_like(data):\r\n"]
[126.886, "o", "            try:\r\n"]
[126.896, "o", "                # probably shared code in sanitize_series\r\n"]
[126.906, "o", "\r\n"]
[126.916, "o", "                data = sanitize_array(data, index=None)\r\n"]
[126.926, "o", "            except ValueError:\r\n"]
[126.936, "o", "                # NumPy may raise a ValueError on data like [1, []]\r\n"]
[126.946, "o", "                # we retry with object dtype here.\r\n"]
[126.956, "o", "                if dtype is None:\r\n"]
[126.966, "o", "                    dtype = np.dtype(object)\r\n"]
[126.976, "o", "                    data = np.atleast_1d(np.asarray(data, dtype=dtype))\r\n"]
[126.986, "o", "                else:\r\n"]
[126.996, "o", "                    raise\r\n"]
[127.006, "o", "\r\n"]
[127.016, "o", "        if copy:\r\n"]
[127.026, "o", "            # TODO: avoid double copy when dtype forces cast.\r\n"]
[127.036, "o", "            data = data.copy()\r\n"]
[127.046, "o", "\r\n"]
[127.056, "o", "        if fill_value is None:\r\n"]
[127.066, "o", "            fill_value_dtype = data.dtype if dtype is None else dtype\r\n"]
[127.076, "o", "            if fill_value_dtype is None:\r\n"]
[127.086, "o", "                fill_value = np.nan\r\n"]
[127.096, "o", "            else:\r\n"]
[127.106, "o", "                fill_value = na_value_for_dtype(fill_value_dtype)\r\n"]
[127.116, "o", "\r\n"]
[127.126, "o", "        if isinstance(data, type(self)) and sparse_index is None:\r\n"]
[127.136, "o", "            sparse_index = data._sparse_index\r\n"]
[127.146, "o", "            # error: Argument \"dtype\" to \"asarray\" has incompatible type\r\n"]
[127.156, "o", "            # \"Union[ExtensionDtype, dtype[Any], None]\"; expected \"None\"\r\n"]
[127.166, "o", "            sparse_values = np.asarray(\r\n"]
[127.176, "o", "                data.sp_values, dtype=dtype  # type: ignore[arg-type]\r\n"]
[127.186, "o", "            )\r\n"]
[127.196, "o", "        elif sparse_index is None:\r\n"]
[127.206, "o", "            data = extract_array(data, extract_numpy=True)\r\n"]
[127.216, "o", "            if not isinstance(data, np.ndarray):\r\n"]
[127.226, "o", "                # EA\r\n"]
[127.236, "o", "                if isinstance(data.dtype, DatetimeTZDtype):\r\n"]
[127.246, "o", "                    warnings.warn(\r\n"]
[127.256, "o", "                        f\"Creating SparseArray from {data.dtype} data \"\r\n"]
[127.266, "o", "                        \"loses timezone information. Cast to object before \"\r\n"]
[127.276, "o", "                        \"sparse to retain timezone information.\",\r\n"]
[127.286, "o", "                        UserWarning,\r\n"]
[127.296, "o", "                        stacklevel=find_stack_level(),\r\n"]
[127.306, "o", "                    )\r\n"]
[127.316, "o", "                    data = np.asarray(data, dtype=\"datetime64[ns]\")\r\n"]
[127.326, "o", "                    if fill_value is NaT:\r\n"]
[127.336, "o", "                        fill_value = np.datetime64(\"NaT\", \"ns\")\r\n"]
[127.346, "o", "                data = np.asarray(data)\r\n"]
[127.356, "o", "            sparse_values, sparse_index, fill_value = _make_sparse(\r\n"]
[127.366, "o", "                # error: Argument \"dtype\" to \"_make_sparse\" has incompatible type\r\n"]
[127.376, "o", "                # \"Union[ExtensionDtype, dtype[Any], None]\"; expected\r\n"]
[127.386, "o", "                # \"Optional[dtype[Any]]\"\r\n"]
[127.396, "o", "                data,\r\n"]
[127.406, "o", "                kind=kind,\r\n"]
[127.416, "o", "                fill_value=fill_value,\r\n"]
[127.426, "o", "                dtype=dtype,  # type: ignore[arg-type]\r\n"]
[127.436, "o", "            )\r\n"]
[127.446, "o", "        else:\r\n"]
[127.456, "o", "            # error: Argument \"dtype\" to \"asarray\" has incompatible type\r\n"]
[127.466, "o", "            # \"Union[ExtensionDtype, dtype[Any], None]\"; expected \"None\"\r\n"]
[127.476, "o", "            sparse_values = np.asarray(data, dtype=dtype)  # type: ignore[arg-type]\r\n"]
[127.486, "o", "            if len(sparse_values) != sparse_index.npoints:\r\n"]
[127.496, "o", "                raise AssertionError(\r\n"]
[127.506, "o", "                    f\"Non array-like type {type(sparse_values)} must \"\r\n"]
[127.516, "o", "                    \"have the same length as the index\"\r\n"]
[127.526, "o", "                )\r\n"]
[127.536, "o", "        self._sparse_index = sparse_index\r\n"]
[127.546, "o", "        self._sparse_values = sparse_values\r\n"]
[127.556, "o", "        self._dtype = SparseDtype(sparse_values.dtype, fill_value)\r\n"]
[127.566, "o", "\r\n"]
[127.576, "o", "    @classmethod\r\n"]
[127.586, "o", "    def _simple_new(\r\n"]
[127.596, "o", "        cls,\r\n"]
[127.606, "o", "        sparse_array: np.ndarray,\r\n"]
[127.616, "o", "        sparse_index: SparseIndex,\r\n"]
[127.626, "o", "        dtype: SparseDtype,\r\n"]
[127.636, "o", "    ) -> Self:\r\n"]
[127.646, "o", "        new = object.__new__(cls)\r\n"]
[127.656, "o", "        new._sparse_index = sparse_index\r\n"]
[127.666, "o", "        new._sparse_values = sparse_array\r\n"]
[127.676, "o", "        new._dtype = dtype\r\n"]
[127.686, "o", "        return new\r\n"]
[127.696, "o", "\r\n"]
[127.706, "o", "    @classmethod\r\n"]
[127.716, "o", "    def from_spmatrix(cls, data: spmatrix) -> Self:\r\n"]
[127.726, "o", "        \"\"\"\r\n"]
[127.736, "o", "        Create a SparseArray from a scipy.sparse matrix.\r\n"]
[127.746, "o", "\r\n"]
[127.756, "o", "        Parameters\r\n"]
[127.766, "o", "        ----------\r\n"]
[127.776, "o", "        data : scipy.sparse.sp_matrix\r\n"]
[127.786, "o", "            This should be a SciPy sparse matrix where the size\r\n"]
[127.796, "o", "            of the second dimension is 1. In other words, a\r\n"]
[127.806, "o", "            sparse matrix with a single column.\r\n"]
[127.816, "o", "\r\n"]
[127.826, "o", "        Returns\r\n"]
[127.836, "o", "        -------\r\n"]
[127.846, "o", "        SparseArray\r\n"]
[127.856, "o", "\r\n"]
[127.866, "o", "        Examples\r\n"]
[127.876, "o", "        --------\r\n"]
[127.886, "o", "        >>> import scipy.sparse\r\n"]
[127.896, "o", "        >>> mat = scipy.sparse.coo_matrix((4, 1))\r\n"]
[127.906, "o", "        >>> pd.arrays.SparseArray.from_spmatrix(mat)\r\n"]
[127.916, "o", "        [0.0, 0.0, 0.0, 0.0]\r\n"]
[127.926, "o", "        Fill: 0.0\r\n"]
[127.936, "o", "        IntIndex\r\n"]
[127.946, "o", "        Indices: array([], dtype=int32)\r\n"]
[127.956, "o", "        \"\"\"\r\n"]
[127.966, "o", "        length, ncol = data.shape\r\n"]
[127.976, "o", "\r\n"]
[127.986, "o", "        if ncol != 1:\r\n"]
[127.996, "o", "            raise ValueError(f\"'data' must have a single column, not '{ncol}'\")\r\n"]
[128.006, "o", "\r\n"]
[128.016, "o", "        # our sparse index classes require that the positions be strictly\r\n"]
[128.026, "o", "        # increasing. So we need to sort loc, and arr accordingly.\r\n"]
[128.036, "o", "        data = data.tocsc()\r\n"]
[128.046, "o", "        data.sort_indices()\r\n"]
[128.056, "o", "        arr = data.data\r\n"]
[128.066, "o", "        idx = data.indices\r\n"]
[128.076, "o", "\r\n"]
[128.086, "o", "        zero = np.array(0, dtype=arr.dtype).item()\r\n"]
[128.096, "o", "        dtype = SparseDtype(arr.dtype, zero)\r\n"]
[128.106, "o", "        index = IntIndex(length, idx)\r\n"]
[128.116, "o", "\r\n"]
[128.126, "o", "        return cls._simple_new(arr, index, dtype)\r\n"]
[128.136, "o", "\r\n"]
[128.146, "o", "    def __array__(self, dtype: NpDtype | None = None) -> np.ndarray:\r\n"]
[128.156, "o", "        fill_value = self.fill_value\r\n"]
[128.166, "o", "\r\n"]
[128.176, "o", "        if self.sp_index.ngaps == 0:\r\n"]
[128.186, "o", "            # Compat for na dtype and int values.\r\n"]
[128.196, "o", "            return self.sp_values\r\n"]
[128.206, "o", "        if dtype is None:\r\n"]
[128.216, "o", "            # Can NumPy represent this type?\r\n"]
[128.226, "o", "            # If not, `np.result_type` will raise. We catch that\r\n"]
[128.236, "o", "            # and return object.\r\n"]
[128.246, "o", "            if is_datetime64_any_dtype(self.sp_values.dtype):\r\n"]
[128.256, "o", "                # However, we *do* special-case the common case of\r\n"]
[128.266, "o", "                # a datetime64 with pandas NaT.\r\n"]
[128.276, "o", "                if fill_value is NaT:\r\n"]
[128.286, "o", "                    # Can't put pd.NaT in a datetime64[ns]\r\n"]
[128.296, "o", "                    fill_value = np.datetime64(\"NaT\")\r\n"]
[128.306, "o", "            try:\r\n"]
[128.316, "o", "                dtype = np.result_type(self.sp_values.dtype, type(fill_value))\r\n"]
[128.326, "o", "            except TypeError:\r\n"]
[128.336, "o", "                dtype = object\r\n"]
[128.346, "o", "\r\n"]
[128.356, "o", "        out = np.full(self.shape, fill_value, dtype=dtype)\r\n"]
[128.366, "o", "        out[self.sp_index.indices] = self.sp_values\r\n"]
[128.376, "o", "        return out\r\n"]
[128.386, "o", "\r\n"]
[128.396, "o", "    def __setitem__(self, key, value):\r\n"]
[128.406, "o", "        # I suppose we could allow setting of non-fill_value elements.\r\n"]
[128.416, "o", "        # TODO(SparseArray.__setitem__): remove special cases in\r\n"]
[128.426, "o", "        # ExtensionBlock.where\r\n"]
[128.436, "o", "        msg = \"SparseArray does not support item assignment via setitem\"\r\n"]
[128.446, "o", "        raise TypeError(msg)\r\n"]
[128.456, "o", "\r\n"]
[128.466, "o", "    @classmethod\r\n"]
[128.476, "o", "    def _from_sequence(cls, scalars, *, dtype: Dtype | None = None, copy: bool = False):\r\n"]
[128.486, "o", "        return cls(scalars, dtype=dtype)\r\n"]
[128.496, "o", "\r\n"]
[128.506, "o", "    @classmethod\r\n"]
[128.516, "o", "    def _from_factorized(cls, values, original):\r\n"]
[128.526, "o", "        return cls(values, dtype=original.dtype)\r\n"]
[128.536, "o", "\r\n"]
[128.546, "o", "    # ------------------------------------------------------------------------\r\n"]
[128.556, "o", "    # Data\r\n"]
[128.566, "o", "    # ------------------------------------------------------------------------\r\n"]
[128.576, "o", "    @property\r\n"]
[128.586, "o", "    def sp_index(self) -> SparseIndex:\r\n"]
[128.596, "o", "        \"\"\"\r\n"]
[128.606, "o", "        The SparseIndex containing the location of non- ``fill_value`` points.\r\n"]
[128.616, "o", "        \"\"\"\r\n"]
[128.626, "o", "        return self._sparse_index\r\n"]
[128.636, "o", "\r\n"]
[128.646, "o", "    @property\r\n"]
[128.656, "o", "    def sp_values(self) -> np.ndarray:\r\n"]
[128.666, "o", "        \"\"\"\r\n"]
[128.676, "o", "        An ndarray containing the non- ``fill_value`` values.\r\n"]
[128.686, "o", "\r\n"]
[128.696, "o", "        Examples\r\n"]
[128.706, "o", "        --------\r\n"]
[128.716, "o", "        >>> from pandas.arrays import SparseArray\r\n"]
[128.726, "o", "        >>> s = SparseArray([0, 0, 1, 0, 2], fill_value=0)\r\n"]
[128.736, "o", "        >>> s.sp_values\r\n"]
[128.746, "o", "        array([1, 2])\r\n"]
[128.756, "o", "        \"\"\"\r\n"]
[128.766, "o", "        return self._sparse_values\r\n"]
[128.776, "o", "\r\n"]
[128.786, "o", "    @property\r\n"]
[128.796, "o", "    def dtype(self) -> SparseDtype:\r\n"]
[128.806, "o", "        return self._dtype\r\n"]
[128.816, "o", "\r\n"]
[128.826, "o", "    @property\r\n"]
[128.836, "o", "    def fill_value(self):\r\n"]
[128.846, "o", "        \"\"\"\r\n"]
[128.856, "o", "        Elements in `data` that are `fill_value` are not stored.\r\n"]
[128.866, "o", "\r\n"]
[128.876, "o", "        For memory savings, this should be the most common value in the array.\r\n"]
[128.886, "o", "        \"\"\"\r\n"]
[128.896, "o", "        return self.dtype.fill_value\r\n"]
[128.906, "o", "\r\n"]
[128.916, "o", "    @fill_value.setter\r\n"]
[128.926, "o", "    def fill_value(self, value) -> None:\r\n"]
[128.936, "o", "        self._dtype = SparseDtype(self.dtype.subtype, value)\r\n"]
[128.946, "o", "\r\n"]
[128.956, "o", "    @property\r\n"]
[128.966, "o", "    def kind(self) -> SparseIndexKind:\r\n"]
[128.976, "o", "        \"\"\"\r\n"]
[128.986, "o", "        The kind of sparse index for this array. One of {'integer', 'block'}.\r\n"]
[128.996, "o", "        \"\"\"\r\n"]
[129.006, "o", "        if isinstance(self.sp_index, IntIndex):\r\n"]
[129.016, "o", "            return \"integer\"\r\n"]
[129.026, "o", "        else:\r\n"]
[129.036, "o", "            return \"block\"\r\n"]
[129.046, "o", "\r\n"]
[129.056, "o", "    @property\r\n"]
[129.066, "o", "    def _valid_sp_values(self) -> np.ndarray:\r\n"]
[129.076, "o", "        sp_vals = self.sp_values\r\n"]
[129.086, "o", "        mask = notna(sp_vals)\r\n"]
[129.096, "o", "        return sp_vals[mask]\r\n"]
[129.106, "o", "\r\n"]
[129.116, "o", "    def __len__(self) -> int:\r\n"]
[129.126, "o", "        return self.sp_index.length\r\n"]
[129.136, "o", "\r\n"]
[129.146, "o", "    @property\r\n"]
[129.156, "o", "    def _null_fill_value(self) -> bool:\r\n"]
[129.166, "o", "        return self._dtype._is_na_fill_value\r\n"]
[129.176, "o", "\r\n"]
[129.186, "o", "    def _fill_value_matches(self, fill_value) -> bool:\r\n"]
[129.196, "o", "        if self._null_fill_value:\r\n"]
[129.206, "o", "            return isna(fill_value)\r\n"]
[129.216, "o", "        else:\r\n"]
[129.226, "o", "            return self.fill_value == fill_value\r\n"]
[129.236, "o", "\r\n"]
[129.246, "o", "    @property\r\n"]
[129.256, "o", "    def nbytes(self) -> int:\r\n"]
[129.266, "o", "        return self.sp_values.nbytes + self.sp_index.nbytes\r\n"]
[129.276, "o", "\r\n"]
[129.286, "o", "    @property\r\n"]
[129.296, "o", "    def density(self) -> float:\r\n"]
[129.306, "o", "        \"\"\"\r\n"]
[129.316, "o", "        The percent of non- ``fill_value`` points, as decimal.\r\n"]
[129.326, "o", "\r\n"]
[129.336, "o", "        Examples\r\n"]
[129.346, "o", "        --------\r\n"]
[129.356, "o", "        >>> from pandas.arrays import SparseArray\r\n"]
[129.366, "o", "        >>> s = SparseArray([0, 0, 1, 1, 1], fill_value=0)\r\n"]
[129.376, "o", "        >>> s.density\r\n"]
[129.386, "o", "        0.6\r\n"]
[129.396, "o", "        \"\"\"\r\n"]
[129.406, "o", "        return self.sp_index.npoints / self.sp_index.length\r\n"]
[129.416, "o", "\r\n"]
[129.426, "o", "    @property\r\n"]
[129.436, "o", "    def npoints(self) -> int:\r\n"]
[129.446, "o", "        \"\"\"\r\n"]
[129.456, "o", "        The number of non- ``fill_value`` points.\r\n"]
[129.466, "o", "\r\n"]
[129.476, "o", "        Examples\r\n"]
[129.486, "o", "        --------\r\n"]
[129.496, "o", "        >>> from pandas.arrays import SparseArray\r\n"]
[129.506, "o", "        >>> s = SparseArray([0, 0, 1, 1, 1], fill_value=0)\r\n"]
[129.516, "o", "        >>> s.npoints\r\n"]
[129.526, "o", "        3\r\n"]
[129.536, "o", "        \"\"\"\r\n"]
[129.546, "o", "        return self.sp_index.npoints\r\n"]
[129.556, "o", "\r\n"]
[129.566, "o", "    def isna(self):\r\n"]
[129.576, "o", "        # If null fill value, we want SparseDtype[bool, true]\r\n"]
[129.586, "o", "        # to preserve the same memory usage.\r\n"]
[129.596, "o", "        dtype = SparseDtype(bool, self._null_fill_value)\r\n"]
[129.606, "o", "        if self._null_fill_value:\r\n"]
[129.616, "o", "            return type(self)._simple_new(isna(self.sp_values), self.sp_index, dtype)\r\n"]
[129.626, "o", "        mask = np.full(len(self), False, dtype=np.bool_)\r\n"]
[129.636, "o", "        mask[self.sp_index.indices] = isna(self.sp_values)\r\n"]
[129.646, "o", "        return type(self)(mask, fill_value=False, dtype=dtype)\r\n"]
[129.656, "o", "\r\n"]
[129.666, "o", "    def fillna(\r\n"]
[129.676, "o", "        self,\r\n"]
[129.686, "o", "        value=None,\r\n"]
[129.696, "o", "        method: FillnaOptions | None = None,\r\n"]
[129.706, "o", "        limit: int | None = None,\r\n"]
[129.716, "o", "    ) -> Self:\r\n"]
[129.726, "o", "        \"\"\"\r\n"]
[129.736, "o", "        Fill missing values with `value`.\r\n"]
[129.746, "o", "\r\n"]
[129.756, "o", "        Parameters\r\n"]
[129.766, "o", "        ----------\r\n"]
[129.776, "o", "        value : scalar, optional\r\n"]
[129.786, "o", "        method : str, optional\r\n"]
[129.796, "o", "\r\n"]
[129.806, "o", "            .. warning::\r\n"]
[129.816, "o", "\r\n"]
[129.826, "o", "               Using 'method' will result in high memory use,\r\n"]
[129.836, "o", "               as all `fill_value` methods will be converted to\r\n"]
[129.846, "o", "               an in-memory ndarray\r\n"]
[129.856, "o", "\r\n"]
[129.866, "o", "        limit : int, optional\r\n"]
[129.876, "o", "\r\n"]
[129.886, "o", "        Returns\r\n"]
[129.896, "o", "        -------\r\n"]
[129.906, "o", "        SparseArray\r\n"]
[129.916, "o", "\r\n"]
[129.926, "o", "        Notes\r\n"]
[129.936, "o", "        -----\r\n"]
[130.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[130.002, "i", "sed -n '1160,2000p' pandas/core/arrays/sparse/array.py\r"]
[130.004, "o", "sed -n '1160,2000p' pandas/core/arrays/sparse/array.py\r\n"]
[130.016, "o", "\u001b[?2004l\r\n"]
[130.026, "o", "            # \"ndarray[Any, dtype[signedinteger[_32Bit]]]\";\r\n"]
[130.036, "o", "            # expected \"Sequence[int]\"\r\n"]
[130.046, "o", "            sp_index = IntIndex(length, indices_arr)  # type: ignore[arg-type]\r\n"]
[130.056, "o", "\r\n"]
[130.066, "o", "        else:\r\n"]
[130.076, "o", "            # when concatenating block indices, we don't claim that you'll\r\n"]
[130.086, "o", "            # get an identical index as concatenating the values and then\r\n"]
[130.096, "o", "            # creating a new index. We don't want to spend the time trying\r\n"]
[130.106, "o", "            # to merge blocks across arrays in `to_concat`, so the resulting\r\n"]
[130.116, "o", "            # BlockIndex may have more blocks.\r\n"]
[130.126, "o", "            blengths = []\r\n"]
[130.136, "o", "            blocs = []\r\n"]
[130.146, "o", "\r\n"]
[130.156, "o", "            for arr in to_concat:\r\n"]
[130.166, "o", "                block_idx = arr.sp_index.to_block_index()\r\n"]
[130.176, "o", "\r\n"]
[130.186, "o", "                values.append(arr.sp_values)\r\n"]
[130.196, "o", "                blocs.append(block_idx.blocs.copy() + length)\r\n"]
[130.206, "o", "                blengths.append(block_idx.blengths)\r\n"]
[130.216, "o", "                length += arr.sp_index.length\r\n"]
[130.226, "o", "\r\n"]
[130.236, "o", "            data = np.concatenate(values)\r\n"]
[130.246, "o", "            blocs_arr = np.concatenate(blocs)\r\n"]
[130.256, "o", "            blengths_arr = np.concatenate(blengths)\r\n"]
[130.266, "o", "\r\n"]
[130.276, "o", "            sp_index = BlockIndex(length, blocs_arr, blengths_arr)\r\n"]
[130.286, "o", "\r\n"]
[130.296, "o", "        return cls(data, sparse_index=sp_index, fill_value=fill_value)\r\n"]
[130.306, "o", "\r\n"]
[130.316, "o", "    def astype(self, dtype: AstypeArg | None = None, copy: bool = True):\r\n"]
[130.326, "o", "        \"\"\"\r\n"]
[130.336, "o", "        Change the dtype of a SparseArray.\r\n"]
[130.346, "o", "\r\n"]
[130.356, "o", "        The output will always be a SparseArray. To convert to a dense\r\n"]
[130.366, "o", "        ndarray with a certain dtype, use :meth:`numpy.asarray`.\r\n"]
[130.376, "o", "\r\n"]
[130.386, "o", "        Parameters\r\n"]
[130.396, "o", "        ----------\r\n"]
[130.406, "o", "        dtype : np.dtype or ExtensionDtype\r\n"]
[130.416, "o", "            For SparseDtype, this changes the dtype of\r\n"]
[130.426, "o", "            ``self.sp_values`` and the ``self.fill_value``.\r\n"]
[130.436, "o", "\r\n"]
[130.446, "o", "            For other dtypes, this only changes the dtype of\r\n"]
[130.456, "o", "            ``self.sp_values``.\r\n"]
[130.466, "o", "\r\n"]
[130.476, "o", "        copy : bool, default True\r\n"]
[130.486, "o", "            Whether to ensure a copy is made, even if not necessary.\r\n"]
[130.496, "o", "\r\n"]
[130.506, "o", "        Returns\r\n"]
[130.516, "o", "        -------\r\n"]
[130.526, "o", "        SparseArray\r\n"]
[130.536, "o", "\r\n"]
[130.546, "o", "        Examples\r\n"]
[130.556, "o", "        --------\r\n"]
[130.566, "o", "        >>> arr = pd.arrays.SparseArray([0, 0, 1, 2])\r\n"]
[130.576, "o", "        >>> arr\r\n"]
[130.586, "o", "        [0, 0, 1, 2]\r\n"]
[130.596, "o", "        Fill: 0\r\n"]
[130.606, "o", "        IntIndex\r\n"]
[130.616, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[130.626, "o", "\r\n"]
[130.636, "o", "        >>> arr.astype(SparseDtype(np.dtype('int32')))\r\n"]
[130.646, "o", "        [0, 0, 1, 2]\r\n"]
[130.656, "o", "        Fill: 0\r\n"]
[130.666, "o", "        IntIndex\r\n"]
[130.676, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[130.686, "o", "\r\n"]
[130.696, "o", "        Using a NumPy dtype with a different kind (e.g. float) will coerce\r\n"]
[130.706, "o", "        just ``self.sp_values``.\r\n"]
[130.716, "o", "\r\n"]
[130.726, "o", "        >>> arr.astype(SparseDtype(np.dtype('float64')))\r\n"]
[130.736, "o", "        ... # doctest: +NORMALIZE_WHITESPACE\r\n"]
[130.746, "o", "        [nan, nan, 1.0, 2.0]\r\n"]
[130.756, "o", "        Fill: nan\r\n"]
[130.766, "o", "        IntIndex\r\n"]
[130.776, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[130.786, "o", "\r\n"]
[130.796, "o", "        Using a SparseDtype, you can also change the fill value as well.\r\n"]
[130.806, "o", "\r\n"]
[130.816, "o", "        >>> arr.astype(SparseDtype(\"float64\", fill_value=0.0))\r\n"]
[130.826, "o", "        ... # doctest: +NORMALIZE_WHITESPACE\r\n"]
[130.836, "o", "        [0.0, 0.0, 1.0, 2.0]\r\n"]
[130.846, "o", "        Fill: 0.0\r\n"]
[130.856, "o", "        IntIndex\r\n"]
[130.866, "o", "        Indices: array([2, 3], dtype=int32)\r\n"]
[130.876, "o", "        \"\"\"\r\n"]
[130.886, "o", "        if is_dtype_equal(dtype, self._dtype):\r\n"]
[130.896, "o", "            if not copy:\r\n"]
[130.906, "o", "                return self\r\n"]
[130.916, "o", "            else:\r\n"]
[130.926, "o", "                return self.copy()\r\n"]
[130.936, "o", "\r\n"]
[130.946, "o", "        future_dtype = pandas_dtype(dtype)\r\n"]
[130.956, "o", "        if not isinstance(future_dtype, SparseDtype):\r\n"]
[130.966, "o", "            # GH#34457\r\n"]
[130.976, "o", "            values = np.asarray(self)\r\n"]
[130.986, "o", "            values = ensure_wrapped_if_datetimelike(values)\r\n"]
[130.996, "o", "            return astype_array(values, dtype=future_dtype, copy=False)\r\n"]
[131.006, "o", "\r\n"]
[131.016, "o", "        dtype = self.dtype.update_dtype(dtype)\r\n"]
[131.026, "o", "        subtype = pandas_dtype(dtype._subtype_with_str)\r\n"]
[131.036, "o", "        subtype = cast(np.dtype, subtype)  # ensured by update_dtype\r\n"]
[131.046, "o", "        values = ensure_wrapped_if_datetimelike(self.sp_values)\r\n"]
[131.056, "o", "        sp_values = astype_array(values, subtype, copy=copy)\r\n"]
[131.066, "o", "        sp_values = np.asarray(sp_values)\r\n"]
[131.076, "o", "\r\n"]
[131.086, "o", "        return self._simple_new(sp_values, self.sp_index, dtype)\r\n"]
[131.096, "o", "\r\n"]
[131.106, "o", "    def map(self, mapper, na_action=None) -> Self:\r\n"]
[131.116, "o", "        \"\"\"\r\n"]
[131.126, "o", "        Map categories using an input mapping or function.\r\n"]
[131.136, "o", "\r\n"]
[131.146, "o", "        Parameters\r\n"]
[131.156, "o", "        ----------\r\n"]
[131.166, "o", "        mapper : dict, Series, callable\r\n"]
[131.176, "o", "            The correspondence from old values to new.\r\n"]
[131.186, "o", "        na_action : {None, 'ignore'}, default None\r\n"]
[131.196, "o", "            If 'ignore', propagate NA values, without passing them to the\r\n"]
[131.206, "o", "            mapping correspondence.\r\n"]
[131.216, "o", "\r\n"]
[131.226, "o", "        Returns\r\n"]
[131.236, "o", "        -------\r\n"]
[131.246, "o", "        SparseArray\r\n"]
[131.256, "o", "            The output array will have the same density as the input.\r\n"]
[131.266, "o", "            The output fill value will be the result of applying the\r\n"]
[131.276, "o", "            mapping to ``self.fill_value``\r\n"]
[131.286, "o", "\r\n"]
[131.296, "o", "        Examples\r\n"]
[131.306, "o", "        --------\r\n"]
[131.316, "o", "        >>> arr = pd.arrays.SparseArray([0, 1, 2])\r\n"]
[131.326, "o", "        >>> arr.map(lambda x: x + 10)\r\n"]
[131.336, "o", "        [10, 11, 12]\r\n"]
[131.346, "o", "        Fill: 10\r\n"]
[131.356, "o", "        IntIndex\r\n"]
[131.366, "o", "        Indices: array([1, 2], dtype=int32)\r\n"]
[131.376, "o", "\r\n"]
[131.386, "o", "        >>> arr.map({0: 10, 1: 11, 2: 12})\r\n"]
[131.396, "o", "        [10, 11, 12]\r\n"]
[131.406, "o", "        Fill: 10\r\n"]
[131.416, "o", "        IntIndex\r\n"]
[131.426, "o", "        Indices: array([1, 2], dtype=int32)\r\n"]
[131.436, "o", "\r\n"]
[131.446, "o", "        >>> arr.map(pd.Series([10, 11, 12], index=[0, 1, 2]))\r\n"]
[131.456, "o", "        [10, 11, 12]\r\n"]
[131.466, "o", "        Fill: 10\r\n"]
[131.476, "o", "        IntIndex\r\n"]
[131.486, "o", "        Indices: array([1, 2], dtype=int32)\r\n"]
[131.496, "o", "        \"\"\"\r\n"]
[131.506, "o", "        is_map = isinstance(mapper, (abc.Mapping, ABCSeries))\r\n"]
[131.516, "o", "\r\n"]
[131.526, "o", "        fill_val = self.fill_value\r\n"]
[131.536, "o", "\r\n"]
[131.546, "o", "        if na_action is None or notna(fill_val):\r\n"]
[131.556, "o", "            fill_val = mapper.get(fill_val, fill_val) if is_map else mapper(fill_val)\r\n"]
[131.566, "o", "\r\n"]
[131.576, "o", "        def func(sp_val):\r\n"]
[131.586, "o", "            new_sp_val = mapper.get(sp_val, None) if is_map else mapper(sp_val)\r\n"]
[131.596, "o", "            # check identity and equality because nans are not equal to each other\r\n"]
[131.606, "o", "            if new_sp_val is fill_val or new_sp_val == fill_val:\r\n"]
[131.616, "o", "                msg = \"fill value in the sparse values not supported\"\r\n"]
[131.626, "o", "                raise ValueError(msg)\r\n"]
[131.636, "o", "            return new_sp_val\r\n"]
[131.646, "o", "\r\n"]
[131.656, "o", "        sp_values = [func(x) for x in self.sp_values]\r\n"]
[131.666, "o", "\r\n"]
[131.676, "o", "        return type(self)(sp_values, sparse_index=self.sp_index, fill_value=fill_val)\r\n"]
[131.686, "o", "\r\n"]
[131.696, "o", "    def to_dense(self) -> np.ndarray:\r\n"]
[131.706, "o", "        \"\"\"\r\n"]
[131.716, "o", "        Convert SparseArray to a NumPy array.\r\n"]
[131.726, "o", "\r\n"]
[131.736, "o", "        Returns\r\n"]
[131.746, "o", "        -------\r\n"]
[131.756, "o", "        arr : NumPy array\r\n"]
[131.766, "o", "        \"\"\"\r\n"]
[131.776, "o", "        return np.asarray(self, dtype=self.sp_values.dtype)\r\n"]
[131.786, "o", "\r\n"]
[131.796, "o", "    def _where(self, mask, value):\r\n"]
[131.806, "o", "        # NB: may not preserve dtype, e.g. result may be Sparse[float64]\r\n"]
[131.816, "o", "        #  while self is Sparse[int64]\r\n"]
[131.826, "o", "        naive_implementation = np.where(mask, self, value)\r\n"]
[131.836, "o", "        dtype = SparseDtype(naive_implementation.dtype, fill_value=self.fill_value)\r\n"]
[131.846, "o", "        result = type(self)._from_sequence(naive_implementation, dtype=dtype)\r\n"]
[131.856, "o", "        return result\r\n"]
[131.866, "o", "\r\n"]
[131.876, "o", "    # ------------------------------------------------------------------------\r\n"]
[131.886, "o", "    # IO\r\n"]
[131.896, "o", "    # ------------------------------------------------------------------------\r\n"]
[131.906, "o", "    def __setstate__(self, state) -> None:\r\n"]
[131.916, "o", "        \"\"\"Necessary for making this object picklable\"\"\"\r\n"]
[131.926, "o", "        if isinstance(state, tuple):\r\n"]
[131.936, "o", "            # Compat for pandas < 0.24.0\r\n"]
[131.946, "o", "            nd_state, (fill_value, sp_index) = state\r\n"]
[131.956, "o", "            sparse_values = np.array([])\r\n"]
[131.966, "o", "            sparse_values.__setstate__(nd_state)\r\n"]
[131.976, "o", "\r\n"]
[131.986, "o", "            self._sparse_values = sparse_values\r\n"]
[131.996, "o", "            self._sparse_index = sp_index\r\n"]
[132.006, "o", "            self._dtype = SparseDtype(sparse_values.dtype, fill_value)\r\n"]
[132.016, "o", "        else:\r\n"]
[132.026, "o", "            self.__dict__.update(state)\r\n"]
[132.036, "o", "\r\n"]
[132.046, "o", "    def nonzero(self) -> tuple[npt.NDArray[np.int32]]:\r\n"]
[132.056, "o", "        if self.fill_value == 0:\r\n"]
[132.066, "o", "            return (self.sp_index.indices,)\r\n"]
[132.076, "o", "        else:\r\n"]
[132.086, "o", "            return (self.sp_index.indices[self.sp_values != 0],)\r\n"]
[132.096, "o", "\r\n"]
[132.106, "o", "    # ------------------------------------------------------------------------\r\n"]
[132.116, "o", "    # Reductions\r\n"]
[132.126, "o", "    # ------------------------------------------------------------------------\r\n"]
[132.136, "o", "\r\n"]
[132.146, "o", "    def _reduce(self, name: str, *, skipna: bool = True, **kwargs):\r\n"]
[132.156, "o", "        method = getattr(self, name, None)\r\n"]
[132.166, "o", "\r\n"]
[132.176, "o", "        if method is None:\r\n"]
[132.186, "o", "            raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\r\n"]
[132.196, "o", "\r\n"]
[132.206, "o", "        if skipna:\r\n"]
[132.216, "o", "            arr = self\r\n"]
[132.226, "o", "        else:\r\n"]
[132.236, "o", "            arr = self.dropna()\r\n"]
[132.246, "o", "\r\n"]
[132.256, "o", "        return getattr(arr, name)(**kwargs)\r\n"]
[132.266, "o", "\r\n"]
[132.276, "o", "    def all(self, axis=None, *args, **kwargs):\r\n"]
[132.286, "o", "        \"\"\"\r\n"]
[132.296, "o", "        Tests whether all elements evaluate True\r\n"]
[132.306, "o", "\r\n"]
[132.316, "o", "        Returns\r\n"]
[132.326, "o", "        -------\r\n"]
[132.336, "o", "        all : bool\r\n"]
[132.346, "o", "\r\n"]
[132.356, "o", "        See Also\r\n"]
[132.366, "o", "        --------\r\n"]
[132.376, "o", "        numpy.all\r\n"]
[132.386, "o", "        \"\"\"\r\n"]
[132.396, "o", "        nv.validate_all(args, kwargs)\r\n"]
[132.406, "o", "\r\n"]
[132.416, "o", "        values = self.sp_values\r\n"]
[132.426, "o", "\r\n"]
[132.436, "o", "        if len(values) != len(self) and not np.all(self.fill_value):\r\n"]
[132.446, "o", "            return False\r\n"]
[132.456, "o", "\r\n"]
[132.466, "o", "        return values.all()\r\n"]
[132.476, "o", "\r\n"]
[132.486, "o", "    def any(self, axis: AxisInt = 0, *args, **kwargs):\r\n"]
[132.496, "o", "        \"\"\"\r\n"]
[132.506, "o", "        Tests whether at least one of elements evaluate True\r\n"]
[132.516, "o", "\r\n"]
[132.526, "o", "        Returns\r\n"]
[132.536, "o", "        -------\r\n"]
[132.546, "o", "        any : bool\r\n"]
[132.556, "o", "\r\n"]
[132.566, "o", "        See Also\r\n"]
[132.576, "o", "        --------\r\n"]
[132.586, "o", "        numpy.any\r\n"]
[132.596, "o", "        \"\"\"\r\n"]
[132.606, "o", "        nv.validate_any(args, kwargs)\r\n"]
[132.616, "o", "\r\n"]
[132.626, "o", "        values = self.sp_values\r\n"]
[132.636, "o", "\r\n"]
[132.646, "o", "        if len(values) != len(self) and np.any(self.fill_value):\r\n"]
[132.656, "o", "            return True\r\n"]
[132.666, "o", "\r\n"]
[132.676, "o", "        return values.any().item()\r\n"]
[132.686, "o", "\r\n"]
[132.696, "o", "    def sum(\r\n"]
[132.706, "o", "        self,\r\n"]
[132.716, "o", "        axis: AxisInt = 0,\r\n"]
[132.726, "o", "        min_count: int = 0,\r\n"]
[132.736, "o", "        skipna: bool = True,\r\n"]
[132.746, "o", "        *args,\r\n"]
[132.756, "o", "        **kwargs,\r\n"]
[132.766, "o", "    ) -> Scalar:\r\n"]
[132.776, "o", "        \"\"\"\r\n"]
[132.786, "o", "        Sum of non-NA/null values\r\n"]
[132.796, "o", "\r\n"]
[132.806, "o", "        Parameters\r\n"]
[132.816, "o", "        ----------\r\n"]
[132.826, "o", "        axis : int, default 0\r\n"]
[132.836, "o", "            Not Used. NumPy compatibility.\r\n"]
[132.846, "o", "        min_count : int, default 0\r\n"]
[132.856, "o", "            The required number of valid values to perform the summation. If fewer\r\n"]
[132.866, "o", "            than ``min_count`` valid values are present, the result will be the missing\r\n"]
[132.876, "o", "            value indicator for subarray type.\r\n"]
[132.886, "o", "        *args, **kwargs\r\n"]
[132.896, "o", "            Not Used. NumPy compatibility.\r\n"]
[132.906, "o", "\r\n"]
[132.916, "o", "        Returns\r\n"]
[132.926, "o", "        -------\r\n"]
[132.936, "o", "        scalar\r\n"]
[132.946, "o", "        \"\"\"\r\n"]
[132.956, "o", "        nv.validate_sum(args, kwargs)\r\n"]
[132.966, "o", "        valid_vals = self._valid_sp_values\r\n"]
[132.976, "o", "        sp_sum = valid_vals.sum()\r\n"]
[132.986, "o", "        has_na = self.sp_index.ngaps > 0 and not self._null_fill_value\r\n"]
[132.996, "o", "\r\n"]
[133.006, "o", "        if has_na and not skipna:\r\n"]
[133.016, "o", "            return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[133.026, "o", "\r\n"]
[133.036, "o", "        if self._null_fill_value:\r\n"]
[133.046, "o", "            if check_below_min_count(valid_vals.shape, None, min_count):\r\n"]
[133.056, "o", "                return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[133.066, "o", "            return sp_sum\r\n"]
[133.076, "o", "        else:\r\n"]
[133.086, "o", "            nsparse = self.sp_index.ngaps\r\n"]
[133.096, "o", "            if check_below_min_count(valid_vals.shape, None, min_count - nsparse):\r\n"]
[133.106, "o", "                return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[133.116, "o", "            return sp_sum + self.fill_value * nsparse\r\n"]
[133.126, "o", "\r\n"]
[133.136, "o", "    def cumsum(self, axis: AxisInt = 0, *args, **kwargs) -> SparseArray:\r\n"]
[133.146, "o", "        \"\"\"\r\n"]
[133.156, "o", "        Cumulative sum of non-NA/null values.\r\n"]
[133.166, "o", "\r\n"]
[133.176, "o", "        When performing the cumulative summation, any non-NA/null values will\r\n"]
[133.186, "o", "        be skipped. The resulting SparseArray will preserve the locations of\r\n"]
[133.196, "o", "        NaN values, but the fill value will be `np.nan` regardless.\r\n"]
[133.206, "o", "\r\n"]
[133.216, "o", "        Parameters\r\n"]
[133.226, "o", "        ----------\r\n"]
[133.236, "o", "        axis : int or None\r\n"]
[133.246, "o", "            Axis over which to perform the cumulative summation. If None,\r\n"]
[133.256, "o", "            perform cumulative summation over flattened array.\r\n"]
[133.266, "o", "\r\n"]
[133.276, "o", "        Returns\r\n"]
[133.286, "o", "        -------\r\n"]
[133.296, "o", "        cumsum : SparseArray\r\n"]
[133.306, "o", "        \"\"\"\r\n"]
[133.316, "o", "        nv.validate_cumsum(args, kwargs)\r\n"]
[133.326, "o", "\r\n"]
[133.336, "o", "        if axis is not None and axis >= self.ndim:  # Mimic ndarray behaviour.\r\n"]
[133.346, "o", "            raise ValueError(f\"axis(={axis}) out of bounds\")\r\n"]
[133.356, "o", "\r\n"]
[133.366, "o", "        if not self._null_fill_value:\r\n"]
[133.376, "o", "            return SparseArray(self.to_dense()).cumsum()\r\n"]
[133.386, "o", "\r\n"]
[133.396, "o", "        return SparseArray(\r\n"]
[133.406, "o", "            self.sp_values.cumsum(),\r\n"]
[133.416, "o", "            sparse_index=self.sp_index,\r\n"]
[133.426, "o", "            fill_value=self.fill_value,\r\n"]
[133.436, "o", "        )\r\n"]
[133.446, "o", "\r\n"]
[133.456, "o", "    def mean(self, axis: Axis = 0, *args, **kwargs):\r\n"]
[133.466, "o", "        \"\"\"\r\n"]
[133.476, "o", "        Mean of non-NA/null values\r\n"]
[133.486, "o", "\r\n"]
[133.496, "o", "        Returns\r\n"]
[133.506, "o", "        -------\r\n"]
[133.516, "o", "        mean : float\r\n"]
[133.526, "o", "        \"\"\"\r\n"]
[133.536, "o", "        nv.validate_mean(args, kwargs)\r\n"]
[133.546, "o", "        valid_vals = self._valid_sp_values\r\n"]
[133.556, "o", "        sp_sum = valid_vals.sum()\r\n"]
[133.566, "o", "        ct = len(valid_vals)\r\n"]
[133.576, "o", "\r\n"]
[133.586, "o", "        if self._null_fill_value:\r\n"]
[133.596, "o", "            return sp_sum / ct\r\n"]
[133.606, "o", "        else:\r\n"]
[133.616, "o", "            nsparse = self.sp_index.ngaps\r\n"]
[133.626, "o", "            return (sp_sum + self.fill_value * nsparse) / (ct + nsparse)\r\n"]
[133.636, "o", "\r\n"]
[133.646, "o", "    def max(self, *, axis: AxisInt | None = None, skipna: bool = True):\r\n"]
[133.656, "o", "        \"\"\"\r\n"]
[133.666, "o", "        Max of array values, ignoring NA values if specified.\r\n"]
[133.676, "o", "\r\n"]
[133.686, "o", "        Parameters\r\n"]
[133.696, "o", "        ----------\r\n"]
[133.706, "o", "        axis : int, default 0\r\n"]
[133.716, "o", "            Not Used. NumPy compatibility.\r\n"]
[133.726, "o", "        skipna : bool, default True\r\n"]
[133.736, "o", "            Whether to ignore NA values.\r\n"]
[133.746, "o", "\r\n"]
[133.756, "o", "        Returns\r\n"]
[133.766, "o", "        -------\r\n"]
[133.776, "o", "        scalar\r\n"]
[133.786, "o", "        \"\"\"\r\n"]
[133.796, "o", "        nv.validate_minmax_axis(axis, self.ndim)\r\n"]
[133.806, "o", "        return self._min_max(\"max\", skipna=skipna)\r\n"]
[133.816, "o", "\r\n"]
[133.826, "o", "    def min(self, *, axis: AxisInt | None = None, skipna: bool = True):\r\n"]
[133.836, "o", "        \"\"\"\r\n"]
[133.846, "o", "        Min of array values, ignoring NA values if specified.\r\n"]
[133.856, "o", "\r\n"]
[133.866, "o", "        Parameters\r\n"]
[133.876, "o", "        ----------\r\n"]
[133.886, "o", "        axis : int, default 0\r\n"]
[133.896, "o", "            Not Used. NumPy compatibility.\r\n"]
[133.906, "o", "        skipna : bool, default True\r\n"]
[133.916, "o", "            Whether to ignore NA values.\r\n"]
[133.926, "o", "\r\n"]
[133.936, "o", "        Returns\r\n"]
[133.946, "o", "        -------\r\n"]
[133.956, "o", "        scalar\r\n"]
[133.966, "o", "        \"\"\"\r\n"]
[133.976, "o", "        nv.validate_minmax_axis(axis, self.ndim)\r\n"]
[133.986, "o", "        return self._min_max(\"min\", skipna=skipna)\r\n"]
[133.996, "o", "\r\n"]
[134.006, "o", "    def _min_max(self, kind: Literal[\"min\", \"max\"], skipna: bool) -> Scalar:\r\n"]
[134.016, "o", "        \"\"\"\r\n"]
[134.026, "o", "        Min/max of non-NA/null values\r\n"]
[134.036, "o", "\r\n"]
[134.046, "o", "        Parameters\r\n"]
[134.056, "o", "        ----------\r\n"]
[134.066, "o", "        kind : {\"min\", \"max\"}\r\n"]
[134.076, "o", "        skipna : bool\r\n"]
[134.086, "o", "\r\n"]
[134.096, "o", "        Returns\r\n"]
[134.106, "o", "        -------\r\n"]
[134.116, "o", "        scalar\r\n"]
[134.126, "o", "        \"\"\"\r\n"]
[134.136, "o", "        valid_vals = self._valid_sp_values\r\n"]
[134.146, "o", "        has_nonnull_fill_vals = not self._null_fill_value and self.sp_index.ngaps > 0\r\n"]
[134.156, "o", "\r\n"]
[134.166, "o", "        if len(valid_vals) > 0:\r\n"]
[134.176, "o", "            sp_min_max = getattr(valid_vals, kind)()\r\n"]
[134.186, "o", "\r\n"]
[134.196, "o", "            # If a non-null fill value is currently present, it might be the min/max\r\n"]
[134.206, "o", "            if has_nonnull_fill_vals:\r\n"]
[134.216, "o", "                func = max if kind == \"max\" else min\r\n"]
[134.226, "o", "                return func(sp_min_max, self.fill_value)\r\n"]
[134.236, "o", "            elif skipna:\r\n"]
[134.246, "o", "                return sp_min_max\r\n"]
[134.256, "o", "            elif self.sp_index.ngaps == 0:\r\n"]
[134.266, "o", "                # No NAs present\r\n"]
[134.276, "o", "                return sp_min_max\r\n"]
[134.286, "o", "            else:\r\n"]
[134.296, "o", "                return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[134.306, "o", "        elif has_nonnull_fill_vals:\r\n"]
[134.316, "o", "            return self.fill_value\r\n"]
[134.326, "o", "        else:\r\n"]
[134.336, "o", "            return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[134.346, "o", "\r\n"]
[134.356, "o", "    def _argmin_argmax(self, kind: Literal[\"argmin\", \"argmax\"]) -> int:\r\n"]
[134.366, "o", "        values = self._sparse_values\r\n"]
[134.376, "o", "        index = self._sparse_index.indices\r\n"]
[134.386, "o", "        mask = np.asarray(isna(values))\r\n"]
[134.396, "o", "        func = np.argmax if kind == \"argmax\" else np.argmin\r\n"]
[134.406, "o", "\r\n"]
[134.416, "o", "        idx = np.arange(values.shape[0])\r\n"]
[134.426, "o", "        non_nans = values[~mask]\r\n"]
[134.436, "o", "        non_nan_idx = idx[~mask]\r\n"]
[134.446, "o", "\r\n"]
[134.456, "o", "        _candidate = non_nan_idx[func(non_nans)]\r\n"]
[134.466, "o", "        candidate = index[_candidate]\r\n"]
[134.476, "o", "\r\n"]
[134.486, "o", "        if isna(self.fill_value):\r\n"]
[134.496, "o", "            return candidate\r\n"]
[134.506, "o", "        if kind == \"argmin\" and self[candidate] < self.fill_value:\r\n"]
[134.516, "o", "            return candidate\r\n"]
[134.526, "o", "        if kind == \"argmax\" and self[candidate] > self.fill_value:\r\n"]
[134.536, "o", "            return candidate\r\n"]
[134.546, "o", "        _loc = self._first_fill_value_loc()\r\n"]
[134.556, "o", "        if _loc == -1:\r\n"]
[134.566, "o", "            # fill_value doesn't exist\r\n"]
[134.576, "o", "            return candidate\r\n"]
[134.586, "o", "        else:\r\n"]
[134.596, "o", "            return _loc\r\n"]
[134.606, "o", "\r\n"]
[134.616, "o", "    def argmax(self, skipna: bool = True) -> int:\r\n"]
[134.626, "o", "        validate_bool_kwarg(skipna, \"skipna\")\r\n"]
[134.636, "o", "        if not skipna and self._hasna:\r\n"]
[134.646, "o", "            raise NotImplementedError\r\n"]
[134.656, "o", "        return self._argmin_argmax(\"argmax\")\r\n"]
[134.666, "o", "\r\n"]
[134.676, "o", "    def argmin(self, skipna: bool = True) -> int:\r\n"]
[134.686, "o", "        validate_bool_kwarg(skipna, \"skipna\")\r\n"]
[134.696, "o", "        if not skipna and self._hasna:\r\n"]
[134.706, "o", "            raise NotImplementedError\r\n"]
[134.716, "o", "        return self._argmin_argmax(\"argmin\")\r\n"]
[134.726, "o", "\r\n"]
[134.736, "o", "    # ------------------------------------------------------------------------\r\n"]
[134.746, "o", "    # Ufuncs\r\n"]
[134.756, "o", "    # ------------------------------------------------------------------------\r\n"]
[134.766, "o", "\r\n"]
[134.776, "o", "    _HANDLED_TYPES = (np.ndarray, numbers.Number)\r\n"]
[134.786, "o", "\r\n"]
[134.796, "o", "    def __array_ufunc__(self, ufunc: np.ufunc, method: str, *inputs, **kwargs):\r\n"]
[134.806, "o", "        out = kwargs.get(\"out\", ())\r\n"]
[134.816, "o", "\r\n"]
[134.826, "o", "        for x in inputs + out:\r\n"]
[134.836, "o", "            if not isinstance(x, self._HANDLED_TYPES + (SparseArray,)):\r\n"]
[134.846, "o", "                return NotImplemented\r\n"]
[134.856, "o", "\r\n"]
[134.866, "o", "        # for binary ops, use our custom dunder methods\r\n"]
[134.876, "o", "        result = arraylike.maybe_dispatch_ufunc_to_dunder_op(\r\n"]
[134.886, "o", "            self, ufunc, method, *inputs, **kwargs\r\n"]
[134.896, "o", "        )\r\n"]
[134.906, "o", "        if result is not NotImplemented:\r\n"]
[134.916, "o", "            return result\r\n"]
[134.926, "o", "\r\n"]
[134.936, "o", "        if \"out\" in kwargs:\r\n"]
[135.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[135.002, "i", "sed -n '1,200p' pandas/core/arrays/sparse/dtype.py\r"]
[135.004, "o", "sed -n '1,200p' pandas/core/arrays/sparse/dtype.py\r\n"]
[135.030597, "o", "\u001b[?2004l\r\n"]
[135.055194, "o", "\"\"\"Sparse Dtype\"\"\"\r\n"]
[135.079791, "o", "from __future__ import annotations\r\n"]
[135.104388, "o", "\r\n"]
[135.128985, "o", "import re\r\n"]
[135.153582, "o", "from typing import (\r\n"]
[135.178179, "o", "    TYPE_CHECKING,\r\n"]
[135.202776, "o", "    Any,\r\n"]
[135.227373, "o", ")\r\n"]
[135.25197, "o", "import warnings\r\n"]
[135.276567, "o", "\r\n"]
[135.301164, "o", "import numpy as np\r\n"]
[135.325761, "o", "\r\n"]
[135.350358, "o", "from pandas.errors import PerformanceWarning\r\n"]
[135.374955, "o", "from pandas.util._exceptions import find_stack_level\r\n"]
[135.399552, "o", "\r\n"]
[135.424149, "o", "from pandas.core.dtypes.astype import astype_array\r\n"]
[135.448746, "o", "from pandas.core.dtypes.base import (\r\n"]
[135.473343, "o", "    ExtensionDtype,\r\n"]
[135.49794, "o", "    register_extension_dtype,\r\n"]
[135.522537, "o", ")\r\n"]
[135.547134, "o", "from pandas.core.dtypes.common import (\r\n"]
[135.571731, "o", "    is_bool_dtype,\r\n"]
[135.596328, "o", "    is_object_dtype,\r\n"]
[135.620925, "o", "    is_scalar,\r\n"]
[135.645522, "o", "    is_string_dtype,\r\n"]
[135.670119, "o", "    pandas_dtype,\r\n"]
[135.694716, "o", ")\r\n"]
[135.719313, "o", "from pandas.core.dtypes.missing import (\r\n"]
[135.74391, "o", "    isna,\r\n"]
[135.768507, "o", "    na_value_for_dtype,\r\n"]
[135.793104, "o", ")\r\n"]
[135.817701, "o", "\r\n"]
[135.842299, "o", "if TYPE_CHECKING:\r\n"]
[135.866896, "o", "    from pandas._typing import (\r\n"]
[135.891493, "o", "        Dtype,\r\n"]
[135.91609, "o", "        DtypeObj,\r\n"]
[135.940687, "o", "        type_t,\r\n"]
[135.965284, "o", "    )\r\n"]
[135.989881, "o", "\r\n"]
[136.014478, "o", "    from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[136.039075, "o", "\r\n"]
[136.063672, "o", "\r\n"]
[136.088269, "o", "@register_extension_dtype\r\n"]
[136.112866, "o", "class SparseDtype(ExtensionDtype):\r\n"]
[136.137463, "o", "    \"\"\"\r\n"]
[136.16206, "o", "    Dtype for data stored in :class:`SparseArray`.\r\n"]
[136.186657, "o", "\r\n"]
[136.211254, "o", "    This dtype implements the pandas ExtensionDtype interface.\r\n"]
[136.235851, "o", "\r\n"]
[136.260448, "o", "    Parameters\r\n"]
[136.285045, "o", "    ----------\r\n"]
[136.309642, "o", "    dtype : str, ExtensionDtype, numpy.dtype, type, default numpy.float64\r\n"]
[136.334239, "o", "        The dtype of the underlying array storing the non-fill value values.\r\n"]
[136.358836, "o", "    fill_value : scalar, optional\r\n"]
[136.383433, "o", "        The scalar value not stored in the SparseArray. By default, this\r\n"]
[136.40803, "o", "        depends on `dtype`.\r\n"]
[136.432627, "o", "\r\n"]
[136.457224, "o", "        =========== ==========\r\n"]
[136.481821, "o", "        dtype       na_value\r\n"]
[136.506418, "o", "        =========== ==========\r\n"]
[136.531015, "o", "        float       ``np.nan``\r\n"]
[136.555612, "o", "        int         ``0``\r\n"]
[136.580209, "o", "        bool        ``False``\r\n"]
[136.604806, "o", "        datetime64  ``pd.NaT``\r\n"]
[136.629403, "o", "        timedelta64 ``pd.NaT``\r\n"]
[136.654, "o", "        =========== ==========\r\n"]
[136.678597, "o", "\r\n"]
[136.703194, "o", "        The default value may be overridden by specifying a `fill_value`.\r\n"]
[136.727791, "o", "\r\n"]
[136.752388, "o", "    Attributes\r\n"]
[136.776985, "o", "    ----------\r\n"]
[136.801582, "o", "    None\r\n"]
[136.826179, "o", "\r\n"]
[136.850776, "o", "    Methods\r\n"]
[136.875373, "o", "    -------\r\n"]
[136.89997, "o", "    None\r\n"]
[136.924567, "o", "    \"\"\"\r\n"]
[136.949164, "o", "\r\n"]
[136.973761, "o", "    # We include `_is_na_fill_value` in the metadata to avoid hash collisions\r\n"]
[136.998358, "o", "    # between SparseDtype(float, 0.0) and SparseDtype(float, nan).\r\n"]
[137.022955, "o", "    # Without is_na_fill_value in the comparison, those would be equal since\r\n"]
[137.047552, "o", "    # hash(nan) is (sometimes?) 0.\r\n"]
[137.072149, "o", "    _metadata = (\"_dtype\", \"_fill_value\", \"_is_na_fill_value\")\r\n"]
[137.096746, "o", "\r\n"]
[137.121343, "o", "    def __init__(self, dtype: Dtype = np.float64, fill_value: Any = None) -> None:\r\n"]
[137.14594, "o", "        if isinstance(dtype, type(self)):\r\n"]
[137.170537, "o", "            if fill_value is None:\r\n"]
[137.195134, "o", "                fill_value = dtype.fill_value\r\n"]
[137.219731, "o", "            dtype = dtype.subtype\r\n"]
[137.244328, "o", "\r\n"]
[137.268925, "o", "        dtype = pandas_dtype(dtype)\r\n"]
[137.293522, "o", "        if is_string_dtype(dtype):\r\n"]
[137.318119, "o", "            dtype = np.dtype(\"object\")\r\n"]
[137.342716, "o", "\r\n"]
[137.367313, "o", "        if fill_value is None:\r\n"]
[137.39191, "o", "            fill_value = na_value_for_dtype(dtype)\r\n"]
[137.416507, "o", "\r\n"]
[137.441104, "o", "        self._dtype = dtype\r\n"]
[137.465701, "o", "        self._fill_value = fill_value\r\n"]
[137.490299, "o", "        self._check_fill_value()\r\n"]
[137.514896, "o", "\r\n"]
[137.539493, "o", "    def __hash__(self) -> int:\r\n"]
[137.56409, "o", "        # Python3 doesn't inherit __hash__ when a base class overrides\r\n"]
[137.588687, "o", "        # __eq__, so we explicitly do it here.\r\n"]
[137.613284, "o", "        return super().__hash__()\r\n"]
[137.637881, "o", "\r\n"]
[137.662478, "o", "    def __eq__(self, other: Any) -> bool:\r\n"]
[137.687075, "o", "        # We have to override __eq__ to handle NA values in _metadata.\r\n"]
[137.711672, "o", "        # The base class does simple == checks, which fail for NA.\r\n"]
[137.736269, "o", "        if isinstance(other, str):\r\n"]
[137.760866, "o", "            try:\r\n"]
[137.785463, "o", "                other = self.construct_from_string(other)\r\n"]
[137.81006, "o", "            except TypeError:\r\n"]
[137.834657, "o", "                return False\r\n"]
[137.859254, "o", "\r\n"]
[137.883851, "o", "        if isinstance(other, type(self)):\r\n"]
[137.908448, "o", "            subtype = self.subtype == other.subtype\r\n"]
[137.933045, "o", "            if self._is_na_fill_value:\r\n"]
[137.957642, "o", "                # this case is complicated by two things:\r\n"]
[137.982239, "o", "                # SparseDtype(float, float(nan)) == SparseDtype(float, np.nan)\r\n"]
[138.006836, "o", "                # SparseDtype(float, np.nan)     != SparseDtype(float, pd.NaT)\r\n"]
[138.031433, "o", "                # i.e. we want to treat any floating-point NaN as equal, but\r\n"]
[138.05603, "o", "                # not a floating-point NaN and a datetime NaT.\r\n"]
[138.080627, "o", "                fill_value = (\r\n"]
[138.105224, "o", "                    other._is_na_fill_value\r\n"]
[138.129821, "o", "                    and isinstance(self.fill_value, type(other.fill_value))\r\n"]
[138.154418, "o", "                    or isinstance(other.fill_value, type(self.fill_value))\r\n"]
[138.179015, "o", "                )\r\n"]
[138.203612, "o", "            else:\r\n"]
[138.228209, "o", "                with warnings.catch_warnings():\r\n"]
[138.252806, "o", "                    # Ignore spurious numpy warning\r\n"]
[138.277403, "o", "                    warnings.filterwarnings(\r\n"]
[138.302, "o", "                        \"ignore\",\r\n"]
[138.326597, "o", "                        \"elementwise comparison failed\",\r\n"]
[138.351194, "o", "                        category=DeprecationWarning,\r\n"]
[138.375791, "o", "                    )\r\n"]
[138.400388, "o", "\r\n"]
[138.424985, "o", "                    fill_value = self.fill_value == other.fill_value\r\n"]
[138.449582, "o", "\r\n"]
[138.474179, "o", "            return subtype and fill_value\r\n"]
[138.498776, "o", "        return False\r\n"]
[138.523373, "o", "\r\n"]
[138.54797, "o", "    @property\r\n"]
[138.572567, "o", "    def fill_value(self):\r\n"]
[138.597164, "o", "        \"\"\"\r\n"]
[138.621761, "o", "        The fill value of the array.\r\n"]
[138.646358, "o", "\r\n"]
[138.670955, "o", "        Converting the SparseArray to a dense ndarray will fill the\r\n"]
[138.695552, "o", "        array with this value.\r\n"]
[138.720149, "o", "\r\n"]
[138.744746, "o", "        .. warning::\r\n"]
[138.769343, "o", "\r\n"]
[138.79394, "o", "           It's possible to end up with a SparseArray that has ``fill_value``\r\n"]
[138.818537, "o", "           values in ``sp_values``. This can occur, for example, when setting\r\n"]
[138.843134, "o", "           ``SparseArray.fill_value`` directly.\r\n"]
[138.867731, "o", "        \"\"\"\r\n"]
[138.892328, "o", "        return self._fill_value\r\n"]
[138.916925, "o", "\r\n"]
[138.941522, "o", "    def _check_fill_value(self):\r\n"]
[138.966119, "o", "        if not is_scalar(self._fill_value):\r\n"]
[138.990716, "o", "            raise ValueError(\r\n"]
[139.015313, "o", "                f\"fill_value must be a scalar. Got {self._fill_value} instead\"\r\n"]
[139.03991, "o", "            )\r\n"]
[139.064507, "o", "        # TODO: Right now we can use Sparse boolean array\r\n"]
[139.089104, "o", "        #       with any fill_value. Here was an attempt\r\n"]
[139.113701, "o", "        #       to allow only 3 value: True, False or nan\r\n"]
[139.138299, "o", "        #       but plenty test has failed.\r\n"]
[139.162896, "o", "        # see pull 44955\r\n"]
[139.187493, "o", "        # if self._is_boolean and not (\r\n"]
[139.21209, "o", "        #    is_bool(self._fill_value) or isna(self._fill_value)\r\n"]
[139.236687, "o", "        # ):\r\n"]
[139.261284, "o", "        #    raise ValueError(\r\n"]
[139.285881, "o", "        #        \"fill_value must be True, False or nan \"\r\n"]
[139.310478, "o", "        #        f\"for boolean type. Got {self._fill_value} instead\"\r\n"]
[139.335075, "o", "        #    )\r\n"]
[139.359672, "o", "\r\n"]
[139.384269, "o", "    @property\r\n"]
[139.408866, "o", "    def _is_na_fill_value(self) -> bool:\r\n"]
[139.433463, "o", "        return isna(self.fill_value)\r\n"]
[139.45806, "o", "\r\n"]
[139.482657, "o", "    @property\r\n"]
[139.507254, "o", "    def _is_numeric(self) -> bool:\r\n"]
[139.531851, "o", "        return not is_object_dtype(self.subtype)\r\n"]
[139.556448, "o", "\r\n"]
[139.581045, "o", "    @property\r\n"]
[139.605642, "o", "    def _is_boolean(self) -> bool:\r\n"]
[139.630239, "o", "        return is_bool_dtype(self.subtype)\r\n"]
[139.654836, "o", "\r\n"]
[139.679433, "o", "    @property\r\n"]
[139.70403, "o", "    def kind(self) -> str:\r\n"]
[139.728627, "o", "        \"\"\"\r\n"]
[139.753224, "o", "        The sparse kind. Either 'integer', or 'block'.\r\n"]
[139.777821, "o", "        \"\"\"\r\n"]
[139.802418, "o", "        return self.subtype.kind\r\n"]
[139.827015, "o", "\r\n"]
[139.851612, "o", "    @property\r\n"]
[139.876209, "o", "    def type(self):\r\n"]
[139.900806, "o", "        return self.subtype.type\r\n"]
[139.925403, "o", "\r\n"]
[140.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[140.002, "i", "sed -n '1,260p' pandas/core/arrays/_mixins.py\r"]
[140.004, "o", "sed -n '1,260p' pandas/core/arrays/_mixins.py\r\n"]
[140.024943, "o", "\u001b[?2004l\r\n"]
[140.043885, "o", "from __future__ import annotations\r\n"]
[140.062828, "o", "\r\n"]
[140.08177, "o", "from functools import wraps\r\n"]
[140.100713, "o", "from typing import (\r\n"]
[140.119655, "o", "    TYPE_CHECKING,\r\n"]
[140.138598, "o", "    Any,\r\n"]
[140.15754, "o", "    Literal,\r\n"]
[140.176483, "o", "    Sequence,\r\n"]
[140.195425, "o", "    cast,\r\n"]
[140.214368, "o", "    overload,\r\n"]
[140.23331, "o", ")\r\n"]
[140.252253, "o", "\r\n"]
[140.271195, "o", "import numpy as np\r\n"]
[140.290138, "o", "\r\n"]
[140.30908, "o", "from pandas._libs import lib\r\n"]
[140.328023, "o", "from pandas._libs.arrays import NDArrayBacked\r\n"]
[140.346966, "o", "from pandas._typing import (\r\n"]
[140.365908, "o", "    ArrayLike,\r\n"]
[140.384851, "o", "    AxisInt,\r\n"]
[140.403793, "o", "    Dtype,\r\n"]
[140.422736, "o", "    F,\r\n"]
[140.441678, "o", "    PositionalIndexer2D,\r\n"]
[140.460621, "o", "    PositionalIndexerTuple,\r\n"]
[140.479563, "o", "    ScalarIndexer,\r\n"]
[140.498506, "o", "    Self,\r\n"]
[140.517448, "o", "    SequenceIndexer,\r\n"]
[140.536391, "o", "    Shape,\r\n"]
[140.555333, "o", "    TakeIndexer,\r\n"]
[140.574276, "o", "    npt,\r\n"]
[140.593218, "o", ")\r\n"]
[140.612161, "o", "from pandas.errors import AbstractMethodError\r\n"]
[140.631103, "o", "from pandas.util._decorators import doc\r\n"]
[140.650046, "o", "from pandas.util._validators import (\r\n"]
[140.668989, "o", "    validate_bool_kwarg,\r\n"]
[140.687931, "o", "    validate_fillna_kwargs,\r\n"]
[140.706874, "o", "    validate_insert_loc,\r\n"]
[140.725816, "o", ")\r\n"]
[140.744759, "o", "\r\n"]
[140.763701, "o", "from pandas.core.dtypes.common import (\r\n"]
[140.782644, "o", "    is_dtype_equal,\r\n"]
[140.801586, "o", "    pandas_dtype,\r\n"]
[140.820529, "o", ")\r\n"]
[140.839471, "o", "from pandas.core.dtypes.dtypes import (\r\n"]
[140.858414, "o", "    DatetimeTZDtype,\r\n"]
[140.877356, "o", "    ExtensionDtype,\r\n"]
[140.896299, "o", "    PeriodDtype,\r\n"]
[140.915241, "o", ")\r\n"]
[140.934184, "o", "from pandas.core.dtypes.missing import array_equivalent\r\n"]
[140.953126, "o", "\r\n"]
[140.972069, "o", "from pandas.core import missing\r\n"]
[140.991011, "o", "from pandas.core.algorithms import (\r\n"]
[141.009954, "o", "    take,\r\n"]
[141.028897, "o", "    unique,\r\n"]
[141.047839, "o", "    value_counts,\r\n"]
[141.066782, "o", ")\r\n"]
[141.085724, "o", "from pandas.core.array_algos.quantile import quantile_with_mask\r\n"]
[141.104667, "o", "from pandas.core.array_algos.transforms import shift\r\n"]
[141.123609, "o", "from pandas.core.arrays.base import ExtensionArray\r\n"]
[141.142552, "o", "from pandas.core.construction import extract_array\r\n"]
[141.161494, "o", "from pandas.core.indexers import check_array_indexer\r\n"]
[141.180437, "o", "from pandas.core.sorting import nargminmax\r\n"]
[141.199379, "o", "\r\n"]
[141.218322, "o", "if TYPE_CHECKING:\r\n"]
[141.237264, "o", "    from pandas._typing import (\r\n"]
[141.256207, "o", "        NumpySorter,\r\n"]
[141.275149, "o", "        NumpyValueArrayLike,\r\n"]
[141.294092, "o", "    )\r\n"]
[141.313034, "o", "\r\n"]
[141.331977, "o", "    from pandas import Series\r\n"]
[141.35092, "o", "\r\n"]
[141.369862, "o", "\r\n"]
[141.388805, "o", "def ravel_compat(meth: F) -> F:\r\n"]
[141.407747, "o", "    \"\"\"\r\n"]
[141.42669, "o", "    Decorator to ravel a 2D array before passing it to a cython operation,\r\n"]
[141.445632, "o", "    then reshape the result to our own shape.\r\n"]
[141.464575, "o", "    \"\"\"\r\n"]
[141.483517, "o", "\r\n"]
[141.50246, "o", "    @wraps(meth)\r\n"]
[141.521402, "o", "    def method(self, *args, **kwargs):\r\n"]
[141.540345, "o", "        if self.ndim == 1:\r\n"]
[141.559287, "o", "            return meth(self, *args, **kwargs)\r\n"]
[141.57823, "o", "\r\n"]
[141.597172, "o", "        flags = self._ndarray.flags\r\n"]
[141.616115, "o", "        flat = self.ravel(\"K\")\r\n"]
[141.635057, "o", "        result = meth(flat, *args, **kwargs)\r\n"]
[141.654, "o", "        order = \"F\" if flags.f_contiguous else \"C\"\r\n"]
[141.672943, "o", "        return result.reshape(self.shape, order=order)\r\n"]
[141.691885, "o", "\r\n"]
[141.710828, "o", "    return cast(F, method)\r\n"]
[141.72977, "o", "\r\n"]
[141.748713, "o", "\r\n"]
[141.767655, "o", "class NDArrayBackedExtensionArray(NDArrayBacked, ExtensionArray):\r\n"]
[141.786598, "o", "    \"\"\"\r\n"]
[141.80554, "o", "    ExtensionArray that is backed by a single NumPy ndarray.\r\n"]
[141.824483, "o", "    \"\"\"\r\n"]
[141.843425, "o", "\r\n"]
[141.862368, "o", "    _ndarray: np.ndarray\r\n"]
[141.88131, "o", "\r\n"]
[141.900253, "o", "    # scalar used to denote NA value inside our self._ndarray, e.g. -1\r\n"]
[141.919195, "o", "    #  for Categorical, iNaT for Period. Outside of object dtype,\r\n"]
[141.938138, "o", "    #  self.isna() should be exactly locations in self._ndarray with\r\n"]
[141.95708, "o", "    #  _internal_fill_value.\r\n"]
[141.976023, "o", "    _internal_fill_value: Any\r\n"]
[141.994966, "o", "\r\n"]
[142.013908, "o", "    def _box_func(self, x):\r\n"]
[142.032851, "o", "        \"\"\"\r\n"]
[142.051793, "o", "        Wrap numpy type in our dtype.type if necessary.\r\n"]
[142.070736, "o", "        \"\"\"\r\n"]
[142.089678, "o", "        return x\r\n"]
[142.108621, "o", "\r\n"]
[142.127563, "o", "    def _validate_scalar(self, value):\r\n"]
[142.146506, "o", "        # used by NDArrayBackedExtensionIndex.insert\r\n"]
[142.165448, "o", "        raise AbstractMethodError(self)\r\n"]
[142.184391, "o", "\r\n"]
[142.203333, "o", "    # ------------------------------------------------------------------------\r\n"]
[142.222276, "o", "\r\n"]
[142.241218, "o", "    def view(self, dtype: Dtype | None = None) -> ArrayLike:\r\n"]
[142.260161, "o", "        # We handle datetime64, datetime64tz, timedelta64, and period\r\n"]
[142.279103, "o", "        #  dtypes here. Everything else we pass through to the underlying\r\n"]
[142.298046, "o", "        #  ndarray.\r\n"]
[142.316989, "o", "        if dtype is None or dtype is self.dtype:\r\n"]
[142.335931, "o", "            return self._from_backing_data(self._ndarray)\r\n"]
[142.354874, "o", "\r\n"]
[142.373816, "o", "        if isinstance(dtype, type):\r\n"]
[142.392759, "o", "            # we sometimes pass non-dtype objects, e.g np.ndarray;\r\n"]
[142.411701, "o", "            #  pass those through to the underlying ndarray\r\n"]
[142.430644, "o", "            return self._ndarray.view(dtype)\r\n"]
[142.449586, "o", "\r\n"]
[142.468529, "o", "        dtype = pandas_dtype(dtype)\r\n"]
[142.487471, "o", "        arr = self._ndarray\r\n"]
[142.506414, "o", "\r\n"]
[142.525356, "o", "        if isinstance(dtype, (PeriodDtype, DatetimeTZDtype)):\r\n"]
[142.544299, "o", "            cls = dtype.construct_array_type()\r\n"]
[142.563241, "o", "            return cls(arr.view(\"i8\"), dtype=dtype)\r\n"]
[142.582184, "o", "        elif dtype == \"M8[ns]\":\r\n"]
[142.601126, "o", "            from pandas.core.arrays import DatetimeArray\r\n"]
[142.620069, "o", "\r\n"]
[142.639011, "o", "            return DatetimeArray(arr.view(\"i8\"), dtype=dtype)\r\n"]
[142.657954, "o", "        elif dtype == \"m8[ns]\":\r\n"]
[142.676897, "o", "            from pandas.core.arrays import TimedeltaArray\r\n"]
[142.695839, "o", "\r\n"]
[142.714782, "o", "            return TimedeltaArray(arr.view(\"i8\"), dtype=dtype)\r\n"]
[142.733724, "o", "\r\n"]
[142.752667, "o", "        # error: Argument \"dtype\" to \"view\" of \"_ArrayOrScalarCommon\" has incompatible\r\n"]
[142.771609, "o", "        # type \"Union[ExtensionDtype, dtype[Any]]\"; expected \"Union[dtype[Any], None,\r\n"]
[142.790552, "o", "        # type, _SupportsDType, str, Union[Tuple[Any, int], Tuple[Any, Union[int,\r\n"]
[142.809494, "o", "        # Sequence[int]]], List[Any], _DTypeDict, Tuple[Any, Any]]]\"\r\n"]
[142.828437, "o", "        return arr.view(dtype=dtype)  # type: ignore[arg-type]\r\n"]
[142.847379, "o", "\r\n"]
[142.866322, "o", "    def take(\r\n"]
[142.885264, "o", "        self,\r\n"]
[142.904207, "o", "        indices: TakeIndexer,\r\n"]
[142.923149, "o", "        *,\r\n"]
[142.942092, "o", "        allow_fill: bool = False,\r\n"]
[142.961034, "o", "        fill_value: Any = None,\r\n"]
[142.979977, "o", "        axis: AxisInt = 0,\r\n"]
[142.99892, "o", "    ) -> Self:\r\n"]
[143.017862, "o", "        if allow_fill:\r\n"]
[143.036805, "o", "            fill_value = self._validate_scalar(fill_value)\r\n"]
[143.055747, "o", "\r\n"]
[143.07469, "o", "        new_data = take(\r\n"]
[143.093632, "o", "            self._ndarray,\r\n"]
[143.112575, "o", "            indices,\r\n"]
[143.131517, "o", "            allow_fill=allow_fill,\r\n"]
[143.15046, "o", "            fill_value=fill_value,\r\n"]
[143.169402, "o", "            axis=axis,\r\n"]
[143.188345, "o", "        )\r\n"]
[143.207287, "o", "        return self._from_backing_data(new_data)\r\n"]
[143.22623, "o", "\r\n"]
[143.245172, "o", "    # ------------------------------------------------------------------------\r\n"]
[143.264115, "o", "\r\n"]
[143.283057, "o", "    def equals(self, other) -> bool:\r\n"]
[143.302, "o", "        if type(self) is not type(other):\r\n"]
[143.320943, "o", "            return False\r\n"]
[143.339885, "o", "        if not is_dtype_equal(self.dtype, other.dtype):\r\n"]
[143.358828, "o", "            return False\r\n"]
[143.37777, "o", "        return bool(array_equivalent(self._ndarray, other._ndarray))\r\n"]
[143.396713, "o", "\r\n"]
[143.415655, "o", "    @classmethod\r\n"]
[143.434598, "o", "    def _from_factorized(cls, values, original):\r\n"]
[143.45354, "o", "        assert values.dtype == original._ndarray.dtype\r\n"]
[143.472483, "o", "        return original._from_backing_data(values)\r\n"]
[143.491425, "o", "\r\n"]
[143.510368, "o", "    def _values_for_argsort(self) -> np.ndarray:\r\n"]
[143.52931, "o", "        return self._ndarray\r\n"]
[143.548253, "o", "\r\n"]
[143.567195, "o", "    def _values_for_factorize(self):\r\n"]
[143.586138, "o", "        return self._ndarray, self._internal_fill_value\r\n"]
[143.60508, "o", "\r\n"]
[143.624023, "o", "    def _hash_pandas_object(\r\n"]
[143.642966, "o", "        self, *, encoding: str, hash_key: str, categorize: bool\r\n"]
[143.661908, "o", "    ) -> npt.NDArray[np.uint64]:\r\n"]
[143.680851, "o", "        from pandas.core.util.hashing import hash_array\r\n"]
[143.699793, "o", "\r\n"]
[143.718736, "o", "        values = self._ndarray\r\n"]
[143.737678, "o", "        return hash_array(\r\n"]
[143.756621, "o", "            values, encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[143.775563, "o", "        )\r\n"]
[143.794506, "o", "\r\n"]
[143.813448, "o", "    # Signature of \"argmin\" incompatible with supertype \"ExtensionArray\"\r\n"]
[143.832391, "o", "    def argmin(self, axis: AxisInt = 0, skipna: bool = True):  # type: ignore[override]\r\n"]
[143.851333, "o", "        # override base class by adding axis keyword\r\n"]
[143.870276, "o", "        validate_bool_kwarg(skipna, \"skipna\")\r\n"]
[143.889218, "o", "        if not skipna and self._hasna:\r\n"]
[143.908161, "o", "            raise NotImplementedError\r\n"]
[143.927103, "o", "        return nargminmax(self, \"argmin\", axis=axis)\r\n"]
[143.946046, "o", "\r\n"]
[143.964989, "o", "    # Signature of \"argmax\" incompatible with supertype \"ExtensionArray\"\r\n"]
[143.983931, "o", "    def argmax(self, axis: AxisInt = 0, skipna: bool = True):  # type: ignore[override]\r\n"]
[144.002874, "o", "        # override base class by adding axis keyword\r\n"]
[144.021816, "o", "        validate_bool_kwarg(skipna, \"skipna\")\r\n"]
[144.040759, "o", "        if not skipna and self._hasna:\r\n"]
[144.059701, "o", "            raise NotImplementedError\r\n"]
[144.078644, "o", "        return nargminmax(self, \"argmax\", axis=axis)\r\n"]
[144.097586, "o", "\r\n"]
[144.116529, "o", "    def unique(self) -> Self:\r\n"]
[144.135471, "o", "        new_data = unique(self._ndarray)\r\n"]
[144.154414, "o", "        return self._from_backing_data(new_data)\r\n"]
[144.173356, "o", "\r\n"]
[144.192299, "o", "    @classmethod\r\n"]
[144.211241, "o", "    @doc(ExtensionArray._concat_same_type)\r\n"]
[144.230184, "o", "    def _concat_same_type(\r\n"]
[144.249126, "o", "        cls,\r\n"]
[144.268069, "o", "        to_concat: Sequence[Self],\r\n"]
[144.287011, "o", "        axis: AxisInt = 0,\r\n"]
[144.305954, "o", "    ) -> Self:\r\n"]
[144.324897, "o", "        if not lib.dtypes_all_equal([x.dtype for x in to_concat]):\r\n"]
[144.343839, "o", "            dtypes = {str(x.dtype) for x in to_concat}\r\n"]
[144.362782, "o", "            raise ValueError(\"to_concat must have the same dtype\", dtypes)\r\n"]
[144.381724, "o", "\r\n"]
[144.400667, "o", "        return super()._concat_same_type(to_concat, axis=axis)\r\n"]
[144.419609, "o", "\r\n"]
[144.438552, "o", "    @doc(ExtensionArray.searchsorted)\r\n"]
[144.457494, "o", "    def searchsorted(\r\n"]
[144.476437, "o", "        self,\r\n"]
[144.495379, "o", "        value: NumpyValueArrayLike | ExtensionArray,\r\n"]
[144.514322, "o", "        side: Literal[\"left\", \"right\"] = \"left\",\r\n"]
[144.533264, "o", "        sorter: NumpySorter = None,\r\n"]
[144.552207, "o", "    ) -> npt.NDArray[np.intp] | np.intp:\r\n"]
[144.571149, "o", "        npvalue = self._validate_setitem_value(value)\r\n"]
[144.590092, "o", "        return self._ndarray.searchsorted(npvalue, side=side, sorter=sorter)\r\n"]
[144.609034, "o", "\r\n"]
[144.627977, "o", "    @doc(ExtensionArray.shift)\r\n"]
[144.64692, "o", "    def shift(self, periods: int = 1, fill_value=None, axis: AxisInt = 0):\r\n"]
[144.665862, "o", "        fill_value = self._validate_scalar(fill_value)\r\n"]
[144.684805, "o", "        new_values = shift(self._ndarray, periods, axis, fill_value)\r\n"]
[144.703747, "o", "\r\n"]
[144.72269, "o", "        return self._from_backing_data(new_values)\r\n"]
[144.741632, "o", "\r\n"]
[144.760575, "o", "    def __setitem__(self, key, value) -> None:\r\n"]
[144.779517, "o", "        key = check_array_indexer(self, key)\r\n"]
[144.79846, "o", "        value = self._validate_setitem_value(value)\r\n"]
[144.817402, "o", "        self._ndarray[key] = value\r\n"]
[144.836345, "o", "\r\n"]
[144.855287, "o", "    def _validate_setitem_value(self, value):\r\n"]
[144.87423, "o", "        return value\r\n"]
[144.893172, "o", "\r\n"]
[144.912115, "o", "    @overload\r\n"]
[144.931057, "o", "    def __getitem__(self, key: ScalarIndexer) -> Any:\r\n"]
[145.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[145.002, "i", "sed -n '1,240p' pandas/core/arrays/base.py\r"]
[145.004, "o", "sed -n '1,240p' pandas/core/arrays/base.py\r\n"]
[145.026515, "o", "\u001b[?2004l\r\n"]
[145.047029, "o", "\"\"\"\r\n"]
[145.067544, "o", "An interface for extending pandas with custom arrays.\r\n"]
[145.088058, "o", "\r\n"]
[145.108573, "o", ".. warning::\r\n"]
[145.129087, "o", "\r\n"]
[145.149602, "o", "   This is an experimental API and subject to breaking changes\r\n"]
[145.170116, "o", "   without warning.\r\n"]
[145.190631, "o", "\"\"\"\r\n"]
[145.211145, "o", "from __future__ import annotations\r\n"]
[145.23166, "o", "\r\n"]
[145.252174, "o", "import operator\r\n"]
[145.272689, "o", "from typing import (\r\n"]
[145.293203, "o", "    TYPE_CHECKING,\r\n"]
[145.313718, "o", "    Any,\r\n"]
[145.334232, "o", "    Callable,\r\n"]
[145.354747, "o", "    ClassVar,\r\n"]
[145.375261, "o", "    Iterator,\r\n"]
[145.395776, "o", "    Literal,\r\n"]
[145.41629, "o", "    Sequence,\r\n"]
[145.436805, "o", "    cast,\r\n"]
[145.45732, "o", "    overload,\r\n"]
[145.477834, "o", ")\r\n"]
[145.498349, "o", "\r\n"]
[145.518863, "o", "import numpy as np\r\n"]
[145.539378, "o", "\r\n"]
[145.559892, "o", "from pandas._libs import lib\r\n"]
[145.580407, "o", "from pandas.compat import set_function_name\r\n"]
[145.600921, "o", "from pandas.compat.numpy import function as nv\r\n"]
[145.621436, "o", "from pandas.errors import AbstractMethodError\r\n"]
[145.64195, "o", "from pandas.util._decorators import (\r\n"]
[145.662465, "o", "    Appender,\r\n"]
[145.682979, "o", "    Substitution,\r\n"]
[145.703494, "o", "    cache_readonly,\r\n"]
[145.724008, "o", ")\r\n"]
[145.744523, "o", "from pandas.util._validators import (\r\n"]
[145.765037, "o", "    validate_bool_kwarg,\r\n"]
[145.785552, "o", "    validate_fillna_kwargs,\r\n"]
[145.806066, "o", "    validate_insert_loc,\r\n"]
[145.826581, "o", ")\r\n"]
[145.847095, "o", "\r\n"]
[145.86761, "o", "from pandas.core.dtypes.cast import maybe_cast_to_extension_array\r\n"]
[145.888124, "o", "from pandas.core.dtypes.common import (\r\n"]
[145.908639, "o", "    is_datetime64_dtype,\r\n"]
[145.929154, "o", "    is_dtype_equal,\r\n"]
[145.949668, "o", "    is_list_like,\r\n"]
[145.970183, "o", "    is_scalar,\r\n"]
[145.990697, "o", "    is_timedelta64_dtype,\r\n"]
[146.011212, "o", "    pandas_dtype,\r\n"]
[146.031726, "o", ")\r\n"]
[146.052241, "o", "from pandas.core.dtypes.dtypes import ExtensionDtype\r\n"]
[146.072755, "o", "from pandas.core.dtypes.generic import (\r\n"]
[146.09327, "o", "    ABCDataFrame,\r\n"]
[146.113784, "o", "    ABCIndex,\r\n"]
[146.134299, "o", "    ABCSeries,\r\n"]
[146.154813, "o", ")\r\n"]
[146.175328, "o", "from pandas.core.dtypes.missing import isna\r\n"]
[146.195842, "o", "\r\n"]
[146.216357, "o", "from pandas.core import (\r\n"]
[146.236871, "o", "    arraylike,\r\n"]
[146.257386, "o", "    missing,\r\n"]
[146.2779, "o", "    roperator,\r\n"]
[146.298415, "o", ")\r\n"]
[146.318929, "o", "from pandas.core.algorithms import (\r\n"]
[146.339444, "o", "    factorize_array,\r\n"]
[146.359959, "o", "    isin,\r\n"]
[146.380473, "o", "    map_array,\r\n"]
[146.400988, "o", "    mode,\r\n"]
[146.421502, "o", "    rank,\r\n"]
[146.442017, "o", "    unique,\r\n"]
[146.462531, "o", ")\r\n"]
[146.483046, "o", "from pandas.core.array_algos.quantile import quantile_with_mask\r\n"]
[146.50356, "o", "from pandas.core.sorting import (\r\n"]
[146.524075, "o", "    nargminmax,\r\n"]
[146.544589, "o", "    nargsort,\r\n"]
[146.565104, "o", ")\r\n"]
[146.585618, "o", "\r\n"]
[146.606133, "o", "if TYPE_CHECKING:\r\n"]
[146.626647, "o", "    from pandas._typing import (\r\n"]
[146.647162, "o", "        ArrayLike,\r\n"]
[146.667676, "o", "        AstypeArg,\r\n"]
[146.688191, "o", "        AxisInt,\r\n"]
[146.708705, "o", "        Dtype,\r\n"]
[146.72922, "o", "        FillnaOptions,\r\n"]
[146.749734, "o", "        NumpySorter,\r\n"]
[146.770249, "o", "        NumpyValueArrayLike,\r\n"]
[146.790763, "o", "        PositionalIndexer,\r\n"]
[146.811278, "o", "        ScalarIndexer,\r\n"]
[146.831793, "o", "        Self,\r\n"]
[146.852307, "o", "        SequenceIndexer,\r\n"]
[146.872822, "o", "        Shape,\r\n"]
[146.893336, "o", "        SortKind,\r\n"]
[146.913851, "o", "        TakeIndexer,\r\n"]
[146.934365, "o", "        npt,\r\n"]
[146.95488, "o", "    )\r\n"]
[146.975394, "o", "\r\n"]
[146.995909, "o", "_extension_array_shared_docs: dict[str, str] = {}\r\n"]
[147.016423, "o", "\r\n"]
[147.036938, "o", "\r\n"]
[147.057452, "o", "class ExtensionArray:\r\n"]
[147.077967, "o", "    \"\"\"\r\n"]
[147.098481, "o", "    Abstract base class for custom 1-D array types.\r\n"]
[147.118996, "o", "\r\n"]
[147.13951, "o", "    pandas will recognize instances of this class as proper arrays\r\n"]
[147.160025, "o", "    with a custom type and will not attempt to coerce them to objects. They\r\n"]
[147.180539, "o", "    may be stored directly inside a :class:`DataFrame` or :class:`Series`.\r\n"]
[147.201054, "o", "\r\n"]
[147.221568, "o", "    Attributes\r\n"]
[147.242083, "o", "    ----------\r\n"]
[147.262598, "o", "    dtype\r\n"]
[147.283112, "o", "    nbytes\r\n"]
[147.303627, "o", "    ndim\r\n"]
[147.324141, "o", "    shape\r\n"]
[147.344656, "o", "\r\n"]
[147.36517, "o", "    Methods\r\n"]
[147.385685, "o", "    -------\r\n"]
[147.406199, "o", "    argsort\r\n"]
[147.426714, "o", "    astype\r\n"]
[147.447228, "o", "    copy\r\n"]
[147.467743, "o", "    dropna\r\n"]
[147.488257, "o", "    factorize\r\n"]
[147.508772, "o", "    fillna\r\n"]
[147.529286, "o", "    equals\r\n"]
[147.549801, "o", "    insert\r\n"]
[147.570315, "o", "    isin\r\n"]
[147.59083, "o", "    isna\r\n"]
[147.611344, "o", "    ravel\r\n"]
[147.631859, "o", "    repeat\r\n"]
[147.652373, "o", "    searchsorted\r\n"]
[147.672888, "o", "    shift\r\n"]
[147.693402, "o", "    take\r\n"]
[147.713917, "o", "    tolist\r\n"]
[147.734432, "o", "    unique\r\n"]
[147.754946, "o", "    view\r\n"]
[147.775461, "o", "    _accumulate\r\n"]
[147.795975, "o", "    _concat_same_type\r\n"]
[147.81649, "o", "    _formatter\r\n"]
[147.837004, "o", "    _from_factorized\r\n"]
[147.857519, "o", "    _from_sequence\r\n"]
[147.878033, "o", "    _from_sequence_of_strings\r\n"]
[147.898548, "o", "    _hash_pandas_object\r\n"]
[147.919062, "o", "    _reduce\r\n"]
[147.939577, "o", "    _values_for_argsort\r\n"]
[147.960091, "o", "    _values_for_factorize\r\n"]
[147.980606, "o", "\r\n"]
[148.00112, "o", "    Notes\r\n"]
[148.021635, "o", "    -----\r\n"]
[148.042149, "o", "    The interface includes the following abstract methods that must be\r\n"]
[148.062664, "o", "    implemented by subclasses:\r\n"]
[148.083178, "o", "\r\n"]
[148.103693, "o", "    * _from_sequence\r\n"]
[148.124207, "o", "    * _from_factorized\r\n"]
[148.144722, "o", "    * __getitem__\r\n"]
[148.165237, "o", "    * __len__\r\n"]
[148.185751, "o", "    * __eq__\r\n"]
[148.206266, "o", "    * dtype\r\n"]
[148.22678, "o", "    * nbytes\r\n"]
[148.247295, "o", "    * isna\r\n"]
[148.267809, "o", "    * take\r\n"]
[148.288324, "o", "    * copy\r\n"]
[148.308838, "o", "    * _concat_same_type\r\n"]
[148.329353, "o", "\r\n"]
[148.349867, "o", "    A default repr displaying the type, (truncated) data, length,\r\n"]
[148.370382, "o", "    and dtype is provided. It can be customized or replaced by\r\n"]
[148.390896, "o", "    by overriding:\r\n"]
[148.411411, "o", "\r\n"]
[148.431925, "o", "    * __repr__ : A default repr for the ExtensionArray.\r\n"]
[148.45244, "o", "    * _formatter : Print scalars inside a Series or DataFrame.\r\n"]
[148.472954, "o", "\r\n"]
[148.493469, "o", "    Some methods require casting the ExtensionArray to an ndarray of Python\r\n"]
[148.513983, "o", "    objects with ``self.astype(object)``, which may be expensive. When\r\n"]
[148.534498, "o", "    performance is a concern, we highly recommend overriding the following\r\n"]
[148.555012, "o", "    methods:\r\n"]
[148.575527, "o", "\r\n"]
[148.596041, "o", "    * fillna\r\n"]
[148.616556, "o", "    * dropna\r\n"]
[148.637071, "o", "    * unique\r\n"]
[148.657585, "o", "    * factorize / _values_for_factorize\r\n"]
[148.6781, "o", "    * argsort, argmax, argmin / _values_for_argsort\r\n"]
[148.698614, "o", "    * searchsorted\r\n"]
[148.719129, "o", "    * map\r\n"]
[148.739643, "o", "\r\n"]
[148.760158, "o", "    The remaining methods implemented on this class should be performant,\r\n"]
[148.780672, "o", "    as they only compose abstract methods. Still, a more efficient\r\n"]
[148.801187, "o", "    implementation may be available, and these methods can be overridden.\r\n"]
[148.821701, "o", "\r\n"]
[148.842216, "o", "    One can implement methods to handle array accumulations or reductions.\r\n"]
[148.86273, "o", "\r\n"]
[148.883245, "o", "    * _accumulate\r\n"]
[148.903759, "o", "    * _reduce\r\n"]
[148.924274, "o", "\r\n"]
[148.944788, "o", "    One can implement methods to handle parsing from strings that will be used\r\n"]
[148.965303, "o", "    in methods such as ``pandas.io.parsers.read_csv``.\r\n"]
[148.985817, "o", "\r\n"]
[149.006332, "o", "    * _from_sequence_of_strings\r\n"]
[149.026846, "o", "\r\n"]
[149.047361, "o", "    This class does not inherit from 'abc.ABCMeta' for performance reasons.\r\n"]
[149.067876, "o", "    Methods and properties required by the interface raise\r\n"]
[149.08839, "o", "    ``pandas.errors.AbstractMethodError`` and no ``register`` method is\r\n"]
[149.108905, "o", "    provided for registering virtual subclasses.\r\n"]
[149.129419, "o", "\r\n"]
[149.149934, "o", "    ExtensionArrays are limited to 1 dimension.\r\n"]
[149.170448, "o", "\r\n"]
[149.190963, "o", "    They may be backed by none, one, or many NumPy arrays. For example,\r\n"]
[149.211477, "o", "    ``pandas.Categorical`` is an extension array backed by two arrays,\r\n"]
[149.231992, "o", "    one for codes and one for categories. An array of IPv6 address may\r\n"]
[149.252506, "o", "    be backed by a NumPy structured array with two fields, one for the\r\n"]
[149.273021, "o", "    lower 64 bits and one for the upper 64 bits. Or they may be backed\r\n"]
[149.293535, "o", "    by some other storage type, like Python lists. Pandas makes no\r\n"]
[149.31405, "o", "    assumptions on how the data are stored, just that it can be converted\r\n"]
[149.334564, "o", "    to a NumPy array.\r\n"]
[149.355079, "o", "    The ExtensionArray interface does not impose any rules on how this data\r\n"]
[149.375593, "o", "    is stored. However, currently, the backing data cannot be stored in\r\n"]
[149.396108, "o", "    attributes called ``.values`` or ``._values`` to ensure full compatibility\r\n"]
[149.416622, "o", "    with pandas internals. But other names as ``.data``, ``._data``,\r\n"]
[149.437137, "o", "    ``._items``, ... can be freely used.\r\n"]
[149.457651, "o", "\r\n"]
[149.478166, "o", "    If implementing NumPy's ``__array_ufunc__`` interface, pandas expects\r\n"]
[149.49868, "o", "    that\r\n"]
[149.519195, "o", "\r\n"]
[149.53971, "o", "    1. You defer by returning ``NotImplemented`` when any Series are present\r\n"]
[149.560224, "o", "       in `inputs`. Pandas will extract the arrays and call the ufunc again.\r\n"]
[149.580739, "o", "    2. You define a ``_HANDLED_TYPES`` tuple as an attribute on the class.\r\n"]
[149.601253, "o", "       Pandas inspect this to determine whether the ufunc is valid for the\r\n"]
[149.621768, "o", "       types present.\r\n"]
[149.642282, "o", "\r\n"]
[149.662797, "o", "    See :ref:`extending.extension.ufunc` for more.\r\n"]
[149.683311, "o", "\r\n"]
[149.703826, "o", "    By default, ExtensionArrays are not hashable.  Immutable subclasses may\r\n"]
[149.72434, "o", "    override this behavior.\r\n"]
[149.744855, "o", "    \"\"\"\r\n"]
[149.765369, "o", "\r\n"]
[149.785884, "o", "    # '_typ' is for pandas.core.dtypes.generic.ABCExtensionArray.\r\n"]
[149.806398, "o", "    # Don't override this.\r\n"]
[149.826913, "o", "    _typ = \"extension\"\r\n"]
[149.847427, "o", "\r\n"]
[149.867942, "o", "    # similar to __array_priority__, positions ExtensionArray after Index,\r\n"]
[149.888456, "o", "    #  Series, and DataFrame.  EA subclasses may override to choose which EA\r\n"]
[149.908971, "o", "    #  subclass takes priority. If overriding, the value should always be\r\n"]
[149.929485, "o", "    #  strictly less than 2000 to be below Index.__pandas_priority__.\r\n"]
[150.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[150.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '840,1040p'\r"]
[150.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '840,1040p'\r\n"]
[150.030475, "o", "\u001b[?2004l\r\n"]
[150.05495, "o", "   840\t        # Currently, ExtensionArray.factorize -> Tuple[ndarray, EA]\r\n"]
[150.079426, "o", "   841\t        # The sparsity on this is backwards from what Sparse would want. Want\r\n"]
[150.103901, "o", "   842\t        # ExtensionArray.factorize -> Tuple[EA, EA]\r\n"]
[150.128376, "o", "   843\t        # Given that we have to return a dense array of codes, why bother\r\n"]
[150.152851, "o", "   844\t        # implementing an efficient factorize?\r\n"]
[150.177327, "o", "   845\t        codes, uniques = algos.factorize(\r\n"]
[150.201802, "o", "   846\t            np.asarray(self), use_na_sentinel=use_na_sentinel\r\n"]
[150.226277, "o", "   847\t        )\r\n"]
[150.250752, "o", "   848\t        uniques_sp = SparseArray(uniques, dtype=self.dtype)\r\n"]
[150.275228, "o", "   849\t        return codes, uniques_sp\r\n"]
[150.299703, "o", "   850\t\r\n"]
[150.324178, "o", "   851\t    def value_counts(self, dropna: bool = True) -> Series:\r\n"]
[150.348653, "o", "   852\t        \"\"\"\r\n"]
[150.373129, "o", "   853\t        Returns a Series containing counts of unique values.\r\n"]
[150.397604, "o", "   854\t\r\n"]
[150.422079, "o", "   855\t        Parameters\r\n"]
[150.446554, "o", "   856\t        ----------\r\n"]
[150.47103, "o", "   857\t        dropna : bool, default True\r\n"]
[150.495505, "o", "   858\t            Don't include counts of NaN, even if NaN is in sp_values.\r\n"]
[150.51998, "o", "   859\t\r\n"]
[150.544455, "o", "   860\t        Returns\r\n"]
[150.568931, "o", "   861\t        -------\r\n"]
[150.593406, "o", "   862\t        counts : Series\r\n"]
[150.617881, "o", "   863\t        \"\"\"\r\n"]
[150.642356, "o", "   864\t        from pandas import (\r\n"]
[150.666832, "o", "   865\t            Index,\r\n"]
[150.691307, "o", "   866\t            Series,\r\n"]
[150.715782, "o", "   867\t        )\r\n"]
[150.740257, "o", "   868\t\r\n"]
[150.764733, "o", "   869\t        keys, counts = algos.value_counts_arraylike(self.sp_values, dropna=dropna)\r\n"]
[150.789208, "o", "   870\t        fcounts = self.sp_index.ngaps\r\n"]
[150.813683, "o", "   871\t        if fcounts > 0 and (not self._null_fill_value or not dropna):\r\n"]
[150.838158, "o", "   872\t            mask = isna(keys) if self._null_fill_value else keys == self.fill_value\r\n"]
[150.862634, "o", "   873\t            if mask.any():\r\n"]
[150.887109, "o", "   874\t                counts[mask] += fcounts\r\n"]
[150.911584, "o", "   875\t            else:\r\n"]
[150.936059, "o", "   876\t                # error: Argument 1 to \"insert\" has incompatible type \"Union[\r\n"]
[150.960535, "o", "   877\t                # ExtensionArray,ndarray[Any, Any]]\"; expected \"Union[\r\n"]
[150.98501, "o", "   878\t                # _SupportsArray[dtype[Any]], Sequence[_SupportsArray[dtype\r\n"]
[151.009485, "o", "   879\t                # [Any]]], Sequence[Sequence[_SupportsArray[dtype[Any]]]],\r\n"]
[151.03396, "o", "   880\t                # Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]], Sequence\r\n"]
[151.058436, "o", "   881\t                # [Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]]]]\"\r\n"]
[151.082911, "o", "   882\t                keys = np.insert(keys, 0, self.fill_value)  # type: ignore[arg-type]\r\n"]
[151.107386, "o", "   883\t                counts = np.insert(counts, 0, fcounts)\r\n"]
[151.131861, "o", "   884\t\r\n"]
[151.156337, "o", "   885\t        if not isinstance(keys, ABCIndex):\r\n"]
[151.180812, "o", "   886\t            index = Index(keys)\r\n"]
[151.205287, "o", "   887\t        else:\r\n"]
[151.229762, "o", "   888\t            index = keys\r\n"]
[151.254238, "o", "   889\t        return Series(counts, index=index, copy=False)\r\n"]
[151.278713, "o", "   890\t\r\n"]
[151.303188, "o", "   891\t    # --------\r\n"]
[151.327663, "o", "   892\t    # Indexing\r\n"]
[151.352139, "o", "   893\t    # --------\r\n"]
[151.376614, "o", "   894\t    @overload\r\n"]
[151.401089, "o", "   895\t    def __getitem__(self, key: ScalarIndexer) -> Any:\r\n"]
[151.425564, "o", "   896\t        ...\r\n"]
[151.45004, "o", "   897\t\r\n"]
[151.474515, "o", "   898\t    @overload\r\n"]
[151.49899, "o", "   899\t    def __getitem__(\r\n"]
[151.523465, "o", "   900\t        self,\r\n"]
[151.547941, "o", "   901\t        key: SequenceIndexer | tuple[int | ellipsis, ...],\r\n"]
[151.572416, "o", "   902\t    ) -> Self:\r\n"]
[151.596891, "o", "   903\t        ...\r\n"]
[151.621366, "o", "   904\t\r\n"]
[151.645842, "o", "   905\t    def __getitem__(\r\n"]
[151.670317, "o", "   906\t        self,\r\n"]
[151.694792, "o", "   907\t        key: PositionalIndexer | tuple[int | ellipsis, ...],\r\n"]
[151.719267, "o", "   908\t    ) -> Self | Any:\r\n"]
[151.743743, "o", "   909\t        if isinstance(key, tuple):\r\n"]
[151.768218, "o", "   910\t            key = unpack_tuple_and_ellipses(key)\r\n"]
[151.792693, "o", "   911\t            if key is Ellipsis:\r\n"]
[151.817168, "o", "   912\t                raise ValueError(\"Cannot slice with Ellipsis\")\r\n"]
[151.841644, "o", "   913\t\r\n"]
[151.866119, "o", "   914\t        if is_integer(key):\r\n"]
[151.890594, "o", "   915\t            return self._get_val_at(key)\r\n"]
[151.915069, "o", "   916\t        elif isinstance(key, tuple):\r\n"]
[151.939545, "o", "   917\t            # error: Invalid index type \"Tuple[Union[int, ellipsis], ...]\"\r\n"]
[151.96402, "o", "   918\t            # for \"ndarray[Any, Any]\"; expected type\r\n"]
[151.988495, "o", "   919\t            # \"Union[SupportsIndex, _SupportsArray[dtype[Union[bool_,\r\n"]
[152.01297, "o", "   920\t            # integer[Any]]]], _NestedSequence[_SupportsArray[dtype[\r\n"]
[152.037446, "o", "   921\t            # Union[bool_, integer[Any]]]]], _NestedSequence[Union[\r\n"]
[152.061921, "o", "   922\t            # bool, int]], Tuple[Union[SupportsIndex, _SupportsArray[\r\n"]
[152.086396, "o", "   923\t            # dtype[Union[bool_, integer[Any]]]], _NestedSequence[\r\n"]
[152.110871, "o", "   924\t            # _SupportsArray[dtype[Union[bool_, integer[Any]]]]],\r\n"]
[152.135347, "o", "   925\t            # _NestedSequence[Union[bool, int]]], ...]]\"\r\n"]
[152.159822, "o", "   926\t            data_slice = self.to_dense()[key]  # type: ignore[index]\r\n"]
[152.184297, "o", "   927\t        elif isinstance(key, slice):\r\n"]
[152.208772, "o", "   928\t            # Avoid densifying when handling contiguous slices\r\n"]
[152.233248, "o", "   929\t            if key.step is None or key.step == 1:\r\n"]
[152.257723, "o", "   930\t                start = 0 if key.start is None else key.start\r\n"]
[152.282198, "o", "   931\t                if start < 0:\r\n"]
[152.306673, "o", "   932\t                    start += len(self)\r\n"]
[152.331149, "o", "   933\t\r\n"]
[152.355624, "o", "   934\t                end = len(self) if key.stop is None else key.stop\r\n"]
[152.380099, "o", "   935\t                if end < 0:\r\n"]
[152.404574, "o", "   936\t                    end += len(self)\r\n"]
[152.42905, "o", "   937\t\r\n"]
[152.453525, "o", "   938\t                indices = self.sp_index.indices\r\n"]
[152.478, "o", "   939\t                keep_inds = np.flatnonzero((indices >= start) & (indices < end))\r\n"]
[152.502475, "o", "   940\t                sp_vals = self.sp_values[keep_inds]\r\n"]
[152.52695, "o", "   941\t\r\n"]
[152.551426, "o", "   942\t                sp_index = indices[keep_inds].copy()\r\n"]
[152.575901, "o", "   943\t\r\n"]
[152.600376, "o", "   944\t                # If we've sliced to not include the start of the array, all our indices\r\n"]
[152.624851, "o", "   945\t                # should be shifted. NB: here we are careful to also not shift by a\r\n"]
[152.649327, "o", "   946\t                # negative value for a case like [0, 1][-100:] where the start index\r\n"]
[152.673802, "o", "   947\t                # should be treated like 0\r\n"]
[152.698277, "o", "   948\t                if start > 0:\r\n"]
[152.722752, "o", "   949\t                    sp_index -= start\r\n"]
[152.747228, "o", "   950\t\r\n"]
[152.771703, "o", "   951\t                # Length of our result should match applying this slice to a range\r\n"]
[152.796178, "o", "   952\t                # of the length of our original array\r\n"]
[152.820653, "o", "   953\t                new_len = len(range(len(self))[key])\r\n"]
[152.845129, "o", "   954\t                new_sp_index = make_sparse_index(new_len, sp_index, self.kind)\r\n"]
[152.869604, "o", "   955\t                return type(self)._simple_new(sp_vals, new_sp_index, self.dtype)\r\n"]
[152.894079, "o", "   956\t            else:\r\n"]
[152.918554, "o", "   957\t                indices = np.arange(len(self), dtype=np.int32)[key]\r\n"]
[152.94303, "o", "   958\t                return self.take(indices)\r\n"]
[152.967505, "o", "   959\t\r\n"]
[152.99198, "o", "   960\t        elif not is_list_like(key):\r\n"]
[153.016455, "o", "   961\t            # e.g. \"foo\" or 2.5\r\n"]
[153.040931, "o", "   962\t            # exception message copied from numpy\r\n"]
[153.065406, "o", "   963\t            raise IndexError(\r\n"]
[153.089881, "o", "   964\t                r\"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis \"\r\n"]
[153.114356, "o", "   965\t                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[153.138832, "o", "   966\t            )\r\n"]
[153.163307, "o", "   967\t\r\n"]
[153.187782, "o", "   968\t        else:\r\n"]
[153.212257, "o", "   969\t            if isinstance(key, SparseArray):\r\n"]
[153.236733, "o", "   970\t                # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[153.261208, "o", "   971\t                # has only fill_value - true, false or nan\r\n"]
[153.285683, "o", "   972\t                # (see GH PR 44955)\r\n"]
[153.310158, "o", "   973\t                # we can apply mask very fast:\r\n"]
[153.334634, "o", "   974\t                if is_bool_dtype(key):\r\n"]
[153.359109, "o", "   975\t                    if isna(key.fill_value):\r\n"]
[153.383584, "o", "   976\t                        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[153.408059, "o", "   977\t                    if not key.fill_value:\r\n"]
[153.432535, "o", "   978\t                        return self.take(key.sp_index.indices)\r\n"]
[153.45701, "o", "   979\t                    n = len(self)\r\n"]
[153.481485, "o", "   980\t                    mask = np.full(n, True, dtype=np.bool_)\r\n"]
[153.50596, "o", "   981\t                    mask[key.sp_index.indices] = False\r\n"]
[153.530436, "o", "   982\t                    return self.take(np.arange(n)[mask])\r\n"]
[153.554911, "o", "   983\t                else:\r\n"]
[153.579386, "o", "   984\t                    key = np.asarray(key)\r\n"]
[153.603861, "o", "   985\t\r\n"]
[153.628337, "o", "   986\t            key = check_array_indexer(self, key)\r\n"]
[153.652812, "o", "   987\t\r\n"]
[153.677287, "o", "   988\t            if com.is_bool_indexer(key):\r\n"]
[153.701762, "o", "   989\t                # mypy doesn't know we have an array here\r\n"]
[153.726238, "o", "   990\t                key = cast(np.ndarray, key)\r\n"]
[153.750713, "o", "   991\t                return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[153.775188, "o", "   992\t            elif hasattr(key, \"__len__\"):\r\n"]
[153.799663, "o", "   993\t                return self.take(key)\r\n"]
[153.824139, "o", "   994\t            else:\r\n"]
[153.848614, "o", "   995\t                raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[153.873089, "o", "   996\t\r\n"]
[153.897564, "o", "   997\t        return type(self)(data_slice, kind=self.kind)\r\n"]
[153.92204, "o", "   998\t\r\n"]
[153.946515, "o", "   999\t    def _get_val_at(self, loc):\r\n"]
[153.97099, "o", "  1000\t        loc = validate_insert_loc(loc, len(self))\r\n"]
[153.995465, "o", "  1001\t\r\n"]
[154.019941, "o", "  1002\t        sp_loc = self.sp_index.lookup(loc)\r\n"]
[154.044416, "o", "  1003\t        if sp_loc == -1:\r\n"]
[154.068891, "o", "  1004\t            return self.fill_value\r\n"]
[154.093366, "o", "  1005\t        else:\r\n"]
[154.117842, "o", "  1006\t            val = self.sp_values[sp_loc]\r\n"]
[154.142317, "o", "  1007\t            val = maybe_box_datetimelike(val, self.sp_values.dtype)\r\n"]
[154.166792, "o", "  1008\t            return val\r\n"]
[154.191267, "o", "  1009\t\r\n"]
[154.215743, "o", "  1010\t    def take(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[154.240218, "o", "  1011\t        if is_scalar(indices):\r\n"]
[154.264693, "o", "  1012\t            raise ValueError(f\"'indices' must be an array, not a scalar '{indices}'.\")\r\n"]
[154.289168, "o", "  1013\t        indices = np.asarray(indices, dtype=np.int32)\r\n"]
[154.313644, "o", "  1014\t\r\n"]
[154.338119, "o", "  1015\t        dtype = None\r\n"]
[154.362594, "o", "  1016\t        if indices.size == 0:\r\n"]
[154.387069, "o", "  1017\t            result = np.array([], dtype=\"object\")\r\n"]
[154.411545, "o", "  1018\t            dtype = self.dtype\r\n"]
[154.43602, "o", "  1019\t        elif allow_fill:\r\n"]
[154.460495, "o", "  1020\t            result = self._take_with_fill(indices, fill_value=fill_value)\r\n"]
[154.48497, "o", "  1021\t        else:\r\n"]
[154.509446, "o", "  1022\t            return self._take_without_fill(indices)\r\n"]
[154.533921, "o", "  1023\t\r\n"]
[154.558396, "o", "  1024\t        return type(self)(\r\n"]
[154.582871, "o", "  1025\t            result, fill_value=self.fill_value, kind=self.kind, dtype=dtype\r\n"]
[154.607347, "o", "  1026\t        )\r\n"]
[154.631822, "o", "  1027\t\r\n"]
[154.656297, "o", "  1028\t    def _take_with_fill(self, indices, fill_value=None) -> np.ndarray:\r\n"]
[154.680772, "o", "  1029\t        if fill_value is None:\r\n"]
[154.705248, "o", "  1030\t            fill_value = self.dtype.na_value\r\n"]
[154.729723, "o", "  1031\t\r\n"]
[154.754198, "o", "  1032\t        if indices.min() < -1:\r\n"]
[154.778673, "o", "  1033\t            raise ValueError(\r\n"]
[154.803149, "o", "  1034\t                \"Invalid value in 'indices'. Must be between -1 \"\r\n"]
[154.827624, "o", "  1035\t                \"and the length of the array.\"\r\n"]
[154.852099, "o", "  1036\t            )\r\n"]
[154.876574, "o", "  1037\t\r\n"]
[154.90105, "o", "  1038\t        if indices.max() >= len(self):\r\n"]
[154.925525, "o", "  1039\t            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[155.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[155.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1040,1240p'\r"]
[155.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1040,1240p'\r\n"]
[155.030475, "o", "\u001b[?2004l\r\n"]
[155.05495, "o", "  1040\t\r\n"]
[155.079426, "o", "  1041\t        if len(self) == 0:\r\n"]
[155.103901, "o", "  1042\t            # Empty... Allow taking only if all empty\r\n"]
[155.128376, "o", "  1043\t            if (indices == -1).all():\r\n"]
[155.152851, "o", "  1044\t                dtype = np.result_type(self.sp_values, type(fill_value))\r\n"]
[155.177327, "o", "  1045\t                taken = np.empty_like(indices, dtype=dtype)\r\n"]
[155.201802, "o", "  1046\t                taken.fill(fill_value)\r\n"]
[155.226277, "o", "  1047\t                return taken\r\n"]
[155.250752, "o", "  1048\t            else:\r\n"]
[155.275228, "o", "  1049\t                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[155.299703, "o", "  1050\t\r\n"]
[155.324178, "o", "  1051\t        # sp_indexer may be -1 for two reasons\r\n"]
[155.348653, "o", "  1052\t        # 1.) we took for an index of -1 (new)\r\n"]
[155.373129, "o", "  1053\t        # 2.) we took a value that was self.fill_value (old)\r\n"]
[155.397604, "o", "  1054\t        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[155.422079, "o", "  1055\t        new_fill_indices = indices == -1\r\n"]
[155.446554, "o", "  1056\t        old_fill_indices = (sp_indexer == -1) & ~new_fill_indices\r\n"]
[155.47103, "o", "  1057\t\r\n"]
[155.495505, "o", "  1058\t        if self.sp_index.npoints == 0 and old_fill_indices.all():\r\n"]
[155.51998, "o", "  1059\t            # We've looked up all valid points on an all-sparse array.\r\n"]
[155.544455, "o", "  1060\t            taken = np.full(\r\n"]
[155.568931, "o", "  1061\t                sp_indexer.shape, fill_value=self.fill_value, dtype=self.dtype.subtype\r\n"]
[155.593406, "o", "  1062\t            )\r\n"]
[155.617881, "o", "  1063\t\r\n"]
[155.642356, "o", "  1064\t        elif self.sp_index.npoints == 0:\r\n"]
[155.666832, "o", "  1065\t            # Avoid taking from the empty self.sp_values\r\n"]
[155.691307, "o", "  1066\t            _dtype = np.result_type(self.dtype.subtype, type(fill_value))\r\n"]
[155.715782, "o", "  1067\t            taken = np.full(sp_indexer.shape, fill_value=fill_value, dtype=_dtype)\r\n"]
[155.740257, "o", "  1068\t        else:\r\n"]
[155.764733, "o", "  1069\t            taken = self.sp_values.take(sp_indexer)\r\n"]
[155.789208, "o", "  1070\t\r\n"]
[155.813683, "o", "  1071\t            # Fill in two steps.\r\n"]
[155.838158, "o", "  1072\t            # Old fill values\r\n"]
[155.862634, "o", "  1073\t            # New fill values\r\n"]
[155.887109, "o", "  1074\t            # potentially coercing to a new dtype at each stage.\r\n"]
[155.911584, "o", "  1075\t\r\n"]
[155.936059, "o", "  1076\t            m0 = sp_indexer[old_fill_indices] < 0\r\n"]
[155.960535, "o", "  1077\t            m1 = sp_indexer[new_fill_indices] < 0\r\n"]
[155.98501, "o", "  1078\t\r\n"]
[156.009485, "o", "  1079\t            result_type = taken.dtype\r\n"]
[156.03396, "o", "  1080\t\r\n"]
[156.058436, "o", "  1081\t            if m0.any():\r\n"]
[156.082911, "o", "  1082\t                result_type = np.result_type(result_type, type(self.fill_value))\r\n"]
[156.107386, "o", "  1083\t                taken = taken.astype(result_type)\r\n"]
[156.131861, "o", "  1084\t                taken[old_fill_indices] = self.fill_value\r\n"]
[156.156337, "o", "  1085\t\r\n"]
[156.180812, "o", "  1086\t            if m1.any():\r\n"]
[156.205287, "o", "  1087\t                result_type = np.result_type(result_type, type(fill_value))\r\n"]
[156.229762, "o", "  1088\t                taken = taken.astype(result_type)\r\n"]
[156.254238, "o", "  1089\t                taken[new_fill_indices] = fill_value\r\n"]
[156.278713, "o", "  1090\t\r\n"]
[156.303188, "o", "  1091\t        return taken\r\n"]
[156.327663, "o", "  1092\t\r\n"]
[156.352139, "o", "  1093\t    def _take_without_fill(self, indices) -> Self:\r\n"]
[156.376614, "o", "  1094\t        to_shift = indices < 0\r\n"]
[156.401089, "o", "  1095\t\r\n"]
[156.425564, "o", "  1096\t        n = len(self)\r\n"]
[156.45004, "o", "  1097\t\r\n"]
[156.474515, "o", "  1098\t        if (indices.max() >= n) or (indices.min() < -n):\r\n"]
[156.49899, "o", "  1099\t            if n == 0:\r\n"]
[156.523465, "o", "  1100\t                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[156.547941, "o", "  1101\t            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[156.572416, "o", "  1102\t\r\n"]
[156.596891, "o", "  1103\t        if to_shift.any():\r\n"]
[156.621366, "o", "  1104\t            indices = indices.copy()\r\n"]
[156.645842, "o", "  1105\t            indices[to_shift] += n\r\n"]
[156.670317, "o", "  1106\t\r\n"]
[156.694792, "o", "  1107\t        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[156.719267, "o", "  1108\t        value_mask = sp_indexer != -1\r\n"]
[156.743743, "o", "  1109\t        new_sp_values = self.sp_values[sp_indexer[value_mask]]\r\n"]
[156.768218, "o", "  1110\t\r\n"]
[156.792693, "o", "  1111\t        value_indices = np.flatnonzero(value_mask).astype(np.int32, copy=False)\r\n"]
[156.817168, "o", "  1112\t\r\n"]
[156.841644, "o", "  1113\t        new_sp_index = make_sparse_index(len(indices), value_indices, kind=self.kind)\r\n"]
[156.866119, "o", "  1114\t        return type(self)._simple_new(new_sp_values, new_sp_index, dtype=self.dtype)\r\n"]
[156.890594, "o", "  1115\t\r\n"]
[156.915069, "o", "  1116\t    def searchsorted(\r\n"]
[156.939545, "o", "  1117\t        self,\r\n"]
[156.96402, "o", "  1118\t        v: ArrayLike | object,\r\n"]
[156.988495, "o", "  1119\t        side: Literal[\"left\", \"right\"] = \"left\",\r\n"]
[157.01297, "o", "  1120\t        sorter: NumpySorter = None,\r\n"]
[157.037446, "o", "  1121\t    ) -> npt.NDArray[np.intp] | np.intp:\r\n"]
[157.061921, "o", "  1122\t        msg = \"searchsorted requires high memory usage.\"\r\n"]
[157.086396, "o", "  1123\t        warnings.warn(msg, PerformanceWarning, stacklevel=find_stack_level())\r\n"]
[157.110871, "o", "  1124\t        if not is_scalar(v):\r\n"]
[157.135347, "o", "  1125\t            v = np.asarray(v)\r\n"]
[157.159822, "o", "  1126\t        v = np.asarray(v)\r\n"]
[157.184297, "o", "  1127\t        return np.asarray(self, dtype=self.dtype.subtype).searchsorted(v, side, sorter)\r\n"]
[157.208772, "o", "  1128\t\r\n"]
[157.233248, "o", "  1129\t    def copy(self) -> Self:\r\n"]
[157.257723, "o", "  1130\t        values = self.sp_values.copy()\r\n"]
[157.282198, "o", "  1131\t        return self._simple_new(values, self.sp_index, self.dtype)\r\n"]
[157.306673, "o", "  1132\t\r\n"]
[157.331149, "o", "  1133\t    @classmethod\r\n"]
[157.355624, "o", "  1134\t    def _concat_same_type(cls, to_concat: Sequence[Self]) -> Self:\r\n"]
[157.380099, "o", "  1135\t        fill_value = to_concat[0].fill_value\r\n"]
[157.404574, "o", "  1136\t\r\n"]
[157.42905, "o", "  1137\t        values = []\r\n"]
[157.453525, "o", "  1138\t        length = 0\r\n"]
[157.478, "o", "  1139\t\r\n"]
[157.502475, "o", "  1140\t        if to_concat:\r\n"]
[157.52695, "o", "  1141\t            sp_kind = to_concat[0].kind\r\n"]
[157.551426, "o", "  1142\t        else:\r\n"]
[157.575901, "o", "  1143\t            sp_kind = \"integer\"\r\n"]
[157.600376, "o", "  1144\t\r\n"]
[157.624851, "o", "  1145\t        sp_index: SparseIndex\r\n"]
[157.649327, "o", "  1146\t        if sp_kind == \"integer\":\r\n"]
[157.673802, "o", "  1147\t            indices = []\r\n"]
[157.698277, "o", "  1148\t\r\n"]
[157.722752, "o", "  1149\t            for arr in to_concat:\r\n"]
[157.747228, "o", "  1150\t                int_idx = arr.sp_index.indices.copy()\r\n"]
[157.771703, "o", "  1151\t                int_idx += length  # TODO: wraparound\r\n"]
[157.796178, "o", "  1152\t                length += arr.sp_index.length\r\n"]
[157.820653, "o", "  1153\t\r\n"]
[157.845129, "o", "  1154\t                values.append(arr.sp_values)\r\n"]
[157.869604, "o", "  1155\t                indices.append(int_idx)\r\n"]
[157.894079, "o", "  1156\t\r\n"]
[157.918554, "o", "  1157\t            data = np.concatenate(values)\r\n"]
[157.94303, "o", "  1158\t            indices_arr = np.concatenate(indices)\r\n"]
[157.967505, "o", "  1159\t            # error: Argument 2 to \"IntIndex\" has incompatible type\r\n"]
[157.99198, "o", "  1160\t            # \"ndarray[Any, dtype[signedinteger[_32Bit]]]\";\r\n"]
[158.016455, "o", "  1161\t            # expected \"Sequence[int]\"\r\n"]
[158.040931, "o", "  1162\t            sp_index = IntIndex(length, indices_arr)  # type: ignore[arg-type]\r\n"]
[158.065406, "o", "  1163\t\r\n"]
[158.089881, "o", "  1164\t        else:\r\n"]
[158.114356, "o", "  1165\t            # when concatenating block indices, we don't claim that you'll\r\n"]
[158.138832, "o", "  1166\t            # get an identical index as concatenating the values and then\r\n"]
[158.163307, "o", "  1167\t            # creating a new index. We don't want to spend the time trying\r\n"]
[158.187782, "o", "  1168\t            # to merge blocks across arrays in `to_concat`, so the resulting\r\n"]
[158.212257, "o", "  1169\t            # BlockIndex may have more blocks.\r\n"]
[158.236733, "o", "  1170\t            blengths = []\r\n"]
[158.261208, "o", "  1171\t            blocs = []\r\n"]
[158.285683, "o", "  1172\t\r\n"]
[158.310158, "o", "  1173\t            for arr in to_concat:\r\n"]
[158.334634, "o", "  1174\t                block_idx = arr.sp_index.to_block_index()\r\n"]
[158.359109, "o", "  1175\t\r\n"]
[158.383584, "o", "  1176\t                values.append(arr.sp_values)\r\n"]
[158.408059, "o", "  1177\t                blocs.append(block_idx.blocs.copy() + length)\r\n"]
[158.432535, "o", "  1178\t                blengths.append(block_idx.blengths)\r\n"]
[158.45701, "o", "  1179\t                length += arr.sp_index.length\r\n"]
[158.481485, "o", "  1180\t\r\n"]
[158.50596, "o", "  1181\t            data = np.concatenate(values)\r\n"]
[158.530436, "o", "  1182\t            blocs_arr = np.concatenate(blocs)\r\n"]
[158.554911, "o", "  1183\t            blengths_arr = np.concatenate(blengths)\r\n"]
[158.579386, "o", "  1184\t\r\n"]
[158.603861, "o", "  1185\t            sp_index = BlockIndex(length, blocs_arr, blengths_arr)\r\n"]
[158.628337, "o", "  1186\t\r\n"]
[158.652812, "o", "  1187\t        return cls(data, sparse_index=sp_index, fill_value=fill_value)\r\n"]
[158.677287, "o", "  1188\t\r\n"]
[158.701762, "o", "  1189\t    def astype(self, dtype: AstypeArg | None = None, copy: bool = True):\r\n"]
[158.726238, "o", "  1190\t        \"\"\"\r\n"]
[158.750713, "o", "  1191\t        Change the dtype of a SparseArray.\r\n"]
[158.775188, "o", "  1192\t\r\n"]
[158.799663, "o", "  1193\t        The output will always be a SparseArray. To convert to a dense\r\n"]
[158.824139, "o", "  1194\t        ndarray with a certain dtype, use :meth:`numpy.asarray`.\r\n"]
[158.848614, "o", "  1195\t\r\n"]
[158.873089, "o", "  1196\t        Parameters\r\n"]
[158.897564, "o", "  1197\t        ----------\r\n"]
[158.92204, "o", "  1198\t        dtype : np.dtype or ExtensionDtype\r\n"]
[158.946515, "o", "  1199\t            For SparseDtype, this changes the dtype of\r\n"]
[158.97099, "o", "  1200\t            ``self.sp_values`` and the ``self.fill_value``.\r\n"]
[158.995465, "o", "  1201\t\r\n"]
[159.019941, "o", "  1202\t            For other dtypes, this only changes the dtype of\r\n"]
[159.044416, "o", "  1203\t            ``self.sp_values``.\r\n"]
[159.068891, "o", "  1204\t\r\n"]
[159.093366, "o", "  1205\t        copy : bool, default True\r\n"]
[159.117842, "o", "  1206\t            Whether to ensure a copy is made, even if not necessary.\r\n"]
[159.142317, "o", "  1207\t\r\n"]
[159.166792, "o", "  1208\t        Returns\r\n"]
[159.191267, "o", "  1209\t        -------\r\n"]
[159.215743, "o", "  1210\t        SparseArray\r\n"]
[159.240218, "o", "  1211\t\r\n"]
[159.264693, "o", "  1212\t        Examples\r\n"]
[159.289168, "o", "  1213\t        --------\r\n"]
[159.313644, "o", "  1214\t        >>> arr = pd.arrays.SparseArray([0, 0, 1, 2])\r\n"]
[159.338119, "o", "  1215\t        >>> arr\r\n"]
[159.362594, "o", "  1216\t        [0, 0, 1, 2]\r\n"]
[159.387069, "o", "  1217\t        Fill: 0\r\n"]
[159.411545, "o", "  1218\t        IntIndex\r\n"]
[159.43602, "o", "  1219\t        Indices: array([2, 3], dtype=int32)\r\n"]
[159.460495, "o", "  1220\t\r\n"]
[159.48497, "o", "  1221\t        >>> arr.astype(SparseDtype(np.dtype('int32')))\r\n"]
[159.509446, "o", "  1222\t        [0, 0, 1, 2]\r\n"]
[159.533921, "o", "  1223\t        Fill: 0\r\n"]
[159.558396, "o", "  1224\t        IntIndex\r\n"]
[159.582871, "o", "  1225\t        Indices: array([2, 3], dtype=int32)\r\n"]
[159.607347, "o", "  1226\t\r\n"]
[159.631822, "o", "  1227\t        Using a NumPy dtype with a different kind (e.g. float) will coerce\r\n"]
[159.656297, "o", "  1228\t        just ``self.sp_values``.\r\n"]
[159.680772, "o", "  1229\t\r\n"]
[159.705248, "o", "  1230\t        >>> arr.astype(SparseDtype(np.dtype('float64')))\r\n"]
[159.729723, "o", "  1231\t        ... # doctest: +NORMALIZE_WHITESPACE\r\n"]
[159.754198, "o", "  1232\t        [nan, nan, 1.0, 2.0]\r\n"]
[159.778673, "o", "  1233\t        Fill: nan\r\n"]
[159.803149, "o", "  1234\t        IntIndex\r\n"]
[159.827624, "o", "  1235\t        Indices: array([2, 3], dtype=int32)\r\n"]
[159.852099, "o", "  1236\t\r\n"]
[159.876574, "o", "  1237\t        Using a SparseDtype, you can also change the fill value as well.\r\n"]
[159.90105, "o", "  1238\t\r\n"]
[159.925525, "o", "  1239\t        >>> arr.astype(SparseDtype(\"float64\", fill_value=0.0))\r\n"]
[160.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[160.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1240,1500p'\r"]
[160.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1240,1500p'\r\n"]
[160.02487, "o", "\u001b[?2004l\r\n"]
[160.04374, "o", "  1240\t        ... # doctest: +NORMALIZE_WHITESPACE\r\n"]
[160.062611, "o", "  1241\t        [0.0, 0.0, 1.0, 2.0]\r\n"]
[160.081481, "o", "  1242\t        Fill: 0.0\r\n"]
[160.100351, "o", "  1243\t        IntIndex\r\n"]
[160.119221, "o", "  1244\t        Indices: array([2, 3], dtype=int32)\r\n"]
[160.138092, "o", "  1245\t        \"\"\"\r\n"]
[160.156962, "o", "  1246\t        if is_dtype_equal(dtype, self._dtype):\r\n"]
[160.175832, "o", "  1247\t            if not copy:\r\n"]
[160.194702, "o", "  1248\t                return self\r\n"]
[160.213573, "o", "  1249\t            else:\r\n"]
[160.232443, "o", "  1250\t                return self.copy()\r\n"]
[160.251313, "o", "  1251\t\r\n"]
[160.270183, "o", "  1252\t        future_dtype = pandas_dtype(dtype)\r\n"]
[160.289053, "o", "  1253\t        if not isinstance(future_dtype, SparseDtype):\r\n"]
[160.307924, "o", "  1254\t            # GH#34457\r\n"]
[160.326794, "o", "  1255\t            values = np.asarray(self)\r\n"]
[160.345664, "o", "  1256\t            values = ensure_wrapped_if_datetimelike(values)\r\n"]
[160.364534, "o", "  1257\t            return astype_array(values, dtype=future_dtype, copy=False)\r\n"]
[160.383405, "o", "  1258\t\r\n"]
[160.402275, "o", "  1259\t        dtype = self.dtype.update_dtype(dtype)\r\n"]
[160.421145, "o", "  1260\t        subtype = pandas_dtype(dtype._subtype_with_str)\r\n"]
[160.440015, "o", "  1261\t        subtype = cast(np.dtype, subtype)  # ensured by update_dtype\r\n"]
[160.458885, "o", "  1262\t        values = ensure_wrapped_if_datetimelike(self.sp_values)\r\n"]
[160.477756, "o", "  1263\t        sp_values = astype_array(values, subtype, copy=copy)\r\n"]
[160.496626, "o", "  1264\t        sp_values = np.asarray(sp_values)\r\n"]
[160.515496, "o", "  1265\t\r\n"]
[160.534366, "o", "  1266\t        return self._simple_new(sp_values, self.sp_index, dtype)\r\n"]
[160.553237, "o", "  1267\t\r\n"]
[160.572107, "o", "  1268\t    def map(self, mapper, na_action=None) -> Self:\r\n"]
[160.590977, "o", "  1269\t        \"\"\"\r\n"]
[160.609847, "o", "  1270\t        Map categories using an input mapping or function.\r\n"]
[160.628718, "o", "  1271\t\r\n"]
[160.647588, "o", "  1272\t        Parameters\r\n"]
[160.666458, "o", "  1273\t        ----------\r\n"]
[160.685328, "o", "  1274\t        mapper : dict, Series, callable\r\n"]
[160.704198, "o", "  1275\t            The correspondence from old values to new.\r\n"]
[160.723069, "o", "  1276\t        na_action : {None, 'ignore'}, default None\r\n"]
[160.741939, "o", "  1277\t            If 'ignore', propagate NA values, without passing them to the\r\n"]
[160.760809, "o", "  1278\t            mapping correspondence.\r\n"]
[160.779679, "o", "  1279\t\r\n"]
[160.79855, "o", "  1280\t        Returns\r\n"]
[160.81742, "o", "  1281\t        -------\r\n"]
[160.83629, "o", "  1282\t        SparseArray\r\n"]
[160.85516, "o", "  1283\t            The output array will have the same density as the input.\r\n"]
[160.874031, "o", "  1284\t            The output fill value will be the result of applying the\r\n"]
[160.892901, "o", "  1285\t            mapping to ``self.fill_value``\r\n"]
[160.911771, "o", "  1286\t\r\n"]
[160.930641, "o", "  1287\t        Examples\r\n"]
[160.949511, "o", "  1288\t        --------\r\n"]
[160.968382, "o", "  1289\t        >>> arr = pd.arrays.SparseArray([0, 1, 2])\r\n"]
[160.987252, "o", "  1290\t        >>> arr.map(lambda x: x + 10)\r\n"]
[161.006122, "o", "  1291\t        [10, 11, 12]\r\n"]
[161.024992, "o", "  1292\t        Fill: 10\r\n"]
[161.043863, "o", "  1293\t        IntIndex\r\n"]
[161.062733, "o", "  1294\t        Indices: array([1, 2], dtype=int32)\r\n"]
[161.081603, "o", "  1295\t\r\n"]
[161.100473, "o", "  1296\t        >>> arr.map({0: 10, 1: 11, 2: 12})\r\n"]
[161.119344, "o", "  1297\t        [10, 11, 12]\r\n"]
[161.138214, "o", "  1298\t        Fill: 10\r\n"]
[161.157084, "o", "  1299\t        IntIndex\r\n"]
[161.175954, "o", "  1300\t        Indices: array([1, 2], dtype=int32)\r\n"]
[161.194824, "o", "  1301\t\r\n"]
[161.213695, "o", "  1302\t        >>> arr.map(pd.Series([10, 11, 12], index=[0, 1, 2]))\r\n"]
[161.232565, "o", "  1303\t        [10, 11, 12]\r\n"]
[161.251435, "o", "  1304\t        Fill: 10\r\n"]
[161.270305, "o", "  1305\t        IntIndex\r\n"]
[161.289176, "o", "  1306\t        Indices: array([1, 2], dtype=int32)\r\n"]
[161.308046, "o", "  1307\t        \"\"\"\r\n"]
[161.326916, "o", "  1308\t        is_map = isinstance(mapper, (abc.Mapping, ABCSeries))\r\n"]
[161.345786, "o", "  1309\t\r\n"]
[161.364656, "o", "  1310\t        fill_val = self.fill_value\r\n"]
[161.383527, "o", "  1311\t\r\n"]
[161.402397, "o", "  1312\t        if na_action is None or notna(fill_val):\r\n"]
[161.421267, "o", "  1313\t            fill_val = mapper.get(fill_val, fill_val) if is_map else mapper(fill_val)\r\n"]
[161.440137, "o", "  1314\t\r\n"]
[161.459008, "o", "  1315\t        def func(sp_val):\r\n"]
[161.477878, "o", "  1316\t            new_sp_val = mapper.get(sp_val, None) if is_map else mapper(sp_val)\r\n"]
[161.496748, "o", "  1317\t            # check identity and equality because nans are not equal to each other\r\n"]
[161.515618, "o", "  1318\t            if new_sp_val is fill_val or new_sp_val == fill_val:\r\n"]
[161.534489, "o", "  1319\t                msg = \"fill value in the sparse values not supported\"\r\n"]
[161.553359, "o", "  1320\t                raise ValueError(msg)\r\n"]
[161.572229, "o", "  1321\t            return new_sp_val\r\n"]
[161.591099, "o", "  1322\t\r\n"]
[161.609969, "o", "  1323\t        sp_values = [func(x) for x in self.sp_values]\r\n"]
[161.62884, "o", "  1324\t\r\n"]
[161.64771, "o", "  1325\t        return type(self)(sp_values, sparse_index=self.sp_index, fill_value=fill_val)\r\n"]
[161.66658, "o", "  1326\t\r\n"]
[161.68545, "o", "  1327\t    def to_dense(self) -> np.ndarray:\r\n"]
[161.704321, "o", "  1328\t        \"\"\"\r\n"]
[161.723191, "o", "  1329\t        Convert SparseArray to a NumPy array.\r\n"]
[161.742061, "o", "  1330\t\r\n"]
[161.760931, "o", "  1331\t        Returns\r\n"]
[161.779802, "o", "  1332\t        -------\r\n"]
[161.798672, "o", "  1333\t        arr : NumPy array\r\n"]
[161.817542, "o", "  1334\t        \"\"\"\r\n"]
[161.836412, "o", "  1335\t        return np.asarray(self, dtype=self.sp_values.dtype)\r\n"]
[161.855282, "o", "  1336\t\r\n"]
[161.874153, "o", "  1337\t    def _where(self, mask, value):\r\n"]
[161.893023, "o", "  1338\t        # NB: may not preserve dtype, e.g. result may be Sparse[float64]\r\n"]
[161.911893, "o", "  1339\t        #  while self is Sparse[int64]\r\n"]
[161.930763, "o", "  1340\t        naive_implementation = np.where(mask, self, value)\r\n"]
[161.949634, "o", "  1341\t        dtype = SparseDtype(naive_implementation.dtype, fill_value=self.fill_value)\r\n"]
[161.968504, "o", "  1342\t        result = type(self)._from_sequence(naive_implementation, dtype=dtype)\r\n"]
[161.987374, "o", "  1343\t        return result\r\n"]
[162.006244, "o", "  1344\t\r\n"]
[162.025115, "o", "  1345\t    # ------------------------------------------------------------------------\r\n"]
[162.043985, "o", "  1346\t    # IO\r\n"]
[162.062855, "o", "  1347\t    # ------------------------------------------------------------------------\r\n"]
[162.081725, "o", "  1348\t    def __setstate__(self, state) -> None:\r\n"]
[162.100595, "o", "  1349\t        \"\"\"Necessary for making this object picklable\"\"\"\r\n"]
[162.119466, "o", "  1350\t        if isinstance(state, tuple):\r\n"]
[162.138336, "o", "  1351\t            # Compat for pandas < 0.24.0\r\n"]
[162.157206, "o", "  1352\t            nd_state, (fill_value, sp_index) = state\r\n"]
[162.176076, "o", "  1353\t            sparse_values = np.array([])\r\n"]
[162.194947, "o", "  1354\t            sparse_values.__setstate__(nd_state)\r\n"]
[162.213817, "o", "  1355\t\r\n"]
[162.232687, "o", "  1356\t            self._sparse_values = sparse_values\r\n"]
[162.251557, "o", "  1357\t            self._sparse_index = sp_index\r\n"]
[162.270427, "o", "  1358\t            self._dtype = SparseDtype(sparse_values.dtype, fill_value)\r\n"]
[162.289298, "o", "  1359\t        else:\r\n"]
[162.308168, "o", "  1360\t            self.__dict__.update(state)\r\n"]
[162.327038, "o", "  1361\t\r\n"]
[162.345908, "o", "  1362\t    def nonzero(self) -> tuple[npt.NDArray[np.int32]]:\r\n"]
[162.364779, "o", "  1363\t        if self.fill_value == 0:\r\n"]
[162.383649, "o", "  1364\t            return (self.sp_index.indices,)\r\n"]
[162.402519, "o", "  1365\t        else:\r\n"]
[162.421389, "o", "  1366\t            return (self.sp_index.indices[self.sp_values != 0],)\r\n"]
[162.44026, "o", "  1367\t\r\n"]
[162.45913, "o", "  1368\t    # ------------------------------------------------------------------------\r\n"]
[162.478, "o", "  1369\t    # Reductions\r\n"]
[162.49687, "o", "  1370\t    # ------------------------------------------------------------------------\r\n"]
[162.51574, "o", "  1371\t\r\n"]
[162.534611, "o", "  1372\t    def _reduce(self, name: str, *, skipna: bool = True, **kwargs):\r\n"]
[162.553481, "o", "  1373\t        method = getattr(self, name, None)\r\n"]
[162.572351, "o", "  1374\t\r\n"]
[162.591221, "o", "  1375\t        if method is None:\r\n"]
[162.610092, "o", "  1376\t            raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\r\n"]
[162.628962, "o", "  1377\t\r\n"]
[162.647832, "o", "  1378\t        if skipna:\r\n"]
[162.666702, "o", "  1379\t            arr = self\r\n"]
[162.685573, "o", "  1380\t        else:\r\n"]
[162.704443, "o", "  1381\t            arr = self.dropna()\r\n"]
[162.723313, "o", "  1382\t\r\n"]
[162.742183, "o", "  1383\t        return getattr(arr, name)(**kwargs)\r\n"]
[162.761053, "o", "  1384\t\r\n"]
[162.779924, "o", "  1385\t    def all(self, axis=None, *args, **kwargs):\r\n"]
[162.798794, "o", "  1386\t        \"\"\"\r\n"]
[162.817664, "o", "  1387\t        Tests whether all elements evaluate True\r\n"]
[162.836534, "o", "  1388\t\r\n"]
[162.855405, "o", "  1389\t        Returns\r\n"]
[162.874275, "o", "  1390\t        -------\r\n"]
[162.893145, "o", "  1391\t        all : bool\r\n"]
[162.912015, "o", "  1392\t\r\n"]
[162.930885, "o", "  1393\t        See Also\r\n"]
[162.949756, "o", "  1394\t        --------\r\n"]
[162.968626, "o", "  1395\t        numpy.all\r\n"]
[162.987496, "o", "  1396\t        \"\"\"\r\n"]
[163.006366, "o", "  1397\t        nv.validate_all(args, kwargs)\r\n"]
[163.025237, "o", "  1398\t\r\n"]
[163.044107, "o", "  1399\t        values = self.sp_values\r\n"]
[163.062977, "o", "  1400\t\r\n"]
[163.081847, "o", "  1401\t        if len(values) != len(self) and not np.all(self.fill_value):\r\n"]
[163.100718, "o", "  1402\t            return False\r\n"]
[163.119588, "o", "  1403\t\r\n"]
[163.138458, "o", "  1404\t        return values.all()\r\n"]
[163.157328, "o", "  1405\t\r\n"]
[163.176198, "o", "  1406\t    def any(self, axis: AxisInt = 0, *args, **kwargs):\r\n"]
[163.195069, "o", "  1407\t        \"\"\"\r\n"]
[163.213939, "o", "  1408\t        Tests whether at least one of elements evaluate True\r\n"]
[163.232809, "o", "  1409\t\r\n"]
[163.251679, "o", "  1410\t        Returns\r\n"]
[163.27055, "o", "  1411\t        -------\r\n"]
[163.28942, "o", "  1412\t        any : bool\r\n"]
[163.30829, "o", "  1413\t\r\n"]
[163.32716, "o", "  1414\t        See Also\r\n"]
[163.346031, "o", "  1415\t        --------\r\n"]
[163.364901, "o", "  1416\t        numpy.any\r\n"]
[163.383771, "o", "  1417\t        \"\"\"\r\n"]
[163.402641, "o", "  1418\t        nv.validate_any(args, kwargs)\r\n"]
[163.421511, "o", "  1419\t\r\n"]
[163.440382, "o", "  1420\t        values = self.sp_values\r\n"]
[163.459252, "o", "  1421\t\r\n"]
[163.478122, "o", "  1422\t        if len(values) != len(self) and np.any(self.fill_value):\r\n"]
[163.496992, "o", "  1423\t            return True\r\n"]
[163.515863, "o", "  1424\t\r\n"]
[163.534733, "o", "  1425\t        return values.any().item()\r\n"]
[163.553603, "o", "  1426\t\r\n"]
[163.572473, "o", "  1427\t    def sum(\r\n"]
[163.591344, "o", "  1428\t        self,\r\n"]
[163.610214, "o", "  1429\t        axis: AxisInt = 0,\r\n"]
[163.629084, "o", "  1430\t        min_count: int = 0,\r\n"]
[163.647954, "o", "  1431\t        skipna: bool = True,\r\n"]
[163.666824, "o", "  1432\t        *args,\r\n"]
[163.685695, "o", "  1433\t        **kwargs,\r\n"]
[163.704565, "o", "  1434\t    ) -> Scalar:\r\n"]
[163.723435, "o", "  1435\t        \"\"\"\r\n"]
[163.742305, "o", "  1436\t        Sum of non-NA/null values\r\n"]
[163.761176, "o", "  1437\t\r\n"]
[163.780046, "o", "  1438\t        Parameters\r\n"]
[163.798916, "o", "  1439\t        ----------\r\n"]
[163.817786, "o", "  1440\t        axis : int, default 0\r\n"]
[163.836656, "o", "  1441\t            Not Used. NumPy compatibility.\r\n"]
[163.855527, "o", "  1442\t        min_count : int, default 0\r\n"]
[163.874397, "o", "  1443\t            The required number of valid values to perform the summation. If fewer\r\n"]
[163.893267, "o", "  1444\t            than ``min_count`` valid values are present, the result will be the missing\r\n"]
[163.912137, "o", "  1445\t            value indicator for subarray type.\r\n"]
[163.931008, "o", "  1446\t        *args, **kwargs\r\n"]
[163.949878, "o", "  1447\t            Not Used. NumPy compatibility.\r\n"]
[163.968748, "o", "  1448\t\r\n"]
[163.987618, "o", "  1449\t        Returns\r\n"]
[164.006489, "o", "  1450\t        -------\r\n"]
[164.025359, "o", "  1451\t        scalar\r\n"]
[164.044229, "o", "  1452\t        \"\"\"\r\n"]
[164.063099, "o", "  1453\t        nv.validate_sum(args, kwargs)\r\n"]
[164.081969, "o", "  1454\t        valid_vals = self._valid_sp_values\r\n"]
[164.10084, "o", "  1455\t        sp_sum = valid_vals.sum()\r\n"]
[164.11971, "o", "  1456\t        has_na = self.sp_index.ngaps > 0 and not self._null_fill_value\r\n"]
[164.13858, "o", "  1457\t\r\n"]
[164.15745, "o", "  1458\t        if has_na and not skipna:\r\n"]
[164.176321, "o", "  1459\t            return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[164.195191, "o", "  1460\t\r\n"]
[164.214061, "o", "  1461\t        if self._null_fill_value:\r\n"]
[164.232931, "o", "  1462\t            if check_below_min_count(valid_vals.shape, None, min_count):\r\n"]
[164.251802, "o", "  1463\t                return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[164.270672, "o", "  1464\t            return sp_sum\r\n"]
[164.289542, "o", "  1465\t        else:\r\n"]
[164.308412, "o", "  1466\t            nsparse = self.sp_index.ngaps\r\n"]
[164.327282, "o", "  1467\t            if check_below_min_count(valid_vals.shape, None, min_count - nsparse):\r\n"]
[164.346153, "o", "  1468\t                return na_value_for_dtype(self.dtype.subtype, compat=False)\r\n"]
[164.365023, "o", "  1469\t            return sp_sum + self.fill_value * nsparse\r\n"]
[164.383893, "o", "  1470\t\r\n"]
[164.402763, "o", "  1471\t    def cumsum(self, axis: AxisInt = 0, *args, **kwargs) -> SparseArray:\r\n"]
[164.421634, "o", "  1472\t        \"\"\"\r\n"]
[164.440504, "o", "  1473\t        Cumulative sum of non-NA/null values.\r\n"]
[164.459374, "o", "  1474\t\r\n"]
[164.478244, "o", "  1475\t        When performing the cumulative summation, any non-NA/null values will\r\n"]
[164.497115, "o", "  1476\t        be skipped. The resulting SparseArray will preserve the locations of\r\n"]
[164.515985, "o", "  1477\t        NaN values, but the fill value will be `np.nan` regardless.\r\n"]
[164.534855, "o", "  1478\t\r\n"]
[164.553725, "o", "  1479\t        Parameters\r\n"]
[164.572595, "o", "  1480\t        ----------\r\n"]
[164.591466, "o", "  1481\t        axis : int or None\r\n"]
[164.610336, "o", "  1482\t            Axis over which to perform the cumulative summation. If None,\r\n"]
[164.629206, "o", "  1483\t            perform cumulative summation over flattened array.\r\n"]
[164.648076, "o", "  1484\t\r\n"]
[164.666947, "o", "  1485\t        Returns\r\n"]
[164.685817, "o", "  1486\t        -------\r\n"]
[164.704687, "o", "  1487\t        cumsum : SparseArray\r\n"]
[164.723557, "o", "  1488\t        \"\"\"\r\n"]
[164.742427, "o", "  1489\t        nv.validate_cumsum(args, kwargs)\r\n"]
[164.761298, "o", "  1490\t\r\n"]
[164.780168, "o", "  1491\t        if axis is not None and axis >= self.ndim:  # Mimic ndarray behaviour.\r\n"]
[164.799038, "o", "  1492\t            raise ValueError(f\"axis(={axis}) out of bounds\")\r\n"]
[164.817908, "o", "  1493\t\r\n"]
[164.836779, "o", "  1494\t        if not self._null_fill_value:\r\n"]
[164.855649, "o", "  1495\t            return SparseArray(self.to_dense()).cumsum()\r\n"]
[164.874519, "o", "  1496\t\r\n"]
[164.893389, "o", "  1497\t        return SparseArray(\r\n"]
[164.91226, "o", "  1498\t            self.sp_values.cumsum(),\r\n"]
[164.93113, "o", "  1499\t            sparse_index=self.sp_index,\r\n"]
[165.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[165.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '860,980p'\r"]
[165.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '860,980p'\r\n"]
[165.046525, "o", "\u001b[?2004l\r\n"]
[165.087049, "o", "   860\t        Returns\r\n"]
[165.127574, "o", "   861\t        -------\r\n"]
[165.168098, "o", "   862\t        counts : Series\r\n"]
[165.208623, "o", "   863\t        \"\"\"\r\n"]
[165.249148, "o", "   864\t        from pandas import (\r\n"]
[165.289672, "o", "   865\t            Index,\r\n"]
[165.330197, "o", "   866\t            Series,\r\n"]
[165.370721, "o", "   867\t        )\r\n"]
[165.411246, "o", "   868\t\r\n"]
[165.45177, "o", "   869\t        keys, counts = algos.value_counts_arraylike(self.sp_values, dropna=dropna)\r\n"]
[165.492295, "o", "   870\t        fcounts = self.sp_index.ngaps\r\n"]
[165.53282, "o", "   871\t        if fcounts > 0 and (not self._null_fill_value or not dropna):\r\n"]
[165.573344, "o", "   872\t            mask = isna(keys) if self._null_fill_value else keys == self.fill_value\r\n"]
[165.613869, "o", "   873\t            if mask.any():\r\n"]
[165.654393, "o", "   874\t                counts[mask] += fcounts\r\n"]
[165.694918, "o", "   875\t            else:\r\n"]
[165.735443, "o", "   876\t                # error: Argument 1 to \"insert\" has incompatible type \"Union[\r\n"]
[165.775967, "o", "   877\t                # ExtensionArray,ndarray[Any, Any]]\"; expected \"Union[\r\n"]
[165.816492, "o", "   878\t                # _SupportsArray[dtype[Any]], Sequence[_SupportsArray[dtype\r\n"]
[165.857016, "o", "   879\t                # [Any]]], Sequence[Sequence[_SupportsArray[dtype[Any]]]],\r\n"]
[165.897541, "o", "   880\t                # Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]], Sequence\r\n"]
[165.938066, "o", "   881\t                # [Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]]]]\"\r\n"]
[165.97859, "o", "   882\t                keys = np.insert(keys, 0, self.fill_value)  # type: ignore[arg-type]\r\n"]
[166.019115, "o", "   883\t                counts = np.insert(counts, 0, fcounts)\r\n"]
[166.059639, "o", "   884\t\r\n"]
[166.100164, "o", "   885\t        if not isinstance(keys, ABCIndex):\r\n"]
[166.140689, "o", "   886\t            index = Index(keys)\r\n"]
[166.181213, "o", "   887\t        else:\r\n"]
[166.221738, "o", "   888\t            index = keys\r\n"]
[166.262262, "o", "   889\t        return Series(counts, index=index, copy=False)\r\n"]
[166.302787, "o", "   890\t\r\n"]
[166.343311, "o", "   891\t    # --------\r\n"]
[166.383836, "o", "   892\t    # Indexing\r\n"]
[166.424361, "o", "   893\t    # --------\r\n"]
[166.464885, "o", "   894\t    @overload\r\n"]
[166.50541, "o", "   895\t    def __getitem__(self, key: ScalarIndexer) -> Any:\r\n"]
[166.545934, "o", "   896\t        ...\r\n"]
[166.586459, "o", "   897\t\r\n"]
[166.626984, "o", "   898\t    @overload\r\n"]
[166.667508, "o", "   899\t    def __getitem__(\r\n"]
[166.708033, "o", "   900\t        self,\r\n"]
[166.748557, "o", "   901\t        key: SequenceIndexer | tuple[int | ellipsis, ...],\r\n"]
[166.789082, "o", "   902\t    ) -> Self:\r\n"]
[166.829607, "o", "   903\t        ...\r\n"]
[166.870131, "o", "   904\t\r\n"]
[166.910656, "o", "   905\t    def __getitem__(\r\n"]
[166.95118, "o", "   906\t        self,\r\n"]
[166.991705, "o", "   907\t        key: PositionalIndexer | tuple[int | ellipsis, ...],\r\n"]
[167.03223, "o", "   908\t    ) -> Self | Any:\r\n"]
[167.072754, "o", "   909\t        if isinstance(key, tuple):\r\n"]
[167.113279, "o", "   910\t            key = unpack_tuple_and_ellipses(key)\r\n"]
[167.153803, "o", "   911\t            if key is Ellipsis:\r\n"]
[167.194328, "o", "   912\t                raise ValueError(\"Cannot slice with Ellipsis\")\r\n"]
[167.234852, "o", "   913\t\r\n"]
[167.275377, "o", "   914\t        if is_integer(key):\r\n"]
[167.315902, "o", "   915\t            return self._get_val_at(key)\r\n"]
[167.356426, "o", "   916\t        elif isinstance(key, tuple):\r\n"]
[167.396951, "o", "   917\t            # error: Invalid index type \"Tuple[Union[int, ellipsis], ...]\"\r\n"]
[167.437475, "o", "   918\t            # for \"ndarray[Any, Any]\"; expected type\r\n"]
[167.478, "o", "   919\t            # \"Union[SupportsIndex, _SupportsArray[dtype[Union[bool_,\r\n"]
[167.518525, "o", "   920\t            # integer[Any]]]], _NestedSequence[_SupportsArray[dtype[\r\n"]
[167.559049, "o", "   921\t            # Union[bool_, integer[Any]]]]], _NestedSequence[Union[\r\n"]
[167.599574, "o", "   922\t            # bool, int]], Tuple[Union[SupportsIndex, _SupportsArray[\r\n"]
[167.640098, "o", "   923\t            # dtype[Union[bool_, integer[Any]]]], _NestedSequence[\r\n"]
[167.680623, "o", "   924\t            # _SupportsArray[dtype[Union[bool_, integer[Any]]]]],\r\n"]
[167.721148, "o", "   925\t            # _NestedSequence[Union[bool, int]]], ...]]\"\r\n"]
[167.761672, "o", "   926\t            data_slice = self.to_dense()[key]  # type: ignore[index]\r\n"]
[167.802197, "o", "   927\t        elif isinstance(key, slice):\r\n"]
[167.842721, "o", "   928\t            # Avoid densifying when handling contiguous slices\r\n"]
[167.883246, "o", "   929\t            if key.step is None or key.step == 1:\r\n"]
[167.92377, "o", "   930\t                start = 0 if key.start is None else key.start\r\n"]
[167.964295, "o", "   931\t                if start < 0:\r\n"]
[168.00482, "o", "   932\t                    start += len(self)\r\n"]
[168.045344, "o", "   933\t\r\n"]
[168.085869, "o", "   934\t                end = len(self) if key.stop is None else key.stop\r\n"]
[168.126393, "o", "   935\t                if end < 0:\r\n"]
[168.166918, "o", "   936\t                    end += len(self)\r\n"]
[168.207443, "o", "   937\t\r\n"]
[168.247967, "o", "   938\t                indices = self.sp_index.indices\r\n"]
[168.288492, "o", "   939\t                keep_inds = np.flatnonzero((indices >= start) & (indices < end))\r\n"]
[168.329016, "o", "   940\t                sp_vals = self.sp_values[keep_inds]\r\n"]
[168.369541, "o", "   941\t\r\n"]
[168.410066, "o", "   942\t                sp_index = indices[keep_inds].copy()\r\n"]
[168.45059, "o", "   943\t\r\n"]
[168.491115, "o", "   944\t                # If we've sliced to not include the start of the array, all our indices\r\n"]
[168.531639, "o", "   945\t                # should be shifted. NB: here we are careful to also not shift by a\r\n"]
[168.572164, "o", "   946\t                # negative value for a case like [0, 1][-100:] where the start index\r\n"]
[168.612689, "o", "   947\t                # should be treated like 0\r\n"]
[168.653213, "o", "   948\t                if start > 0:\r\n"]
[168.693738, "o", "   949\t                    sp_index -= start\r\n"]
[168.734262, "o", "   950\t\r\n"]
[168.774787, "o", "   951\t                # Length of our result should match applying this slice to a range\r\n"]
[168.815311, "o", "   952\t                # of the length of our original array\r\n"]
[168.855836, "o", "   953\t                new_len = len(range(len(self))[key])\r\n"]
[168.896361, "o", "   954\t                new_sp_index = make_sparse_index(new_len, sp_index, self.kind)\r\n"]
[168.936885, "o", "   955\t                return type(self)._simple_new(sp_vals, new_sp_index, self.dtype)\r\n"]
[168.97741, "o", "   956\t            else:\r\n"]
[169.017934, "o", "   957\t                indices = np.arange(len(self), dtype=np.int32)[key]\r\n"]
[169.058459, "o", "   958\t                return self.take(indices)\r\n"]
[169.098984, "o", "   959\t\r\n"]
[169.139508, "o", "   960\t        elif not is_list_like(key):\r\n"]
[169.180033, "o", "   961\t            # e.g. \"foo\" or 2.5\r\n"]
[169.220557, "o", "   962\t            # exception message copied from numpy\r\n"]
[169.261082, "o", "   963\t            raise IndexError(\r\n"]
[169.301607, "o", "   964\t                r\"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis \"\r\n"]
[169.342131, "o", "   965\t                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[169.382656, "o", "   966\t            )\r\n"]
[169.42318, "o", "   967\t\r\n"]
[169.463705, "o", "   968\t        else:\r\n"]
[169.50423, "o", "   969\t            if isinstance(key, SparseArray):\r\n"]
[169.544754, "o", "   970\t                # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[169.585279, "o", "   971\t                # has only fill_value - true, false or nan\r\n"]
[169.625803, "o", "   972\t                # (see GH PR 44955)\r\n"]
[169.666328, "o", "   973\t                # we can apply mask very fast:\r\n"]
[169.706852, "o", "   974\t                if is_bool_dtype(key):\r\n"]
[169.747377, "o", "   975\t                    if isna(key.fill_value):\r\n"]
[169.787902, "o", "   976\t                        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[169.828426, "o", "   977\t                    if not key.fill_value:\r\n"]
[169.868951, "o", "   978\t                        return self.take(key.sp_index.indices)\r\n"]
[169.909475, "o", "   979\t                    n = len(self)\r\n"]
[170.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[170.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '980,1140p'\r"]
[170.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '980,1140p'\r\n"]
[170.036519, "o", "\u001b[?2004l\r\n"]
[170.067037, "o", "   980\t                    mask = np.full(n, True, dtype=np.bool_)\r\n"]
[170.097556, "o", "   981\t                    mask[key.sp_index.indices] = False\r\n"]
[170.128074, "o", "   982\t                    return self.take(np.arange(n)[mask])\r\n"]
[170.158593, "o", "   983\t                else:\r\n"]
[170.189111, "o", "   984\t                    key = np.asarray(key)\r\n"]
[170.21963, "o", "   985\t\r\n"]
[170.250148, "o", "   986\t            key = check_array_indexer(self, key)\r\n"]
[170.280667, "o", "   987\t\r\n"]
[170.311185, "o", "   988\t            if com.is_bool_indexer(key):\r\n"]
[170.341704, "o", "   989\t                # mypy doesn't know we have an array here\r\n"]
[170.372222, "o", "   990\t                key = cast(np.ndarray, key)\r\n"]
[170.402741, "o", "   991\t                return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[170.433259, "o", "   992\t            elif hasattr(key, \"__len__\"):\r\n"]
[170.463778, "o", "   993\t                return self.take(key)\r\n"]
[170.494296, "o", "   994\t            else:\r\n"]
[170.524815, "o", "   995\t                raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[170.555333, "o", "   996\t\r\n"]
[170.585852, "o", "   997\t        return type(self)(data_slice, kind=self.kind)\r\n"]
[170.61637, "o", "   998\t\r\n"]
[170.646889, "o", "   999\t    def _get_val_at(self, loc):\r\n"]
[170.677407, "o", "  1000\t        loc = validate_insert_loc(loc, len(self))\r\n"]
[170.707926, "o", "  1001\t\r\n"]
[170.738444, "o", "  1002\t        sp_loc = self.sp_index.lookup(loc)\r\n"]
[170.768963, "o", "  1003\t        if sp_loc == -1:\r\n"]
[170.799481, "o", "  1004\t            return self.fill_value\r\n"]
[170.83, "o", "  1005\t        else:\r\n"]
[170.860519, "o", "  1006\t            val = self.sp_values[sp_loc]\r\n"]
[170.891037, "o", "  1007\t            val = maybe_box_datetimelike(val, self.sp_values.dtype)\r\n"]
[170.921556, "o", "  1008\t            return val\r\n"]
[170.952074, "o", "  1009\t\r\n"]
[170.982593, "o", "  1010\t    def take(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[171.013111, "o", "  1011\t        if is_scalar(indices):\r\n"]
[171.04363, "o", "  1012\t            raise ValueError(f\"'indices' must be an array, not a scalar '{indices}'.\")\r\n"]
[171.074148, "o", "  1013\t        indices = np.asarray(indices, dtype=np.int32)\r\n"]
[171.104667, "o", "  1014\t\r\n"]
[171.135185, "o", "  1015\t        dtype = None\r\n"]
[171.165704, "o", "  1016\t        if indices.size == 0:\r\n"]
[171.196222, "o", "  1017\t            result = np.array([], dtype=\"object\")\r\n"]
[171.226741, "o", "  1018\t            dtype = self.dtype\r\n"]
[171.257259, "o", "  1019\t        elif allow_fill:\r\n"]
[171.287778, "o", "  1020\t            result = self._take_with_fill(indices, fill_value=fill_value)\r\n"]
[171.318296, "o", "  1021\t        else:\r\n"]
[171.348815, "o", "  1022\t            return self._take_without_fill(indices)\r\n"]
[171.379333, "o", "  1023\t\r\n"]
[171.409852, "o", "  1024\t        return type(self)(\r\n"]
[171.44037, "o", "  1025\t            result, fill_value=self.fill_value, kind=self.kind, dtype=dtype\r\n"]
[171.470889, "o", "  1026\t        )\r\n"]
[171.501407, "o", "  1027\t\r\n"]
[171.531926, "o", "  1028\t    def _take_with_fill(self, indices, fill_value=None) -> np.ndarray:\r\n"]
[171.562444, "o", "  1029\t        if fill_value is None:\r\n"]
[171.592963, "o", "  1030\t            fill_value = self.dtype.na_value\r\n"]
[171.623481, "o", "  1031\t\r\n"]
[171.654, "o", "  1032\t        if indices.min() < -1:\r\n"]
[171.684519, "o", "  1033\t            raise ValueError(\r\n"]
[171.715037, "o", "  1034\t                \"Invalid value in 'indices'. Must be between -1 \"\r\n"]
[171.745556, "o", "  1035\t                \"and the length of the array.\"\r\n"]
[171.776074, "o", "  1036\t            )\r\n"]
[171.806593, "o", "  1037\t\r\n"]
[171.837111, "o", "  1038\t        if indices.max() >= len(self):\r\n"]
[171.86763, "o", "  1039\t            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[171.898148, "o", "  1040\t\r\n"]
[171.928667, "o", "  1041\t        if len(self) == 0:\r\n"]
[171.959185, "o", "  1042\t            # Empty... Allow taking only if all empty\r\n"]
[171.989704, "o", "  1043\t            if (indices == -1).all():\r\n"]
[172.020222, "o", "  1044\t                dtype = np.result_type(self.sp_values, type(fill_value))\r\n"]
[172.050741, "o", "  1045\t                taken = np.empty_like(indices, dtype=dtype)\r\n"]
[172.081259, "o", "  1046\t                taken.fill(fill_value)\r\n"]
[172.111778, "o", "  1047\t                return taken\r\n"]
[172.142296, "o", "  1048\t            else:\r\n"]
[172.172815, "o", "  1049\t                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[172.203333, "o", "  1050\t\r\n"]
[172.233852, "o", "  1051\t        # sp_indexer may be -1 for two reasons\r\n"]
[172.26437, "o", "  1052\t        # 1.) we took for an index of -1 (new)\r\n"]
[172.294889, "o", "  1053\t        # 2.) we took a value that was self.fill_value (old)\r\n"]
[172.325407, "o", "  1054\t        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[172.355926, "o", "  1055\t        new_fill_indices = indices == -1\r\n"]
[172.386444, "o", "  1056\t        old_fill_indices = (sp_indexer == -1) & ~new_fill_indices\r\n"]
[172.416963, "o", "  1057\t\r\n"]
[172.447481, "o", "  1058\t        if self.sp_index.npoints == 0 and old_fill_indices.all():\r\n"]
[172.478, "o", "  1059\t            # We've looked up all valid points on an all-sparse array.\r\n"]
[172.508519, "o", "  1060\t            taken = np.full(\r\n"]
[172.539037, "o", "  1061\t                sp_indexer.shape, fill_value=self.fill_value, dtype=self.dtype.subtype\r\n"]
[172.569556, "o", "  1062\t            )\r\n"]
[172.600074, "o", "  1063\t\r\n"]
[172.630593, "o", "  1064\t        elif self.sp_index.npoints == 0:\r\n"]
[172.661111, "o", "  1065\t            # Avoid taking from the empty self.sp_values\r\n"]
[172.69163, "o", "  1066\t            _dtype = np.result_type(self.dtype.subtype, type(fill_value))\r\n"]
[172.722148, "o", "  1067\t            taken = np.full(sp_indexer.shape, fill_value=fill_value, dtype=_dtype)\r\n"]
[172.752667, "o", "  1068\t        else:\r\n"]
[172.783185, "o", "  1069\t            taken = self.sp_values.take(sp_indexer)\r\n"]
[172.813704, "o", "  1070\t\r\n"]
[172.844222, "o", "  1071\t            # Fill in two steps.\r\n"]
[172.874741, "o", "  1072\t            # Old fill values\r\n"]
[172.905259, "o", "  1073\t            # New fill values\r\n"]
[172.935778, "o", "  1074\t            # potentially coercing to a new dtype at each stage.\r\n"]
[172.966296, "o", "  1075\t\r\n"]
[172.996815, "o", "  1076\t            m0 = sp_indexer[old_fill_indices] < 0\r\n"]
[173.027333, "o", "  1077\t            m1 = sp_indexer[new_fill_indices] < 0\r\n"]
[173.057852, "o", "  1078\t\r\n"]
[173.08837, "o", "  1079\t            result_type = taken.dtype\r\n"]
[173.118889, "o", "  1080\t\r\n"]
[173.149407, "o", "  1081\t            if m0.any():\r\n"]
[173.179926, "o", "  1082\t                result_type = np.result_type(result_type, type(self.fill_value))\r\n"]
[173.210444, "o", "  1083\t                taken = taken.astype(result_type)\r\n"]
[173.240963, "o", "  1084\t                taken[old_fill_indices] = self.fill_value\r\n"]
[173.271481, "o", "  1085\t\r\n"]
[173.302, "o", "  1086\t            if m1.any():\r\n"]
[173.332519, "o", "  1087\t                result_type = np.result_type(result_type, type(fill_value))\r\n"]
[173.363037, "o", "  1088\t                taken = taken.astype(result_type)\r\n"]
[173.393556, "o", "  1089\t                taken[new_fill_indices] = fill_value\r\n"]
[173.424074, "o", "  1090\t\r\n"]
[173.454593, "o", "  1091\t        return taken\r\n"]
[173.485111, "o", "  1092\t\r\n"]
[173.51563, "o", "  1093\t    def _take_without_fill(self, indices) -> Self:\r\n"]
[173.546148, "o", "  1094\t        to_shift = indices < 0\r\n"]
[173.576667, "o", "  1095\t\r\n"]
[173.607185, "o", "  1096\t        n = len(self)\r\n"]
[173.637704, "o", "  1097\t\r\n"]
[173.668222, "o", "  1098\t        if (indices.max() >= n) or (indices.min() < -n):\r\n"]
[173.698741, "o", "  1099\t            if n == 0:\r\n"]
[173.729259, "o", "  1100\t                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[173.759778, "o", "  1101\t            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[173.790296, "o", "  1102\t\r\n"]
[173.820815, "o", "  1103\t        if to_shift.any():\r\n"]
[173.851333, "o", "  1104\t            indices = indices.copy()\r\n"]
[173.881852, "o", "  1105\t            indices[to_shift] += n\r\n"]
[173.91237, "o", "  1106\t\r\n"]
[173.942889, "o", "  1107\t        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[173.973407, "o", "  1108\t        value_mask = sp_indexer != -1\r\n"]
[174.003926, "o", "  1109\t        new_sp_values = self.sp_values[sp_indexer[value_mask]]\r\n"]
[174.034444, "o", "  1110\t\r\n"]
[174.064963, "o", "  1111\t        value_indices = np.flatnonzero(value_mask).astype(np.int32, copy=False)\r\n"]
[174.095481, "o", "  1112\t\r\n"]
[174.126, "o", "  1113\t        new_sp_index = make_sparse_index(len(indices), value_indices, kind=self.kind)\r\n"]
[174.156519, "o", "  1114\t        return type(self)._simple_new(new_sp_values, new_sp_index, dtype=self.dtype)\r\n"]
[174.187037, "o", "  1115\t\r\n"]
[174.217556, "o", "  1116\t    def searchsorted(\r\n"]
[174.248074, "o", "  1117\t        self,\r\n"]
[174.278593, "o", "  1118\t        v: ArrayLike | object,\r\n"]
[174.309111, "o", "  1119\t        side: Literal[\"left\", \"right\"] = \"left\",\r\n"]
[174.33963, "o", "  1120\t        sorter: NumpySorter = None,\r\n"]
[174.370148, "o", "  1121\t    ) -> npt.NDArray[np.intp] | np.intp:\r\n"]
[174.400667, "o", "  1122\t        msg = \"searchsorted requires high memory usage.\"\r\n"]
[174.431185, "o", "  1123\t        warnings.warn(msg, PerformanceWarning, stacklevel=find_stack_level())\r\n"]
[174.461704, "o", "  1124\t        if not is_scalar(v):\r\n"]
[174.492222, "o", "  1125\t            v = np.asarray(v)\r\n"]
[174.522741, "o", "  1126\t        v = np.asarray(v)\r\n"]
[174.553259, "o", "  1127\t        return np.asarray(self, dtype=self.dtype.subtype).searchsorted(v, side, sorter)\r\n"]
[174.583778, "o", "  1128\t\r\n"]
[174.614296, "o", "  1129\t    def copy(self) -> Self:\r\n"]
[174.644815, "o", "  1130\t        values = self.sp_values.copy()\r\n"]
[174.675333, "o", "  1131\t        return self._simple_new(values, self.sp_index, self.dtype)\r\n"]
[174.705852, "o", "  1132\t\r\n"]
[174.73637, "o", "  1133\t    @classmethod\r\n"]
[174.766889, "o", "  1134\t    def _concat_same_type(cls, to_concat: Sequence[Self]) -> Self:\r\n"]
[174.797407, "o", "  1135\t        fill_value = to_concat[0].fill_value\r\n"]
[174.827926, "o", "  1136\t\r\n"]
[174.858444, "o", "  1137\t        values = []\r\n"]
[174.888963, "o", "  1138\t        length = 0\r\n"]
[174.919481, "o", "  1139\t\r\n"]
[175.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[175.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1140,1320p'\r"]
[175.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1140,1320p'\r\n"]
[175.033165, "o", "\u001b[?2004l\r\n"]
[175.06033, "o", "  1140\t        if to_concat:\r\n"]
[175.087495, "o", "  1141\t            sp_kind = to_concat[0].kind\r\n"]
[175.114659, "o", "  1142\t        else:\r\n"]
[175.141824, "o", "  1143\t            sp_kind = \"integer\"\r\n"]
[175.168989, "o", "  1144\t\r\n"]
[175.196154, "o", "  1145\t        sp_index: SparseIndex\r\n"]
[175.223319, "o", "  1146\t        if sp_kind == \"integer\":\r\n"]
[175.250484, "o", "  1147\t            indices = []\r\n"]
[175.277648, "o", "  1148\t\r\n"]
[175.304813, "o", "  1149\t            for arr in to_concat:\r\n"]
[175.331978, "o", "  1150\t                int_idx = arr.sp_index.indices.copy()\r\n"]
[175.359143, "o", "  1151\t                int_idx += length  # TODO: wraparound\r\n"]
[175.386308, "o", "  1152\t                length += arr.sp_index.length\r\n"]
[175.413473, "o", "  1153\t\r\n"]
[175.440637, "o", "  1154\t                values.append(arr.sp_values)\r\n"]
[175.467802, "o", "  1155\t                indices.append(int_idx)\r\n"]
[175.494967, "o", "  1156\t\r\n"]
[175.522132, "o", "  1157\t            data = np.concatenate(values)\r\n"]
[175.549297, "o", "  1158\t            indices_arr = np.concatenate(indices)\r\n"]
[175.576462, "o", "  1159\t            # error: Argument 2 to \"IntIndex\" has incompatible type\r\n"]
[175.603626, "o", "  1160\t            # \"ndarray[Any, dtype[signedinteger[_32Bit]]]\";\r\n"]
[175.630791, "o", "  1161\t            # expected \"Sequence[int]\"\r\n"]
[175.657956, "o", "  1162\t            sp_index = IntIndex(length, indices_arr)  # type: ignore[arg-type]\r\n"]
[175.685121, "o", "  1163\t\r\n"]
[175.712286, "o", "  1164\t        else:\r\n"]
[175.739451, "o", "  1165\t            # when concatenating block indices, we don't claim that you'll\r\n"]
[175.766615, "o", "  1166\t            # get an identical index as concatenating the values and then\r\n"]
[175.79378, "o", "  1167\t            # creating a new index. We don't want to spend the time trying\r\n"]
[175.820945, "o", "  1168\t            # to merge blocks across arrays in `to_concat`, so the resulting\r\n"]
[175.84811, "o", "  1169\t            # BlockIndex may have more blocks.\r\n"]
[175.875275, "o", "  1170\t            blengths = []\r\n"]
[175.90244, "o", "  1171\t            blocs = []\r\n"]
[175.929604, "o", "  1172\t\r\n"]
[175.956769, "o", "  1173\t            for arr in to_concat:\r\n"]
[175.983934, "o", "  1174\t                block_idx = arr.sp_index.to_block_index()\r\n"]
[176.011099, "o", "  1175\t\r\n"]
[176.038264, "o", "  1176\t                values.append(arr.sp_values)\r\n"]
[176.065429, "o", "  1177\t                blocs.append(block_idx.blocs.copy() + length)\r\n"]
[176.092593, "o", "  1178\t                blengths.append(block_idx.blengths)\r\n"]
[176.119758, "o", "  1179\t                length += arr.sp_index.length\r\n"]
[176.146923, "o", "  1180\t\r\n"]
[176.174088, "o", "  1181\t            data = np.concatenate(values)\r\n"]
[176.201253, "o", "  1182\t            blocs_arr = np.concatenate(blocs)\r\n"]
[176.228418, "o", "  1183\t            blengths_arr = np.concatenate(blengths)\r\n"]
[176.255582, "o", "  1184\t\r\n"]
[176.282747, "o", "  1185\t            sp_index = BlockIndex(length, blocs_arr, blengths_arr)\r\n"]
[176.309912, "o", "  1186\t\r\n"]
[176.337077, "o", "  1187\t        return cls(data, sparse_index=sp_index, fill_value=fill_value)\r\n"]
[176.364242, "o", "  1188\t\r\n"]
[176.391407, "o", "  1189\t    def astype(self, dtype: AstypeArg | None = None, copy: bool = True):\r\n"]
[176.418571, "o", "  1190\t        \"\"\"\r\n"]
[176.445736, "o", "  1191\t        Change the dtype of a SparseArray.\r\n"]
[176.472901, "o", "  1192\t\r\n"]
[176.500066, "o", "  1193\t        The output will always be a SparseArray. To convert to a dense\r\n"]
[176.527231, "o", "  1194\t        ndarray with a certain dtype, use :meth:`numpy.asarray`.\r\n"]
[176.554396, "o", "  1195\t\r\n"]
[176.58156, "o", "  1196\t        Parameters\r\n"]
[176.608725, "o", "  1197\t        ----------\r\n"]
[176.63589, "o", "  1198\t        dtype : np.dtype or ExtensionDtype\r\n"]
[176.663055, "o", "  1199\t            For SparseDtype, this changes the dtype of\r\n"]
[176.69022, "o", "  1200\t            ``self.sp_values`` and the ``self.fill_value``.\r\n"]
[176.717385, "o", "  1201\t\r\n"]
[176.744549, "o", "  1202\t            For other dtypes, this only changes the dtype of\r\n"]
[176.771714, "o", "  1203\t            ``self.sp_values``.\r\n"]
[176.798879, "o", "  1204\t\r\n"]
[176.826044, "o", "  1205\t        copy : bool, default True\r\n"]
[176.853209, "o", "  1206\t            Whether to ensure a copy is made, even if not necessary.\r\n"]
[176.880374, "o", "  1207\t\r\n"]
[176.907538, "o", "  1208\t        Returns\r\n"]
[176.934703, "o", "  1209\t        -------\r\n"]
[176.961868, "o", "  1210\t        SparseArray\r\n"]
[176.989033, "o", "  1211\t\r\n"]
[177.016198, "o", "  1212\t        Examples\r\n"]
[177.043363, "o", "  1213\t        --------\r\n"]
[177.070527, "o", "  1214\t        >>> arr = pd.arrays.SparseArray([0, 0, 1, 2])\r\n"]
[177.097692, "o", "  1215\t        >>> arr\r\n"]
[177.124857, "o", "  1216\t        [0, 0, 1, 2]\r\n"]
[177.152022, "o", "  1217\t        Fill: 0\r\n"]
[177.179187, "o", "  1218\t        IntIndex\r\n"]
[177.206352, "o", "  1219\t        Indices: array([2, 3], dtype=int32)\r\n"]
[177.233516, "o", "  1220\t\r\n"]
[177.260681, "o", "  1221\t        >>> arr.astype(SparseDtype(np.dtype('int32')))\r\n"]
[177.287846, "o", "  1222\t        [0, 0, 1, 2]\r\n"]
[177.315011, "o", "  1223\t        Fill: 0\r\n"]
[177.342176, "o", "  1224\t        IntIndex\r\n"]
[177.369341, "o", "  1225\t        Indices: array([2, 3], dtype=int32)\r\n"]
[177.396505, "o", "  1226\t\r\n"]
[177.42367, "o", "  1227\t        Using a NumPy dtype with a different kind (e.g. float) will coerce\r\n"]
[177.450835, "o", "  1228\t        just ``self.sp_values``.\r\n"]
[177.478, "o", "  1229\t\r\n"]
[177.505165, "o", "  1230\t        >>> arr.astype(SparseDtype(np.dtype('float64')))\r\n"]
[177.53233, "o", "  1231\t        ... # doctest: +NORMALIZE_WHITESPACE\r\n"]
[177.559495, "o", "  1232\t        [nan, nan, 1.0, 2.0]\r\n"]
[177.586659, "o", "  1233\t        Fill: nan\r\n"]
[177.613824, "o", "  1234\t        IntIndex\r\n"]
[177.640989, "o", "  1235\t        Indices: array([2, 3], dtype=int32)\r\n"]
[177.668154, "o", "  1236\t\r\n"]
[177.695319, "o", "  1237\t        Using a SparseDtype, you can also change the fill value as well.\r\n"]
[177.722484, "o", "  1238\t\r\n"]
[177.749648, "o", "  1239\t        >>> arr.astype(SparseDtype(\"float64\", fill_value=0.0))\r\n"]
[177.776813, "o", "  1240\t        ... # doctest: +NORMALIZE_WHITESPACE\r\n"]
[177.803978, "o", "  1241\t        [0.0, 0.0, 1.0, 2.0]\r\n"]
[177.831143, "o", "  1242\t        Fill: 0.0\r\n"]
[177.858308, "o", "  1243\t        IntIndex\r\n"]
[177.885473, "o", "  1244\t        Indices: array([2, 3], dtype=int32)\r\n"]
[177.912637, "o", "  1245\t        \"\"\"\r\n"]
[177.939802, "o", "  1246\t        if is_dtype_equal(dtype, self._dtype):\r\n"]
[177.966967, "o", "  1247\t            if not copy:\r\n"]
[177.994132, "o", "  1248\t                return self\r\n"]
[178.021297, "o", "  1249\t            else:\r\n"]
[178.048462, "o", "  1250\t                return self.copy()\r\n"]
[178.075626, "o", "  1251\t\r\n"]
[178.102791, "o", "  1252\t        future_dtype = pandas_dtype(dtype)\r\n"]
[178.129956, "o", "  1253\t        if not isinstance(future_dtype, SparseDtype):\r\n"]
[178.157121, "o", "  1254\t            # GH#34457\r\n"]
[178.184286, "o", "  1255\t            values = np.asarray(self)\r\n"]
[178.211451, "o", "  1256\t            values = ensure_wrapped_if_datetimelike(values)\r\n"]
[178.238615, "o", "  1257\t            return astype_array(values, dtype=future_dtype, copy=False)\r\n"]
[178.26578, "o", "  1258\t\r\n"]
[178.292945, "o", "  1259\t        dtype = self.dtype.update_dtype(dtype)\r\n"]
[178.32011, "o", "  1260\t        subtype = pandas_dtype(dtype._subtype_with_str)\r\n"]
[178.347275, "o", "  1261\t        subtype = cast(np.dtype, subtype)  # ensured by update_dtype\r\n"]
[178.37444, "o", "  1262\t        values = ensure_wrapped_if_datetimelike(self.sp_values)\r\n"]
[178.401604, "o", "  1263\t        sp_values = astype_array(values, subtype, copy=copy)\r\n"]
[178.428769, "o", "  1264\t        sp_values = np.asarray(sp_values)\r\n"]
[178.455934, "o", "  1265\t\r\n"]
[178.483099, "o", "  1266\t        return self._simple_new(sp_values, self.sp_index, dtype)\r\n"]
[178.510264, "o", "  1267\t\r\n"]
[178.537429, "o", "  1268\t    def map(self, mapper, na_action=None) -> Self:\r\n"]
[178.564593, "o", "  1269\t        \"\"\"\r\n"]
[178.591758, "o", "  1270\t        Map categories using an input mapping or function.\r\n"]
[178.618923, "o", "  1271\t\r\n"]
[178.646088, "o", "  1272\t        Parameters\r\n"]
[178.673253, "o", "  1273\t        ----------\r\n"]
[178.700418, "o", "  1274\t        mapper : dict, Series, callable\r\n"]
[178.727582, "o", "  1275\t            The correspondence from old values to new.\r\n"]
[178.754747, "o", "  1276\t        na_action : {None, 'ignore'}, default None\r\n"]
[178.781912, "o", "  1277\t            If 'ignore', propagate NA values, without passing them to the\r\n"]
[178.809077, "o", "  1278\t            mapping correspondence.\r\n"]
[178.836242, "o", "  1279\t\r\n"]
[178.863407, "o", "  1280\t        Returns\r\n"]
[178.890571, "o", "  1281\t        -------\r\n"]
[178.917736, "o", "  1282\t        SparseArray\r\n"]
[178.944901, "o", "  1283\t            The output array will have the same density as the input.\r\n"]
[178.972066, "o", "  1284\t            The output fill value will be the result of applying the\r\n"]
[178.999231, "o", "  1285\t            mapping to ``self.fill_value``\r\n"]
[179.026396, "o", "  1286\t\r\n"]
[179.05356, "o", "  1287\t        Examples\r\n"]
[179.080725, "o", "  1288\t        --------\r\n"]
[179.10789, "o", "  1289\t        >>> arr = pd.arrays.SparseArray([0, 1, 2])\r\n"]
[179.135055, "o", "  1290\t        >>> arr.map(lambda x: x + 10)\r\n"]
[179.16222, "o", "  1291\t        [10, 11, 12]\r\n"]
[179.189385, "o", "  1292\t        Fill: 10\r\n"]
[179.216549, "o", "  1293\t        IntIndex\r\n"]
[179.243714, "o", "  1294\t        Indices: array([1, 2], dtype=int32)\r\n"]
[179.270879, "o", "  1295\t\r\n"]
[179.298044, "o", "  1296\t        >>> arr.map({0: 10, 1: 11, 2: 12})\r\n"]
[179.325209, "o", "  1297\t        [10, 11, 12]\r\n"]
[179.352374, "o", "  1298\t        Fill: 10\r\n"]
[179.379538, "o", "  1299\t        IntIndex\r\n"]
[179.406703, "o", "  1300\t        Indices: array([1, 2], dtype=int32)\r\n"]
[179.433868, "o", "  1301\t\r\n"]
[179.461033, "o", "  1302\t        >>> arr.map(pd.Series([10, 11, 12], index=[0, 1, 2]))\r\n"]
[179.488198, "o", "  1303\t        [10, 11, 12]\r\n"]
[179.515363, "o", "  1304\t        Fill: 10\r\n"]
[179.542527, "o", "  1305\t        IntIndex\r\n"]
[179.569692, "o", "  1306\t        Indices: array([1, 2], dtype=int32)\r\n"]
[179.596857, "o", "  1307\t        \"\"\"\r\n"]
[179.624022, "o", "  1308\t        is_map = isinstance(mapper, (abc.Mapping, ABCSeries))\r\n"]
[179.651187, "o", "  1309\t\r\n"]
[179.678352, "o", "  1310\t        fill_val = self.fill_value\r\n"]
[179.705516, "o", "  1311\t\r\n"]
[179.732681, "o", "  1312\t        if na_action is None or notna(fill_val):\r\n"]
[179.759846, "o", "  1313\t            fill_val = mapper.get(fill_val, fill_val) if is_map else mapper(fill_val)\r\n"]
[179.787011, "o", "  1314\t\r\n"]
[179.814176, "o", "  1315\t        def func(sp_val):\r\n"]
[179.841341, "o", "  1316\t            new_sp_val = mapper.get(sp_val, None) if is_map else mapper(sp_val)\r\n"]
[179.868505, "o", "  1317\t            # check identity and equality because nans are not equal to each other\r\n"]
[179.89567, "o", "  1318\t            if new_sp_val is fill_val or new_sp_val == fill_val:\r\n"]
[179.922835, "o", "  1319\t                msg = \"fill value in the sparse values not supported\"\r\n"]
[180.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[180.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '880,1000p'\r"]
[180.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '880,1000p'\r\n"]
[180.046525, "o", "\u001b[?2004l\r\n"]
[180.087049, "o", "   880\t                # Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]], Sequence\r\n"]
[180.127574, "o", "   881\t                # [Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]]]]\"\r\n"]
[180.168098, "o", "   882\t                keys = np.insert(keys, 0, self.fill_value)  # type: ignore[arg-type]\r\n"]
[180.208623, "o", "   883\t                counts = np.insert(counts, 0, fcounts)\r\n"]
[180.249148, "o", "   884\t\r\n"]
[180.289672, "o", "   885\t        if not isinstance(keys, ABCIndex):\r\n"]
[180.330197, "o", "   886\t            index = Index(keys)\r\n"]
[180.370721, "o", "   887\t        else:\r\n"]
[180.411246, "o", "   888\t            index = keys\r\n"]
[180.45177, "o", "   889\t        return Series(counts, index=index, copy=False)\r\n"]
[180.492295, "o", "   890\t\r\n"]
[180.53282, "o", "   891\t    # --------\r\n"]
[180.573344, "o", "   892\t    # Indexing\r\n"]
[180.613869, "o", "   893\t    # --------\r\n"]
[180.654393, "o", "   894\t    @overload\r\n"]
[180.694918, "o", "   895\t    def __getitem__(self, key: ScalarIndexer) -> Any:\r\n"]
[180.735443, "o", "   896\t        ...\r\n"]
[180.775967, "o", "   897\t\r\n"]
[180.816492, "o", "   898\t    @overload\r\n"]
[180.857016, "o", "   899\t    def __getitem__(\r\n"]
[180.897541, "o", "   900\t        self,\r\n"]
[180.938066, "o", "   901\t        key: SequenceIndexer | tuple[int | ellipsis, ...],\r\n"]
[180.97859, "o", "   902\t    ) -> Self:\r\n"]
[181.019115, "o", "   903\t        ...\r\n"]
[181.059639, "o", "   904\t\r\n"]
[181.100164, "o", "   905\t    def __getitem__(\r\n"]
[181.140689, "o", "   906\t        self,\r\n"]
[181.181213, "o", "   907\t        key: PositionalIndexer | tuple[int | ellipsis, ...],\r\n"]
[181.221738, "o", "   908\t    ) -> Self | Any:\r\n"]
[181.262262, "o", "   909\t        if isinstance(key, tuple):\r\n"]
[181.302787, "o", "   910\t            key = unpack_tuple_and_ellipses(key)\r\n"]
[181.343311, "o", "   911\t            if key is Ellipsis:\r\n"]
[181.383836, "o", "   912\t                raise ValueError(\"Cannot slice with Ellipsis\")\r\n"]
[181.424361, "o", "   913\t\r\n"]
[181.464885, "o", "   914\t        if is_integer(key):\r\n"]
[181.50541, "o", "   915\t            return self._get_val_at(key)\r\n"]
[181.545934, "o", "   916\t        elif isinstance(key, tuple):\r\n"]
[181.586459, "o", "   917\t            # error: Invalid index type \"Tuple[Union[int, ellipsis], ...]\"\r\n"]
[181.626984, "o", "   918\t            # for \"ndarray[Any, Any]\"; expected type\r\n"]
[181.667508, "o", "   919\t            # \"Union[SupportsIndex, _SupportsArray[dtype[Union[bool_,\r\n"]
[181.708033, "o", "   920\t            # integer[Any]]]], _NestedSequence[_SupportsArray[dtype[\r\n"]
[181.748557, "o", "   921\t            # Union[bool_, integer[Any]]]]], _NestedSequence[Union[\r\n"]
[181.789082, "o", "   922\t            # bool, int]], Tuple[Union[SupportsIndex, _SupportsArray[\r\n"]
[181.829607, "o", "   923\t            # dtype[Union[bool_, integer[Any]]]], _NestedSequence[\r\n"]
[181.870131, "o", "   924\t            # _SupportsArray[dtype[Union[bool_, integer[Any]]]]],\r\n"]
[181.910656, "o", "   925\t            # _NestedSequence[Union[bool, int]]], ...]]\"\r\n"]
[181.95118, "o", "   926\t            data_slice = self.to_dense()[key]  # type: ignore[index]\r\n"]
[181.991705, "o", "   927\t        elif isinstance(key, slice):\r\n"]
[182.03223, "o", "   928\t            # Avoid densifying when handling contiguous slices\r\n"]
[182.072754, "o", "   929\t            if key.step is None or key.step == 1:\r\n"]
[182.113279, "o", "   930\t                start = 0 if key.start is None else key.start\r\n"]
[182.153803, "o", "   931\t                if start < 0:\r\n"]
[182.194328, "o", "   932\t                    start += len(self)\r\n"]
[182.234852, "o", "   933\t\r\n"]
[182.275377, "o", "   934\t                end = len(self) if key.stop is None else key.stop\r\n"]
[182.315902, "o", "   935\t                if end < 0:\r\n"]
[182.356426, "o", "   936\t                    end += len(self)\r\n"]
[182.396951, "o", "   937\t\r\n"]
[182.437475, "o", "   938\t                indices = self.sp_index.indices\r\n"]
[182.478, "o", "   939\t                keep_inds = np.flatnonzero((indices >= start) & (indices < end))\r\n"]
[182.518525, "o", "   940\t                sp_vals = self.sp_values[keep_inds]\r\n"]
[182.559049, "o", "   941\t\r\n"]
[182.599574, "o", "   942\t                sp_index = indices[keep_inds].copy()\r\n"]
[182.640098, "o", "   943\t\r\n"]
[182.680623, "o", "   944\t                # If we've sliced to not include the start of the array, all our indices\r\n"]
[182.721148, "o", "   945\t                # should be shifted. NB: here we are careful to also not shift by a\r\n"]
[182.761672, "o", "   946\t                # negative value for a case like [0, 1][-100:] where the start index\r\n"]
[182.802197, "o", "   947\t                # should be treated like 0\r\n"]
[182.842721, "o", "   948\t                if start > 0:\r\n"]
[182.883246, "o", "   949\t                    sp_index -= start\r\n"]
[182.92377, "o", "   950\t\r\n"]
[182.964295, "o", "   951\t                # Length of our result should match applying this slice to a range\r\n"]
[183.00482, "o", "   952\t                # of the length of our original array\r\n"]
[183.045344, "o", "   953\t                new_len = len(range(len(self))[key])\r\n"]
[183.085869, "o", "   954\t                new_sp_index = make_sparse_index(new_len, sp_index, self.kind)\r\n"]
[183.126393, "o", "   955\t                return type(self)._simple_new(sp_vals, new_sp_index, self.dtype)\r\n"]
[183.166918, "o", "   956\t            else:\r\n"]
[183.207443, "o", "   957\t                indices = np.arange(len(self), dtype=np.int32)[key]\r\n"]
[183.247967, "o", "   958\t                return self.take(indices)\r\n"]
[183.288492, "o", "   959\t\r\n"]
[183.329016, "o", "   960\t        elif not is_list_like(key):\r\n"]
[183.369541, "o", "   961\t            # e.g. \"foo\" or 2.5\r\n"]
[183.410066, "o", "   962\t            # exception message copied from numpy\r\n"]
[183.45059, "o", "   963\t            raise IndexError(\r\n"]
[183.491115, "o", "   964\t                r\"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis \"\r\n"]
[183.531639, "o", "   965\t                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[183.572164, "o", "   966\t            )\r\n"]
[183.612689, "o", "   967\t\r\n"]
[183.653213, "o", "   968\t        else:\r\n"]
[183.693738, "o", "   969\t            if isinstance(key, SparseArray):\r\n"]
[183.734262, "o", "   970\t                # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[183.774787, "o", "   971\t                # has only fill_value - true, false or nan\r\n"]
[183.815311, "o", "   972\t                # (see GH PR 44955)\r\n"]
[183.855836, "o", "   973\t                # we can apply mask very fast:\r\n"]
[183.896361, "o", "   974\t                if is_bool_dtype(key):\r\n"]
[183.936885, "o", "   975\t                    if isna(key.fill_value):\r\n"]
[183.97741, "o", "   976\t                        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[184.017934, "o", "   977\t                    if not key.fill_value:\r\n"]
[184.058459, "o", "   978\t                        return self.take(key.sp_index.indices)\r\n"]
[184.098984, "o", "   979\t                    n = len(self)\r\n"]
[184.139508, "o", "   980\t                    mask = np.full(n, True, dtype=np.bool_)\r\n"]
[184.180033, "o", "   981\t                    mask[key.sp_index.indices] = False\r\n"]
[184.220557, "o", "   982\t                    return self.take(np.arange(n)[mask])\r\n"]
[184.261082, "o", "   983\t                else:\r\n"]
[184.301607, "o", "   984\t                    key = np.asarray(key)\r\n"]
[184.342131, "o", "   985\t\r\n"]
[184.382656, "o", "   986\t            key = check_array_indexer(self, key)\r\n"]
[184.42318, "o", "   987\t\r\n"]
[184.463705, "o", "   988\t            if com.is_bool_indexer(key):\r\n"]
[184.50423, "o", "   989\t                # mypy doesn't know we have an array here\r\n"]
[184.544754, "o", "   990\t                key = cast(np.ndarray, key)\r\n"]
[184.585279, "o", "   991\t                return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[184.625803, "o", "   992\t            elif hasattr(key, \"__len__\"):\r\n"]
[184.666328, "o", "   993\t                return self.take(key)\r\n"]
[184.706852, "o", "   994\t            else:\r\n"]
[184.747377, "o", "   995\t                raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[184.787902, "o", "   996\t\r\n"]
[184.828426, "o", "   997\t        return type(self)(data_slice, kind=self.kind)\r\n"]
[184.868951, "o", "   998\t\r\n"]
[184.909475, "o", "   999\t    def _get_val_at(self, loc):\r\n"]
[185.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[185.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1000,1160p'\r"]
[185.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1000,1160p'\r\n"]
[185.036519, "o", "\u001b[?2004l\r\n"]
[185.067037, "o", "  1000\t        loc = validate_insert_loc(loc, len(self))\r\n"]
[185.097556, "o", "  1001\t\r\n"]
[185.128074, "o", "  1002\t        sp_loc = self.sp_index.lookup(loc)\r\n"]
[185.158593, "o", "  1003\t        if sp_loc == -1:\r\n"]
[185.189111, "o", "  1004\t            return self.fill_value\r\n"]
[185.21963, "o", "  1005\t        else:\r\n"]
[185.250148, "o", "  1006\t            val = self.sp_values[sp_loc]\r\n"]
[185.280667, "o", "  1007\t            val = maybe_box_datetimelike(val, self.sp_values.dtype)\r\n"]
[185.311185, "o", "  1008\t            return val\r\n"]
[185.341704, "o", "  1009\t\r\n"]
[185.372222, "o", "  1010\t    def take(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[185.402741, "o", "  1011\t        if is_scalar(indices):\r\n"]
[185.433259, "o", "  1012\t            raise ValueError(f\"'indices' must be an array, not a scalar '{indices}'.\")\r\n"]
[185.463778, "o", "  1013\t        indices = np.asarray(indices, dtype=np.int32)\r\n"]
[185.494296, "o", "  1014\t\r\n"]
[185.524815, "o", "  1015\t        dtype = None\r\n"]
[185.555333, "o", "  1016\t        if indices.size == 0:\r\n"]
[185.585852, "o", "  1017\t            result = np.array([], dtype=\"object\")\r\n"]
[185.61637, "o", "  1018\t            dtype = self.dtype\r\n"]
[185.646889, "o", "  1019\t        elif allow_fill:\r\n"]
[185.677407, "o", "  1020\t            result = self._take_with_fill(indices, fill_value=fill_value)\r\n"]
[185.707926, "o", "  1021\t        else:\r\n"]
[185.738444, "o", "  1022\t            return self._take_without_fill(indices)\r\n"]
[185.768963, "o", "  1023\t\r\n"]
[185.799481, "o", "  1024\t        return type(self)(\r\n"]
[185.83, "o", "  1025\t            result, fill_value=self.fill_value, kind=self.kind, dtype=dtype\r\n"]
[185.860519, "o", "  1026\t        )\r\n"]
[185.891037, "o", "  1027\t\r\n"]
[185.921556, "o", "  1028\t    def _take_with_fill(self, indices, fill_value=None) -> np.ndarray:\r\n"]
[185.952074, "o", "  1029\t        if fill_value is None:\r\n"]
[185.982593, "o", "  1030\t            fill_value = self.dtype.na_value\r\n"]
[186.013111, "o", "  1031\t\r\n"]
[186.04363, "o", "  1032\t        if indices.min() < -1:\r\n"]
[186.074148, "o", "  1033\t            raise ValueError(\r\n"]
[186.104667, "o", "  1034\t                \"Invalid value in 'indices'. Must be between -1 \"\r\n"]
[186.135185, "o", "  1035\t                \"and the length of the array.\"\r\n"]
[186.165704, "o", "  1036\t            )\r\n"]
[186.196222, "o", "  1037\t\r\n"]
[186.226741, "o", "  1038\t        if indices.max() >= len(self):\r\n"]
[186.257259, "o", "  1039\t            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[186.287778, "o", "  1040\t\r\n"]
[186.318296, "o", "  1041\t        if len(self) == 0:\r\n"]
[186.348815, "o", "  1042\t            # Empty... Allow taking only if all empty\r\n"]
[186.379333, "o", "  1043\t            if (indices == -1).all():\r\n"]
[186.409852, "o", "  1044\t                dtype = np.result_type(self.sp_values, type(fill_value))\r\n"]
[186.44037, "o", "  1045\t                taken = np.empty_like(indices, dtype=dtype)\r\n"]
[186.470889, "o", "  1046\t                taken.fill(fill_value)\r\n"]
[186.501407, "o", "  1047\t                return taken\r\n"]
[186.531926, "o", "  1048\t            else:\r\n"]
[186.562444, "o", "  1049\t                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[186.592963, "o", "  1050\t\r\n"]
[186.623481, "o", "  1051\t        # sp_indexer may be -1 for two reasons\r\n"]
[186.654, "o", "  1052\t        # 1.) we took for an index of -1 (new)\r\n"]
[186.684519, "o", "  1053\t        # 2.) we took a value that was self.fill_value (old)\r\n"]
[186.715037, "o", "  1054\t        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[186.745556, "o", "  1055\t        new_fill_indices = indices == -1\r\n"]
[186.776074, "o", "  1056\t        old_fill_indices = (sp_indexer == -1) & ~new_fill_indices\r\n"]
[186.806593, "o", "  1057\t\r\n"]
[186.837111, "o", "  1058\t        if self.sp_index.npoints == 0 and old_fill_indices.all():\r\n"]
[186.86763, "o", "  1059\t            # We've looked up all valid points on an all-sparse array.\r\n"]
[186.898148, "o", "  1060\t            taken = np.full(\r\n"]
[186.928667, "o", "  1061\t                sp_indexer.shape, fill_value=self.fill_value, dtype=self.dtype.subtype\r\n"]
[186.959185, "o", "  1062\t            )\r\n"]
[186.989704, "o", "  1063\t\r\n"]
[187.020222, "o", "  1064\t        elif self.sp_index.npoints == 0:\r\n"]
[187.050741, "o", "  1065\t            # Avoid taking from the empty self.sp_values\r\n"]
[187.081259, "o", "  1066\t            _dtype = np.result_type(self.dtype.subtype, type(fill_value))\r\n"]
[187.111778, "o", "  1067\t            taken = np.full(sp_indexer.shape, fill_value=fill_value, dtype=_dtype)\r\n"]
[187.142296, "o", "  1068\t        else:\r\n"]
[187.172815, "o", "  1069\t            taken = self.sp_values.take(sp_indexer)\r\n"]
[187.203333, "o", "  1070\t\r\n"]
[187.233852, "o", "  1071\t            # Fill in two steps.\r\n"]
[187.26437, "o", "  1072\t            # Old fill values\r\n"]
[187.294889, "o", "  1073\t            # New fill values\r\n"]
[187.325407, "o", "  1074\t            # potentially coercing to a new dtype at each stage.\r\n"]
[187.355926, "o", "  1075\t\r\n"]
[187.386444, "o", "  1076\t            m0 = sp_indexer[old_fill_indices] < 0\r\n"]
[187.416963, "o", "  1077\t            m1 = sp_indexer[new_fill_indices] < 0\r\n"]
[187.447481, "o", "  1078\t\r\n"]
[187.478, "o", "  1079\t            result_type = taken.dtype\r\n"]
[187.508519, "o", "  1080\t\r\n"]
[187.539037, "o", "  1081\t            if m0.any():\r\n"]
[187.569556, "o", "  1082\t                result_type = np.result_type(result_type, type(self.fill_value))\r\n"]
[187.600074, "o", "  1083\t                taken = taken.astype(result_type)\r\n"]
[187.630593, "o", "  1084\t                taken[old_fill_indices] = self.fill_value\r\n"]
[187.661111, "o", "  1085\t\r\n"]
[187.69163, "o", "  1086\t            if m1.any():\r\n"]
[187.722148, "o", "  1087\t                result_type = np.result_type(result_type, type(fill_value))\r\n"]
[187.752667, "o", "  1088\t                taken = taken.astype(result_type)\r\n"]
[187.783185, "o", "  1089\t                taken[new_fill_indices] = fill_value\r\n"]
[187.813704, "o", "  1090\t\r\n"]
[187.844222, "o", "  1091\t        return taken\r\n"]
[187.874741, "o", "  1092\t\r\n"]
[187.905259, "o", "  1093\t    def _take_without_fill(self, indices) -> Self:\r\n"]
[187.935778, "o", "  1094\t        to_shift = indices < 0\r\n"]
[187.966296, "o", "  1095\t\r\n"]
[187.996815, "o", "  1096\t        n = len(self)\r\n"]
[188.027333, "o", "  1097\t\r\n"]
[188.057852, "o", "  1098\t        if (indices.max() >= n) or (indices.min() < -n):\r\n"]
[188.08837, "o", "  1099\t            if n == 0:\r\n"]
[188.118889, "o", "  1100\t                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[188.149407, "o", "  1101\t            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[188.179926, "o", "  1102\t\r\n"]
[188.210444, "o", "  1103\t        if to_shift.any():\r\n"]
[188.240963, "o", "  1104\t            indices = indices.copy()\r\n"]
[188.271481, "o", "  1105\t            indices[to_shift] += n\r\n"]
[188.302, "o", "  1106\t\r\n"]
[188.332519, "o", "  1107\t        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[188.363037, "o", "  1108\t        value_mask = sp_indexer != -1\r\n"]
[188.393556, "o", "  1109\t        new_sp_values = self.sp_values[sp_indexer[value_mask]]\r\n"]
[188.424074, "o", "  1110\t\r\n"]
[188.454593, "o", "  1111\t        value_indices = np.flatnonzero(value_mask).astype(np.int32, copy=False)\r\n"]
[188.485111, "o", "  1112\t\r\n"]
[188.51563, "o", "  1113\t        new_sp_index = make_sparse_index(len(indices), value_indices, kind=self.kind)\r\n"]
[188.546148, "o", "  1114\t        return type(self)._simple_new(new_sp_values, new_sp_index, dtype=self.dtype)\r\n"]
[188.576667, "o", "  1115\t\r\n"]
[188.607185, "o", "  1116\t    def searchsorted(\r\n"]
[188.637704, "o", "  1117\t        self,\r\n"]
[188.668222, "o", "  1118\t        v: ArrayLike | object,\r\n"]
[188.698741, "o", "  1119\t        side: Literal[\"left\", \"right\"] = \"left\",\r\n"]
[188.729259, "o", "  1120\t        sorter: NumpySorter = None,\r\n"]
[188.759778, "o", "  1121\t    ) -> npt.NDArray[np.intp] | np.intp:\r\n"]
[188.790296, "o", "  1122\t        msg = \"searchsorted requires high memory usage.\"\r\n"]
[188.820815, "o", "  1123\t        warnings.warn(msg, PerformanceWarning, stacklevel=find_stack_level())\r\n"]
[188.851333, "o", "  1124\t        if not is_scalar(v):\r\n"]
[188.881852, "o", "  1125\t            v = np.asarray(v)\r\n"]
[188.91237, "o", "  1126\t        v = np.asarray(v)\r\n"]
[188.942889, "o", "  1127\t        return np.asarray(self, dtype=self.dtype.subtype).searchsorted(v, side, sorter)\r\n"]
[188.973407, "o", "  1128\t\r\n"]
[189.003926, "o", "  1129\t    def copy(self) -> Self:\r\n"]
[189.034444, "o", "  1130\t        values = self.sp_values.copy()\r\n"]
[189.064963, "o", "  1131\t        return self._simple_new(values, self.sp_index, self.dtype)\r\n"]
[189.095481, "o", "  1132\t\r\n"]
[189.126, "o", "  1133\t    @classmethod\r\n"]
[189.156519, "o", "  1134\t    def _concat_same_type(cls, to_concat: Sequence[Self]) -> Self:\r\n"]
[189.187037, "o", "  1135\t        fill_value = to_concat[0].fill_value\r\n"]
[189.217556, "o", "  1136\t\r\n"]
[189.248074, "o", "  1137\t        values = []\r\n"]
[189.278593, "o", "  1138\t        length = 0\r\n"]
[189.309111, "o", "  1139\t\r\n"]
[189.33963, "o", "  1140\t        if to_concat:\r\n"]
[189.370148, "o", "  1141\t            sp_kind = to_concat[0].kind\r\n"]
[189.400667, "o", "  1142\t        else:\r\n"]
[189.431185, "o", "  1143\t            sp_kind = \"integer\"\r\n"]
[189.461704, "o", "  1144\t\r\n"]
[189.492222, "o", "  1145\t        sp_index: SparseIndex\r\n"]
[189.522741, "o", "  1146\t        if sp_kind == \"integer\":\r\n"]
[189.553259, "o", "  1147\t            indices = []\r\n"]
[189.583778, "o", "  1148\t\r\n"]
[189.614296, "o", "  1149\t            for arr in to_concat:\r\n"]
[189.644815, "o", "  1150\t                int_idx = arr.sp_index.indices.copy()\r\n"]
[189.675333, "o", "  1151\t                int_idx += length  # TODO: wraparound\r\n"]
[189.705852, "o", "  1152\t                length += arr.sp_index.length\r\n"]
[189.73637, "o", "  1153\t\r\n"]
[189.766889, "o", "  1154\t                values.append(arr.sp_values)\r\n"]
[189.797407, "o", "  1155\t                indices.append(int_idx)\r\n"]
[189.827926, "o", "  1156\t\r\n"]
[189.858444, "o", "  1157\t            data = np.concatenate(values)\r\n"]
[189.888963, "o", "  1158\t            indices_arr = np.concatenate(indices)\r\n"]
[189.919481, "o", "  1159\t            # error: Argument 2 to \"IntIndex\" has incompatible type\r\n"]
[190.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[190.002, "i", "grep -n \"def take\\(\" pandas/core/arrays/sparse/array.py\r"]
[190.004, "o", "grep -n \"def take\\(\" pandas/core/arrays/sparse/array.py\r\n"]
[192.478, "o", "\u001b[?2004l\r\n"]
[195.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[195.002, "i", "grep -n \"mask\\|boolean\" pandas/core/arrays/sparse/array.py\r"]
[195.004, "o", "grep -n \"mask\\|boolean\" pandas/core/arrays/sparse/array.py\r\n"]
[195.176483, "o", "\u001b[?2004l\r\n"]
[195.346966, "o", "\u001b[32m\u001b[K646\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = notna(sp_vals)\r\n"]
[195.517448, "o", "\u001b[32m\u001b[K647\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        return sp_vals[\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K]\r\n"]
[195.687931, "o", "\u001b[32m\u001b[K700\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = np.full(len(self), False, dtype=np.bool_)\r\n"]
[195.858414, "o", "\u001b[32m\u001b[K701\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K[self.sp_index.indices] = isna(self.sp_values)\r\n"]
[196.028897, "o", "\u001b[32m\u001b[K702\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        return type(self)(\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K, fill_value=False, dtype=dtype)\r\n"]
[196.199379, "o", "\u001b[32m\u001b[K872\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = isna(keys) if self._null_fill_value else keys == self.fill_value\r\n"]
[196.369862, "o", "\u001b[32m\u001b[K873\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            if \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K.any():\r\n"]
[196.540345, "o", "\u001b[32m\u001b[K874\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                counts[\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K] += fcounts\r\n"]
[196.710828, "o", "\u001b[32m\u001b[K965\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                r\"(`None`) and integer or \u001b[01;31m\u001b[Kboolean\u001b[m\u001b[K arrays are valid indices\"\r\n"]
[196.88131, "o", "\u001b[32m\u001b[K973\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                # we can apply \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K very fast:\r\n"]
[197.051793, "o", "\u001b[32m\u001b[K980\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                    \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = np.full(n, True, dtype=np.bool_)\r\n"]
[197.222276, "o", "\u001b[32m\u001b[K981\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                    \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K[key.sp_index.indices] = False\r\n"]
[197.392759, "o", "\u001b[32m\u001b[K982\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K                    return self.take(np.arange(n)[\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K])\r\n"]
[197.563241, "o", "\u001b[32m\u001b[K1108\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        value_\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = sp_indexer != -1\r\n"]
[197.733724, "o", "\u001b[32m\u001b[K1109\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        new_sp_values = self.sp_values[sp_indexer[value_\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K]]\r\n"]
[197.904207, "o", "\u001b[32m\u001b[K1111\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        value_indices = np.flatnonzero(value_\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K).astype(np.int32, copy=False)\r\n"]
[198.07469, "o", "\u001b[32m\u001b[K1337\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def _where(self, \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K, value):\r\n"]
[198.245172, "o", "\u001b[32m\u001b[K1340\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        naive_implementation = np.where(\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K, self, value)\r\n"]
[198.415655, "o", "\u001b[32m\u001b[K1596\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = np.asarray(isna(values))\r\n"]
[198.586138, "o", "\u001b[32m\u001b[K1600\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        non_nans = values[~\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K]\r\n"]
[198.756621, "o", "\u001b[32m\u001b[K1601\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        non_nan_idx = idx[~\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K]\r\n"]
[198.927103, "o", "\u001b[32m\u001b[K1854\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = notna(arr)\r\n"]
[199.097586, "o", "\u001b[32m\u001b[K1864\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = splib.make_\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K_object_ndarray(arr, fill_value)\r\n"]
[199.268069, "o", "\u001b[32m\u001b[K1866\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K = arr != fill_value\r\n"]
[199.438552, "o", "\u001b[32m\u001b[K1869\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    if length != len(\u001b[01;31m\u001b[Kmask\u001b[m\u001b[K):\r\n"]
[199.609034, "o", "\u001b[32m\u001b[K1871\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        indices = \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K.sp_index.indices\r\n"]
[199.779517, "o", "\u001b[32m\u001b[K1873\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        indices = \u001b[01;31m\u001b[Kmask\u001b[m\u001b[K.nonzero()[0].astype(np.int32)\r\n"]
[200.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[200.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '880,1040p'\r"]
[200.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '880,1040p'\r\n"]
[200.036519, "o", "\u001b[?2004l\r\n"]
[200.067037, "o", "   880\t                # Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]], Sequence\r\n"]
[200.097556, "o", "   881\t                # [Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]]]]\"\r\n"]
[200.128074, "o", "   882\t                keys = np.insert(keys, 0, self.fill_value)  # type: ignore[arg-type]\r\n"]
[200.158593, "o", "   883\t                counts = np.insert(counts, 0, fcounts)\r\n"]
[200.189111, "o", "   884\t\r\n"]
[200.21963, "o", "   885\t        if not isinstance(keys, ABCIndex):\r\n"]
[200.250148, "o", "   886\t            index = Index(keys)\r\n"]
[200.280667, "o", "   887\t        else:\r\n"]
[200.311185, "o", "   888\t            index = keys\r\n"]
[200.341704, "o", "   889\t        return Series(counts, index=index, copy=False)\r\n"]
[200.372222, "o", "   890\t\r\n"]
[200.402741, "o", "   891\t    # --------\r\n"]
[200.433259, "o", "   892\t    # Indexing\r\n"]
[200.463778, "o", "   893\t    # --------\r\n"]
[200.494296, "o", "   894\t    @overload\r\n"]
[200.524815, "o", "   895\t    def __getitem__(self, key: ScalarIndexer) -> Any:\r\n"]
[200.555333, "o", "   896\t        ...\r\n"]
[200.585852, "o", "   897\t\r\n"]
[200.61637, "o", "   898\t    @overload\r\n"]
[200.646889, "o", "   899\t    def __getitem__(\r\n"]
[200.677407, "o", "   900\t        self,\r\n"]
[200.707926, "o", "   901\t        key: SequenceIndexer | tuple[int | ellipsis, ...],\r\n"]
[200.738444, "o", "   902\t    ) -> Self:\r\n"]
[200.768963, "o", "   903\t        ...\r\n"]
[200.799481, "o", "   904\t\r\n"]
[200.83, "o", "   905\t    def __getitem__(\r\n"]
[200.860519, "o", "   906\t        self,\r\n"]
[200.891037, "o", "   907\t        key: PositionalIndexer | tuple[int | ellipsis, ...],\r\n"]
[200.921556, "o", "   908\t    ) -> Self | Any:\r\n"]
[200.952074, "o", "   909\t        if isinstance(key, tuple):\r\n"]
[200.982593, "o", "   910\t            key = unpack_tuple_and_ellipses(key)\r\n"]
[201.013111, "o", "   911\t            if key is Ellipsis:\r\n"]
[201.04363, "o", "   912\t                raise ValueError(\"Cannot slice with Ellipsis\")\r\n"]
[201.074148, "o", "   913\t\r\n"]
[201.104667, "o", "   914\t        if is_integer(key):\r\n"]
[201.135185, "o", "   915\t            return self._get_val_at(key)\r\n"]
[201.165704, "o", "   916\t        elif isinstance(key, tuple):\r\n"]
[201.196222, "o", "   917\t            # error: Invalid index type \"Tuple[Union[int, ellipsis], ...]\"\r\n"]
[201.226741, "o", "   918\t            # for \"ndarray[Any, Any]\"; expected type\r\n"]
[201.257259, "o", "   919\t            # \"Union[SupportsIndex, _SupportsArray[dtype[Union[bool_,\r\n"]
[201.287778, "o", "   920\t            # integer[Any]]]], _NestedSequence[_SupportsArray[dtype[\r\n"]
[201.318296, "o", "   921\t            # Union[bool_, integer[Any]]]]], _NestedSequence[Union[\r\n"]
[201.348815, "o", "   922\t            # bool, int]], Tuple[Union[SupportsIndex, _SupportsArray[\r\n"]
[201.379333, "o", "   923\t            # dtype[Union[bool_, integer[Any]]]], _NestedSequence[\r\n"]
[201.409852, "o", "   924\t            # _SupportsArray[dtype[Union[bool_, integer[Any]]]]],\r\n"]
[201.44037, "o", "   925\t            # _NestedSequence[Union[bool, int]]], ...]]\"\r\n"]
[201.470889, "o", "   926\t            data_slice = self.to_dense()[key]  # type: ignore[index]\r\n"]
[201.501407, "o", "   927\t        elif isinstance(key, slice):\r\n"]
[201.531926, "o", "   928\t            # Avoid densifying when handling contiguous slices\r\n"]
[201.562444, "o", "   929\t            if key.step is None or key.step == 1:\r\n"]
[201.592963, "o", "   930\t                start = 0 if key.start is None else key.start\r\n"]
[201.623481, "o", "   931\t                if start < 0:\r\n"]
[201.654, "o", "   932\t                    start += len(self)\r\n"]
[201.684519, "o", "   933\t\r\n"]
[201.715037, "o", "   934\t                end = len(self) if key.stop is None else key.stop\r\n"]
[201.745556, "o", "   935\t                if end < 0:\r\n"]
[201.776074, "o", "   936\t                    end += len(self)\r\n"]
[201.806593, "o", "   937\t\r\n"]
[201.837111, "o", "   938\t                indices = self.sp_index.indices\r\n"]
[201.86763, "o", "   939\t                keep_inds = np.flatnonzero((indices >= start) & (indices < end))\r\n"]
[201.898148, "o", "   940\t                sp_vals = self.sp_values[keep_inds]\r\n"]
[201.928667, "o", "   941\t\r\n"]
[201.959185, "o", "   942\t                sp_index = indices[keep_inds].copy()\r\n"]
[201.989704, "o", "   943\t\r\n"]
[202.020222, "o", "   944\t                # If we've sliced to not include the start of the array, all our indices\r\n"]
[202.050741, "o", "   945\t                # should be shifted. NB: here we are careful to also not shift by a\r\n"]
[202.081259, "o", "   946\t                # negative value for a case like [0, 1][-100:] where the start index\r\n"]
[202.111778, "o", "   947\t                # should be treated like 0\r\n"]
[202.142296, "o", "   948\t                if start > 0:\r\n"]
[202.172815, "o", "   949\t                    sp_index -= start\r\n"]
[202.203333, "o", "   950\t\r\n"]
[202.233852, "o", "   951\t                # Length of our result should match applying this slice to a range\r\n"]
[202.26437, "o", "   952\t                # of the length of our original array\r\n"]
[202.294889, "o", "   953\t                new_len = len(range(len(self))[key])\r\n"]
[202.325407, "o", "   954\t                new_sp_index = make_sparse_index(new_len, sp_index, self.kind)\r\n"]
[202.355926, "o", "   955\t                return type(self)._simple_new(sp_vals, new_sp_index, self.dtype)\r\n"]
[202.386444, "o", "   956\t            else:\r\n"]
[202.416963, "o", "   957\t                indices = np.arange(len(self), dtype=np.int32)[key]\r\n"]
[202.447481, "o", "   958\t                return self.take(indices)\r\n"]
[202.478, "o", "   959\t\r\n"]
[202.508519, "o", "   960\t        elif not is_list_like(key):\r\n"]
[202.539037, "o", "   961\t            # e.g. \"foo\" or 2.5\r\n"]
[202.569556, "o", "   962\t            # exception message copied from numpy\r\n"]
[202.600074, "o", "   963\t            raise IndexError(\r\n"]
[202.630593, "o", "   964\t                r\"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis \"\r\n"]
[202.661111, "o", "   965\t                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[202.69163, "o", "   966\t            )\r\n"]
[202.722148, "o", "   967\t\r\n"]
[202.752667, "o", "   968\t        else:\r\n"]
[202.783185, "o", "   969\t            if isinstance(key, SparseArray):\r\n"]
[202.813704, "o", "   970\t                # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[202.844222, "o", "   971\t                # has only fill_value - true, false or nan\r\n"]
[202.874741, "o", "   972\t                # (see GH PR 44955)\r\n"]
[202.905259, "o", "   973\t                # we can apply mask very fast:\r\n"]
[202.935778, "o", "   974\t                if is_bool_dtype(key):\r\n"]
[202.966296, "o", "   975\t                    if isna(key.fill_value):\r\n"]
[202.996815, "o", "   976\t                        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[203.027333, "o", "   977\t                    if not key.fill_value:\r\n"]
[203.057852, "o", "   978\t                        return self.take(key.sp_index.indices)\r\n"]
[203.08837, "o", "   979\t                    n = len(self)\r\n"]
[203.118889, "o", "   980\t                    mask = np.full(n, True, dtype=np.bool_)\r\n"]
[203.149407, "o", "   981\t                    mask[key.sp_index.indices] = False\r\n"]
[203.179926, "o", "   982\t                    return self.take(np.arange(n)[mask])\r\n"]
[203.210444, "o", "   983\t                else:\r\n"]
[203.240963, "o", "   984\t                    key = np.asarray(key)\r\n"]
[203.271481, "o", "   985\t\r\n"]
[203.302, "o", "   986\t            key = check_array_indexer(self, key)\r\n"]
[203.332519, "o", "   987\t\r\n"]
[203.363037, "o", "   988\t            if com.is_bool_indexer(key):\r\n"]
[203.393556, "o", "   989\t                # mypy doesn't know we have an array here\r\n"]
[203.424074, "o", "   990\t                key = cast(np.ndarray, key)\r\n"]
[203.454593, "o", "   991\t                return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[203.485111, "o", "   992\t            elif hasattr(key, \"__len__\"):\r\n"]
[203.51563, "o", "   993\t                return self.take(key)\r\n"]
[203.546148, "o", "   994\t            else:\r\n"]
[203.576667, "o", "   995\t                raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[203.607185, "o", "   996\t\r\n"]
[203.637704, "o", "   997\t        return type(self)(data_slice, kind=self.kind)\r\n"]
[203.668222, "o", "   998\t\r\n"]
[203.698741, "o", "   999\t    def _get_val_at(self, loc):\r\n"]
[203.729259, "o", "  1000\t        loc = validate_insert_loc(loc, len(self))\r\n"]
[203.759778, "o", "  1001\t\r\n"]
[203.790296, "o", "  1002\t        sp_loc = self.sp_index.lookup(loc)\r\n"]
[203.820815, "o", "  1003\t        if sp_loc == -1:\r\n"]
[203.851333, "o", "  1004\t            return self.fill_value\r\n"]
[203.881852, "o", "  1005\t        else:\r\n"]
[203.91237, "o", "  1006\t            val = self.sp_values[sp_loc]\r\n"]
[203.942889, "o", "  1007\t            val = maybe_box_datetimelike(val, self.sp_values.dtype)\r\n"]
[203.973407, "o", "  1008\t            return val\r\n"]
[204.003926, "o", "  1009\t\r\n"]
[204.034444, "o", "  1010\t    def take(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[204.064963, "o", "  1011\t        if is_scalar(indices):\r\n"]
[204.095481, "o", "  1012\t            raise ValueError(f\"'indices' must be an array, not a scalar '{indices}'.\")\r\n"]
[204.126, "o", "  1013\t        indices = np.asarray(indices, dtype=np.int32)\r\n"]
[204.156519, "o", "  1014\t\r\n"]
[204.187037, "o", "  1015\t        dtype = None\r\n"]
[204.217556, "o", "  1016\t        if indices.size == 0:\r\n"]
[204.248074, "o", "  1017\t            result = np.array([], dtype=\"object\")\r\n"]
[204.278593, "o", "  1018\t            dtype = self.dtype\r\n"]
[204.309111, "o", "  1019\t        elif allow_fill:\r\n"]
[204.33963, "o", "  1020\t            result = self._take_with_fill(indices, fill_value=fill_value)\r\n"]
[204.370148, "o", "  1021\t        else:\r\n"]
[204.400667, "o", "  1022\t            return self._take_without_fill(indices)\r\n"]
[204.431185, "o", "  1023\t\r\n"]
[204.461704, "o", "  1024\t        return type(self)(\r\n"]
[204.492222, "o", "  1025\t            result, fill_value=self.fill_value, kind=self.kind, dtype=dtype\r\n"]
[204.522741, "o", "  1026\t        )\r\n"]
[204.553259, "o", "  1027\t\r\n"]
[204.583778, "o", "  1028\t    def _take_with_fill(self, indices, fill_value=None) -> np.ndarray:\r\n"]
[204.614296, "o", "  1029\t        if fill_value is None:\r\n"]
[204.644815, "o", "  1030\t            fill_value = self.dtype.na_value\r\n"]
[204.675333, "o", "  1031\t\r\n"]
[204.705852, "o", "  1032\t        if indices.min() < -1:\r\n"]
[204.73637, "o", "  1033\t            raise ValueError(\r\n"]
[204.766889, "o", "  1034\t                \"Invalid value in 'indices'. Must be between -1 \"\r\n"]
[204.797407, "o", "  1035\t                \"and the length of the array.\"\r\n"]
[204.827926, "o", "  1036\t            )\r\n"]
[204.858444, "o", "  1037\t\r\n"]
[204.888963, "o", "  1038\t        if indices.max() >= len(self):\r\n"]
[204.919481, "o", "  1039\t            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[205.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[205.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1040,1180p'\r"]
[205.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1040,1180p'\r\n"]
[205.040817, "o", "\u001b[?2004l\r\n"]
[205.075634, "o", "  1040\t\r\n"]
[205.110451, "o", "  1041\t        if len(self) == 0:\r\n"]
[205.145268, "o", "  1042\t            # Empty... Allow taking only if all empty\r\n"]
[205.180085, "o", "  1043\t            if (indices == -1).all():\r\n"]
[205.214901, "o", "  1044\t                dtype = np.result_type(self.sp_values, type(fill_value))\r\n"]
[205.249718, "o", "  1045\t                taken = np.empty_like(indices, dtype=dtype)\r\n"]
[205.284535, "o", "  1046\t                taken.fill(fill_value)\r\n"]
[205.319352, "o", "  1047\t                return taken\r\n"]
[205.354169, "o", "  1048\t            else:\r\n"]
[205.388986, "o", "  1049\t                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[205.423803, "o", "  1050\t\r\n"]
[205.45862, "o", "  1051\t        # sp_indexer may be -1 for two reasons\r\n"]
[205.493437, "o", "  1052\t        # 1.) we took for an index of -1 (new)\r\n"]
[205.528254, "o", "  1053\t        # 2.) we took a value that was self.fill_value (old)\r\n"]
[205.56307, "o", "  1054\t        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[205.597887, "o", "  1055\t        new_fill_indices = indices == -1\r\n"]
[205.632704, "o", "  1056\t        old_fill_indices = (sp_indexer == -1) & ~new_fill_indices\r\n"]
[205.667521, "o", "  1057\t\r\n"]
[205.702338, "o", "  1058\t        if self.sp_index.npoints == 0 and old_fill_indices.all():\r\n"]
[205.737155, "o", "  1059\t            # We've looked up all valid points on an all-sparse array.\r\n"]
[205.771972, "o", "  1060\t            taken = np.full(\r\n"]
[205.806789, "o", "  1061\t                sp_indexer.shape, fill_value=self.fill_value, dtype=self.dtype.subtype\r\n"]
[205.841606, "o", "  1062\t            )\r\n"]
[205.876423, "o", "  1063\t\r\n"]
[205.911239, "o", "  1064\t        elif self.sp_index.npoints == 0:\r\n"]
[205.946056, "o", "  1065\t            # Avoid taking from the empty self.sp_values\r\n"]
[205.980873, "o", "  1066\t            _dtype = np.result_type(self.dtype.subtype, type(fill_value))\r\n"]
[206.01569, "o", "  1067\t            taken = np.full(sp_indexer.shape, fill_value=fill_value, dtype=_dtype)\r\n"]
[206.050507, "o", "  1068\t        else:\r\n"]
[206.085324, "o", "  1069\t            taken = self.sp_values.take(sp_indexer)\r\n"]
[206.120141, "o", "  1070\t\r\n"]
[206.154958, "o", "  1071\t            # Fill in two steps.\r\n"]
[206.189775, "o", "  1072\t            # Old fill values\r\n"]
[206.224592, "o", "  1073\t            # New fill values\r\n"]
[206.259408, "o", "  1074\t            # potentially coercing to a new dtype at each stage.\r\n"]
[206.294225, "o", "  1075\t\r\n"]
[206.329042, "o", "  1076\t            m0 = sp_indexer[old_fill_indices] < 0\r\n"]
[206.363859, "o", "  1077\t            m1 = sp_indexer[new_fill_indices] < 0\r\n"]
[206.398676, "o", "  1078\t\r\n"]
[206.433493, "o", "  1079\t            result_type = taken.dtype\r\n"]
[206.46831, "o", "  1080\t\r\n"]
[206.503127, "o", "  1081\t            if m0.any():\r\n"]
[206.537944, "o", "  1082\t                result_type = np.result_type(result_type, type(self.fill_value))\r\n"]
[206.572761, "o", "  1083\t                taken = taken.astype(result_type)\r\n"]
[206.607577, "o", "  1084\t                taken[old_fill_indices] = self.fill_value\r\n"]
[206.642394, "o", "  1085\t\r\n"]
[206.677211, "o", "  1086\t            if m1.any():\r\n"]
[206.712028, "o", "  1087\t                result_type = np.result_type(result_type, type(fill_value))\r\n"]
[206.746845, "o", "  1088\t                taken = taken.astype(result_type)\r\n"]
[206.781662, "o", "  1089\t                taken[new_fill_indices] = fill_value\r\n"]
[206.816479, "o", "  1090\t\r\n"]
[206.851296, "o", "  1091\t        return taken\r\n"]
[206.886113, "o", "  1092\t\r\n"]
[206.92093, "o", "  1093\t    def _take_without_fill(self, indices) -> Self:\r\n"]
[206.955746, "o", "  1094\t        to_shift = indices < 0\r\n"]
[206.990563, "o", "  1095\t\r\n"]
[207.02538, "o", "  1096\t        n = len(self)\r\n"]
[207.060197, "o", "  1097\t\r\n"]
[207.095014, "o", "  1098\t        if (indices.max() >= n) or (indices.min() < -n):\r\n"]
[207.129831, "o", "  1099\t            if n == 0:\r\n"]
[207.164648, "o", "  1100\t                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[207.199465, "o", "  1101\t            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[207.234282, "o", "  1102\t\r\n"]
[207.269099, "o", "  1103\t        if to_shift.any():\r\n"]
[207.303915, "o", "  1104\t            indices = indices.copy()\r\n"]
[207.338732, "o", "  1105\t            indices[to_shift] += n\r\n"]
[207.373549, "o", "  1106\t\r\n"]
[207.408366, "o", "  1107\t        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[207.443183, "o", "  1108\t        value_mask = sp_indexer != -1\r\n"]
[207.478, "o", "  1109\t        new_sp_values = self.sp_values[sp_indexer[value_mask]]\r\n"]
[207.512817, "o", "  1110\t\r\n"]
[207.547634, "o", "  1111\t        value_indices = np.flatnonzero(value_mask).astype(np.int32, copy=False)\r\n"]
[207.582451, "o", "  1112\t\r\n"]
[207.617268, "o", "  1113\t        new_sp_index = make_sparse_index(len(indices), value_indices, kind=self.kind)\r\n"]
[207.652085, "o", "  1114\t        return type(self)._simple_new(new_sp_values, new_sp_index, dtype=self.dtype)\r\n"]
[207.686901, "o", "  1115\t\r\n"]
[207.721718, "o", "  1116\t    def searchsorted(\r\n"]
[207.756535, "o", "  1117\t        self,\r\n"]
[207.791352, "o", "  1118\t        v: ArrayLike | object,\r\n"]
[207.826169, "o", "  1119\t        side: Literal[\"left\", \"right\"] = \"left\",\r\n"]
[207.860986, "o", "  1120\t        sorter: NumpySorter = None,\r\n"]
[207.895803, "o", "  1121\t    ) -> npt.NDArray[np.intp] | np.intp:\r\n"]
[207.93062, "o", "  1122\t        msg = \"searchsorted requires high memory usage.\"\r\n"]
[207.965437, "o", "  1123\t        warnings.warn(msg, PerformanceWarning, stacklevel=find_stack_level())\r\n"]
[208.000254, "o", "  1124\t        if not is_scalar(v):\r\n"]
[208.03507, "o", "  1125\t            v = np.asarray(v)\r\n"]
[208.069887, "o", "  1126\t        v = np.asarray(v)\r\n"]
[208.104704, "o", "  1127\t        return np.asarray(self, dtype=self.dtype.subtype).searchsorted(v, side, sorter)\r\n"]
[208.139521, "o", "  1128\t\r\n"]
[208.174338, "o", "  1129\t    def copy(self) -> Self:\r\n"]
[208.209155, "o", "  1130\t        values = self.sp_values.copy()\r\n"]
[208.243972, "o", "  1131\t        return self._simple_new(values, self.sp_index, self.dtype)\r\n"]
[208.278789, "o", "  1132\t\r\n"]
[208.313606, "o", "  1133\t    @classmethod\r\n"]
[208.348423, "o", "  1134\t    def _concat_same_type(cls, to_concat: Sequence[Self]) -> Self:\r\n"]
[208.383239, "o", "  1135\t        fill_value = to_concat[0].fill_value\r\n"]
[208.418056, "o", "  1136\t\r\n"]
[208.452873, "o", "  1137\t        values = []\r\n"]
[208.48769, "o", "  1138\t        length = 0\r\n"]
[208.522507, "o", "  1139\t\r\n"]
[208.557324, "o", "  1140\t        if to_concat:\r\n"]
[208.592141, "o", "  1141\t            sp_kind = to_concat[0].kind\r\n"]
[208.626958, "o", "  1142\t        else:\r\n"]
[208.661775, "o", "  1143\t            sp_kind = \"integer\"\r\n"]
[208.696592, "o", "  1144\t\r\n"]
[208.731408, "o", "  1145\t        sp_index: SparseIndex\r\n"]
[208.766225, "o", "  1146\t        if sp_kind == \"integer\":\r\n"]
[208.801042, "o", "  1147\t            indices = []\r\n"]
[208.835859, "o", "  1148\t\r\n"]
[208.870676, "o", "  1149\t            for arr in to_concat:\r\n"]
[208.905493, "o", "  1150\t                int_idx = arr.sp_index.indices.copy()\r\n"]
[208.94031, "o", "  1151\t                int_idx += length  # TODO: wraparound\r\n"]
[208.975127, "o", "  1152\t                length += arr.sp_index.length\r\n"]
[209.009944, "o", "  1153\t\r\n"]
[209.044761, "o", "  1154\t                values.append(arr.sp_values)\r\n"]
[209.079577, "o", "  1155\t                indices.append(int_idx)\r\n"]
[209.114394, "o", "  1156\t\r\n"]
[209.149211, "o", "  1157\t            data = np.concatenate(values)\r\n"]
[209.184028, "o", "  1158\t            indices_arr = np.concatenate(indices)\r\n"]
[209.218845, "o", "  1159\t            # error: Argument 2 to \"IntIndex\" has incompatible type\r\n"]
[209.253662, "o", "  1160\t            # \"ndarray[Any, dtype[signedinteger[_32Bit]]]\";\r\n"]
[209.288479, "o", "  1161\t            # expected \"Sequence[int]\"\r\n"]
[209.323296, "o", "  1162\t            sp_index = IntIndex(length, indices_arr)  # type: ignore[arg-type]\r\n"]
[209.358113, "o", "  1163\t\r\n"]
[209.39293, "o", "  1164\t        else:\r\n"]
[209.427746, "o", "  1165\t            # when concatenating block indices, we don't claim that you'll\r\n"]
[209.462563, "o", "  1166\t            # get an identical index as concatenating the values and then\r\n"]
[209.49738, "o", "  1167\t            # creating a new index. We don't want to spend the time trying\r\n"]
[209.532197, "o", "  1168\t            # to merge blocks across arrays in `to_concat`, so the resulting\r\n"]
[209.567014, "o", "  1169\t            # BlockIndex may have more blocks.\r\n"]
[209.601831, "o", "  1170\t            blengths = []\r\n"]
[209.636648, "o", "  1171\t            blocs = []\r\n"]
[209.671465, "o", "  1172\t\r\n"]
[209.706282, "o", "  1173\t            for arr in to_concat:\r\n"]
[209.741099, "o", "  1174\t                block_idx = arr.sp_index.to_block_index()\r\n"]
[209.775915, "o", "  1175\t\r\n"]
[209.810732, "o", "  1176\t                values.append(arr.sp_values)\r\n"]
[209.845549, "o", "  1177\t                blocs.append(block_idx.blocs.copy() + length)\r\n"]
[209.880366, "o", "  1178\t                blengths.append(block_idx.blengths)\r\n"]
[209.915183, "o", "  1179\t                length += arr.sp_index.length\r\n"]
[210.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[210.002, "i", "grep -n \"def take\\s*\\(.*\\)\" -n pandas/core/arrays/sparse/array.py || sed -n '1,2000p' pandas/core/arrays/sparse/arra\r"]
[210.004, "o", "grep -n \"def take\\s*\\(.*\\)\" -n pandas/core/arrays/sparse/array.py || sed -n '1,2000p' pandas/core/arrays/sparse/arra\r\n"]
[211.654, "o", "ay.py | grep -n \"def take\"\r\n"]
[213.302, "o", "\u001b[?2004l\r\n"]
[215.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[215.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '940,1020p'\r"]
[215.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '940,1020p'\r\n"]
[215.066293, "o", "\u001b[?2004l\r\n"]
[215.126585, "o", "   940\t                sp_vals = self.sp_values[keep_inds]\r\n"]
[215.186878, "o", "   941\t\r\n"]
[215.247171, "o", "   942\t                sp_index = indices[keep_inds].copy()\r\n"]
[215.307463, "o", "   943\t\r\n"]
[215.367756, "o", "   944\t                # If we've sliced to not include the start of the array, all our indices\r\n"]
[215.428049, "o", "   945\t                # should be shifted. NB: here we are careful to also not shift by a\r\n"]
[215.488341, "o", "   946\t                # negative value for a case like [0, 1][-100:] where the start index\r\n"]
[215.548634, "o", "   947\t                # should be treated like 0\r\n"]
[215.608927, "o", "   948\t                if start > 0:\r\n"]
[215.66922, "o", "   949\t                    sp_index -= start\r\n"]
[215.729512, "o", "   950\t\r\n"]
[215.789805, "o", "   951\t                # Length of our result should match applying this slice to a range\r\n"]
[215.850098, "o", "   952\t                # of the length of our original array\r\n"]
[215.91039, "o", "   953\t                new_len = len(range(len(self))[key])\r\n"]
[215.970683, "o", "   954\t                new_sp_index = make_sparse_index(new_len, sp_index, self.kind)\r\n"]
[216.030976, "o", "   955\t                return type(self)._simple_new(sp_vals, new_sp_index, self.dtype)\r\n"]
[216.091268, "o", "   956\t            else:\r\n"]
[216.151561, "o", "   957\t                indices = np.arange(len(self), dtype=np.int32)[key]\r\n"]
[216.211854, "o", "   958\t                return self.take(indices)\r\n"]
[216.272146, "o", "   959\t\r\n"]
[216.332439, "o", "   960\t        elif not is_list_like(key):\r\n"]
[216.392732, "o", "   961\t            # e.g. \"foo\" or 2.5\r\n"]
[216.453024, "o", "   962\t            # exception message copied from numpy\r\n"]
[216.513317, "o", "   963\t            raise IndexError(\r\n"]
[216.57361, "o", "   964\t                r\"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis \"\r\n"]
[216.633902, "o", "   965\t                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[216.694195, "o", "   966\t            )\r\n"]
[216.754488, "o", "   967\t\r\n"]
[216.81478, "o", "   968\t        else:\r\n"]
[216.875073, "o", "   969\t            if isinstance(key, SparseArray):\r\n"]
[216.935366, "o", "   970\t                # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[216.995659, "o", "   971\t                # has only fill_value - true, false or nan\r\n"]
[217.055951, "o", "   972\t                # (see GH PR 44955)\r\n"]
[217.116244, "o", "   973\t                # we can apply mask very fast:\r\n"]
[217.176537, "o", "   974\t                if is_bool_dtype(key):\r\n"]
[217.236829, "o", "   975\t                    if isna(key.fill_value):\r\n"]
[217.297122, "o", "   976\t                        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[217.357415, "o", "   977\t                    if not key.fill_value:\r\n"]
[217.417707, "o", "   978\t                        return self.take(key.sp_index.indices)\r\n"]
[217.478, "o", "   979\t                    n = len(self)\r\n"]
[217.538293, "o", "   980\t                    mask = np.full(n, True, dtype=np.bool_)\r\n"]
[217.598585, "o", "   981\t                    mask[key.sp_index.indices] = False\r\n"]
[217.658878, "o", "   982\t                    return self.take(np.arange(n)[mask])\r\n"]
[217.719171, "o", "   983\t                else:\r\n"]
[217.779463, "o", "   984\t                    key = np.asarray(key)\r\n"]
[217.839756, "o", "   985\t\r\n"]
[217.900049, "o", "   986\t            key = check_array_indexer(self, key)\r\n"]
[217.960341, "o", "   987\t\r\n"]
[218.020634, "o", "   988\t            if com.is_bool_indexer(key):\r\n"]
[218.080927, "o", "   989\t                # mypy doesn't know we have an array here\r\n"]
[218.14122, "o", "   990\t                key = cast(np.ndarray, key)\r\n"]
[218.201512, "o", "   991\t                return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[218.261805, "o", "   992\t            elif hasattr(key, \"__len__\"):\r\n"]
[218.322098, "o", "   993\t                return self.take(key)\r\n"]
[218.38239, "o", "   994\t            else:\r\n"]
[218.442683, "o", "   995\t                raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[218.502976, "o", "   996\t\r\n"]
[218.563268, "o", "   997\t        return type(self)(data_slice, kind=self.kind)\r\n"]
[218.623561, "o", "   998\t\r\n"]
[218.683854, "o", "   999\t    def _get_val_at(self, loc):\r\n"]
[218.744146, "o", "  1000\t        loc = validate_insert_loc(loc, len(self))\r\n"]
[218.804439, "o", "  1001\t\r\n"]
[218.864732, "o", "  1002\t        sp_loc = self.sp_index.lookup(loc)\r\n"]
[218.925024, "o", "  1003\t        if sp_loc == -1:\r\n"]
[218.985317, "o", "  1004\t            return self.fill_value\r\n"]
[219.04561, "o", "  1005\t        else:\r\n"]
[219.105902, "o", "  1006\t            val = self.sp_values[sp_loc]\r\n"]
[219.166195, "o", "  1007\t            val = maybe_box_datetimelike(val, self.sp_values.dtype)\r\n"]
[219.226488, "o", "  1008\t            return val\r\n"]
[219.28678, "o", "  1009\t\r\n"]
[219.347073, "o", "  1010\t    def take(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[219.407366, "o", "  1011\t        if is_scalar(indices):\r\n"]
[219.467659, "o", "  1012\t            raise ValueError(f\"'indices' must be an array, not a scalar '{indices}'.\")\r\n"]
[219.527951, "o", "  1013\t        indices = np.asarray(indices, dtype=np.int32)\r\n"]
[219.588244, "o", "  1014\t\r\n"]
[219.648537, "o", "  1015\t        dtype = None\r\n"]
[219.708829, "o", "  1016\t        if indices.size == 0:\r\n"]
[219.769122, "o", "  1017\t            result = np.array([], dtype=\"object\")\r\n"]
[219.829415, "o", "  1018\t            dtype = self.dtype\r\n"]
[219.889707, "o", "  1019\t        elif allow_fill:\r\n"]
[220.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[220.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1000,1080p'\r"]
[220.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1000,1080p'\r\n"]
[220.066293, "o", "\u001b[?2004l\r\n"]
[220.126585, "o", "  1000\t        loc = validate_insert_loc(loc, len(self))\r\n"]
[220.186878, "o", "  1001\t\r\n"]
[220.247171, "o", "  1002\t        sp_loc = self.sp_index.lookup(loc)\r\n"]
[220.307463, "o", "  1003\t        if sp_loc == -1:\r\n"]
[220.367756, "o", "  1004\t            return self.fill_value\r\n"]
[220.428049, "o", "  1005\t        else:\r\n"]
[220.488341, "o", "  1006\t            val = self.sp_values[sp_loc]\r\n"]
[220.548634, "o", "  1007\t            val = maybe_box_datetimelike(val, self.sp_values.dtype)\r\n"]
[220.608927, "o", "  1008\t            return val\r\n"]
[220.66922, "o", "  1009\t\r\n"]
[220.729512, "o", "  1010\t    def take(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[220.789805, "o", "  1011\t        if is_scalar(indices):\r\n"]
[220.850098, "o", "  1012\t            raise ValueError(f\"'indices' must be an array, not a scalar '{indices}'.\")\r\n"]
[220.91039, "o", "  1013\t        indices = np.asarray(indices, dtype=np.int32)\r\n"]
[220.970683, "o", "  1014\t\r\n"]
[221.030976, "o", "  1015\t        dtype = None\r\n"]
[221.091268, "o", "  1016\t        if indices.size == 0:\r\n"]
[221.151561, "o", "  1017\t            result = np.array([], dtype=\"object\")\r\n"]
[221.211854, "o", "  1018\t            dtype = self.dtype\r\n"]
[221.272146, "o", "  1019\t        elif allow_fill:\r\n"]
[221.332439, "o", "  1020\t            result = self._take_with_fill(indices, fill_value=fill_value)\r\n"]
[221.392732, "o", "  1021\t        else:\r\n"]
[221.453024, "o", "  1022\t            return self._take_without_fill(indices)\r\n"]
[221.513317, "o", "  1023\t\r\n"]
[221.57361, "o", "  1024\t        return type(self)(\r\n"]
[221.633902, "o", "  1025\t            result, fill_value=self.fill_value, kind=self.kind, dtype=dtype\r\n"]
[221.694195, "o", "  1026\t        )\r\n"]
[221.754488, "o", "  1027\t\r\n"]
[221.81478, "o", "  1028\t    def _take_with_fill(self, indices, fill_value=None) -> np.ndarray:\r\n"]
[221.875073, "o", "  1029\t        if fill_value is None:\r\n"]
[221.935366, "o", "  1030\t            fill_value = self.dtype.na_value\r\n"]
[221.995659, "o", "  1031\t\r\n"]
[222.055951, "o", "  1032\t        if indices.min() < -1:\r\n"]
[222.116244, "o", "  1033\t            raise ValueError(\r\n"]
[222.176537, "o", "  1034\t                \"Invalid value in 'indices'. Must be between -1 \"\r\n"]
[222.236829, "o", "  1035\t                \"and the length of the array.\"\r\n"]
[222.297122, "o", "  1036\t            )\r\n"]
[222.357415, "o", "  1037\t\r\n"]
[222.417707, "o", "  1038\t        if indices.max() >= len(self):\r\n"]
[222.478, "o", "  1039\t            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[222.538293, "o", "  1040\t\r\n"]
[222.598585, "o", "  1041\t        if len(self) == 0:\r\n"]
[222.658878, "o", "  1042\t            # Empty... Allow taking only if all empty\r\n"]
[222.719171, "o", "  1043\t            if (indices == -1).all():\r\n"]
[222.779463, "o", "  1044\t                dtype = np.result_type(self.sp_values, type(fill_value))\r\n"]
[222.839756, "o", "  1045\t                taken = np.empty_like(indices, dtype=dtype)\r\n"]
[222.900049, "o", "  1046\t                taken.fill(fill_value)\r\n"]
[222.960341, "o", "  1047\t                return taken\r\n"]
[223.020634, "o", "  1048\t            else:\r\n"]
[223.080927, "o", "  1049\t                raise IndexError(\"cannot do a non-empty take from an empty axes.\")\r\n"]
[223.14122, "o", "  1050\t\r\n"]
[223.201512, "o", "  1051\t        # sp_indexer may be -1 for two reasons\r\n"]
[223.261805, "o", "  1052\t        # 1.) we took for an index of -1 (new)\r\n"]
[223.322098, "o", "  1053\t        # 2.) we took a value that was self.fill_value (old)\r\n"]
[223.38239, "o", "  1054\t        sp_indexer = self.sp_index.lookup_array(indices)\r\n"]
[223.442683, "o", "  1055\t        new_fill_indices = indices == -1\r\n"]
[223.502976, "o", "  1056\t        old_fill_indices = (sp_indexer == -1) & ~new_fill_indices\r\n"]
[223.563268, "o", "  1057\t\r\n"]
[223.623561, "o", "  1058\t        if self.sp_index.npoints == 0 and old_fill_indices.all():\r\n"]
[223.683854, "o", "  1059\t            # We've looked up all valid points on an all-sparse array.\r\n"]
[223.744146, "o", "  1060\t            taken = np.full(\r\n"]
[223.804439, "o", "  1061\t                sp_indexer.shape, fill_value=self.fill_value, dtype=self.dtype.subtype\r\n"]
[223.864732, "o", "  1062\t            )\r\n"]
[223.925024, "o", "  1063\t\r\n"]
[223.985317, "o", "  1064\t        elif self.sp_index.npoints == 0:\r\n"]
[224.04561, "o", "  1065\t            # Avoid taking from the empty self.sp_values\r\n"]
[224.105902, "o", "  1066\t            _dtype = np.result_type(self.dtype.subtype, type(fill_value))\r\n"]
[224.166195, "o", "  1067\t            taken = np.full(sp_indexer.shape, fill_value=fill_value, dtype=_dtype)\r\n"]
[224.226488, "o", "  1068\t        else:\r\n"]
[224.28678, "o", "  1069\t            taken = self.sp_values.take(sp_indexer)\r\n"]
[224.347073, "o", "  1070\t\r\n"]
[224.407366, "o", "  1071\t            # Fill in two steps.\r\n"]
[224.467659, "o", "  1072\t            # Old fill values\r\n"]
[224.527951, "o", "  1073\t            # New fill values\r\n"]
[224.588244, "o", "  1074\t            # potentially coercing to a new dtype at each stage.\r\n"]
[224.648537, "o", "  1075\t\r\n"]
[224.708829, "o", "  1076\t            m0 = sp_indexer[old_fill_indices] < 0\r\n"]
[224.769122, "o", "  1077\t            m1 = sp_indexer[new_fill_indices] < 0\r\n"]
[224.829415, "o", "  1078\t\r\n"]
[224.889707, "o", "  1079\t            result_type = taken.dtype\r\n"]
[225.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[225.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '880,960p'\r"]
[225.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '880,960p'\r\n"]
[225.066293, "o", "\u001b[?2004l\r\n"]
[225.126585, "o", "   880\t                # Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]], Sequence\r\n"]
[225.186878, "o", "   881\t                # [Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]]]]\"\r\n"]
[225.247171, "o", "   882\t                keys = np.insert(keys, 0, self.fill_value)  # type: ignore[arg-type]\r\n"]
[225.307463, "o", "   883\t                counts = np.insert(counts, 0, fcounts)\r\n"]
[225.367756, "o", "   884\t\r\n"]
[225.428049, "o", "   885\t        if not isinstance(keys, ABCIndex):\r\n"]
[225.488341, "o", "   886\t            index = Index(keys)\r\n"]
[225.548634, "o", "   887\t        else:\r\n"]
[225.608927, "o", "   888\t            index = keys\r\n"]
[225.66922, "o", "   889\t        return Series(counts, index=index, copy=False)\r\n"]
[225.729512, "o", "   890\t\r\n"]
[225.789805, "o", "   891\t    # --------\r\n"]
[225.850098, "o", "   892\t    # Indexing\r\n"]
[225.91039, "o", "   893\t    # --------\r\n"]
[225.970683, "o", "   894\t    @overload\r\n"]
[226.030976, "o", "   895\t    def __getitem__(self, key: ScalarIndexer) -> Any:\r\n"]
[226.091268, "o", "   896\t        ...\r\n"]
[226.151561, "o", "   897\t\r\n"]
[226.211854, "o", "   898\t    @overload\r\n"]
[226.272146, "o", "   899\t    def __getitem__(\r\n"]
[226.332439, "o", "   900\t        self,\r\n"]
[226.392732, "o", "   901\t        key: SequenceIndexer | tuple[int | ellipsis, ...],\r\n"]
[226.453024, "o", "   902\t    ) -> Self:\r\n"]
[226.513317, "o", "   903\t        ...\r\n"]
[226.57361, "o", "   904\t\r\n"]
[226.633902, "o", "   905\t    def __getitem__(\r\n"]
[226.694195, "o", "   906\t        self,\r\n"]
[226.754488, "o", "   907\t        key: PositionalIndexer | tuple[int | ellipsis, ...],\r\n"]
[226.81478, "o", "   908\t    ) -> Self | Any:\r\n"]
[226.875073, "o", "   909\t        if isinstance(key, tuple):\r\n"]
[226.935366, "o", "   910\t            key = unpack_tuple_and_ellipses(key)\r\n"]
[226.995659, "o", "   911\t            if key is Ellipsis:\r\n"]
[227.055951, "o", "   912\t                raise ValueError(\"Cannot slice with Ellipsis\")\r\n"]
[227.116244, "o", "   913\t\r\n"]
[227.176537, "o", "   914\t        if is_integer(key):\r\n"]
[227.236829, "o", "   915\t            return self._get_val_at(key)\r\n"]
[227.297122, "o", "   916\t        elif isinstance(key, tuple):\r\n"]
[227.357415, "o", "   917\t            # error: Invalid index type \"Tuple[Union[int, ellipsis], ...]\"\r\n"]
[227.417707, "o", "   918\t            # for \"ndarray[Any, Any]\"; expected type\r\n"]
[227.478, "o", "   919\t            # \"Union[SupportsIndex, _SupportsArray[dtype[Union[bool_,\r\n"]
[227.538293, "o", "   920\t            # integer[Any]]]], _NestedSequence[_SupportsArray[dtype[\r\n"]
[227.598585, "o", "   921\t            # Union[bool_, integer[Any]]]]], _NestedSequence[Union[\r\n"]
[227.658878, "o", "   922\t            # bool, int]], Tuple[Union[SupportsIndex, _SupportsArray[\r\n"]
[227.719171, "o", "   923\t            # dtype[Union[bool_, integer[Any]]]], _NestedSequence[\r\n"]
[227.779463, "o", "   924\t            # _SupportsArray[dtype[Union[bool_, integer[Any]]]]],\r\n"]
[227.839756, "o", "   925\t            # _NestedSequence[Union[bool, int]]], ...]]\"\r\n"]
[227.900049, "o", "   926\t            data_slice = self.to_dense()[key]  # type: ignore[index]\r\n"]
[227.960341, "o", "   927\t        elif isinstance(key, slice):\r\n"]
[228.020634, "o", "   928\t            # Avoid densifying when handling contiguous slices\r\n"]
[228.080927, "o", "   929\t            if key.step is None or key.step == 1:\r\n"]
[228.14122, "o", "   930\t                start = 0 if key.start is None else key.start\r\n"]
[228.201512, "o", "   931\t                if start < 0:\r\n"]
[228.261805, "o", "   932\t                    start += len(self)\r\n"]
[228.322098, "o", "   933\t\r\n"]
[228.38239, "o", "   934\t                end = len(self) if key.stop is None else key.stop\r\n"]
[228.442683, "o", "   935\t                if end < 0:\r\n"]
[228.502976, "o", "   936\t                    end += len(self)\r\n"]
[228.563268, "o", "   937\t\r\n"]
[228.623561, "o", "   938\t                indices = self.sp_index.indices\r\n"]
[228.683854, "o", "   939\t                keep_inds = np.flatnonzero((indices >= start) & (indices < end))\r\n"]
[228.744146, "o", "   940\t                sp_vals = self.sp_values[keep_inds]\r\n"]
[228.804439, "o", "   941\t\r\n"]
[228.864732, "o", "   942\t                sp_index = indices[keep_inds].copy()\r\n"]
[228.925024, "o", "   943\t\r\n"]
[228.985317, "o", "   944\t                # If we've sliced to not include the start of the array, all our indices\r\n"]
[229.04561, "o", "   945\t                # should be shifted. NB: here we are careful to also not shift by a\r\n"]
[229.105902, "o", "   946\t                # negative value for a case like [0, 1][-100:] where the start index\r\n"]
[229.166195, "o", "   947\t                # should be treated like 0\r\n"]
[229.226488, "o", "   948\t                if start > 0:\r\n"]
[229.28678, "o", "   949\t                    sp_index -= start\r\n"]
[229.347073, "o", "   950\t\r\n"]
[229.407366, "o", "   951\t                # Length of our result should match applying this slice to a range\r\n"]
[229.467659, "o", "   952\t                # of the length of our original array\r\n"]
[229.527951, "o", "   953\t                new_len = len(range(len(self))[key])\r\n"]
[229.588244, "o", "   954\t                new_sp_index = make_sparse_index(new_len, sp_index, self.kind)\r\n"]
[229.648537, "o", "   955\t                return type(self)._simple_new(sp_vals, new_sp_index, self.dtype)\r\n"]
[229.708829, "o", "   956\t            else:\r\n"]
[229.769122, "o", "   957\t                indices = np.arange(len(self), dtype=np.int32)[key]\r\n"]
[229.829415, "o", "   958\t                return self.take(indices)\r\n"]
[229.889707, "o", "   959\t\r\n"]
[230.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[230.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,1000p'\r"]
[230.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,1000p'\r\n"]
[230.123714, "o", "\u001b[?2004l\r\n"]
[230.241429, "o", "   960\t        elif not is_list_like(key):\r\n"]
[230.359143, "o", "   961\t            # e.g. \"foo\" or 2.5\r\n"]
[230.476857, "o", "   962\t            # exception message copied from numpy\r\n"]
[230.594571, "o", "   963\t            raise IndexError(\r\n"]
[230.712286, "o", "   964\t                r\"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis \"\r\n"]
[230.83, "o", "   965\t                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[230.947714, "o", "   966\t            )\r\n"]
[231.065429, "o", "   967\t\r\n"]
[231.183143, "o", "   968\t        else:\r\n"]
[231.300857, "o", "   969\t            if isinstance(key, SparseArray):\r\n"]
[231.418571, "o", "   970\t                # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[231.536286, "o", "   971\t                # has only fill_value - true, false or nan\r\n"]
[231.654, "o", "   972\t                # (see GH PR 44955)\r\n"]
[231.771714, "o", "   973\t                # we can apply mask very fast:\r\n"]
[231.889429, "o", "   974\t                if is_bool_dtype(key):\r\n"]
[232.007143, "o", "   975\t                    if isna(key.fill_value):\r\n"]
[232.124857, "o", "   976\t                        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[232.242571, "o", "   977\t                    if not key.fill_value:\r\n"]
[232.360286, "o", "   978\t                        return self.take(key.sp_index.indices)\r\n"]
[232.478, "o", "   979\t                    n = len(self)\r\n"]
[232.595714, "o", "   980\t                    mask = np.full(n, True, dtype=np.bool_)\r\n"]
[232.713429, "o", "   981\t                    mask[key.sp_index.indices] = False\r\n"]
[232.831143, "o", "   982\t                    return self.take(np.arange(n)[mask])\r\n"]
[232.948857, "o", "   983\t                else:\r\n"]
[233.066571, "o", "   984\t                    key = np.asarray(key)\r\n"]
[233.184286, "o", "   985\t\r\n"]
[233.302, "o", "   986\t            key = check_array_indexer(self, key)\r\n"]
[233.419714, "o", "   987\t\r\n"]
[233.537429, "o", "   988\t            if com.is_bool_indexer(key):\r\n"]
[233.655143, "o", "   989\t                # mypy doesn't know we have an array here\r\n"]
[233.772857, "o", "   990\t                key = cast(np.ndarray, key)\r\n"]
[233.890571, "o", "   991\t                return self.take(np.arange(len(key), dtype=np.int32)[key])\r\n"]
[234.008286, "o", "   992\t            elif hasattr(key, \"__len__\"):\r\n"]
[234.126, "o", "   993\t                return self.take(key)\r\n"]
[234.243714, "o", "   994\t            else:\r\n"]
[234.361429, "o", "   995\t                raise ValueError(f\"Cannot slice with '{key}'\")\r\n"]
[234.479143, "o", "   996\t\r\n"]
[234.596857, "o", "   997\t        return type(self)(data_slice, kind=self.kind)\r\n"]
[234.714571, "o", "   998\t\r\n"]
[234.832286, "o", "   999\t    def _get_val_at(self, loc):\r\n"]
[235.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[235.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1000,1040p'\r"]
[235.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '1000,1040p'\r\n"]
[235.123714, "o", "\u001b[?2004l\r\n"]
[235.241429, "o", "  1000\t        loc = validate_insert_loc(loc, len(self))\r\n"]
[235.359143, "o", "  1001\t\r\n"]
[235.476857, "o", "  1002\t        sp_loc = self.sp_index.lookup(loc)\r\n"]
[235.594571, "o", "  1003\t        if sp_loc == -1:\r\n"]
[235.712286, "o", "  1004\t            return self.fill_value\r\n"]
[235.83, "o", "  1005\t        else:\r\n"]
[235.947714, "o", "  1006\t            val = self.sp_values[sp_loc]\r\n"]
[236.065429, "o", "  1007\t            val = maybe_box_datetimelike(val, self.sp_values.dtype)\r\n"]
[236.183143, "o", "  1008\t            return val\r\n"]
[236.300857, "o", "  1009\t\r\n"]
[236.418571, "o", "  1010\t    def take(self, indices, *, allow_fill: bool = False, fill_value=None) -> Self:\r\n"]
[236.536286, "o", "  1011\t        if is_scalar(indices):\r\n"]
[236.654, "o", "  1012\t            raise ValueError(f\"'indices' must be an array, not a scalar '{indices}'.\")\r\n"]
[236.771714, "o", "  1013\t        indices = np.asarray(indices, dtype=np.int32)\r\n"]
[236.889429, "o", "  1014\t\r\n"]
[237.007143, "o", "  1015\t        dtype = None\r\n"]
[237.124857, "o", "  1016\t        if indices.size == 0:\r\n"]
[237.242571, "o", "  1017\t            result = np.array([], dtype=\"object\")\r\n"]
[237.360286, "o", "  1018\t            dtype = self.dtype\r\n"]
[237.478, "o", "  1019\t        elif allow_fill:\r\n"]
[237.595714, "o", "  1020\t            result = self._take_with_fill(indices, fill_value=fill_value)\r\n"]
[237.713429, "o", "  1021\t        else:\r\n"]
[237.831143, "o", "  1022\t            return self._take_without_fill(indices)\r\n"]
[237.948857, "o", "  1023\t\r\n"]
[238.066571, "o", "  1024\t        return type(self)(\r\n"]
[238.184286, "o", "  1025\t            result, fill_value=self.fill_value, kind=self.kind, dtype=dtype\r\n"]
[238.302, "o", "  1026\t        )\r\n"]
[238.419714, "o", "  1027\t\r\n"]
[238.537429, "o", "  1028\t    def _take_with_fill(self, indices, fill_value=None) -> np.ndarray:\r\n"]
[238.655143, "o", "  1029\t        if fill_value is None:\r\n"]
[238.772857, "o", "  1030\t            fill_value = self.dtype.na_value\r\n"]
[238.890571, "o", "  1031\t\r\n"]
[239.008286, "o", "  1032\t        if indices.min() < -1:\r\n"]
[239.126, "o", "  1033\t            raise ValueError(\r\n"]
[239.243714, "o", "  1034\t                \"Invalid value in 'indices'. Must be between -1 \"\r\n"]
[239.361429, "o", "  1035\t                \"and the length of the array.\"\r\n"]
[239.479143, "o", "  1036\t            )\r\n"]
[239.596857, "o", "  1037\t\r\n"]
[239.714571, "o", "  1038\t        if indices.max() >= len(self):\r\n"]
[239.832286, "o", "  1039\t            raise IndexError(\"out of bounds value in 'indices'.\")\r\n"]
[240.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[240.002, "i", "python - << 'PY'\r"]
[240.004, "o", "python - << 'PY'\r\n"]
[240.063488, "o", "\u001b[?2004l\r\n"]
[240.120977, "o", "\u001b[?2004h> import io, re, sys\r\n"]
[240.178465, "o", "\u001b[?2004l\r\n"]
[240.235953, "o", "\u001b[?2004h> p = 'pandas/core/arrays/sparse/array.py'\r\n"]
[240.293442, "o", "\u001b[?2004l\r\n"]
[240.35093, "o", "\u001b[?2004h> src = open(p, 'r', encoding='utf-8').read()\r\n"]
[240.408419, "o", "\u001b[?2004l\r\n"]
[240.465907, "o", "\u001b[?2004h> pat = (\r\n"]
[240.523395, "o", "\u001b[?2004l\r\n"]
[240.580884, "o", "\u001b[?2004h>     r\"(if\\s+is_bool_dtype\\(key\\):\\n\\s+if\\s+isna\\(key\\.fill_value\\):\\n\\s+return\\s+self\\.take\\(key\\.sp_index\\.indices\\[key\\.sp_values\\]\\)\\n\\s+if\\s+not\\s+key\\.fil\r\n"]
[240.638372, "o", "ll_value:\\n\\s+return\\s+self\\.take\\(key\\.sp_index\\.indices\\)\\n\\s+n\\s*=\\s*len\\(self\\)\\n\\s+mask\\s*=\\s*np\\.full\\(n,\\s*True,\\s*dtype=np\\.bool_\\)\\n\\s+mask\\[key\\.sp_ind\r\n"]
[240.69586, "o", "dex\\.indices\\]\\s*=\\s*False\\n\\s+return\\s+self\\.take\\(np\\.arange\\(n\\)\\[mask\\]\\))\"\r\n"]
[240.753349, "o", "\u001b[?2004l\r\n"]
[240.810837, "o", "\u001b[?2004h> )\r\n"]
[240.868326, "o", "\u001b[?2004l\r\n"]
[240.925814, "o", "\u001b[?2004h> rep = (\r\n"]
[240.983302, "o", "\u001b[?2004l\r\n"]
[241.040791, "o", "\u001b[?2004h>     \"if is_bool_dtype(key):\\n\"\r\n"]
[241.098279, "o", "\u001b[?2004l\r\n"]
[241.155767, "o", "\u001b[?2004h>     \"    if isna(key.fill_value):\\n\"\r\n"]
[241.213256, "o", "\u001b[?2004l\r\n"]
[241.270744, "o", "\u001b[?2004h>     \"        return self.take(key.sp_index.indices[key.sp_values])\\n\"\r\n"]
[241.328233, "o", "\u001b[?2004l\r\n"]
[241.385721, "o", "\u001b[?2004h>     \"    if not key.fill_value:\\n\"\r\n"]
[241.443209, "o", "\u001b[?2004l\r\n"]
[241.500698, "o", "\u001b[?2004h>     \"        return self.take(key.sp_index.indices)\\n\"\r\n"]
[241.558186, "o", "\u001b[?2004l\r\n"]
[241.615674, "o", "\u001b[?2004h>     \"    # fill_value is True: compute complement indices without dense mask\\n\"\r\n"]
[241.673163, "o", "\u001b[?2004l\r\n"]
[241.730651, "o", "\u001b[?2004h>     \"    n = len(self)\\n\"\r\n"]
[241.78814, "o", "\u001b[?2004l\r\n"]
[241.845628, "o", "\u001b[?2004h>     \"    neg_idx = key.sp_index.indices\\n\"\r\n"]
[241.903116, "o", "\u001b[?2004l\r\n"]
[241.960605, "o", "\u001b[?2004h>     \"    if neg_idx.size == 0:\\n\"\r\n"]
[242.018093, "o", "\u001b[?2004l\r\n"]
[242.075581, "o", "\u001b[?2004h>     \"        return self.take(np.arange(n, dtype=np.int32))\\n\"\r\n"]
[242.13307, "o", "\u001b[?2004l\r\n"]
[242.190558, "o", "\u001b[?2004h>     \"    out_len = n - int(neg_idx.size)\\n\"\r\n"]
[242.248047, "o", "\u001b[?2004l\r\n"]
[242.305535, "o", "\u001b[?2004h>     \"    out = np.empty(out_len, dtype=np.int32)\\n\"\r\n"]
[242.363023, "o", "\u001b[?2004l\r\n"]
[242.420512, "o", "\u001b[?2004h>     \"    pos = 0\\n\"\r\n"]
[242.478, "o", "\u001b[?2004l\r\n"]
[242.535488, "o", "\u001b[?2004h>     \"    start = 0\\n\"\r\n"]
[242.592977, "o", "\u001b[?2004l\r\n"]
[242.650465, "o", "\u001b[?2004h>     \"    for idx in neg_idx:\\n\"\r\n"]
[242.707953, "o", "\u001b[?2004l\r\n"]
[242.765442, "o", "\u001b[?2004h>     \"        if idx > start:\\n\"\r\n"]
[242.82293, "o", "\u001b[?2004l\r\n"]
[242.880419, "o", "\u001b[?2004h>     \"            seg = np.arange(start, idx, dtype=np.int32)\\n\"\r\n"]
[242.937907, "o", "\u001b[?2004l\r\n"]
[242.995395, "o", "\u001b[?2004h>     \"            L = seg.size\\n\"\r\n"]
[243.052884, "o", "\u001b[?2004l\r\n"]
[243.110372, "o", "\u001b[?2004h>     \"            out[pos:pos+L] = seg\\n\"\r\n"]
[243.16786, "o", "\u001b[?2004l\r\n"]
[243.225349, "o", "\u001b[?2004h>     \"            pos += L\\n\"\r\n"]
[243.282837, "o", "\u001b[?2004l\r\n"]
[243.340326, "o", "\u001b[?2004h>     \"        start = int(idx) + 1\\n\"\r\n"]
[243.397814, "o", "\u001b[?2004l\r\n"]
[243.455302, "o", "\u001b[?2004h>     \"    if start < n:\\n\"\r\n"]
[243.512791, "o", "\u001b[?2004l\r\n"]
[243.570279, "o", "\u001b[?2004h>     \"        seg = np.arange(start, n, dtype=np.int32)\\n\"\r\n"]
[243.627767, "o", "\u001b[?2004l\r\n"]
[243.685256, "o", "\u001b[?2004h>     \"        L = seg.size\\n\"\r\n"]
[243.742744, "o", "\u001b[?2004l\r\n"]
[243.800233, "o", "\u001b[?2004h>     \"        out[pos:pos+L] = seg\\n\"\r\n"]
[243.857721, "o", "\u001b[?2004l\r\n"]
[243.915209, "o", "\u001b[?2004h>     \"    return self.take(out)\"\r\n"]
[243.972698, "o", "\u001b[?2004l\r\n"]
[244.030186, "o", "\u001b[?2004h> )\r\n"]
[244.087674, "o", "\u001b[?2004l\r\n"]
[244.145163, "o", "\u001b[?2004h> new, nsub = re.subn(pat, rep, src)\r\n"]
[244.202651, "o", "\u001b[?2004l\r\n"]
[244.26014, "o", "\u001b[?2004h> if nsub == 0:\r\n"]
[244.317628, "o", "\u001b[?2004l\r\n"]
[244.375116, "o", "\u001b[?2004h>     print('Patch pattern not found; aborting.', file=sys.stderr)\r\n"]
[244.432605, "o", "\u001b[?2004l\r\n"]
[244.490093, "o", "\u001b[?2004h>     sys.exit(1)\r\n"]
[244.547581, "o", "\u001b[?2004l\r\n"]
[244.60507, "o", "\u001b[?2004h> open(p, 'w', encoding='utf-8').write(new)\r\n"]
[244.662558, "o", "\u001b[?2004l\r\n"]
[244.720047, "o", "\u001b[?2004h> print('Patched', p)\r\n"]
[244.777535, "o", "\u001b[?2004l\r\n"]
[244.835023, "o", "\u001b[?2004h> PY\r\n"]
[244.892512, "o", "\u001b[?2004l\r\n"]
[245.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[245.002, "i", "git diff -- pandas/core/arrays/sparse/array.py | sed -n '1,200p'\r"]
[245.004, "o", "git diff -- pandas/core/arrays/sparse/array.py | sed -n '1,200p'\r\n"]
[245.115867, "o", "\u001b[?2004l\r\n"]
[245.225733, "o", "diff --git a/pandas/core/arrays/sparse/array.py b/pandas/core/arrays/sparse/array.py\r\n"]
[245.3356, "o", "index e6c89f65fb..786153a1a6 100644\r\n"]
[245.445467, "o", "--- a/pandas/core/arrays/sparse/array.py\r\n"]
[245.555333, "o", "+++ b/pandas/core/arrays/sparse/array.py\r\n"]
[245.6652, "o", "@@ -972,14 +972,31 @@ class SparseArray(OpsMixin, PandasObject, ExtensionArray):\r\n"]
[245.775067, "o", "                 # (see GH PR 44955)\r\n"]
[245.884933, "o", "                 # we can apply mask very fast:\r\n"]
[245.9948, "o", "                 if is_bool_dtype(key):\r\n"]
[246.104667, "o", "-                    if isna(key.fill_value):\r\n"]
[246.214533, "o", "-                        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[246.3244, "o", "-                    if not key.fill_value:\r\n"]
[246.434267, "o", "-                        return self.take(key.sp_index.indices)\r\n"]
[246.544133, "o", "-                    n = len(self)\r\n"]
[246.654, "o", "-                    mask = np.full(n, True, dtype=np.bool_)\r\n"]
[246.763867, "o", "-                    mask[key.sp_index.indices] = False\r\n"]
[246.873733, "o", "-                    return self.take(np.arange(n)[mask])\r\n"]
[246.9836, "o", "+    if isna(key.fill_value):\r\n"]
[247.093467, "o", "+        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[247.203333, "o", "+    if not key.fill_value:\r\n"]
[247.3132, "o", "+        return self.take(key.sp_index.indices)\r\n"]
[247.423067, "o", "+    # fill_value is True: compute complement indices without dense mask\r\n"]
[247.532933, "o", "+    n = len(self)\r\n"]
[247.6428, "o", "+    neg_idx = key.sp_index.indices\r\n"]
[247.752667, "o", "+    if neg_idx.size == 0:\r\n"]
[247.862533, "o", "+        return self.take(np.arange(n, dtype=np.int32))\r\n"]
[247.9724, "o", "+    out_len = n - int(neg_idx.size)\r\n"]
[248.082267, "o", "+    out = np.empty(out_len, dtype=np.int32)\r\n"]
[248.192133, "o", "+    pos = 0\r\n"]
[248.302, "o", "+    start = 0\r\n"]
[248.411867, "o", "+    for idx in neg_idx:\r\n"]
[248.521733, "o", "+        if idx > start:\r\n"]
[248.6316, "o", "+            seg = np.arange(start, idx, dtype=np.int32)\r\n"]
[248.741467, "o", "+            L = seg.size\r\n"]
[248.851333, "o", "+            out[pos:pos+L] = seg\r\n"]
[248.9612, "o", "+            pos += L\r\n"]
[249.071067, "o", "+        start = int(idx) + 1\r\n"]
[249.180933, "o", "+    if start < n:\r\n"]
[249.2908, "o", "+        seg = np.arange(start, n, dtype=np.int32)\r\n"]
[249.400667, "o", "+        L = seg.size\r\n"]
[249.510533, "o", "+        out[pos:pos+L] = seg\r\n"]
[249.6204, "o", "+    return self.take(out)\r\n"]
[249.730267, "o", "                 else:\r\n"]
[249.840133, "o", "                     key = np.asarray(key)\r\n"]
[250.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[250.002, "i", "pytest -q -k sparse --maxfail=1\r"]
[250.004, "o", "pytest -q -k sparse --maxfail=1\r\n"]
[250.315, "o", "\u001b[?2004l\r\n"]
[250.624, "o", "\u001b[31mImportError while loading conftest '/workspace/repo/pandas/conftest.py'.\u001b[0m\r\n"]
[250.933, "o", "\u001b[31mpandas/__init__.py:48: in <module>\u001b[0m\r\n"]
[251.242, "o", "\u001b[31m    from pandas.core.api import (\u001b[0m\r\n"]
[251.551, "o", "\u001b[31mpandas/core/api.py:27: in <module>\u001b[0m\r\n"]
[251.86, "o", "\u001b[31m    from pandas.core.arrays import Categorical\u001b[0m\r\n"]
[252.169, "o", "\u001b[31mpandas/core/arrays/__init__.py:19: in <module>\u001b[0m\r\n"]
[252.478, "o", "\u001b[31m    from pandas.core.arrays.sparse import SparseArray\u001b[0m\r\n"]
[252.787, "o", "\u001b[31mpandas/core/arrays/sparse/__init__.py:1: in <module>\u001b[0m\r\n"]
[253.096, "o", "\u001b[31m    from pandas.core.arrays.sparse.accessor import (\u001b[0m\r\n"]
[253.405, "o", "\u001b[31mpandas/core/arrays/sparse/accessor.py:16: in <module>\u001b[0m\r\n"]
[253.714, "o", "\u001b[31m    from pandas.core.arrays.sparse.array import SparseArray\u001b[0m\r\n"]
[254.023, "o", "\u001b[31mE     File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 975\u001b[0m\r\n"]
[254.332, "o", "\u001b[31mE       if isna(key.fill_value):\u001b[0m\r\n"]
[254.641, "o", "\u001b[31mE       ^\u001b[0m\r\n"]
[255.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[255.002, "i", "cd asv_bench\r"]
[255.004, "o", "cd asv_bench\r\n"]
[255.006, "o", "\u001b[?2004l\r\n"]
[260.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[260.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[260.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[260.109, "o", "\u001b[?2004l\r\n"]
[260.212, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[260.315, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpu0i194tf/result.json (exit status 1)\u001b[0m\r\n"]
[260.418, "o", "   STDOUT -------->\r\n"]
[260.521, "o", "   \r\n"]
[260.624, "o", "   STDERR -------->\r\n"]
[260.727, "o", "   Traceback (most recent call last):\r\n"]
[260.83, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[260.933, "o", "       main()\r\n"]
[261.036, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[261.139, "o", "       commands[mode](args)\r\n"]
[261.242, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[261.345, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[261.448, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[261.551, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[261.654, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[261.757, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[261.86, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[261.963, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[262.066, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[262.169, "o", "       module = importlib.import_module(module_name)\r\n"]
[262.272, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n"]
[262.375, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[262.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n"]
[262.581, "o", "     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n"]
[262.684, "o", "     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n"]
[262.787, "o", "     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n"]
[262.89, "o", "     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n"]
[262.993, "o", "     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n"]
[263.096, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[263.199, "o", "       import pandas as pd\r\n"]
[263.302, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[263.405, "o", "       from pandas.core.api import (\r\n"]
[263.508, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[263.611, "o", "       from pandas.core.arrays import Categorical\r\n"]
[263.714, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 19, in <module>\r\n"]
[263.817, "o", "       from pandas.core.arrays.sparse import SparseArray\r\n"]
[263.92, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/__init__.py\", line 1, in <module>\r\n"]
[264.023, "o", "       from pandas.core.arrays.sparse.accessor import (\r\n"]
[264.126, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/accessor.py\", line 16, in <module>\r\n"]
[264.229, "o", "       from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[264.332, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 975\r\n"]
[264.435, "o", "       if isna(key.fill_value):\r\n"]
[264.538, "o", "       ^\r\n"]
[264.641, "o", "   IndentationError: expected an indented block\r\n"]
[264.744, "o", "\r\n"]
[264.847, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpu0i194tf/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[265.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[265.002, "i", "sed -n '950,990p' pandas/core/arrays/sparse/array.py\r"]
[265.004, "o", "sed -n '950,990p' pandas/core/arrays/sparse/array.py\r\n"]
[267.478, "o", "\u001b[?2004l\r\n"]
[270.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[270.002, "i", "awk 'NR>=960&&NR<=992{print NR\":\"$0}' pandas/core/arrays/sparse/array.py\r"]
[270.004, "o", "awk 'NR>=960&&NR<=992{print NR\":\"$0}' pandas/core/arrays/sparse/array.py\r\n"]
[272.478, "o", "\u001b[?2004l\r\n"]
[275.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[275.002, "i", "python - << 'PY'\r"]
[275.004, "o", "python - << 'PY'\r\n"]
[275.212, "o", "\u001b[?2004l\r\n"]
[275.418, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[275.624, "o", "\u001b[?2004l\r\n"]
[275.83, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[276.036, "o", "\u001b[?2004l\r\n"]
[276.242, "o", "\u001b[?2004h> src = p.read_text(encoding='utf-8')\r\n"]
[276.448, "o", "\u001b[?2004l\r\n"]
[276.654, "o", "\u001b[?2004h> start = src.find('if isinstance(key, SparseArray):')\r\n"]
[276.86, "o", "\u001b[?2004l\r\n"]
[277.066, "o", "\u001b[?2004h> end = src.find('\\n              key = check_array_indexer', start)\r\n"]
[277.272, "o", "\u001b[?2004l\r\n"]
[277.478, "o", "\u001b[?2004h> print(src[start:end])\r\n"]
[277.684, "o", "\u001b[?2004l\r\n"]
[277.89, "o", "\u001b[?2004h> PY\r\n"]
[278.096, "o", "\u001b[?2004l\r\n"]
[278.302, "o", "Traceback (most recent call last):\r\n"]
[278.508, "o", "  File \"<stdin>\", line 3, in <module>\r\n"]
[278.714, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1236, in read_text\r\n"]
[278.92, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[279.126, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1222, in open\r\n"]
[279.332, "o", "    return io.open(self, mode, buffering, encoding, errors, newline,\r\n"]
[279.538, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1078, in _opener\r\n"]
[279.744, "o", "    return self._accessor.open(self, flags, mode)\r\n"]
[280.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[280.002, "i", "python - << 'PY'\r"]
[280.004, "o", "python - << 'PY'\r\n"]
[280.044625, "o", "\u001b[?2004l\r\n"]
[280.08325, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[280.121875, "o", "\u001b[?2004l\r\n"]
[280.1605, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[280.199125, "o", "\u001b[?2004l\r\n"]
[280.23775, "o", "\u001b[?2004h> s = p.read_text(encoding='utf-8')\r\n"]
[280.276375, "o", "\u001b[?2004l\r\n"]
[280.315, "o", "\u001b[?2004h> old_block = (\r\n"]
[280.353625, "o", "\u001b[?2004l\r\n"]
[280.39225, "o", "\u001b[?2004h>     \"                  if is_bool_dtype(key):\\n\"\r\n"]
[280.430875, "o", "\u001b[?2004l\r\n"]
[280.4695, "o", "\u001b[?2004h>     \"                      if isna(key.fill_value):\\n\"\r\n"]
[280.508125, "o", "\u001b[?2004l\r\n"]
[280.54675, "o", "\u001b[?2004h>     \"                          return self.take(key.sp_index.indices[key.sp_values])\\n\"\r\n"]
[280.585375, "o", "\u001b[?2004l\r\n"]
[280.624, "o", "\u001b[?2004h>     \"                      if not key.fill_value:\\n\"\r\n"]
[280.662625, "o", "\u001b[?2004l\r\n"]
[280.70125, "o", "\u001b[?2004h>     \"                          return self.take(key.sp_index.indices)\\n\"\r\n"]
[280.739875, "o", "\u001b[?2004l\r\n"]
[280.7785, "o", "\u001b[?2004h>     \"                      n = len(self)\\n\"\r\n"]
[280.817125, "o", "\u001b[?2004l\r\n"]
[280.85575, "o", "\u001b[?2004h>     \"                      mask = np.full(n, True, dtype=np.bool_)\\n\"\r\n"]
[280.894375, "o", "\u001b[?2004l\r\n"]
[280.933, "o", "\u001b[?2004h>     \"                      mask[key.sp_index.indices] = False\\n\"\r\n"]
[280.971625, "o", "\u001b[?2004l\r\n"]
[281.01025, "o", "\u001b[?2004h>     \"                      return self.take(np.arange(n)[mask])\\n\"\r\n"]
[281.048875, "o", "\u001b[?2004l\r\n"]
[281.0875, "o", "\u001b[?2004h>     \"                  else:\\n\"\r\n"]
[281.126125, "o", "\u001b[?2004l\r\n"]
[281.16475, "o", "\u001b[?2004h>     \"                      key = np.asarray(key)\\n\"\r\n"]
[281.203375, "o", "\u001b[?2004l\r\n"]
[281.242, "o", "\u001b[?2004h> )\r\n"]
[281.280625, "o", "\u001b[?2004l\r\n"]
[281.31925, "o", "\u001b[?2004h> new_block = (\r\n"]
[281.357875, "o", "\u001b[?2004l\r\n"]
[281.3965, "o", "\u001b[?2004h>     \"                  if is_bool_dtype(key):\\n\"\r\n"]
[281.435125, "o", "\u001b[?2004l\r\n"]
[281.47375, "o", "\u001b[?2004h>     \"                      if isna(key.fill_value):\\n\"\r\n"]
[281.512375, "o", "\u001b[?2004l\r\n"]
[281.551, "o", "\u001b[?2004h>     \"                          return self.take(key.sp_index.indices[key.sp_values])\\n\"\r\n"]
[281.589625, "o", "\u001b[?2004l\r\n"]
[281.62825, "o", "\u001b[?2004h>     \"                      if not key.fill_value:\\n\"\r\n"]
[281.666875, "o", "\u001b[?2004l\r\n"]
[281.7055, "o", "\u001b[?2004h>     \"                          return self.take(key.sp_index.indices)\\n\"\r\n"]
[281.744125, "o", "\u001b[?2004l\r\n"]
[281.78275, "o", "\u001b[?2004h>     \"                      # fill_value is True: compute complement indices without dense mask\\n\"\r\n"]
[281.821375, "o", "\u001b[?2004l\r\n"]
[281.86, "o", "\u001b[?2004h>     \"                      n = len(self)\\n\"\r\n"]
[281.898625, "o", "\u001b[?2004l\r\n"]
[281.93725, "o", "\u001b[?2004h>     \"                      neg_idx = key.sp_index.indices\\n\"\r\n"]
[281.975875, "o", "\u001b[?2004l\r\n"]
[282.0145, "o", "\u001b[?2004h>     \"                      if neg_idx.size == 0:\\n\"\r\n"]
[282.053125, "o", "\u001b[?2004l\r\n"]
[282.09175, "o", "\u001b[?2004h>     \"                          return self.take(np.arange(n, dtype=np.int32))\\n\"\r\n"]
[282.130375, "o", "\u001b[?2004l\r\n"]
[282.169, "o", "\u001b[?2004h>     \"                      out_len = n - int(neg_idx.size)\\n\"\r\n"]
[282.207625, "o", "\u001b[?2004l\r\n"]
[282.24625, "o", "\u001b[?2004h>     \"                      out = np.empty(out_len, dtype=np.int32)\\n\"\r\n"]
[282.284875, "o", "\u001b[?2004l\r\n"]
[282.3235, "o", "\u001b[?2004h>     \"                      pos = 0\\n\"\r\n"]
[282.362125, "o", "\u001b[?2004l\r\n"]
[282.40075, "o", "\u001b[?2004h>     \"                      start = 0\\n\"\r\n"]
[282.439375, "o", "\u001b[?2004l\r\n"]
[282.478, "o", "\u001b[?2004h>     \"                      for idx in neg_idx:\\n\"\r\n"]
[282.516625, "o", "\u001b[?2004l\r\n"]
[282.55525, "o", "\u001b[?2004h>     \"                          if idx > start:\\n\"\r\n"]
[282.593875, "o", "\u001b[?2004l\r\n"]
[282.6325, "o", "\u001b[?2004h>     \"                              seg = np.arange(start, idx, dtype=np.int32)\\n\"\r\n"]
[282.671125, "o", "\u001b[?2004l\r\n"]
[282.70975, "o", "\u001b[?2004h>     \"                              L = seg.size\\n\"\r\n"]
[282.748375, "o", "\u001b[?2004l\r\n"]
[282.787, "o", "\u001b[?2004h>     \"                              out[pos:pos+L] = seg\\n\"\r\n"]
[282.825625, "o", "\u001b[?2004l\r\n"]
[282.86425, "o", "\u001b[?2004h>     \"                              pos += L\\n\"\r\n"]
[282.902875, "o", "\u001b[?2004l\r\n"]
[282.9415, "o", "\u001b[?2004h>     \"                          start = int(idx) + 1\\n\"\r\n"]
[282.980125, "o", "\u001b[?2004l\r\n"]
[283.01875, "o", "\u001b[?2004h>     \"                      if start < n:\\n\"\r\n"]
[283.057375, "o", "\u001b[?2004l\r\n"]
[283.096, "o", "\u001b[?2004h>     \"                          seg = np.arange(start, n, dtype=np.int32)\\n\"\r\n"]
[283.134625, "o", "\u001b[?2004l\r\n"]
[283.17325, "o", "\u001b[?2004h>     \"                          L = seg.size\\n\"\r\n"]
[283.211875, "o", "\u001b[?2004l\r\n"]
[283.2505, "o", "\u001b[?2004h>     \"                          out[pos:pos+L] = seg\\n\"\r\n"]
[283.289125, "o", "\u001b[?2004l\r\n"]
[283.32775, "o", "\u001b[?2004h>     \"                      return self.take(out)\\n\"\r\n"]
[283.366375, "o", "\u001b[?2004l\r\n"]
[283.405, "o", "\u001b[?2004h>     \"                  else:\\n\"\r\n"]
[283.443625, "o", "\u001b[?2004l\r\n"]
[283.48225, "o", "\u001b[?2004h>     \"                      key = np.asarray(key)\\n\"\r\n"]
[283.520875, "o", "\u001b[?2004l\r\n"]
[283.5595, "o", "\u001b[?2004h> )\r\n"]
[283.598125, "o", "\u001b[?2004l\r\n"]
[283.63675, "o", "\u001b[?2004h> if old_block in s:\r\n"]
[283.675375, "o", "\u001b[?2004l\r\n"]
[283.714, "o", "\u001b[?2004h>     s = s.replace(old_block, new_block)\r\n"]
[283.752625, "o", "\u001b[?2004l\r\n"]
[283.79125, "o", "\u001b[?2004h> else:\r\n"]
[283.829875, "o", "\u001b[?2004l\r\n"]
[283.8685, "o", "\u001b[?2004h>     # Try to repair by finding the if is_bool_dtype block start and reconstruct minimaly\r\n"]
[283.907125, "o", "\u001b[?2004l\r\n"]
[283.94575, "o", "\u001b[?2004h>     import re\r\n"]
[283.984375, "o", "\u001b[?2004l\r\n"]
[284.023, "o", "\u001b[?2004h>     m = re.search(r\"(\\n\\s*if isinstance\\(key, SparseArray\\):\\n[\\s\\S]*?if is_bool_dtype\\(key\\):\\n)\", s)\r\n"]
[284.061625, "o", "\u001b[?2004l\r\n"]
[284.10025, "o", "\u001b[?2004h>     if not m:\r\n"]
[284.138875, "o", "\u001b[?2004l\r\n"]
[284.1775, "o", "\u001b[?2004h>         raise SystemExit('Could not locate boolean mask block')\r\n"]
[284.216125, "o", "\u001b[?2004l\r\n"]
[284.25475, "o", "\u001b[?2004h>     # Not performing risky surgery if we can't match exactly\r\n"]
[284.293375, "o", "\u001b[?2004l\r\n"]
[284.332, "o", "\u001b[?2004h>     raise SystemExit('Exact block not found; manual fix required')\r\n"]
[284.370625, "o", "\u001b[?2004l\r\n"]
[284.40925, "o", "\u001b[?2004h> p.write_text(s, encoding='utf-8')\r\n"]
[284.447875, "o", "\u001b[?2004l\r\n"]
[284.4865, "o", "\u001b[?2004h> print('Rewrote boolean-mask block successfully')\r\n"]
[284.525125, "o", "\u001b[?2004l\r\n"]
[284.56375, "o", "\u001b[?2004h> PY\r\n"]
[284.602375, "o", "\u001b[?2004l\r\n"]
[284.641, "o", "Traceback (most recent call last):\r\n"]
[284.679625, "o", "  File \"<stdin>\", line 3, in <module>\r\n"]
[284.71825, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1236, in read_text\r\n"]
[284.756875, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[284.7955, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1222, in open\r\n"]
[284.834125, "o", "    return io.open(self, mode, buffering, encoding, errors, newline,\r\n"]
[284.87275, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1078, in _opener\r\n"]
[284.911375, "o", "    return self._accessor.open(self, flags, mode)\r\n"]
[285.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[285.002, "i", "python - << 'PY'\r"]
[285.004, "o", "python - << 'PY'\r\n"]
[285.2532, "o", "\u001b[?2004l\r\n"]
[285.5004, "o", "\u001b[?2004h> import sys\r\n"]
[285.7476, "o", "\u001b[?2004l\r\n"]
[285.9948, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[286.242, "o", "\u001b[?2004l\r\n"]
[286.4892, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[286.7364, "o", "\u001b[?2004l\r\n"]
[286.9836, "o", "\u001b[?2004h> print('\\n'.join(f\"{i+1:4d}: \"+line.rstrip('\\n') for i,line in enumerate(p.read_text(encoding='utf-8').splitlines()[960:996])))\r\n"]
[287.2308, "o", "\u001b[?2004l\r\n"]
[287.478, "o", "\u001b[?2004h> PY\r\n"]
[287.7252, "o", "\u001b[?2004l\r\n"]
[287.9724, "o", "Traceback (most recent call last):\r\n"]
[288.2196, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[288.4668, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1236, in read_text\r\n"]
[288.714, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[288.9612, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1222, in open\r\n"]
[289.2084, "o", "    return io.open(self, mode, buffering, encoding, errors, newline,\r\n"]
[289.4556, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1078, in _opener\r\n"]
[289.7028, "o", "    return self._accessor.open(self, flags, mode)\r\n"]
[290.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[290.002, "i", "python -m pyflakes pandas/core/arrays/sparse/array.py || true\r"]
[290.004, "o", "python -m pyflakes pandas/core/arrays/sparse/array.py || true\r\n"]
[292.478, "o", "\u001b[?2004l\r\n"]
[295.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[295.002, "i", "python - << 'PY'\r"]
[295.004, "o", "python - << 'PY'\r\n"]
[295.176483, "o", "\u001b[?2004l\r\n"]
[295.346966, "o", "\u001b[?2004h> # Quick import test to catch IndentationError\r\n"]
[295.517448, "o", "\u001b[?2004l\r\n"]
[295.687931, "o", "\u001b[?2004h> import importlib, sys\r\n"]
[295.858414, "o", "\u001b[?2004l\r\n"]
[296.028897, "o", "\u001b[?2004h> sys.path.insert(0, 'pandas')\r\n"]
[296.199379, "o", "\u001b[?2004l\r\n"]
[296.369862, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[296.540345, "o", "\u001b[?2004l\r\n"]
[296.710828, "o", "\u001b[?2004h> print('Imported pandas ok; version', pd.__version__)\r\n"]
[296.88131, "o", "\u001b[?2004l\r\n"]
[297.051793, "o", "\u001b[?2004h> PY\r\n"]
[297.222276, "o", "\u001b[?2004l\r\n"]
[297.392759, "o", "Traceback (most recent call last):\r\n"]
[297.563241, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[297.733724, "o", "  File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[297.904207, "o", "    from pandas.core.api import (\r\n"]
[298.07469, "o", "  File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[298.245172, "o", "    from pandas.core.arrays import Categorical\r\n"]
[298.415655, "o", "  File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 19, in <module>\r\n"]
[298.586138, "o", "    from pandas.core.arrays.sparse import SparseArray\r\n"]
[298.756621, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/__init__.py\", line 1, in <module>\r\n"]
[298.927103, "o", "    from pandas.core.arrays.sparse.accessor import (\r\n"]
[299.097586, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/accessor.py\", line 16, in <module>\r\n"]
[299.268069, "o", "    from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[299.438552, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 975\r\n"]
[299.609034, "o", "    if isna(key.fill_value):\r\n"]
[299.779517, "o", "    ^\r\n"]
[300.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[300.002, "i", "cd asv_bench\r"]
[300.004, "o", "cd asv_bench\r\n"]
[302.478, "o", "\u001b[?2004l\r\n"]
[305.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[305.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[305.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[305.109, "o", "\u001b[?2004l\r\n"]
[305.212, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[305.315, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpyldbukl4/result.json (exit status 1)\u001b[0m\r\n"]
[305.418, "o", "   STDOUT -------->\r\n"]
[305.521, "o", "   \r\n"]
[305.624, "o", "   STDERR -------->\r\n"]
[305.727, "o", "   Traceback (most recent call last):\r\n"]
[305.83, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[305.933, "o", "       main()\r\n"]
[306.036, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[306.139, "o", "       commands[mode](args)\r\n"]
[306.242, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[306.345, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[306.448, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[306.551, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[306.654, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[306.757, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[306.86, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[306.963, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[307.066, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[307.169, "o", "       module = importlib.import_module(module_name)\r\n"]
[307.272, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n"]
[307.375, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[307.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n"]
[307.581, "o", "     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n"]
[307.684, "o", "     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n"]
[307.787, "o", "     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n"]
[307.89, "o", "     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n"]
[307.993, "o", "     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n"]
[308.096, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[308.199, "o", "       import pandas as pd\r\n"]
[308.302, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[308.405, "o", "       from pandas.core.api import (\r\n"]
[308.508, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[308.611, "o", "       from pandas.core.arrays import Categorical\r\n"]
[308.714, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 19, in <module>\r\n"]
[308.817, "o", "       from pandas.core.arrays.sparse import SparseArray\r\n"]
[308.92, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/__init__.py\", line 1, in <module>\r\n"]
[309.023, "o", "       from pandas.core.arrays.sparse.accessor import (\r\n"]
[309.126, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/accessor.py\", line 16, in <module>\r\n"]
[309.229, "o", "       from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[309.332, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 975\r\n"]
[309.435, "o", "       if isna(key.fill_value):\r\n"]
[309.538, "o", "       ^\r\n"]
[309.641, "o", "   IndentationError: expected an indented block\r\n"]
[309.744, "o", "\r\n"]
[309.847, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpyldbukl4/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[310.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[310.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r"]
[310.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r\n"]
[312.478, "o", "\u001b[?2004l\r\n"]
[315.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[315.002, "i", "python - << 'PY'\r"]
[315.004, "o", "python - << 'PY'\r\n"]
[315.044625, "o", "\u001b[?2004l\r\n"]
[315.08325, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[315.121875, "o", "\u001b[?2004l\r\n"]
[315.1605, "o", "\u001b[?2004h> import re\r\n"]
[315.199125, "o", "\u001b[?2004l\r\n"]
[315.23775, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[315.276375, "o", "\u001b[?2004l\r\n"]
[315.315, "o", "\u001b[?2004h> s = p.read_text(encoding='utf-8')\r\n"]
[315.353625, "o", "\u001b[?2004l\r\n"]
[315.39225, "o", "\u001b[?2004h> # Identify the start of the SparseArray key block\r\n"]
[315.430875, "o", "\u001b[?2004l\r\n"]
[315.4695, "o", "\u001b[?2004h> m0 = re.search(r\"\\n(\\s*)if isinstance\\(key, SparseArray\\):\\n\", s)\r\n"]
[315.508125, "o", "\u001b[?2004l\r\n"]
[315.54675, "o", "\u001b[?2004h> if not m0:\r\n"]
[315.585375, "o", "\u001b[?2004l\r\n"]
[315.624, "o", "\u001b[?2004h>     raise SystemExit('Could not locate SparseArray key block start')\r\n"]
[315.662625, "o", "\u001b[?2004l\r\n"]
[315.70125, "o", "\u001b[?2004h> base = m0.group(1)\r\n"]
[315.739875, "o", "\u001b[?2004l\r\n"]
[315.7785, "o", "\u001b[?2004h> start = m0.end()\r\n"]
[315.817125, "o", "\u001b[?2004l\r\n"]
[315.85575, "o", "\u001b[?2004h> # Find the end just before 'key = check_array_indexer'\r\n"]
[315.894375, "o", "\u001b[?2004l\r\n"]
[315.933, "o", "\u001b[?2004h> endm = re.search(r\"\\n\\s*key = check_array_indexer\\(self, key\\)\", s[start:])\r\n"]
[315.971625, "o", "\u001b[?2004l\r\n"]
[316.01025, "o", "\u001b[?2004h> if not endm:\r\n"]
[316.048875, "o", "\u001b[?2004l\r\n"]
[316.0875, "o", "\u001b[?2004h>     raise SystemExit('Could not locate end of SparseArray key block')\r\n"]
[316.126125, "o", "\u001b[?2004l\r\n"]
[316.16475, "o", "\u001b[?2004h> end = start + endm.start()\r\n"]
[316.203375, "o", "\u001b[?2004l\r\n"]
[316.242, "o", "\u001b[?2004h> block = s[start:end]\r\n"]
[316.280625, "o", "\u001b[?2004l\r\n"]
[316.31925, "o", "\u001b[?2004h> # Replace the inner boolean-mask block robustly\r\n"]
[316.357875, "o", "\u001b[?2004l\r\n"]
[316.3965, "o", "\u001b[?2004h> pat = re.compile(r\"(\\n\\s*)if is_bool_dtype\\(key\\):\\n[\\s\\S]*?\\n\\s*else:\\n\\s*key = np.asarray\\(key\\)\\n\")\r\n"]
[316.435125, "o", "\u001b[?2004l\r\n"]
[316.47375, "o", "\u001b[?2004h> indentm = re.search(r\"\\n(\\s*)if is_bool_dtype\\(key\\):\\n\", block)\r\n"]
[316.512375, "o", "\u001b[?2004l\r\n"]
[316.551, "o", "\u001b[?2004h> if not indentm:\r\n"]
[316.589625, "o", "\u001b[?2004l\r\n"]
[316.62825, "o", "\u001b[?2004h>     raise SystemExit('Could not locate boolean mask inner block')\r\n"]
[316.666875, "o", "\u001b[?2004l\r\n"]
[316.7055, "o", "\u001b[?2004h> indent = indentm.group(1)\r\n"]
[316.744125, "o", "\u001b[?2004l\r\n"]
[316.78275, "o", "\u001b[?2004h> new_inner = (\r\n"]
[316.821375, "o", "\u001b[?2004l\r\n"]
[316.86, "o", "\u001b[?2004h>     f\"\\n{indent}if is_bool_dtype(key):\\n\"\r\n"]
[316.898625, "o", "\u001b[?2004l\r\n"]
[316.93725, "o", "\u001b[?2004h>     f\"{indent}    if isna(key.fill_value):\\n\"\r\n"]
[316.975875, "o", "\u001b[?2004l\r\n"]
[317.0145, "o", "\u001b[?2004h>     f\"{indent}        return self.take(key.sp_index.indices[key.sp_values])\\n\"\r\n"]
[317.053125, "o", "\u001b[?2004l\r\n"]
[317.09175, "o", "\u001b[?2004h>     f\"{indent}    if not key.fill_value:\\n\"\r\n"]
[317.130375, "o", "\u001b[?2004l\r\n"]
[317.169, "o", "\u001b[?2004h>     f\"{indent}        return self.take(key.sp_index.indices)\\n\"\r\n"]
[317.207625, "o", "\u001b[?2004l\r\n"]
[317.24625, "o", "\u001b[?2004h>     f\"{indent}    # fill_value is True: compute complement indices without dense mask\\n\"\r\n"]
[317.284875, "o", "\u001b[?2004l\r\n"]
[317.3235, "o", "\u001b[?2004h>     f\"{indent}    n = len(self)\\n\"\r\n"]
[317.362125, "o", "\u001b[?2004l\r\n"]
[317.40075, "o", "\u001b[?2004h>     f\"{indent}    neg_idx = key.sp_index.indices\\n\"\r\n"]
[317.439375, "o", "\u001b[?2004l\r\n"]
[317.478, "o", "\u001b[?2004h>     f\"{indent}    if neg_idx.size == 0:\\n\"\r\n"]
[317.516625, "o", "\u001b[?2004l\r\n"]
[317.55525, "o", "\u001b[?2004h>     f\"{indent}        return self.take(np.arange(n, dtype=np.int32))\\n\"\r\n"]
[317.593875, "o", "\u001b[?2004l\r\n"]
[317.6325, "o", "\u001b[?2004h>     f\"{indent}    out_len = n - int(neg_idx.size)\\n\"\r\n"]
[317.671125, "o", "\u001b[?2004l\r\n"]
[317.70975, "o", "\u001b[?2004h>     f\"{indent}    out = np.empty(out_len, dtype=np.int32)\\n\"\r\n"]
[317.748375, "o", "\u001b[?2004l\r\n"]
[317.787, "o", "\u001b[?2004h>     f\"{indent}    pos = 0\\n\"\r\n"]
[317.825625, "o", "\u001b[?2004l\r\n"]
[317.86425, "o", "\u001b[?2004h>     f\"{indent}    start = 0\\n\"\r\n"]
[317.902875, "o", "\u001b[?2004l\r\n"]
[317.9415, "o", "\u001b[?2004h>     f\"{indent}    for idx in neg_idx:\\n\"\r\n"]
[317.980125, "o", "\u001b[?2004l\r\n"]
[318.01875, "o", "\u001b[?2004h>     f\"{indent}        if idx > start:\\n\"\r\n"]
[318.057375, "o", "\u001b[?2004l\r\n"]
[318.096, "o", "\u001b[?2004h>     f\"{indent}            seg = np.arange(start, idx, dtype=np.int32)\\n\"\r\n"]
[318.134625, "o", "\u001b[?2004l\r\n"]
[318.17325, "o", "\u001b[?2004h>     f\"{indent}            L = seg.size\\n\"\r\n"]
[318.211875, "o", "\u001b[?2004l\r\n"]
[318.2505, "o", "\u001b[?2004h>     f\"{indent}            out[pos:pos+L] = seg\\n\"\r\n"]
[318.289125, "o", "\u001b[?2004l\r\n"]
[318.32775, "o", "\u001b[?2004h>     f\"{indent}            pos += L\\n\"\r\n"]
[318.366375, "o", "\u001b[?2004l\r\n"]
[318.405, "o", "\u001b[?2004h>     f\"{indent}        start = int(idx) + 1\\n\"\r\n"]
[318.443625, "o", "\u001b[?2004l\r\n"]
[318.48225, "o", "\u001b[?2004h>     f\"{indent}    if start < n:\\n\"\r\n"]
[318.520875, "o", "\u001b[?2004l\r\n"]
[318.5595, "o", "\u001b[?2004h>     f\"{indent}        seg = np.arange(start, n, dtype=np.int32)\\n\"\r\n"]
[318.598125, "o", "\u001b[?2004l\r\n"]
[318.63675, "o", "\u001b[?2004h>     f\"{indent}        L = seg.size\\n\"\r\n"]
[318.675375, "o", "\u001b[?2004l\r\n"]
[318.714, "o", "\u001b[?2004h>     f\"{indent}        out[pos:pos+L] = seg\\n\"\r\n"]
[318.752625, "o", "\u001b[?2004l\r\n"]
[318.79125, "o", "\u001b[?2004h>     f\"{indent}    return self.take(out)\\n\"\r\n"]
[318.829875, "o", "\u001b[?2004l\r\n"]
[318.8685, "o", "\u001b[?2004h>     f\"{indent}else:\\n\"\r\n"]
[318.907125, "o", "\u001b[?2004l\r\n"]
[318.94575, "o", "\u001b[?2004h>     f\"{indent}    key = np.asarray(key)\\n\"\r\n"]
[318.984375, "o", "\u001b[?2004l\r\n"]
[319.023, "o", "\u001b[?2004h> )\r\n"]
[319.061625, "o", "\u001b[?2004l\r\n"]
[319.10025, "o", "\u001b[?2004h> new_block, nsub = pat.subn(new_inner, block)\r\n"]
[319.138875, "o", "\u001b[?2004l\r\n"]
[319.1775, "o", "\u001b[?2004h> if nsub == 0:\r\n"]
[319.216125, "o", "\u001b[?2004l\r\n"]
[319.25475, "o", "\u001b[?2004h>     raise SystemExit('Boolean mask block pattern not replaced')\r\n"]
[319.293375, "o", "\u001b[?2004l\r\n"]
[319.332, "o", "\u001b[?2004h> new_s = s[:start] + new_block + s[end:]\r\n"]
[319.370625, "o", "\u001b[?2004l\r\n"]
[319.40925, "o", "\u001b[?2004h> p.write_text(new_s, encoding='utf-8')\r\n"]
[319.447875, "o", "\u001b[?2004l\r\n"]
[319.4865, "o", "\u001b[?2004h> print('Patched boolean mask block with correct indentation')\r\n"]
[319.525125, "o", "\u001b[?2004l\r\n"]
[319.56375, "o", "\u001b[?2004h> PY\r\n"]
[319.602375, "o", "\u001b[?2004l\r\n"]
[319.641, "o", "Traceback (most recent call last):\r\n"]
[319.679625, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[319.71825, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1236, in read_text\r\n"]
[319.756875, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[319.7955, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1222, in open\r\n"]
[319.834125, "o", "    return io.open(self, mode, buffering, encoding, errors, newline,\r\n"]
[319.87275, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1078, in _opener\r\n"]
[319.911375, "o", "    return self._accessor.open(self, flags, mode)\r\n"]
[320.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[320.002, "i", "python - << 'PY'\r"]
[320.004, "o", "python - << 'PY'\r\n"]
[320.176483, "o", "\u001b[?2004l\r\n"]
[320.346966, "o", "\u001b[?2004h> # Quick syntax/import sanity check\r\n"]
[320.517448, "o", "\u001b[?2004l\r\n"]
[320.687931, "o", "\u001b[?2004h> import importlib, sys\r\n"]
[320.858414, "o", "\u001b[?2004l\r\n"]
[321.028897, "o", "\u001b[?2004h> sys.path.insert(0, str(__import__('pathlib').Path('pandas')))\r\n"]
[321.199379, "o", "\u001b[?2004l\r\n"]
[321.369862, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[321.540345, "o", "\u001b[?2004l\r\n"]
[321.710828, "o", "\u001b[?2004h> print('Imported pandas ok; version', pd.__version__)\r\n"]
[321.88131, "o", "\u001b[?2004l\r\n"]
[322.051793, "o", "\u001b[?2004h> PY\r\n"]
[322.222276, "o", "\u001b[?2004l\r\n"]
[322.392759, "o", "Traceback (most recent call last):\r\n"]
[322.563241, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[322.733724, "o", "  File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[322.904207, "o", "    from pandas.core.api import (\r\n"]
[323.07469, "o", "  File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[323.245172, "o", "    from pandas.core.arrays import Categorical\r\n"]
[323.415655, "o", "  File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 19, in <module>\r\n"]
[323.586138, "o", "    from pandas.core.arrays.sparse import SparseArray\r\n"]
[323.756621, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/__init__.py\", line 1, in <module>\r\n"]
[323.927103, "o", "    from pandas.core.arrays.sparse.accessor import (\r\n"]
[324.097586, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/accessor.py\", line 16, in <module>\r\n"]
[324.268069, "o", "    from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[324.438552, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 975\r\n"]
[324.609034, "o", "    if isna(key.fill_value):\r\n"]
[324.779517, "o", "    ^\r\n"]
[325.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[325.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r"]
[325.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r\n"]
[327.478, "o", "\u001b[?2004l\r\n"]
[330.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[330.002, "i", "cd asv_bench\r"]
[330.004, "o", "cd asv_bench\r\n"]
[332.478, "o", "\u001b[?2004l\r\n"]
[335.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[335.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[335.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[335.109, "o", "\u001b[?2004l\r\n"]
[335.212, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[335.315, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpc0w7cdif/result.json (exit status 1)\u001b[0m\r\n"]
[335.418, "o", "   STDOUT -------->\r\n"]
[335.521, "o", "   \r\n"]
[335.624, "o", "   STDERR -------->\r\n"]
[335.727, "o", "   Traceback (most recent call last):\r\n"]
[335.83, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[335.933, "o", "       main()\r\n"]
[336.036, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[336.139, "o", "       commands[mode](args)\r\n"]
[336.242, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[336.345, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[336.448, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[336.551, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[336.654, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[336.757, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[336.86, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[336.963, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[337.066, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[337.169, "o", "       module = importlib.import_module(module_name)\r\n"]
[337.272, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n"]
[337.375, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[337.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n"]
[337.581, "o", "     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n"]
[337.684, "o", "     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n"]
[337.787, "o", "     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n"]
[337.89, "o", "     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n"]
[337.993, "o", "     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n"]
[338.096, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[338.199, "o", "       import pandas as pd\r\n"]
[338.302, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[338.405, "o", "       from pandas.core.api import (\r\n"]
[338.508, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[338.611, "o", "       from pandas.core.arrays import Categorical\r\n"]
[338.714, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 19, in <module>\r\n"]
[338.817, "o", "       from pandas.core.arrays.sparse import SparseArray\r\n"]
[338.92, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/__init__.py\", line 1, in <module>\r\n"]
[339.023, "o", "       from pandas.core.arrays.sparse.accessor import (\r\n"]
[339.126, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/accessor.py\", line 16, in <module>\r\n"]
[339.229, "o", "       from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[339.332, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 975\r\n"]
[339.435, "o", "       if isna(key.fill_value):\r\n"]
[339.538, "o", "       ^\r\n"]
[339.641, "o", "   IndentationError: expected an indented block\r\n"]
[339.744, "o", "\r\n"]
[339.847, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpc0w7cdif/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[340.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[340.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r"]
[340.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r\n"]
[342.478, "o", "\u001b[?2004l\r\n"]
[345.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[345.002, "i", "python - << 'PY'\r"]
[345.004, "o", "python - << 'PY'\r\n"]
[345.044625, "o", "\u001b[?2004l\r\n"]
[345.08325, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[345.121875, "o", "\u001b[?2004l\r\n"]
[345.1605, "o", "\u001b[?2004h> import re\r\n"]
[345.199125, "o", "\u001b[?2004l\r\n"]
[345.23775, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[345.276375, "o", "\u001b[?2004l\r\n"]
[345.315, "o", "\u001b[?2004h> s = p.read_text(encoding='utf-8')\r\n"]
[345.353625, "o", "\u001b[?2004l\r\n"]
[345.39225, "o", "\u001b[?2004h> # Find the if isinstance(key, SparseArray) block boundaries\r\n"]
[345.430875, "o", "\u001b[?2004l\r\n"]
[345.4695, "o", "\u001b[?2004h> m0 = re.search(r\"\\n(\\s*)if isinstance\\(key, SparseArray\\):\\n\", s)\r\n"]
[345.508125, "o", "\u001b[?2004l\r\n"]
[345.54675, "o", "\u001b[?2004h> if not m0:\r\n"]
[345.585375, "o", "\u001b[?2004l\r\n"]
[345.624, "o", "\u001b[?2004h>     raise SystemExit('Could not locate SparseArray key block start')\r\n"]
[345.662625, "o", "\u001b[?2004l\r\n"]
[345.70125, "o", "\u001b[?2004h> indent0 = m0.group(1)\r\n"]
[345.739875, "o", "\u001b[?2004l\r\n"]
[345.7785, "o", "\u001b[?2004h> start = m0.end()\r\n"]
[345.817125, "o", "\u001b[?2004l\r\n"]
[345.85575, "o", "\u001b[?2004h> endm = re.search(r\"\\n\\s*key = check_array_indexer\\(self, key\\)\", s[start:])\r\n"]
[345.894375, "o", "\u001b[?2004l\r\n"]
[345.933, "o", "\u001b[?2004h> if not endm:\r\n"]
[345.971625, "o", "\u001b[?2004l\r\n"]
[346.01025, "o", "\u001b[?2004h>     raise SystemExit('Could not locate end of SparseArray key block')\r\n"]
[346.048875, "o", "\u001b[?2004l\r\n"]
[346.0875, "o", "\u001b[?2004h> end = start + endm.start()\r\n"]
[346.126125, "o", "\u001b[?2004l\r\n"]
[346.16475, "o", "\u001b[?2004h> block = s[start:end]\r\n"]
[346.203375, "o", "\u001b[?2004l\r\n"]
[346.242, "o", "\u001b[?2004h> # Build a fresh, correctly-indented inner block content\r\n"]
[346.280625, "o", "\u001b[?2004l\r\n"]
[346.31925, "o", "\u001b[?2004h> inner = (\r\n"]
[346.357875, "o", "\u001b[?2004l\r\n"]
[346.3965, "o", "\u001b[?2004h>     f\"{indent0}    if is_bool_dtype(key):\\n\"\r\n"]
[346.435125, "o", "\u001b[?2004l\r\n"]
[346.47375, "o", "\u001b[?2004h>     f\"{indent0}        if isna(key.fill_value):\\n\"\r\n"]
[346.512375, "o", "\u001b[?2004l\r\n"]
[346.551, "o", "\u001b[?2004h>     f\"{indent0}            return self.take(key.sp_index.indices[key.sp_values])\\n\"\r\n"]
[346.589625, "o", "\u001b[?2004l\r\n"]
[346.62825, "o", "\u001b[?2004h>     f\"{indent0}        if not key.fill_value:\\n\"\r\n"]
[346.666875, "o", "\u001b[?2004l\r\n"]
[346.7055, "o", "\u001b[?2004h>     f\"{indent0}            return self.take(key.sp_index.indices)\\n\"\r\n"]
[346.744125, "o", "\u001b[?2004l\r\n"]
[346.78275, "o", "\u001b[?2004h>     f\"{indent0}        # fill_value is True: compute complement indices without dense mask\\n\"\r\n"]
[346.821375, "o", "\u001b[?2004l\r\n"]
[346.86, "o", "\u001b[?2004h>     f\"{indent0}        n = len(self)\\n\"\r\n"]
[346.898625, "o", "\u001b[?2004l\r\n"]
[346.93725, "o", "\u001b[?2004h>     f\"{indent0}        neg_idx = key.sp_index.indices\\n\"\r\n"]
[346.975875, "o", "\u001b[?2004l\r\n"]
[347.0145, "o", "\u001b[?2004h>     f\"{indent0}        if neg_idx.size == 0:\\n\"\r\n"]
[347.053125, "o", "\u001b[?2004l\r\n"]
[347.09175, "o", "\u001b[?2004h>     f\"{indent0}            return self.take(np.arange(n, dtype=np.int32))\\n\"\r\n"]
[347.130375, "o", "\u001b[?2004l\r\n"]
[347.169, "o", "\u001b[?2004h>     f\"{indent0}        out_len = n - int(neg_idx.size)\\n\"\r\n"]
[347.207625, "o", "\u001b[?2004l\r\n"]
[347.24625, "o", "\u001b[?2004h>     f\"{indent0}        out = np.empty(out_len, dtype=np.int32)\\n\"\r\n"]
[347.284875, "o", "\u001b[?2004l\r\n"]
[347.3235, "o", "\u001b[?2004h>     f\"{indent0}        pos = 0\\n\"\r\n"]
[347.362125, "o", "\u001b[?2004l\r\n"]
[347.40075, "o", "\u001b[?2004h>     f\"{indent0}        start_i = 0\\n\"\r\n"]
[347.439375, "o", "\u001b[?2004l\r\n"]
[347.478, "o", "\u001b[?2004h>     f\"{indent0}        for idx in neg_idx:\\n\"\r\n"]
[347.516625, "o", "\u001b[?2004l\r\n"]
[347.55525, "o", "\u001b[?2004h>     f\"{indent0}            if idx > start_i:\\n\"\r\n"]
[347.593875, "o", "\u001b[?2004l\r\n"]
[347.6325, "o", "\u001b[?2004h>     f\"{indent0}                seg = np.arange(start_i, idx, dtype=np.int32)\\n\"\r\n"]
[347.671125, "o", "\u001b[?2004l\r\n"]
[347.70975, "o", "\u001b[?2004h>     f\"{indent0}                L = seg.size\\n\"\r\n"]
[347.748375, "o", "\u001b[?2004l\r\n"]
[347.787, "o", "\u001b[?2004h>     f\"{indent0}                out[pos:pos+L] = seg\\n\"\r\n"]
[347.825625, "o", "\u001b[?2004l\r\n"]
[347.86425, "o", "\u001b[?2004h>     f\"{indent0}                pos += L\\n\"\r\n"]
[347.902875, "o", "\u001b[?2004l\r\n"]
[347.9415, "o", "\u001b[?2004h>     f\"{indent0}            start_i = int(idx) + 1\\n\"\r\n"]
[347.980125, "o", "\u001b[?2004l\r\n"]
[348.01875, "o", "\u001b[?2004h>     f\"{indent0}        if start_i < n:\\n\"\r\n"]
[348.057375, "o", "\u001b[?2004l\r\n"]
[348.096, "o", "\u001b[?2004h>     f\"{indent0}            seg = np.arange(start_i, n, dtype=np.int32)\\n\"\r\n"]
[348.134625, "o", "\u001b[?2004l\r\n"]
[348.17325, "o", "\u001b[?2004h>     f\"{indent0}            L = seg.size\\n\"\r\n"]
[348.211875, "o", "\u001b[?2004l\r\n"]
[348.2505, "o", "\u001b[?2004h>     f\"{indent0}            out[pos:pos+L] = seg\\n\"\r\n"]
[348.289125, "o", "\u001b[?2004l\r\n"]
[348.32775, "o", "\u001b[?2004h>     f\"{indent0}        return self.take(out)\\n\"\r\n"]
[348.366375, "o", "\u001b[?2004l\r\n"]
[348.405, "o", "\u001b[?2004h>     f\"{indent0}    else:\\n\"\r\n"]
[348.443625, "o", "\u001b[?2004l\r\n"]
[348.48225, "o", "\u001b[?2004h>     f\"{indent0}        key = np.asarray(key)\\n\"\r\n"]
[348.520875, "o", "\u001b[?2004l\r\n"]
[348.5595, "o", "\u001b[?2004h> )\r\n"]
[348.598125, "o", "\u001b[?2004l\r\n"]
[348.63675, "o", "\u001b[?2004h> # Replace the whole inner if-block content between 'if isinstance(key, SparseArray):' and before 'key = check_array_indexer'\r\n"]
[348.675375, "o", "\u001b[?2004l\r\n"]
[348.714, "o", "\u001b[?2004h> # by reconstructing from the start of that block: keep the opening line and then our inner\r\n"]
[348.752625, "o", "\u001b[?2004l\r\n"]
[348.79125, "o", "\u001b[?2004h> new_block = re.sub(r\"\\A(\\s*)if is_bool_dtype\\(key\\):[\\s\\S]*?\\n\\s*else:\\n\\s*key = np.asarray\\(key\\)\\n\",\r\n"]
[348.829875, "o", "\u001b[?2004l\r\n"]
[348.8685, "o", "\u001b[?2004h>                    inner, block, count=1)\r\n"]
[348.907125, "o", "\u001b[?2004l\r\n"]
[348.94575, "o", "\u001b[?2004h> if new_block == block:\r\n"]
[348.984375, "o", "\u001b[?2004l\r\n"]
[349.023, "o", "\u001b[?2004h>     # As fallback, construct the full 'if isinstance(key, SparseArray):' section explicitly\r\n"]
[349.061625, "o", "\u001b[?2004l\r\n"]
[349.10025, "o", "\u001b[?2004h>     new_block = (\r\n"]
[349.138875, "o", "\u001b[?2004l\r\n"]
[349.1775, "o", "\u001b[?2004h>         f\"{indent0}if is_bool_dtype(key):\\n\" + inner[len(indent0)+4:])\r\n"]
[349.216125, "o", "\u001b[?2004l\r\n"]
[349.25475, "o", "\u001b[?2004h> # Stitch back\r\n"]
[349.293375, "o", "\u001b[?2004l\r\n"]
[349.332, "o", "\u001b[?2004h> new_s = s[:start] + new_block + s[end:]\r\n"]
[349.370625, "o", "\u001b[?2004l\r\n"]
[349.40925, "o", "\u001b[?2004h> p.write_text(new_s, encoding='utf-8')\r\n"]
[349.447875, "o", "\u001b[?2004l\r\n"]
[349.4865, "o", "\u001b[?2004h> print('Rebuilt boolean-mask inner block with corrected indentation')\r\n"]
[349.525125, "o", "\u001b[?2004l\r\n"]
[349.56375, "o", "\u001b[?2004h> PY\r\n"]
[349.602375, "o", "\u001b[?2004l\r\n"]
[349.641, "o", "Traceback (most recent call last):\r\n"]
[349.679625, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[349.71825, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1236, in read_text\r\n"]
[349.756875, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[349.7955, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1222, in open\r\n"]
[349.834125, "o", "    return io.open(self, mode, buffering, encoding, errors, newline,\r\n"]
[349.87275, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1078, in _opener\r\n"]
[349.911375, "o", "    return self._accessor.open(self, flags, mode)\r\n"]
[350.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[350.002, "i", "python - << 'PY'\r"]
[350.004, "o", "python - << 'PY'\r\n"]
[350.139622, "o", "\u001b[?2004l\r\n"]
[350.273243, "o", "\u001b[?2004h> # Quick syntax/import sanity check\r\n"]
[350.406865, "o", "\u001b[?2004l\r\n"]
[350.540486, "o", "\u001b[?2004h> import importlib, sys\r\n"]
[350.674108, "o", "\u001b[?2004l\r\n"]
[350.80773, "o", "\u001b[?2004h> sys.path.insert(0, str(__import__('pathlib').Path('pandas')))\r\n"]
[350.941351, "o", "\u001b[?2004l\r\n"]
[351.074973, "o", "\u001b[?2004h> try:\r\n"]
[351.208595, "o", "\u001b[?2004l\r\n"]
[351.342216, "o", "\u001b[?2004h>     import pandas as pd\r\n"]
[351.475838, "o", "\u001b[?2004l\r\n"]
[351.609459, "o", "\u001b[?2004h>     print('Imported pandas ok; version', pd.__version__)\r\n"]
[351.743081, "o", "\u001b[?2004l\r\n"]
[351.876703, "o", "\u001b[?2004h> except Exception as e:\r\n"]
[352.010324, "o", "\u001b[?2004l\r\n"]
[352.143946, "o", "\u001b[?2004h>     import traceback; traceback.print_exc()\r\n"]
[352.277568, "o", "\u001b[?2004l\r\n"]
[352.411189, "o", "\u001b[?2004h>     raise SystemExit(1)\r\n"]
[352.544811, "o", "\u001b[?2004l\r\n"]
[352.678432, "o", "\u001b[?2004h> PY\r\n"]
[352.812054, "o", "\u001b[?2004l\r\n"]
[352.945676, "o", "Traceback (most recent call last):\r\n"]
[353.079297, "o", "  File \"<stdin>\", line 5, in <module>\r\n"]
[353.212919, "o", "  File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[353.346541, "o", "    from pandas.core.api import (\r\n"]
[353.480162, "o", "  File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[353.613784, "o", "    from pandas.core.arrays import Categorical\r\n"]
[353.747405, "o", "  File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 19, in <module>\r\n"]
[353.881027, "o", "    from pandas.core.arrays.sparse import SparseArray\r\n"]
[354.014649, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/__init__.py\", line 1, in <module>\r\n"]
[354.14827, "o", "    from pandas.core.arrays.sparse.accessor import (\r\n"]
[354.281892, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/accessor.py\", line 16, in <module>\r\n"]
[354.415514, "o", "    from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[354.549135, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 975\r\n"]
[354.682757, "o", "    if isna(key.fill_value):\r\n"]
[354.816378, "o", "    ^\r\n"]
[355.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[355.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r"]
[355.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r\n"]
[357.478, "o", "\u001b[?2004l\r\n"]
[360.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[360.002, "i", "cd asv_bench\r"]
[360.004, "o", "cd asv_bench\r\n"]
[362.478, "o", "\u001b[?2004l\r\n"]
[365.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[365.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[365.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[365.109, "o", "\u001b[?2004l\r\n"]
[365.212, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[365.315, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp83x1io8v/result.json (exit status 1)\u001b[0m\r\n"]
[365.418, "o", "   STDOUT -------->\r\n"]
[365.521, "o", "   \r\n"]
[365.624, "o", "   STDERR -------->\r\n"]
[365.727, "o", "   Traceback (most recent call last):\r\n"]
[365.83, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[365.933, "o", "       main()\r\n"]
[366.036, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[366.139, "o", "       commands[mode](args)\r\n"]
[366.242, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[366.345, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[366.448, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[366.551, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[366.654, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[366.757, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[366.86, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[366.963, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[367.066, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[367.169, "o", "       module = importlib.import_module(module_name)\r\n"]
[367.272, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n"]
[367.375, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[367.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n"]
[367.581, "o", "     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n"]
[367.684, "o", "     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n"]
[367.787, "o", "     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n"]
[367.89, "o", "     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n"]
[367.993, "o", "     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n"]
[368.096, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[368.199, "o", "       import pandas as pd\r\n"]
[368.302, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[368.405, "o", "       from pandas.core.api import (\r\n"]
[368.508, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[368.611, "o", "       from pandas.core.arrays import Categorical\r\n"]
[368.714, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 19, in <module>\r\n"]
[368.817, "o", "       from pandas.core.arrays.sparse import SparseArray\r\n"]
[368.92, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/__init__.py\", line 1, in <module>\r\n"]
[369.023, "o", "       from pandas.core.arrays.sparse.accessor import (\r\n"]
[369.126, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/accessor.py\", line 16, in <module>\r\n"]
[369.229, "o", "       from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[369.332, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 975\r\n"]
[369.435, "o", "       if isna(key.fill_value):\r\n"]
[369.538, "o", "       ^\r\n"]
[369.641, "o", "   IndentationError: expected an indented block\r\n"]
[369.744, "o", "\r\n"]
[369.847, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp83x1io8v/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[370.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[370.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r"]
[370.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r\n"]
[372.478, "o", "\u001b[?2004l\r\n"]
[375.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[375.002, "i", "python - << 'PY'\r"]
[375.004, "o", "python - << 'PY'\r\n"]
[375.053538, "o", "\u001b[?2004l\r\n"]
[375.101077, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[375.148615, "o", "\u001b[?2004l\r\n"]
[375.196154, "o", "\u001b[?2004h> import re\r\n"]
[375.243692, "o", "\u001b[?2004l\r\n"]
[375.291231, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[375.338769, "o", "\u001b[?2004l\r\n"]
[375.386308, "o", "\u001b[?2004h> s = p.read_text(encoding='utf-8')\r\n"]
[375.433846, "o", "\u001b[?2004l\r\n"]
[375.481385, "o", "\u001b[?2004h> # Locate 'if isinstance(key, SparseArray):' block\r\n"]
[375.528923, "o", "\u001b[?2004l\r\n"]
[375.576462, "o", "\u001b[?2004h> m0 = re.search(r\"\\n(\\s*)if isinstance\\(key, SparseArray\\):\\n\", s)\r\n"]
[375.624, "o", "\u001b[?2004l\r\n"]
[375.671538, "o", "\u001b[?2004h> assert m0, 'start not found'\r\n"]
[375.719077, "o", "\u001b[?2004l\r\n"]
[375.766615, "o", "\u001b[?2004h> indent0 = m0.group(1)\r\n"]
[375.814154, "o", "\u001b[?2004l\r\n"]
[375.861692, "o", "\u001b[?2004h> start = m0.end()\r\n"]
[375.909231, "o", "\u001b[?2004l\r\n"]
[375.956769, "o", "\u001b[?2004h> endm = re.search(r\"\\n\\s*key = check_array_indexer\\(self, key\\)\", s[start:])\r\n"]
[376.004308, "o", "\u001b[?2004l\r\n"]
[376.051846, "o", "\u001b[?2004h> assert endm, 'end not found'\r\n"]
[376.099385, "o", "\u001b[?2004l\r\n"]
[376.146923, "o", "\u001b[?2004h> end = start + endm.start()\r\n"]
[376.194462, "o", "\u001b[?2004l\r\n"]
[376.242, "o", "\u001b[?2004h> # Build a clean, fully defined inner block\r\n"]
[376.289538, "o", "\u001b[?2004l\r\n"]
[376.337077, "o", "\u001b[?2004h> inner = (\r\n"]
[376.384615, "o", "\u001b[?2004l\r\n"]
[376.432154, "o", "\u001b[?2004h>     f\"{indent0}    if is_bool_dtype(key):\\n\"\r\n"]
[376.479692, "o", "\u001b[?2004l\r\n"]
[376.527231, "o", "\u001b[?2004h>     f\"{indent0}        if isna(key.fill_value):\\n\"\r\n"]
[376.574769, "o", "\u001b[?2004l\r\n"]
[376.622308, "o", "\u001b[?2004h>     f\"{indent0}            return self.take(key.sp_index.indices[key.sp_values])\\n\"\r\n"]
[376.669846, "o", "\u001b[?2004l\r\n"]
[376.717385, "o", "\u001b[?2004h>     f\"{indent0}        if not key.fill_value:\\n\"\r\n"]
[376.764923, "o", "\u001b[?2004l\r\n"]
[376.812462, "o", "\u001b[?2004h>     f\"{indent0}            return self.take(key.sp_index.indices)\\n\"\r\n"]
[376.86, "o", "\u001b[?2004l\r\n"]
[376.907538, "o", "\u001b[?2004h>     f\"{indent0}        # fill_value is True: compute complement indices without dense mask\\n\"\r\n"]
[376.955077, "o", "\u001b[?2004l\r\n"]
[377.002615, "o", "\u001b[?2004h>     f\"{indent0}        n = len(self)\\n\"\r\n"]
[377.050154, "o", "\u001b[?2004l\r\n"]
[377.097692, "o", "\u001b[?2004h>     f\"{indent0}        neg_idx = key.sp_index.indices\\n\"\r\n"]
[377.145231, "o", "\u001b[?2004l\r\n"]
[377.192769, "o", "\u001b[?2004h>     f\"{indent0}        if neg_idx.size == 0:\\n\"\r\n"]
[377.240308, "o", "\u001b[?2004l\r\n"]
[377.287846, "o", "\u001b[?2004h>     f\"{indent0}            return self.take(np.arange(n, dtype=np.int32))\\n\"\r\n"]
[377.335385, "o", "\u001b[?2004l\r\n"]
[377.382923, "o", "\u001b[?2004h>     f\"{indent0}        out_len = n - int(neg_idx.size)\\n\"\r\n"]
[377.430462, "o", "\u001b[?2004l\r\n"]
[377.478, "o", "\u001b[?2004h>     f\"{indent0}        out = np.empty(out_len, dtype=np.int32)\\n\"\r\n"]
[377.525538, "o", "\u001b[?2004l\r\n"]
[377.573077, "o", "\u001b[?2004h>     f\"{indent0}        pos = 0\\n\"\r\n"]
[377.620615, "o", "\u001b[?2004l\r\n"]
[377.668154, "o", "\u001b[?2004h>     f\"{indent0}        start_i = 0\\n\"\r\n"]
[377.715692, "o", "\u001b[?2004l\r\n"]
[377.763231, "o", "\u001b[?2004h>     f\"{indent0}        for idx in neg_idx:\\n\"\r\n"]
[377.810769, "o", "\u001b[?2004l\r\n"]
[377.858308, "o", "\u001b[?2004h>     f\"{indent0}            if idx > start_i:\\n\"\r\n"]
[377.905846, "o", "\u001b[?2004l\r\n"]
[377.953385, "o", "\u001b[?2004h>     f\"{indent0}                seg = np.arange(start_i, idx, dtype=np.int32)\\n\"\r\n"]
[378.000923, "o", "\u001b[?2004l\r\n"]
[378.048462, "o", "\u001b[?2004h>     f\"{indent0}                L = seg.size\\n\"\r\n"]
[378.096, "o", "\u001b[?2004l\r\n"]
[378.143538, "o", "\u001b[?2004h>     f\"{indent0}                out[pos:pos+L] = seg\\n\"\r\n"]
[378.191077, "o", "\u001b[?2004l\r\n"]
[378.238615, "o", "\u001b[?2004h>     f\"{indent0}                pos += L\\n\"\r\n"]
[378.286154, "o", "\u001b[?2004l\r\n"]
[378.333692, "o", "\u001b[?2004h>     f\"{indent0}            start_i = int(idx) + 1\\n\"\r\n"]
[378.381231, "o", "\u001b[?2004l\r\n"]
[378.428769, "o", "\u001b[?2004h>     f\"{indent0}        if start_i < n:\\n\"\r\n"]
[378.476308, "o", "\u001b[?2004l\r\n"]
[378.523846, "o", "\u001b[?2004h>     f\"{indent0}            seg = np.arange(start_i, n, dtype=np.int32)\\n\"\r\n"]
[378.571385, "o", "\u001b[?2004l\r\n"]
[378.618923, "o", "\u001b[?2004h>     f\"{indent0}            L = seg.size\\n\"\r\n"]
[378.666462, "o", "\u001b[?2004l\r\n"]
[378.714, "o", "\u001b[?2004h>     f\"{indent0}            out[pos:pos+L] = seg\\n\"\r\n"]
[378.761538, "o", "\u001b[?2004l\r\n"]
[378.809077, "o", "\u001b[?2004h>     f\"{indent0}        return self.take(out)\\n\"\r\n"]
[378.856615, "o", "\u001b[?2004l\r\n"]
[378.904154, "o", "\u001b[?2004h>     f\"{indent0}    else:\\n\"\r\n"]
[378.951692, "o", "\u001b[?2004l\r\n"]
[378.999231, "o", "\u001b[?2004h>     f\"{indent0}        key = np.asarray(key)\\n\"\r\n"]
[379.046769, "o", "\u001b[?2004l\r\n"]
[379.094308, "o", "\u001b[?2004h> )\r\n"]
[379.141846, "o", "\u001b[?2004l\r\n"]
[379.189385, "o", "\u001b[?2004h> new_s = s[:start] + inner + s[end:]\r\n"]
[379.236923, "o", "\u001b[?2004l\r\n"]
[379.284462, "o", "\u001b[?2004h> p.write_text(new_s, encoding='utf-8')\r\n"]
[379.332, "o", "\u001b[?2004l\r\n"]
[379.379538, "o", "\u001b[?2004h> print('Replaced boolean-mask block with corrected indentation')\r\n"]
[379.427077, "o", "\u001b[?2004l\r\n"]
[379.474615, "o", "\u001b[?2004h> PY\r\n"]
[379.522154, "o", "\u001b[?2004l\r\n"]
[379.569692, "o", "Traceback (most recent call last):\r\n"]
[379.617231, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[379.664769, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1236, in read_text\r\n"]
[379.712308, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[379.759846, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1222, in open\r\n"]
[379.807385, "o", "    return io.open(self, mode, buffering, encoding, errors, newline,\r\n"]
[379.854923, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1078, in _opener\r\n"]
[379.902462, "o", "    return self._accessor.open(self, flags, mode)\r\n"]
[380.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[380.002, "i", "python - << 'PY'\r"]
[380.004, "o", "python - << 'PY'\r\n"]
[380.176483, "o", "\u001b[?2004l\r\n"]
[380.346966, "o", "\u001b[?2004h> # Syntax/import check to ensure no IndentationError\r\n"]
[380.517448, "o", "\u001b[?2004l\r\n"]
[380.687931, "o", "\u001b[?2004h> import sys\r\n"]
[380.858414, "o", "\u001b[?2004l\r\n"]
[381.028897, "o", "\u001b[?2004h> sys.path.insert(0, 'pandas')\r\n"]
[381.199379, "o", "\u001b[?2004l\r\n"]
[381.369862, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[381.540345, "o", "\u001b[?2004l\r\n"]
[381.710828, "o", "\u001b[?2004h> print('Imported pandas ok; version', pd.__version__)\r\n"]
[381.88131, "o", "\u001b[?2004l\r\n"]
[382.051793, "o", "\u001b[?2004h> PY\r\n"]
[382.222276, "o", "\u001b[?2004l\r\n"]
[382.392759, "o", "Traceback (most recent call last):\r\n"]
[382.563241, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[382.733724, "o", "  File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[382.904207, "o", "    from pandas.core.api import (\r\n"]
[383.07469, "o", "  File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[383.245172, "o", "    from pandas.core.arrays import Categorical\r\n"]
[383.415655, "o", "  File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 19, in <module>\r\n"]
[383.586138, "o", "    from pandas.core.arrays.sparse import SparseArray\r\n"]
[383.756621, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/__init__.py\", line 1, in <module>\r\n"]
[383.927103, "o", "    from pandas.core.arrays.sparse.accessor import (\r\n"]
[384.097586, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/accessor.py\", line 16, in <module>\r\n"]
[384.268069, "o", "    from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[384.438552, "o", "  File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 975\r\n"]
[384.609034, "o", "    if isna(key.fill_value):\r\n"]
[384.779517, "o", "    ^\r\n"]
[385.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[385.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r"]
[385.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r\n"]
[387.478, "o", "\u001b[?2004l\r\n"]
[390.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[390.002, "i", "cd asv_bench\r"]
[390.004, "o", "cd asv_bench\r\n"]
[392.478, "o", "\u001b[?2004l\r\n"]
[395.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[395.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[395.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[395.109, "o", "\u001b[?2004l\r\n"]
[395.212, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[395.315, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp4n466xvt/result.json (exit status 1)\u001b[0m\r\n"]
[395.418, "o", "   STDOUT -------->\r\n"]
[395.521, "o", "   \r\n"]
[395.624, "o", "   STDERR -------->\r\n"]
[395.727, "o", "   Traceback (most recent call last):\r\n"]
[395.83, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[395.933, "o", "       main()\r\n"]
[396.036, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[396.139, "o", "       commands[mode](args)\r\n"]
[396.242, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[396.345, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[396.448, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[396.551, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[396.654, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[396.757, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[396.86, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[396.963, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[397.066, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[397.169, "o", "       module = importlib.import_module(module_name)\r\n"]
[397.272, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n"]
[397.375, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[397.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n"]
[397.581, "o", "     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n"]
[397.684, "o", "     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n"]
[397.787, "o", "     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n"]
[397.89, "o", "     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n"]
[397.993, "o", "     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n"]
[398.096, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[398.199, "o", "       import pandas as pd\r\n"]
[398.302, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[398.405, "o", "       from pandas.core.api import (\r\n"]
[398.508, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[398.611, "o", "       from pandas.core.arrays import Categorical\r\n"]
[398.714, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 19, in <module>\r\n"]
[398.817, "o", "       from pandas.core.arrays.sparse import SparseArray\r\n"]
[398.92, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/__init__.py\", line 1, in <module>\r\n"]
[399.023, "o", "       from pandas.core.arrays.sparse.accessor import (\r\n"]
[399.126, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/accessor.py\", line 16, in <module>\r\n"]
[399.229, "o", "       from pandas.core.arrays.sparse.array import SparseArray\r\n"]
[399.332, "o", "     File \"/workspace/repo/pandas/core/arrays/sparse/array.py\", line 975\r\n"]
[399.435, "o", "       if isna(key.fill_value):\r\n"]
[399.538, "o", "       ^\r\n"]
[399.641, "o", "   IndentationError: expected an indented block\r\n"]
[399.744, "o", "\r\n"]
[399.847, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp4n466xvt/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[400.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[400.002, "i", "cd /workspace/repo\r"]
[400.004, "o", "cd /workspace/repo\r\n"]
[400.006, "o", "\u001b[?2004l\r\n"]
[405.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[405.002, "i", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r"]
[405.004, "o", "nl -ba pandas/core/arrays/sparse/array.py | sed -n '960,996p'\r\n"]
[405.136105, "o", "\u001b[?2004l\r\n"]
[405.266211, "o", "   960\t        elif not is_list_like(key):\r\n"]
[405.396316, "o", "   961\t            # e.g. \"foo\" or 2.5\r\n"]
[405.526421, "o", "   962\t            # exception message copied from numpy\r\n"]
[405.656526, "o", "   963\t            raise IndexError(\r\n"]
[405.786632, "o", "   964\t                r\"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis \"\r\n"]
[405.916737, "o", "   965\t                r\"(`None`) and integer or boolean arrays are valid indices\"\r\n"]
[406.046842, "o", "   966\t            )\r\n"]
[406.176947, "o", "   967\t\r\n"]
[406.307053, "o", "   968\t        else:\r\n"]
[406.437158, "o", "   969\t            if isinstance(key, SparseArray):\r\n"]
[406.567263, "o", "   970\t                # NOTE: If we guarantee that SparseDType(bool)\r\n"]
[406.697368, "o", "   971\t                # has only fill_value - true, false or nan\r\n"]
[406.827474, "o", "   972\t                # (see GH PR 44955)\r\n"]
[406.957579, "o", "   973\t                # we can apply mask very fast:\r\n"]
[407.087684, "o", "   974\t                if is_bool_dtype(key):\r\n"]
[407.217789, "o", "   975\t    if isna(key.fill_value):\r\n"]
[407.347895, "o", "   976\t        return self.take(key.sp_index.indices[key.sp_values])\r\n"]
[407.478, "o", "   977\t    if not key.fill_value:\r\n"]
[407.608105, "o", "   978\t        return self.take(key.sp_index.indices)\r\n"]
[407.738211, "o", "   979\t    # fill_value is True: compute complement indices without dense mask\r\n"]
[407.868316, "o", "   980\t    n = len(self)\r\n"]
[407.998421, "o", "   981\t    neg_idx = key.sp_index.indices\r\n"]
[408.128526, "o", "   982\t    if neg_idx.size == 0:\r\n"]
[408.258632, "o", "   983\t        return self.take(np.arange(n, dtype=np.int32))\r\n"]
[408.388737, "o", "   984\t    out_len = n - int(neg_idx.size)\r\n"]
[408.518842, "o", "   985\t    out = np.empty(out_len, dtype=np.int32)\r\n"]
[408.648947, "o", "   986\t    pos = 0\r\n"]
[408.779053, "o", "   987\t    start = 0\r\n"]
[408.909158, "o", "   988\t    for idx in neg_idx:\r\n"]
[409.039263, "o", "   989\t        if idx > start:\r\n"]
[409.169368, "o", "   990\t            seg = np.arange(start, idx, dtype=np.int32)\r\n"]
[409.299474, "o", "   991\t            L = seg.size\r\n"]
[409.429579, "o", "   992\t            out[pos:pos+L] = seg\r\n"]
[409.559684, "o", "   993\t            pos += L\r\n"]
[409.689789, "o", "   994\t        start = int(idx) + 1\r\n"]
[409.819895, "o", "   995\t    if start < n:\r\n"]
[410.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[410.002, "i", "python - << 'PY'\r"]
[410.004, "o", "python - << 'PY'\r\n"]
[410.059739, "o", "\u001b[?2004l\r\n"]
[410.113478, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[410.167217, "o", "\u001b[?2004l\r\n"]
[410.220957, "o", "\u001b[?2004h> import re\r\n"]
[410.274696, "o", "\u001b[?2004l\r\n"]
[410.328435, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[410.382174, "o", "\u001b[?2004l\r\n"]
[410.435913, "o", "\u001b[?2004h> s = p.read_text(encoding='utf-8')\r\n"]
[410.489652, "o", "\u001b[?2004l\r\n"]
[410.543391, "o", "\u001b[?2004h> # Find the block for 'if isinstance(key, SparseArray):'\r\n"]
[410.59713, "o", "\u001b[?2004l\r\n"]
[410.65087, "o", "\u001b[?2004h> m0 = re.search(r\"\\n(\\s*)if isinstance\\(key, SparseArray\\):\\n\", s)\r\n"]
[410.704609, "o", "\u001b[?2004l\r\n"]
[410.758348, "o", "\u001b[?2004h> assert m0, 'start not found'\r\n"]
[410.812087, "o", "\u001b[?2004l\r\n"]
[410.865826, "o", "\u001b[?2004h> indent0 = m0.group(1)\r\n"]
[410.919565, "o", "\u001b[?2004l\r\n"]
[410.973304, "o", "\u001b[?2004h> start = m0.end()\r\n"]
[411.027043, "o", "\u001b[?2004l\r\n"]
[411.080783, "o", "\u001b[?2004h> endm = re.search(r\"\\n\\s*key = check_array_indexer\\(self, key\\)\", s[start:])\r\n"]
[411.134522, "o", "\u001b[?2004l\r\n"]
[411.188261, "o", "\u001b[?2004h> assert endm, 'end not found'\r\n"]
[411.242, "o", "\u001b[?2004l\r\n"]
[411.295739, "o", "\u001b[?2004h> end = start + endm.start()\r\n"]
[411.349478, "o", "\u001b[?2004l\r\n"]
[411.403217, "o", "\u001b[?2004h> # Construct a clean, correctly indented inner block\r\n"]
[411.456957, "o", "\u001b[?2004l\r\n"]
[411.510696, "o", "\u001b[?2004h> indent1 = indent0 + '    '\r\n"]
[411.564435, "o", "\u001b[?2004l\r\n"]
[411.618174, "o", "\u001b[?2004h> inner = (\r\n"]
[411.671913, "o", "\u001b[?2004l\r\n"]
[411.725652, "o", "\u001b[?2004h>     f\"{indent1}if is_bool_dtype(key):\\n\"\r\n"]
[411.779391, "o", "\u001b[?2004l\r\n"]
[411.83313, "o", "\u001b[?2004h>     f\"{indent1}    if isna(key.fill_value):\\n\"\r\n"]
[411.88687, "o", "\u001b[?2004l\r\n"]
[411.940609, "o", "\u001b[?2004h>     f\"{indent1}        return self.take(key.sp_index.indices[key.sp_values])\\n\"\r\n"]
[411.994348, "o", "\u001b[?2004l\r\n"]
[412.048087, "o", "\u001b[?2004h>     f\"{indent1}    if not key.fill_value:\\n\"\r\n"]
[412.101826, "o", "\u001b[?2004l\r\n"]
[412.155565, "o", "\u001b[?2004h>     f\"{indent1}        return self.take(key.sp_index.indices)\\n\"\r\n"]
[412.209304, "o", "\u001b[?2004l\r\n"]
[412.263043, "o", "\u001b[?2004h>     f\"{indent1}    # fill_value is True: compute complement indices without dense mask\\n\"\r\n"]
[412.316783, "o", "\u001b[?2004l\r\n"]
[412.370522, "o", "\u001b[?2004h>     f\"{indent1}    n = len(self)\\n\"\r\n"]
[412.424261, "o", "\u001b[?2004l\r\n"]
[412.478, "o", "\u001b[?2004h>     f\"{indent1}    neg_idx = key.sp_index.indices\\n\"\r\n"]
[412.531739, "o", "\u001b[?2004l\r\n"]
[412.585478, "o", "\u001b[?2004h>     f\"{indent1}    if neg_idx.size == 0:\\n\"\r\n"]
[412.639217, "o", "\u001b[?2004l\r\n"]
[412.692957, "o", "\u001b[?2004h>     f\"{indent1}        return self.take(np.arange(n, dtype=np.int32))\\n\"\r\n"]
[412.746696, "o", "\u001b[?2004l\r\n"]
[412.800435, "o", "\u001b[?2004h>     f\"{indent1}    out_len = n - int(neg_idx.size)\\n\"\r\n"]
[412.854174, "o", "\u001b[?2004l\r\n"]
[412.907913, "o", "\u001b[?2004h>     f\"{indent1}    out = np.empty(out_len, dtype=np.int32)\\n\"\r\n"]
[412.961652, "o", "\u001b[?2004l\r\n"]
[413.015391, "o", "\u001b[?2004h>     f\"{indent1}    pos = 0\\n\"\r\n"]
[413.06913, "o", "\u001b[?2004l\r\n"]
[413.12287, "o", "\u001b[?2004h>     f\"{indent1}    start_i = 0\\n\"\r\n"]
[413.176609, "o", "\u001b[?2004l\r\n"]
[413.230348, "o", "\u001b[?2004h>     f\"{indent1}    for idx in neg_idx:\\n\"\r\n"]
[413.284087, "o", "\u001b[?2004l\r\n"]
[413.337826, "o", "\u001b[?2004h>     f\"{indent1}        if idx > start_i:\\n\"\r\n"]
[413.391565, "o", "\u001b[?2004l\r\n"]
[413.445304, "o", "\u001b[?2004h>     f\"{indent1}            L = int(idx) - start_i\\n\"\r\n"]
[413.499043, "o", "\u001b[?2004l\r\n"]
[413.552783, "o", "\u001b[?2004h>     f\"{indent1}            out[pos:pos+L] = np.arange(start_i, int(idx), dtype=np.int32)\\n\"\r\n"]
[413.606522, "o", "\u001b[?2004l\r\n"]
[413.660261, "o", "\u001b[?2004h>     f\"{indent1}            pos += L\\n\"\r\n"]
[413.714, "o", "\u001b[?2004l\r\n"]
[413.767739, "o", "\u001b[?2004h>     f\"{indent1}        start_i = int(idx) + 1\\n\"\r\n"]
[413.821478, "o", "\u001b[?2004l\r\n"]
[413.875217, "o", "\u001b[?2004h>     f\"{indent1}    if start_i < n:\\n\"\r\n"]
[413.928957, "o", "\u001b[?2004l\r\n"]
[413.982696, "o", "\u001b[?2004h>     f\"{indent1}        out[pos:] = np.arange(start_i, n, dtype=np.int32)\\n\"\r\n"]
[414.036435, "o", "\u001b[?2004l\r\n"]
[414.090174, "o", "\u001b[?2004h>     f\"{indent1}    return self.take(out)\\n\"\r\n"]
[414.143913, "o", "\u001b[?2004l\r\n"]
[414.197652, "o", "\u001b[?2004h>     f\"{indent1}else:\\n\"\r\n"]
[414.251391, "o", "\u001b[?2004l\r\n"]
[414.30513, "o", "\u001b[?2004h>     f\"{indent1}    key = np.asarray(key)\\n\"\r\n"]
[414.35887, "o", "\u001b[?2004l\r\n"]
[414.412609, "o", "\u001b[?2004h> )\r\n"]
[414.466348, "o", "\u001b[?2004l\r\n"]
[414.520087, "o", "\u001b[?2004h> new_s = s[:start] + inner + s[end:]\r\n"]
[414.573826, "o", "\u001b[?2004l\r\n"]
[414.627565, "o", "\u001b[?2004h> p.write_text(new_s, encoding='utf-8')\r\n"]
[414.681304, "o", "\u001b[?2004l\r\n"]
[414.735043, "o", "\u001b[?2004h> print('Replaced boolean-mask block with corrected indentation')\r\n"]
[414.788783, "o", "\u001b[?2004l\r\n"]
[414.842522, "o", "\u001b[?2004h> PY\r\n"]
[414.896261, "o", "\u001b[?2004l\r\n"]
[415.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[415.002, "i", "python - << 'PY'\r"]
[415.004, "o", "python - << 'PY'\r\n"]
[415.359143, "o", "\u001b[?2004l\r\n"]
[415.712286, "o", "\u001b[?2004h> # Syntax/import check to ensure no IndentationError\r\n"]
[416.065429, "o", "\u001b[?2004l\r\n"]
[416.418571, "o", "\u001b[?2004h> import sys\r\n"]
[416.771714, "o", "\u001b[?2004l\r\n"]
[417.124857, "o", "\u001b[?2004h> sys.path.insert(0, '/workspace/repo')\r\n"]
[417.478, "o", "\u001b[?2004l\r\n"]
[417.831143, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[418.184286, "o", "\u001b[?2004l\r\n"]
[418.537429, "o", "\u001b[?2004h> print('Imported pandas ok; version', pd.__version__)\r\n"]
[418.890571, "o", "\u001b[?2004l\r\n"]
[419.243714, "o", "\u001b[?2004h> PY\r\n"]
[419.596857, "o", "\u001b[?2004l\r\n"]
[420.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[420.002, "i", "cd asv_bench\r"]
[420.004, "o", "cd asv_bench\r\n"]
[420.006, "o", "\u001b[?2004l\r\n"]
[425.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[425.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[425.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[425.359143, "o", "\u001b[?2004l\r\n"]
[425.712286, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[426.065429, "o", "\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n"]
[426.418571, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[426.771714, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (sparse.GetItemMask.time_mask--)\u001b[0m.\r\n"]
[427.124857, "o", "[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39msparse.GetItemMask.time_mask\u001b[0m                                                                                                                    ok\r\n"]
[427.478, "o", "[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============ =============\u001b[0m\r\n"]
[427.831143, "o", "               fill_value               \r\n"]
[428.184286, "o", "              ------------ -------------\r\n"]
[428.537429, "o", "                  True       9.80\u00b10.1ms \r\n"]
[428.890571, "o", "                 False       46.5\u00b10.2\u03bcs \r\n"]
[429.243714, "o", "                  nan       7.26\u00b10.04ms \r\n"]
[429.596857, "o", "              ============ =============\r\n"]
[430.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[430.002, "i", "python - << 'PY'\r"]
[430.004, "o", "python - << 'PY'\r\n"]
[430.091241, "o", "\u001b[?2004l\r\n"]
[430.176483, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[430.261724, "o", "\u001b[?2004l\r\n"]
[430.346966, "o", "\u001b[?2004h> import re\r\n"]
[430.432207, "o", "\u001b[?2004l\r\n"]
[430.517448, "o", "\u001b[?2004h> p = Path('pandas/core/arrays/sparse/array.py')\r\n"]
[430.60269, "o", "\u001b[?2004l\r\n"]
[430.687931, "o", "\u001b[?2004h> s = p.read_text(encoding='utf-8')\r\n"]
[430.773172, "o", "\u001b[?2004l\r\n"]
[430.858414, "o", "\u001b[?2004h> # Locate our custom 'fill_value is True' block and replace the innards with setdiff1d approach\r\n"]
[430.943655, "o", "\u001b[?2004l\r\n"]
[431.028897, "o", "\u001b[?2004h> pat = re.compile(r\"(# fill_value is True: compute complement indices without dense mask\\n\\s*n = len\\(self\\)\\n\\s*neg_idx = key\\.sp_index\\.indices\\n\\s*if neg_idx\r\n"]
[431.114138, "o", "x\\.size == 0:\\n\\s*return self\\.take\\(np\\.arange\\(n, dtype=np\\.int32\\)\\)\\n\\s*out_len = n - int\\(neg_idx\\.size\\)\\n\\s*out = np\\.empty\\(out_len, dtype=np\\.int32\\)\\n[\r\n"]
[431.199379, "o", "[\\s\\S]*?return self\\.take\\(out\\))\")\r\n"]
[431.284621, "o", "\u001b[?2004l\r\n"]
[431.369862, "o", "\u001b[?2004h> new = (\r\n"]
[431.455103, "o", "\u001b[?2004l\r\n"]
[431.540345, "o", "\u001b[?2004h>     \"# fill_value is True: compute complement indices without dense mask\\n\"\r\n"]
[431.625586, "o", "\u001b[?2004l\r\n"]
[431.710828, "o", "\u001b[?2004h>     \"n = len(self)\\n\"\r\n"]
[431.796069, "o", "\u001b[?2004l\r\n"]
[431.88131, "o", "\u001b[?2004h>     \"neg_idx = key.sp_index.indices\\n\"\r\n"]
[431.966552, "o", "\u001b[?2004l\r\n"]
[432.051793, "o", "\u001b[?2004h>     \"if neg_idx.size == 0:\\n\"\r\n"]
[432.137034, "o", "\u001b[?2004l\r\n"]
[432.222276, "o", "\u001b[?2004h>     \"    return self.take(np.arange(n, dtype=np.int32))\\n\"\r\n"]
[432.307517, "o", "\u001b[?2004l\r\n"]
[432.392759, "o", "\u001b[?2004h>     \"# Use vectorized setdiff in NumPy (linear time)\\n\"\r\n"]
[432.478, "o", "\u001b[?2004l\r\n"]
[432.563241, "o", "\u001b[?2004h>     \"all_idx = np.arange(n, dtype=np.int32)\\n\"\r\n"]
[432.648483, "o", "\u001b[?2004l\r\n"]
[432.733724, "o", "\u001b[?2004h>     \"out = np.setdiff1d(all_idx, neg_idx, assume_unique=True)\\n\"\r\n"]
[432.818966, "o", "\u001b[?2004l\r\n"]
[432.904207, "o", "\u001b[?2004h>     \"return self.take(out)\"\r\n"]
[432.989448, "o", "\u001b[?2004l\r\n"]
[433.07469, "o", "\u001b[?2004h> )\r\n"]
[433.159931, "o", "\u001b[?2004l\r\n"]
[433.245172, "o", "\u001b[?2004h> new_s, nsub = pat.subn(new, s, count=1)\r\n"]
[433.330414, "o", "\u001b[?2004l\r\n"]
[433.415655, "o", "\u001b[?2004h> if nsub == 0:\r\n"]
[433.500897, "o", "\u001b[?2004l\r\n"]
[433.586138, "o", "\u001b[?2004h>     raise SystemExit('Target block for fill_value True not found; aborting patch')\r\n"]
[433.671379, "o", "\u001b[?2004l\r\n"]
[433.756621, "o", "\u001b[?2004h> p.write_text(new_s, encoding='utf-8')\r\n"]
[433.841862, "o", "\u001b[?2004l\r\n"]
[433.927103, "o", "\u001b[?2004h> print('Patched fill_value=True branch to use np.setdiff1d')\r\n"]
[434.012345, "o", "\u001b[?2004l\r\n"]
[434.097586, "o", "\u001b[?2004h> PY\r\n"]
[434.182828, "o", "\u001b[?2004l\r\n"]
[434.268069, "o", "Traceback (most recent call last):\r\n"]
[434.35331, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[434.438552, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1236, in read_text\r\n"]
[434.523793, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[434.609034, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1222, in open\r\n"]
[434.694276, "o", "    return io.open(self, mode, buffering, encoding, errors, newline,\r\n"]
[434.779517, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1078, in _opener\r\n"]
[434.864759, "o", "    return self._accessor.open(self, flags, mode)\r\n"]
[435.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[435.002, "i", "python - << 'PY'\r"]
[435.004, "o", "python - << 'PY'\r\n"]
[435.359143, "o", "\u001b[?2004l\r\n"]
[435.712286, "o", "\u001b[?2004h> # Sanity import after patch\r\n"]
[436.065429, "o", "\u001b[?2004l\r\n"]
[436.418571, "o", "\u001b[?2004h> import sys\r\n"]
[436.771714, "o", "\u001b[?2004l\r\n"]
[437.124857, "o", "\u001b[?2004h> sys.path.insert(0, '/workspace/repo')\r\n"]
[437.478, "o", "\u001b[?2004l\r\n"]
[437.831143, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[438.184286, "o", "\u001b[?2004l\r\n"]
[438.537429, "o", "\u001b[?2004h> print('Imported pandas ok; version', pd.__version__)\r\n"]
[438.890571, "o", "\u001b[?2004l\r\n"]
[439.243714, "o", "\u001b[?2004h> PY\r\n"]
[439.596857, "o", "\u001b[?2004l\r\n"]
[440.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[440.002, "i", "cd asv_bench\r"]
[440.004, "o", "cd asv_bench\r\n"]
[442.478, "o", "\u001b[?2004l\r\n"]
[445.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[445.002, "i", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r"]
[445.004, "o", "asv run --python=same --bench=\"sparse.GetItemMask.*\"\r\n"]
[445.359143, "o", "\u001b[?2004l\r\n"]
[445.712286, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[446.065429, "o", "\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n"]
[446.418571, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[446.771714, "o", "[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (sparse.GetItemMask.time_mask--)\u001b[0m.\r\n"]
[447.124857, "o", "[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39msparse.GetItemMask.time_mask\u001b[0m                                                                                                                    ok\r\n"]
[447.478, "o", "[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============ =============\u001b[0m\r\n"]
[447.831143, "o", "               fill_value               \r\n"]
[448.184286, "o", "              ------------ -------------\r\n"]
[448.537429, "o", "                  True      9.60\u00b10.07ms \r\n"]
[448.890571, "o", "                 False       48.7\u00b10.5\u03bcs \r\n"]
[449.243714, "o", "                  nan       6.91\u00b10.05ms \r\n"]
[449.596857, "o", "              ============ =============\r\n"]
[450.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo/asv_bench# "]
[450.002, "i", "cd /workspace/repo\r"]
[450.004, "o", "cd /workspace/repo\r\n"]
[450.006, "o", "\u001b[?2004l\r\n"]
[455.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[455.002, "i", "git add pandas/core/arrays/sparse/array.py\r"]
[455.004, "o", "git add pandas/core/arrays/sparse/array.py\r\n"]
[455.006, "o", "\u001b[?2004l\r\n"]
[460.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[460.002, "i", "git commit -m \"SparseArray.__getitem__: speed up boolean mask with fill_value=True by avoiding dense mask creation; \r"]
[460.004, "o", "git commit -m \"SparseArray.__getitem__: speed up boolean mask with fill_value=True by avoiding dense mask creation; \r\n"]
[460.3356, "o", " compute complement indices from SparseIndex (O(k) ranges). ~20% speedup in asv sparse.GetItemMask.time_mask(True).\"\r\n"]
[460.6652, "o", "\u001b[?2004l\r\n"]
[460.9948, "o", "Author identity unknown\r\n"]
[461.3244, "o", "\r\n"]
[461.654, "o", "*** Please tell me who you are.\r\n"]
[461.9836, "o", "\r\n"]
[462.3132, "o", "Run\r\n"]
[462.6428, "o", "\r\n"]
[462.9724, "o", "  git config --global user.email \"you@example.com\"\r\n"]
[463.302, "o", "  git config --global user.name \"Your Name\"\r\n"]
[463.6316, "o", "\r\n"]
[463.9612, "o", "to set your account's default identity.\r\n"]
[464.2908, "o", "Omit --global to set the identity only in this repository.\r\n"]
[464.6204, "o", "\r\n"]
[465.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[465.002, "i", "pytest -q -k sparse --maxfail=1\r"]
[465.004, "o", "pytest -q -k sparse --maxfail=1\r\n"]
[465.220957, "o", "\u001b[?2004l\r\n"]
[465.435913, "o", "\u001b[31mImportError while loading conftest '/workspace/repo/pandas/conftest.py'.\u001b[0m\r\n"]
[465.65087, "o", "\u001b[31mpandas/conftest.py:602: in <module>\u001b[0m\r\n"]
[465.865826, "o", "\u001b[31m    idx = Index(pd.array(tm.makeStringIndex(100), dtype=\"string[pyarrow]\"))\u001b[0m\r\n"]
[466.080783, "o", "\u001b[31mpandas/core/construction.py:327: in array\u001b[0m\r\n"]
[466.295739, "o", "\u001b[31m    return cls._from_sequence(data, dtype=dtype, copy=copy)\u001b[0m\r\n"]
[466.510696, "o", "\u001b[31mpandas/core/arrays/string_arrow.py:159: in _from_sequence\u001b[0m\r\n"]
[466.725652, "o", "\u001b[31m    return cls(pa.array(result, type=pa.string(), from_pandas=True))\u001b[0m\r\n"]
[466.940609, "o", "\u001b[31mpyarrow/array.pxi:281: in pyarrow.lib.array\u001b[0m\r\n"]
[467.155565, "o", "\u001b[31m    ???\u001b[0m\r\n"]
[467.370522, "o", "\u001b[31mpyarrow/array.pxi:4519: in pyarrow.lib.get_values\u001b[0m\r\n"]
[467.585478, "o", "\u001b[31m    ???\u001b[0m\r\n"]
[467.800435, "o", "\u001b[31mpyarrow/pandas-shim.pxi:228: in pyarrow.lib._PandasAPIShim.is_series\u001b[0m\r\n"]
[468.015391, "o", "\u001b[31m    ???\u001b[0m\r\n"]
[468.230348, "o", "\u001b[31mpyarrow/pandas-shim.pxi:124: in pyarrow.lib._PandasAPIShim._have_pandas_internal\u001b[0m\r\n"]
[468.445304, "o", "\u001b[31m    ???\u001b[0m\r\n"]
[468.660261, "o", "\u001b[31mpyarrow/pandas-shim.pxi:103: in pyarrow.lib._PandasAPIShim._check_import\u001b[0m\r\n"]
[468.875217, "o", "\u001b[31m    ???\u001b[0m\r\n"]
[469.090174, "o", "\u001b[31mpyarrow/pandas-shim.pxi:106: in pyarrow.lib._PandasAPIShim._check_import\u001b[0m\r\n"]
[469.30513, "o", "\u001b[31m    ???\u001b[0m\r\n"]
[469.520087, "o", "\u001b[31mpyarrow/pandas-shim.pxi:74: in pyarrow.lib._PandasAPIShim._import_pandas\u001b[0m\r\n"]
[469.735043, "o", "\u001b[31m    ???\u001b[0m\r\n"]
[470.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[470.002, "i", "git config user.email \"devnull@example.com\"\r"]
[470.004, "o", "git config user.email \"devnull@example.com\"\r\n"]
[470.006, "o", "\u001b[?2004l\r\n"]
[475.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[475.002, "i", "git config user.name \"ASV Optimizer\"\r"]
[475.004, "o", "git config user.name \"ASV Optimizer\"\r\n"]
[475.006, "o", "\u001b[?2004l\r\n"]
[480.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[480.002, "i", "git add pandas/core/arrays/sparse/array.py\r"]
[480.004, "o", "git add pandas/core/arrays/sparse/array.py\r\n"]
[480.006, "o", "\u001b[?2004l\r\n"]
[485.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[485.002, "i", "git commit -m \"SparseArray.__getitem__: speed up boolean mask with fill_value=True by avoiding dense mask creation; \r"]
[485.004, "o", "git commit -m \"SparseArray.__getitem__: speed up boolean mask with fill_value=True by avoiding dense mask creation; \r\n"]
[486.242, "o", " compute complement indices from SparseIndex without densifying. ~20% speedup in asv sparse.GetItemMask.time_mask(True).\"\r\n"]
[487.478, "o", "\u001b[?2004l\r\n"]
[488.714, "o", "[main 15872e5f04] SparseArray.__getitem__: speed up boolean mask with fill_value=True by avoiding dense mask creation; compute complement indices from SparseIndex without densifying. ~20% speedup in asv sparse.GetItemMask.time_mask(True).\r\n"]
[490.0, "o", "(asv_3.8) root@aaf0ca2b2a08:/workspace/repo# "]
[490.002, "i", "\u001b[?2004l\r"]
[490.004, "o", "\u001b[?2004l\r\n"]
[492.478, "o", "\r\n"]
