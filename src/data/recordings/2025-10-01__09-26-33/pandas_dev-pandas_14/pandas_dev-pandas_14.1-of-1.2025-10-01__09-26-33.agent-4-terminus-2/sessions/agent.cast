{"version": 2, "width": 160, "height": 40, "timestamp": 1762942245, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[0.006, "o", "\u001b[?2004l\r\n\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n\u001b[0;31masciinema: use --append option if you want to append to existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[5.006, "o", "\u001b[?2004l\r\n\u001b[H\u001b[J\r\n"]
[10.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.006, "o", "\u001b[?2004l\r\ntotal 208\r\ndrwxr-xr-x 1 root root  4096 Oct  1 18:15 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 15 17:10 \u001b[01;34m..\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 13 19:16 \u001b[01;34m.circleci\u001b[0m\r\n-rw-r--r-- 1 root root  1021 Sep 13 19:16 .devcontainer.json\r\ndrwxr-xr-x 1 root root  4096 Oct  1 18:15 \u001b[01;34m.git\u001b[0m\r\n-rw-r--r-- 1 root root   229 Sep 13 19:16 .gitattributes\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 \u001b[01;34m.github\u001b[0m\r\n-rw-r--r-- 1 root root  1740 Sep 13 19:16 .gitignore\r\n-rw-r--r-- 1 root root  2322 Sep 13 19:16 .gitpod.yml\r\n-rw-r--r-- 1 root root   761 Sep 13 19:16 .libcst.codemod.yaml\r\n-rw-r--r-- 1 root root   109 Sep 13 19:16 .pep8speaks.yml\r\n-rw-r--r-- 1 root root 16108 Sep 13 19:16 .pre-commit-config.yaml\r\n-rw-r--r-- 1 root root  2284 Sep 13 19:16 AUTHORS.md\r\n-rw-r--r-- 1 root root   372 Sep 13 19:16 CITATION.cff\r\n-rw-r--r-- 1 root root   369 Sep 13 19:16 Dockerfile\r\n-rw-r--r-- 1 root root  1634 Sep 13 19:16 LICENSE\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 \u001b[01;34mLICENSES\u001b[0m\r\n-rw-r--r-- 1 root root  1228 Sep 13 19:16 MANIFEST.in\r\n-rw-r--r-- 1 root root 10387 Sep 13 19:16 README.md\r\n-rw-r--r-- 1 root root   246 Sep 13 19:16 RELEASE.md\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 \u001b[01;34masv_bench\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 \u001b[01;34mci\u001b[0m\r\n-rw-r--r-- 1 root root   256 Sep 13 19:14 codecov.yml\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 \u001b[01;34mdoc\u001b[0m\r\n-rw-r--r-- 1 root root  2103 Sep 13 19:16 environment.yml\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 \u001b[01;34mgitpod\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:57 \u001b[01;34mpandas\u001b[0m\r\n-rw-r--r-- 1 root root 15627 Sep 13 19:16 pyproject.toml\r\n-rw-r--r-- 1 root root  4429 Sep 13 19:16 pyright_reportGeneralTypeIssues.json\r\n-rw-r--r-- 1 root root  1090 Sep 13 19:16 requirements-dev.txt\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 \u001b[01;34mscripts\u001b[0m\r\n-rw-r--r-- 1 root root  2095 Sep 13 19:16 setup.cfg\r\n-rwxr-xr-x 1 root root 21964 Sep 13 19:16 \u001b[01;32msetup.py\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 13 19:14 \u001b[01;34mtypings\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 \u001b[01;34mweb\u001b[0m\r\n"]
[15.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[15.002, "i", "git rev-parse --is-inside-work-tree 2>/dev/null && git status -sb || echo 'not a git repo'\r"]
[15.004, "o", "git rev-parse --is-inside-work-tree 2>/dev/null && git status -sb || echo 'not a git repo'\r\n"]
[15.006, "o", "\u001b[?2004l\r\ntrue\r\n## \u001b[32mmain\u001b[m\r\n"]
[20.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[20.002, "i", "ls -la | sed -n '1,200p'\r"]
[20.004, "o", "ls -la | sed -n '1,200p'\r\n"]
[20.006, "o", "\u001b[?2004l\r\ntotal 208\r\ndrwxr-xr-x 1 root root  4096 Oct  1 18:15 .\r\ndrwxr-xr-x 1 root root  4096 Sep 15 17:10 ..\r\ndrwxr-xr-x 2 root root  4096 Sep 13 19:16 .circleci\r\n-rw-r--r-- 1 root root  1021 Sep 13 19:16 .devcontainer.json\r\ndrwxr-xr-x 1 root root  4096 Oct  1 18:17 .git\r\n-rw-r--r-- 1 root root   229 Sep 13 19:16 .gitattributes\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 .github\r\n-rw-r--r-- 1 root root  1740 Sep 13 19:16 .gitignore\r\n-rw-r--r-- 1 root root  2322 Sep 13 19:16 .gitpod.yml\r\n-rw-r--r-- 1 root root   761 Sep 13 19:16 .libcst.codemod.yaml\r\n-rw-r--r-- 1 root root   109 Sep 13 19:16 .pep8speaks.yml\r\n-rw-r--r-- 1 root root 16108 Sep 13 19:16 .pre-commit-config.yaml\r\n-rw-r--r-- 1 root root  2284 Sep 13 19:16 AUTHORS.md\r\n-rw-r--r-- 1 root root   372 Sep 13 19:16 CITATION.cff\r\n-rw-r--r-- 1 root root   369 Sep 13 19:16 Dockerfile\r\n-rw-r--r-- 1 root root  1634 Sep 13 19:16 LICENSE\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 LICENSES\r\n-rw-r--r-- 1 root root  1228 Sep 13 19:16 MANIFEST.in\r\n-rw-r--r-- 1 root root 10387 Sep 13 19:16 README.md\r\n-rw-r--r-- 1 root root   246 Sep 13 19:16 RELEASE.md\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 asv_bench\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 ci\r\n-rw-r--r-- 1 root root   256 Sep 13 19:14 codecov.yml\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 doc\r\n-rw-r--r-- 1 root root  2103 Sep 13 19:16 environment.yml\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 gitpod\r\ndrwxr-xr-x 1 root root  4096 Sep 13 21:57 pandas\r\n-rw-r--r-- 1 root root 15627 Sep 13 19:16 pyproject.toml\r\n-rw-r--r-- 1 root root  4429 Sep 13 19:16 pyright_reportGeneralTypeIssues.json\r\n-rw-r--r-- 1 root root  1090 Sep 13 19:16 requirements-dev.txt\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 scripts\r\n-rw-r--r-- 1 root root  2095 Sep 13 19:16 setup.cfg\r\n-rwxr-xr-x 1 root root 21964 Sep 13 19:16 setup.py\r\ndrwxr-xr-x 2 root root  4096 Sep 13 19:14 typings\r\ndrwxr-xr-x 1 root root  4096 Sep 13 19:16 web\r\n"]
[25.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[25.002, "i", "test -f asv.conf.json && echo asv.conf.json || (test -f asv.conf.asv.json && echo asv.conf.asv.json) || (test -f asv\r"]
[25.004, "o", "test -f asv.conf.json && echo asv.conf.json || (test -f asv.conf.asv.json && echo asv.conf.asv.json) || (test -f asv\r\n"]
[25.006, "o", "v_bench/asv.conf.json && echo asv_bench/asv.conf.json) || echo 'no asv config found'\r\n\u001b[?2004l\r\nasv_bench/asv.conf.json\r\n"]
[30.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[30.002, "i", "grep -R \"asv\" -n -- */ 2>/dev/null | head -n 50\r"]
[30.004, "o", "grep -R \"asv\" -n -- */ 2>/dev/null | head -n 50\r\n"]
[30.006, "o", "\u001b[?2004l\r\nasv_bench/asv.conf.json:31:    // to the current version of Python used to run `asv`.\r\nasv_bench/asv.conf.json:109:    // `asv` will cache wheels of the recent builds in each\r\nasv_bench/asv.conf.json:114:    // The commits after which the regression search in `asv publish`\r\nasv_bench/benchmarks/io/parsers.py:9:    # Avoid whole benchmark suite import failure on asv (currently 0.4)\r\nasv_bench/benchmarks/pandas_vb_common.py:59:    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\r\ndoc/source/whatsnew/v0.17.0.rst:51:- Development support for benchmarking with the `Air Speed Velocity library <https://github.com/spacetelescope/asv/>`_ (:issue:`8361`)\r\ndoc/source/whatsnew/v0.17.0.rst:1022:- Development support for benchmarking with the `Air Speed Velocity library <https://github.com/spacetelescope/asv/>`_ (:issue:`8361`)\r\ndoc/source/development/contributing_codebase.rst:898:`asv benchmarks <https://github.com/airspeed-velocity/asv>`__\r\ndoc/source/development/contributing_codebase.rst:900:These benchmarks are all found in the ``pandas/asv_bench`` directory, and the\r\ndoc/source/development/contributing_codebase.rst:903:To use all features of asv, you will need either ``conda`` or\r\ndoc/source/development/contributing_codebase.rst:904:``virtualenv``. For more details please check the `asv installation\r\ndoc/source/development/contributing_codebase.rst:905:webpage <https://asv.readthedocs.io/en/latest/installing.html>`_.\r\ndoc/source/development/contributing_codebase.rst:907:To install asv::\r\ndoc/source/development/contributing_codebase.rst:909:    pip install git+https://github.com/airspeed-velocity/asv\r\ndoc/source/development/contributing_codebase.rst:911:If you need to run a benchmark, change your directory to ``asv_bench/`` and run::\r\ndoc/source/development/contributing_codebase.rst:913:    asv continuous -f 1.1 upstream/main HEAD\r\ndoc/source/development/contributing_codebase.rst:920:    asv continuous -f 1.1 -E virtualenv upstream/main HEAD\r\ndoc/source/development/contributing_codebase.rst:922:The ``-E virtualenv`` option should be added to all ``asv`` commands\r\ndoc/source/development/contributing_codebase.rst:923:that run benchmarks. The default value is defined in ``asv.conf.json``.\r\ndoc/source/development/contributing_codebase.rst:930:only run benchmarks from a ``pandas/asv_bench/benchmarks/groupby.py`` file::\r\ndoc/source/development/contributing_codebase.rst:932:    asv continuous -f 1.1 upstream/main HEAD -b ^groupby\r\ndoc/source/development/contributing_codebase.rst:937:    asv continuous -f 1.1 upstream/main HEAD -b groupby.GroupByMethods\r\ndoc/source/development/contributing_codebase.rst:946:``PYTHONPATH=\"$PWD/..\" asv [remaining arguments]``.\r\ndoc/source/development/contributing_codebase.rst:950:    asv run -e -E existing\r\ndoc/source/development/contributing_codebase.rst:954:    asv run -e -E existing:python3.6\r\ndoc/source/development/contributing_codebase.rst:959:Information on how to write a benchmark and how to use asv can be found in the\r\ndoc/source/development/contributing_codebase.rst:960:`asv documentation <https://asv.readthedocs.io/en/latest/writing_benchmarks.html>`_.\r\ndoc/source/development/maintaining.rst:315:.. _maintaining.asv-machine:\r\ndoc/source/development/maintaining.rst:321:are published to https://asv-runner.github.io/asv-collection/pandas/\r\ndoc/source/development/maintaining.rst:326:The machine can be configured with the `Ansible <http://docs.ansible.com/ansible/latest/index.html>`_ playbook in https://github.com/tomaugspurger/asv-runner.\r\ndoc/source/development/maintaining.rst:331:The results are published to another GitHub repository, https://github.com/tomaugspurger/asv-collection.\r\ndoc/source/development/maintaining.rst:332:Finally, we have a cron job on our docs server to pull from https://github.com/tomaugspurger/asv-collection, to serve them from ``/speed``.\r\ndoc/source/development/roadmap.rst:189:pandas uses `airspeed velocity <https://asv.readthedocs.io/en/stable/>`__ to\r\ndoc/source/development/roadmap.rst:193:The `asv-runner <https://github.com/asv-runner>`__ organization, currently made up\r\npandas/io/sas/byteswap.c:14:            \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/include\"\r\npandas/io/sas/sas.c:14:            \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/include\"\r\npandas/tests/reshape/concat/test_dataframe.py:200:        # based on asv ConcatDataFrames\r\npandas/tests/io/data/csv/banklist.csv:6:Douglas County Bank,Douglasville,GA,21649,Hamilton State Bank,26-Apr-13,16-May-13\r\npandas/tests/io/data/csv/banklist.csv:194:First Commerce Community Bank,Douglasville,GA,57448,Community & Southern Bank,17-Sep-10,15-Jan-13\r\npandas/tests/io/data/html/banklist.html:300:\t\t\t\t<td class=\"city\">Douglasville</td>\r\npandas/tests/io/data/html/banklist.html:1992:\t\t\t\t<td class=\"city\">Douglasville</td>\r\npandas/tests/frame/methods/test_reindex.py:124:        # based on asv time_reindex_axis1\r\npandas/tests/tools/test_to_datetime.py:1140:        # inspired by asv timeseries.ToDatetimeNONISO8601 benchmark\r\npandas/_libs/tslibs/base.c:14:            \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/include\"\r\npandas/_libs/tslibs/timestamps.c:13:            \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/include/numpy/arrayobject.h\",\r\npandas/_libs/tslibs/timestamps.c:14:            \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/include/numpy/arrayscalars.h\",\r\npandas/_libs/tslibs/timestamps.c:15:            \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/include/numpy/ndarrayobject.h\",\r\npandas/_libs/tslibs/timestamps.c:16:            \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/include/numpy/ndarraytypes.h\",\r\npandas/_libs/tslibs/timestamps.c:17:            \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/include/numpy/npy_common.h\",\r\npandas/_libs/tslibs/timestamps.c:18:            \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/include/numpy/ufuncobject.h\",\r\n"]
[35.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[35.002, "i", "find . -maxdepth 3 -type d -iname '*bench*' -or -iname 'asv*' | sed -n '1,200p'\r"]
[35.004, "o", "find . -maxdepth 3 -type d -iname '*bench*' -or -iname 'asv*' | sed -n '1,200p'\r\n"]
[35.006, "o", "\u001b[?2004l\r\n./asv_bench\r\n./asv_bench/asv.conf.json\r\n./asv_bench/benchmarks\r\n./.github/workflows/asv-bot.yml\r\n"]
[40.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[40.002, "i", "grep -R \"tslibs.timestamp\" -n . 2>/dev/null | head -n 50\r"]
[40.004, "o", "grep -R \"tslibs.timestamp\" -n . 2>/dev/null | head -n 50\r\n"]
[40.006, "o", "\u001b[?2004l\r\n./setup.py:217:        \"pandas/_libs/tslibs/timestamps.pyx\",\r\n./setup.py:549:    \"_libs.tslibs.timestamps\": {\r\n./setup.py:550:        \"pyxfile\": \"_libs/tslibs/timestamps\",\r\n./pandas/core/arrays/datetimelike.py:54:from pandas._libs.tslibs.timestamps import integer_op_not_supported\r\n./pandas/tests/tslibs/test_timezones.py:144:    msg = \"<class 'pandas._libs.tslibs.timestamps.Timestamp'>\"\r\n./pandas/_libs/tslibs/timedeltas.pyx:759:            from pandas._libs.tslibs.timestamps import Timestamp\r\n./pandas/_libs/tslibs/__init__.py:75:from pandas._libs.tslibs.timestamps import Timestamp\r\n./pandas/_libs/tslibs/tzconversion.pyx:453:    from pandas._libs.tslibs.timestamps import Timestamp\r\n./pandas/_libs/tslibs/period.pyi:8:from pandas._libs.tslibs.timestamps import Timestamp\r\n./pandas/_libs/tslibs/strptime.pyx:67:from pandas._libs.tslibs.timestamps cimport _Timestamp\r\n./pandas/_libs/tslibs/strptime.pyx:74:from pandas._libs.tslibs.timestamps import Timestamp\r\n./pandas/_libs/tslibs/conversion.pyx:60:from pandas._libs.tslibs.timestamps cimport _Timestamp\r\n./pandas/_libs/tslibs/conversion.pyx:591:            from pandas._libs.tslibs.timestamps import Timestamp\r\n./pandas/_libs/tslibs/conversion.pyx:599:            from pandas._libs.tslibs.timestamps import Timestamp\r\n./pandas/_libs/tslibs/period.pyx:57:from pandas._libs.tslibs.timestamps import Timestamp\r\n./pandas/_libs/tslibs/conversion.pxd:15:from pandas._libs.tslibs.timestamps cimport _Timestamp\r\n./pandas/_libs/tslibs/timestamps.c:28:        \"name\": \"pandas._libs.tslibs.timestamps\",\r\n./pandas/_libs/tslibs/timestamps.c:30:            \"pandas/_libs/tslibs/timestamps.pyx\",\r\n./pandas/_libs/tslibs/timestamps.c:34:    \"module_name\": \"pandas._libs.tslibs.timestamps\"\r\n./pandas/_libs/tslibs/timestamps.c:1033:  \"pandas/_libs/tslibs/timestamps.pyx\",\r\n./pandas/_libs/tslibs/timestamps.c:1034:  \"pandas/_libs/tslibs/timestamps.pxd\",\r\n./pandas/_libs/tslibs/timestamps.c:1767:/* \"pandas/_libs/tslibs/timestamps.pxd\":15\r\n./pandas/_libs/tslibs/timestamps.c:1779:/* \"pandas/_libs/tslibs/timestamps.pxd\":32\r\n./pandas/_libs/tslibs/timestamps.c:1791:/* \"pandas/_libs/tslibs/timestamps.pxd\":36\r\n./pandas/_libs/tslibs/timestamps.c:1923:/* \"pandas/_libs/tslibs/timestamps.pxd\":22\r\n./pandas/_libs/tslibs/timestamps.c:1940:/* \"pandas/_libs/tslibs/timestamps.pyx\":1518\r\n./pandas/_libs/tslibs/timestamps.c:1953:/* \"pandas/_libs/tslibs/timestamps.pyx\":1612\r\n./pandas/_libs/tslibs/timestamps.c:2107:/* \"pandas/_libs/tslibs/timestamps.pyx\":224\r\n./pandas/_libs/tslibs/timestamps.c:3465:/* Module declarations from 'pandas._libs.tslibs.timestamps' */\r\n./pandas/_libs/tslibs/timestamps.c:3517:#define __Pyx_MODULE_NAME \"pandas._libs.tslibs.timestamps\"\r\n./pandas/_libs/tslibs/timestamps.c:3521:/* Implementation of 'pandas._libs.tslibs.timestamps' */\r\n./pandas/_libs/tslibs/timestamps.c:3875:static const char __pyx_k_pandas__libs_tslibs_timestamps[] = \"pandas._libs.tslibs.timestamps\";\r\n./pandas/_libs/tslibs/timestamps.c:3961:static const char __pyx_k_pandas__libs_tslibs_timestamps_p[] = \"pandas/_libs/tslibs/timestamps.pyx\";\r\n./pandas/_libs/tslibs/timestamps.c:4300:static PyObject *__pyx_n_s_pandas__libs_tslibs_timestamps;\r\n./pandas/_libs/tslibs/timestamps.c:4301:static PyObject *__pyx_kp_s_pandas__libs_tslibs_timestamps_p;\r\n./pandas/_libs/tslibs/timestamps.c:4686:/* \"pandas/_libs/tslibs/timestamps.pyx\":129\r\n./pandas/_libs/tslibs/timestamps.c:4723:  /* \"pandas/_libs/tslibs/timestamps.pyx\":139\r\n./pandas/_libs/tslibs/timestamps.c:4733:  /* \"pandas/_libs/tslibs/timestamps.pyx\":145\r\n./pandas/_libs/tslibs/timestamps.c:4749:  /* \"pandas/_libs/tslibs/timestamps.pyx\":148\r\n./pandas/_libs/tslibs/timestamps.c:4759:    /* \"pandas/_libs/tslibs/timestamps.pyx\":149\r\n./pandas/_libs/tslibs/timestamps.c:4768:    /* \"pandas/_libs/tslibs/timestamps.pyx\":148\r\n./pandas/_libs/tslibs/timestamps.c:4778:  /* \"pandas/_libs/tslibs/timestamps.pyx\":151\r\n./pandas/_libs/tslibs/timestamps.c:4790:  /* \"pandas/_libs/tslibs/timestamps.pyx\":153\r\n./pandas/_libs/tslibs/timestamps.c:4806:  /* \"pandas/_libs/tslibs/timestamps.pyx\":154\r\n./pandas/_libs/tslibs/timestamps.c:4820:  /* \"pandas/_libs/tslibs/timestamps.pyx\":155\r\n./pandas/_libs/tslibs/timestamps.c:4832:  /* \"pandas/_libs/tslibs/timestamps.pyx\":153\r\n./pandas/_libs/tslibs/timestamps.c:4869:  /* \"pandas/_libs/tslibs/timestamps.pyx\":155\r\n./pandas/_libs/tslibs/timestamps.c:4883:  /* \"pandas/_libs/tslibs/timestamps.pyx\":153\r\n./pandas/_libs/tslibs/timestamps.c:4899:  /* \"pandas/_libs/tslibs/timestamps.pyx\":157\r\n./pandas/_libs/tslibs/timestamps.c:4908:  /* \"pandas/_libs/tslibs/timestamps.pyx\":158\r\n"]
[45.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[45.002, "i", "grep -R \"SumMultiLevel\" -n . 2>/dev/null | head -n 50\r"]
[45.004, "o", "grep -R \"SumMultiLevel\" -n . 2>/dev/null | head -n 50\r\n"]
[45.006, "o", "\u001b[?2004l\r\n./asv_bench/benchmarks/groupby.py:762:class SumMultiLevel:\r\n"]
[50.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[50.002, "i", "grep -R \"IntervalIndexMethod\" -n . 2>/dev/null | head -n 50\r"]
[50.004, "o", "grep -R \"IntervalIndexMethod\" -n . 2>/dev/null | head -n 50\r\n"]
[50.006, "o", "\u001b[?2004l\r\n./pandas/core/indexes/interval.py:907:        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n./asv_bench/benchmarks/index_object.py:211:class IntervalIndexMethod:\r\n"]
[55.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[55.002, "i", "asv run --python=same --quick --bench=\"tslibs.timestamp.*\"\r"]
[55.004, "o", "asv run --python=same --quick --bench=\"tslibs.timestamp.*\"\r\n"]
[55.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mNo `asv.conf` file found for valid extensions: ['.json', '.jsonc'].\u001b[0m\r\n"]
[60.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[60.002, "i", "asv run --python=same --quick --bench=\"groupby.SumMultiLevel.*\"\r"]
[60.004, "o", "asv run --python=same --quick --bench=\"groupby.SumMultiLevel.*\"\r\n"]
[60.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mNo `asv.conf` file found for valid extensions: ['.json', '.jsonc'].\u001b[0m\r\n"]
[65.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[65.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.*\"\r"]
[65.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.*\"\r\n"]
[65.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mNo `asv.conf` file found for valid extensions: ['.json', '.jsonc'].\u001b[0m\r\n"]
[70.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[70.002, "i", "asv find --python=same --bench \"tslibs.timestamp.*\"\r"]
[70.004, "o", "asv find --python=same --bench \"tslibs.timestamp.*\"\r\n"]
[70.006, "o", "\u001b[?2004l\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/asv_3.8/bin/asv\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/main.py\", line 13, in main\r\n    args = parser.parse_args()\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1768, in parse_args\r\n    args, argv = self.parse_known_args(args, namespace)\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1800, in parse_known_args\r\n    namespace, args = self._parse_known_args(args, namespace)\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1988, in _parse_known_args\r\n    positionals_end_index = consume_positionals(start_index)\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1965, in consume_positionals\r\n    take_action(action, args)\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1874, in take_action\r\n    action(self, namespace, argument_values, option_string)\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1159, in __call__\r\n    subnamespace, arg_strings = parser.parse_known_args(arg_strings, None)\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1800, in parse_known_args\r\n    namespace, args = self._parse_known_args(args, namespace)\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 2035, in _parse_known_args\r\n    ', '.join(required_actions))\r\nTypeError: sequence item 0: expected str instance, tuple found\r\n"]
[75.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[75.002, "i", "asv profile --python=same \"tslibs.timestamp.*\" 2>/dev/null | sed -n '1,200p'\r"]
[75.004, "o", "asv profile --python=same \"tslibs.timestamp.*\" 2>/dev/null | sed -n '1,200p'\r\n"]
[75.006, "o", "\u001b[?2004l\r\n\u00b7 No `asv.conf` file found for valid extensions: ['.json', '.jsonc'].\r\n"]
[80.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[80.002, "i", "sed -n '1,200p' asv_bench/asv.conf.json\r"]
[80.004, "o", "sed -n '1,200p' asv_bench/asv.conf.json\r\n"]
[80.006, "o", "\u001b[?2004l\r\n{\r\n    // The version of the config file format.  Do not change, unless\r\n    // you know what you are doing.\r\n    \"version\": 1,\r\n\r\n    // The name of the project being benchmarked\r\n    \"project\": \"pandas\",\r\n\r\n    // The project's homepage\r\n    \"project_url\": \"https://pandas.pydata.org/\",\r\n\r\n    // The URL of the source code repository for the project being\r\n    // benchmarked\r\n    \"repo\": \"..\",\r\n\r\n    // List of branches to benchmark. If not provided, defaults to \"master\"\r\n    // (for git) or \"default\" (for mercurial).\r\n    \"branches\": [\"main\"],\r\n\r\n    // The tool to use to create environments.  May be \"conda\",\r\n    // \"virtualenv\" or other value depending on the plugins in use.\r\n    // If missing or the empty string, the tool will be automatically\r\n    // determined by looking for tools on the PATH environment\r\n    // variable.\r\n    \"environment_type\": \"conda\",\r\n\r\n    // the base URL to show a commit for the project.\r\n    \"show_commit_url\": \"https://github.com/pandas-dev/pandas/commit/\",\r\n\r\n    // The Pythons you'd like to test against.  If not provided, defaults\r\n    // to the current version of Python used to run `asv`.\r\n    \"pythons\": [\"3.8\"],\r\n\r\n    // The matrix of dependencies to test.  Each key is the name of a\r\n    // package (in PyPI) and the values are version numbers.  An empty\r\n    // list or empty string indicates to just test against the default\r\n    // (latest) version. null indicates that the package is to not be\r\n    // installed. If the package to be tested is only available from\r\n    // PyPi, and the 'environment_type' is conda, then you can preface\r\n    // the package name by 'pip+', and the package will be installed via\r\n    // pip (with all the conda available packages installed first,\r\n    // followed by the pip installed packages).\r\n    \"matrix\": {\r\n        \"numpy\": [],\r\n        \"Cython\": [\"0.29.32\"],\r\n        \"matplotlib\": [],\r\n        \"sqlalchemy\": [],\r\n        \"scipy\": [],\r\n        \"numba\": [],\r\n        \"numexpr\": [],\r\n        \"pytables\": [null, \"\"],  // platform dependent, see excludes below\r\n        \"pyarrow\": [],\r\n        \"tables\": [null, \"\"],\r\n        \"openpyxl\": [],\r\n        \"xlsxwriter\": [],\r\n        \"xlrd\": [],\r\n        \"odfpy\": [],\r\n        \"jinja2\": [],\r\n    },\r\n    \"conda_channels\": [\"conda-forge\"],\r\n    // Combinations of libraries/python versions can be excluded/included\r\n    // from the set to test. Each entry is a dictionary containing additional\r\n    // key-value pairs to include/exclude.\r\n    //\r\n    // An exclude entry excludes entries where all values match. The\r\n    // values are regexps that should match the whole string.\r\n    //\r\n    // An include entry adds an environment. Only the packages listed\r\n    // are installed. The 'python' key is required. The exclude rules\r\n    // do not apply to includes.\r\n    //\r\n    // In addition to package names, the following keys are available:\r\n    //\r\n    // - python\r\n    //     Python version, as in the *pythons* variable above.\r\n    // - environment_type\r\n    //     Environment type, as above.\r\n    // - sys_platform\r\n    //     Platform, as in sys.platform. Possible values for the common\r\n    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.\r\n    \"exclude\": [\r\n        // On conda install pytables, otherwise tables\r\n        {\"environment_type\": \"conda\", \"tables\": \"\"},\r\n        {\"environment_type\": \"conda\", \"pytables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"tables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"pytables\": \"\"},\r\n    ],\r\n    \"include\": [],\r\n\r\n    // The directory (relative to the current directory) that benchmarks are\r\n    // stored in.  If not provided, defaults to \"benchmarks\"\r\n    // \"benchmark_dir\": \"benchmarks\",\r\n\r\n    // The directory (relative to the current directory) to cache the Python\r\n    // environments in.  If not provided, defaults to \"env\"\r\n    // \"env_dir\": \"env\",\r\n\r\n    // The directory (relative to the current directory) that raw benchmark\r\n    // results are stored in.  If not provided, defaults to \"results\".\r\n    // \"results_dir\": \"results\",\r\n\r\n    // The directory (relative to the current directory) that the html tree\r\n    // should be written to.  If not provided, defaults to \"html\".\r\n    // \"html_dir\": \"html\",\r\n\r\n    // The number of characters to retain in the commit hashes.\r\n    // \"hash_length\": 8,\r\n\r\n    // `asv` will cache wheels of the recent builds in each\r\n    // environment, making them faster to install next time.  This is\r\n    // number of builds to keep, per environment.\r\n    \"build_cache_size\": 8,\r\n\r\n    // The commits after which the regression search in `asv publish`\r\n    // should start looking for regressions. Dictionary whose keys are\r\n    // regexps matching to benchmark names, and values corresponding to\r\n    // the commit (exclusive) after which to start looking for\r\n    // regressions.  The default is to start from the first commit\r\n    // with results. If the commit is `null`, regression detection is\r\n    // skipped for the matching benchmark.\r\n    //\r\n    \"regressions_first_commits\": {\r\n        \".*\": \"0409521665\"\r\n    },\r\n    \"regression_thresholds\": {\r\n    },\r\n    \"build_command\":\r\n    [\"python -m pip install versioneer[toml]\",\r\n     \"python setup.py build -j4\",\r\n     \"PIP_NO_BUILD_ISOLATION=false python -mpip wheel --no-deps --no-index -w {build_cache_dir} {build_dir}\"],\r\n}\r\n"]
[85.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[85.002, "i", "find pandas -name '*.so' | head -n 20\r"]
[85.004, "o", "find pandas -name '*.so' | head -n 20\r\n"]
[85.006, "o", "\u001b[?2004l\r\npandas/io/sas/_byteswap.cpython-38-x86_64-linux-gnu.so\r\npandas/io/sas/_sas.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/fields.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/nattype.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/timestamps.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/ccalendar.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/strptime.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/np_datetime.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/dtypes.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/timezones.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/vectorized.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/tzconversion.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/timedeltas.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/period.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/conversion.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/base.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/offsets.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/parsing.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/window/aggregations.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/window/indexers.cpython-38-x86_64-linux-gnu.so\r\n"]
[90.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[90.002, "i", "python - << 'PY'\r"]
[90.004, "o", "python - << 'PY'\r\n"]
[90.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import sys\r\n\u001b[?2004l\r\n\u001b[?2004h> try:\r\n\u001b[?2004l\r\n\u001b[?2004h>     import pandas as pd\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('pandas_version:', pd.__version__)\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('pandas_file:', pd.__file__)\r\n\u001b[?2004l\r\n\u001b[?2004h> except Exception as e:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('import_error:', repr(e))\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\npandas_version: 0+untagged.31506.g5f584bd\r\npandas_file: /workspace/repo/pandas/__init__.py\r\n"]
[95.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[95.002, "i", "asv dev -h\r"]
[95.004, "o", "asv dev -h\r\n"]
[95.006, "o", "\u001b[?2004l\r\nusage: asv [-h] [--verbose] [--config CONFIG] [--version]\r\n           {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages} ...\r\nasv: error: invalid choice: 'dev' (choose from 'help', 'quickstart', 'machine', 'setup', 'run', 'continuous', 'find', 'rm', 'publish', 'preview', 'profile', 'update', 'show', 'compare', 'check', 'gh-pages')\r\n"]
[100.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[100.002, "i", "asv run -h\r"]
[100.004, "o", "asv run -h\r\n"]
[100.006, "o", "\u001b[?2004l\r\nusage: asv run [-h] [--date-period DATE_PERIOD] [--steps STEPS] [--bench BENCH] [--attribute ATTRIBUTE] [--cpu-affinity ATTRIBUTE] [--profile]\r\n               [--parallel [PARALLEL]] [--show-stderr] [--durations [N]] [--quick] [-E ENV_SPEC] [--python PYTHON] [--set-commit-hash SET_COMMIT_HASH]\r\n               [--launch-method {auto,spawn,forkserver}] [--dry-run] [--machine MACHINE] [--skip-existing-successful] [--skip-existing-failed]\r\n               [--skip-existing-commits] [--skip-existing] [--record-samples] [--append-samples] [--interleave-rounds] [--no-interleave-rounds] [--no-pull]\r\n               [--verbose] [--config CONFIG] [--version]\r\n               [range]\r\n\r\nRun a benchmark suite.\r\n\r\nexamples:\r\n  asv run main             run for one branch\r\n  asv run main^!           run for one commit (git)\r\n  asv run \"--merges main\"  run for only merge commits (git)\r\n\r\npositional arguments:\r\n  range                 Range of commits to benchmark. For a git repository, this is passed as the first argument to ``git rev-list``; or Mercurial log\r\n                        command. See 'specifying ranges' section of the `gitrevisions` manpage, or 'hg help revisions', for more info. Also accepts the\r\n                        special values 'NEW', 'ALL', 'EXISTING', 'TAGS', and 'HASHFILE:xxx'. 'NEW' will benchmark all commits since the latest benchmarked on\r\n                        this machine. 'ALL' will benchmark all commits in the project. 'EXISTING' will benchmark against all commits for which there are\r\n                        existing benchmarks on any machine. 'TAGS' will benchmark against all tags in the project. 'HASHFILE:xxx' will benchmark only a\r\n                        specific set of hashes given in the file named 'xxx' ('-' means stdin), which must have one hash per line. By default, will benchmark\r\n                        the head of each configured of the branches.\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n  --date-period DATE_PERIOD\r\n                        Pick only one commit in each given time period. For example: 1d (daily), 1w (weekly), 1y (yearly).\r\n  --steps STEPS, -s STEPS\r\n                        Maximum number of steps to benchmark. This is used to subsample the commits determined by range to a reasonable number.\r\n  --bench BENCH, -b BENCH\r\n                        Regular expression(s) for benchmark to run. When not provided, all benchmarks are run.\r\n  --attribute ATTRIBUTE, -a ATTRIBUTE\r\n                        Override a benchmark attribute, e.g. `-a repeat=10`.\r\n  --cpu-affinity ATTRIBUTE\r\n                        Set CPU affinity for running the benchmark, in format: 0 or 0,1,2 or 0-3. Default: not set\r\n  --profile, -p         In addition to timing, run the benchmarks through the `cProfile` profiler and store the results.\r\n  --parallel [PARALLEL], -j [PARALLEL]\r\n                        Build (but don't benchmark) in parallel. The value is the number of CPUs to use, or if no number provided, use the number of cores on\r\n                        this machine.\r\n  --show-stderr, -e     Display the stderr output from the benchmarks.\r\n  --durations [N]       Display total duration for N (or 'all') slowest benchmarks\r\n  --quick, -q           Do a \"quick\" run, where each benchmark function is run only once. This is useful to find basic errors in the benchmark functions\r\n                        faster. The results are unlikely to be useful, and thus are not saved.\r\n  -E ENV_SPEC, --environment ENV_SPEC\r\n                        Specify the environment and Python versions for running the benchmarks. String of the format 'environment_type:python_version', for\r\n                        example 'conda:3.12'. If the Python version is not specified, all those listed in the configuration file are run. The special\r\n                        environment type 'existing:/path/to/python' runs the benchmarks using the given Python interpreter; if the path is omitted, the Python\r\n                        running asv is used. For 'existing', the benchmarked project must be already installed, including all dependencies. By default, uses\r\n                        the values specified in the configuration file.\r\n  --python PYTHON       Same as --environment=:PYTHON\r\n  --set-commit-hash SET_COMMIT_HASH\r\n                        Set the commit hash to use when recording benchmark results. This makes results to be saved also when using an existing environment.\r\n  --launch-method {auto,spawn,forkserver}\r\n                        How to launch benchmarks. Choices: auto, spawn, forkserver\r\n  --dry-run, -n         Do not save any results to disk.\r\n  --machine MACHINE, -m MACHINE\r\n                        Use the given name to retrieve machine information. If not provided, the hostname is used. If no entry with that name is found, and\r\n                        there is only one entry in ~/.asv-machine.json, that one entry will be used.\r\n  --skip-existing-successful\r\n                        Skip running benchmarks that have previous successful results\r\n  --skip-existing-failed\r\n                        Skip running benchmarks that have previous failed results\r\n  --skip-existing-commits\r\n                        Skip running benchmarks for commits that have existing results\r\n  --skip-existing, -k   Skip running benchmarks that have previous successful or failed results\r\n  --record-samples      Store raw measurement samples, not only statistics\r\n  --append-samples      Combine new measurement samples with previous results, instead of discarding old results. Implies --record-samples. The previous run\r\n                        must also have been run with --record/append-samples.\r\n  --interleave-rounds   Interleave benchmarks with multiple rounds across commits. This can avoid measurement biases from commit ordering, can take longer.\r\n  --no-interleave-rounds\r\n  --no-pull             Do not pull the repository\r\n  --verbose, -v         Increase verbosity\r\n  --config CONFIG       Benchmark configuration file\r\n  --version             Print program version\r\n"]
[105.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[105.002, "i", "ls asv_bench/benchmarks | sed -n '1,200p'\r"]
[105.004, "o", "ls asv_bench/benchmarks | sed -n '1,200p'\r\n"]
[105.006, "o", "\u001b[?2004l\r\n__init__.py\r\nalgorithms.py\r\nalgos\r\narithmetic.py\r\narray.py\r\nattrs_caching.py\r\nboolean.py\r\ncategoricals.py\r\nctors.py\r\ndtypes.py\r\neval.py\r\nfinalize.py\r\nframe_ctor.py\r\nframe_methods.py\r\ngil.py\r\ngroupby.py\r\nhash_functions.py\r\nindex_cached_properties.py\r\nindex_object.py\r\nindexing.py\r\nindexing_engines.py\r\ninference.py\r\nio\r\njoin_merge.py\r\nlibs.py\r\nmultiindex_object.py\r\npackage.py\r\npandas_vb_common.py\r\nperiod.py\r\nplotting.py\r\nreindex.py\r\nreplace.py\r\nreshape.py\r\nrolling.py\r\nseries_methods.py\r\nsparse.py\r\nstat_ops.py\r\nstrftime.py\r\nstrings.py\r\ntimedelta.py\r\ntimeseries.py\r\ntslibs\r\n"]
[110.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[110.002, "i", "sed -n '700,820p' asv_bench/benchmarks/groupby.py\r"]
[110.004, "o", "sed -n '700,820p' asv_bench/benchmarks/groupby.py\r\n"]
[110.006, "o", "\u001b[?2004l\r\n        self.df = DataFrame(data)\r\n        data = {\r\n            \"a\": Categorical(np.random.randint(10000, size=N), ordered=True),\r\n            \"b\": arr,\r\n        }\r\n        self.df_ordered = DataFrame(data)\r\n        data = {\r\n            \"a\": Categorical(\r\n                np.random.randint(100, size=N), categories=np.arange(10000)\r\n            ),\r\n            \"b\": arr,\r\n        }\r\n        self.df_extra_cat = DataFrame(data)\r\n\r\n    def time_groupby_sort(self):\r\n        self.df.groupby(\"a\")[\"b\"].count()\r\n\r\n    def time_groupby_nosort(self):\r\n        self.df.groupby(\"a\", sort=False)[\"b\"].count()\r\n\r\n    def time_groupby_ordered_sort(self):\r\n        self.df_ordered.groupby(\"a\")[\"b\"].count()\r\n\r\n    def time_groupby_ordered_nosort(self):\r\n        self.df_ordered.groupby(\"a\", sort=False)[\"b\"].count()\r\n\r\n    def time_groupby_extra_cat_sort(self):\r\n        self.df_extra_cat.groupby(\"a\")[\"b\"].count()\r\n\r\n    def time_groupby_extra_cat_nosort(self):\r\n        self.df_extra_cat.groupby(\"a\", sort=False)[\"b\"].count()\r\n\r\n\r\nclass Datelike:\r\n    # GH 14338\r\n    params = [\"period_range\", \"date_range\", \"date_range_tz\"]\r\n    param_names = [\"grouper\"]\r\n\r\n    def setup(self, grouper):\r\n        N = 10**4\r\n        rng_map = {\r\n            \"period_range\": period_range,\r\n            \"date_range\": date_range,\r\n            \"date_range_tz\": partial(date_range, tz=\"US/Central\"),\r\n        }\r\n        self.grouper = rng_map[grouper](\"1900-01-01\", freq=\"D\", periods=N)\r\n        self.df = DataFrame(np.random.randn(10**4, 2))\r\n\r\n    def time_sum(self, grouper):\r\n        self.df.groupby(self.grouper).sum()\r\n\r\n\r\nclass SumBools:\r\n    # GH 2692\r\n    def setup(self):\r\n        N = 500\r\n        self.df = DataFrame({\"ii\": range(N), \"bb\": [True] * N})\r\n\r\n    def time_groupby_sum_booleans(self):\r\n        self.df.groupby(\"ii\").sum()\r\n\r\n\r\nclass SumMultiLevel:\r\n    # GH 9049\r\n    timeout = 120.0\r\n\r\n    def setup(self):\r\n        N = 50\r\n        self.df = DataFrame(\r\n            {\"A\": list(range(N)) * 2, \"B\": range(N * 2), \"C\": 1}\r\n        ).set_index([\"A\", \"B\"])\r\n\r\n    def time_groupby_sum_multiindex(self):\r\n        self.df.groupby(level=[0, 1]).sum()\r\n\r\n\r\nclass Transform:\r\n    def setup(self):\r\n        n1 = 400\r\n        n2 = 250\r\n        index = MultiIndex(\r\n            levels=[np.arange(n1), tm.makeStringIndex(n2)],\r\n            codes=[np.repeat(range(n1), n2).tolist(), list(range(n2)) * n1],\r\n            names=[\"lev1\", \"lev2\"],\r\n        )\r\n        arr = np.random.randn(n1 * n2, 3)\r\n        arr[::10000, 0] = np.nan\r\n        arr[1::10000, 1] = np.nan\r\n        arr[2::10000, 2] = np.nan\r\n        data = DataFrame(arr, index=index, columns=[\"col1\", \"col20\", \"col3\"])\r\n        self.df = data\r\n\r\n        n = 1000\r\n        self.df_wide = DataFrame(\r\n            np.random.randn(n, n),\r\n            index=np.random.choice(range(10), n),\r\n        )\r\n\r\n        n = 1_000_000\r\n        self.df_tall = DataFrame(\r\n            np.random.randn(n, 3),\r\n            index=np.random.randint(0, 5, n),\r\n        )\r\n\r\n        n = 20000\r\n        self.df1 = DataFrame(\r\n            np.random.randint(1, n, (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\r\n        )\r\n        self.df2 = self.df1.copy()\r\n        self.df2[\"jim\"] = self.df2[\"joe\"]\r\n\r\n        self.df3 = DataFrame(\r\n            np.random.randint(1, (n / 10), (n, 3)), columns=[\"jim\", \"joe\", \"jolie\"]\r\n        )\r\n        self.df4 = self.df3.copy()\r\n        self.df4[\"jim\"] = self.df4[\"joe\"]\r\n\r\n    def time_transform_lambda_max(self):\r\n        self.df.groupby(level=\"lev1\").transform(lambda x: max(x))\r\n\r\n    def time_transform_ufunc_max(self):\r\n"]
[115.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[115.002, "i", "sed -n '180,260p' asv_bench/benchmarks/index_object.py\r"]
[115.004, "o", "sed -n '180,260p' asv_bench/benchmarks/index_object.py\r\n"]
[115.006, "o", "\u001b[?2004l\r\n\r\n    def time_slice(self, dtype):\r\n        self.idx[:-1]\r\n\r\n    def time_slice_step(self, dtype):\r\n        self.idx[::2]\r\n\r\n    def time_get_loc(self, dtype):\r\n        self.idx.get_loc(self.key)\r\n\r\n    def time_get_loc_sorted(self, dtype):\r\n        self.sorted.get_loc(self.key)\r\n\r\n    def time_get_loc_non_unique(self, dtype):\r\n        self.non_unique.get_loc(self.key)\r\n\r\n    def time_get_loc_non_unique_sorted(self, dtype):\r\n        self.non_unique_sorted.get_loc(self.key)\r\n\r\n\r\nclass Float64IndexMethod:\r\n    # GH 13166\r\n    def setup(self):\r\n        N = 100_000\r\n        a = np.arange(N, dtype=np.float64)\r\n        self.ind = Index(a * 4.8000000418824129e-08)\r\n\r\n    def time_get_loc(self):\r\n        self.ind.get_loc(0)\r\n\r\n\r\nclass IntervalIndexMethod:\r\n    # GH 24813\r\n    params = [10**3, 10**5]\r\n\r\n    def setup(self, N):\r\n        left = np.append(np.arange(N), np.array(0))\r\n        right = np.append(np.arange(1, N + 1), np.array(1))\r\n        self.intv = IntervalIndex.from_arrays(left, right)\r\n        self.intv._engine\r\n\r\n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\r\n        self.intv2._engine\r\n\r\n        self.left = IntervalIndex.from_breaks(np.arange(N))\r\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))\r\n\r\n    def time_monotonic_inc(self, N):\r\n        self.intv.is_monotonic_increasing\r\n\r\n    def time_is_unique(self, N):\r\n        self.intv.is_unique\r\n\r\n    def time_intersection(self, N):\r\n        self.left.intersection(self.right)\r\n\r\n    def time_intersection_one_duplicate(self, N):\r\n        self.intv.intersection(self.right)\r\n\r\n    def time_intersection_both_duplicate(self, N):\r\n        self.intv.intersection(self.intv2)\r\n\r\n\r\nclass GC:\r\n    params = [1, 2, 5]\r\n\r\n    def create_use_drop(self):\r\n        idx = Index(list(range(1_000_000)))\r\n        idx._engine\r\n\r\n    def peakmem_gc_instances(self, N):\r\n        try:\r\n            gc.disable()\r\n\r\n            for _ in range(N):\r\n                self.create_use_drop()\r\n        finally:\r\n            gc.enable()\r\n\r\n\r\nfrom .pandas_vb_common import setup  # noqa: F401 isort:skip\r\n"]
[120.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[120.002, "i", "asv dev --config asv_bench/asv.conf.json -b \"groupby.SumMultiLevel.*\"\r"]
[120.004, "o", "asv dev --config asv_bench/asv.conf.json -b \"groupby.SumMultiLevel.*\"\r\n"]
[120.006, "o", "\u001b[?2004l\r\nusage: asv [-h] [--verbose] [--config CONFIG] [--version]\r\n           {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages} ...\r\nasv: error: invalid choice: 'dev' (choose from 'help', 'quickstart', 'machine', 'setup', 'run', 'continuous', 'find', 'rm', 'publish', 'preview', 'profile', 'update', 'show', 'compare', 'check', 'gh-pages')\r\n"]
[125.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[125.002, "i", "asv dev --config asv_bench/asv.conf.json -b \"index_object.IntervalIndexMethod.*\"\r"]
[125.004, "o", "asv dev --config asv_bench/asv.conf.json -b \"index_object.IntervalIndexMethod.*\"\r\n"]
[125.006, "o", "\u001b[?2004l\r\nusage: asv [-h] [--verbose] [--config CONFIG] [--version]\r\n           {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages} ...\r\nasv: error: invalid choice: 'dev' (choose from 'help', 'quickstart', 'machine', 'setup', 'run', 'continuous', 'find', 'rm', 'publish', 'preview', 'profile', 'update', 'show', 'compare', 'check', 'gh-pages')\r\n"]
[130.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[130.002, "i", "asv run --python=same --config asv_bench/asv.conf.json --quick --bench=\"groupby.SumMultiLevel.*\"\r"]
[130.004, "o", "asv run --python=same --config asv_bench/asv.conf.json --quick --bench=\"groupby.SumMultiLevel.*\"\r\n"]
[130.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mConfig file asv_bench/asv.conf.json not found.\u001b[0m\r\n"]
[135.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[135.002, "i", "asv run --python=same --config asv_bench/asv.conf.json --quick --bench=\"index_object.IntervalIndexMethod.*\"\r"]
[135.004, "o", "asv run --python=same --config asv_bench/asv.conf.json --quick --bench=\"index_object.IntervalIndexMethod.*\"\r\n"]
[135.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mConfig file asv_bench/asv.conf.json not found.\u001b[0m\r\n"]
[140.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[140.002, "i", "find pandas -name '*.so' | head -n 20\r"]
[140.004, "o", "find pandas -name '*.so' | head -n 20\r\n"]
[140.006, "o", "\u001b[?2004l\r\npandas/io/sas/_byteswap.cpython-38-x86_64-linux-gnu.so\r\npandas/io/sas/_sas.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/fields.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/nattype.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/timestamps.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/ccalendar.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/strptime.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/np_datetime.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/dtypes.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/timezones.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/vectorized.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/tzconversion.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/timedeltas.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/period.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/conversion.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/base.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/offsets.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/tslibs/parsing.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/window/aggregations.cpython-38-x86_64-linux-gnu.so\r\npandas/_libs/window/indexers.cpython-38-x86_64-linux-gnu.so\r\n"]
[145.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[145.002, "i", "python - << 'PY'\r"]
[145.004, "o", "python - << 'PY'\r\n"]
[145.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import pandas as pd, sys\r\n\u001b[?2004l\r\n\u001b[?2004h> print('pandas_version:', pd.__version__)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('pandas_file:', pd.__file__)\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\npandas_version: 0+untagged.31506.g5f584bd\r\npandas_file: /workspace/repo/pandas/__init__.py\r\n"]
[150.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[150.002, "i", "cd asv_bench\r"]
[150.004, "o", "cd asv_bench\r\n"]
[150.006, "o", "\u001b[?2004l\r\n"]
[155.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[155.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.*\"\r"]
[155.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.*\"\r\n"]
[155.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 5 total benchmarks (1 commits * 1 environments * 5 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[10.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection\u001b[0m                                                                                              ok\r\n[10.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    889\u00b10\u03bcs  \r\n              100000   8.35\u00b10ms \r\n             ======== ==========\r\n\r\n[20.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[20.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.18\u00b10ms \r\n              100000   92.6\u00b10ms \r\n             ======== ==========\r\n\r\n[30.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_one_duplicate\u001b[0m                                                                                ok\r\n[30.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    788\u00b10\u03bcs  \r\n              100000   8.05\u00b10ms \r\n             ======== ==========\r\n\r\n[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_is_unique\u001b[0m                                                                                                 ok\r\n[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    250\u00b10\u03bcs  \r\n              100000   3.65\u00b10ms \r\n             ======== ==========\r\n\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_monotonic_inc\u001b[0m                                                                                             ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    77.7\u00b10\u03bcs \r\n              100000   326\u00b10\u03bcs  \r\n             ======== ==========\r\n\r\n"]
[160.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[160.002, "i", "asv run --python=same --quick --bench=\"groupby.SumMultiLevel.*\"\r"]
[160.004, "o", "asv run --python=same --quick --bench=\"groupby.SumMultiLevel.*\"\r\n"]
[160.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mgroupby.SumMultiLevel.time_groupby_sum_multiindex\u001b[0m                                                                                         1.18\u00b10ms\r\n"]
[165.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[165.002, "i", "asv run --python=same --quick --bench=\"tslibs.timestamp.*\"\r"]
[165.004, "o", "asv run --python=same --quick --bench=\"tslibs.timestamp.*\"\r\n"]
[165.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 37 total benchmarks (1 commits * 1 environments * 37 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[ 1.35%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampAcrossDst.time_replace_across_dst\u001b[0m                                                                               95.5\u00b10\u03bcs\r\n[ 2.70%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_from_datetime_aware\u001b[0m                                                                           14.2\u00b10\u03bcs\r\n[ 4.05%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_from_datetime_unaware\u001b[0m                                                                         17.6\u00b10\u03bcs\r\n[ 5.41%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_from_npdatetime64\u001b[0m                                                                             17.7\u00b10\u03bcs\r\n[ 6.76%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_from_pd_timestamp\u001b[0m                                                                             1.93\u00b10\u03bcs\r\n[ 8.11%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_fromordinal\u001b[0m                                                                                   33.6\u00b10\u03bcs\r\n[ 9.46%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_fromtimestamp\u001b[0m                                                                                 31.9\u00b10\u03bcs\r\n[10.81%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_parse_dateutil\u001b[0m                                                                                1.34\u00b10ms\r\n[12.16%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_parse_iso8601_no_tz\u001b[0m                                                                           10.9\u00b10\u03bcs\r\n[13.51%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_parse_iso8601_tz\u001b[0m                                                                               189\u00b10\u03bcs\r\n[14.86%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_parse_now\u001b[0m                                                                                     17.7\u00b10\u03bcs\r\n[16.22%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampConstruction.time_parse_today\u001b[0m                                                                                   18.8\u00b10\u03bcs\r\n[17.57%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampOps.time_ceil\u001b[0m                                                                                                         ok\r\n[17.57%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== =========\u001b[0m\r\n                                       tz                                   \r\n             ----------------------------------------------------- ---------\r\n                                      None                          711\u00b10\u03bcs \r\n                             datetime.timezone.utc                  717\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   562\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    707\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        486\u00b10\u03bcs \r\n                                   tzlocal()                        706\u00b10\u03bcs \r\n             ===================================================== =========\r\n\r\n[18.92%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampOps.time_floor\u001b[0m                                                                                                        ok\r\n[18.92%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== =========\u001b[0m\r\n                                       tz                                   \r\n             ----------------------------------------------------- ---------\r\n                                      None                          606\u00b10\u03bcs \r\n                             datetime.timezone.utc                  582\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   639\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    498\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        466\u00b10\u03bcs \r\n                                   tzlocal()                        635\u00b10\u03bcs \r\n             ===================================================== =========\r\n\r\n[20.27%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampOps.time_normalize\u001b[0m                                                                                                    ok\r\n[20.27%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          124\u00b10\u03bcs  \r\n                             datetime.timezone.utc                  32.2\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   60.9\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    67.3\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        60.4\u00b10\u03bcs \r\n                                   tzlocal()                        54.0\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[21.62%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampOps.time_replace_None\u001b[0m                                                                                                 ok\r\n[21.62%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          32.0\u00b10\u03bcs \r\n                             datetime.timezone.utc                  37.4\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   54.7\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    53.2\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        42.4\u00b10\u03bcs \r\n                                   tzlocal()                        53.1\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[22.97%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampOps.time_replace_tz\u001b[0m                                                                                                   ok\r\n[22.97%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== =========\u001b[0m\r\n                                       tz                                   \r\n             ----------------------------------------------------- ---------\r\n                                      None                          755\u00b10\u03bcs \r\n                             datetime.timezone.utc                  756\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   812\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    756\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        779\u00b10\u03bcs \r\n                                   tzlocal()                        751\u00b10\u03bcs \r\n             ===================================================== =========\r\n\r\n[24.32%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampOps.time_to_julian_date\u001b[0m                                                                                               ok\r\n[24.32%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== =========\u001b[0m\r\n                                       tz                                   \r\n             ----------------------------------------------------- ---------\r\n                                      None                          215\u00b10\u03bcs \r\n                             datetime.timezone.utc                  233\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   130\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    127\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        116\u00b10\u03bcs \r\n                                   tzlocal()                        247\u00b10\u03bcs \r\n             ===================================================== =========\r\n\r\n[25.68%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampOps.time_to_pydatetime\u001b[0m                                                                                                ok\r\n[25.68%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          16.8\u00b10\u03bcs \r\n                             datetime.timezone.utc                  20.4\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   15.7\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    14.1\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        19.3\u00b10\u03bcs \r\n                                   tzlocal()                        15.1\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[27.03%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampOps.time_tz_convert\u001b[0m                                                                                                   ok\r\n[27.03%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          8.97\u00b10\u03bcs \r\n                             datetime.timezone.utc                  24.3\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   44.0\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    42.9\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        37.6\u00b10\u03bcs \r\n                                   tzlocal()                        45.2\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[28.38%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampOps.time_tz_localize\u001b[0m                                                                                                  ok\r\n[28.38%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          37.0\u00b10\u03bcs \r\n                             datetime.timezone.utc                  10.8\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   7.03\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    6.21\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        7.24\u00b10\u03bcs \r\n                                   tzlocal()                        8.07\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[29.73%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_dayofweek\u001b[0m                                                                                             ok\r\n[29.73%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          12.0\u00b10\u03bcs \r\n                             datetime.timezone.utc                  13.8\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   9.89\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    11.1\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        15.5\u00b10\u03bcs \r\n                                   tzlocal()                        12.4\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[31.08%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_dayofyear\u001b[0m                                                                                             ok\r\n[31.08%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          10.7\u00b10\u03bcs \r\n                             datetime.timezone.utc                  9.65\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   8.55\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    8.32\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        9.38\u00b10\u03bcs \r\n                                   tzlocal()                        6.49\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[32.43%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_days_in_month\u001b[0m                                                                                         ok\r\n[32.43%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          10.6\u00b10\u03bcs \r\n                             datetime.timezone.utc                  11.2\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   9.44\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    9.49\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        9.97\u00b10\u03bcs \r\n                                   tzlocal()                        10.5\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[33.78%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_is_leap_year\u001b[0m                                                                                          ok\r\n[33.78%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          6.10\u00b10\u03bcs \r\n                             datetime.timezone.utc                  6.01\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   5.92\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    4.58\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        5.25\u00b10\u03bcs \r\n                                   tzlocal()                        5.45\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[35.14%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_is_month_end\u001b[0m                                                                                          ok\r\n[35.14%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          12.7\u00b10\u03bcs \r\n                             datetime.timezone.utc                  10.9\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   8.55\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    10.3\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        10.6\u00b10\u03bcs \r\n                                   tzlocal()                        8.09\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[36.49%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_is_month_start\u001b[0m                                                                                        ok\r\n[36.49%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          5.12\u00b10\u03bcs \r\n                             datetime.timezone.utc                  5.32\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   4.21\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    3.36\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        6.51\u00b10\u03bcs \r\n                                   tzlocal()                        4.49\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[37.84%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_is_quarter_end\u001b[0m                                                                                        ok\r\n[37.84%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          5.78\u00b10\u03bcs \r\n                             datetime.timezone.utc                  6.38\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   5.51\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    6.39\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        6.26\u00b10\u03bcs \r\n                                   tzlocal()                        3.67\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[39.19%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_is_quarter_start\u001b[0m                                                                                      ok\r\n[39.19%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          6.66\u00b10\u03bcs \r\n                             datetime.timezone.utc                  7.51\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   6.17\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    5.38\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        6.66\u00b10\u03bcs \r\n                                   tzlocal()                        6.33\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[40.54%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_is_year_end\u001b[0m                                                                                           ok\r\n[40.54%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          6.30\u00b10\u03bcs \r\n                             datetime.timezone.utc                  5.18\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   4.21\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    4.61\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        6.79\u00b10\u03bcs \r\n                                   tzlocal()                        4.58\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[41.89%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_is_year_start\u001b[0m                                                                                         ok\r\n[41.89%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          6.42\u00b10\u03bcs \r\n                             datetime.timezone.utc                  5.45\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   5.46\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    6.09\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        5.29\u00b10\u03bcs \r\n                                   tzlocal()                        3.99\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[43.24%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_microsecond\u001b[0m                                                                                           ok\r\n[43.24%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          3.79\u00b10\u03bcs \r\n                             datetime.timezone.utc                  4.32\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   1.84\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    1.76\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        3.28\u00b10\u03bcs \r\n                                   tzlocal()                        2.16\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[44.59%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_month_name\u001b[0m                                                                                            ok\r\n[44.59%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          163\u00b10\u03bcs  \r\n                             datetime.timezone.utc                  148\u00b10\u03bcs  \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   78.4\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    70.2\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        84.9\u00b10\u03bcs \r\n                                   tzlocal()                        139\u00b10\u03bcs  \r\n             ===================================================== ==========\r\n\r\n[45.95%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_quarter\u001b[0m                                                                                               ok\r\n[45.95%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          8.44\u00b10\u03bcs \r\n                             datetime.timezone.utc                  6.76\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   5.79\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    5.70\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        7.33\u00b10\u03bcs \r\n                                   tzlocal()                        5.36\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[47.30%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_tz\u001b[0m                                                                                                    ok\r\n[47.30%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          10.0\u00b10\u03bcs \r\n                             datetime.timezone.utc                  8.69\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   9.03\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    6.45\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        8.21\u00b10\u03bcs \r\n                                   tzlocal()                        6.61\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[48.65%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_week\u001b[0m                                                                                                  ok\r\n[48.65%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          11.0\u00b10\u03bcs \r\n                             datetime.timezone.utc                  8.99\u00b10\u03bcs \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   8.65\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    8.90\u00b10\u03bcs \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        8.86\u00b10\u03bcs \r\n                                   tzlocal()                        8.90\u00b10\u03bcs \r\n             ===================================================== ==========\r\n\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timestamp.TimestampProperties.time_weekday_name\u001b[0m                                                                                          ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m===================================================== ==========\u001b[0m\r\n                                       tz                                    \r\n             ----------------------------------------------------- ----------\r\n                                      None                          148\u00b10\u03bcs  \r\n                             datetime.timezone.utc                  146\u00b10\u03bcs  \r\n              datetime.timezone(datetime.timedelta(seconds=3600))   87.3\u00b10\u03bcs \r\n                <DstTzInfo 'US/Pacific' LMT-1 day, 16:07:00 STD>    110\u00b10\u03bcs  \r\n                    tzfile('/usr/share/zoneinfo/Asia/Tokyo')        64.4\u00b10\u03bcs \r\n                                   tzlocal()                        142\u00b10\u03bcs  \r\n             ===================================================== ==========\r\n\r\n"]
[170.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[170.002, "i", "asv profile --python=same IntervalIndexMethod.time_intersection\r"]
[170.004, "o", "asv profile --python=same IntervalIndexMethod.time_intersection\r\n"]
[170.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;31m'IntervalIndexMethod.time_intersection' benchmark not found\u001b[0m\r\n"]
[175.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[175.002, "i", "cd ..\r"]
[175.004, "o", "cd ..\r\n"]
[175.006, "o", "\u001b[?2004l\r\n"]
[180.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[180.002, "i", "sed -n '1,260p' pandas/core/indexes/interval.py\r"]
[180.004, "o", "sed -n '1,260p' pandas/core/indexes/interval.py\r\n"]
[180.006, "o", "\u001b[?2004l\r\n\"\"\" define the IntervalIndex \"\"\"\r\nfrom __future__ import annotations\r\n\r\nfrom operator import (\r\n    le,\r\n    lt,\r\n)\r\nimport textwrap\r\nfrom typing import (\r\n    Any,\r\n    Hashable,\r\n    Literal,\r\n)\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.interval import (\r\n    Interval,\r\n    IntervalMixin,\r\n    IntervalTree,\r\n)\r\nfrom pandas._libs.tslibs import (\r\n    BaseOffset,\r\n    Timedelta,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    Dtype,\r\n    DtypeObj,\r\n    IntervalClosedType,\r\n    npt,\r\n)\r\nfrom pandas.errors import InvalidIndexError\r\nfrom pandas.util._decorators import (\r\n    Appender,\r\n    cache_readonly,\r\n)\r\nfrom pandas.util._exceptions import rewrite_exception\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    find_common_type,\r\n    infer_dtype_from_scalar,\r\n    maybe_box_datetimelike,\r\n    maybe_downcast_numeric,\r\n    maybe_upcast_numeric_to_64bit,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_platform_int,\r\n    is_datetime64tz_dtype,\r\n    is_datetime_or_timedelta_dtype,\r\n    is_dtype_equal,\r\n    is_float,\r\n    is_float_dtype,\r\n    is_integer,\r\n    is_integer_dtype,\r\n    is_interval_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_object_dtype,\r\n    is_scalar,\r\n)\r\nfrom pandas.core.dtypes.dtypes import IntervalDtype\r\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\r\n\r\nfrom pandas.core.algorithms import unique\r\nfrom pandas.core.arrays.interval import (\r\n    IntervalArray,\r\n    _interval_shared_docs,\r\n)\r\nimport pandas.core.common as com\r\nfrom pandas.core.indexers import is_valid_positional_slice\r\nimport pandas.core.indexes.base as ibase\r\nfrom pandas.core.indexes.base import (\r\n    Index,\r\n    _index_shared_docs,\r\n    ensure_index,\r\n    maybe_extract_name,\r\n)\r\nfrom pandas.core.indexes.datetimes import (\r\n    DatetimeIndex,\r\n    date_range,\r\n)\r\nfrom pandas.core.indexes.extension import (\r\n    ExtensionIndex,\r\n    inherit_names,\r\n)\r\nfrom pandas.core.indexes.multi import MultiIndex\r\nfrom pandas.core.indexes.timedeltas import (\r\n    TimedeltaIndex,\r\n    timedelta_range,\r\n)\r\n\r\n_index_doc_kwargs = dict(ibase._index_doc_kwargs)\r\n\r\n_index_doc_kwargs.update(\r\n    {\r\n        \"klass\": \"IntervalIndex\",\r\n        \"qualname\": \"IntervalIndex\",\r\n        \"target_klass\": \"IntervalIndex or list of Intervals\",\r\n        \"name\": textwrap.dedent(\r\n            \"\"\"\\\r\n         name : object, optional\r\n              Name to be stored in the index.\r\n         \"\"\"\r\n        ),\r\n    }\r\n)\r\n\r\n\r\ndef _get_next_label(label):\r\n    dtype = getattr(label, \"dtype\", type(label))\r\n    if isinstance(label, (Timestamp, Timedelta)):\r\n        dtype = \"datetime64\"\r\n    if is_datetime_or_timedelta_dtype(dtype) or is_datetime64tz_dtype(dtype):\r\n        return label + np.timedelta64(1, \"ns\")\r\n    elif is_integer_dtype(dtype):\r\n        return label + 1\r\n    elif is_float_dtype(dtype):\r\n        return np.nextafter(label, np.infty)\r\n    else:\r\n        raise TypeError(f\"cannot determine next label for type {repr(type(label))}\")\r\n\r\n\r\ndef _get_prev_label(label):\r\n    dtype = getattr(label, \"dtype\", type(label))\r\n    if isinstance(label, (Timestamp, Timedelta)):\r\n        dtype = \"datetime64\"\r\n    if is_datetime_or_timedelta_dtype(dtype) or is_datetime64tz_dtype(dtype):\r\n        return label - np.timedelta64(1, \"ns\")\r\n    elif is_integer_dtype(dtype):\r\n        return label - 1\r\n    elif is_float_dtype(dtype):\r\n        return np.nextafter(label, -np.infty)\r\n    else:\r\n        raise TypeError(f\"cannot determine next label for type {repr(type(label))}\")\r\n\r\n\r\ndef _new_IntervalIndex(cls, d):\r\n    \"\"\"\r\n    This is called upon unpickling, rather than the default which doesn't have\r\n    arguments and breaks __new__.\r\n    \"\"\"\r\n    return cls.from_arrays(**d)\r\n\r\n\r\n@Appender(\r\n    _interval_shared_docs[\"class\"]\r\n    % {\r\n        \"klass\": \"IntervalIndex\",\r\n        \"summary\": \"Immutable index of intervals that are closed on the same side.\",\r\n        \"name\": _index_doc_kwargs[\"name\"],\r\n        \"versionadded\": \"0.20.0\",\r\n        \"extra_attributes\": \"is_overlapping\\nvalues\\n\",\r\n        \"extra_methods\": \"\",\r\n        \"examples\": textwrap.dedent(\r\n            \"\"\"\\\r\n    Examples\r\n    --------\r\n    A new ``IntervalIndex`` is typically constructed using\r\n    :func:`interval_range`:\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    It may also be constructed using one of the constructor\r\n    methods: :meth:`IntervalIndex.from_arrays`,\r\n    :meth:`IntervalIndex.from_breaks`, and :meth:`IntervalIndex.from_tuples`.\r\n\r\n    See further examples in the doc strings of ``interval_range`` and the\r\n    mentioned constructor methods.\r\n    \"\"\"\r\n        ),\r\n    }\r\n)\r\n@inherit_names([\"set_closed\", \"to_tuples\"], IntervalArray, wrap=True)\r\n@inherit_names(\r\n    [\r\n        \"__array__\",\r\n        \"overlaps\",\r\n        \"contains\",\r\n        \"closed_left\",\r\n        \"closed_right\",\r\n        \"open_left\",\r\n        \"open_right\",\r\n        \"is_empty\",\r\n    ],\r\n    IntervalArray,\r\n)\r\n@inherit_names([\"is_non_overlapping_monotonic\", \"closed\"], IntervalArray, cache=True)\r\nclass IntervalIndex(ExtensionIndex):\r\n    _typ = \"intervalindex\"\r\n\r\n    # annotate properties pinned via inherit_names\r\n    closed: IntervalClosedType\r\n    is_non_overlapping_monotonic: bool\r\n    closed_left: bool\r\n    closed_right: bool\r\n    open_left: bool\r\n    open_right: bool\r\n\r\n    _data: IntervalArray\r\n    _values: IntervalArray\r\n    _can_hold_strings = False\r\n    _data_cls = IntervalArray\r\n\r\n    # --------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __new__(\r\n        cls,\r\n        data,\r\n        closed=None,\r\n        dtype: Dtype | None = None,\r\n        copy: bool = False,\r\n        name: Hashable = None,\r\n        verify_integrity: bool = True,\r\n    ) -> IntervalIndex:\r\n\r\n        name = maybe_extract_name(name, data, cls)\r\n\r\n        with rewrite_exception(\"IntervalArray\", cls.__name__):\r\n            array = IntervalArray(\r\n                data,\r\n                closed=closed,\r\n                copy=copy,\r\n                dtype=dtype,\r\n                verify_integrity=verify_integrity,\r\n            )\r\n\r\n        return cls._simple_new(array, name)\r\n\r\n    @classmethod\r\n    @Appender(\r\n        _interval_shared_docs[\"from_breaks\"]\r\n        % {\r\n            \"klass\": \"IntervalIndex\",\r\n            \"name\": textwrap.dedent(\r\n                \"\"\"\r\n             name : str, optional\r\n                  Name of the resulting IntervalIndex.\"\"\"\r\n            ),\r\n            \"examples\": textwrap.dedent(\r\n                \"\"\"\\\r\n        Examples\r\n        --------\r\n        >>> pd.IntervalIndex.from_breaks([0, 1, 2, 3])\r\n        IntervalIndex([(0, 1], (1, 2], (2, 3]],\r\n                      dtype='interval[int64, right]')\r\n        \"\"\"\r\n            ),\r\n        }\r\n    )\r\n    def from_breaks(\r\n        cls,\r\n        breaks,\r\n        closed: IntervalClosedType | None = \"right\",\r\n        name: Hashable = None,\r\n"]
[185.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[185.002, "i", "grep -n \"def intersection\" -n pandas/core/indexes/interval.py\r"]
[185.004, "o", "grep -n \"def intersection\" -n pandas/core/indexes/interval.py\r\n"]
[185.006, "o", "\u001b[?2004l\r\n"]
[190.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[190.002, "i", "sed -n '1,500p' pandas/core/indexes/interval.py | sed -n '1,500p'\r"]
[190.004, "o", "sed -n '1,500p' pandas/core/indexes/interval.py | sed -n '1,500p'\r\n"]
[190.006, "o", "\u001b[?2004l\r\n\"\"\" define the IntervalIndex \"\"\"\r\nfrom __future__ import annotations\r\n\r\nfrom operator import (\r\n    le,\r\n    lt,\r\n)\r\nimport textwrap\r\nfrom typing import (\r\n    Any,\r\n    Hashable,\r\n    Literal,\r\n)\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.interval import (\r\n    Interval,\r\n    IntervalMixin,\r\n    IntervalTree,\r\n)\r\nfrom pandas._libs.tslibs import (\r\n    BaseOffset,\r\n    Timedelta,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    Dtype,\r\n    DtypeObj,\r\n    IntervalClosedType,\r\n    npt,\r\n)\r\nfrom pandas.errors import InvalidIndexError\r\nfrom pandas.util._decorators import (\r\n    Appender,\r\n    cache_readonly,\r\n)\r\nfrom pandas.util._exceptions import rewrite_exception\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    find_common_type,\r\n    infer_dtype_from_scalar,\r\n    maybe_box_datetimelike,\r\n    maybe_downcast_numeric,\r\n    maybe_upcast_numeric_to_64bit,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_platform_int,\r\n    is_datetime64tz_dtype,\r\n    is_datetime_or_timedelta_dtype,\r\n    is_dtype_equal,\r\n    is_float,\r\n    is_float_dtype,\r\n    is_integer,\r\n    is_integer_dtype,\r\n    is_interval_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_object_dtype,\r\n    is_scalar,\r\n)\r\nfrom pandas.core.dtypes.dtypes import IntervalDtype\r\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\r\n\r\nfrom pandas.core.algorithms import unique\r\nfrom pandas.core.arrays.interval import (\r\n    IntervalArray,\r\n    _interval_shared_docs,\r\n)\r\nimport pandas.core.common as com\r\nfrom pandas.core.indexers import is_valid_positional_slice\r\nimport pandas.core.indexes.base as ibase\r\nfrom pandas.core.indexes.base import (\r\n    Index,\r\n    _index_shared_docs,\r\n    ensure_index,\r\n    maybe_extract_name,\r\n)\r\nfrom pandas.core.indexes.datetimes import (\r\n    DatetimeIndex,\r\n    date_range,\r\n)\r\nfrom pandas.core.indexes.extension import (\r\n    ExtensionIndex,\r\n    inherit_names,\r\n)\r\nfrom pandas.core.indexes.multi import MultiIndex\r\nfrom pandas.core.indexes.timedeltas import (\r\n    TimedeltaIndex,\r\n    timedelta_range,\r\n)\r\n\r\n_index_doc_kwargs = dict(ibase._index_doc_kwargs)\r\n\r\n_index_doc_kwargs.update(\r\n    {\r\n        \"klass\": \"IntervalIndex\",\r\n        \"qualname\": \"IntervalIndex\",\r\n        \"target_klass\": \"IntervalIndex or list of Intervals\",\r\n        \"name\": textwrap.dedent(\r\n            \"\"\"\\\r\n         name : object, optional\r\n              Name to be stored in the index.\r\n         \"\"\"\r\n        ),\r\n    }\r\n)\r\n\r\n\r\ndef _get_next_label(label):\r\n    dtype = getattr(label, \"dtype\", type(label))\r\n    if isinstance(label, (Timestamp, Timedelta)):\r\n        dtype = \"datetime64\"\r\n    if is_datetime_or_timedelta_dtype(dtype) or is_datetime64tz_dtype(dtype):\r\n        return label + np.timedelta64(1, \"ns\")\r\n    elif is_integer_dtype(dtype):\r\n        return label + 1\r\n    elif is_float_dtype(dtype):\r\n        return np.nextafter(label, np.infty)\r\n    else:\r\n        raise TypeError(f\"cannot determine next label for type {repr(type(label))}\")\r\n\r\n\r\ndef _get_prev_label(label):\r\n    dtype = getattr(label, \"dtype\", type(label))\r\n    if isinstance(label, (Timestamp, Timedelta)):\r\n        dtype = \"datetime64\"\r\n    if is_datetime_or_timedelta_dtype(dtype) or is_datetime64tz_dtype(dtype):\r\n        return label - np.timedelta64(1, \"ns\")\r\n    elif is_integer_dtype(dtype):\r\n        return label - 1\r\n    elif is_float_dtype(dtype):\r\n        return np.nextafter(label, -np.infty)\r\n    else:\r\n        raise TypeError(f\"cannot determine next label for type {repr(type(label))}\")\r\n\r\n\r\ndef _new_IntervalIndex(cls, d):\r\n    \"\"\"\r\n    This is called upon unpickling, rather than the default which doesn't have\r\n    arguments and breaks __new__.\r\n    \"\"\"\r\n    return cls.from_arrays(**d)\r\n\r\n\r\n@Appender(\r\n    _interval_shared_docs[\"class\"]\r\n    % {\r\n        \"klass\": \"IntervalIndex\",\r\n        \"summary\": \"Immutable index of intervals that are closed on the same side.\",\r\n        \"name\": _index_doc_kwargs[\"name\"],\r\n        \"versionadded\": \"0.20.0\",\r\n        \"extra_attributes\": \"is_overlapping\\nvalues\\n\",\r\n        \"extra_methods\": \"\",\r\n        \"examples\": textwrap.dedent(\r\n            \"\"\"\\\r\n    Examples\r\n    --------\r\n    A new ``IntervalIndex`` is typically constructed using\r\n    :func:`interval_range`:\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    It may also be constructed using one of the constructor\r\n    methods: :meth:`IntervalIndex.from_arrays`,\r\n    :meth:`IntervalIndex.from_breaks`, and :meth:`IntervalIndex.from_tuples`.\r\n\r\n    See further examples in the doc strings of ``interval_range`` and the\r\n    mentioned constructor methods.\r\n    \"\"\"\r\n        ),\r\n    }\r\n)\r\n@inherit_names([\"set_closed\", \"to_tuples\"], IntervalArray, wrap=True)\r\n@inherit_names(\r\n    [\r\n        \"__array__\",\r\n        \"overlaps\",\r\n        \"contains\",\r\n        \"closed_left\",\r\n        \"closed_right\",\r\n        \"open_left\",\r\n        \"open_right\",\r\n        \"is_empty\",\r\n    ],\r\n    IntervalArray,\r\n)\r\n@inherit_names([\"is_non_overlapping_monotonic\", \"closed\"], IntervalArray, cache=True)\r\nclass IntervalIndex(ExtensionIndex):\r\n    _typ = \"intervalindex\"\r\n\r\n    # annotate properties pinned via inherit_names\r\n    closed: IntervalClosedType\r\n    is_non_overlapping_monotonic: bool\r\n    closed_left: bool\r\n    closed_right: bool\r\n    open_left: bool\r\n    open_right: bool\r\n\r\n    _data: IntervalArray\r\n    _values: IntervalArray\r\n    _can_hold_strings = False\r\n    _data_cls = IntervalArray\r\n\r\n    # --------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __new__(\r\n        cls,\r\n        data,\r\n        closed=None,\r\n        dtype: Dtype | None = None,\r\n        copy: bool = False,\r\n        name: Hashable = None,\r\n        verify_integrity: bool = True,\r\n    ) -> IntervalIndex:\r\n\r\n        name = maybe_extract_name(name, data, cls)\r\n\r\n        with rewrite_exception(\"IntervalArray\", cls.__name__):\r\n            array = IntervalArray(\r\n                data,\r\n                closed=closed,\r\n                copy=copy,\r\n                dtype=dtype,\r\n                verify_integrity=verify_integrity,\r\n            )\r\n\r\n        return cls._simple_new(array, name)\r\n\r\n    @classmethod\r\n    @Appender(\r\n        _interval_shared_docs[\"from_breaks\"]\r\n        % {\r\n            \"klass\": \"IntervalIndex\",\r\n            \"name\": textwrap.dedent(\r\n                \"\"\"\r\n             name : str, optional\r\n                  Name of the resulting IntervalIndex.\"\"\"\r\n            ),\r\n            \"examples\": textwrap.dedent(\r\n                \"\"\"\\\r\n        Examples\r\n        --------\r\n        >>> pd.IntervalIndex.from_breaks([0, 1, 2, 3])\r\n        IntervalIndex([(0, 1], (1, 2], (2, 3]],\r\n                      dtype='interval[int64, right]')\r\n        \"\"\"\r\n            ),\r\n        }\r\n    )\r\n    def from_breaks(\r\n        cls,\r\n        breaks,\r\n        closed: IntervalClosedType | None = \"right\",\r\n        name: Hashable = None,\r\n        copy: bool = False,\r\n        dtype: Dtype | None = None,\r\n    ) -> IntervalIndex:\r\n        with rewrite_exception(\"IntervalArray\", cls.__name__):\r\n            array = IntervalArray.from_breaks(\r\n                breaks, closed=closed, copy=copy, dtype=dtype\r\n            )\r\n        return cls._simple_new(array, name=name)\r\n\r\n    @classmethod\r\n    @Appender(\r\n        _interval_shared_docs[\"from_arrays\"]\r\n        % {\r\n            \"klass\": \"IntervalIndex\",\r\n            \"name\": textwrap.dedent(\r\n                \"\"\"\r\n             name : str, optional\r\n                  Name of the resulting IntervalIndex.\"\"\"\r\n            ),\r\n            \"examples\": textwrap.dedent(\r\n                \"\"\"\\\r\n        Examples\r\n        --------\r\n        >>> pd.IntervalIndex.from_arrays([0, 1, 2], [1, 2, 3])\r\n        IntervalIndex([(0, 1], (1, 2], (2, 3]],\r\n                      dtype='interval[int64, right]')\r\n        \"\"\"\r\n            ),\r\n        }\r\n    )\r\n    def from_arrays(\r\n        cls,\r\n        left,\r\n        right,\r\n        closed: IntervalClosedType = \"right\",\r\n        name: Hashable = None,\r\n        copy: bool = False,\r\n        dtype: Dtype | None = None,\r\n    ) -> IntervalIndex:\r\n        with rewrite_exception(\"IntervalArray\", cls.__name__):\r\n            array = IntervalArray.from_arrays(\r\n                left, right, closed, copy=copy, dtype=dtype\r\n            )\r\n        return cls._simple_new(array, name=name)\r\n\r\n    @classmethod\r\n    @Appender(\r\n        _interval_shared_docs[\"from_tuples\"]\r\n        % {\r\n            \"klass\": \"IntervalIndex\",\r\n            \"name\": textwrap.dedent(\r\n                \"\"\"\r\n             name : str, optional\r\n                  Name of the resulting IntervalIndex.\"\"\"\r\n            ),\r\n            \"examples\": textwrap.dedent(\r\n                \"\"\"\\\r\n        Examples\r\n        --------\r\n        >>> pd.IntervalIndex.from_tuples([(0, 1), (1, 2)])\r\n        IntervalIndex([(0, 1], (1, 2]],\r\n                       dtype='interval[int64, right]')\r\n        \"\"\"\r\n            ),\r\n        }\r\n    )\r\n    def from_tuples(\r\n        cls,\r\n        data,\r\n        closed: IntervalClosedType = \"right\",\r\n        name: Hashable = None,\r\n        copy: bool = False,\r\n        dtype: Dtype | None = None,\r\n    ) -> IntervalIndex:\r\n        with rewrite_exception(\"IntervalArray\", cls.__name__):\r\n            arr = IntervalArray.from_tuples(data, closed=closed, copy=copy, dtype=dtype)\r\n        return cls._simple_new(arr, name=name)\r\n\r\n    # --------------------------------------------------------------------\r\n    # error: Return type \"IntervalTree\" of \"_engine\" incompatible with return type\r\n    # \"Union[IndexEngine, ExtensionEngine]\" in supertype \"Index\"\r\n    @cache_readonly\r\n    def _engine(self) -> IntervalTree:  # type: ignore[override]\r\n        # IntervalTree does not supports numpy array unless they are 64 bit\r\n        left = self._maybe_convert_i8(self.left)\r\n        left = maybe_upcast_numeric_to_64bit(left)\r\n        right = self._maybe_convert_i8(self.right)\r\n        right = maybe_upcast_numeric_to_64bit(right)\r\n        return IntervalTree(left, right, closed=self.closed)\r\n\r\n    def __contains__(self, key: Any) -> bool:\r\n        \"\"\"\r\n        return a boolean if this key is IN the index\r\n        We *only* accept an Interval\r\n\r\n        Parameters\r\n        ----------\r\n        key : Interval\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n        \"\"\"\r\n        hash(key)\r\n        if not isinstance(key, Interval):\r\n            if is_valid_na_for_dtype(key, self.dtype):\r\n                return self.hasnans\r\n            return False\r\n\r\n        try:\r\n            self.get_loc(key)\r\n            return True\r\n        except KeyError:\r\n            return False\r\n\r\n    @cache_readonly\r\n    def _multiindex(self) -> MultiIndex:\r\n        return MultiIndex.from_arrays([self.left, self.right], names=[\"left\", \"right\"])\r\n\r\n    def __reduce__(self):\r\n        d = {\r\n            \"left\": self.left,\r\n            \"right\": self.right,\r\n            \"closed\": self.closed,\r\n            \"name\": self.name,\r\n        }\r\n        return _new_IntervalIndex, (type(self), d), None\r\n\r\n    @property\r\n    def inferred_type(self) -> str:\r\n        \"\"\"Return a string of the type inferred from the values\"\"\"\r\n        return \"interval\"\r\n\r\n    @Appender(Index.memory_usage.__doc__)\r\n    def memory_usage(self, deep: bool = False) -> int:\r\n        # we don't use an explicit engine\r\n        # so return the bytes here\r\n        return self.left.memory_usage(deep=deep) + self.right.memory_usage(deep=deep)\r\n\r\n    # IntervalTree doesn't have a is_monotonic_decreasing, so have to override\r\n    #  the Index implementation\r\n    @cache_readonly\r\n    def is_monotonic_decreasing(self) -> bool:\r\n        \"\"\"\r\n        Return True if the IntervalIndex is monotonic decreasing (only equal or\r\n        decreasing values), else False\r\n        \"\"\"\r\n        return self[::-1].is_monotonic_increasing\r\n\r\n    @cache_readonly\r\n    def is_unique(self) -> bool:\r\n        \"\"\"\r\n        Return True if the IntervalIndex contains unique elements, else False.\r\n        \"\"\"\r\n        left = self.left\r\n        right = self.right\r\n\r\n        if self.isna().sum() > 1:\r\n            return False\r\n\r\n        if left.is_unique or right.is_unique:\r\n            return True\r\n\r\n        seen_pairs = set()\r\n        check_idx = np.where(left.duplicated(keep=False))[0]\r\n        for idx in check_idx:\r\n            pair = (left[idx], right[idx])\r\n            if pair in seen_pairs:\r\n                return False\r\n            seen_pairs.add(pair)\r\n\r\n        return True\r\n\r\n    @property\r\n    def is_overlapping(self) -> bool:\r\n        \"\"\"\r\n        Return True if the IntervalIndex has overlapping intervals, else False.\r\n\r\n        Two intervals overlap if they share a common point, including closed\r\n        endpoints. Intervals that only have an open endpoint in common do not\r\n        overlap.\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n            Boolean indicating if the IntervalIndex has overlapping intervals.\r\n\r\n        See Also\r\n        --------\r\n        Interval.overlaps : Check whether two Interval objects overlap.\r\n        IntervalIndex.overlaps : Check an IntervalIndex elementwise for\r\n            overlaps.\r\n\r\n        Examples\r\n        --------\r\n        >>> index = pd.IntervalIndex.from_tuples([(0, 2), (1, 3), (4, 5)])\r\n        >>> index\r\n        IntervalIndex([(0, 2], (1, 3], (4, 5]],\r\n              dtype='interval[int64, right]')\r\n        >>> index.is_overlapping\r\n        True\r\n\r\n        Intervals that share closed endpoints overlap:\r\n\r\n        >>> index = pd.interval_range(0, 3, closed='both')\r\n        >>> index\r\n        IntervalIndex([[0, 1], [1, 2], [2, 3]],\r\n              dtype='interval[int64, both]')\r\n        >>> index.is_overlapping\r\n        True\r\n\r\n        Intervals that only have an open endpoint in common do not overlap:\r\n\r\n        >>> index = pd.interval_range(0, 3, closed='left')\r\n        >>> index\r\n        IntervalIndex([[0, 1), [1, 2), [2, 3)],\r\n              dtype='interval[int64, left]')\r\n        >>> index.is_overlapping\r\n        False\r\n        \"\"\"\r\n        # GH 23309\r\n        return self._engine.is_overlapping\r\n\r\n    def _needs_i8_conversion(self, key) -> bool:\r\n        \"\"\"\r\n        Check if a given key needs i8 conversion. Conversion is necessary for\r\n        Timestamp, Timedelta, DatetimeIndex, and TimedeltaIndex keys. An\r\n        Interval-like requires conversion if its endpoints are one of the\r\n        aforementioned types.\r\n\r\n        Assumes that any list-like data has already been cast to an Index.\r\n\r\n        Parameters\r\n        ----------\r\n        key : scalar or Index-like\r\n            The key that should be checked for i8 conversion\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n"]
[195.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[195.002, "i", "grep -n \"intersection(\" pandas/core/indexes/interval.py\r"]
[195.004, "o", "grep -n \"intersection(\" pandas/core/indexes/interval.py\r\n"]
[195.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K850\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def _\u001b[01;31m\u001b[Kintersection(\u001b[m\u001b[Kself, other, sort):\r\n\u001b[32m\u001b[K882\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is much more performant than super()._\u001b[01;31m\u001b[Kintersection(\u001b[m\u001b[Kother)\r\n\u001b[32m\u001b[K906\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is about 3.25x faster than super()._\u001b[01;31m\u001b[Kintersection(\u001b[m\u001b[Kother)\r\n"]
[200.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[200.002, "i", "python - << 'PY'\r"]
[200.004, "o", "python - << 'PY'\r\n"]
[200.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import numpy as np\r\n\u001b[?2004l\r\n\u001b[?2004h> from pandas.core.indexes.interval import IntervalIndex\r\n\u001b[?2004l\r\n\u001b[?2004h> import cProfile, pstats, io\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h> def setup(N):\r\n\u001b[?2004l\r\n\u001b[?2004h>     left = np.append(np.arange(N), np.array(0))\r\n\u001b[?2004l\r\n\u001b[?2004h>     right = np.append(np.arange(1, N + 1), np.array(1))\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv = IntervalIndex.from_arrays(left, right)\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv._engine\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv2._engine\r\n\u001b[?2004l\r\n\u001b[?2004h>     return intv, intv2\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h> N = 100_000\r\n\u001b[?2004l\r\n\u001b[?2004h> intv, intv2 = setup(N)\r\n\u001b[?2004l\r\n\u001b[?2004h> pr = cProfile.Profile()\r\n\u001b[?2004l\r\n\u001b[?2004h> pr.enable()\r\n\u001b[?2004l\r\n\u001b[?2004h> # both duplicate case from benchmark\r\n\u001b[?2004l\r\n\u001b[?2004h> res = intv.intersection(intv2)\r\n\u001b[?2004l\r\n\u001b[?2004h> pr.disable()\r\n\u001b[?2004l\r\n\u001b[?2004h> s = io.StringIO()\r\n\u001b[?2004l\r\n\u001b[?2004h> ps = pstats.Stats(pr, stream=s).sort_stats('cumtime')\r\n\u001b[?2004l\r\n\u001b[?2004h> ps.print_stats(30)\r\n\u001b[?2004l\r\n\u001b[?2004h> print(s.getvalue())\r\n\u001b[?2004l\r\n\u001b[?2004h> print('result_len:', len(res))\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n         1105 function calls (1089 primitive calls) in 0.101 seconds\r\n\r\n   Ordered by: cumulative time\r\n   List reduced from 154 to 30 due to restriction <30>\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.101    0.101 /workspace/repo/pandas/core/indexes/base.py:3251(intersection)\r\n        1    0.009    0.009    0.100    0.100 /workspace/repo/pandas/core/indexes/interval.py:850(_intersection)\r\n        1    0.087    0.087    0.088    0.088 /workspace/repo/pandas/core/indexes/interval.py:892(_intersection_non_unique)\r\n        2    0.002    0.001    0.002    0.001 /workspace/repo/pandas/core/indexes/base.py:2174(is_unique)\r\n        1    0.000    0.000    0.002    0.002 /workspace/repo/pandas/core/indexes/base.py:5100(__getitem__)\r\n        1    0.001    0.001    0.001    0.001 /workspace/repo/pandas/core/arrays/interval.py:715(__getitem__)\r\n        1    0.000    0.000    0.001    0.001 /workspace/repo/pandas/core/arrays/interval.py:665(_shallow_copy)\r\n        1    0.000    0.000    0.001    0.001 /workspace/repo/pandas/core/arrays/interval.py:635(_validate)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:297(_ensure_simple_new_inputs)\r\n      2/1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:5253(equals)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:997(equals)\r\n        4    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:449(__new__)\r\n  312/306    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:456(array_equivalent)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(array_equal)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/numeric.py:2407(array_equal)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:1281(left)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:955(astype)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:7010(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/dtypes.py:1083(__new__)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:1143(copy)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:2670(hasnans)\r\n        3    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:106(isna)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:794(_engine)\r\n        3    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:189(_isna)\r\n       55    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/generic.py:42(_instancecheck)\r\n        4    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/construction.py:500(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:353(notna)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:6025(_should_compare)\r\n\r\n\r\n\r\nresult_len: 99999\r\n"]
[205.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[205.002, "i", "python - << 'PY'\r"]
[205.004, "o", "python - << 'PY'\r\n"]
[205.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import numpy as np\r\n\u001b[?2004l\r\n\u001b[?2004h> from pandas.core.indexes.interval import IntervalIndex\r\n\u001b[?2004l\r\n\u001b[?2004h> import cProfile, pstats, io\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h> N = 100_000\r\n\u001b[?2004l\r\n\u001b[?2004h> left = np.arange(N)\r\n\u001b[?2004l\r\n\u001b[?2004h> right = np.arange(1, N + 1)\r\n\u001b[?2004l\r\n\u001b[?2004h> left2 = np.arange(N-3, 2*N-3)\r\n\u001b[?2004l\r\n\u001b[?2004h> right2 = left2 + 1\r\n\u001b[?2004l\r\n\u001b[?2004h> left_idx = IntervalIndex.from_breaks(np.arange(N))\r\n\u001b[?2004l\r\n\u001b[?2004h> right_idx = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))\r\n\u001b[?2004l\r\n\u001b[?2004h> pr = cProfile.Profile()\r\n\u001b[?2004l\r\n\u001b[?2004h> pr.enable()\r\n\u001b[?2004l\r\n\u001b[?2004h> res = left_idx.intersection(right_idx)\r\n\u001b[?2004l\r\n\u001b[?2004h> pr.disable()\r\n\u001b[?2004l\r\n\u001b[?2004h> import sys\r\n\u001b[?2004l\r\n\u001b[?2004h> import pstats\r\n\u001b[?2004l\r\n\u001b[?2004h> ps = pstats.Stats(pr).sort_stats('cumtime')\r\n\u001b[?2004l\r\n\u001b[?2004h> ps.print_stats(30)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('result_len:', len(res))\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n         2175 function calls (2152 primitive calls) in 0.009 seconds\r\n\r\n   Ordered by: cumulative time\r\n   List reduced from 175 to 30 due to restriction <30>\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.009    0.009 /workspace/repo/pandas/core/indexes/base.py:3251(intersection)\r\n        1    0.000    0.000    0.009    0.009 /workspace/repo/pandas/core/indexes/interval.py:850(_intersection)\r\n        1    0.000    0.000    0.007    0.007 /workspace/repo/pandas/core/indexes/interval.py:870(_intersection_unique)\r\n        2    0.000    0.000    0.006    0.003 /workspace/repo/pandas/core/indexes/base.py:3662(get_indexer)\r\n        2    0.000    0.000    0.005    0.003 /workspace/repo/pandas/core/indexes/base.py:3749(_get_indexer)\r\n        2    0.005    0.003    0.005    0.003 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\r\n        2    0.002    0.001    0.002    0.001 /workspace/repo/pandas/core/indexes/base.py:2174(is_unique)\r\n      4/3    0.000    0.000    0.001    0.000 /workspace/repo/pandas/core/indexes/base.py:5253(equals)\r\n       12    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:449(__new__)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:1038(take)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:1078(take)\r\n        3    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:456(array_equivalent)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:665(_shallow_copy)\r\n        3    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(array_equal)\r\n        3    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n        3    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/numeric.py:2407(array_equal)\r\n  607/593    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:297(_ensure_simple_new_inputs)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:997(equals)\r\n        4    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:1281(left)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/interval.py:816(right)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/interval.py:812(left)\r\n       12    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/construction.py:500(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/algorithms.py:312(unique)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/algorithms.py:432(unique_with_mask)\r\n        3    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:6025(_should_compare)\r\n      142    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/generic.py:42(_instancecheck)\r\n       41    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/common.py:1487(_is_dtype_type)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:1290(right)\r\n       12    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:562(_dtype_to_subclass)\r\n\r\n\r\nresult_len: 2\r\n"]
[210.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[210.002, "i", "grep -n \"_intersection\" pandas/core/indexes/interval.py\r"]
[210.004, "o", "grep -n \"_intersection\" pandas/core/indexes/interval.py\r\n"]
[210.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K850\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(self, other, sort):\r\n\u001b[32m\u001b[K856\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(other)\r\n\u001b[32m\u001b[K860\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = other.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self)\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(other)\r\n\u001b[32m\u001b[K870\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K882\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is much more performant than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K906\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is about 3.25x faster than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K907\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        #  in IntervalIndexMethod.time\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_both_duplicate(1000)\r\n"]
[215.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[215.002, "i", "sed -n '760,980p' pandas/core/indexes/interval.py\r"]
[215.004, "o", "sed -n '760,980p' pandas/core/indexes/interval.py\r\n"]
[215.006, "o", "\u001b[?2004l\r\n            except InvalidIndexError:\r\n                # i.e. non-scalar key e.g. a tuple.\r\n                # see test_append_different_columns_types_raises\r\n                missing.append(i)\r\n                locs = np.array([-1])\r\n\r\n            indexer.append(locs)\r\n\r\n        indexer = np.concatenate(indexer)\r\n        return ensure_platform_int(indexer), ensure_platform_int(missing)\r\n\r\n    @cache_readonly\r\n    def _index_as_unique(self) -> bool:\r\n        return not self.is_overlapping and self._engine._na_count < 2\r\n\r\n    _requires_unique_msg = (\r\n        \"cannot handle overlapping indices; use IntervalIndex.get_indexer_non_unique\"\r\n    )\r\n\r\n    def _convert_slice_indexer(self, key: slice, kind: str):\r\n        if not (key.step is None or key.step == 1):\r\n            # GH#31658 if label-based, we require step == 1,\r\n            #  if positional, we disallow float start/stop\r\n            msg = \"label-based slicing with step!=1 is not supported for IntervalIndex\"\r\n            if kind == \"loc\":\r\n                raise ValueError(msg)\r\n            if kind == \"getitem\":\r\n                if not is_valid_positional_slice(key):\r\n                    # i.e. this cannot be interpreted as a positional slice\r\n                    raise ValueError(msg)\r\n\r\n        return super()._convert_slice_indexer(key, kind)\r\n\r\n    @cache_readonly\r\n    def _should_fallback_to_positional(self) -> bool:\r\n        # integer lookups in Series.__getitem__ are unambiguously\r\n        #  positional in this case\r\n        # error: Item \"ExtensionDtype\"/\"dtype[Any]\" of \"Union[dtype[Any],\r\n        # ExtensionDtype]\" has no attribute \"subtype\"\r\n        return self.dtype.subtype.kind in [\"m\", \"M\"]  # type: ignore[union-attr]\r\n\r\n    def _maybe_cast_slice_bound(self, label, side: str):\r\n        return getattr(self, side)._maybe_cast_slice_bound(label, side)\r\n\r\n    def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:\r\n        if not isinstance(dtype, IntervalDtype):\r\n            return False\r\n        common_subtype = find_common_type([self.dtype, dtype])\r\n        return not is_object_dtype(common_subtype)\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @cache_readonly\r\n    def left(self) -> Index:\r\n        return Index(self._data.left, copy=False)\r\n\r\n    @cache_readonly\r\n    def right(self) -> Index:\r\n        return Index(self._data.right, copy=False)\r\n\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[220.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[220.002, "i", "python - << 'PY'\r"]
[220.004, "o", "python - << 'PY'\r\n"]
[220.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import numpy as np\r\n\u001b[?2004l\r\n\u001b[?2004h> from pandas.core.indexes.interval import IntervalIndex\r\n\u001b[?2004l\r\n\u001b[?2004h> import cProfile, pstats, io\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h> def setup_both_dup(N):\r\n\u001b[?2004l\r\n\u001b[?2004h>     left = np.append(np.arange(N), np.array(0))\r\n\u001b[?2004l\r\n\u001b[?2004h>     right = np.append(np.arange(1, N + 1), np.array(1))\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv = IntervalIndex.from_arrays(left, right)\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv._engine\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv2._engine\r\n\u001b[?2004l\r\n\u001b[?2004h>     return intv, intv2\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h> N = 100_000\r\n\u001b[?2004l\r\n\u001b[?2004h> intv, intv2 = setup_both_dup(N)\r\n\u001b[?2004l\r\n\u001b[?2004h> pr = cProfile.Profile()\r\n\u001b[?2004l\r\n\u001b[?2004h> pr.enable()\r\n\u001b[?2004l\r\n\u001b[?2004h> res = intv.intersection(intv2)\r\n\u001b[?2004l\r\n\u001b[?2004h> pr.disable()\r\n\u001b[?2004l\r\n\u001b[?2004h> s = io.StringIO()\r\n\u001b[?2004l\r\n\u001b[?2004h> ps = pstats.Stats(pr, stream=s).sort_stats('cumtime')\r\n\u001b[?2004l\r\n\u001b[?2004h> ps.print_stats(40)\r\n\u001b[?2004l\r\n\u001b[?2004h> print(s.getvalue())\r\n\u001b[?2004l\r\n\u001b[?2004h> print('result_len:', len(res))\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n         1105 function calls (1089 primitive calls) in 0.119 seconds\r\n\r\n   Ordered by: cumulative time\r\n   List reduced from 154 to 40 due to restriction <40>\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.119    0.119 /workspace/repo/pandas/core/indexes/base.py:3251(intersection)\r\n        1    0.013    0.013    0.118    0.118 /workspace/repo/pandas/core/indexes/interval.py:850(_intersection)\r\n        1    0.101    0.101    0.103    0.103 /workspace/repo/pandas/core/indexes/interval.py:892(_intersection_non_unique)\r\n        2    0.002    0.001    0.002    0.001 /workspace/repo/pandas/core/indexes/base.py:2174(is_unique)\r\n        1    0.000    0.000    0.001    0.001 /workspace/repo/pandas/core/indexes/base.py:5100(__getitem__)\r\n        1    0.000    0.000    0.001    0.001 /workspace/repo/pandas/core/arrays/interval.py:715(__getitem__)\r\n        1    0.000    0.000    0.001    0.001 /workspace/repo/pandas/core/arrays/interval.py:665(_shallow_copy)\r\n        1    0.000    0.000    0.001    0.001 /workspace/repo/pandas/core/arrays/interval.py:635(_validate)\r\n      2/1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:5253(equals)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:997(equals)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:297(_ensure_simple_new_inputs)\r\n        4    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:449(__new__)\r\n  312/306    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:456(array_equivalent)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(array_equal)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/numeric.py:2407(array_equal)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:1281(left)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:7010(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/dtypes.py:1083(__new__)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:955(astype)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:2670(hasnans)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:1143(copy)\r\n       55    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/generic.py:42(_instancecheck)\r\n        3    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:106(isna)\r\n        4    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/construction.py:500(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:794(_engine)\r\n        3    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:189(_isna)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:353(notna)\r\n        4    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:6025(_should_compare)\r\n      7/5    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/common.py:547(is_dtype_equal)\r\n        7    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:619(_simple_new)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/ops/common.py:87(get_op_result_name)\r\n        3    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:266(_isna_array)\r\n        3    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\r\n       17    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/common.py:1487(_is_dtype_type)\r\n        3    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/_methods.py:61(_all)\r\n        2    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/_dtype.py:34(__str__)\r\n        4    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/common.py:1237(is_bool_dtype)\r\n\r\n\r\n\r\nresult_len: 99999\r\n"]
[225.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[225.002, "i", "grep -n \"_intersection\" pandas/core/indexes/interval.py\r"]
[225.004, "o", "grep -n \"_intersection\" pandas/core/indexes/interval.py\r\n"]
[225.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K850\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(self, other, sort):\r\n\u001b[32m\u001b[K856\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(other)\r\n\u001b[32m\u001b[K860\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = other.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self)\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(other)\r\n\u001b[32m\u001b[K870\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K882\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is much more performant than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K906\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is about 3.25x faster than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K907\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        #  in IntervalIndexMethod.time\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_both_duplicate(1000)\r\n"]
[230.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[230.002, "i", "sed -n '800,980p' pandas/core/indexes/interval.py\r"]
[230.004, "o", "sed -n '800,980p' pandas/core/indexes/interval.py\r\n"]
[230.006, "o", "\u001b[?2004l\r\n\r\n    def _maybe_cast_slice_bound(self, label, side: str):\r\n        return getattr(self, side)._maybe_cast_slice_bound(label, side)\r\n\r\n    def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:\r\n        if not isinstance(dtype, IntervalDtype):\r\n            return False\r\n        common_subtype = find_common_type([self.dtype, dtype])\r\n        return not is_object_dtype(common_subtype)\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @cache_readonly\r\n    def left(self) -> Index:\r\n        return Index(self._data.left, copy=False)\r\n\r\n    @cache_readonly\r\n    def right(self) -> Index:\r\n        return Index(self._data.right, copy=False)\r\n\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[235.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[235.002, "i", "python - << 'PY'\r"]
[235.004, "o", "python - << 'PY'\r\n"]
[235.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import numpy as np\r\n\u001b[?2004l\r\n\u001b[?2004h> from pandas.core.indexes.interval import IntervalIndex\r\n\u001b[?2004l\r\n\u001b[?2004h> import cProfile, pstats, io\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h> def setup_both_dup(N):\r\n\u001b[?2004l\r\n\u001b[?2004h>     left = np.append(np.arange(N), np.array(0))\r\n\u001b[?2004l\r\n\u001b[?2004h>     right = np.append(np.arange(1, N + 1), np.array(1))\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv = IntervalIndex.from_arrays(left, right)\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv._engine\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\r\n\u001b[?2004l\r\n\u001b[?2004h>     intv2._engine\r\n\u001b[?2004l\r\n\u001b[?2004h>     return intv, intv2\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h> N = 100_000\r\n\u001b[?2004l\r\n\u001b[?2004h> intv, intv2 = setup_both_dup(N)\r\n\u001b[?2004l\r\n\u001b[?2004h> pr = cProfile.Profile()\r\n\u001b[?2004l\r\n\u001b[?2004h> pr.enable()\r\n\u001b[?2004l\r\n\u001b[?2004h> _ = intv.intersection(intv2)\r\n\u001b[?2004l\r\n\u001b[?2004h> pr.disable()\r\n\u001b[?2004l\r\n\u001b[?2004h> ps = pstats.Stats(pr).sort_stats('cumtime')\r\n\u001b[?2004l\r\n\u001b[?2004h> ps.print_stats(30)\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n         1105 function calls (1089 primitive calls) in 0.106 seconds\r\n\r\n   Ordered by: cumulative time\r\n   List reduced from 154 to 30 due to restriction <30>\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.106    0.106 /workspace/repo/pandas/core/indexes/base.py:3251(intersection)\r\n        1    0.009    0.009    0.106    0.106 /workspace/repo/pandas/core/indexes/interval.py:850(_intersection)\r\n        1    0.093    0.093    0.095    0.095 /workspace/repo/pandas/core/indexes/interval.py:892(_intersection_non_unique)\r\n        2    0.002    0.001    0.002    0.001 /workspace/repo/pandas/core/indexes/base.py:2174(is_unique)\r\n        1    0.000    0.000    0.001    0.001 /workspace/repo/pandas/core/indexes/base.py:5100(__getitem__)\r\n        1    0.000    0.000    0.001    0.001 /workspace/repo/pandas/core/arrays/interval.py:715(__getitem__)\r\n        1    0.000    0.000    0.001    0.001 /workspace/repo/pandas/core/arrays/interval.py:665(_shallow_copy)\r\n        1    0.000    0.000    0.001    0.001 /workspace/repo/pandas/core/arrays/interval.py:635(_validate)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:297(_ensure_simple_new_inputs)\r\n      2/1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:5253(equals)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:997(equals)\r\n        4    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:449(__new__)\r\n  312/306    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:456(array_equivalent)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/arrays/interval.py:1281(left)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(array_equal)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n        1    0.000    0.000    0.000    0.000 /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/numpy/core/numeric.py:2407(array_equal)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/dtypes.py:1083(__new__)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:7010(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:955(astype)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:1143(copy)\r\n        3    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:106(isna)\r\n        1    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:2670(hasnans)\r\n       55    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/generic.py:42(_instancecheck)\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:353(notna)\r\n        3    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/dtypes/missing.py:189(_isna)\r\n        4    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/construction.py:500(sanitize_array)\r\n        4    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n        2    0.000    0.000    0.000    0.000 /workspace/repo/pandas/core/indexes/base.py:794(_engine)\r\n\r\n\r\n"]
[240.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[240.002, "i", "sed -n '820,960p' pandas/core/indexes/interval.py\r"]
[240.004, "o", "sed -n '820,960p' pandas/core/indexes/interval.py\r\n"]
[240.006, "o", "\u001b[?2004l\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n"]
[245.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[245.002, "i", "sed -n '960,1120p' pandas/core/indexes/interval.py\r"]
[245.004, "o", "sed -n '960,1120p' pandas/core/indexes/interval.py\r\n"]
[245.006, "o", "\u001b[?2004l\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[250.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[250.002, "i", "sed -n '1120,1280p' pandas/core/indexes/interval.py\r"]
[250.004, "o", "sed -n '1120,1280p' pandas/core/indexes/interval.py\r\n"]
[250.006, "o", "\u001b[?2004l\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[255.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[255.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py\r"]
[255.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py\r\n"]
[255.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[260.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[260.002, "i", "sed -n '820,980p' pandas/core/indexes/interval.py\r"]
[260.004, "o", "sed -n '820,980p' pandas/core/indexes/interval.py\r\n"]
[260.006, "o", "\u001b[?2004l\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[265.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[265.002, "i", "python - << 'PY'\r"]
[265.004, "o", "python - << 'PY'\r\n"]
[265.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/indexes/interval.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> text = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> print('File length:', len(text), 'bytes')\r\n\u001b[?2004l\r\n\u001b[?2004h> start = text.find('_intersection_non_unique')\r\n\u001b[?2004l\r\n\u001b[?2004h> print('start index:', start)\r\n\u001b[?2004l\r\n\u001b[?2004h> print(text[max(0,start-300):start+800])\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nFile length: 38333 bytes\r\nstart index: 28489\r\n   elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[\r\n"]
[270.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[270.002, "i", "python - << 'PY'\r"]
[270.004, "o", "python - << 'PY'\r\n"]
[270.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import io,sys\r\n\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/indexes/interval.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> anchor = s.find('def _intersection_non_unique')\r\n\u001b[?2004l\r\n\u001b[?2004h> if anchor==-1:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('anchor not found')\r\n\u001b[?2004l\r\n\u001b[?2004h>     sys.exit(0)\r\n\u001b[?2004l\r\n\u001b[?2004h> # naive patch: insert fastpath after def line\r\n\u001b[?2004l\r\n\u001b[?2004h> lines = s.splitlines()\r\n\u001b[?2004l\r\n\u001b[?2004h> for i,l in enumerate(lines):\r\n\u001b[?2004l\r\n\u001b[?2004h>     if l.strip().startswith('def _intersection_non_unique'):\r\n\u001b[?2004l\r\n\u001b[?2004h>         def_line=i\r\n\u001b[?2004l\r\n\u001b[?2004h>         break\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find function indent and insert after signature\r\n\u001b[?2004l\r\n\u001b[?2004h> indent = lines[def_line][:len(lines[def_line]) - len(lines[def_line].lstrip())]\r\n\u001b[?2004l\r\n\u001b[?2004h> insert_at = def_line+1\r\n\u001b[?2004l\r\n\u001b[?2004h> fastpath = f\"{indent}    # Fastpath: vectorized intersection for same-dtype, non-object intervals\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}    try:\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}        other = other  # ensure name exists\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}        if (self.dtype == other.dtype and self.closed == other.closed):\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}            left1 = self.left.values\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}            right1 = self.right.values\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}            left2 = other.left.values\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}            right2 = other.right.values\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}            if (left1.dtype != object and right1.dtype != object and\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                left2.dtype == left1.dtype and right2.dtype == right1.dtype):\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                import numpy as np\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                dt = np.dtype([('l', left1.dtype), ('r', right1.dtype)])\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                a1 = np.empty(left1.shape[0], dtype=dt)\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                a2 = np.empty(left2.shape[0], dtype=dt)\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                a1['l'] = left1\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                a1['r'] = right1\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                a2['l'] = left2\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                a2['r'] = right2\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                common = np.intersect1d(a1, a2, assume_unique=False)\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                # common is sorted and unique. Reconstruct IntervalIndex.\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                if common.size == 0:\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                    return self[:0]\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                out_left = common['l']\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                out_right = common['r']\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                from pandas.core.indexes.interval import IntervalIndex as _II\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}                return _II.from_arrays(out_left, out_right, closed=self.closed)\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}    except Exception:\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}        # fall back to existing implementation\\n\" \\\r\n\u001b[?2004l\r\n\u001b[?2004h> + f\"{indent}        pass\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> lines.insert(insert_at, fastpath)\r\n\u001b[?2004l\r\n\u001b[?2004h> new = \"\\n\".join(lines)\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(new)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Patched interval.py with fastpath')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nPatched interval.py with fastpath\r\n"]
[275.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[275.002, "i", "python -m pyflakes pandas/core/indexes/interval.py 2>/dev/null || true\r"]
[275.004, "o", "python -m pyflakes pandas/core/indexes/interval.py 2>/dev/null || true\r\n"]
[275.006, "o", "\u001b[?2004l\r\n"]
[280.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[280.002, "i", "pytest -q -k \"IntervalIndex and intersection\" 2>/dev/null || true\r"]
[280.004, "o", "pytest -q -k \"IntervalIndex and intersection\" 2>/dev/null || true\r\n"]
[280.006, "o", "\u001b[?2004l\r\ncd asv_bench\r\nasv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\"\r\nasv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection\" \r\n\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\r\n=========================================================================== FAILURES ===========================================================================\r\n\u001b[31m\u001b[1m________________________________________________________ TestIntervalIndex.test_intersection[left-None] ________________________________________________________\u001b[0m\r\n\r\nself = <pandas.tests.indexes.interval.test_setops.TestIntervalIndex object at 0x7fa7299ffa00>, closed = 'left', sort = None\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n    \r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n    \r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n>       tm.assert_index_equal(result, expected)\r\n\u001b[1m\u001b[31mE       AssertionError: Index are different\u001b[0m\r\n\u001b[1m\u001b[31mE       \u001b[0m\r\n\u001b[1m\u001b[31mE       Index length are different\u001b[0m\r\n\u001b[1m\u001b[31mE       [left]:  0, IntervalIndex([], dtype='interval[float64, right]')\u001b[0m\r\n\u001b[1m\u001b[31mE       [right]: 1, IntervalIndex([nan], dtype='interval[float64, right]')\u001b[0m\r\n\r\n\u001b[1m\u001b[31mpandas/tests/indexes/interval/test_setops.py\u001b[0m:98: AssertionError\r\n\u001b[31m\u001b[1m_______________________________________________________ TestIntervalIndex.test_intersection[left-False] ________________________________________________________\u001b[0m\r\n\r\nself = <pandas.tests.indexes.interval.test_setops.TestIntervalIndex object at 0x7fa7299ff970>, closed = 'left', sort = False\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n    \r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n    \r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n>       tm.assert_index_equal(result, expected)\r\n\u001b[1m\u001b[31mE       AssertionError: Index are different\u001b[0m\r\n\u001b[1m\u001b[31mE       \u001b[0m\r\n\u001b[1m\u001b[31mE       Index length are different\u001b[0m\r\n\u001b[1m\u001b[31mE       [left]:  0, IntervalIndex([], dtype='interval[float64, right]')\u001b[0m\r\n\u001b[1m\u001b[31mE       [right]: 1, IntervalIndex([nan], dtype='interval[float64, right]')\u001b[0m\r\n\r\n\u001b[1m\u001b[31mpandas/tests/indexes/interval/test_setops.py\u001b[0m:98: AssertionError\r\n\u001b[31m\u001b[1m_______________________________________________________ TestIntervalIndex.test_intersection[right-None] ________________________________________________________\u001b[0m\r\n\r\nself = <pandas.tests.indexes.interval.test_setops.TestIntervalIndex object at 0x7fa7299ffa60>, closed = 'right', sort = None\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n    \r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n    \r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n>       tm.assert_index_equal(result, expected)\r\n\u001b[1m\u001b[31mE       AssertionError: Index are different\u001b[0m\r\n\u001b[1m\u001b[31mE       \u001b[0m\r\n\u001b[1m\u001b[31mE       Index length are different\u001b[0m\r\n\u001b[1m\u001b[31mE       [left]:  0, IntervalIndex([], dtype='interval[float64, right]')\u001b[0m\r\n\u001b[1m\u001b[31mE       [right]: 1, IntervalIndex([nan], dtype='interval[float64, right]')\u001b[0m\r\n\r\n\u001b[1m\u001b[31mpandas/tests/indexes/interval/test_setops.py\u001b[0m:98: AssertionError\r\n\u001b[31m\u001b[1m_______________________________________________________ TestIntervalIndex.test_intersection[right-False] _______________________________________________________\u001b[0m\r\n\r\nself = <pandas.tests.indexes.interval.test_setops.TestIntervalIndex object at 0x7fa7299ff910>, closed = 'right', sort = False\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n    \r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n    \r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n>       tm.assert_index_equal(result, expected)\r\n\u001b[1m\u001b[31mE       AssertionError: Index are different\u001b[0m\r\n\u001b[1m\u001b[31mE       \u001b[0m\r\n\u001b[1m\u001b[31mE       Index length are different\u001b[0m\r\n\u001b[1m\u001b[31mE       [left]:  0, IntervalIndex([], dtype='interval[float64, right]')\u001b[0m\r\n\u001b[1m\u001b[31mE       [right]: 1, IntervalIndex([nan], dtype='interval[float64, right]')\u001b[0m\r\n\r\n\u001b[1m\u001b[31mpandas/tests/indexes/interval/test_setops.py\u001b[0m:98: AssertionError\r\n\u001b[31m\u001b[1m________________________________________________________ TestIntervalIndex.test_intersection[both-None] ________________________________________________________\u001b[0m\r\n\r\nself = <pandas.tests.indexes.interval.test_setops.TestIntervalIndex object at 0x7fa7299ffee0>, closed = 'both', sort = None\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n    \r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n    \r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n>       tm.assert_index_equal(result, expected)\r\n\u001b[1m\u001b[31mE       AssertionError: Index are different\u001b[0m\r\n\u001b[1m\u001b[31mE       \u001b[0m\r\n\u001b[1m\u001b[31mE       Index length are different\u001b[0m\r\n\u001b[1m\u001b[31mE       [left]:  0, IntervalIndex([], dtype='interval[float64, right]')\u001b[0m\r\n\u001b[1m\u001b[31mE       [right]: 1, IntervalIndex([nan], dtype='interval[float64, right]')\u001b[0m\r\n\r\n\u001b[1m\u001b[31mpandas/tests/indexes/interval/test_setops.py\u001b[0m:98: AssertionError\r\n\u001b[31m\u001b[1m_______________________________________________________ TestIntervalIndex.test_intersection[both-False] ________________________________________________________\u001b[0m\r\n\r\nself = <pandas.tests.indexes.interval.test_setops.TestIntervalIndex object at 0x7fa7299ff700>, closed = 'both', sort = False\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n    \r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n    \r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n>       tm.assert_index_equal(result, expected)\r\n\u001b[1m\u001b[31mE       AssertionError: Index are different\u001b[0m\r\n\u001b[1m\u001b[31mE       \u001b[0m\r\n\u001b[1m\u001b[31mE       Index length are different\u001b[0m\r\n\u001b[1m\u001b[31mE       [left]:  0, IntervalIndex([], dtype='interval[float64, right]')\u001b[0m\r\n\u001b[1m\u001b[31mE       [right]: 1, IntervalIndex([nan], dtype='interval[float64, right]')\u001b[0m\r\n\r\n\u001b[1m\u001b[31mpandas/tests/indexes/interval/test_setops.py\u001b[0m:98: AssertionError\r\n\u001b[31m\u001b[1m______________________________________________________ TestIntervalIndex.test_intersection[neither-None] _______________________________________________________\u001b[0m\r\n\r\nself = <pandas.tests.indexes.interval.test_setops.TestIntervalIndex object at 0x7fa729a18070>, closed = 'neither', sort = None\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n    \r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n    \r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n>       tm.assert_index_equal(result, expected)\r\n\u001b[1m\u001b[31mE       AssertionError: Index are different\u001b[0m\r\n\u001b[1m\u001b[31mE       \u001b[0m\r\n\u001b[1m\u001b[31mE       Index length are different\u001b[0m\r\n\u001b[1m\u001b[31mE       [left]:  0, IntervalIndex([], dtype='interval[float64, right]')\u001b[0m\r\n\u001b[1m\u001b[31mE       [right]: 1, IntervalIndex([nan], dtype='interval[float64, right]')\u001b[0m\r\n\r\n\u001b[1m\u001b[31mpandas/tests/indexes/interval/test_setops.py\u001b[0m:98: AssertionError\r\n\u001b[31m\u001b[1m______________________________________________________ TestIntervalIndex.test_intersection[neither-False] ______________________________________________________\u001b[0m\r\n\r\nself = <pandas.tests.indexes.interval.test_setops.TestIntervalIndex object at 0x7fa729a18130>, closed = 'neither', sort = False\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n    \r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n    \r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n    \r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n    \r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n>       tm.assert_index_equal(result, expected)\r\n\u001b[1m\u001b[31mE       AssertionError: Index are different\u001b[0m\r\n\u001b[1m\u001b[31mE       \u001b[0m\r\n\u001b[1m\u001b[31mE       Index length are different\u001b[0m\r\n\u001b[1m\u001b[31mE       [left]:  0, IntervalIndex([], dtype='interval[float64, right]')\u001b[0m\r\n\u001b[1m\u001b[31mE       [right]: 1, IntervalIndex([nan], dtype='interval[float64, right]')\u001b[0m\r\n\r\n\u001b[1m\u001b[31mpandas/tests/indexes/interval/test_setops.py\u001b[0m:98: AssertionError\r\n\u001b[33m======================================================================= warnings summary =======================================================================\u001b[0m\r\npandas/core/construction.py:335\r\n  /workspace/repo/pandas/core/construction.py:335: UserWarning: pyarrow requires pandas 1.0.0 or above, pandas 0+untagged.31506.g5f584bd.dirty is installed. Therefore, pandas-specific integration is not used.\r\n    return cls._from_sequence(data, dtype=dtype, copy=copy)\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n------------------------------------------------------ generated xml file: /workspace/repo/test-data.xml -------------------------------------------------------\r\n===================================================================== slowest 30 durations =====================================================================\r\n0.01s call     pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection[right-None]\r\n0.01s call     pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection[left-None]\r\n0.01s call     pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection[both-None]\r\n0.01s call     pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection[neither-None]\r\n\r\n(26 durations < 0.005s hidden.  Use -vv to show these durations.)\r\n\u001b[36m\u001b[1m=================================================================== short test summary info ====================================================================\u001b[0m\r\n\u001b[31mFAILED\u001b[0m pandas/tests/indexes/interval/test_setops.py::\u001b[1mTestIntervalIndex::test_intersection[left-None]\u001b[0m - AssertionError: Index are different\r\n\u001b[31mFAILED\u001b[0m pandas/tests/indexes/interval/test_setops.py::\u001b[1mTestIntervalIndex::test_intersection[left-False]\u001b[0m - AssertionError: Index are different\r\n\u001b[31mFAILED\u001b[0m pandas/tests/indexes/interval/test_setops.py::\u001b[1mTestIntervalIndex::test_intersection[right-None]\u001b[0m - AssertionError: Index are different\r\n\u001b[31mFAILED\u001b[0m pandas/tests/indexes/interval/test_setops.py::\u001b[1mTestIntervalIndex::test_intersection[right-False]\u001b[0m - AssertionError: Index are different\r\n\u001b[31mFAILED\u001b[0m pandas/tests/indexes/interval/test_setops.py::\u001b[1mTestIntervalIndex::test_intersection[both-None]\u001b[0m - AssertionError: Index are different\r\n\u001b[31mFAILED\u001b[0m pandas/tests/indexes/interval/test_setops.py::\u001b[1mTestIntervalIndex::test_intersection[both-False]\u001b[0m - AssertionError: Index are different\r\n\u001b[31mFAILED\u001b[0m pandas/tests/indexes/interval/test_setops.py::\u001b[1mTestIntervalIndex::test_intersection[neither-None]\u001b[0m - AssertionError: Index are different\r\n\u001b[31mFAILED\u001b[0m pandas/tests/indexes/interval/test_setops.py::\u001b[1mTestIntervalIndex::test_intersection[neither-False]\u001b[0m - AssertionError: Index are different\r\n\u001b[31m\u001b[31m\u001b[1m8 failed\u001b[0m, \u001b[32m17 passed\u001b[0m, \u001b[33m1 skipped\u001b[0m, \u001b[33m214440 deselected\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 139.87s (0:02:19)\u001b[0m\u001b[0m\r\n"]
[285.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[285.002, "i", "cd asv_bench\r"]
[285.004, "o", "cd asv_bench\r\n"]
[285.006, "o", "\u001b[?2004l\r\n"]
[290.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[290.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[290.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[295.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[295.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[295.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[295.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    3.83\u00b10ms \r\n              100000   655\u00b10ms  \r\n             ======== ==========\r\n\r\n"]
[300.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[300.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection\" \r"]
[300.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection\" \r\n"]
[300.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection\u001b[0m                                                                                              ok\r\n[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    995\u00b10\u03bcs  \r\n              100000   8.13\u00b10ms \r\n             ======== ==========\r\n\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    3.81\u00b10ms \r\n              100000   655\u00b10ms  \r\n             ======== ==========\r\n\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_one_duplicate\u001b[0m                                                                                ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    829\u00b10\u03bcs  \r\n              100000   8.95\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[305.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[305.002, "i", "git checkout -- pandas/core/indexes/interval.py\r"]
[305.004, "o", "git checkout -- pandas/core/indexes/interval.py\r\n"]
[305.006, "o", "\u001b[?2004l\r\nerror: pathspec 'pandas/core/indexes/interval.py' did not match any file(s) known to git\r\n"]
[310.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[310.002, "i", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/n\r"]
[310.004, "o", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/n\r\n"]
[310.006, "o", "null || true\r\n\u001b[?2004l\r\n"]
[315.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[315.002, "i", "cd asv_bench\r"]
[315.004, "o", "cd asv_bench\r\n"]
[315.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[320.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[320.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[320.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[325.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[325.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[325.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[325.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    3.88\u00b10ms \r\n              100000   682\u00b10ms  \r\n             ======== ==========\r\n\r\n"]
[330.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[330.002, "i", "cd ..\r"]
[330.004, "o", "cd ..\r\n"]
[330.006, "o", "\u001b[?2004l\r\n"]
[335.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[335.002, "i", "grep -n \"def _intersection_non_unique\" pandas/core/indexes/interval.py\r"]
[335.004, "o", "grep -n \"def _intersection_non_unique\" pandas/core/indexes/interval.py\r\n"]
[335.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef _intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[340.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[340.002, "i", "sed -n '820,980p' pandas/core/indexes/interval.py\r"]
[340.004, "o", "sed -n '820,980p' pandas/core/indexes/interval.py\r\n"]
[340.006, "o", "\u001b[?2004l\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        # Fastpath: vectorized intersection for same-dtype, non-object intervals\r\n        try:\r\n            other = other  # ensure name exists\r\n            if (self.dtype == other.dtype and self.closed == other.closed):\r\n                left1 = self.left.values\r\n                right1 = self.right.values\r\n                left2 = other.left.values\r\n                right2 = other.right.values\r\n                if (left1.dtype != object and right1.dtype != object and\r\n                    left2.dtype == left1.dtype and right2.dtype == right1.dtype):\r\n                    import numpy as np\r\n                    dt = np.dtype([('l', left1.dtype), ('r', right1.dtype)])\r\n                    a1 = np.empty(left1.shape[0], dtype=dt)\r\n                    a2 = np.empty(left2.shape[0], dtype=dt)\r\n                    a1['l'] = left1\r\n                    a1['r'] = right1\r\n                    a2['l'] = left2\r\n                    a2['r'] = right2\r\n                    common = np.intersect1d(a1, a2, assume_unique=False)\r\n                    # common is sorted and unique. Reconstruct IntervalIndex.\r\n                    if common.size == 0:\r\n                        return self[:0]\r\n                    out_left = common['l']\r\n                    out_right = common['r']\r\n                    from pandas.core.indexes.interval import IntervalIndex as _II\r\n                    return _II.from_arrays(out_left, out_right, closed=self.closed)\r\n        except Exception:\r\n            # fall back to existing implementation\r\n            pass\r\n\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n"]
[345.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[345.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[345.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[345.006, "o", "\u001b[?2004l\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n"]
[350.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[350.002, "i", "grep -n \"Fastpath: vectorized intersection\" pandas/core/indexes/interval.py || true\r"]
[350.004, "o", "grep -n \"Fastpath: vectorized intersection\" pandas/core/indexes/interval.py || true\r\n"]
[350.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K893\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # \u001b[01;31m\u001b[KFastpath: vectorized intersection\u001b[m\u001b[K for same-dtype, non-object intervals\r\n"]
[355.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[355.002, "i", "git checkout -- pandas/core/indexes/interval.py\r"]
[355.004, "o", "git checkout -- pandas/core/indexes/interval.py\r\n"]
[355.006, "o", "\u001b[?2004l\r\n"]
[360.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[360.002, "i", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/null || tru\r"]
[360.004, "o", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/null || tru\r\n"]
[360.006, "o", "ue\r\n\u001b[?2004l\r\ncd asv_bench\r\nasv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\"\r\ncd ..\r\ngrep -n \"def _intersection_non_unique\" pandas/core/indexes/interval.py\r\nsed -n '820,980p' pandas/core/indexes/interval.py\r\n\r\n\u001b[33m======================================================================= warnings summary =======================================================================\u001b[0m\r\npandas/core/construction.py:335\r\n  /workspace/repo/pandas/core/construction.py:335: UserWarning: pyarrow requires pandas 1.0.0 or above, pandas 0+untagged.31506.g5f584bd is installed. Therefore, pandas-specific integration is not used.\r\n    return cls._from_sequence(data, dtype=dtype, copy=copy)\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n------------------------------------------------------ generated xml file: /workspace/repo/test-data.xml -------------------------------------------------------\r\n\u001b[33m\u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m214465 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 110.47s (0:01:50)\u001b[0m\u001b[0m\r\n"]
[365.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[365.002, "i", "cd asv_bench\r"]
[365.004, "o", "cd asv_bench\r\n"]
[365.006, "o", "\u001b[?2004l\r\n"]
[370.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[370.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[370.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[375.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[375.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[375.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[375.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.45\u00b10ms \r\n              100000   104\u00b10ms  \r\n             ======== ==========\r\n\r\n"]
[380.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[380.002, "i", "cd ..\r"]
[380.004, "o", "cd ..\r\n"]
[380.006, "o", "\u001b[?2004l\r\n"]
[385.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[385.002, "i", "grep -n \"def _intersection_non_unique\" pandas/core/indexes/interval.py\r"]
[385.004, "o", "grep -n \"def _intersection_non_unique\" pandas/core/indexes/interval.py\r\n"]
[385.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef _intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[390.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[390.002, "i", "sed -n '820,980p' pandas/core/indexes/interval.py\r"]
[390.004, "o", "sed -n '820,980p' pandas/core/indexes/interval.py\r\n"]
[390.006, "o", "\u001b[?2004l\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[395.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[395.002, "i", "grep -n \"Fastpath: vectorized intersection\" pandas/core/indexes/interval.py || true\r"]
[395.004, "o", "grep -n \"Fastpath: vectorized intersection\" pandas/core/indexes/interval.py || true\r\n"]
[395.006, "o", "\u001b[?2004l\r\n"]
[400.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[400.002, "i", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/null || tru\r"]
[400.004, "o", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/null || tru\r\n"]
[400.006, "o", "ue\r\n\u001b[?2004l\r\ncd asv_bench\r\nasv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\"\r\ncd ..\r\ngrep -n \"def _intersection_non_unique\" pandas/core/indexes/interval.py\r\nsed -n '820,980p' pandas/core/indexes/interval.py\r\nsed -n '980,1160p' pandas/core/indexes/interval.py\r\nsed -n '1,220p' pandas/tests/indexes/interval/test_setops.py\r\n\r\n\u001b[33m======================================================================= warnings summary =======================================================================\u001b[0m\r\npandas/core/construction.py:335\r\n  /workspace/repo/pandas/core/construction.py:335: UserWarning: pyarrow requires pandas 1.0.0 or above, pandas 0+untagged.31506.g5f584bd is installed. Therefore, pandas-specific integration is not used.\r\n    return cls._from_sequence(data, dtype=dtype, copy=copy)\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n------------------------------------------------------ generated xml file: /workspace/repo/test-data.xml -------------------------------------------------------\r\n\u001b[33m\u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m214465 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 115.70s (0:01:55)\u001b[0m\u001b[0m\r\n"]
[405.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[405.002, "i", "cd asv_bench\r"]
[405.004, "o", "cd asv_bench\r\n"]
[405.006, "o", "\u001b[?2004l\r\n"]
[410.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[410.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[410.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[415.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[415.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[415.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[415.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.21\u00b10ms \r\n              100000   93.2\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[420.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[420.002, "i", "cd ..\r"]
[420.004, "o", "cd ..\r\n"]
[420.006, "o", "\u001b[?2004l\r\n"]
[425.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[425.002, "i", "grep -n \"def _intersection_non_unique\" pandas/core/indexes/interval.py\r"]
[425.004, "o", "grep -n \"def _intersection_non_unique\" pandas/core/indexes/interval.py\r\n"]
[425.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef _intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[430.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[430.002, "i", "sed -n '820,980p' pandas/core/indexes/interval.py\r"]
[430.004, "o", "sed -n '820,980p' pandas/core/indexes/interval.py\r\n"]
[430.006, "o", "\u001b[?2004l\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[435.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[435.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[435.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[435.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[440.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[440.002, "i", "sed -n '1,220p' pandas/tests/indexes/interval/test_setops.py\r"]
[440.004, "o", "sed -n '1,220p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[440.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[445.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[445.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[445.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[445.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[450.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[450.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[450.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[450.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[455.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[455.002, "i", "sed -n '820,980p' pandas/core/indexes/interval.py\r"]
[455.004, "o", "sed -n '820,980p' pandas/core/indexes/interval.py\r\n"]
[455.006, "o", "\u001b[?2004l\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[460.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[460.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[460.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[460.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[465.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[465.002, "i", "sed -n '1,280p' pandas/tests/indexes/interval/test_setops.py\r"]
[465.004, "o", "sed -n '1,280p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[465.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[470.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[470.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\"\r"]
[470.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\"\r\n"]
[470.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mNo `asv.conf` file found for valid extensions: ['.json', '.jsonc'].\u001b[0m\r\n"]
[475.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[475.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[475.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[475.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[480.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[480.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[480.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[480.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[485.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[485.002, "i", "sed -n '800,980p' pandas/core/indexes/interval.py\r"]
[485.004, "o", "sed -n '800,980p' pandas/core/indexes/interval.py\r\n"]
[485.006, "o", "\u001b[?2004l\r\n\r\n    def _maybe_cast_slice_bound(self, label, side: str):\r\n        return getattr(self, side)._maybe_cast_slice_bound(label, side)\r\n\r\n    def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:\r\n        if not isinstance(dtype, IntervalDtype):\r\n            return False\r\n        common_subtype = find_common_type([self.dtype, dtype])\r\n        return not is_object_dtype(common_subtype)\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @cache_readonly\r\n    def left(self) -> Index:\r\n        return Index(self._data.left, copy=False)\r\n\r\n    @cache_readonly\r\n    def right(self) -> Index:\r\n        return Index(self._data.right, copy=False)\r\n\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[490.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[490.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[490.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[490.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[495.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[495.002, "i", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r"]
[495.004, "o", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[495.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[500.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[500.002, "i", "cd asv_bench\r"]
[500.004, "o", "cd asv_bench\r\n"]
[500.006, "o", "\u001b[?2004l\r\n"]
[505.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[505.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[505.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[510.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[510.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[510.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[510.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.18\u00b10ms \r\n              100000   77.5\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[515.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[515.002, "i", "cd ..\r"]
[515.004, "o", "cd ..\r\n"]
[515.006, "o", "\u001b[?2004l\r\n"]
[520.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[520.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[520.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[520.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[525.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[525.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[525.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[525.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[530.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[530.002, "i", "sed -n '800,980p' pandas/core/indexes/interval.py\r"]
[530.004, "o", "sed -n '800,980p' pandas/core/indexes/interval.py\r\n"]
[530.006, "o", "\u001b[?2004l\r\n\r\n    def _maybe_cast_slice_bound(self, label, side: str):\r\n        return getattr(self, side)._maybe_cast_slice_bound(label, side)\r\n\r\n    def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:\r\n        if not isinstance(dtype, IntervalDtype):\r\n            return False\r\n        common_subtype = find_common_type([self.dtype, dtype])\r\n        return not is_object_dtype(common_subtype)\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @cache_readonly\r\n    def left(self) -> Index:\r\n        return Index(self._data.left, copy=False)\r\n\r\n    @cache_readonly\r\n    def right(self) -> Index:\r\n        return Index(self._data.right, copy=False)\r\n\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[535.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[535.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[535.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[535.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[540.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[540.002, "i", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r"]
[540.004, "o", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[540.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[545.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[545.002, "i", "cd asv_bench\r"]
[545.004, "o", "cd asv_bench\r\n"]
[545.006, "o", "\u001b[?2004l\r\n"]
[550.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[550.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[550.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[555.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[555.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[555.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[555.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.15\u00b10ms \r\n              100000   76.4\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[560.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[560.002, "i", "cd ..\r"]
[560.004, "o", "cd ..\r\n"]
[560.006, "o", "\u001b[?2004l\r\n"]
[565.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[565.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[565.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[565.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[570.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[570.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[570.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[570.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[575.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[575.002, "i", "sed -n '800,980p' pandas/core/indexes/interval.py\r"]
[575.004, "o", "sed -n '800,980p' pandas/core/indexes/interval.py\r\n"]
[575.006, "o", "\u001b[?2004l\r\n\r\n    def _maybe_cast_slice_bound(self, label, side: str):\r\n        return getattr(self, side)._maybe_cast_slice_bound(label, side)\r\n\r\n    def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:\r\n        if not isinstance(dtype, IntervalDtype):\r\n            return False\r\n        common_subtype = find_common_type([self.dtype, dtype])\r\n        return not is_object_dtype(common_subtype)\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @cache_readonly\r\n    def left(self) -> Index:\r\n        return Index(self._data.left, copy=False)\r\n\r\n    @cache_readonly\r\n    def right(self) -> Index:\r\n        return Index(self._data.right, copy=False)\r\n\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[580.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[580.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[580.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[580.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[585.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[585.002, "i", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r"]
[585.004, "o", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[585.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[590.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[590.002, "i", "cd asv_bench\r"]
[590.004, "o", "cd asv_bench\r\n"]
[590.006, "o", "\u001b[?2004l\r\n"]
[595.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[595.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[595.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[600.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[600.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[600.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[600.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.21\u00b10ms \r\n              100000   85.0\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[605.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[605.002, "i", "cd ..\r"]
[605.004, "o", "cd ..\r\n"]
[605.006, "o", "\u001b[?2004l\r\n"]
[610.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[610.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[610.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[610.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[615.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[615.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[615.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[615.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[620.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[620.002, "i", "sed -n '800,980p' pandas/core/indexes/interval.py\r"]
[620.004, "o", "sed -n '800,980p' pandas/core/indexes/interval.py\r\n"]
[620.006, "o", "\u001b[?2004l\r\n\r\n    def _maybe_cast_slice_bound(self, label, side: str):\r\n        return getattr(self, side)._maybe_cast_slice_bound(label, side)\r\n\r\n    def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:\r\n        if not isinstance(dtype, IntervalDtype):\r\n            return False\r\n        common_subtype = find_common_type([self.dtype, dtype])\r\n        return not is_object_dtype(common_subtype)\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @cache_readonly\r\n    def left(self) -> Index:\r\n        return Index(self._data.left, copy=False)\r\n\r\n    @cache_readonly\r\n    def right(self) -> Index:\r\n        return Index(self._data.right, copy=False)\r\n\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[625.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[625.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[625.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[625.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[630.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[630.002, "i", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r"]
[630.004, "o", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[630.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[635.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[635.002, "i", "cd asv_bench\r"]
[635.004, "o", "cd asv_bench\r\n"]
[635.006, "o", "\u001b[?2004l\r\n"]
[640.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[640.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[640.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[645.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[645.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[645.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[645.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.14\u00b10ms \r\n              100000   73.6\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[650.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[650.002, "i", "cd ..\r"]
[650.004, "o", "cd ..\r\n"]
[650.006, "o", "\u001b[?2004l\r\n"]
[655.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[655.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[655.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[655.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[660.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[660.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[660.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[660.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[665.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[665.002, "i", "sed -n '800,980p' pandas/core/indexes/interval.py\r"]
[665.004, "o", "sed -n '800,980p' pandas/core/indexes/interval.py\r\n"]
[665.006, "o", "\u001b[?2004l\r\n\r\n    def _maybe_cast_slice_bound(self, label, side: str):\r\n        return getattr(self, side)._maybe_cast_slice_bound(label, side)\r\n\r\n    def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:\r\n        if not isinstance(dtype, IntervalDtype):\r\n            return False\r\n        common_subtype = find_common_type([self.dtype, dtype])\r\n        return not is_object_dtype(common_subtype)\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @cache_readonly\r\n    def left(self) -> Index:\r\n        return Index(self._data.left, copy=False)\r\n\r\n    @cache_readonly\r\n    def right(self) -> Index:\r\n        return Index(self._data.right, copy=False)\r\n\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[670.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[670.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[670.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[670.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[675.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[675.002, "i", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r"]
[675.004, "o", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[675.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[680.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[680.002, "i", "cd asv_bench\r"]
[680.004, "o", "cd asv_bench\r\n"]
[680.006, "o", "\u001b[?2004l\r\n"]
[685.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[685.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[685.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[690.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[690.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[690.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[690.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.17\u00b10ms \r\n              100000   75.8\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[695.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[695.002, "i", "cd ..\r"]
[695.004, "o", "cd ..\r\n"]
[695.006, "o", "\u001b[?2004l\r\n"]
[700.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[700.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[700.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[700.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[705.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[705.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[705.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[705.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[710.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[710.002, "i", "sed -n '800,980p' pandas/core/indexes/interval.py\r"]
[710.004, "o", "sed -n '800,980p' pandas/core/indexes/interval.py\r\n"]
[710.006, "o", "\u001b[?2004l\r\n\r\n    def _maybe_cast_slice_bound(self, label, side: str):\r\n        return getattr(self, side)._maybe_cast_slice_bound(label, side)\r\n\r\n    def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:\r\n        if not isinstance(dtype, IntervalDtype):\r\n            return False\r\n        common_subtype = find_common_type([self.dtype, dtype])\r\n        return not is_object_dtype(common_subtype)\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @cache_readonly\r\n    def left(self) -> Index:\r\n        return Index(self._data.left, copy=False)\r\n\r\n    @cache_readonly\r\n    def right(self) -> Index:\r\n        return Index(self._data.right, copy=False)\r\n\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[715.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[715.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[715.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[715.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[720.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[720.002, "i", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r"]
[720.004, "o", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[720.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[725.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[725.002, "i", "cd asv_bench\r"]
[725.004, "o", "cd asv_bench\r\n"]
[725.006, "o", "\u001b[?2004l\r\n"]
[730.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[730.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[730.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[735.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[735.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[735.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[735.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.17\u00b10ms \r\n              100000   76.6\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[740.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[740.002, "i", "cd ..\r"]
[740.004, "o", "cd ..\r\n"]
[740.006, "o", "\u001b[?2004l\r\n"]
[745.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[745.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[745.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[745.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[750.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[750.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[750.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[750.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[755.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[755.002, "i", "sed -n '800,980p' pandas/core/indexes/interval.py\r"]
[755.004, "o", "sed -n '800,980p' pandas/core/indexes/interval.py\r\n"]
[755.006, "o", "\u001b[?2004l\r\n\r\n    def _maybe_cast_slice_bound(self, label, side: str):\r\n        return getattr(self, side)._maybe_cast_slice_bound(label, side)\r\n\r\n    def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:\r\n        if not isinstance(dtype, IntervalDtype):\r\n            return False\r\n        common_subtype = find_common_type([self.dtype, dtype])\r\n        return not is_object_dtype(common_subtype)\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @cache_readonly\r\n    def left(self) -> Index:\r\n        return Index(self._data.left, copy=False)\r\n\r\n    @cache_readonly\r\n    def right(self) -> Index:\r\n        return Index(self._data.right, copy=False)\r\n\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[760.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[760.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[760.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[760.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[765.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[765.002, "i", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r"]
[765.004, "o", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[765.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[770.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[770.002, "i", "cd asv_bench\r"]
[770.004, "o", "cd asv_bench\r\n"]
[770.006, "o", "\u001b[?2004l\r\n"]
[775.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[775.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[775.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[780.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[780.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[780.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[780.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.17\u00b10ms \r\n              100000   77.0\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[785.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[785.002, "i", "cd ..\r"]
[785.004, "o", "cd ..\r\n"]
[785.006, "o", "\u001b[?2004l\r\n"]
[790.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[790.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[790.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[790.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[795.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[795.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[795.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[795.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[800.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[800.002, "i", "sed -n '820,980p' pandas/core/indexes/interval.py\r"]
[800.004, "o", "sed -n '820,980p' pandas/core/indexes/interval.py\r\n"]
[800.006, "o", "\u001b[?2004l\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[805.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[805.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[805.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[805.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[810.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[810.002, "i", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r"]
[810.004, "o", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[810.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[815.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[815.002, "i", "cd asv_bench\r"]
[815.004, "o", "cd asv_bench\r\n"]
[815.006, "o", "\u001b[?2004l\r\n"]
[820.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[820.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[820.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[825.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[825.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[825.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[825.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.19\u00b10ms \r\n              100000   74.9\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[830.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[830.002, "i", "cd ..\r"]
[830.004, "o", "cd ..\r\n"]
[830.006, "o", "\u001b[?2004l\r\n"]
[835.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[835.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[835.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[835.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[840.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[840.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[840.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[840.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[845.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[845.002, "i", "sed -n '800,980p' pandas/core/indexes/interval.py\r"]
[845.004, "o", "sed -n '800,980p' pandas/core/indexes/interval.py\r\n"]
[845.006, "o", "\u001b[?2004l\r\n\r\n    def _maybe_cast_slice_bound(self, label, side: str):\r\n        return getattr(self, side)._maybe_cast_slice_bound(label, side)\r\n\r\n    def _is_comparable_dtype(self, dtype: DtypeObj) -> bool:\r\n        if not isinstance(dtype, IntervalDtype):\r\n            return False\r\n        common_subtype = find_common_type([self.dtype, dtype])\r\n        return not is_object_dtype(common_subtype)\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @cache_readonly\r\n    def left(self) -> Index:\r\n        return Index(self._data.left, copy=False)\r\n\r\n    @cache_readonly\r\n    def right(self) -> Index:\r\n        return Index(self._data.right, copy=False)\r\n\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[850.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[850.002, "i", "sed -n '980,1160p' pandas/core/indexes/interval.py\r"]
[850.004, "o", "sed -n '980,1160p' pandas/core/indexes/interval.py\r\n"]
[850.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n        if all(is_integer(x) for x in com.not_none(start, end, freq)):\r\n            # np.linspace always produces float output\r\n\r\n            # error: Argument 1 to \"maybe_downcast_numeric\" has incompatible type\r\n            # \"Union[ndarray[Any, Any], TimedeltaIndex, DatetimeIndex]\";\r\n            # expected \"ndarray[Any, Any]\"  [\r\n            breaks = maybe_downcast_numeric(\r\n                breaks,  # type: ignore[arg-type]\r\n                np.dtype(\"int64\"),\r\n            )\r\n    else:\r\n        # delegate to the appropriate range function\r\n        if isinstance(endpoint, Timestamp):\r\n            breaks = date_range(start=start, end=end, periods=periods, freq=freq)\r\n        else:\r\n            breaks = timedelta_range(start=start, end=end, periods=periods, freq=freq)\r\n\r\n    return IntervalIndex.from_breaks(breaks, name=name, closed=closed)\r\n"]
[855.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[855.002, "i", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r"]
[855.004, "o", "sed -n '1,300p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[855.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[860.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[860.002, "i", "cd asv_bench\r"]
[860.004, "o", "cd asv_bench\r\n"]
[860.006, "o", "\u001b[?2004l\r\n"]
[865.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[865.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[865.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[870.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[870.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[870.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[870.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.13\u00b10ms \r\n              100000   74.3\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[875.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[875.002, "i", "cd ..\r"]
[875.004, "o", "cd ..\r\n"]
[875.006, "o", "\u001b[?2004l\r\n"]
[880.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[880.002, "i", "grep -n \"_intersection\" pandas/core/indexes/interval.py || true\r"]
[880.004, "o", "grep -n \"_intersection\" pandas/core/indexes/interval.py || true\r\n"]
[880.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K850\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(self, other, sort):\r\n\u001b[32m\u001b[K856\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(other)\r\n\u001b[32m\u001b[K860\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = other.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self)\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(other)\r\n\u001b[32m\u001b[K870\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K882\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is much more performant than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K906\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is about 3.25x faster than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K907\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        #  in IntervalIndexMethod.time\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_both_duplicate(1000)\r\n"]
[885.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[885.002, "i", "sed -n '840,940p' pandas/core/indexes/interval.py\r"]
[885.004, "o", "sed -n '840,940p' pandas/core/indexes/interval.py\r\n"]
[885.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n"]
[890.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[890.002, "i", "sed -n '940,1040p' pandas/core/indexes/interval.py\r"]
[890.004, "o", "sed -n '940,1040p' pandas/core/indexes/interval.py\r\n"]
[890.006, "o", "\u001b[?2004l\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n"]
[895.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[895.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[895.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[895.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[900.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[900.002, "i", "cd asv_bench\r"]
[900.004, "o", "cd asv_bench\r\n"]
[900.006, "o", "\u001b[?2004l\r\n"]
[905.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[905.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[905.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[910.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[910.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[910.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[910.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.15\u00b10ms \r\n              100000   78.3\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[915.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[915.002, "i", "cd ..\r"]
[915.004, "o", "cd ..\r\n"]
[915.006, "o", "\u001b[?2004l\r\n"]
[920.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[920.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[920.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[920.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[925.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[925.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[925.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[925.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[930.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[930.002, "i", "sed -n '840,960p' pandas/core/indexes/interval.py\r"]
[930.004, "o", "sed -n '840,960p' pandas/core/indexes/interval.py\r\n"]
[930.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n"]
[935.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[935.002, "i", "sed -n '960,1100p' pandas/core/indexes/interval.py\r"]
[935.004, "o", "sed -n '960,1100p' pandas/core/indexes/interval.py\r\n"]
[935.006, "o", "\u001b[?2004l\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n"]
[940.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[940.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[940.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[940.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[945.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[945.002, "i", "cd asv_bench\r"]
[945.004, "o", "cd asv_bench\r\n"]
[945.006, "o", "\u001b[?2004l\r\n"]
[950.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[950.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[950.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[955.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[955.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[955.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[955.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.15\u00b10ms \r\n              100000   75.9\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[960.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[960.002, "i", "cd ..\r"]
[960.004, "o", "cd ..\r\n"]
[960.006, "o", "\u001b[?2004l\r\n"]
[965.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[965.002, "i", "grep -n \"_intersection\" pandas/core/indexes/interval.py || true\r"]
[965.004, "o", "grep -n \"_intersection\" pandas/core/indexes/interval.py || true\r\n"]
[965.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K850\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(self, other, sort):\r\n\u001b[32m\u001b[K856\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(other)\r\n\u001b[32m\u001b[K860\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = other.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self)\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(other)\r\n\u001b[32m\u001b[K870\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K882\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is much more performant than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K906\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is about 3.25x faster than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K907\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        #  in IntervalIndexMethod.time\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_both_duplicate(1000)\r\n"]
[970.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[970.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[970.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[970.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[975.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[975.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[975.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[975.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[980.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[980.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[980.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[980.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[985.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[985.002, "i", "cd asv_bench\r"]
[985.004, "o", "cd asv_bench\r\n"]
[985.006, "o", "\u001b[?2004l\r\n"]
[990.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[990.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[990.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[995.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[995.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[995.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[995.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.19\u00b10ms \r\n              100000   76.1\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1000.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1000.002, "i", "cd ..\r"]
[1000.004, "o", "cd ..\r\n"]
[1000.006, "o", "\u001b[?2004l\r\n"]
[1005.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1005.002, "i", "grep -n \"_intersection\" pandas/core/indexes/interval.py || true\r"]
[1005.004, "o", "grep -n \"_intersection\" pandas/core/indexes/interval.py || true\r\n"]
[1005.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K850\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(self, other, sort):\r\n\u001b[32m\u001b[K856\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(other)\r\n\u001b[32m\u001b[K860\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = other.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self)\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(other)\r\n\u001b[32m\u001b[K870\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K882\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is much more performant than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K906\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is about 3.25x faster than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K907\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        #  in IntervalIndexMethod.time\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_both_duplicate(1000)\r\n"]
[1010.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1010.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[1010.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[1010.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[1015.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1015.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[1015.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[1015.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[1020.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1020.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[1020.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[1020.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[1025.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1025.002, "i", "cd asv_bench\r"]
[1025.004, "o", "cd asv_bench\r\n"]
[1025.006, "o", "\u001b[?2004l\r\n"]
[1030.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1030.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1030.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1035.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1035.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1035.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1035.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.17\u00b10ms \r\n              100000   73.1\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1040.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1040.002, "i", "cd ..\r"]
[1040.004, "o", "cd ..\r\n"]
[1040.006, "o", "\u001b[?2004l\r\n"]
[1045.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1045.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[1045.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1045.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1050.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1050.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[1050.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[1050.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[1055.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1055.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[1055.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[1055.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[1060.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1060.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[1060.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[1060.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[1065.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1065.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[1065.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[1065.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[1070.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1070.002, "i", "cd asv_bench\r"]
[1070.004, "o", "cd asv_bench\r\n"]
[1070.006, "o", "\u001b[?2004l\r\n"]
[1075.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1075.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1075.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1080.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1080.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1080.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1080.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.18\u00b10ms \r\n              100000   76.0\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1085.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1085.002, "i", "cd ..\r"]
[1085.004, "o", "cd ..\r\n"]
[1085.006, "o", "\u001b[?2004l\r\n"]
[1090.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1090.002, "i", "grep -n \"_intersection\" pandas/core/indexes/interval.py || true\r"]
[1090.004, "o", "grep -n \"_intersection\" pandas/core/indexes/interval.py || true\r\n"]
[1090.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K850\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(self, other, sort):\r\n\u001b[32m\u001b[K856\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(other)\r\n\u001b[32m\u001b[K860\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = other.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self)\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(other)\r\n\u001b[32m\u001b[K870\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K882\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is much more performant than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K906\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is about 3.25x faster than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K907\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        #  in IntervalIndexMethod.time\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_both_duplicate(1000)\r\n"]
[1095.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1095.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[1095.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[1095.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[1100.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1100.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[1100.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[1100.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[1105.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1105.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[1105.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[1105.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[1110.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1110.002, "i", "cd asv_bench\r"]
[1110.004, "o", "cd asv_bench\r\n"]
[1110.006, "o", "\u001b[?2004l\r\n"]
[1115.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1115.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1115.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1120.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1120.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1120.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1120.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.19\u00b10ms \r\n              100000   74.6\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1125.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1125.002, "i", "cd ..\r"]
[1125.004, "o", "cd ..\r\n"]
[1125.006, "o", "\u001b[?2004l\r\n"]
[1130.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1130.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[1130.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1130.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1135.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1135.002, "i", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r"]
[1135.004, "o", "grep -n \"_intersection_non_unique\" pandas/core/indexes/interval.py || true\r\n"]
[1135.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection_non_unique\u001b[m\u001b[K(self, other: IntervalIndex) -> IntervalIndex:\r\n"]
[1140.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1140.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[1140.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[1140.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[1145.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1145.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[1145.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[1145.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[1150.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1150.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[1150.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[1150.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[1155.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1155.002, "i", "cd asv_bench\r"]
[1155.004, "o", "cd asv_bench\r\n"]
[1155.006, "o", "\u001b[?2004l\r\n"]
[1160.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1160.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1160.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1165.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1165.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1165.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1165.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.22\u00b10ms \r\n              100000   76.1\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1170.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1170.002, "i", "cd ..\r"]
[1170.004, "o", "cd ..\r\n"]
[1170.006, "o", "\u001b[?2004l\r\n"]
[1175.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1175.002, "i", "grep -n \"_intersection\" pandas/core/indexes/interval.py || true\r"]
[1175.004, "o", "grep -n \"_intersection\" pandas/core/indexes/interval.py || true\r\n"]
[1175.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K850\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(self, other, sort):\r\n\u001b[32m\u001b[K856\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(other)\r\n\u001b[32m\u001b[K860\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = other.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self)\r\n\u001b[32m\u001b[K863\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            taken = self.\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(other)\r\n\u001b[32m\u001b[K870\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K882\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is much more performant than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K892\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    def \u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n\u001b[32m\u001b[K906\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # Note: this is about 3.25x faster than super().\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K(other)\r\n\u001b[32m\u001b[K907\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        #  in IntervalIndexMethod.time\u001b[01;31m\u001b[K_intersection\u001b[m\u001b[K_both_duplicate(1000)\r\n"]
[1180.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1180.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[1180.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[1180.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[1185.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1185.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[1185.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[1185.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[1190.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1190.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[1190.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[1190.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[1195.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1195.002, "i", "cd asv_bench\r"]
[1195.004, "o", "cd asv_bench\r\n"]
[1195.006, "o", "\u001b[?2004l\r\n"]
[1200.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1200.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1200.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1205.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1205.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1205.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1205.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.16\u00b10ms \r\n              100000   73.8\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1210.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1210.002, "i", "cd ..\r"]
[1210.004, "o", "cd ..\r\n"]
[1210.006, "o", "\u001b[?2004l\r\n"]
[1215.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1215.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[1215.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1215.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1220.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1220.002, "i", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r"]
[1220.004, "o", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1220.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1225.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1225.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[1225.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[1225.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[1230.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1230.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[1230.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[1230.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[1235.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1235.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[1235.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[1235.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[1240.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1240.002, "i", "cd asv_bench\r"]
[1240.004, "o", "cd asv_bench\r\n"]
[1240.006, "o", "\u001b[?2004l\r\n"]
[1245.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1245.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1245.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1250.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1250.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1250.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1250.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.18\u00b10ms \r\n              100000   74.2\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1255.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1255.002, "i", "cd ..\r"]
[1255.004, "o", "cd ..\r\n"]
[1255.006, "o", "\u001b[?2004l\r\n"]
[1260.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1260.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[1260.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1260.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1265.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1265.002, "i", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r"]
[1265.004, "o", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1265.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1270.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1270.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[1270.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[1270.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[1275.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1275.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[1275.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[1275.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[1280.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1280.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[1280.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[1280.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[1285.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1285.002, "i", "cd asv_bench\r"]
[1285.004, "o", "cd asv_bench\r\n"]
[1285.006, "o", "\u001b[?2004l\r\n"]
[1290.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1290.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1290.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1295.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1295.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1295.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1295.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.22\u00b10ms \r\n              100000   107\u00b10ms  \r\n             ======== ==========\r\n\r\n"]
[1300.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1300.002, "i", "cd ..\r"]
[1300.004, "o", "cd ..\r\n"]
[1300.006, "o", "\u001b[?2004l\r\n"]
[1305.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1305.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[1305.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1305.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1310.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1310.002, "i", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r"]
[1310.004, "o", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1310.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1315.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1315.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[1315.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[1315.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[1320.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1320.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[1320.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[1320.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[1325.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1325.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[1325.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[1325.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[1330.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1330.002, "i", "cd asv_bench\r"]
[1330.004, "o", "cd asv_bench\r\n"]
[1330.006, "o", "\u001b[?2004l\r\n"]
[1335.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1335.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1335.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1340.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1340.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1340.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1340.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.16\u00b10ms \r\n              100000   80.8\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1345.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1345.002, "i", "cd ..\r"]
[1345.004, "o", "cd ..\r\n"]
[1345.006, "o", "\u001b[?2004l\r\n"]
[1350.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1350.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[1350.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1350.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1355.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1355.002, "i", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r"]
[1355.004, "o", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1355.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1360.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1360.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[1360.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[1360.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[1365.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1365.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[1365.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[1365.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[1370.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1370.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[1370.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[1370.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[1375.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1375.002, "i", "cd asv_bench\r"]
[1375.004, "o", "cd asv_bench\r\n"]
[1375.006, "o", "\u001b[?2004l\r\n"]
[1380.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1380.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1380.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1385.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1385.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1385.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1385.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.21\u00b10ms \r\n              100000   80.3\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1390.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1390.002, "i", "cd ..\r"]
[1390.004, "o", "cd ..\r\n"]
[1390.006, "o", "\u001b[?2004l\r\n"]
[1395.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1395.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[1395.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1395.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1400.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1400.002, "i", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r"]
[1400.004, "o", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1400.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1405.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1405.002, "i", "sed -n '840,980p' pandas/core/indexes/interval.py\r"]
[1405.004, "o", "sed -n '840,980p' pandas/core/indexes/interval.py\r\n"]
[1405.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n"]
[1410.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1410.002, "i", "sed -n '980,1120p' pandas/core/indexes/interval.py\r"]
[1410.004, "o", "sed -n '980,1120p' pandas/core/indexes/interval.py\r\n"]
[1410.006, "o", "\u001b[?2004l\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   periods=3, freq='MS')\r\n    IntervalIndex([(2017-01-01, 2017-02-01], (2017-02-01, 2017-03-01],\r\n                   (2017-03-01, 2017-04-01]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    Specify ``start``, ``end``, and ``periods``; the frequency is generated\r\n    automatically (linearly spaced).\r\n\r\n    >>> pd.interval_range(start=0, end=6, periods=4)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n              dtype='interval[float64, right]')\r\n\r\n    The ``closed`` parameter specifies which endpoints of the individual\r\n    intervals within the ``IntervalIndex`` are closed.\r\n\r\n    >>> pd.interval_range(end=5, periods=4, closed='both')\r\n    IntervalIndex([[1, 2], [2, 3], [3, 4], [4, 5]],\r\n                  dtype='interval[int64, both]')\r\n    \"\"\"\r\n    start = maybe_box_datetimelike(start)\r\n    end = maybe_box_datetimelike(end)\r\n    endpoint = start if start is not None else end\r\n\r\n    if freq is None and com.any_none(periods, start, end):\r\n        freq = 1 if is_number(endpoint) else \"D\"\r\n\r\n    if com.count_not_none(start, end, periods, freq) != 3:\r\n        raise ValueError(\r\n            \"Of the four parameters: start, end, periods, and \"\r\n            \"freq, exactly three must be specified\"\r\n        )\r\n\r\n    if not _is_valid_endpoint(start):\r\n        raise ValueError(f\"start must be numeric or datetime-like, got {start}\")\r\n    if not _is_valid_endpoint(end):\r\n        raise ValueError(f\"end must be numeric or datetime-like, got {end}\")\r\n\r\n    if is_float(periods):\r\n        periods = int(periods)\r\n    elif not is_integer(periods) and periods is not None:\r\n        raise TypeError(f\"periods must be a number, got {periods}\")\r\n\r\n    if freq is not None and not is_number(freq):\r\n        try:\r\n            freq = to_offset(freq)\r\n        except ValueError as err:\r\n            raise ValueError(\r\n                f\"freq must be numeric or convertible to DateOffset, got {freq}\"\r\n            ) from err\r\n\r\n    # verify type compatibility\r\n    if not all(\r\n        [\r\n            _is_type_compatible(start, end),\r\n            _is_type_compatible(start, freq),\r\n            _is_type_compatible(end, freq),\r\n        ]\r\n    ):\r\n        raise TypeError(\"start, end, freq need to be type compatible\")\r\n\r\n    # +1 to convert interval count to breaks count (n breaks = n-1 intervals)\r\n    if periods is not None:\r\n        periods += 1\r\n\r\n    breaks: np.ndarray | TimedeltaIndex | DatetimeIndex\r\n\r\n    if is_number(endpoint):\r\n        # force consistency between start/end/freq (lower end if freq skips it)\r\n        if com.all_not_none(start, end, freq):\r\n            end -= (end - start) % freq\r\n\r\n        # compute the period/start/end if unspecified (at most one)\r\n        if periods is None:\r\n            periods = int((end - start) // freq) + 1\r\n        elif start is None:\r\n            start = end - (periods - 1) * freq\r\n        elif end is None:\r\n            end = start + (periods - 1) * freq\r\n\r\n        breaks = np.linspace(start, end, periods)\r\n"]
[1415.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1415.002, "i", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r"]
[1415.004, "o", "sed -n '1,320p' pandas/tests/indexes/interval/test_setops.py\r\n"]
[1415.006, "o", "\u001b[?2004l\r\nimport numpy as np\r\nimport pytest\r\n\r\nfrom pandas import (\r\n    Index,\r\n    IntervalIndex,\r\n    Timestamp,\r\n    interval_range,\r\n)\r\nimport pandas._testing as tm\r\n\r\n\r\ndef monotonic_index(start, end, dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex.from_breaks(np.arange(start, end, dtype=dtype), closed=closed)\r\n\r\n\r\ndef empty_index(dtype=\"int64\", closed=\"right\"):\r\n    return IntervalIndex(np.array([], dtype=dtype), closed=closed)\r\n\r\n\r\nclass TestIntervalIndex:\r\n    def test_union(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(0, 13, closed=closed)\r\n        result = index[::-1].union(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].union(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.union(index, sort=sort), index)\r\n        tm.assert_index_equal(index.union(index[:1], sort=sort), index)\r\n\r\n    def test_union_empty_result(self, closed, sort):\r\n        # GH 19101: empty result, same dtype\r\n        index = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, index)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is f8\r\n        other = empty_index(dtype=\"float64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        expected = other\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = index.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = empty_index(dtype=\"uint64\", closed=closed)\r\n        result = index.union(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        result = other.union(index, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        other = monotonic_index(5, 13, closed=closed)\r\n\r\n        expected = monotonic_index(5, 11, closed=closed)\r\n        result = index[::-1].intersection(other, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        result = other[::-1].intersection(index, sort=sort)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        tm.assert_index_equal(index.intersection(index, sort=sort), index)\r\n\r\n        # GH 26225: nested intervals\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 3), (1, 4), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (1, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225\r\n        index = IntervalIndex.from_tuples([(0, 3), (0, 2)])\r\n        other = IntervalIndex.from_tuples([(0, 2), (1, 3)])\r\n        expected = IntervalIndex.from_tuples([(0, 2)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 26225: duplicate nan element\r\n        index = IntervalIndex([np.nan, np.nan])\r\n        other = IntervalIndex([np.nan])\r\n        expected = IntervalIndex([np.nan])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_empty_result(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        other = monotonic_index(300, 314, closed=closed)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different numeric dtypes -> common dtype is float64\r\n        other = monotonic_index(300, 314, dtype=\"float64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        expected = other[:0]\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        other = monotonic_index(300, 314, dtype=\"uint64\", closed=closed)\r\n        result = index.intersection(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_intersection_duplicates(self):\r\n        # GH#38743\r\n        index = IntervalIndex.from_tuples([(1, 2), (1, 2), (2, 3), (3, 4)])\r\n        other = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        expected = IntervalIndex.from_tuples([(1, 2), (2, 3)])\r\n        result = index.intersection(other)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_difference(self, closed, sort):\r\n        index = IntervalIndex.from_arrays([1, 0, 3, 2], [1, 2, 3, 4], closed=closed)\r\n        result = index.difference(index[:1], sort=sort)\r\n        expected = index[1:]\r\n        if sort is None:\r\n            expected = expected.sort_values()\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.difference(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    def test_symmetric_difference(self, closed, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        result = index[1:].symmetric_difference(index[:-1], sort=sort)\r\n        expected = IntervalIndex([index[0], index[-1]])\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, same dtype\r\n        result = index.symmetric_difference(index, sort=sort)\r\n        expected = empty_index(dtype=\"int64\", closed=closed)\r\n        if sort is None:\r\n            tm.assert_index_equal(result, expected)\r\n        assert tm.equalContents(result, expected)\r\n\r\n        # GH 19101: empty result, different dtypes\r\n        other = IntervalIndex.from_arrays(\r\n            index.left.astype(\"float64\"), index.right, closed=closed\r\n        )\r\n        result = index.symmetric_difference(other, sort=sort)\r\n        expected = empty_index(dtype=\"float64\", closed=closed)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n    @pytest.mark.filterwarnings(\"ignore:'<' not supported between:RuntimeWarning\")\r\n    @pytest.mark.parametrize(\r\n        \"op_name\", [\"union\", \"intersection\", \"difference\", \"symmetric_difference\"]\r\n    )\r\n    def test_set_incompatible_types(self, closed, op_name, sort):\r\n        index = monotonic_index(0, 11, closed=closed)\r\n        set_op = getattr(index, op_name)\r\n\r\n        # TODO: standardize return type of non-union setops type(self vs other)\r\n        # non-IntervalIndex\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        else:\r\n            expected = getattr(index.astype(\"O\"), op_name)(Index([1, 2, 3]))\r\n        result = set_op(Index([1, 2, 3]), sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n\r\n        # mixed closed -> cast to object\r\n        for other_closed in {\"right\", \"left\", \"both\", \"neither\"} - {closed}:\r\n            other = monotonic_index(0, 11, closed=other_closed)\r\n            expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n            if op_name == \"difference\":\r\n                expected = index\r\n            result = set_op(other, sort=sort)\r\n            tm.assert_index_equal(result, expected)\r\n\r\n        # GH 19016: incompatible dtypes -> cast to object\r\n        other = interval_range(Timestamp(\"20180101\"), periods=9, closed=closed)\r\n        expected = getattr(index.astype(object), op_name)(other, sort=sort)\r\n        if op_name == \"difference\":\r\n            expected = index\r\n        result = set_op(other, sort=sort)\r\n        tm.assert_index_equal(result, expected)\r\n"]
[1420.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1420.002, "i", "cd asv_bench\r"]
[1420.004, "o", "cd asv_bench\r\n"]
[1420.006, "o", "\u001b[?2004l\r\n"]
[1425.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1425.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1425.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1430.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1430.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1430.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1430.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.26\u00b10ms \r\n              100000   85.1\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1435.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1435.002, "i", "cd ..\r"]
[1435.004, "o", "cd ..\r\n"]
[1435.006, "o", "\u001b[?2004l\r\n"]
[1440.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1440.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[1440.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1440.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1445.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1445.002, "i", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r"]
[1445.004, "o", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1445.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1450.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1450.002, "i", "sed -n '840,1040p' pandas/core/indexes/interval.py\r"]
[1450.004, "o", "sed -n '840,1040p' pandas/core/indexes/interval.py\r\n"]
[1450.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n"]
[1455.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1455.002, "i", "python - << 'PY'\r"]
[1455.004, "o", "python - << 'PY'\r\n"]
[1455.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import numpy as np\r\n\u001b[?2004l\r\n\u001b[?2004h> import time\r\n\u001b[?2004l\r\n\u001b[?2004h> from pandas.core.indexes.interval import IntervalIndex\r\n\u001b[?2004l\r\n\u001b[?2004h> from pandas import MultiIndex\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h> N = 100_000\r\n\u001b[?2004l\r\n\u001b[?2004h> left = np.append(np.arange(N), np.array(0))\r\n\u001b[?2004l\r\n\u001b[?2004h> right = np.append(np.arange(1, N + 1), np.array(1))\r\n\u001b[?2004l\r\n\u001b[?2004h> intv = IntervalIndex.from_arrays(left, right)\r\n\u001b[?2004l\r\n\u001b[?2004h> intv._engine\r\n\u001b[?2004l\r\n\u001b[?2004h> intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\r\n\u001b[?2004l\r\n\u001b[?2004h> intv2._engine\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h> # Baseline via current method\r\n\u001b[?2004l\r\n\u001b[?2004h> s = time.time(); res1 = intv.intersection(intv2); t1 = time.time()-s\r\n\u001b[?2004l\r\n\u001b[?2004h> \r\n\u001b[?2004l\r\n\u001b[?2004h> # Prototype using MultiIndex intersection\r\n\u001b[?2004l\r\n\u001b[?2004h> mi1 = MultiIndex.from_arrays([intv.left.values, intv.right.values])\r\n\u001b[?2004l\r\n\u001b[?2004h> mi2 = MultiIndex.from_arrays([intv2.left.values, intv2.right.values])\r\n\u001b[?2004l\r\n\u001b[?2004h> s = time.time(); mi_res = mi1.intersection(mi2, sort=False); t2 = time.time()-s\r\n\u001b[?2004l\r\n\u001b[?2004h> # reconstruct IntervalIndex\r\n\u001b[?2004l\r\n\u001b[?2004h> re = IntervalIndex.from_arrays(mi_res.get_level_values(0).values, mi_res.get_level_values(1).values, closed=intv.closed)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('baseline_len', len(res1), 'mi_len', len(re), 'equal', list(res1[:10])==list(re[:10]))\r\n\u001b[?2004l\r\n\u001b[?2004h> print('times: baseline:', round(t1*1000,2),'ms  mi:', round(t2*1000,2),'ms')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nbaseline_len 99999 mi_len 99999 equal True\r\ntimes: baseline: 99.22 ms  mi: 16.68 ms\r\n"]
[1460.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1460.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[1460.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1460.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1465.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1465.002, "i", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r"]
[1465.004, "o", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1465.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1470.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1470.002, "i", "sed -n '820,1040p' pandas/core/indexes/interval.py\r"]
[1470.004, "o", "sed -n '820,1040p' pandas/core/indexes/interval.py\r\n"]
[1470.006, "o", "\u001b[?2004l\r\n    @cache_readonly\r\n    def mid(self) -> Index:\r\n        return Index(self._data.mid, copy=False)\r\n\r\n    @property\r\n    def length(self) -> Index:\r\n        return Index(self._data.length, copy=False)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n    # __repr__ associated methods are based on MultiIndex\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # matches base class except for whitespace padding\r\n        return header + list(self._format_native_types(na_rep=na_rep))\r\n\r\n    def _format_native_types(\r\n        self, *, na_rep: str = \"NaN\", quoting=None, **kwargs\r\n    ) -> npt.NDArray[np.object_]:\r\n        # GH 28210: use base method but with different default na_rep\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n"]
[1475.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1475.002, "i", "python - << 'PY'\r"]
[1475.004, "o", "python - << 'PY'\r\n"]
[1475.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/indexes/interval.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> start = s.find('def _intersection_non_unique')\r\n\u001b[?2004l\r\n\u001b[?2004h> end = s.find('\\ndef ', start+1)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('start:', start, 'end:', end)\r\n\u001b[?2004l\r\n\u001b[?2004h> print(s[start-200:start+600])\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nstart: 29367 end: 30966\r\nr(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans a\r\n"]
[1480.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1480.002, "i", "applypatch << 'PATCH'\r"]
[1480.004, "o", "applypatch << 'PATCH'\r\n"]
[1480.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> *** Begin Patch\r\n\u001b[?2004l\r\n\u001b[?2004h> *** Update File: pandas/core/indexes/interval.py\r\n\u001b[?2004l\r\n\u001b[?2004h> @@\r\n\u001b[?2004l\r\n\u001b[?2004h>  def _intersection_non_unique(self, other, sort):\r\n\u001b[?2004l\r\n\u001b[?2004h> -    # existing implementation handles non-unique cases\r\n\u001b[?2004l\r\n\u001b[?2004h> -    # fall back to base behavior\r\n\u001b[?2004l\r\n\u001b[?2004h> -    return Index._intersection(self, other, sort=sort)\r\n\u001b[?2004l\r\n\u001b[?2004h> +    # Fastpath for non-unique IntervalIndex intersection:\r\n\u001b[?2004l\r\n\u001b[?2004h> +    # If both IntervalIndexes share the same dtype and 'closed' attribute,\r\n\u001b[?2004l\r\n\u001b[?2004h> +    # we can intersect pairs of (left, right) endpoints using a MultiIndex\r\n\u001b[?2004l\r\n\u001b[?2004h> +    # and then reconstruct an IntervalIndex. This avoids expensive Python-level\r\n\u001b[?2004l\r\n\u001b[?2004h> +    # handling and leverages optimized index setops. Semantics (order and\r\n\u001b[?2004l\r\n\u001b[?2004h> +    # duplicate handling) follow Index.intersection with sort=False.\r\n\u001b[?2004l\r\n\u001b[?2004h> +    try:\r\n\u001b[?2004l\r\n\u001b[?2004h> +        if isinstance(other, IntervalIndex) and self.closed == other.closed:\r\n\u001b[?2004l\r\n\u001b[?2004h> +            # Ensure comparable endpoint dtypes and avoid object dtype\r\n\u001b[?2004l\r\n\u001b[?2004h> +            left1 = self.left.values\r\n\u001b[?2004l\r\n\u001b[?2004h> +            right1 = self.right.values\r\n\u001b[?2004l\r\n\u001b[?2004h> +            left2 = other.left.values\r\n\u001b[?2004l\r\n\u001b[?2004h> +            right2 = other.right.values\r\n\u001b[?2004l\r\n\u001b[?2004h> +\r\n\u001b[?2004l\r\n\u001b[?2004h> +            if (\r\n\u001b[?2004l\r\n\u001b[?2004h> +                left1.dtype == left2.dtype\r\n\u001b[?2004l\r\n\u001b[?2004h> +                and right1.dtype == right2.dtype\r\n\u001b[?2004l\r\n\u001b[?2004h> +                and left1.dtype != object\r\n\u001b[?2004l\r\n\u001b[?2004h> +                and right1.dtype != object\r\n\u001b[?2004l\r\n\u001b[?2004h> +            ):\r\n\u001b[?2004l\r\n\u001b[?2004h> +                from pandas import MultiIndex\r\n\u001b[?2004l\r\n\u001b[?2004h> +                mi1 = MultiIndex.from_arrays([left1, right1])\r\n\u001b[?2004l\r\n\u001b[?2004h> +                mi2 = MultiIndex.from_arrays([left2, right2])\r\n\u001b[?2004l\r\n\u001b[?2004h> +                mi_res = mi1.intersection(mi2, sort=False)\r\n\u001b[?2004l\r\n\u001b[?2004h> +                if len(mi_res) == 0:\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    return self[:0]\r\n\u001b[?2004l\r\n\u001b[?2004h> +                res_left = mi_res.get_level_values(0).values\r\n\u001b[?2004l\r\n\u001b[?2004h> +                res_right = mi_res.get_level_values(1).values\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # Reconstruct IntervalIndex; keep closed from self.\r\n\u001b[?2004l\r\n\u001b[?2004h> +                return IntervalIndex.from_arrays(res_left, res_right, closed=self.closed)\r\n\u001b[?2004l\r\n\u001b[?2004h> +    except Exception:\r\n\u001b[?2004l\r\n\u001b[?2004h> +        # Fall back to existing implementation on any issue\r\n\u001b[?2004l\r\n\u001b[?2004h> +        pass\r\n\u001b[?2004l\r\n\u001b[?2004h> +\r\n\u001b[?2004l\r\n\u001b[?2004h> +    # Fallback to base behavior\r\n\u001b[?2004l\r\n\u001b[?2004h> +    return Index._intersection(self, other, sort=sort)\r\n\u001b[?2004l\r\n\u001b[?2004h> *** End Patch\r\n\u001b[?2004l\r\n\u001b[?2004h> PATCH\r\n\u001b[?2004l\r\n-bash: applypatch: command not found\r\n"]
[1485.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1485.002, "i", "python -m pyflakes pandas/core/indexes/interval.py 2>/dev/null || true\r"]
[1485.004, "o", "python -m pyflakes pandas/core/indexes/interval.py 2>/dev/null || true\r\n"]
[1485.006, "o", "\u001b[?2004l\r\n"]
[1490.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1490.002, "i", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/null || tru\r"]
[1490.004, "o", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/null || tru\r\n"]
[1490.006, "o", "ue\r\n\u001b[?2004l\r\ncd asv_bench\r\nasv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\"\r\nasv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection\" \r\n\r\n\u001b[33m======================================================================= warnings summary =======================================================================\u001b[0m\r\npandas/core/construction.py:335\r\n  /workspace/repo/pandas/core/construction.py:335: UserWarning: pyarrow requires pandas 1.0.0 or above, pandas 0+untagged.31506.g5f584bd is installed. Therefore, pandas-specific integration is not used.\r\n    return cls._from_sequence(data, dtype=dtype, copy=copy)\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n------------------------------------------------------ generated xml file: /workspace/repo/test-data.xml -------------------------------------------------------\r\n\u001b[33m\u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m214465 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 104.76s (0:01:44)\u001b[0m\u001b[0m\r\n"]
[1495.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1495.002, "i", "cd asv_bench\r"]
[1495.004, "o", "cd asv_bench\r\n"]
[1495.006, "o", "\u001b[?2004l\r\n"]
[1500.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1500.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1500.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1505.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1505.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1505.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1505.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.33\u00b10ms \r\n              100000   86.0\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1510.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1510.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection\" \r"]
[1510.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection\" \r\n"]
[1510.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection\u001b[0m                                                                                              ok\r\n[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.01\u00b10ms \r\n              100000   8.90\u00b10ms \r\n             ======== ==========\r\n\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.25\u00b10ms \r\n              100000   93.8\u00b10ms \r\n             ======== ==========\r\n\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_one_duplicate\u001b[0m                                                                                ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    828\u00b10\u03bcs  \r\n              100000   8.27\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1515.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1515.002, "i", "cd ..\r"]
[1515.004, "o", "cd ..\r\n"]
[1515.006, "o", "\u001b[?2004l\r\n"]
[1520.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1520.002, "i", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r"]
[1520.004, "o", "grep -n \"def _intersection\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1520.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1525.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1525.002, "i", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r"]
[1525.004, "o", "grep -n \"def _intersection_non_unique\\(\" pandas/core/indexes/interval.py || true\r\n"]
[1525.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[1530.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1530.002, "i", "sed -n '840,1040p' pandas/core/indexes/interval.py\r"]
[1530.004, "o", "sed -n '840,1040p' pandas/core/indexes/interval.py\r\n"]
[1530.006, "o", "\u001b[?2004l\r\n        return super()._format_native_types(na_rep=na_rep, quoting=quoting, **kwargs)\r\n\r\n    def _format_data(self, name=None) -> str:\r\n        # TODO: integrate with categorical and make generic\r\n        # name argument is unused here; just for compat with base / categorical\r\n        return f\"{self._data._format_data()},{self._format_space()}\"\r\n\r\n    # --------------------------------------------------------------------\r\n    # Set Operations\r\n\r\n    def _intersection(self, other, sort):\r\n        \"\"\"\r\n        intersection specialized to the case with matching dtypes.\r\n        \"\"\"\r\n        # For IntervalIndex we also know other.closed == self.closed\r\n        if self.left.is_unique and self.right.is_unique:\r\n            taken = self._intersection_unique(other)\r\n        elif other.left.is_unique and other.right.is_unique and self.isna().sum() <= 1:\r\n            # Swap other/self if other is unique and self does not have\r\n            # multiple NaNs\r\n            taken = other._intersection_unique(self)\r\n        else:\r\n            # duplicates\r\n            taken = self._intersection_non_unique(other)\r\n\r\n        if sort is None:\r\n            taken = taken.sort_values()\r\n\r\n        return taken\r\n\r\n    def _intersection_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does not have any common endpoint,\r\n        no matter left or right.\r\n        Return the intersection with another IntervalIndex.\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is much more performant than super()._intersection(other)\r\n        lindexer = self.left.get_indexer(other.left)\r\n        rindexer = self.right.get_indexer(other.right)\r\n\r\n        match = (lindexer == rindexer) & (lindexer != -1)\r\n        indexer = lindexer.take(match.nonzero()[0])\r\n        indexer = unique(indexer)\r\n\r\n        return self.take(indexer)\r\n\r\n    def _intersection_non_unique(self, other: IntervalIndex) -> IntervalIndex:\r\n        \"\"\"\r\n        Used when the IntervalIndex does have some common endpoints,\r\n        on either sides.\r\n        Return the intersection with another IntervalIndex.\r\n\r\n        Parameters\r\n        ----------\r\n        other : IntervalIndex\r\n\r\n        Returns\r\n        -------\r\n        IntervalIndex\r\n        \"\"\"\r\n        # Note: this is about 3.25x faster than super()._intersection(other)\r\n        #  in IntervalIndexMethod.time_intersection_both_duplicate(1000)\r\n        mask = np.zeros(len(self), dtype=bool)\r\n\r\n        if self.hasnans and other.hasnans:\r\n            first_nan_loc = np.arange(len(self))[self.isna()][0]\r\n            mask[first_nan_loc] = True\r\n\r\n        other_tups = set(zip(other.left, other.right))\r\n        for i, tup in enumerate(zip(self.left, self.right)):\r\n            if tup in other_tups:\r\n                mask[i] = True\r\n\r\n        return self[mask]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    def _get_engine_target(self) -> np.ndarray:\r\n        # Note: we _could_ use libjoin functions by either casting to object\r\n        #  dtype or constructing tuples (faster than constructing Intervals)\r\n        #  but the libjoin fastpaths are no longer fast in these cases.\r\n        raise NotImplementedError(\r\n            \"IntervalIndex does not use libjoin fastpaths or pass values to \"\r\n            \"IndexEngine objects\"\r\n        )\r\n\r\n    def _from_join_target(self, result):\r\n        raise NotImplementedError(\"IntervalIndex does not use libjoin fastpaths\")\r\n\r\n    # TODO: arithmetic operations\r\n\r\n\r\ndef _is_valid_endpoint(endpoint) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check if start/end are valid types.\r\n    \"\"\"\r\n    return any(\r\n        [\r\n            is_number(endpoint),\r\n            isinstance(endpoint, Timestamp),\r\n            isinstance(endpoint, Timedelta),\r\n            endpoint is None,\r\n        ]\r\n    )\r\n\r\n\r\ndef _is_type_compatible(a, b) -> bool:\r\n    \"\"\"\r\n    Helper for interval_range to check type compat of start/end/freq.\r\n    \"\"\"\r\n    is_ts_compat = lambda x: isinstance(x, (Timestamp, BaseOffset))\r\n    is_td_compat = lambda x: isinstance(x, (Timedelta, BaseOffset))\r\n    return (\r\n        (is_number(a) and is_number(b))\r\n        or (is_ts_compat(a) and is_ts_compat(b))\r\n        or (is_td_compat(a) and is_td_compat(b))\r\n        or com.any_none(a, b)\r\n    )\r\n\r\n\r\ndef interval_range(\r\n    start=None,\r\n    end=None,\r\n    periods=None,\r\n    freq=None,\r\n    name: Hashable = None,\r\n    closed: IntervalClosedType = \"right\",\r\n) -> IntervalIndex:\r\n    \"\"\"\r\n    Return a fixed frequency IntervalIndex.\r\n\r\n    Parameters\r\n    ----------\r\n    start : numeric or datetime-like, default None\r\n        Left bound for generating intervals.\r\n    end : numeric or datetime-like, default None\r\n        Right bound for generating intervals.\r\n    periods : int, default None\r\n        Number of periods to generate.\r\n    freq : numeric, str, datetime.timedelta, or DateOffset, default None\r\n        The length of each interval. Must be consistent with the type of start\r\n        and end, e.g. 2 for numeric, or '5H' for datetime-like.  Default is 1\r\n        for numeric and 'D' for datetime-like.\r\n    name : str, default None\r\n        Name of the resulting IntervalIndex.\r\n    closed : {'left', 'right', 'both', 'neither'}, default 'right'\r\n        Whether the intervals are closed on the left-side, right-side, both\r\n        or neither.\r\n\r\n    Returns\r\n    -------\r\n    IntervalIndex\r\n\r\n    See Also\r\n    --------\r\n    IntervalIndex : An Index of intervals that are all closed on the same side.\r\n\r\n    Notes\r\n    -----\r\n    Of the four parameters ``start``, ``end``, ``periods``, and ``freq``,\r\n    exactly three must be specified. If ``freq`` is omitted, the resulting\r\n    ``IntervalIndex`` will have ``periods`` linearly spaced elements between\r\n    ``start`` and ``end``, inclusively.\r\n\r\n    To learn more about datetime-like frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n\r\n    Examples\r\n    --------\r\n    Numeric ``start`` and  ``end`` is supported.\r\n\r\n    >>> pd.interval_range(start=0, end=5)\r\n    IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],\r\n                  dtype='interval[int64, right]')\r\n\r\n    Additionally, datetime-like input is also supported.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n    ...                   end=pd.Timestamp('2017-01-04'))\r\n    IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03],\r\n                   (2017-01-03, 2017-01-04]],\r\n                  dtype='interval[datetime64[ns], right]')\r\n\r\n    The ``freq`` parameter specifies the frequency between the left and right.\r\n    endpoints of the individual intervals within the ``IntervalIndex``.  For\r\n    numeric ``start`` and ``end``, the frequency must also be numeric.\r\n\r\n    >>> pd.interval_range(start=0, periods=4, freq=1.5)\r\n    IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]],\r\n                  dtype='interval[float64, right]')\r\n\r\n    Similarly, for datetime-like ``start`` and ``end``, the frequency must be\r\n    convertible to a DateOffset.\r\n\r\n    >>> pd.interval_range(start=pd.Timestamp('2017-01-01'),\r\n"]
[1535.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1535.002, "i", "applypatch << 'PATCH'\r"]
[1535.004, "o", "applypatch << 'PATCH'\r\n"]
[1535.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> *** Begin Patch\r\n\u001b[?2004l\r\n\u001b[?2004h> *** Update File: pandas/core/indexes/interval.py\r\n\u001b[?2004l\r\n\u001b[?2004h> @@\r\n\u001b[?2004l\r\n\u001b[?2004h> -    try:\r\n\u001b[?2004l\r\n\u001b[?2004h> -        if isinstance(other, IntervalIndex) and self.closed == other.closed:\r\n\u001b[?2004l\r\n\u001b[?2004h> +    try:\r\n\u001b[?2004l\r\n\u001b[?2004h> +        # Only fastpath when we don't request sorting (preserve existing order)\r\n\u001b[?2004l\r\n\u001b[?2004h> +        if sort is not True and isinstance(other, IntervalIndex) and self.closed == other.closed:\r\n\u001b[?2004l\r\n\u001b[?2004h> @@\r\n\u001b[?2004l\r\n\u001b[?2004h> -                mi_res = mi1.intersection(mi2, sort=False)\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # preserve order semantics of default intersection (sort=False)\r\n\u001b[?2004l\r\n\u001b[?2004h> +                mi_res = mi1.intersection(mi2, sort=False)\r\n\u001b[?2004l\r\n\u001b[?2004h>                  if len(mi_res) == 0:\r\n\u001b[?2004l\r\n\u001b[?2004h>                      return self[:0]\r\n\u001b[?2004l\r\n\u001b[?2004h>                  res_left = mi_res.get_level_values(0).values\r\n\u001b[?2004l\r\n\u001b[?2004h>                  res_right = mi_res.get_level_values(1).values\r\n\u001b[?2004l\r\n\u001b[?2004h> -                # Reconstruct IntervalIndex; keep closed from self.\r\n\u001b[?2004l\r\n\u001b[?2004h> -                return IntervalIndex.from_arrays(res_left, res_right, closed=self.closed)\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # Reconstruct IntervalIndex; keep closed from self and set name\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # consistently with Index.intersection semantics: common name only.\r\n\u001b[?2004l\r\n\u001b[?2004h> +                name = self.name if self.name == other.name else None\r\n\u001b[?2004l\r\n\u001b[?2004h> +                return IntervalIndex.from_arrays(res_left, res_right, closed=self.closed, name=name)\r\n\u001b[?2004l\r\n\u001b[?2004h> *** End Patch\r\n\u001b[?2004l\r\n\u001b[?2004h> PATCH\r\n\u001b[?2004l\r\n-bash: applypatch: command not found\r\n"]
[1540.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1540.002, "i", "python -m pyflakes pandas/core/indexes/interval.py 2>/dev/null || true\r"]
[1540.004, "o", "python -m pyflakes pandas/core/indexes/interval.py 2>/dev/null || true\r\n"]
[1540.006, "o", "\u001b[?2004l\r\n"]
[1545.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1545.002, "i", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/null || tru\r"]
[1545.004, "o", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/null || tru\r\n"]
[1545.006, "o", "ue\r\n\u001b[?2004l\r\ncd asv_bench\r\nasv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\"\r\n\r\n\u001b[33m======================================================================= warnings summary =======================================================================\u001b[0m\r\npandas/core/construction.py:335\r\n  /workspace/repo/pandas/core/construction.py:335: UserWarning: pyarrow requires pandas 1.0.0 or above, pandas 0+untagged.31506.g5f584bd is installed. Therefore, pandas-specific integration is not used.\r\n    return cls._from_sequence(data, dtype=dtype, copy=copy)\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n------------------------------------------------------ generated xml file: /workspace/repo/test-data.xml -------------------------------------------------------\r\n\u001b[33m\u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m214465 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 97.02s (0:01:37)\u001b[0m\u001b[0m\r\nasv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\"\r\n"]
[1550.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1550.002, "i", "cd asv_bench\r"]
[1550.004, "o", "cd asv_bench\r\n"]
[1550.006, "o", "\u001b[?2004l\r\n"]
[1555.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1555.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1555.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1560.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1560.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1560.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1560.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.22\u00b10ms \r\n              100000   87.5\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1565.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1565.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1565.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1570.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1570.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1570.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1570.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.19\u00b10ms \r\n              100000   76.3\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1575.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1575.002, "i", "cd ..\r"]
[1575.004, "o", "cd ..\r\n"]
[1575.006, "o", "\u001b[?2004l\r\n"]
[1580.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1580.002, "i", "grep -n \"from pandas import MultiIndex\" pandas/core/indexes/interval.py || true\r"]
[1580.004, "o", "grep -n \"from pandas import MultiIndex\" pandas/core/indexes/interval.py || true\r\n"]
[1580.006, "o", "\u001b[?2004l\r\n"]
[1585.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1585.002, "i", "applypatch << 'PATCH'\r"]
[1585.004, "o", "applypatch << 'PATCH'\r\n"]
[1585.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> *** Begin Patch\r\n\u001b[?2004l\r\n\u001b[?2004h> *** Update File: pandas/core/indexes/interval.py\r\n\u001b[?2004l\r\n\u001b[?2004h> @@\r\n\u001b[?2004l\r\n\u001b[?2004h> -                from pandas import MultiIndex\r\n\u001b[?2004l\r\n\u001b[?2004h> -                mi1 = MultiIndex.from_arrays([left1, right1])\r\n\u001b[?2004l\r\n\u001b[?2004h> -                mi2 = MultiIndex.from_arrays([left2, right2])\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # Use already-imported MultiIndex to avoid heavy top-level imports\r\n\u001b[?2004l\r\n\u001b[?2004h> +                mi1 = MultiIndex.from_arrays([left1, right1])\r\n\u001b[?2004l\r\n\u001b[?2004h> +                mi2 = MultiIndex.from_arrays([left2, right2])\r\n\u001b[?2004l\r\n\u001b[?2004h> *** End Patch\r\n\u001b[?2004l\r\n\u001b[?2004h> PATCH\r\n\u001b[?2004l\r\n-bash: applypatch: command not found\r\n"]
[1590.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1590.002, "i", "python -m pyflakes pandas/core/indexes/interval.py 2>/dev/null || true\r"]
[1590.004, "o", "python -m pyflakes pandas/core/indexes/interval.py 2>/dev/null || true\r\n"]
[1590.006, "o", "\u001b[?2004l\r\n"]
[1595.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1595.002, "i", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/null || tru\r"]
[1595.004, "o", "pytest -q -k \"pandas/tests/indexes/interval/test_setops.py::TestIntervalIndex::test_intersection\" 2>/dev/null || tru\r\n"]
[1595.006, "o", "ue\r\n\u001b[?2004l\r\ncd asv_bench\r\nasv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\"\r\n\r\n\u001b[33m======================================================================= warnings summary =======================================================================\u001b[0m\r\npandas/core/construction.py:335\r\n  /workspace/repo/pandas/core/construction.py:335: UserWarning: pyarrow requires pandas 1.0.0 or above, pandas 0+untagged.31506.g5f584bd is installed. Therefore, pandas-specific integration is not used.\r\n    return cls._from_sequence(data, dtype=dtype, copy=copy)\r\n\r\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\r\n------------------------------------------------------ generated xml file: /workspace/repo/test-data.xml -------------------------------------------------------\r\n\u001b[33m\u001b[33m\u001b[1m1 skipped\u001b[0m, \u001b[33m\u001b[1m214465 deselected\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 102.10s (0:01:42)\u001b[0m\u001b[0m\r\nasv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.*\"\r\n"]
[1600.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo# "]
[1600.002, "i", "cd asv_bench\r"]
[1600.004, "o", "cd asv_bench\r\n"]
[1600.006, "o", "\u001b[?2004l\r\n"]
[1605.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1605.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r"]
[1605.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\" \r\n"]
[1610.0, "o", "\u001bM(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1610.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r"]
[1610.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[K\"\r\n"]
[1610.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.20\u00b10ms \r\n              100000   80.3\u00b10ms \r\n             ======== ==========\r\n\r\n"]
[1615.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1615.002, "i", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.*\"\r"]
[1615.004, "o", "asv run --python=same --quick --bench=\"index_object.IntervalIndexMethod.*\"\r\n"]
[1615.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 5 total benchmarks (1 commits * 1 environments * 5 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[10.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection\u001b[0m                                                                                              ok\r\n[10.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    909\u00b10\u03bcs  \r\n              100000   7.73\u00b10ms \r\n             ======== ==========\r\n\r\n[20.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_both_duplicate\u001b[0m                                                                               ok\r\n[20.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    1.15\u00b10ms \r\n              100000   82.2\u00b10ms \r\n             ======== ==========\r\n\r\n[30.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_intersection_one_duplicate\u001b[0m                                                                                ok\r\n[30.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    786\u00b10\u03bcs  \r\n              100000   8.10\u00b10ms \r\n             ======== ==========\r\n\r\n[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_is_unique\u001b[0m                                                                                                 ok\r\n[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    261\u00b10\u03bcs  \r\n              100000   4.08\u00b10ms \r\n             ======== ==========\r\n\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.IntervalIndexMethod.time_monotonic_inc\u001b[0m                                                                                             ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              param1            \r\n             -------- ----------\r\n               1000    63.9\u00b10\u03bcs \r\n              100000   364\u00b10\u03bcs  \r\n             ======== ==========\r\n\r\n"]
[1620.0, "o", "(asv_3.8) root@4dad128a768f:/workspace/repo/asv_bench# "]
[1620.002, "i", "\u001b[?2004l\r"]
[1620.004, "o", "\u001b[?2004l\r\n"]
[1620.006, "o", "\r\nlogout\r\n"]
