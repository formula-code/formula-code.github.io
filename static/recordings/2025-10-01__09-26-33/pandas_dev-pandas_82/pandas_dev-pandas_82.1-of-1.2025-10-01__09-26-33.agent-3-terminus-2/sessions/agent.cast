{"version": 2, "width": 160, "height": 40, "timestamp": 1762942266, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[0.006, "o", "\u001b[?2004l\r\n\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n\u001b[0;31masciinema: use --append option if you want to append to existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[5.006, "o", "\u001b[?2004l\r\n\u001b[H\u001b[J\r\n"]
[10.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.006, "o", "\u001b[?2004l\r\ntotal 216\r\ndrwxr-xr-x 1 root root  4096 Oct  1 14:09 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 15 17:16 \u001b[01;34m..\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 12 22:25 \u001b[01;34m.circleci\u001b[0m\r\n-rw-r--r-- 1 root root  1021 Sep 12 22:25 .devcontainer.json\r\ndrwxr-xr-x 1 root root  4096 Oct  1 14:01 \u001b[01;34m.git\u001b[0m\r\n-rw-r--r-- 1 root root  1670 Sep 12 22:25 .gitattributes\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34m.github\u001b[0m\r\n-rw-r--r-- 1 root root  1919 Sep 12 22:25 .gitignore\r\n-rw-r--r-- 1 root root  2296 Sep 12 22:25 .gitpod.yml\r\n-rw-r--r-- 1 root root 10674 Sep 12 22:25 .pre-commit-config.yaml\r\n-rw-r--r-- 1 root root  2284 Sep 12 22:25 AUTHORS.md\r\n-rw-r--r-- 1 root root  1541 Sep 12 22:25 CITATION.cff\r\n-rw-r--r-- 1 root root   455 Sep 12 22:25 Dockerfile\r\n-rw-r--r-- 1 root root  1634 Sep 12 22:25 LICENSE\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mLICENSES\u001b[0m\r\n-rw-r--r-- 1 root root  1335 Sep 12 22:25 MANIFEST.in\r\n-rw-r--r-- 1 root root 11670 Sep 12 22:25 README.md\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34masv_bench\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:27 \u001b[01;34mbuild\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mci\u001b[0m\r\n-rw-r--r-- 1 root root   256 Sep 12 22:25 codecov.yml\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mdoc\u001b[0m\r\n-rw-r--r-- 1 root root  2612 Sep 12 22:25 environment.yml\r\n-rw-r--r-- 1 root root   866 Sep 12 22:25 generate_pxi.py\r\n-rw-r--r-- 1 root root  1715 Sep 12 22:25 generate_version.py\r\ndrwxr-xr-x 2 root root  4096 Sep 12 22:25 \u001b[01;34mgitpod\u001b[0m\r\n-rw-r--r-- 1 root root  1646 Sep 12 22:25 meson.build\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mpandas\u001b[0m\r\n-rw-r--r-- 1 root root 21652 Sep 12 22:25 pyproject.toml\r\n-rw-r--r-- 1 root root  4307 Sep 12 22:25 pyright_reportGeneralTypeIssues.json\r\n-rw-r--r-- 1 root root  1398 Sep 12 22:25 requirements-dev.txt\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mscripts\u001b[0m\r\n-rwxr-xr-x 1 root root 21960 Sep 12 22:25 \u001b[01;32msetup.py\u001b[0m\r\ndrwxr-xr-x 3 root root  4096 Sep 12 22:25 \u001b[01;34mtooling\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 12 22:25 \u001b[01;34mtypings\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mweb\u001b[0m\r\n"]
[15.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[15.002, "i", "ls -la asv_bench/\r"]
[15.004, "o", "ls -la asv_bench/\r\n"]
[15.006, "o", "\u001b[?2004l\r\ntotal 24\r\ndrwxr-xr-x 1 root root 4096 Sep 12 22:25 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root 4096 Oct  1 14:09 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root 5194 Sep 12 22:25 asv.conf.json\r\ndrwxr-xr-x 1 root root 4096 Sep 12 22:25 \u001b[01;34mbenchmarks\u001b[0m\r\n"]
[20.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[20.002, "i", "cat asv_bench/asv.conf.json\r"]
[20.004, "o", "cat asv_bench/asv.conf.json\r\n"]
[20.006, "o", "\u001b[?2004l\r\n{\r\n    // The version of the config file format.  Do not change, unless\r\n    // you know what you are doing.\r\n    \"version\": 1,\r\n\r\n    // The name of the project being benchmarked\r\n    \"project\": \"pandas\",\r\n\r\n    // The project's homepage\r\n    \"project_url\": \"https://pandas.pydata.org/\",\r\n\r\n    // The URL of the source code repository for the project being\r\n    // benchmarked\r\n    \"repo\": \"..\",\r\n\r\n    // List of branches to benchmark. If not provided, defaults to \"master\"\r\n    // (for git) or \"default\" (for mercurial).\r\n    \"branches\": [\"main\"],\r\n\r\n    // The tool to use to create environments.  May be \"conda\",\r\n    // \"virtualenv\" or other value depending on the plugins in use.\r\n    // If missing or the empty string, the tool will be automatically\r\n    // determined by looking for tools on the PATH environment\r\n    // variable.\r\n    \"environment_type\": \"conda\",\r\n\r\n    // the base URL to show a commit for the project.\r\n    \"show_commit_url\": \"https://github.com/pandas-dev/pandas/commit/\",\r\n\r\n    // The Pythons you'd like to test against.  If not provided, defaults\r\n    // to the current version of Python used to run `asv`.\r\n    \"pythons\": [\"3.10\"],\r\n\r\n    // The matrix of dependencies to test.  Each key is the name of a\r\n    // package (in PyPI) and the values are version numbers.  An empty\r\n    // list or empty string indicates to just test against the default\r\n    // (latest) version. null indicates that the package is to not be\r\n    // installed. If the package to be tested is only available from\r\n    // PyPi, and the 'environment_type' is conda, then you can preface\r\n    // the package name by 'pip+', and the package will be installed via\r\n    // pip (with all the conda available packages installed first,\r\n    // followed by the pip installed packages).\r\n    \"matrix\": {\r\n        \"pip+build\": [],\r\n        \"Cython\": [\"3.0\"],\r\n        \"matplotlib\": [],\r\n        \"sqlalchemy\": [],\r\n        \"scipy\": [],\r\n        \"numba\": [],\r\n        \"numexpr\": [],\r\n        \"pytables\": [null, \"\"],  // platform dependent, see excludes below\r\n        \"pyarrow\": [],\r\n        \"tables\": [null, \"\"],\r\n        \"openpyxl\": [],\r\n        \"xlsxwriter\": [],\r\n        \"xlrd\": [],\r\n        \"odfpy\": [],\r\n        \"jinja2\": [],\r\n        \"meson\": [],\r\n        \"meson-python\": [],\r\n        \"python-build\": [],\r\n    },\r\n    \"conda_channels\": [\"conda-forge\"],\r\n    // Combinations of libraries/python versions can be excluded/included\r\n    // from the set to test. Each entry is a dictionary containing additional\r\n    // key-value pairs to include/exclude.\r\n    //\r\n    // An exclude entry excludes entries where all values match. The\r\n    // values are regexps that should match the whole string.\r\n    //\r\n    // An include entry adds an environment. Only the packages listed\r\n    // are installed. The 'python' key is required. The exclude rules\r\n    // do not apply to includes.\r\n    //\r\n    // In addition to package names, the following keys are available:\r\n    //\r\n    // - python\r\n    //     Python version, as in the *pythons* variable above.\r\n    // - environment_type\r\n    //     Environment type, as above.\r\n    // - sys_platform\r\n    //     Platform, as in sys.platform. Possible values for the common\r\n    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.\r\n    \"exclude\": [\r\n        // On conda install pytables, otherwise tables\r\n        {\"environment_type\": \"conda\", \"tables\": \"\"},\r\n        {\"environment_type\": \"conda\", \"pytables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"tables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"pytables\": \"\"},\r\n    ],\r\n    \"include\": [],\r\n\r\n    // The directory (relative to the current directory) that benchmarks are\r\n    // stored in.  If not provided, defaults to \"benchmarks\"\r\n    // \"benchmark_dir\": \"benchmarks\",\r\n\r\n    // The directory (relative to the current directory) to cache the Python\r\n    // environments in.  If not provided, defaults to \"env\"\r\n    // \"env_dir\": \"env\",\r\n\r\n    // The directory (relative to the current directory) that raw benchmark\r\n    // results are stored in.  If not provided, defaults to \"results\".\r\n    // \"results_dir\": \"results\",\r\n\r\n    // The directory (relative to the current directory) that the html tree\r\n    // should be written to.  If not provided, defaults to \"html\".\r\n    // \"html_dir\": \"html\",\r\n\r\n    // The number of characters to retain in the commit hashes.\r\n    // \"hash_length\": 8,\r\n\r\n    // `asv` will cache wheels of the recent builds in each\r\n    // environment, making them faster to install next time.  This is\r\n    // number of builds to keep, per environment.\r\n    \"build_cache_size\": 8,\r\n\r\n    // The commits after which the regression search in `asv publish`\r\n    // should start looking for regressions. Dictionary whose keys are\r\n    // regexps matching to benchmark names, and values corresponding to\r\n    // the commit (exclusive) after which to start looking for\r\n    // regressions.  The default is to start from the first commit\r\n    // with results. If the commit is `null`, regression detection is\r\n    // skipped for the matching benchmark.\r\n    //\r\n    \"regressions_first_commits\": {\r\n        \".*\": \"0409521665\"\r\n    },\r\n    \"regression_thresholds\": {\r\n    },\r\n    \"build_command\":\r\n    [\"python -m build -Cbuilddir=builddir --wheel --outdir {build_cache_dir} {build_dir}\"]\r\n}\r\n"]
[25.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[25.002, "i", "ls -la asv_bench/benchmarks/\r"]
[25.004, "o", "ls -la asv_bench/benchmarks/\r\n"]
[25.006, "o", "\u001b[?2004l\r\ntotal 376\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root    25 Sep 12 22:25 __init__.py\r\n-rw-r--r-- 1 root root  6160 Sep 12 22:25 algorithms.py\r\ndrwxr-xr-x 2 root root  4096 Sep 12 22:25 \u001b[01;34malgos\u001b[0m\r\n-rw-r--r-- 1 root root 12498 Sep 12 22:25 arithmetic.py\r\n-rw-r--r-- 1 root root  4282 Sep 12 22:25 array.py\r\n-rw-r--r-- 1 root root  1414 Sep 12 22:25 attrs_caching.py\r\n-rw-r--r-- 1 root root   739 Sep 12 22:25 boolean.py\r\n-rw-r--r-- 1 root root  9776 Sep 12 22:25 categoricals.py\r\n-rw-r--r-- 1 root root  3462 Sep 12 22:25 ctors.py\r\n-rw-r--r-- 1 root root  3559 Sep 12 22:25 dtypes.py\r\n-rw-r--r-- 1 root root  1988 Sep 12 22:25 eval.py\r\n-rw-r--r-- 1 root root   379 Sep 12 22:25 finalize.py\r\n-rw-r--r-- 1 root root  5142 Sep 12 22:25 frame_ctor.py\r\n-rw-r--r-- 1 root root 24291 Sep 12 22:25 frame_methods.py\r\n-rw-r--r-- 1 root root  8150 Sep 12 22:25 gil.py\r\n-rw-r--r-- 1 root root 33302 Sep 12 22:25 groupby.py\r\n-rw-r--r-- 1 root root  2393 Sep 12 22:25 hash_functions.py\r\n-rw-r--r-- 1 root root  2274 Sep 12 22:25 index_cached_properties.py\r\n-rw-r--r-- 1 root root  7138 Sep 12 22:25 index_object.py\r\n-rw-r--r-- 1 root root 16983 Sep 12 22:25 indexing.py\r\n-rw-r--r-- 1 root root  5952 Sep 12 22:25 indexing_engines.py\r\n-rw-r--r-- 1 root root  8662 Sep 12 22:25 inference.py\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mio\u001b[0m\r\n-rw-r--r-- 1 root root 18607 Sep 12 22:25 join_merge.py\r\n-rw-r--r-- 1 root root  2445 Sep 12 22:25 libs.py\r\n-rw-r--r-- 1 root root 12356 Sep 12 22:25 multiindex_object.py\r\n-rw-r--r-- 1 root root   624 Sep 12 22:25 package.py\r\n-rw-r--r-- 1 root root  1740 Sep 12 22:25 pandas_vb_common.py\r\n-rw-r--r-- 1 root root  2909 Sep 12 22:25 period.py\r\n-rw-r--r-- 1 root root  4554 Sep 12 22:25 plotting.py\r\n-rw-r--r-- 1 root root  4948 Sep 12 22:25 reindex.py\r\n-rw-r--r-- 1 root root  2103 Sep 12 22:25 replace.py\r\n-rw-r--r-- 1 root root  9973 Sep 12 22:25 reshape.py\r\n-rw-r--r-- 1 root root 11474 Sep 12 22:25 rolling.py\r\n-rw-r--r-- 1 root root 10571 Sep 12 22:25 series_methods.py\r\n-rw-r--r-- 1 root root  6817 Sep 12 22:25 sparse.py\r\n-rw-r--r-- 1 root root  4685 Sep 12 22:25 stat_ops.py\r\n-rw-r--r-- 1 root root  3535 Sep 12 22:25 strftime.py\r\n-rw-r--r-- 1 root root  7996 Sep 12 22:25 strings.py\r\n-rw-r--r-- 1 root root  1528 Sep 12 22:25 timedelta.py\r\n-rw-r--r-- 1 root root  8565 Sep 12 22:25 timeseries.py\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:25 \u001b[01;34mtslibs\u001b[0m\r\n"]
[30.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[30.002, "i", "find . -name \"asv_benchmarks.txt\" 2>/dev/null\r"]
[30.004, "o", "find . -name \"asv_benchmarks.txt\" 2>/dev/null\r\n"]
[30.006, "o", "\u001b[?2004l\r\n"]
[35.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[35.002, "i", "grep -r \"TODO(cython3)\" pandas/ --include=\"*.py\" --include=\"*.pyx\" --include=\"*.pxd\" | head -20\r"]
[35.004, "o", "grep -r \"TODO(cython3)\" pandas/ --include=\"*.py\" --include=\"*.pyx\" --include=\"*.pxd\" | head -20\r\n"]
[35.006, "o", "\u001b[?2004l\r\npandas/_libs/algos.pyx:    # TODO(cython3): de-duplicate once cython supports conditional nogil\r\npandas/_libs/tslibs/timedeltas.pyx:    def days(self) -> int:  # TODO(cython3): make cdef property\r\npandas/_libs/tslibs/timedeltas.pyx:    def seconds(self) -> int:  # TODO(cython3): make cdef property\r\npandas/_libs/tslibs/timedeltas.pyx:    def microseconds(self) -> int:  # TODO(cython3): make cdef property\r\npandas/_libs/tslibs/np_datetime.pxd:# TODO(cython3): most of these can be cimported directly from numpy\r\npandas/tests/tseries/offsets/test_year.py:    # TODO(cython3): \"arg: datetime\" annotation will impose\r\n"]
[40.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[40.002, "i", "grep -r \"ndarray\\[intp_t\\]\" pandas/ --include=\"*.pyx\" --include=\"*.pxd\"\r"]
[40.004, "o", "grep -r \"ndarray\\[intp_t\\]\" pandas/ --include=\"*.pyx\" --include=\"*.pxd\"\r\n"]
[40.006, "o", "\u001b[?2004l\r\n\u001b[35m\u001b[Kpandas/_libs/join.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K rev\r\n\u001b[35m\u001b[Kpandas/_libs/join.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K result\r\n\u001b[35m\u001b[Kpandas/_libs/join.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K indexer\r\n\u001b[35m\u001b[Kpandas/_libs/join.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K lindexer, rindexer\r\n\u001b[35m\u001b[Kpandas/_libs/join.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K lindexer, rindexer\r\n\u001b[35m\u001b[Kpandas/_libs/join.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K lindexer, rindexer\r\n\u001b[35m\u001b[Kpandas/_libs/join.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K left_indexer, right_indexer\r\n\u001b[35m\u001b[Kpandas/_libs/join.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K left_indexer, right_indexer\r\n\u001b[35m\u001b[Kpandas/_libs/join.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K bli, bri, fli, fri\r\n\u001b[35m\u001b[Kpandas/_libs/join.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K left_indexer, right_indexer\r\n\u001b[35m\u001b[Kpandas/_libs/groupby.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K labels,\r\n\u001b[35m\u001b[Kpandas/_libs/groupby.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K _counts\r\n\u001b[35m\u001b[Kpandas/_libs/groupby.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K indexer\r\n\u001b[35m\u001b[Kpandas/_libs/hashtable.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K labels\r\n\u001b[35m\u001b[Kpandas/_libs/internals.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K blknos, cur_blknos, run_blknos\r\n\u001b[35m\u001b[Kpandas/_libs/index.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K result, missing\r\n\u001b[35m\u001b[Kpandas/_libs/index.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K result, missing\r\n\u001b[35m\u001b[Kpandas/_libs/tslibs/tzconversion.pyx\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K switch_idxs, trans_idx, grp, a_idx, b_idx, one_diff\r\n"]
[45.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[45.002, "i", "cd asv_bench\r"]
[45.004, "o", "cd asv_bench\r\n"]
[45.006, "o", "\u001b[?2004l\r\n"]
[50.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[50.002, "i", "asv run --python=same --bench=\"multiindex_object.GetLocs.*\"\r"]
[50.004, "o", "asv run --python=same --bench=\"multiindex_object.GetLocs.*\"\r\n"]
[50.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (multiindex_object.GetLocs.time_large_get_locs--)\u001b[0m...\r\n[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mmultiindex_object.GetLocs.time_large_get_locs\u001b[0m                                                                                          1.05\u00b10.04ms\r\n[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mmultiindex_object.GetLocs.time_med_get_locs\u001b[0m                                                                                               88.8\u00b11\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mmultiindex_object.GetLocs.time_small_get_locs\u001b[0m                                                                                           80.2\u00b10.6\u03bcs\r\n"]
[55.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[55.002, "i", "asv run --python=same --bench=\"frame_methods.Apply.*\"\r"]
[55.004, "o", "asv run --python=same --bench=\"frame_methods.Apply.*\"\r\n"]
[55.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 6 total benchmarks (1 commits * 1 environments * 6 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 8.33%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (frame_methods.Apply.time_apply_axis_1--)\u001b[0m......\r\n[58.33%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_axis_1\u001b[0m                                                                                                   93.4\u00b10.1ms\r\n[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_lambda_mean\u001b[0m                                                                                              4.21\u00b10.1ms\r\n[75.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_pass_thru\u001b[0m                                                                                               5.26\u00b10.08ms\r\n[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_ref_by_name\u001b[0m                                                                                             6.62\u00b10.06ms\r\n[91.67%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_str_mean\u001b[0m                                                                                                    284\u00b12\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_user_func\u001b[0m                                                                                                   132\u00b11ms\r\n"]
[60.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[60.002, "i", "asv run --python=same --bench=\"reshape.ReshapeExtensionDtype.*\"\r"]
[60.004, "o", "asv run --python=same --bench=\"reshape.ReshapeExtensionDtype.*\"\r\n"]
[60.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 4 total benchmarks (1 commits * 1 environments * 4 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[12.50%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (reshape.ReshapeExtensionDtype.time_stack--)\u001b[0m....\r\n[62.50%] \u00b7\u00b7\u00b7 \u001b[0;39mreshape.ReshapeExtensionDtype.time_stack\u001b[0m                                                                                                        ok\r\n[62.50%] \u00b7\u00b7\u00b7 \u001b[0;39m============================ ============\u001b[0m\r\n                        dtype                         \r\n             ---------------------------- ------------\r\n              datetime64[ns, US/Pacific]   44.0\u00b10.4ms \r\n                      Period[s]            45.5\u00b10.7ms \r\n             ============================ ============\r\n\r\n[75.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreshape.ReshapeExtensionDtype.time_transpose\u001b[0m                                                                                                    ok\r\n[75.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============================ ============\u001b[0m\r\n                        dtype                         \r\n             ---------------------------- ------------\r\n              datetime64[ns, US/Pacific]    121\u00b130\u03bcs  \r\n                      Period[s]            99.8\u00b10.9\u03bcs \r\n             ============================ ============\r\n\r\n[87.50%] \u00b7\u00b7\u00b7 \u001b[0;39mreshape.ReshapeExtensionDtype.time_unstack_fast\u001b[0m                                                                                                 ok\r\n[87.50%] \u00b7\u00b7\u00b7 \u001b[0;39m============================ ==========\u001b[0m\r\n                        dtype                       \r\n             ---------------------------- ----------\r\n              datetime64[ns, US/Pacific]   872\u00b120\u03bcs \r\n                      Period[s]            816\u00b110\u03bcs \r\n             ============================ ==========\r\n\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreshape.ReshapeExtensionDtype.time_unstack_slow\u001b[0m                                                                                                 ok\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============================ ============\u001b[0m\r\n                         dtype                         \r\n              ---------------------------- ------------\r\n               datetime64[ns, US/Pacific]   1.63\u00b10.1ms \r\n                       Period[s]            1.56\u00b10.1ms \r\n              ============================ ============\r\n\r\n"]
[65.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[65.002, "i", "asv run --python=same --bench=\"stat_ops.Correlation.*\"\r"]
[65.004, "o", "asv run --python=same --bench=\"stat_ops.Correlation.*\"\r\n"]
[65.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (stat_ops.Correlation.time_corr--)\u001b[0m......\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.peakmem_corr_wide\u001b[0m                                                                                                          ok\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39m========== ======\u001b[0m\r\n               method         \r\n             ---------- ------\r\n              spearman   219M \r\n              kendall    254M \r\n              pearson    218M \r\n             ========== ======\r\n\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corr\u001b[0m                                                                                                                  ok\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39m========== ============\u001b[0m\r\n               method               \r\n             ---------- ------------\r\n              spearman    840\u00b15\u03bcs   \r\n              kendall    27.0\u00b10.2ms \r\n              pearson     259\u00b14\u03bcs   \r\n             ========== ============\r\n\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corr_series\u001b[0m                                                                                                           ok\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39m========== ===========\u001b[0m\r\n               method              \r\n             ---------- -----------\r\n              spearman    640\u00b140\u03bcs \r\n              kendall     525\u00b130\u03bcs \r\n              pearson    161\u00b10.9\u03bcs \r\n             ========== ===========\r\n\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corr_wide\u001b[0m                                                                                                             ok\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39m========== =============\u001b[0m\r\n               method                \r\n             ---------- -------------\r\n              spearman   7.98\u00b10.09ms \r\n              kendall     1.27\u00b10.01s \r\n              pearson    9.05\u00b10.06ms \r\n             ========== =============\r\n\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corr_wide_nans\u001b[0m                                                                                                        ok\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39m========== =============\u001b[0m\r\n               method                \r\n             ---------- -------------\r\n              spearman     409\u00b17ms   \r\n              kendall     1.25\u00b10.01s \r\n              pearson    9.59\u00b10.09ms \r\n             ========== =============\r\n\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corrwith_cols\u001b[0m                                                                                                         ok\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39m========== =============\u001b[0m\r\n               method                \r\n             ---------- -------------\r\n              spearman    6.80\u00b10.1ms \r\n              kendall    4.58\u00b10.07ms \r\n              pearson     2.36\u00b10.1ms \r\n             ========== =============\r\n\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corrwith_rows\u001b[0m                                                                                                         ok\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========== =============\u001b[0m\r\n                method                \r\n              ---------- -------------\r\n               spearman     182\u00b14ms   \r\n               kendall     150\u00b10.9ms  \r\n               pearson    3.03\u00b10.04ms \r\n              ========== =============\r\n\r\n"]
[70.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[70.002, "i", "asv run --python=same --bench=\"io.hdf.*\"\r"]
[70.004, "o", "asv run --python=same --bench=\"io.hdf.*\"\r\n"]
[70.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 19 total benchmarks (1 commits * 1 environments * 19 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 5.26%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (io.hdf.HDF.time_read_hdf--)\u001b[0m...............\r\n[44.74%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (io.hdf.HDFStoreDataFrame.time_write_store_table_dc--)\u001b[0m...\r\n[52.63%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDF.peakmem_read_hdf\u001b[0m                                                                                                                     ok\r\n[52.63%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ======\u001b[0m\r\n              format        \r\n             -------- ------\r\n              table    280M \r\n              fixed    276M \r\n             ======== ======\r\n\r\n[55.26%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDF.time_read_hdf\u001b[0m                                                                                                                        ok\r\n[55.26%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ============\u001b[0m\r\n              format              \r\n             -------- ------------\r\n              table    47.6\u00b10.7ms \r\n              fixed    14.7\u00b10.6ms \r\n             ======== ============\r\n\r\n[57.89%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDF.time_write_hdf\u001b[0m                                                                                                                       ok\r\n[57.89%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ==========\u001b[0m\r\n              format            \r\n             -------- ----------\r\n              table    62.4\u00b11ms \r\n              fixed    22.2\u00b11ms \r\n             ======== ==========\r\n\r\n[60.53%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_query_store_table\u001b[0m                                                                                         7.95\u00b10.1ms\r\n[63.16%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_query_store_table_wide\u001b[0m                                                                                    10.5\u00b10.8ms\r\n[65.79%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_read_store\u001b[0m                                                                                                13.1\u00b10.1ms\r\n[68.42%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_read_store_mixed\u001b[0m                                                                                          33.9\u00b10.6ms\r\n[71.05%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_read_store_table\u001b[0m                                                                                         2.67\u00b10.04ms\r\n[73.68%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_read_store_table_mixed\u001b[0m                                                                                    27.3\u00b10.2ms\r\n[76.32%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_read_store_table_wide\u001b[0m                                                                                     8.55\u00b10.2ms\r\n[78.95%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_store_info\u001b[0m                                                                                                22.7\u00b10.3ms\r\n[81.58%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_store_repr\u001b[0m                                                                                               1.75\u00b10.02\u03bcs\r\n[84.21%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_store_str\u001b[0m                                                                                                1.74\u00b10.03\u03bcs\r\n[86.84%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store\u001b[0m                                                                                               12.0\u00b10.4ms\r\n[89.47%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store_mixed\u001b[0m                                                                                         17.7\u00b10.4ms\r\n[92.11%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store_table\u001b[0m                                                                                         22.9\u00b10.5ms\r\n[94.74%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store_table_dc\u001b[0m                                                                                         131\u00b12ms\r\n[97.37%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store_table_mixed\u001b[0m                                                                                   32.3\u00b10.5ms\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store_table_wide\u001b[0m                                                                                    34.0\u00b10.9ms\r\n"]
[75.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[75.002, "i", "asv run --python=same --bench=\"reindex.ReindexMethod.*\"\r"]
[75.004, "o", "asv run --python=same --bench=\"reindex.ReindexMethod.*\"\r\n"]
[75.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (reindex.ReindexMethod.time_reindex_method--)\u001b[0m.\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.ReindexMethod.time_reindex_method\u001b[0m                                                                                                       ok\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========== ======================= =========================\u001b[0m\r\n              --                            constructor                   \r\n              ---------- -------------------------------------------------\r\n                method    <function date_range>   <function period_range> \r\n              ========== ======================= =========================\r\n                 pad             697\u00b130\u03bcs                 664\u00b130\u03bcs        \r\n               backfill          668\u00b130\u03bcs                 641\u00b110\u03bcs        \r\n              ========== ======================= =========================\r\n\r\n"]
[80.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[80.002, "i", "cd ..\r"]
[80.004, "o", "cd ..\r\n"]
[80.006, "o", "\u001b[?2004l\r\n"]
[85.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[85.002, "i", "head -50 pandas/_libs/join.pyx\r"]
[85.004, "o", "head -50 pandas/_libs/join.pyx\r\n"]
[85.006, "o", "\u001b[?2004l\r\ncimport cython\r\nfrom cython cimport Py_ssize_t\r\nimport numpy as np\r\n\r\ncimport numpy as cnp\r\nfrom numpy cimport (\r\n    int64_t,\r\n    intp_t,\r\n    ndarray,\r\n)\r\n\r\ncnp.import_array()\r\n\r\nfrom pandas._libs.algos import groupsort_indexer\r\n\r\nfrom pandas._libs.dtypes cimport (\r\n    numeric_object_t,\r\n    numeric_t,\r\n)\r\n\r\n\r\n@cython.wraparound(False)\r\n@cython.boundscheck(False)\r\ndef inner_join(const intp_t[:] left, const intp_t[:] right,\r\n               Py_ssize_t max_groups, bint sort=True):\r\n    cdef:\r\n        Py_ssize_t i, j, k, count = 0\r\n        intp_t[::1] left_sorter, right_sorter\r\n        intp_t[::1] left_count, right_count\r\n        intp_t[::1] left_indexer, right_indexer\r\n        intp_t lc, rc\r\n        Py_ssize_t left_pos = 0, right_pos = 0, position = 0\r\n        Py_ssize_t offset\r\n\r\n    left_sorter, left_count = groupsort_indexer(left, max_groups)\r\n    right_sorter, right_count = groupsort_indexer(right, max_groups)\r\n\r\n    with nogil:\r\n        # First pass, determine size of result set, do not use the NA group\r\n        for i in range(1, max_groups + 1):\r\n            lc = left_count[i]\r\n            rc = right_count[i]\r\n\r\n            if rc > 0 and lc > 0:\r\n                count += lc * rc\r\n\r\n    left_indexer = np.empty(count, dtype=np.intp)\r\n    right_indexer = np.empty(count, dtype=np.intp)\r\n\r\n    with nogil:\r\n"]
[90.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[90.002, "i", "grep -n \"ndarray\\[intp_t\\]\" pandas/_libs/join.pyx\r"]
[90.004, "o", "grep -n \"ndarray\\[intp_t\\]\" pandas/_libs/join.pyx\r\n"]
[90.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K94\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K rev\r\n\u001b[32m\u001b[K253\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K result\r\n\u001b[32m\u001b[K289\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K indexer\r\n\u001b[32m\u001b[K341\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K lindexer, rindexer\r\n\u001b[32m\u001b[K451\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K lindexer, rindexer\r\n\u001b[32m\u001b[K549\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K lindexer, rindexer\r\n\u001b[32m\u001b[K694\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K left_indexer, right_indexer\r\n\u001b[32m\u001b[K765\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K left_indexer, right_indexer\r\n\u001b[32m\u001b[K836\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K bli, bri, fli, fri\r\n\u001b[32m\u001b[K838\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        \u001b[01;31m\u001b[Kndarray[intp_t]\u001b[m\u001b[K left_indexer, right_indexer\r\n"]
[95.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[95.002, "i", "sed -n '90,100p' pandas/_libs/join.pyx\r"]
[95.004, "o", "sed -n '90,100p' pandas/_libs/join.pyx\r\n"]
[95.006, "o", "\u001b[?2004l\r\ndef left_outer_join(const intp_t[:] left, const intp_t[:] right,\r\n                    Py_ssize_t max_groups, bint sort=True):\r\n    cdef:\r\n        Py_ssize_t i, j, k, count = 0\r\n        ndarray[intp_t] rev\r\n        intp_t[::1] left_count, right_count\r\n        intp_t[::1] left_sorter, right_sorter\r\n        intp_t[::1] left_indexer, right_indexer\r\n        intp_t lc, rc\r\n        Py_ssize_t left_pos = 0, right_pos = 0, position = 0\r\n        Py_ssize_t offset\r\n"]
[100.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[100.002, "i", "sed -n '250,260p' pandas/_libs/join.pyx\r"]
[100.004, "o", "sed -n '250,260p' pandas/_libs/join.pyx\r\n"]
[100.006, "o", "\u001b[?2004l\r\ndef ffill_indexer(const intp_t[:] indexer) -> np.ndarray:\r\n    cdef:\r\n        Py_ssize_t i, n = len(indexer)\r\n        ndarray[intp_t] result\r\n        intp_t val, last_obs\r\n\r\n    result = np.empty(n, dtype=np.intp)\r\n    last_obs = -1\r\n\r\n    for i in range(n):\r\n        val = indexer[i]\r\n"]
[105.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[105.002, "i", "sed -i '94s/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/join.pyx\r"]
[105.004, "o", "sed -i '94s/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/join.pyx\r\n"]
[105.006, "o", "\u001b[?2004l\r\n"]
[110.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[110.002, "i", "sed -n '90,100p' pandas/_libs/join.pyx\r"]
[110.004, "o", "sed -n '90,100p' pandas/_libs/join.pyx\r\n"]
[110.006, "o", "\u001b[?2004l\r\ndef left_outer_join(const intp_t[:] left, const intp_t[:] right,\r\n                    Py_ssize_t max_groups, bint sort=True):\r\n    cdef:\r\n        Py_ssize_t i, j, k, count = 0\r\n        Py_ssize_t[] rev\r\n        intp_t[::1] left_count, right_count\r\n        intp_t[::1] left_sorter, right_sorter\r\n        intp_t[::1] left_indexer, right_indexer\r\n        intp_t lc, rc\r\n        Py_ssize_t left_pos = 0, right_pos = 0, position = 0\r\n        Py_ssize_t offset\r\n"]
[115.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[115.002, "i", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/join.pyx\r"]
[115.004, "o", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/join.pyx\r\n"]
[115.006, "o", "\u001b[?2004l\r\n"]
[120.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[120.002, "i", "grep -n \"ndarray\\[intp_t\\]\" pandas/_libs/join.pyx\r"]
[120.004, "o", "grep -n \"ndarray\\[intp_t\\]\" pandas/_libs/join.pyx\r\n"]
[120.006, "o", "\u001b[?2004l\r\n"]
[125.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[125.002, "i", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/groupby.pyx\r"]
[125.004, "o", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/groupby.pyx\r\n"]
[125.006, "o", "\u001b[?2004l\r\n"]
[130.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[130.002, "i", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/hashtable.pyx\r"]
[130.004, "o", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/hashtable.pyx\r\n"]
[130.006, "o", "\u001b[?2004l\r\n"]
[135.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[135.002, "i", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/internals.pyx\r"]
[135.004, "o", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/internals.pyx\r\n"]
[135.006, "o", "\u001b[?2004l\r\n"]
[140.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[140.002, "i", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/index.pyx\r"]
[140.004, "o", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/index.pyx\r\n"]
[140.006, "o", "\u001b[?2004l\r\n"]
[145.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[145.002, "i", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/tslibs/tzconversion.pyx\r"]
[145.004, "o", "sed -i 's/ndarray\\[intp_t\\]/Py_ssize_t[]/g' pandas/_libs/tslibs/tzconversion.pyx\r\n"]
[145.006, "o", "\u001b[?2004l\r\n"]
[150.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[150.002, "i", "grep -r \"ndarray\\[intp_t\\]\" pandas/ --include=\"*.pyx\" --include=\"*.pxd\"\r"]
[150.004, "o", "grep -r \"ndarray\\[intp_t\\]\" pandas/ --include=\"*.pyx\" --include=\"*.pxd\"\r\n"]
[150.006, "o", "\u001b[?2004l\r\n"]
[155.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[155.002, "i", "python -m pip install -e . --no-build-isolation -v\r"]
[155.004, "o", "python -m pip install -e . --no-build-isolation -v\r\n"]
[155.006, "o", "\u001b[?2004l\r\nUsing pip 25.2 from /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/pip (python 3.10)\r\nObtaining file:///workspace/repo\r\n  Running command Checking if build backend supports build_editable\r\n  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\r\n  Running command Preparing editable metadata (pyproject.toml)\r\n  + meson setup --reconfigure /workspace/repo /workspace/repo/build/cp310 -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --vsenv --native-file=/workspace/repo/build/cp310/meson-python-native-file.ini\r\n  The Meson build system\r\n  Version: 1.2.1\r\n  Source dir: /workspace/repo\r\n  Build dir: /workspace/repo/build/cp310\r\n  Build type: native build\r\n  Project name: pandas\r\n  Project version: 0+untagged.34756.g86e807d.dirty\r\n  C compiler for the host machine: /opt/conda/envs/asv_3.10/bin/x86_64-conda-linux-gnu-cc (gcc 14.3.0 \"x86_64-conda-linux-gnu-cc (conda-forge gcc 14.3.0-5) 14.3.0\")\r\n  C linker for the host machine: /opt/conda/envs/asv_3.10/bin/x86_64-conda-linux-gnu-cc ld.bfd 2.44\r\n  C++ compiler for the host machine: /opt/conda/envs/asv_3.10/bin/x86_64-conda-linux-gnu-c++ (gcc 14.3.0 \"x86_64-conda-linux-gnu-c++ (conda-forge gcc 14.3.0-5) 14.3.0\")\r\n  C++ linker for the host machine: /opt/conda/envs/asv_3.10/bin/x86_64-conda-linux-gnu-c++ ld.bfd 2.44\r\n  Cython compiler for the host machine: cython (cython 3.0.12)\r\n  Host machine cpu family: x86_64\r\n  Host machine cpu: x86_64\r\n  Program python found: YES (/opt/conda/envs/asv_3.10/bin/python)\r\n  Build targets in project: 54\r\n\r\n  pandas 0+untagged.34756.g86e807d.dirty\r\n\r\n    User defined options\r\n      Native files: /workspace/repo/build/cp310/meson-python-native-file.ini\r\n      buildtype   : release\r\n      vsenv       : True\r\n      b_ndebug    : if-release\r\n      b_vscrt     : md\r\n\r\n  Found ninja-1.13.1 at /opt/conda/envs/asv_3.10/bin/ninja\r\n\r\n  Visual Studio environment is needed to run Ninja. It is recommended to use Meson wrapper:\r\n  /opt/conda/envs/asv_3.10/bin/meson compile -C .\r\n\r\n  Generating targets:   0%|          | 0/54 eta ?\r\n\r\n\r\n  Writing build.ninja:   0%|          | 0/222 eta ?\r\n\r\n  Cleaning... 0 files.\r\n  + /opt/conda/envs/asv_3.10/bin/ninja\r\n  [1/19] Compiling Cython source /workspace/repo/pandas/_libs/tslibs/tzconversion.pyx\r\n  FAILED: [code=1] pandas/_libs/tslibs/tzconversion.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslibs/tzconversion.pyx.c\r\n  cython -M --fast-fail -3 --include-dir /workspace/repo/build/cp310/pandas/_libs/tslibs '-X always_allow_keywords=true' /workspace/repo/pandas/_libs/tslibs/tzconversion.pyx -o pandas/_libs/tslibs/tzconversion.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/tslibs/tzconversion.pyx.c\r\n\r\n  Error compiling Cython file:\r\n  ------------------------------------------------------------\r\n  ...\r\n  ):\r\n      cdef:\r\n          Py_ssize_t i, n = vals.shape[0]\r\n          ndarray[uint8_t, cast=True] mismatch\r\n          ndarray[int64_t] delta, dst_hours\r\n          Py_ssize_t[] switch_idxs, trans_idx, grp, a_idx, b_idx, one_diff\r\n                       ^\r\n  ------------------------------------------------------------\r\n\r\n  /workspace/repo/pandas/_libs/tslibs/tzconversion.pyx:609:21: Variable type 'Py_ssize_t []' is incomplete\r\n  [2/19] Compiling Cython source /workspace/repo/pandas/_libs/groupby.pyx\r\n  FAILED: [code=1] pandas/_libs/groupby.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/groupby.pyx.c\r\n  cython -M --fast-fail -3 --include-dir /workspace/repo/build/cp310/pandas/_libs '-X always_allow_keywords=true' /workspace/repo/pandas/_libs/groupby.pyx -o pandas/_libs/groupby.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/groupby.pyx.c\r\n\r\n  Error compiling Cython file:\r\n  ------------------------------------------------------------\r\n  ...\r\n      \"\"\"\r\n      Only aggregates on axis=0\r\n      \"\"\"\r\n      cdef:\r\n          Py_ssize_t i, j, N, K, ngroups, size\r\n          Py_ssize_t[] _counts\r\n                       ^\r\n  ------------------------------------------------------------\r\n\r\n  /workspace/repo/pandas/_libs/groupby.pyx:195:21: Variable type 'Py_ssize_t []' is incomplete\r\n  [3/19] Compiling Cython source /workspace/repo/pandas/_libs/hashtable.pyx\r\n  FAILED: [code=1] pandas/_libs/hashtable.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/hashtable.pyx.c\r\n  cython -M --fast-fail -3 --include-dir /workspace/repo/build/cp310/pandas/_libs '-X always_allow_keywords=true' /workspace/repo/pandas/_libs/hashtable.pyx -o pandas/_libs/hashtable.cpython-310-x86_64-linux-gnu.so.p/pandas/_libs/hashtable.pyx.c\r\n\r\n  Error compiling Cython file:\r\n  ------------------------------------------------------------\r\n  ...\r\n          >>> fac = ObjectFactorizer(3)\r\n          >>> fac.factorize(np.array([1,2,np.nan], dtype='O'), na_sentinel=20)\r\n          array([ 0,  1, 20])\r\n          \"\"\"\r\n          cdef:\r\n              Py_ssize_t[] labels\r\n                           ^\r\n  ------------------------------------------------------------\r\n\r\n  /workspace/repo/pandas/_libs/hashtable.pyx:113:25: Variable type 'Py_ssize_t []' is incomplete\r\n  ninja: build stopped: subcommand failed.\r\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n  \r\n  \u001b[31m\u00d7\u001b[0m \u001b[32mPreparing editable metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\r\n  \u001b[31m\u2502\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n  \u001b[31m\u2570\u2500>\u001b[0m See above for output.\r\n  \r\n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n  \u001b[1;35mfull command\u001b[0m: \u001b[34m/opt/conda/envs/asv_3.10/bin/python /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py prepare_metadata_for_build_editable /tmp/tmpoegy7wvd\u001b[0m\r\n  \u001b[1;35mcwd\u001b[0m: /workspace/repo\r\n  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25herror\r\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\r\n\r\n\u001b[31m\u00d7\u001b[0m Encountered error while generating package metadata.\r\n\u001b[31m\u2570\u2500>\u001b[0m See above for output.\r\n\r\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\r\n\u001b[1;36mhint\u001b[0m: See above for details.\r\n"]
[160.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[160.002, "i", "git checkout -- pandas/_libs/\r"]
[160.004, "o", "git checkout -- pandas/_libs/\r\n"]
[160.006, "o", "\u001b[?2004l\r\n"]
[165.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[165.002, "i", "grep -A 5 -B 5 \"ndarray\\[intp_t\\]\" pandas/_libs/join.pyx | head -20\r"]
[165.004, "o", "grep -A 5 -B 5 \"ndarray\\[intp_t\\]\" pandas/_libs/join.pyx | head -20\r\n"]
[165.006, "o", "\u001b[?2004l\r\n@cython.boundscheck(False)\r\ndef left_outer_join(const intp_t[:] left, const intp_t[:] right,\r\n                    Py_ssize_t max_groups, bint sort=True):\r\n    cdef:\r\n        Py_ssize_t i, j, k, count = 0\r\n        ndarray[intp_t] rev\r\n        intp_t[::1] left_count, right_count\r\n        intp_t[::1] left_sorter, right_sorter\r\n        intp_t[::1] left_indexer, right_indexer\r\n        intp_t lc, rc\r\n        Py_ssize_t left_pos = 0, right_pos = 0, position = 0\r\n--\r\n@cython.wraparound(False)\r\n@cython.boundscheck(False)\r\ndef ffill_indexer(const intp_t[:] indexer) -> np.ndarray:\r\n    cdef:\r\n        Py_ssize_t i, n = len(indexer)\r\n        ndarray[intp_t] result\r\n        intp_t val, last_obs\r\n\r\n"]
[170.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[170.002, "i", "sed -i '94s/ndarray\\[intp_t\\]/Py_ssize_t[:]/g' pandas/_libs/join.pyx\r"]
[170.004, "o", "sed -i '94s/ndarray\\[intp_t\\]/Py_ssize_t[:]/g' pandas/_libs/join.pyx\r\n"]
[170.006, "o", "\u001b[?2004l\r\n"]
[175.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[175.002, "i", "sed -n '90,100p' pandas/_libs/join.pyx\r"]
[175.004, "o", "sed -n '90,100p' pandas/_libs/join.pyx\r\n"]
[175.006, "o", "\u001b[?2004l\r\ndef left_outer_join(const intp_t[:] left, const intp_t[:] right,\r\n                    Py_ssize_t max_groups, bint sort=True):\r\n    cdef:\r\n        Py_ssize_t i, j, k, count = 0\r\n        Py_ssize_t[:] rev\r\n        intp_t[::1] left_count, right_count\r\n        intp_t[::1] left_sorter, right_sorter\r\n        intp_t[::1] left_indexer, right_indexer\r\n        intp_t lc, rc\r\n        Py_ssize_t left_pos = 0, right_pos = 0, position = 0\r\n        Py_ssize_t offset\r\n"]
[180.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[180.002, "i", "sed -n '90,130p' pandas/_libs/join.pyx | grep -A 10 -B 10 \"rev\"\r"]
[180.004, "o", "sed -n '90,130p' pandas/_libs/join.pyx | grep -A 10 -B 10 \"rev\"\r\n"]
[180.006, "o", "\u001b[?2004l\r\ndef left_outer_join(const intp_t[:] left, const intp_t[:] right,\r\n                    Py_ssize_t max_groups, bint sort=True):\r\n    cdef:\r\n        Py_ssize_t i, j, k, count = 0\r\n        Py_ssize_t[:] \u001b[01;31m\u001b[Krev\u001b[m\u001b[K\r\n        intp_t[::1] left_count, right_count\r\n        intp_t[::1] left_sorter, right_sorter\r\n        intp_t[::1] left_indexer, right_indexer\r\n        intp_t lc, rc\r\n        Py_ssize_t left_pos = 0, right_pos = 0, position = 0\r\n        Py_ssize_t offset\r\n\r\n    left_sorter, left_count = groupsort_indexer(left, max_groups)\r\n    right_sorter, right_count = groupsort_indexer(right, max_groups)\r\n\r\n"]
[185.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[185.002, "i", "grep -n \"rev\" pandas/_libs/join.pyx\r"]
[185.004, "o", "grep -n \"rev\" pandas/_libs/join.pyx\r\n"]
[185.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K73\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # if not asked to sort, \u001b[01;31m\u001b[Krev\u001b[m\u001b[Kert to original order\r\n\u001b[32m\u001b[K78\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Krev\u001b[m\u001b[K = np.empty(len(left), dtype=np.intp)\r\n\u001b[32m\u001b[K79\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Krev\u001b[m\u001b[K.put(np.asarray(left_sorter), np.arange(len(left)))\r\n\u001b[32m\u001b[K81\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Krev\u001b[m\u001b[K, _ = groupsort_indexer(left_indexer, len(left))\r\n\u001b[32m\u001b[K83\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        return np.asarray(left_indexer).take(\u001b[01;31m\u001b[Krev\u001b[m\u001b[K), np.asarray(right_indexer).take(\u001b[01;31m\u001b[Krev\u001b[m\u001b[K)\r\n\u001b[32m\u001b[K94\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        Py_ssize_t[:] \u001b[01;31m\u001b[Krev\u001b[m\u001b[K\r\n\u001b[32m\u001b[K146\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    if not sort:  # if not asked to sort, \u001b[01;31m\u001b[Krev\u001b[m\u001b[Kert to original order\r\n\u001b[32m\u001b[K151\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Krev\u001b[m\u001b[K = np.empty(len(left), dtype=np.intp)\r\n\u001b[32m\u001b[K152\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Krev\u001b[m\u001b[K.put(np.asarray(left_sorter), np.arange(len(left)))\r\n\u001b[32m\u001b[K154\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Krev\u001b[m\u001b[K, _ = groupsort_indexer(left_indexer, len(left))\r\n\u001b[32m\u001b[K156\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        return np.asarray(left_indexer).take(\u001b[01;31m\u001b[Krev\u001b[m\u001b[K), np.asarray(right_indexer).take(\u001b[01;31m\u001b[Krev\u001b[m\u001b[K)\r\n\u001b[32m\u001b[K716\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # restart right_pos if it went negative in a p\u001b[01;31m\u001b[Krev\u001b[m\u001b[Kious iteration\r\n\u001b[32m\u001b[K787\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        # restart right_pos if it went over in a p\u001b[01;31m\u001b[Krev\u001b[m\u001b[Kious iteration\r\n"]
[190.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[190.002, "i", "git checkout -- pandas/_libs/join.pyx\r"]
[190.004, "o", "git checkout -- pandas/_libs/join.pyx\r\n"]
[190.006, "o", "\u001b[?2004l\r\n"]
[195.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[195.002, "i", "grep -A 10 -B 5 \"TODO(cython3)\" pandas/_libs/algos.pyx\r"]
[195.004, "o", "grep -A 10 -B 5 \"TODO(cython3)\" pandas/_libs/algos.pyx\r\n"]
[195.006, "o", "\u001b[?2004l\r\n    # Loop over the length of the value array\r\n    # each incremental i value can be looked up in the lexsort_indexer\r\n    # array that we sorted previously, which gives us the location of\r\n    # that sorted value for retrieval back from the original\r\n    # values / masked_vals arrays\r\n    # \u001b[01;31m\u001b[KTODO(cython3)\u001b[m\u001b[K: de-duplicate once cython supports conditional nogil\r\n    with gil(numeric_object_t is object):\r\n        for i in range(N):\r\n            at_end = i == N - 1\r\n\r\n            # dups and sum_ranks will be incremented each loop where\r\n            # the value / group remains the same, and should be reset\r\n            # when either of those change. Used to calculate tiebreakers\r\n            dups += 1\r\n            sum_ranks += i - grp_start + 1\r\n\r\n"]
[200.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[200.002, "i", "grep -A 5 -B 5 \"TODO(cython3)\" pandas/_libs/tslibs/timedeltas.pyx\r"]
[200.004, "o", "grep -A 5 -B 5 \"TODO(cython3)\" pandas/_libs/tslibs/timedeltas.pyx\r\n"]
[200.006, "o", "\u001b[?2004l\r\n        The abbreviation associated with self._creso.\r\n        \"\"\"\r\n        return npy_unit_to_abbrev(self._creso)\r\n\r\n    @property\r\n    def days(self) -> int:  # \u001b[01;31m\u001b[KTODO(cython3)\u001b[m\u001b[K: make cdef property\r\n        \"\"\"\r\n        Returns the days of the timedelta.\r\n\r\n        Returns\r\n        -------\r\n\u001b[36m\u001b[K--\u001b[m\u001b[K\r\n        #  (or be incorrect)\r\n        self._ensure_components()\r\n        return self._d\r\n\r\n    @property\r\n    def seconds(self) -> int:  # \u001b[01;31m\u001b[KTODO(cython3)\u001b[m\u001b[K: make cdef property\r\n        \"\"\"\r\n        Return the total hours, minutes, and seconds of the timedelta as seconds.\r\n\r\n        Timedelta.seconds = hours * 3600 + minutes * 60 + seconds.\r\n\r\n\u001b[36m\u001b[K--\u001b[m\u001b[K\r\n        #  (or be incorrect)\r\n        self._ensure_components()\r\n        return self._h * 3600 + self._m * 60 + self._s\r\n\r\n    @property\r\n    def microseconds(self) -> int:  # \u001b[01;31m\u001b[KTODO(cython3)\u001b[m\u001b[K: make cdef property\r\n        # NB: using the python C-API PyDateTime_DELTA_GET_MICROSECONDS will fail\r\n        #  (or be incorrect)\r\n        \"\"\"\r\n        Return the number of microseconds (n), where 0 <= n < 1 millisecond.\r\n\r\n"]
[205.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[205.002, "i", "grep -A 5 -B 5 \"TODO(cython3)\" pandas/_libs/tslibs/np_datetime.pxd\r"]
[205.004, "o", "grep -A 5 -B 5 \"TODO(cython3)\" pandas/_libs/tslibs/np_datetime.pxd\r\n"]
[205.006, "o", "\u001b[?2004l\r\n    npy_datetime,\r\n    npy_timedelta,\r\n)\r\n\r\n\r\n# \u001b[01;31m\u001b[KTODO(cython3)\u001b[m\u001b[K: most of these can be cimported directly from numpy\r\ncdef extern from \"numpy/ndarraytypes.h\":\r\n    ctypedef struct npy_datetimestruct:\r\n        int64_t year\r\n        int32_t month, day, hour, min, sec, us, ps, as\r\n\r\n"]
[210.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[210.002, "i", "sed -i '94s/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/join.pyx\r"]
[210.004, "o", "sed -i '94s/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/join.pyx\r\n"]
[210.006, "o", "\u001b[?2004l\r\n"]
[215.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[215.002, "i", "sed -n '90,100p' pandas/_libs/join.pyx\r"]
[215.004, "o", "sed -n '90,100p' pandas/_libs/join.pyx\r\n"]
[215.006, "o", "\u001b[?2004l\r\ndef left_outer_join(const intp_t[:] left, const intp_t[:] right,\r\n                    Py_ssize_t max_groups, bint sort=True):\r\n    cdef:\r\n        Py_ssize_t i, j, k, count = 0\r\n        intp_t[:] rev\r\n        intp_t[::1] left_count, right_count\r\n        intp_t[::1] left_sorter, right_sorter\r\n        intp_t[::1] left_indexer, right_indexer\r\n        intp_t lc, rc\r\n        Py_ssize_t left_pos = 0, right_pos = 0, position = 0\r\n        Py_ssize_t offset\r\n"]
[220.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[220.002, "i", "python -c \"import pandas._libs.join\" 2>&1 | head -10\r"]
[220.004, "o", "python -c \"import pandas._libs.join\" 2>&1 | head -10\r\n"]
[220.006, "o", "\u001b[?2004l\r\n[1/19] Compiling Cython source /workspace/repo/pandas/_libs/tslibs/tzconversion.pyx\r\n[2/19] Compiling Cython source /workspace/repo/pandas/_libs/index.pyx\r\n[3/19] Compiling Cython source /workspace/repo/pandas/_libs/internals.pyx\r\n[4/19] Compiling Cython source /workspace/repo/pandas/_libs/hashtable.pyx\r\n[5/19] Compiling Cython source /workspace/repo/pandas/_libs/groupby.pyx\r\n[6/19] Compiling Cython source /workspace/repo/pandas/_libs/join.pyx\r\n[7/19] Compiling C object pandas/_libs/tslibs/tzconversion.cpython-310-x86_64-linux-gnu.so.p/meson-generated_pandas__libs_tslibs_tzconversion.pyx.c.o\r\n[8/19] Compiling C object pandas/_libs/index.cpython-310-x86_64-linux-gnu.so.p/meson-generated_pandas__libs_index.pyx.c.o\r\n[9/19] Compiling C object pandas/_libs/internals.cpython-310-x86_64-linux-gnu.so.p/meson-generated_pandas__libs_internals.pyx.c.o\r\n[10/19] Compiling C object pandas/_libs/groupby.cpython-310-x86_64-linux-gnu.so.p/meson-generated_pandas__libs_groupby.pyx.c.o\r\n"]
[225.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[225.002, "i", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/join.pyx\r"]
[225.004, "o", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/join.pyx\r\n"]
[225.006, "o", "\u001b[?2004l\r\n"]
[230.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[230.002, "i", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/groupby.pyx\r"]
[230.004, "o", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/groupby.pyx\r\n"]
[230.006, "o", "\u001b[?2004l\r\n"]
[235.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[235.002, "i", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/hashtable.pyx\r"]
[235.004, "o", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/hashtable.pyx\r\n"]
[235.006, "o", "\u001b[?2004l\r\n"]
[240.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[240.002, "i", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/internals.pyx\r"]
[240.004, "o", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/internals.pyx\r\n"]
[240.006, "o", "\u001b[?2004l\r\n"]
[245.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[245.002, "i", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/index.pyx\r"]
[245.004, "o", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/index.pyx\r\n"]
[245.006, "o", "\u001b[?2004l\r\n"]
[250.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[250.002, "i", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/tslibs/tzconversion.pyx\r"]
[250.004, "o", "sed -i 's/ndarray\\[intp_t\\]/intp_t[:]/g' pandas/_libs/tslibs/tzconversion.pyx\r\n"]
[250.006, "o", "\u001b[?2004l\r\n"]
[255.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[255.002, "i", "grep -r \"ndarray\\[intp_t\\]\" pandas/ --include=\"*.pyx\" --include=\"*.pxd\"\r"]
[255.004, "o", "grep -r \"ndarray\\[intp_t\\]\" pandas/ --include=\"*.pyx\" --include=\"*.pxd\"\r\n"]
[255.006, "o", "\u001b[?2004l\r\n"]
[260.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[260.002, "i", "python -m pip install -e . --no-build-isolation -v\r"]
[260.004, "o", "python -m pip install -e . --no-build-isolation -v\r\n"]
[260.006, "o", "\u001b[?2004l\r\nUsing pip 25.2 from /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/pip (python 3.10)\r\nObtaining file:///workspace/repo\r\n  Running command Checking if build backend supports build_editable\r\n  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\r\n  Running command Preparing editable metadata (pyproject.toml)\r\n  + meson setup --reconfigure /workspace/repo /workspace/repo/build/cp310 -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --vsenv --native-file=/workspace/repo/build/cp310/meson-python-native-file.ini\r\n  The Meson build system\r\n  Version: 1.2.1\r\n  Source dir: /workspace/repo\r\n  Build dir: /workspace/repo/build/cp310\r\n  Build type: native build\r\n  Project name: pandas\r\n  Project version: 0+untagged.34756.g86e807d.dirty\r\n  C compiler for the host machine: /opt/conda/envs/asv_3.10/bin/x86_64-conda-linux-gnu-cc (gcc 14.3.0 \"x86_64-conda-linux-gnu-cc (conda-forge gcc 14.3.0-5) 14.3.0\")\r\n  C linker for the host machine: /opt/conda/envs/asv_3.10/bin/x86_64-conda-linux-gnu-cc ld.bfd 2.44\r\n  C++ compiler for the host machine: /opt/conda/envs/asv_3.10/bin/x86_64-conda-linux-gnu-c++ (gcc 14.3.0 \"x86_64-conda-linux-gnu-c++ (conda-forge gcc 14.3.0-5) 14.3.0\")\r\n  C++ linker for the host machine: /opt/conda/envs/asv_3.10/bin/x86_64-conda-linux-gnu-c++ ld.bfd 2.44\r\n  Cython compiler for the host machine: cython (cython 3.0.12)\r\n  Host machine cpu family: x86_64\r\n  Host machine cpu: x86_64\r\n  Program python found: YES (/opt/conda/envs/asv_3.10/bin/python)\r\n  Build targets in project: 54\r\n\r\n  pandas 0+untagged.34756.g86e807d.dirty\r\n\r\n    User defined options\r\n      Native files: /workspace/repo/build/cp310/meson-python-native-file.ini\r\n      buildtype   : release\r\n      vsenv       : True\r\n      b_ndebug    : if-release\r\n      b_vscrt     : md\r\n\r\n  Found ninja-1.13.1 at /opt/conda/envs/asv_3.10/bin/ninja\r\n\r\n  Visual Studio environment is needed to run Ninja. It is recommended to use Meson wrapper:\r\n  /opt/conda/envs/asv_3.10/bin/meson compile -C .\r\n\r\n  Generating targets:   0%|          | 0/54 eta ?\r\n\r\n\r\n  Writing build.ninja:   0%|          | 0/222 eta ?\r\n\r\n  Cleaning... 0 files.\r\n  + /opt/conda/envs/asv_3.10/bin/ninja\r\n  [1/19] Compiling Cython source /workspace/repo/pandas/_libs/tslibs/tzconversion.pyx\r\n  [2/19] Compiling Cython source /workspace/repo/pandas/_libs/index.pyx\r\n  [3/19] Compiling Cython source /workspace/repo/pandas/_libs/internals.pyx\r\n  [4/19] Compiling Cython source /workspace/repo/pandas/_libs/groupby.pyx\r\n  [5/19] Compiling Cython source /workspace/repo/pandas/_libs/hashtable.pyx\r\n  [6/19] Compiling Cython source /workspace/repo/pandas/_libs/join.pyx\r\n  [7/19] Compiling C object pandas/_libs/tslibs/tzconversion.cpython-310-x86_64-linux-gnu.so.p/meson-generated_pandas__libs_tslibs_tzconversion.pyx.c.o\r\n  [8/19] Compiling C object pandas/_libs/index.cpython-310-x86_64-linux-gnu.so.p/meson-generated_pandas__libs_index.pyx.c.o\r\n  [9/19] Compiling C object pandas/_libs/internals.cpython-310-x86_64-linux-gnu.so.p/meson-generated_pandas__libs_internals.pyx.c.o\r\n  [10/19] Compiling C object pandas/_libs/groupby.cpython-310-x86_64-linux-gnu.so.p/meson-generated_pandas__libs_groupby.pyx.c.o\r\n  [11/19] Generating write_version_file with a custom command\r\n  [12/19] Linking target pandas/_libs/tslibs/tzconversion.cpython-310-x86_64-linux-gnu.so\r\n  [13/19] Linking target pandas/_libs/groupby.cpython-310-x86_64-linux-gnu.so\r\n  [14/19] Linking target pandas/_libs/index.cpython-310-x86_64-linux-gnu.so\r\n  [15/19] Linking target pandas/_libs/internals.cpython-310-x86_64-linux-gnu.so\r\n  [16/19] Compiling C object pandas/_libs/join.cpython-310-x86_64-linux-gnu.so.p/meson-generated_pandas__libs_join.pyx.c.o\r\n  [17/19] Linking target pandas/_libs/join.cpython-310-x86_64-linux-gnu.so\r\n  [18/19] Compiling C object pandas/_libs/hashtable.cpython-310-x86_64-linux-gnu.so.p/meson-generated_pandas__libs_hashtable.pyx.c.o\r\n  [19/19] Linking target pandas/_libs/hashtable.cpython-310-x86_64-linux-gnu.so\r\n  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\nRequirement already satisfied: numpy>=1.23.5 in /opt/conda/envs/asv_3.10/lib/python3.10/site-packages (from pandas==0+untagged.34756.g86e807d.dirty) (2.1.3)\r\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/asv_3.10/lib/python3.10/site-packages (from pandas==0+untagged.34756.g86e807d.dirty) (2.9.0.post0)\r\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/envs/asv_3.10/lib/python3.10/site-packages (from pandas==0+untagged.34756.g86e807d.dirty) (2025.2)\r\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/asv_3.10/lib/python3.10/site-packages (from pandas==0+untagged.34756.g86e807d.dirty) (2025.2)\r\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/asv_3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==0+untagged.34756.g86e807d.dirty) (1.17.0)\r\nBuilding wheels for collected packages: pandas\r\n  Running command Building editable for pandas (pyproject.toml)\r\n  Building editable for pandas (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n  Created wheel for pandas: filename=pandas-0+untagged.34756.g86e807d.dirty-cp310-cp310-linux_x86_64.whl size=33789 sha256=79d9a2b1b824a2a4ce6eb4cad0c67a6a40fe5972db62fb7056aa7f899dfe9d68\r\n  Stored in directory: /tmp/pip-ephem-wheel-cache-t2h2ewph/wheels/cc/57/e9/7b2753aadf0528eeb98ef2dfdd21de00453ccef9cb8e7cbb2a\r\nSuccessfully built pandas\r\nInstalling collected packages: pandas\r\n  Attempting uninstall: pandas\r\n    Found existing installation: pandas 0+untagged.34756.g86e807d\r\n    Uninstalling pandas-0+untagged.34756.g86e807d:\r\n      Removing file or directory /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/__pycache__/_pandas_editable_loader.cpython-310.pyc\r\n      Removing file or directory /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/_pandas_editable_loader.py\r\n      Removing file or directory /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/pandas-0+untagged.34756.g86e807d.dist-info/\r\n      Removing file or directory /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/pandas-editable.pth\r\n      Successfully uninstalled pandas-0+untagged.34756.g86e807d\r\nSuccessfully installed pandas-0+untagged.34756.g86e807d.dirty\r\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\r\n\u001b[0m\r\n"]
[265.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[265.002, "i", "cd asv_bench\r"]
[265.004, "o", "cd asv_bench\r\n"]
[265.006, "o", "\u001b[?2004l\r\n"]
[270.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[270.002, "i", "asv run --python=same --bench=\"multiindex_object.GetLocs.*\"\r"]
[270.004, "o", "asv run --python=same --bench=\"multiindex_object.GetLocs.*\"\r\n"]
[270.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (multiindex_object.GetLocs.time_large_get_locs--)\u001b[0m...\r\n[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mmultiindex_object.GetLocs.time_large_get_locs\u001b[0m                                                                                             974\u00b120\u03bcs\r\n[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mmultiindex_object.GetLocs.time_med_get_locs\u001b[0m                                                                                             86.5\u00b10.9\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mmultiindex_object.GetLocs.time_small_get_locs\u001b[0m                                                                                           76.1\u00b10.8\u03bcs\r\n"]
[275.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[275.002, "i", "asv run --python=same --bench=\"frame_methods.Apply.*\"\r"]
[275.004, "o", "asv run --python=same --bench=\"frame_methods.Apply.*\"\r\n"]
[275.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 6 total benchmarks (1 commits * 1 environments * 6 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 8.33%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (frame_methods.Apply.time_apply_axis_1--)\u001b[0m......\r\n[58.33%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_axis_1\u001b[0m                                                                                                     91.7\u00b11ms\r\n[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_lambda_mean\u001b[0m                                                                                             3.99\u00b10.07ms\r\n[75.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_pass_thru\u001b[0m                                                                                                5.11\u00b10.2ms\r\n[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_ref_by_name\u001b[0m                                                                                             6.27\u00b10.04ms\r\n[91.67%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_str_mean\u001b[0m                                                                                                  268\u00b10.7\u03bcs\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Apply.time_apply_user_func\u001b[0m                                                                                                 127\u00b10.6ms\r\n"]
[280.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[280.002, "i", "asv run --python=same --bench=\"reshape.ReshapeExtensionDtype.*\"\r"]
[280.004, "o", "asv run --python=same --bench=\"reshape.ReshapeExtensionDtype.*\"\r\n"]
[280.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 4 total benchmarks (1 commits * 1 environments * 4 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[12.50%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (reshape.ReshapeExtensionDtype.time_stack--)\u001b[0m....\r\n[62.50%] \u00b7\u00b7\u00b7 \u001b[0;39mreshape.ReshapeExtensionDtype.time_stack\u001b[0m                                                                                                        ok\r\n[62.50%] \u00b7\u00b7\u00b7 \u001b[0;39m============================ ============\u001b[0m\r\n                        dtype                         \r\n             ---------------------------- ------------\r\n              datetime64[ns, US/Pacific]   42.3\u00b10.1ms \r\n                      Period[s]            42.9\u00b10.7ms \r\n             ============================ ============\r\n\r\n[75.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreshape.ReshapeExtensionDtype.time_transpose\u001b[0m                                                                                                    ok\r\n[75.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============================ ============\u001b[0m\r\n                        dtype                         \r\n             ---------------------------- ------------\r\n              datetime64[ns, US/Pacific]   98.5\u00b10.8\u03bcs \r\n                      Period[s]             98.0\u00b11\u03bcs  \r\n             ============================ ============\r\n\r\n[87.50%] \u00b7\u00b7\u00b7 \u001b[0;39mreshape.ReshapeExtensionDtype.time_unstack_fast\u001b[0m                                                                                                 ok\r\n[87.50%] \u00b7\u00b7\u00b7 \u001b[0;39m============================ =========\u001b[0m\r\n                        dtype                      \r\n             ---------------------------- ---------\r\n              datetime64[ns, US/Pacific]   801\u00b13\u03bcs \r\n                      Period[s]            776\u00b12\u03bcs \r\n             ============================ =========\r\n\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreshape.ReshapeExtensionDtype.time_unstack_slow\u001b[0m                                                                                                 ok\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============================ =============\u001b[0m\r\n                         dtype                          \r\n              ---------------------------- -------------\r\n               datetime64[ns, US/Pacific]    1.62\u00b10.3ms \r\n                       Period[s]            1.31\u00b10.01ms \r\n              ============================ =============\r\n\r\n"]
[285.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[285.002, "i", "asv run --python=same --bench=\"stat_ops.Correlation.*\"\r"]
[285.004, "o", "asv run --python=same --bench=\"stat_ops.Correlation.*\"\r\n"]
[285.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (stat_ops.Correlation.time_corr--)\u001b[0m......\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.peakmem_corr_wide\u001b[0m                                                                                                          ok\r\n[57.14%] \u00b7\u00b7\u00b7 \u001b[0;39m========== ======\u001b[0m\r\n               method         \r\n             ---------- ------\r\n              spearman   218M \r\n              kendall    254M \r\n              pearson    218M \r\n             ========== ======\r\n\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corr\u001b[0m                                                                                                                  ok\r\n[64.29%] \u00b7\u00b7\u00b7 \u001b[0;39m========== ============\u001b[0m\r\n               method               \r\n             ---------- ------------\r\n              spearman    799\u00b18\u03bcs   \r\n              kendall    26.4\u00b10.2ms \r\n              pearson    254\u00b10.8\u03bcs  \r\n             ========== ============\r\n\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corr_series\u001b[0m                                                                                                           ok\r\n[71.43%] \u00b7\u00b7\u00b7 \u001b[0;39m========== ==========\u001b[0m\r\n               method             \r\n             ---------- ----------\r\n              spearman   724\u00b150\u03bcs \r\n              kendall    426\u00b120\u03bcs \r\n              pearson    160\u00b13\u03bcs  \r\n             ========== ==========\r\n\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corr_wide\u001b[0m                                                                                                             ok\r\n[78.57%] \u00b7\u00b7\u00b7 \u001b[0;39m========== =============\u001b[0m\r\n               method                \r\n             ---------- -------------\r\n              spearman   7.93\u00b10.03ms \r\n              kendall     1.22\u00b10.01s \r\n              pearson    8.72\u00b10.02ms \r\n             ========== =============\r\n\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corr_wide_nans\u001b[0m                                                                                                        ok\r\n[85.71%] \u00b7\u00b7\u00b7 \u001b[0;39m========== =============\u001b[0m\r\n               method                \r\n             ---------- -------------\r\n              spearman     390\u00b12ms   \r\n              kendall      1.22\u00b10s   \r\n              pearson    9.48\u00b10.09ms \r\n             ========== =============\r\n\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corrwith_cols\u001b[0m                                                                                                         ok\r\n[92.86%] \u00b7\u00b7\u00b7 \u001b[0;39m========== =============\u001b[0m\r\n               method                \r\n             ---------- -------------\r\n              spearman   7.35\u00b10.07ms \r\n              kendall     4.59\u00b10.2ms \r\n              pearson    2.58\u00b10.04ms \r\n             ========== =============\r\n\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mstat_ops.Correlation.time_corrwith_rows\u001b[0m                                                                                                         ok\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========== ============\u001b[0m\r\n                method               \r\n              ---------- ------------\r\n               spearman    183\u00b18ms   \r\n               kendall     148\u00b12ms   \r\n               pearson    3.52\u00b10.2ms \r\n              ========== ============\r\n\r\n"]
[290.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[290.002, "i", "asv run --python=same --bench=\"io.hdf.*\"\r"]
[290.004, "o", "asv run --python=same --bench=\"io.hdf.*\"\r\n"]
[290.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 19 total benchmarks (1 commits * 1 environments * 19 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 5.26%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (io.hdf.HDF.time_read_hdf--)\u001b[0m................\r\n[47.37%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (io.hdf.HDFStoreDataFrame.time_write_store_table_mixed--)\u001b[0m..\r\n[52.63%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDF.peakmem_read_hdf\u001b[0m                                                                                                                     ok\r\n[52.63%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ======\u001b[0m\r\n              format        \r\n             -------- ------\r\n              table    280M \r\n              fixed    275M \r\n             ======== ======\r\n\r\n[55.26%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDF.time_read_hdf\u001b[0m                                                                                                                        ok\r\n[55.26%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ============\u001b[0m\r\n              format              \r\n             -------- ------------\r\n              table    45.9\u00b10.5ms \r\n              fixed    13.5\u00b10.4ms \r\n             ======== ============\r\n\r\n[57.89%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDF.time_write_hdf\u001b[0m                                                                                                                       ok\r\n[57.89%] \u00b7\u00b7\u00b7 \u001b[0;39m======== ============\u001b[0m\r\n              format              \r\n             -------- ------------\r\n              table    59.7\u00b10.5ms \r\n              fixed    21.1\u00b10.3ms \r\n             ======== ============\r\n\r\n[60.53%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_query_store_table\u001b[0m                                                                                         7.65\u00b10.2ms\r\n[63.16%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_query_store_table_wide\u001b[0m                                                                                    9.64\u00b10.3ms\r\n[65.79%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_read_store\u001b[0m                                                                                                12.2\u00b10.1ms\r\n[68.42%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_read_store_mixed\u001b[0m                                                                                          31.1\u00b10.3ms\r\n[71.05%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_read_store_table\u001b[0m                                                                                          2.38\u00b10.1ms\r\n[73.68%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_read_store_table_mixed\u001b[0m                                                                                    26.4\u00b10.2ms\r\n[76.32%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_read_store_table_wide\u001b[0m                                                                                     8.34\u00b10.2ms\r\n[78.95%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_store_info\u001b[0m                                                                                                22.0\u00b10.9ms\r\n[81.58%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_store_repr\u001b[0m                                                                                               1.70\u00b10.01\u03bcs\r\n[84.21%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_store_str\u001b[0m                                                                                                1.71\u00b10.01\u03bcs\r\n[86.84%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store\u001b[0m                                                                                              11.1\u00b10.08ms\r\n[89.47%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store_mixed\u001b[0m                                                                                         15.9\u00b10.3ms\r\n[92.11%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store_table\u001b[0m                                                                                         21.5\u00b10.4ms\r\n[94.74%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store_table_dc\u001b[0m                                                                                         121\u00b12ms\r\n[97.37%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store_table_mixed\u001b[0m                                                                                   30.9\u00b10.2ms\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mio.hdf.HDFStoreDataFrame.time_write_store_table_wide\u001b[0m                                                                                    31.9\u00b10.2ms\r\n"]
[295.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[295.002, "i", "asv run --python=same --bench=\"reindex.ReindexMethod.*\"\r"]
[295.004, "o", "asv run --python=same --bench=\"reindex.ReindexMethod.*\"\r\n"]
[295.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (reindex.ReindexMethod.time_reindex_method--)\u001b[0m.\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39mreindex.ReindexMethod.time_reindex_method\u001b[0m                                                                                                       ok\r\n[100.00%] \u00b7\u00b7\u00b7 \u001b[0;39m========== ======================= =========================\u001b[0m\r\n              --                            constructor                   \r\n              ---------- -------------------------------------------------\r\n                method    <function date_range>   <function period_range> \r\n              ========== ======================= =========================\r\n                 pad             583\u00b12\u03bcs                  590\u00b13\u03bcs         \r\n               backfill          569\u00b13\u03bcs                  566\u00b15\u03bcs         \r\n              ========== ======================= =========================\r\n\r\n"]
[300.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo/asv_bench# "]
[300.002, "i", "cd ..\r"]
[300.004, "o", "cd ..\r\n"]
[300.006, "o", "\u001b[?2004l\r\n"]
[305.0, "o", "(asv_3.10) root@ae6a97092e18:/workspace/repo# "]
[305.002, "i", "\u001b[?2004l\r"]
[305.004, "o", "\u001b[?2004l\r\n"]
[305.006, "o", "\r\nlogout\r\n"]
