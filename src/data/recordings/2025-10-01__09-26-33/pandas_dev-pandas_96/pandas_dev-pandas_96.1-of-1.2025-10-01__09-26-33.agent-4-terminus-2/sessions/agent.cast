{"version": 2, "width": 160, "height": 40, "timestamp": 1762942269, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[0.006, "o", "\u001b[?2004l\r\n\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n\u001b[0;31masciinema: use --append option if you want to append to existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[5.006, "o", "\u001b[?2004l\r\n\u001b[H\u001b[J\r\n"]
[10.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.006, "o", "\u001b[?2004l\r\ntotal 212\r\ndrwxr-xr-x 1 root root  4096 Oct  1 16:58 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 15 17:10 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root   971 Sep 12 22:36 .devcontainer.json\r\ndrwxr-xr-x 1 root root  4096 Oct  1 16:50 \u001b[01;34m.git\u001b[0m\r\n-rw-r--r-- 1 root root  1866 Sep 12 22:37 .gitattributes\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:37 \u001b[01;34m.github\u001b[0m\r\n-rw-r--r-- 1 root root  2004 Sep 12 22:36 .gitignore\r\n-rw-r--r-- 1 root root  2280 Sep 12 22:36 .gitpod.yml\r\n-rw-r--r-- 1 root root 11223 Sep 12 22:37 .pre-commit-config.yaml\r\n-rw-r--r-- 1 root root  2284 Sep 12 22:37 AUTHORS.md\r\n-rw-r--r-- 1 root root  1541 Sep 12 22:36 CITATION.cff\r\n-rw-r--r-- 1 root root   494 Sep 12 22:37 Dockerfile\r\n-rw-r--r-- 1 root root  1634 Sep 12 22:36 LICENSE\r\ndrwxr-xr-x 2 root root  4096 Sep 12 22:36 \u001b[01;34mLICENSES\u001b[0m\r\n-rw-r--r-- 1 root root  1531 Sep 12 22:37 MANIFEST.in\r\n-rw-r--r-- 1 root root 11661 Sep 12 22:37 README.md\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:37 \u001b[01;34masv_bench\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 15 14:18 \u001b[01;34mbuild\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:37 \u001b[01;34mci\u001b[0m\r\n-rw-r--r-- 1 root root   256 Sep 12 22:36 codecov.yml\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:37 \u001b[01;34mdoc\u001b[0m\r\n-rw-r--r-- 1 root root  2623 Sep 12 22:37 environment.yml\r\n-rw-r--r-- 1 root root   866 Sep 12 22:36 generate_pxi.py\r\n-rw-r--r-- 1 root root  1715 Sep 12 22:36 generate_version.py\r\ndrwxr-xr-x 2 root root  4096 Sep 12 22:36 \u001b[01;34mgitpod\u001b[0m\r\n-rw-r--r-- 1 root root  1774 Sep 12 22:37 meson.build\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:37 \u001b[01;34mpandas\u001b[0m\r\n-rw-r--r-- 1 root root 22900 Sep 12 22:37 pyproject.toml\r\n-rw-r--r-- 1 root root  4307 Sep 12 22:36 pyright_reportGeneralTypeIssues.json\r\n-rw-r--r-- 1 root root  1415 Sep 12 22:37 requirements-dev.txt\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:37 \u001b[01;34mscripts\u001b[0m\r\n-rwxr-xr-x 1 root root 21960 Sep 12 22:37 \u001b[01;32msetup.py\u001b[0m\r\ndrwxr-xr-x 3 root root  4096 Sep 12 22:36 \u001b[01;34mtooling\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 12 22:36 \u001b[01;34mtypings\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:37 \u001b[01;34mweb\u001b[0m\r\n"]
[15.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[15.002, "i", "ls -la asv.conf.json\r"]
[15.004, "o", "ls -la asv.conf.json\r\n"]
[15.006, "o", "\u001b[?2004l\r\nls: cannot access 'asv.conf.json': No such file or directory\r\n"]
[20.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[20.002, "i", "grep -R \"asv\" -n . | head -n 50\r"]
[20.004, "o", "grep -R \"asv\" -n . | head -n 50\r\n"]
[20.006, "o", "\u001b[?2004l\r\ngrep: ./.git/index: binary file matches\r\n./.pre-commit-config.yaml:193:    -   id: seed-check-asv\r\n./.pre-commit-config.yaml:194:        name: Check for unnecessary random seeds in asv benchmarks\r\n./.pre-commit-config.yaml:197:        files: ^asv_bench/benchmarks\r\n./.pre-commit-config.yaml:198:        exclude: ^asv_bench/benchmarks/pandas_vb_common\\.py\r\n./.pre-commit-config.yaml:250:        exclude: ^(asv_bench|pandas/tests|doc)/\r\n./.pre-commit-config.yaml:258:            ^(asv_bench|pandas/tests|doc)/\r\n./.github/workflows/code-checks.yml:103:  asv-benchmarks:\r\n./.github/workflows/code-checks.yml:112:      group: ${{ github.event_name == 'push' && github.run_number || github.ref }}-asv-benchmarks\r\n./.github/workflows/code-checks.yml:130:        cd asv_bench\r\n./.github/workflows/code-checks.yml:131:        asv machine --yes\r\n./.github/workflows/code-checks.yml:132:        asv run --quick --dry-run --durations=30 --python=same --show-stderr\r\n./.github/workflows/comment-commands.yml:31:  asv_run:\r\n./.github/workflows/comment-commands.yml:47:      group: ${{ github.actor }}-asv\r\n./.github/workflows/comment-commands.yml:56:        # Although asv sets up its own env, deps are still needed\r\n./.github/workflows/comment-commands.yml:63:        continue-on-error: true # asv will exit code 1 for regressions\r\n./.github/workflows/comment-commands.yml:67:          cd asv_bench\r\n./.github/workflows/comment-commands.yml:68:          asv check -E existing\r\n./.github/workflows/comment-commands.yml:71:          asv machine --yes\r\n./.github/workflows/comment-commands.yml:72:          asv continuous -f 1.1 -b $REGEX upstream/main HEAD\r\n./.github/workflows/comment-commands.yml:74:          asv compare -f 1.1 upstream/main HEAD >> $GITHUB_ENV\r\n./web/pandas/about/roadmap.md:180:Pandas uses [airspeed velocity](https://asv.readthedocs.io/en/stable/)\r\n./web/pandas/about/roadmap.md:185:The [asv-runner](https://github.com/asv-runner) organization, currently\r\n./web/pandas/community/blog/asv-pandas-grant.md:14:[asv library](https://asv.readthedocs.io/en/stable/), a tool used by\r\n./web/pandas/community/blog/asv-pandas-grant.md:58:started building the CI on GitHub actions for the asv package; for that we\r\n./web/pandas/community/blog/asv-pandas-grant.md:91:with [PyLadies Colombia](https://bit.ly/sprint-asv).\r\n./web/pandas/community/benchmarks.md:12:pandas benchmarks are implemented in the [asv_bench](https://github.com/pandas-dev/pandas/tree/main/asv_bench)\r\n./web/pandas/community/benchmarks.md:14:[airspeed velocity](https://asv.readthedocs.io/en/v0.6.1/) (asv for short) framework.\r\n./web/pandas/community/benchmarks.md:17:with the `asv run` command, and it can be useful to detect if local changes have\r\n./web/pandas/community/benchmarks.md:39:- Original server: [asv](https://asv-runner.github.io/asv-collection/pandas/)\r\n./web/pandas/community/benchmarks.md:40:- OVH server: [asv](https://pandas.pydata.org/benchmarks/asv/) (benchmarks results can\r\n./web/pandas/community/benchmarks.md:46:[tomaugspurger/asv-runner](https://github.com/tomaugspurger/asv-runner).\r\n./web/pandas/community/benchmarks.md:48:[tomaugspurger/asv-collection](https://github.com/tomaugspurger/asv-collection).\r\n./asv_bench/benchmarks/io/parsers.py:4:    # Avoid whole benchmark suite import failure on asv (currently 0.4)\r\n./asv_bench/benchmarks/pandas_vb_common.py:59:    # https://asv.readthedocs.io/en/latest/writing_benchmarks.html\r\n./asv_bench/asv.conf.json:31:    // to the current version of Python used to run `asv`.\r\n./asv_bench/asv.conf.json:112:    // `asv` will cache wheels of the recent builds in each\r\n./asv_bench/asv.conf.json:117:    // The commits after which the regression search in `asv publish`\r\n./.gitignore:116:asv_bench/env/\r\n./.gitignore:117:asv_bench/html/\r\n./.gitignore:118:asv_bench/results/\r\n./.gitignore:119:asv_bench/pandas/\r\ngrep: ./.git/objects/pack/pack-5981407437a8d584577275cef839e8009bba105e.pack: binary file matches\r\ngrep: ./pandas/tests/io/data/orc/TestOrcFile.testDate1900.orc: binary file matches\r\n./setup.py:39:# note: sync with pyproject.toml, environment.yml and asv.conf.json\r\n./scripts/tests/data/deps_minimum.toml:7:    \"Cython>=0.29.32,<3\",  # Note: sync with setup.py, environment.yml and asv.conf.json\r\n./scripts/tests/data/deps_minimum.toml:228:  # exclude asv benchmark environments from linting\r\n./requirements-dev.txt:56:asv>=0.6.1\r\n./environment.yml:73:  - asv>=0.6.1\r\n./doc/source/whatsnew/v0.17.0.rst:51:- Development support for benchmarking with the `Air Speed Velocity library <https://github.com/spacetelescope/asv/>`_ (:issue:`8361`)\r\n./doc/source/whatsnew/v0.17.0.rst:1023:- Development support for benchmarking with the `Air Speed Velocity library <https://github.com/spacetelescope/asv/>`_ (:issue:`8361`)\r\n./doc/source/development/contributing_codebase.rst:864:`asv benchmarks <https://github.com/airspeed-velocity/asv>`__\r\n./doc/source/development/contributing_codebase.rst:866:These benchmarks are all found in the ``pandas/asv_bench`` directory, and the\r\ngrep: ./pandas/tests/io/data/orc/TestOrcFile.testDate2038.orc: binary file matches\r\n"]
[25.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[25.002, "i", "ls -la benchmarks\r"]
[25.004, "o", "ls -la benchmarks\r\n"]
[25.006, "o", "\u001b[?2004l\r\nls: cannot access 'benchmarks': No such file or directory\r\n"]
[30.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[30.002, "i", "find . -maxdepth 3 -type f -iname \"*bench*\" -o -iname \"asv*.json\" -o -iname \"asv*.cfg\" -o -iname \"asv_*.txt\"\r"]
[30.004, "o", "find . -maxdepth 3 -type f -iname \"*bench*\" -o -iname \"asv*.json\" -o -iname \"asv*.cfg\" -o -iname \"asv_*.txt\"\r\n"]
[30.006, "o", "\u001b[?2004l\r\n./asv_bench/asv.conf.json\r\n"]
[35.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[35.002, "i", "sed -n '1,200p' asv_benchmarks.txt\r"]
[35.004, "o", "sed -n '1,200p' asv_benchmarks.txt\r\n"]
[35.006, "o", "\u001b[?2004l\r\nsed: can't read asv_benchmarks.txt: No such file or directory\r\n"]
[40.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[40.002, "i", "git status -sb\r"]
[40.004, "o", "git status -sb\r\n"]
[40.006, "o", "\u001b[?2004l\r\n## \u001b[32mmain\u001b[m\r\n"]
[45.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[45.002, "i", "ls -la asv_bench\r"]
[45.004, "o", "ls -la asv_bench\r\n"]
[45.006, "o", "\u001b[?2004l\r\ntotal 24\r\ndrwxr-xr-x 1 root root 4096 Sep 12 22:37 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root 4096 Oct  1 16:58 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root 5194 Sep 12 22:37 asv.conf.json\r\ndrwxr-xr-x 1 root root 4096 Sep 12 22:37 \u001b[01;34mbenchmarks\u001b[0m\r\n"]
[50.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[50.002, "i", "sed -n '1,220p' asv_bench/asv.conf.json\r"]
[50.004, "o", "sed -n '1,220p' asv_bench/asv.conf.json\r\n"]
[50.006, "o", "\u001b[?2004l\r\n{\r\n    // The version of the config file format.  Do not change, unless\r\n    // you know what you are doing.\r\n    \"version\": 1,\r\n\r\n    // The name of the project being benchmarked\r\n    \"project\": \"pandas\",\r\n\r\n    // The project's homepage\r\n    \"project_url\": \"https://pandas.pydata.org/\",\r\n\r\n    // The URL of the source code repository for the project being\r\n    // benchmarked\r\n    \"repo\": \"..\",\r\n\r\n    // List of branches to benchmark. If not provided, defaults to \"master\"\r\n    // (for git) or \"default\" (for mercurial).\r\n    \"branches\": [\"main\"],\r\n\r\n    // The tool to use to create environments.  May be \"conda\",\r\n    // \"virtualenv\" or other value depending on the plugins in use.\r\n    // If missing or the empty string, the tool will be automatically\r\n    // determined by looking for tools on the PATH environment\r\n    // variable.\r\n    \"environment_type\": \"conda\",\r\n\r\n    // the base URL to show a commit for the project.\r\n    \"show_commit_url\": \"https://github.com/pandas-dev/pandas/commit/\",\r\n\r\n    // The Pythons you'd like to test against.  If not provided, defaults\r\n    // to the current version of Python used to run `asv`.\r\n    \"pythons\": [\"3.10\"],\r\n\r\n    // The matrix of dependencies to test.  Each key is the name of a\r\n    // package (in PyPI) and the values are version numbers.  An empty\r\n    // list or empty string indicates to just test against the default\r\n    // (latest) version. null indicates that the package is to not be\r\n    // installed. If the package to be tested is only available from\r\n    // PyPi, and the 'environment_type' is conda, then you can preface\r\n    // the package name by 'pip+', and the package will be installed via\r\n    // pip (with all the conda available packages installed first,\r\n    // followed by the pip installed packages).\r\n    \"matrix\": {\r\n        \"pip+build\": [],\r\n        \"Cython\": [\"3.0\"],\r\n        \"matplotlib\": [],\r\n        \"sqlalchemy\": [],\r\n        \"scipy\": [],\r\n        \"numba\": [],\r\n        \"numexpr\": [],\r\n        \"pytables\": [null, \"\"],  // platform dependent, see excludes below\r\n        \"pyarrow\": [],\r\n        \"tables\": [null, \"\"],\r\n        \"openpyxl\": [],\r\n        \"xlsxwriter\": [],\r\n        \"xlrd\": [],\r\n        \"odfpy\": [],\r\n        \"jinja2\": [],\r\n        \"meson\": [],\r\n        \"meson-python\": [],\r\n        \"python-build\": [],\r\n    },\r\n    \"conda_channels\": [\"conda-forge\"],\r\n    // Combinations of libraries/python versions can be excluded/included\r\n    // from the set to test. Each entry is a dictionary containing additional\r\n    // key-value pairs to include/exclude.\r\n    //\r\n    // An exclude entry excludes entries where all values match. The\r\n    // values are regexps that should match the whole string.\r\n    //\r\n    // An include entry adds an environment. Only the packages listed\r\n    // are installed. The 'python' key is required. The exclude rules\r\n    // do not apply to includes.\r\n    //\r\n    // In addition to package names, the following keys are available:\r\n    //\r\n    // - python\r\n    //     Python version, as in the *pythons* variable above.\r\n    // - environment_type\r\n    //     Environment type, as above.\r\n    // - sys_platform\r\n    //     Platform, as in sys.platform. Possible values for the common\r\n    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.\r\n    \"exclude\": [\r\n        // On conda install pytables, otherwise tables\r\n        {\"environment_type\": \"conda\", \"tables\": \"\"},\r\n        {\"environment_type\": \"conda\", \"pytables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"tables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"pytables\": \"\"},\r\n    ],\r\n    \"include\": [],\r\n\r\n    // The directory (relative to the current directory) that benchmarks are\r\n    // stored in.  If not provided, defaults to \"benchmarks\"\r\n    // \"benchmark_dir\": \"benchmarks\",\r\n\r\n    // The directory (relative to the current directory) to cache the Python\r\n    // environments in.  If not provided, defaults to \"env\"\r\n    // \"env_dir\": \"env\",\r\n\r\n    // The directory (relative to the current directory) that raw benchmark\r\n    // results are stored in.  If not provided, defaults to \"results\".\r\n    // \"results_dir\": \"results\",\r\n\r\n    // The directory (relative to the current directory) that the html tree\r\n    // should be written to.  If not provided, defaults to \"html\".\r\n    // \"html_dir\": \"html\",\r\n\r\n    // The number of characters to retain in the commit hashes.\r\n    // \"hash_length\": 8,\r\n\r\n    // `asv` will cache wheels of the recent builds in each\r\n    // environment, making them faster to install next time.  This is\r\n    // number of builds to keep, per environment.\r\n    \"build_cache_size\": 8,\r\n\r\n    // The commits after which the regression search in `asv publish`\r\n    // should start looking for regressions. Dictionary whose keys are\r\n    // regexps matching to benchmark names, and values corresponding to\r\n    // the commit (exclusive) after which to start looking for\r\n    // regressions.  The default is to start from the first commit\r\n    // with results. If the commit is `null`, regression detection is\r\n    // skipped for the matching benchmark.\r\n    //\r\n    \"regressions_first_commits\": {\r\n        \".*\": \"0409521665\"\r\n    },\r\n    \"regression_thresholds\": {\r\n    },\r\n    \"build_command\":\r\n    [\"python -m build -Cbuilddir=builddir --wheel --outdir {build_cache_dir} {build_dir}\"]\r\n}\r\n"]
[55.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[55.002, "i", "ls -la asv_bench/benchmarks\r"]
[55.004, "o", "ls -la asv_bench/benchmarks\r\n"]
[55.006, "o", "\u001b[?2004l\r\ntotal 376\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:37 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:37 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root    25 Sep 12 22:36 __init__.py\r\n-rw-r--r-- 1 root root  6160 Sep 12 22:36 algorithms.py\r\ndrwxr-xr-x 2 root root  4096 Sep 12 22:36 \u001b[01;34malgos\u001b[0m\r\n-rw-r--r-- 1 root root 12498 Sep 12 22:36 arithmetic.py\r\n-rw-r--r-- 1 root root  4282 Sep 12 22:36 array.py\r\n-rw-r--r-- 1 root root  1414 Sep 12 22:36 attrs_caching.py\r\n-rw-r--r-- 1 root root   739 Sep 12 22:36 boolean.py\r\n-rw-r--r-- 1 root root  9776 Sep 12 22:36 categoricals.py\r\n-rw-r--r-- 1 root root  3462 Sep 12 22:36 ctors.py\r\n-rw-r--r-- 1 root root  3559 Sep 12 22:36 dtypes.py\r\n-rw-r--r-- 1 root root  1988 Sep 12 22:36 eval.py\r\n-rw-r--r-- 1 root root   379 Sep 12 22:36 finalize.py\r\n-rw-r--r-- 1 root root  5142 Sep 12 22:36 frame_ctor.py\r\n-rw-r--r-- 1 root root 24291 Sep 12 22:37 frame_methods.py\r\n-rw-r--r-- 1 root root  8150 Sep 12 22:37 gil.py\r\n-rw-r--r-- 1 root root 33292 Sep 12 22:36 groupby.py\r\n-rw-r--r-- 1 root root  2393 Sep 12 22:36 hash_functions.py\r\n-rw-r--r-- 1 root root  2274 Sep 12 22:36 index_cached_properties.py\r\n-rw-r--r-- 1 root root  7138 Sep 12 22:36 index_object.py\r\n-rw-r--r-- 1 root root 16813 Sep 12 22:36 indexing.py\r\n-rw-r--r-- 1 root root  5949 Sep 12 22:37 indexing_engines.py\r\n-rw-r--r-- 1 root root  8662 Sep 12 22:36 inference.py\r\ndrwxr-xr-x 1 root root  4096 Sep 12 22:37 \u001b[01;34mio\u001b[0m\r\n-rw-r--r-- 1 root root 18607 Sep 12 22:36 join_merge.py\r\n-rw-r--r-- 1 root root  2445 Sep 12 22:36 libs.py\r\n-rw-r--r-- 1 root root 12356 Sep 12 22:36 multiindex_object.py\r\n-rw-r--r-- 1 root root   624 Sep 12 22:36 package.py\r\n-rw-r--r-- 1 root root  1740 Sep 12 22:36 pandas_vb_common.py\r\n-rw-r--r-- 1 root root  2909 Sep 12 22:36 period.py\r\n-rw-r--r-- 1 root root  4554 Sep 12 22:36 plotting.py\r\n-rw-r--r-- 1 root root  4948 Sep 12 22:36 reindex.py\r\n-rw-r--r-- 1 root root  2103 Sep 12 22:36 replace.py\r\n-rw-r--r-- 1 root root  9973 Sep 12 22:36 reshape.py\r\n-rw-r--r-- 1 root root 11474 Sep 12 22:37 rolling.py\r\n-rw-r--r-- 1 root root 10677 Sep 12 22:36 series_methods.py\r\n-rw-r--r-- 1 root root  6817 Sep 12 22:36 sparse.py\r\n-rw-r--r-- 1 root root  4685 Sep 12 22:36 stat_ops.py\r\n-rw-r--r-- 1 root root  3535 Sep 12 22:36 strftime.py\r\n-rw-r--r-- 1 root root  7996 Sep 12 22:37 strings.py\r\n-rw-r--r-- 1 root root  1528 Sep 12 22:36 timedelta.py\r\n-rw-r--r-- 1 root root  8565 Sep 12 22:36 timeseries.py\r\ndrwxr-xr-x 2 root root  4096 Sep 12 22:36 \u001b[01;34mtslibs\u001b[0m\r\n"]
[60.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[60.002, "i", "find asv_bench/benchmarks -maxdepth 3 -type f -name \"*.py\" | sed 's#.*/benchmarks/##' | sort | head -n 200\r"]
[60.004, "o", "find asv_bench/benchmarks -maxdepth 3 -type f -name \"*.py\" | sed 's#.*/benchmarks/##' | sort | head -n 200\r\n"]
[60.006, "o", "\u001b[?2004l\r\n__init__.py\r\nalgorithms.py\r\nalgos/__init__.py\r\nalgos/isin.py\r\narithmetic.py\r\narray.py\r\nattrs_caching.py\r\nboolean.py\r\ncategoricals.py\r\nctors.py\r\ndtypes.py\r\neval.py\r\nfinalize.py\r\nframe_ctor.py\r\nframe_methods.py\r\ngil.py\r\ngroupby.py\r\nhash_functions.py\r\nindex_cached_properties.py\r\nindex_object.py\r\nindexing.py\r\nindexing_engines.py\r\ninference.py\r\nio/__init__.py\r\nio/csv.py\r\nio/excel.py\r\nio/hdf.py\r\nio/json.py\r\nio/parsers.py\r\nio/pickle.py\r\nio/sas.py\r\nio/sql.py\r\nio/stata.py\r\nio/style.py\r\njoin_merge.py\r\nlibs.py\r\nmultiindex_object.py\r\npackage.py\r\npandas_vb_common.py\r\nperiod.py\r\nplotting.py\r\nreindex.py\r\nreplace.py\r\nreshape.py\r\nrolling.py\r\nseries_methods.py\r\nsparse.py\r\nstat_ops.py\r\nstrftime.py\r\nstrings.py\r\ntimedelta.py\r\ntimeseries.py\r\ntslibs/__init__.py\r\ntslibs/fields.py\r\ntslibs/normalize.py\r\ntslibs/offsets.py\r\ntslibs/period.py\r\ntslibs/resolution.py\r\ntslibs/timedelta.py\r\ntslibs/timestamp.py\r\ntslibs/tslib.py\r\ntslibs/tz_convert.py\r\n"]
[65.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[65.002, "i", "grep -R \"class .*\\(Base.*Benchmark\\|Timed.*\\)\" -n asv_bench/benchmarks | head -n 50\r"]
[65.004, "o", "grep -R \"class .*\\(Base.*Benchmark\\|Timed.*\\)\" -n asv_bench/benchmarks | head -n 50\r\n"]
[65.006, "o", "\u001b[?2004l\r\nasv_bench/benchmarks/arithmetic.py:298:class TimedeltaOps:\r\nasv_bench/benchmarks/inference.py:268:class ToTimedelta:\r\nasv_bench/benchmarks/inference.py:287:class ToTimedeltaErrors:\r\nasv_bench/benchmarks/tslibs/fields.py:12:class TimeGetTimedeltaField:\r\nasv_bench/benchmarks/tslibs/timedelta.py:13:class TimedeltaConstructor:\r\nasv_bench/benchmarks/tslibs/timedelta.py:55:class TimedeltaProperties:\r\nasv_bench/benchmarks/timedelta.py:35:class TimedeltaIndexing:\r\n"]
[70.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[70.002, "i", "grep -R \"DatetimeIndex\" -n asv_bench/benchmarks | head -n 50\r"]
[70.004, "o", "grep -R \"DatetimeIndex\" -n asv_bench/benchmarks | head -n 50\r\n"]
[70.006, "o", "\u001b[?2004l\r\nasv_bench/benchmarks/ctors.py:4:    DatetimeIndex,\r\nasv_bench/benchmarks/ctors.py:107:        DatetimeIndex(self.s)\r\nasv_bench/benchmarks/ctors.py:122:class DatetimeIndexConstructor:\r\nasv_bench/benchmarks/ctors.py:133:        DatetimeIndex(self.list_of_timestamps)\r\nasv_bench/benchmarks/ctors.py:136:        DatetimeIndex(self.list_of_dates)\r\nasv_bench/benchmarks/ctors.py:139:        DatetimeIndex(self.list_of_datetimes)\r\nasv_bench/benchmarks/ctors.py:142:        DatetimeIndex(self.list_of_str)\r\nasv_bench/benchmarks/tslibs/tz_convert.py:42:        #  dti = DatetimeIndex(self.i8data, tz=tz)\r\nasv_bench/benchmarks/tslibs/tz_convert.py:51:        #  dti = DatetimeIndex(self.i8data)\r\nasv_bench/benchmarks/plotting.py:15:    DatetimeIndex,\r\nasv_bench/benchmarks/plotting.py:82:        idx_irregular = DatetimeIndex(\r\nasv_bench/benchmarks/index_object.py:6:    DatetimeIndex,\r\nasv_bench/benchmarks/index_object.py:57:        self.datetime_left = DatetimeIndex(range(N))\r\nasv_bench/benchmarks/index_object.py:58:        self.datetime_right = DatetimeIndex(range(N, B))\r\nasv_bench/benchmarks/indexing.py:342:class DatetimeIndexIndexing:\r\nasv_bench/benchmarks/indexing.py:356:class SortedAndUnsortedDatetimeIndexLoc:\r\nasv_bench/benchmarks/io/csv.py:86:class ToCSVDatetimeIndex(BaseIO):\r\nasv_bench/benchmarks/index_cached_properties.py:11:            \"DatetimeIndex\",\r\nasv_bench/benchmarks/index_cached_properties.py:30:        elif index_type == \"DatetimeIndex\":\r\nasv_bench/benchmarks/timeseries.py:22:class DatetimeIndex:\r\n"]
[75.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[75.002, "i", "grep -R \"MaskBool\" -n asv_bench/benchmarks | head -n 50\r"]
[75.004, "o", "grep -R \"MaskBool\" -n asv_bench/benchmarks | head -n 50\r\n"]
[75.006, "o", "\u001b[?2004l\r\nasv_bench/benchmarks/frame_methods.py:357:class MaskBool:\r\n"]
[80.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[80.002, "i", "cd asv_bench\r"]
[80.004, "o", "cd asv_bench\r\n"]
[80.006, "o", "\u001b[?2004l\r\n"]
[85.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[85.002, "i", "asv run --python=same --quick --bench=\"timeseries.DatetimeIndex.*|period.Indexing.*|frame_methods.MaskBoo\r"]
[85.004, "o", "asv run --python=same --quick --bench=\"timeseries.DatetimeIndex.*|period.Indexing.*|frame_methods.MaskBoo\r\n"]
[85.006, "o", "ol.*|categoricals.Indexing.*|timedelta.TimedeltaIndexing.*\" --show-stderr\r\n\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 32 total benchmarks (1 commits * 1 environments * 32 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[ 1.56%] \u00b7\u00b7\u00b7 \u001b[0;39mcategoricals.Indexing.time_align\u001b[0m                                                                                                          4.66\u00b10ms\r\n[ 3.12%] \u00b7\u00b7\u00b7 \u001b[0;39mcategoricals.Indexing.time_get_loc\u001b[0m                                                                                                         843\u00b10\u03bcs\r\n[ 4.69%] \u00b7\u00b7\u00b7 \u001b[0;39mcategoricals.Indexing.time_intersection\u001b[0m                                                                                                   2.30\u00b10ms\r\n[ 6.25%] \u00b7\u00b7\u00b7 \u001b[0;39mcategoricals.Indexing.time_reindex\u001b[0m                                                                                                        2.72\u00b10ms\r\n[ 7.81%] \u00b7\u00b7\u00b7 \u001b[0;39mcategoricals.Indexing.time_reindex_missing\u001b[0m                                                                                                11.1\u00b10ms\r\n[ 9.38%] \u00b7\u00b7\u00b7 \u001b[0;39mcategoricals.Indexing.time_shallow_copy\u001b[0m                                                                                                   5.78\u00b10\u03bcs\r\n[10.94%] \u00b7\u00b7\u00b7 \u001b[0;39mcategoricals.Indexing.time_sort_values\u001b[0m                                                                                                    4.29\u00b10ms\r\n[12.50%] \u00b7\u00b7\u00b7 \u001b[0;39mcategoricals.Indexing.time_unique\u001b[0m                                                                                                         17.6\u00b10\u03bcs\r\n[14.06%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              54.9\u00b10ms\r\n[15.62%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             4.22\u00b10ms\r\n[17.19%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_align\u001b[0m                                                                                                                1.59\u00b10ms\r\n[18.75%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_get_loc\u001b[0m                                                                                                               256\u00b10\u03bcs\r\n[20.31%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_intersection\u001b[0m                                                                                                          582\u00b10\u03bcs\r\n[21.88%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_series_loc\u001b[0m                                                                                                            325\u00b10\u03bcs\r\n[23.44%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_shallow_copy\u001b[0m                                                                                                         10.8\u00b10\u03bcs\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_unique\u001b[0m                                                                                                                156\u00b10\u03bcs\r\n[26.56%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_align\u001b[0m                                                                                                    1.70\u00b10ms\r\n[28.12%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_get_loc\u001b[0m                                                                                                   210\u00b10\u03bcs\r\n[29.69%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_intersection\u001b[0m                                                                                              370\u00b10\u03bcs\r\n[31.25%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_series_loc\u001b[0m                                                                                                327\u00b10\u03bcs\r\n[32.81%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_shallow_copy\u001b[0m                                                                                             12.1\u00b10\u03bcs\r\n[34.38%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_union\u001b[0m                                                                                                     558\u00b10\u03bcs\r\n[35.94%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_unique\u001b[0m                                                                                                    174\u00b10\u03bcs\r\n[37.50%] \u00b7\u00b7\u00b7 \u001b[0;39mtimeseries.DatetimeIndex.time_add_timedelta\u001b[0m                                                                                                     ok\r\n[37.50%] \u00b7\u00b7\u00b7 \u001b[0;39m============ =========\u001b[0m\r\n              index_type           \r\n             ------------ ---------\r\n                 dst       329\u00b10\u03bcs \r\n               repeated    807\u00b10\u03bcs \r\n               tz_aware    843\u00b10\u03bcs \r\n               tz_local    827\u00b10\u03bcs \r\n               tz_naive    935\u00b10\u03bcs \r\n             ============ =========\r\n\r\n[39.06%] \u00b7\u00b7\u00b7 \u001b[0;39mtimeseries.DatetimeIndex.time_get\u001b[0m                                                                                                               ok\r\n[39.06%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ==========\u001b[0m\r\n              index_type            \r\n             ------------ ----------\r\n                 dst       66.8\u00b10\u03bcs \r\n               repeated    67.3\u00b10\u03bcs \r\n               tz_aware    65.4\u00b10\u03bcs \r\n               tz_local    90.6\u00b10\u03bcs \r\n               tz_naive    121\u00b10\u03bcs  \r\n             ============ ==========\r\n\r\n[40.62%] \u00b7\u00b7\u00b7 \u001b[0;39mtimeseries.DatetimeIndex.time_is_dates_only\u001b[0m                                                                                                     ok\r\n[40.62%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ==========\u001b[0m\r\n              index_type            \r\n             ------------ ----------\r\n                 dst       58.4\u00b10\u03bcs \r\n               repeated    998\u00b10\u03bcs  \r\n               tz_aware    55.6\u00b10\u03bcs \r\n               tz_local    57.9\u00b10\u03bcs \r\n               tz_naive    51.5\u00b10\u03bcs \r\n             ============ ==========\r\n\r\n[42.19%] \u00b7\u00b7\u00b7 \u001b[0;39mtimeseries.DatetimeIndex.time_normalize\u001b[0m                                                                                                         ok\r\n[42.19%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ==========\u001b[0m\r\n              index_type            \r\n             ------------ ----------\r\n                 dst       547\u00b10\u03bcs  \r\n               repeated    1.89\u00b10ms \r\n               tz_aware    641\u00b10ms  \r\n               tz_local    907\u00b10ms  \r\n               tz_naive    1.82\u00b10ms \r\n             ============ ==========\r\n\r\n[43.75%] \u00b7\u00b7\u00b7 \u001b[0;39mtimeseries.DatetimeIndex.time_timeseries_is_month_start\u001b[0m                                                                                         ok\r\n[43.75%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ==========\u001b[0m\r\n              index_type            \r\n             ------------ ----------\r\n                 dst       168\u00b10\u03bcs  \r\n               repeated    1.55\u00b10ms \r\n               tz_aware    42.5\u00b10ms \r\n               tz_local    872\u00b10ms  \r\n               tz_naive    1.50\u00b10ms \r\n             ============ ==========\r\n\r\n[45.31%] \u00b7\u00b7\u00b7 \u001b[0;39mtimeseries.DatetimeIndex.time_to_date\u001b[0m                                                                                                           ok\r\n[45.31%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ==========\u001b[0m\r\n              index_type            \r\n             ------------ ----------\r\n                 dst       658\u00b10\u03bcs  \r\n               repeated    15.7\u00b10ms \r\n               tz_aware    56.6\u00b10ms \r\n               tz_local    886\u00b10ms  \r\n               tz_naive    15.7\u00b10ms \r\n             ============ ==========\r\n\r\n[46.88%] \u00b7\u00b7\u00b7 \u001b[0;39mtimeseries.DatetimeIndex.time_to_pydatetime\u001b[0m                                                                                                     ok\r\n[46.88%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ==========\u001b[0m\r\n              index_type            \r\n             ------------ ----------\r\n                 dst       1.54\u00b10ms \r\n               repeated    39.7\u00b10ms \r\n               tz_aware    82.2\u00b10ms \r\n               tz_local    916\u00b10ms  \r\n               tz_naive    40.1\u00b10ms \r\n             ============ ==========\r\n\r\n[48.44%] \u00b7\u00b7\u00b7 \u001b[0;39mtimeseries.DatetimeIndex.time_to_time\u001b[0m                                                                                                           ok\r\n[48.44%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ==========\u001b[0m\r\n              index_type            \r\n             ------------ ----------\r\n                 dst       1.33\u00b10ms \r\n               repeated    32.2\u00b10ms \r\n               tz_aware    73.0\u00b10ms \r\n               tz_local    904\u00b10ms  \r\n               tz_naive    32.3\u00b10ms \r\n             ============ ==========\r\n\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mtimeseries.DatetimeIndex.time_unique\u001b[0m                                                                                                            ok\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39m============ ==========\u001b[0m\r\n              index_type            \r\n             ------------ ----------\r\n                 dst       153\u00b10\u03bcs  \r\n               repeated    2.05\u00b10ms \r\n               tz_aware    297\u00b10\u03bcs  \r\n               tz_local    283\u00b10\u03bcs  \r\n               tz_naive    290\u00b10\u03bcs  \r\n             ============ ==========\r\n\r\n"]
[90.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[90.002, "i", "grep -R \"class .*MaskBool\" -n benchmarks | head -n 20\r"]
[90.004, "o", "grep -R \"class .*MaskBool\" -n benchmarks | head -n 20\r\n"]
[90.006, "o", "\u001b[?2004l\r\nbenchmarks/frame_methods.py:357:class MaskBool:\r\n"]
[95.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[95.002, "i", "grep -R \"class .*Indexing\" -n benchmarks | head -n 50\r"]
[95.004, "o", "grep -R \"class .*Indexing\" -n benchmarks | head -n 50\r\n"]
[95.006, "o", "\u001b[?2004l\r\nbenchmarks/indexing_engines.py:58:class NumericEngineIndexing:\r\nbenchmarks/indexing_engines.py:105:class MaskedNumericEngineIndexing:\r\nbenchmarks/indexing_engines.py:158:class ObjectEngineIndexing:\r\nbenchmarks/hash_functions.py:57:class NumericSeriesIndexing:\r\nbenchmarks/hash_functions.py:74:class NumericSeriesIndexingShuffled:\r\nbenchmarks/index_object.py:154:class Indexing:\r\nbenchmarks/indexing.py:27:class NumericSeriesIndexing:\r\nbenchmarks/indexing.py:86:class NumericMaskedIndexing:\r\nbenchmarks/indexing.py:114:class NonNumericSeriesIndexing:\r\nbenchmarks/indexing.py:154:class DataFrameStringIndexing:\r\nbenchmarks/indexing.py:188:class DataFrameNumericIndexing:\r\nbenchmarks/indexing.py:242:class MultiIndexing:\r\nbenchmarks/indexing.py:323:class IntervalIndexing:\r\nbenchmarks/indexing.py:342:class DatetimeIndexIndexing:\r\nbenchmarks/indexing.py:374:class CategoricalIndexIndexing:\r\nbenchmarks/indexing.py:531:class ChainIndexing:\r\nbenchmarks/timedelta.py:35:class TimedeltaIndexing:\r\nbenchmarks/period.py:85:class Indexing:\r\nbenchmarks/categoricals.py:291:class Indexing:\r\n"]
[100.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[100.002, "i", "grep -R \"DatetimeIndex\" -n benchmarks | head -n 50\r"]
[100.004, "o", "grep -R \"DatetimeIndex\" -n benchmarks | head -n 50\r\n"]
[100.006, "o", "\u001b[?2004l\r\ngrep: benchmarks/io/__pycache__/csv.cpython-310.pyc: binary file matches\r\nbenchmarks/ctors.py:4:    DatetimeIndex,\r\nbenchmarks/ctors.py:107:        DatetimeIndex(self.s)\r\nbenchmarks/ctors.py:122:class DatetimeIndexConstructor:\r\nbenchmarks/ctors.py:133:        DatetimeIndex(self.list_of_timestamps)\r\nbenchmarks/ctors.py:136:        DatetimeIndex(self.list_of_dates)\r\nbenchmarks/ctors.py:139:        DatetimeIndex(self.list_of_datetimes)\r\nbenchmarks/ctors.py:142:        DatetimeIndex(self.list_of_str)\r\nbenchmarks/tslibs/tz_convert.py:42:        #  dti = DatetimeIndex(self.i8data, tz=tz)\r\nbenchmarks/tslibs/tz_convert.py:51:        #  dti = DatetimeIndex(self.i8data)\r\nbenchmarks/plotting.py:15:    DatetimeIndex,\r\nbenchmarks/plotting.py:82:        idx_irregular = DatetimeIndex(\r\nbenchmarks/index_object.py:6:    DatetimeIndex,\r\nbenchmarks/index_object.py:57:        self.datetime_left = DatetimeIndex(range(N))\r\nbenchmarks/index_object.py:58:        self.datetime_right = DatetimeIndex(range(N, B))\r\nbenchmarks/indexing.py:342:class DatetimeIndexIndexing:\r\nbenchmarks/indexing.py:356:class SortedAndUnsortedDatetimeIndexLoc:\r\nbenchmarks/io/csv.py:86:class ToCSVDatetimeIndex(BaseIO):\r\ngrep: benchmarks/index_cached_properties.py:11:            \"DatetimeIndex\",\r\nbenchmarks/index_cached_properties.py:30:        elif index_type == \"DatetimeIndex\":\r\nbenchmarks/timeseries.py:22:class DatetimeIndex:\r\nbenchmarks/__pycache__/plotting.cpython-310.pyc: binary file matches\r\ngrep: benchmarks/__pycache__/ctors.cpython-310.pyc: binary file matches\r\ngrep: benchmarks/__pycache__/indexing.cpython-310.pyc: binary file matches\r\ngrep: benchmarks/__pycache__/timeseries.cpython-310.pyc: binary file matches\r\ngrep: benchmarks/__pycache__/index_cached_properties.cpython-310.pyc: binary file matches\r\ngrep: benchmarks/__pycache__/index_object.cpython-310.pyc: binary file matches\r\n"]
[105.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[105.002, "i", "sed -n '1,200p' benchmarks/frame_methods.py\r"]
[105.004, "o", "sed -n '1,200p' benchmarks/frame_methods.py\r\n"]
[105.006, "o", "\u001b[?2004l\r\nimport string\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas import (\r\n    DataFrame,\r\n    Index,\r\n    MultiIndex,\r\n    NaT,\r\n    Series,\r\n    date_range,\r\n    isnull,\r\n    period_range,\r\n    timedelta_range,\r\n)\r\n\r\n\r\nclass AsType:\r\n    params = [\r\n        [\r\n            # from_dtype == to_dtype\r\n            (\"Float64\", \"Float64\"),\r\n            (\"float64[pyarrow]\", \"float64[pyarrow]\"),\r\n            # from non-EA to EA\r\n            (\"float64\", \"Float64\"),\r\n            (\"float64\", \"float64[pyarrow]\"),\r\n            # from EA to non-EA\r\n            (\"Float64\", \"float64\"),\r\n            (\"float64[pyarrow]\", \"float64\"),\r\n            # from EA to EA\r\n            (\"Int64\", \"Float64\"),\r\n            (\"int64[pyarrow]\", \"float64[pyarrow]\"),\r\n        ],\r\n        [False, True],\r\n    ]\r\n    param_names = [\"from_to_dtypes\", \"copy\"]\r\n\r\n    def setup(self, from_to_dtypes, copy):\r\n        from_dtype = from_to_dtypes[0]\r\n        if from_dtype in (\"float64\", \"Float64\", \"float64[pyarrow]\"):\r\n            data = np.random.randn(100, 100)\r\n        elif from_dtype in (\"int64\", \"Int64\", \"int64[pyarrow]\"):\r\n            data = np.random.randint(0, 1000, (100, 100))\r\n        else:\r\n            raise NotImplementedError\r\n        self.df = DataFrame(data, dtype=from_dtype)\r\n\r\n    def time_astype(self, from_to_dtypes, copy):\r\n        self.df.astype(from_to_dtypes[1], copy=copy)\r\n\r\n\r\nclass Clip:\r\n    params = [\r\n        [\"float64\", \"Float64\", \"float64[pyarrow]\"],\r\n    ]\r\n    param_names = [\"dtype\"]\r\n\r\n    def setup(self, dtype):\r\n        data = np.random.randn(100_000, 10)\r\n        df = DataFrame(data, dtype=dtype)\r\n        self.df = df\r\n\r\n    def time_clip(self, dtype):\r\n        self.df.clip(-1.0, 1.0)\r\n\r\n\r\nclass GetNumericData:\r\n    def setup(self):\r\n        self.df = DataFrame(np.random.randn(10000, 25))\r\n        self.df[\"foo\"] = \"bar\"\r\n        self.df[\"bar\"] = \"baz\"\r\n        self.df = self.df._consolidate()\r\n\r\n    def time_frame_get_numeric_data(self):\r\n        self.df._get_numeric_data()\r\n\r\n\r\nclass Reindex:\r\n    def setup(self):\r\n        N = 10**3\r\n        self.df = DataFrame(np.random.randn(N * 10, N))\r\n        self.idx = np.arange(4 * N, 7 * N)\r\n        self.idx_cols = np.random.randint(0, N, N)\r\n        self.df2 = DataFrame(\r\n            {\r\n                c: {\r\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\r\n                    1: np.random.randint(0, N, N).astype(np.int16),\r\n                    2: np.random.randint(0, N, N).astype(np.int32),\r\n                    3: np.random.randint(0, N, N).astype(np.int64),\r\n                }[np.random.randint(0, 4)]\r\n                for c in range(N)\r\n            }\r\n        )\r\n\r\n    def time_reindex_axis0(self):\r\n        self.df.reindex(self.idx)\r\n\r\n    def time_reindex_axis1(self):\r\n        self.df.reindex(columns=self.idx_cols)\r\n\r\n    def time_reindex_axis1_missing(self):\r\n        self.df.reindex(columns=self.idx)\r\n\r\n    def time_reindex_both_axes(self):\r\n        self.df.reindex(index=self.idx, columns=self.idx_cols)\r\n\r\n    def time_reindex_upcast(self):\r\n        self.df2.reindex(np.random.permutation(range(1200)))\r\n\r\n\r\nclass Rename:\r\n    def setup(self):\r\n        N = 10**3\r\n        self.df = DataFrame(np.random.randn(N * 10, N))\r\n        self.idx = np.arange(4 * N, 7 * N)\r\n        self.dict_idx = {k: k for k in self.idx}\r\n        self.df2 = DataFrame(\r\n            {\r\n                c: {\r\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\r\n                    1: np.random.randint(0, N, N).astype(np.int16),\r\n                    2: np.random.randint(0, N, N).astype(np.int32),\r\n                    3: np.random.randint(0, N, N).astype(np.int64),\r\n                }[np.random.randint(0, 4)]\r\n                for c in range(N)\r\n            }\r\n        )\r\n\r\n    def time_rename_single(self):\r\n        self.df.rename({0: 0})\r\n\r\n    def time_rename_axis0(self):\r\n        self.df.rename(self.dict_idx)\r\n\r\n    def time_rename_axis1(self):\r\n        self.df.rename(columns=self.dict_idx)\r\n\r\n    def time_rename_both_axes(self):\r\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\r\n\r\n    def time_dict_rename_both_axes(self):\r\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\r\n\r\n\r\nclass Iteration:\r\n    # mem_itertuples_* benchmarks are slow\r\n    timeout = 120\r\n\r\n    def setup(self):\r\n        N = 1000\r\n        self.df = DataFrame(np.random.randn(N * 10, N))\r\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\r\n        self.df3 = DataFrame(\r\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\r\n        )\r\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))\r\n\r\n    def time_items(self):\r\n        # (monitor no-copying behaviour)\r\n        for name, col in self.df.items():\r\n            pass\r\n\r\n    def time_iteritems_indexing(self):\r\n        for col in self.df3:\r\n            self.df3[col]\r\n\r\n    def time_itertuples_start(self):\r\n        self.df4.itertuples()\r\n\r\n    def time_itertuples_read_first(self):\r\n        next(self.df4.itertuples())\r\n\r\n    def time_itertuples(self):\r\n        for row in self.df4.itertuples():\r\n            pass\r\n\r\n    def time_itertuples_to_list(self):\r\n        list(self.df4.itertuples())\r\n\r\n    def mem_itertuples_start(self):\r\n        return self.df4.itertuples()\r\n\r\n    def peakmem_itertuples_start(self):\r\n        self.df4.itertuples()\r\n\r\n    def mem_itertuples_read_first(self):\r\n        return next(self.df4.itertuples())\r\n\r\n    def peakmem_itertuples(self):\r\n        for row in self.df4.itertuples():\r\n            pass\r\n\r\n    def mem_itertuples_to_list(self):\r\n        return list(self.df4.itertuples())\r\n\r\n    def peakmem_itertuples_to_list(self):\r\n        list(self.df4.itertuples())\r\n\r\n"]
[110.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[110.002, "i", "sed -n '1,200p' benchmarks/categoricals.py\r"]
[110.004, "o", "sed -n '1,200p' benchmarks/categoricals.py\r\n"]
[110.006, "o", "\u001b[?2004l\r\nimport string\r\nimport sys\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nimport pandas as pd\r\n\r\ntry:\r\n    from pandas.api.types import union_categoricals\r\nexcept ImportError:\r\n    try:\r\n        from pandas.types.concat import union_categoricals\r\n    except ImportError:\r\n        pass\r\n\r\n\r\nclass Constructor:\r\n    def setup(self):\r\n        N = 10**5\r\n        self.categories = list(\"abcde\")\r\n        self.cat_idx = pd.Index(self.categories)\r\n        self.values = np.tile(self.categories, N)\r\n        self.codes = np.tile(range(len(self.categories)), N)\r\n\r\n        self.datetimes = pd.Series(\r\n            pd.date_range(\"1995-01-01 00:00:00\", periods=N // 10, freq=\"s\")\r\n        )\r\n        self.datetimes_with_nat = self.datetimes.copy()\r\n        self.datetimes_with_nat.iloc[-1] = pd.NaT\r\n\r\n        self.values_some_nan = list(np.tile(self.categories + [np.nan], N))\r\n        self.values_all_nan = [np.nan] * len(self.values)\r\n        self.values_all_int8 = np.ones(N, \"int8\")\r\n        self.categorical = pd.Categorical(self.values, self.categories)\r\n        self.series = pd.Series(self.categorical)\r\n        self.intervals = pd.interval_range(0, 1, periods=N // 10)\r\n\r\n    def time_regular(self):\r\n        pd.Categorical(self.values, self.categories)\r\n\r\n    def time_fastpath(self):\r\n        dtype = pd.CategoricalDtype(categories=self.cat_idx)\r\n        pd.Categorical._simple_new(self.codes, dtype)\r\n\r\n    def time_datetimes(self):\r\n        pd.Categorical(self.datetimes)\r\n\r\n    def time_interval(self):\r\n        pd.Categorical(self.datetimes, categories=self.datetimes)\r\n\r\n    def time_datetimes_with_nat(self):\r\n        pd.Categorical(self.datetimes_with_nat)\r\n\r\n    def time_with_nan(self):\r\n        pd.Categorical(self.values_some_nan)\r\n\r\n    def time_all_nan(self):\r\n        pd.Categorical(self.values_all_nan)\r\n\r\n    def time_from_codes_all_int8(self):\r\n        pd.Categorical.from_codes(self.values_all_int8, self.categories)\r\n\r\n    def time_existing_categorical(self):\r\n        pd.Categorical(self.categorical)\r\n\r\n    def time_existing_series(self):\r\n        pd.Categorical(self.series)\r\n\r\n\r\nclass AsType:\r\n    def setup(self):\r\n        N = 10**5\r\n\r\n        random_pick = np.random.default_rng().choice\r\n\r\n        categories = {\r\n            \"str\": list(string.ascii_letters),\r\n            \"int\": np.random.randint(2**16, size=154),\r\n            \"float\": sys.maxsize * np.random.random((38,)),\r\n            \"timestamp\": [\r\n                pd.Timestamp(x, unit=\"s\") for x in np.random.randint(2**18, size=578)\r\n            ],\r\n        }\r\n\r\n        self.df = pd.DataFrame(\r\n            {col: random_pick(cats, N) for col, cats in categories.items()}\r\n        )\r\n\r\n        for col in (\"int\", \"float\", \"timestamp\"):\r\n            self.df[f\"{col}_as_str\"] = self.df[col].astype(str)\r\n\r\n        for col in self.df.columns:\r\n            self.df[col] = self.df[col].astype(\"category\")\r\n\r\n    def astype_str(self):\r\n        [self.df[col].astype(\"str\") for col in \"int float timestamp\".split()]\r\n\r\n    def astype_int(self):\r\n        [self.df[col].astype(\"int\") for col in \"int_as_str timestamp\".split()]\r\n\r\n    def astype_float(self):\r\n        [\r\n            self.df[col].astype(\"float\")\r\n            for col in \"float_as_str int int_as_str timestamp\".split()\r\n        ]\r\n\r\n    def astype_datetime(self):\r\n        self.df[\"float\"].astype(pd.DatetimeTZDtype(tz=\"US/Pacific\"))\r\n\r\n\r\nclass Concat:\r\n    def setup(self):\r\n        N = 10**5\r\n        self.s = pd.Series(list(\"aabbcd\") * N).astype(\"category\")\r\n\r\n        self.a = pd.Categorical(list(\"aabbcd\") * N)\r\n        self.b = pd.Categorical(list(\"bbcdjk\") * N)\r\n\r\n        self.idx_a = pd.CategoricalIndex(range(N), range(N))\r\n        self.idx_b = pd.CategoricalIndex(range(N + 1), range(N + 1))\r\n        self.df_a = pd.DataFrame(range(N), columns=[\"a\"], index=self.idx_a)\r\n        self.df_b = pd.DataFrame(range(N + 1), columns=[\"a\"], index=self.idx_b)\r\n\r\n    def time_concat(self):\r\n        pd.concat([self.s, self.s])\r\n\r\n    def time_union(self):\r\n        union_categoricals([self.a, self.b])\r\n\r\n    def time_append_overlapping_index(self):\r\n        self.idx_a.append(self.idx_a)\r\n\r\n    def time_append_non_overlapping_index(self):\r\n        self.idx_a.append(self.idx_b)\r\n\r\n    def time_concat_overlapping_index(self):\r\n        pd.concat([self.df_a, self.df_a])\r\n\r\n    def time_concat_non_overlapping_index(self):\r\n        pd.concat([self.df_a, self.df_b])\r\n\r\n\r\nclass ValueCounts:\r\n    params = [True, False]\r\n    param_names = [\"dropna\"]\r\n\r\n    def setup(self, dropna):\r\n        n = 5 * 10**5\r\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\r\n        self.ts = pd.Series(arr).astype(\"category\")\r\n\r\n    def time_value_counts(self, dropna):\r\n        self.ts.value_counts(dropna=dropna)\r\n\r\n\r\nclass Repr:\r\n    def setup(self):\r\n        self.sel = pd.Series([\"s1234\"]).astype(\"category\")\r\n\r\n    def time_rendering(self):\r\n        str(self.sel)\r\n\r\n\r\nclass SetCategories:\r\n    def setup(self):\r\n        n = 5 * 10**5\r\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\r\n        self.ts = pd.Series(arr).astype(\"category\")\r\n\r\n    def time_set_categories(self):\r\n        self.ts.cat.set_categories(self.ts.cat.categories[::2])\r\n\r\n\r\nclass RemoveCategories:\r\n    def setup(self):\r\n        n = 5 * 10**5\r\n        arr = [f\"s{i:04d}\" for i in np.random.randint(0, n // 10, size=n)]\r\n        self.ts = pd.Series(arr).astype(\"category\")\r\n\r\n    def time_remove_categories(self):\r\n        self.ts.cat.remove_categories(self.ts.cat.categories[::2])\r\n\r\n\r\nclass Rank:\r\n    def setup(self):\r\n        N = 10**5\r\n        ncats = 15\r\n\r\n        self.s_str = pd.Series(np.random.randint(0, ncats, size=N).astype(str))\r\n        self.s_str_cat = pd.Series(self.s_str, dtype=\"category\")\r\n        with warnings.catch_warnings(record=True):\r\n            str_cat_type = pd.CategoricalDtype(set(self.s_str), ordered=True)\r\n            self.s_str_cat_ordered = self.s_str.astype(str_cat_type)\r\n\r\n        self.s_int = pd.Series(np.random.randint(0, ncats, size=N))\r\n        self.s_int_cat = pd.Series(self.s_int, dtype=\"category\")\r\n        with warnings.catch_warnings(record=True):\r\n            int_cat_type = pd.CategoricalDtype(set(self.s_int), ordered=True)\r\n            self.s_int_cat_ordered = self.s_int.astype(int_cat_type)\r\n"]
[115.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[115.002, "i", "sed -n '1,200p' benchmarks/period.py\r"]
[115.004, "o", "sed -n '1,200p' benchmarks/period.py\r\n"]
[115.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nPeriod benchmarks with non-tslibs dependencies.  See\r\nbenchmarks.tslibs.period for benchmarks that rely only on tslibs.\r\n\"\"\"\r\n\r\nfrom pandas import (\r\n    DataFrame,\r\n    Period,\r\n    PeriodIndex,\r\n    Series,\r\n    date_range,\r\n    period_range,\r\n)\r\n\r\nfrom pandas.tseries.frequencies import to_offset\r\n\r\n\r\nclass PeriodIndexConstructor:\r\n    params = [[\"D\"], [True, False]]\r\n    param_names = [\"freq\", \"is_offset\"]\r\n\r\n    def setup(self, freq, is_offset):\r\n        self.rng = date_range(\"1985\", periods=1000)\r\n        self.rng2 = date_range(\"1985\", periods=1000).to_pydatetime()\r\n        self.ints = list(range(2000, 3000))\r\n        self.daily_ints = (\r\n            date_range(\"1/1/2000\", periods=1000, freq=freq).strftime(\"%Y%m%d\").map(int)\r\n        )\r\n        if is_offset:\r\n            self.freq = to_offset(freq)\r\n        else:\r\n            self.freq = freq\r\n\r\n    def time_from_date_range(self, freq, is_offset):\r\n        PeriodIndex(self.rng, freq=freq)\r\n\r\n    def time_from_pydatetime(self, freq, is_offset):\r\n        PeriodIndex(self.rng2, freq=freq)\r\n\r\n    def time_from_ints(self, freq, is_offset):\r\n        PeriodIndex(self.ints, freq=freq)\r\n\r\n    def time_from_ints_daily(self, freq, is_offset):\r\n        PeriodIndex(self.daily_ints, freq=freq)\r\n\r\n\r\nclass DataFramePeriodColumn:\r\n    def setup(self):\r\n        self.rng = period_range(start=\"1/1/1990\", freq=\"s\", periods=20000)\r\n        self.df = DataFrame(index=range(len(self.rng)))\r\n\r\n    def time_setitem_period_column(self):\r\n        self.df[\"col\"] = self.rng\r\n\r\n    def time_set_index(self):\r\n        # GH#21582 limited by comparisons of Period objects\r\n        self.df[\"col2\"] = self.rng\r\n        self.df.set_index(\"col2\", append=True)\r\n\r\n\r\nclass Algorithms:\r\n    params = [\"index\", \"series\"]\r\n    param_names = [\"typ\"]\r\n\r\n    def setup(self, typ):\r\n        data = [\r\n            Period(\"2011-01\", freq=\"M\"),\r\n            Period(\"2011-02\", freq=\"M\"),\r\n            Period(\"2011-03\", freq=\"M\"),\r\n            Period(\"2011-04\", freq=\"M\"),\r\n        ]\r\n\r\n        if typ == \"index\":\r\n            self.vector = PeriodIndex(data * 1000, freq=\"M\")\r\n        elif typ == \"series\":\r\n            self.vector = Series(data * 1000)\r\n\r\n    def time_drop_duplicates(self, typ):\r\n        self.vector.drop_duplicates()\r\n\r\n    def time_value_counts(self, typ):\r\n        self.vector.value_counts()\r\n\r\n\r\nclass Indexing:\r\n    def setup(self):\r\n        self.index = period_range(start=\"1985\", periods=1000, freq=\"D\")\r\n        self.series = Series(range(1000), index=self.index)\r\n        self.period = self.index[500]\r\n\r\n    def time_get_loc(self):\r\n        self.index.get_loc(self.period)\r\n\r\n    def time_shallow_copy(self):\r\n        self.index._view()\r\n\r\n    def time_series_loc(self):\r\n        self.series.loc[self.period]\r\n\r\n    def time_align(self):\r\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\r\n\r\n    def time_intersection(self):\r\n        self.index[:750].intersection(self.index[250:])\r\n\r\n    def time_unique(self):\r\n        self.index.unique()\r\n"]
[120.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[120.002, "i", "sed -n '1,200p' benchmarks/timedelta.py\r"]
[120.004, "o", "sed -n '1,200p' benchmarks/timedelta.py\r\n"]
[120.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nTimedelta benchmarks with non-tslibs dependencies.  See\r\nbenchmarks.tslibs.timedelta for benchmarks that rely only on tslibs.\r\n\"\"\"\r\n\r\nfrom pandas import (\r\n    DataFrame,\r\n    Series,\r\n    timedelta_range,\r\n)\r\n\r\n\r\nclass DatetimeAccessor:\r\n    def setup_cache(self):\r\n        N = 100000\r\n        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\r\n        return series\r\n\r\n    def time_dt_accessor(self, series):\r\n        series.dt\r\n\r\n    def time_timedelta_days(self, series):\r\n        series.dt.days\r\n\r\n    def time_timedelta_seconds(self, series):\r\n        series.dt.seconds\r\n\r\n    def time_timedelta_microseconds(self, series):\r\n        series.dt.microseconds\r\n\r\n    def time_timedelta_nanoseconds(self, series):\r\n        series.dt.nanoseconds\r\n\r\n\r\nclass TimedeltaIndexing:\r\n    def setup(self):\r\n        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\r\n        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\r\n        self.series = Series(range(1000), index=self.index)\r\n        self.timedelta = self.index[500]\r\n\r\n    def time_get_loc(self):\r\n        self.index.get_loc(self.timedelta)\r\n\r\n    def time_shallow_copy(self):\r\n        self.index._view()\r\n\r\n    def time_series_loc(self):\r\n        self.series.loc[self.timedelta]\r\n\r\n    def time_align(self):\r\n        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\r\n\r\n    def time_intersection(self):\r\n        self.index.intersection(self.index2)\r\n\r\n    def time_union(self):\r\n        self.index.union(self.index2)\r\n\r\n    def time_unique(self):\r\n        self.index.unique()\r\n"]
[125.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[125.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_mask_bool\r"]
[125.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_mask_bool\r\n"]
[125.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;31m'frame_methods.MaskBool.time_mask_bool' benchmark not found\u001b[0m\r\n"]
[130.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[130.002, "i", "nl -ba benchmarks/frame_methods.py | sed -n '320,520p'\r"]
[130.004, "o", "nl -ba benchmarks/frame_methods.py | sed -n '320,520p'\r\n"]
[130.006, "o", "\u001b[?2004l\r\n   320\t                date_range(\"1970-01-01\", periods=N, freq=\"ms\"),\r\n   321\t            ]\r\n   322\t        )\r\n   323\t        self.df = DataFrame(data)\r\n   324\t        self.df_mi = DataFrame(data, index=mi)\r\n   325\t\r\n   326\t    def time_to_records(self):\r\n   327\t        self.df.to_records(index=True)\r\n   328\t\r\n   329\t    def time_to_records_multiindex(self):\r\n   330\t        self.df_mi.to_records(index=True)\r\n   331\t\r\n   332\t\r\n   333\tclass Repr:\r\n   334\t    def setup(self):\r\n   335\t        nrows = 10000\r\n   336\t        data = np.random.randn(nrows, 10)\r\n   337\t        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\r\n   338\t        idx = MultiIndex.from_arrays(arrays)\r\n   339\t        self.df3 = DataFrame(data, index=idx)\r\n   340\t        self.df4 = DataFrame(data, index=np.random.randn(nrows))\r\n   341\t        self.df_tall = DataFrame(np.random.randn(nrows, 10))\r\n   342\t        self.df_wide = DataFrame(np.random.randn(10, nrows))\r\n   343\t\r\n   344\t    def time_html_repr_trunc_mi(self):\r\n   345\t        self.df3._repr_html_()\r\n   346\t\r\n   347\t    def time_html_repr_trunc_si(self):\r\n   348\t        self.df4._repr_html_()\r\n   349\t\r\n   350\t    def time_repr_tall(self):\r\n   351\t        repr(self.df_tall)\r\n   352\t\r\n   353\t    def time_frame_repr_wide(self):\r\n   354\t        repr(self.df_wide)\r\n   355\t\r\n   356\t\r\n   357\tclass MaskBool:\r\n   358\t    def setup(self):\r\n   359\t        data = np.random.randn(1000, 500)\r\n   360\t        df = DataFrame(data)\r\n   361\t        df = df.where(df > 0)\r\n   362\t        self.bools = df > 0\r\n   363\t        self.mask = isnull(df)\r\n   364\t\r\n   365\t    def time_frame_mask_bools(self):\r\n   366\t        self.bools.mask(self.mask)\r\n   367\t\r\n   368\t    def time_frame_mask_floats(self):\r\n   369\t        self.bools.astype(float).mask(self.mask)\r\n   370\t\r\n   371\t\r\n   372\tclass Isnull:\r\n   373\t    def setup(self):\r\n   374\t        N = 10**3\r\n   375\t        self.df_no_null = DataFrame(np.random.randn(N, N))\r\n   376\t\r\n   377\t        sample = np.array([np.nan, 1.0])\r\n   378\t        data = np.random.choice(sample, (N, N))\r\n   379\t        self.df = DataFrame(data)\r\n   380\t\r\n   381\t        sample = np.array(list(string.ascii_letters + string.whitespace))\r\n   382\t        data = np.random.choice(sample, (N, N))\r\n   383\t        self.df_strings = DataFrame(data)\r\n   384\t\r\n   385\t        sample = np.array(\r\n   386\t            [\r\n   387\t                NaT,\r\n   388\t                np.nan,\r\n   389\t                None,\r\n   390\t                np.datetime64(\"NaT\"),\r\n   391\t                np.timedelta64(\"NaT\"),\r\n   392\t                0,\r\n   393\t                1,\r\n   394\t                2.0,\r\n   395\t                \"\",\r\n   396\t                \"abcd\",\r\n   397\t            ]\r\n   398\t        )\r\n   399\t        data = np.random.choice(sample, (N, N))\r\n   400\t        self.df_obj = DataFrame(data)\r\n   401\t\r\n   402\t    def time_isnull_floats_no_null(self):\r\n   403\t        isnull(self.df_no_null)\r\n   404\t\r\n   405\t    def time_isnull(self):\r\n   406\t        isnull(self.df)\r\n   407\t\r\n   408\t    def time_isnull_strngs(self):\r\n   409\t        isnull(self.df_strings)\r\n   410\t\r\n   411\t    def time_isnull_obj(self):\r\n   412\t        isnull(self.df_obj)\r\n   413\t\r\n   414\t\r\n   415\tclass Fillna:\r\n   416\t    params = (\r\n   417\t        [True, False],\r\n   418\t        [\r\n   419\t            \"float64\",\r\n   420\t            \"float32\",\r\n   421\t            \"object\",\r\n   422\t            \"Int64\",\r\n   423\t            \"Float64\",\r\n   424\t            \"datetime64[ns]\",\r\n   425\t            \"datetime64[ns, tz]\",\r\n   426\t            \"timedelta64[ns]\",\r\n   427\t        ],\r\n   428\t    )\r\n   429\t    param_names = [\"inplace\", \"dtype\"]\r\n   430\t\r\n   431\t    def setup(self, inplace, dtype):\r\n   432\t        N, M = 10000, 100\r\n   433\t        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\r\n   434\t            data = {\r\n   435\t                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"h\", periods=N),\r\n   436\t                \"datetime64[ns, tz]\": date_range(\r\n   437\t                    \"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\"\r\n   438\t                ),\r\n   439\t                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\r\n   440\t            }\r\n   441\t            self.df = DataFrame({f\"col_{i}\": data[dtype] for i in range(M)})\r\n   442\t            self.df[::2] = None\r\n   443\t        else:\r\n   444\t            values = np.random.randn(N, M)\r\n   445\t            values[::2] = np.nan\r\n   446\t            if dtype == \"Int64\":\r\n   447\t                values = values.round()\r\n   448\t            self.df = DataFrame(values, dtype=dtype)\r\n   449\t        self.fill_values = self.df.iloc[self.df.first_valid_index()].to_dict()\r\n   450\t\r\n   451\t    def time_fillna(self, inplace, dtype):\r\n   452\t        self.df.fillna(value=self.fill_values, inplace=inplace)\r\n   453\t\r\n   454\t    def time_ffill(self, inplace, dtype):\r\n   455\t        self.df.ffill(inplace=inplace)\r\n   456\t\r\n   457\t    def time_bfill(self, inplace, dtype):\r\n   458\t        self.df.bfill(inplace=inplace)\r\n   459\t\r\n   460\t\r\n   461\tclass Dropna:\r\n   462\t    params = ([\"all\", \"any\"], [0, 1])\r\n   463\t    param_names = [\"how\", \"axis\"]\r\n   464\t\r\n   465\t    def setup(self, how, axis):\r\n   466\t        self.df = DataFrame(np.random.randn(10000, 1000))\r\n   467\t        self.df.iloc[50:1000, 20:50] = np.nan\r\n   468\t        self.df.iloc[2000:3000] = np.nan\r\n   469\t        self.df.iloc[:, 60:70] = np.nan\r\n   470\t        self.df_mixed = self.df.copy()\r\n   471\t        self.df_mixed[\"foo\"] = \"bar\"\r\n   472\t\r\n   473\t    def time_dropna(self, how, axis):\r\n   474\t        self.df.dropna(how=how, axis=axis)\r\n   475\t\r\n   476\t    def time_dropna_axis_mixed_dtypes(self, how, axis):\r\n   477\t        self.df_mixed.dropna(how=how, axis=axis)\r\n   478\t\r\n   479\t\r\n   480\tclass Isna:\r\n   481\t    params = [\"float64\", \"Float64\", \"float64[pyarrow]\"]\r\n   482\t    param_names = [\"dtype\"]\r\n   483\t\r\n   484\t    def setup(self, dtype):\r\n   485\t        data = np.random.randn(10000, 1000)\r\n   486\t        # all-na columns\r\n   487\t        data[:, 600:800] = np.nan\r\n   488\t        # partial-na columns\r\n   489\t        data[800:1000, 4000:5000] = np.nan\r\n   490\t        self.df = DataFrame(data, dtype=dtype)\r\n   491\t\r\n   492\t    def time_isna(self, dtype):\r\n   493\t        self.df.isna()\r\n   494\t\r\n   495\t\r\n   496\tclass Count:\r\n   497\t    params = [0, 1]\r\n   498\t    param_names = [\"axis\"]\r\n   499\t\r\n   500\t    def setup(self, axis):\r\n   501\t        self.df = DataFrame(np.random.randn(10000, 1000))\r\n   502\t        self.df.iloc[50:1000, 20:50] = np.nan\r\n   503\t        self.df.iloc[2000:3000] = np.nan\r\n   504\t        self.df.iloc[:, 60:70] = np.nan\r\n   505\t        self.df_mixed = self.df.copy()\r\n   506\t        self.df_mixed[\"foo\"] = \"bar\"\r\n   507\t\r\n   508\t    def time_count(self, axis):\r\n   509\t        self.df.count(axis=axis)\r\n   510\t\r\n   511\t    def time_count_mixed_dtypes(self, axis):\r\n   512\t        self.df_mixed.count(axis=axis)\r\n   513\t\r\n   514\t\r\n   515\tclass Apply:\r\n   516\t    def setup(self):\r\n   517\t        self.df = DataFrame(np.random.randn(1000, 100))\r\n   518\t\r\n   519\t        self.s = Series(np.arange(1028.0))\r\n   520\t        self.df2 = DataFrame({i: self.s for i in range(1028)})\r\n"]
[135.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[135.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[135.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[135.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              55.3\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             4.24\u00b10ms\r\n"]
[140.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[140.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool\r"]
[140.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool\r\n"]
[140.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;31m'frame_methods.MaskBool' benchmark not found\u001b[0m\r\n"]
[145.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[145.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r"]
[145.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r\n"]
[145.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (frame_methods.MaskBool.time_frame_mask_bools--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                            47.3\u00b10.1ms\r\n\r\nWed Oct  1 17:06:17 2025    /tmp/tmpc6rmvzct\r\n\r\n         83260 function calls (82244 primitive calls) in 0.139 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.139    0.139 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.139    0.139 _base.py:689(method_caller)\r\n        1    0.005    0.005    0.139    0.139 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.134    0.134 generic.py:10068(mask)\r\n        1    0.000    0.000    0.134    0.134 generic.py:9685(_where)\r\n        7    0.000    0.000    0.132    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.132    0.132 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.132    0.132 blocks.py:1211(where)\r\n      500    0.001    0.000    0.088    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.068    0.000 common.py:702(is_integer_dtype)\r\n      500    0.065    0.000    0.065    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.002    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.001    0.000    0.004    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n      500    0.000    0.000    0.003    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.002    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.001    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55ff37dad640}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[150.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[150.002, "i", "cd ..\r"]
[150.004, "o", "cd ..\r\n"]
[150.006, "o", "\u001b[?2004l\r\n"]
[155.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[155.002, "i", "grep -R \"def mask\\(\" -n pandas/core | head -n 20\r"]
[155.004, "o", "grep -R \"def mask\\(\" -n pandas/core | head -n 20\r\n"]
[155.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[160.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[160.002, "i", "grep -R \"def where\\(\" -n pandas/core | head -n 30\r"]
[160.004, "o", "grep -R \"def where\\(\" -n pandas/core | head -n 30\r\n"]
[160.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[165.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[165.002, "i", "sed -n '1,240p' pandas/core/generic.py\r"]
[165.004, "o", "sed -n '1,240p' pandas/core/generic.py\r\n"]
[165.006, "o", "\u001b[?2004l\r\n# pyright: reportPropertyTypeMismatch=false\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom copy import deepcopy\r\nimport datetime as dt\r\nfrom functools import partial\r\nfrom json import loads\r\nimport operator\r\nimport pickle\r\nimport re\r\nimport sys\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    ClassVar,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import config\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas._libs.tslibs import (\r\n    Period,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    AlignJoin,\r\n    AnyArrayLike,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    AxisInt,\r\n    CompressionOptions,\r\n    Concatenate,\r\n    DtypeArg,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FilePath,\r\n    FillnaOptions,\r\n    FloatFormatType,\r\n    FormattersType,\r\n    Frequency,\r\n    IgnoreRaise,\r\n    IndexKeyFunc,\r\n    IndexLabel,\r\n    InterpolateOptions,\r\n    IntervalClosedType,\r\n    JSONSerializable,\r\n    Level,\r\n    ListLike,\r\n    Manager,\r\n    NaPosition,\r\n    NDFrameT,\r\n    OpenFileErrors,\r\n    RandomState,\r\n    ReindexMethod,\r\n    Renamer,\r\n    Scalar,\r\n    Self,\r\n    SequenceNotStr,\r\n    SortKind,\r\n    StorageOptions,\r\n    Suffixes,\r\n    T,\r\n    TimeAmbiguous,\r\n    TimedeltaConvertibleTypes,\r\n    TimeNonexistent,\r\n    TimestampConvertibleTypes,\r\n    TimeUnit,\r\n    ValueKeyFunc,\r\n    WriteBuffer,\r\n    WriteExcelBuffer,\r\n    npt,\r\n)\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import _chained_assignment_method_msg\r\nfrom pandas.util._decorators import (\r\n    deprecate_kwarg,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import (\r\n    check_dtype_backend,\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_inclusive,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_is_view\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    ensure_str,\r\n    is_bool,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_extension_array_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_numeric_dtype,\r\n    is_re_compilable,\r\n    is_scalar,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import (\r\n    is_hashable,\r\n    is_nested_list_like,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms as algos,\r\n    arraylike,\r\n    common,\r\n    indexing,\r\n    missing,\r\n    nanops,\r\n    sample,\r\n)\r\nfrom pandas.core.array_algos.replace import should_use_regex\r\nfrom pandas.core.arrays import ExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import extract_array\r\nfrom pandas.core.flags import Flags\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    MultiIndex,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.methods.describe import describe_ndframe\r\nfrom pandas.core.missing import (\r\n    clean_fill_method,\r\n    clean_reindex_fill_method,\r\n    find_valid_index,\r\n)\r\nfrom pandas.core.reshape.concat import concat\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import get_indexer_indexer\r\nfrom pandas.core.window import (\r\n    Expanding,\r\n    ExponentialMovingWindow,\r\n    Rolling,\r\n    Window,\r\n)\r\n\r\nfrom pandas.io.formats.format import (\r\n    DataFrameFormatter,\r\n    DataFrameRenderer,\r\n)\r\nfrom pandas.io.formats.printing import pprint_thing\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Callable\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterator,\r\n        Mapping,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._libs.tslibs import BaseOffset\r\n    from pandas._typing import P\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        ExcelWriter,\r\n        HDFStore,\r\n        Series,\r\n    )\r\n    from pandas.core.indexers.objects import BaseIndexer\r\n    from pandas.core.resample import Resampler\r\n\r\nimport textwrap\r\n\r\n# goal is to be able to define the docs close to function, while still being\r\n# able to share\r\n_shared_docs = {**_shared_docs}\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"keywords for axes\",\r\n    \"klass\": \"Series/DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\",  # noqa: E501\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        If True, performs operation inplace and returns None.\"\"\",\r\n    \"optional_by\": \"\"\"\r\n        by : str or list of str\r\n            Name or list of names to sort by\"\"\",\r\n}\r\n\r\n\r\nclass NDFrame(PandasObject, indexing.IndexingMixin):\r\n    \"\"\"\r\n    N-dimensional analogue of DataFrame. Store multi-dimensional in a\r\n    size-mutable, labeled data structure\r\n\r\n    Parameters\r\n    ----------\r\n    data : BlockManager\r\n    axes : list\r\n    copy : bool, default False\r\n    \"\"\"\r\n\r\n    _internal_names: list[str] = [\r\n        \"_mgr\",\r\n        \"_item_cache\",\r\n        \"_cache\",\r\n"]
[170.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[170.002, "i", "sed -n '1,260p' pandas/core/frame.py\r"]
[170.004, "o", "sed -n '1,260p' pandas/core/frame.py\r\n"]
[170.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nDataFrame\r\n---------\r\nAn efficient 2D container for potentially mixed-type time series or other\r\nlabeled data series.\r\n\r\nSimilar to its R counterpart, data.frame, except providing automatic data\r\nalignment and a host of useful data manipulation methods having to do with the\r\nlabeling information\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom collections import abc\r\nfrom collections.abc import (\r\n    Callable,\r\n    Hashable,\r\n    Iterable,\r\n    Iterator,\r\n    Mapping,\r\n    Sequence,\r\n)\r\nimport functools\r\nfrom io import StringIO\r\nimport itertools\r\nimport operator\r\nimport sys\r\nfrom textwrap import dedent\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\nfrom numpy import ma\r\n\r\nfrom pandas._config import get_option\r\n\r\nfrom pandas._libs import (\r\n    algos as libalgos,\r\n    lib,\r\n    properties,\r\n)\r\nfrom pandas._libs.hashtable import duplicated\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import (\r\n    _chained_assignment_method_msg,\r\n    _chained_assignment_msg,\r\n)\r\nfrom pandas.util._decorators import (\r\n    Appender,\r\n    Substitution,\r\n    deprecate_nonkeyword_arguments,\r\n    doc,\r\n    set_module,\r\n)\r\nfrom pandas.util._exceptions import (\r\n    find_stack_level,\r\n    rewrite_warning,\r\n)\r\nfrom pandas.util._validators import (\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_percentile,\r\n)\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    construct_1d_arraylike_from_scalar,\r\n    construct_2d_arraylike_from_scalar,\r\n    find_common_type,\r\n    infer_dtype_from_scalar,\r\n    invalidate_string_dtypes,\r\n    maybe_downcast_to_dtype,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    infer_dtype_from_object,\r\n    is_1d_only_ea_dtype,\r\n    is_array_like,\r\n    is_bool_dtype,\r\n    is_dataclass,\r\n    is_dict_like,\r\n    is_float,\r\n    is_float_dtype,\r\n    is_hashable,\r\n    is_integer,\r\n    is_integer_dtype,\r\n    is_iterator,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_sequence,\r\n    needs_i8_conversion,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.concat import concat_compat\r\nfrom pandas.core.dtypes.dtypes import (\r\n    ArrowDtype,\r\n    BaseMaskedDtype,\r\n    ExtensionDtype,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms,\r\n    common as com,\r\n    nanops,\r\n    ops,\r\n    roperator,\r\n)\r\nfrom pandas.core.accessor import Accessor\r\nfrom pandas.core.apply import reconstruct_and_relabel_result\r\nfrom pandas.core.array_algos.take import take_2d_multi\r\nfrom pandas.core.arraylike import OpsMixin\r\nfrom pandas.core.arrays import (\r\n    BaseMaskedArray,\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.sparse import SparseFrameAccessor\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    sanitize_array,\r\n    sanitize_masked_array,\r\n)\r\nfrom pandas.core.generic import (\r\n    NDFrame,\r\n    make_doc,\r\n)\r\nfrom pandas.core.indexers import check_key_length\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n    ensure_index_from_sequences,\r\n)\r\nfrom pandas.core.indexes.multi import (\r\n    MultiIndex,\r\n    maybe_droplevels,\r\n)\r\nfrom pandas.core.indexing import (\r\n    check_bool_indexer,\r\n    check_dict_or_set_indexers,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.internals.construction import (\r\n    arrays_to_mgr,\r\n    dataclasses_to_dicts,\r\n    dict_to_mgr,\r\n    ndarray_to_mgr,\r\n    nested_data_to_arrays,\r\n    rec_array_to_mgr,\r\n    reorder_arrays,\r\n    to_arrays,\r\n    treat_as_nested,\r\n)\r\nfrom pandas.core.methods import selectn\r\nfrom pandas.core.reshape.melt import melt\r\nfrom pandas.core.series import Series\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import (\r\n    get_group_index,\r\n    lexsort_indexer,\r\n    nargsort,\r\n)\r\n\r\nfrom pandas.io.common import get_handle\r\nfrom pandas.io.formats import (\r\n    console,\r\n    format as fmt,\r\n)\r\nfrom pandas.io.formats.info import (\r\n    INFO_DOCSTRING,\r\n    DataFrameInfo,\r\n    frame_sub_kwargs,\r\n)\r\nimport pandas.plotting\r\n\r\nif TYPE_CHECKING:\r\n    import datetime\r\n\r\n    from pandas._libs.internals import BlockValuesRefs\r\n    from pandas._typing import (\r\n        AggFuncType,\r\n        AnyAll,\r\n        AnyArrayLike,\r\n        ArrayLike,\r\n        Axes,\r\n        Axis,\r\n        AxisInt,\r\n        ColspaceArgType,\r\n        CompressionOptions,\r\n        CorrelationMethod,\r\n        DropKeep,\r\n        Dtype,\r\n        DtypeObj,\r\n        FilePath,\r\n        FloatFormatType,\r\n        FormattersType,\r\n        Frequency,\r\n        FromDictOrient,\r\n        HashableT,\r\n        HashableT2,\r\n        IgnoreRaise,\r\n        IndexKeyFunc,\r\n        IndexLabel,\r\n        JoinValidate,\r\n        Level,\r\n        ListLike,\r\n        MergeHow,\r\n        MergeValidate,\r\n        MutableMappingT,\r\n        NaPosition,\r\n        NsmallestNlargestKeep,\r\n        PythonFuncType,\r\n        QuantileInterpolation,\r\n        ReadBuffer,\r\n        ReindexMethod,\r\n        Renamer,\r\n        Scalar,\r\n        Self,\r\n        SequenceNotStr,\r\n        SortKind,\r\n        StorageOptions,\r\n        Suffixes,\r\n        T,\r\n        ToStataByteorder,\r\n        ToTimestampHow,\r\n        UpdateJoin,\r\n        ValueKeyFunc,\r\n        WriteBuffer,\r\n        XMLParsers,\r\n        npt,\r\n    )\r\n\r\n    from pandas.core.groupby.generic import DataFrameGroupBy\r\n    from pandas.core.interchange.dataframe_protocol import DataFrame as DataFrameXchg\r\n    from pandas.core.internals.managers import SingleBlockManager\r\n\r\n    from pandas.io.formats.style import Styler\r\n"]
[175.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[175.002, "i", "cd asv_bench\r"]
[175.004, "o", "cd asv_bench\r\n"]
[175.006, "o", "\u001b[?2004l\r\n"]
[180.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[180.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r"]
[180.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r\n"]
[180.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (frame_methods.MaskBool.time_frame_mask_bools--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                            47.5\u00b10.2ms\r\n\r\nWed Oct  1 17:07:56 2025    /tmp/tmpesuuqs60\r\n\r\n         83260 function calls (82244 primitive calls) in 0.139 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.139    0.139 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.139    0.139 _base.py:689(method_caller)\r\n        1    0.005    0.005    0.139    0.139 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.134    0.134 generic.py:10068(mask)\r\n        1    0.000    0.000    0.134    0.134 generic.py:9685(_where)\r\n        7    0.000    0.000    0.132    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.132    0.132 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.132    0.132 blocks.py:1211(where)\r\n      500    0.001    0.000    0.088    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.068    0.000 common.py:702(is_integer_dtype)\r\n      500    0.066    0.000    0.066    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.002    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.003    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.001    0.000    0.003    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n     1001    0.001    0.000    0.001    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55aeadaf7640}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[185.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[185.002, "i", "cd ..\r"]
[185.004, "o", "cd ..\r\n"]
[185.006, "o", "\u001b[?2004l\r\n"]
[190.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[190.002, "i", "grep -R \"def mask\\(\" -n pandas/core | head -n 20\r"]
[190.004, "o", "grep -R \"def mask\\(\" -n pandas/core | head -n 20\r\n"]
[190.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[195.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[195.002, "i", "grep -R \"def where\\(\" -n pandas/core | head -n 30\r"]
[195.004, "o", "grep -R \"def where\\(\" -n pandas/core | head -n 30\r\n"]
[195.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[200.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[200.002, "i", "sed -n '1,260p' pandas/core/generic.py\r"]
[200.004, "o", "sed -n '1,260p' pandas/core/generic.py\r\n"]
[200.006, "o", "\u001b[?2004l\r\n# pyright: reportPropertyTypeMismatch=false\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom copy import deepcopy\r\nimport datetime as dt\r\nfrom functools import partial\r\nfrom json import loads\r\nimport operator\r\nimport pickle\r\nimport re\r\nimport sys\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    ClassVar,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import config\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas._libs.tslibs import (\r\n    Period,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    AlignJoin,\r\n    AnyArrayLike,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    AxisInt,\r\n    CompressionOptions,\r\n    Concatenate,\r\n    DtypeArg,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FilePath,\r\n    FillnaOptions,\r\n    FloatFormatType,\r\n    FormattersType,\r\n    Frequency,\r\n    IgnoreRaise,\r\n    IndexKeyFunc,\r\n    IndexLabel,\r\n    InterpolateOptions,\r\n    IntervalClosedType,\r\n    JSONSerializable,\r\n    Level,\r\n    ListLike,\r\n    Manager,\r\n    NaPosition,\r\n    NDFrameT,\r\n    OpenFileErrors,\r\n    RandomState,\r\n    ReindexMethod,\r\n    Renamer,\r\n    Scalar,\r\n    Self,\r\n    SequenceNotStr,\r\n    SortKind,\r\n    StorageOptions,\r\n    Suffixes,\r\n    T,\r\n    TimeAmbiguous,\r\n    TimedeltaConvertibleTypes,\r\n    TimeNonexistent,\r\n    TimestampConvertibleTypes,\r\n    TimeUnit,\r\n    ValueKeyFunc,\r\n    WriteBuffer,\r\n    WriteExcelBuffer,\r\n    npt,\r\n)\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import _chained_assignment_method_msg\r\nfrom pandas.util._decorators import (\r\n    deprecate_kwarg,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import (\r\n    check_dtype_backend,\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_inclusive,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_is_view\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    ensure_str,\r\n    is_bool,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_extension_array_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_numeric_dtype,\r\n    is_re_compilable,\r\n    is_scalar,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import (\r\n    is_hashable,\r\n    is_nested_list_like,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms as algos,\r\n    arraylike,\r\n    common,\r\n    indexing,\r\n    missing,\r\n    nanops,\r\n    sample,\r\n)\r\nfrom pandas.core.array_algos.replace import should_use_regex\r\nfrom pandas.core.arrays import ExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import extract_array\r\nfrom pandas.core.flags import Flags\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    MultiIndex,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.methods.describe import describe_ndframe\r\nfrom pandas.core.missing import (\r\n    clean_fill_method,\r\n    clean_reindex_fill_method,\r\n    find_valid_index,\r\n)\r\nfrom pandas.core.reshape.concat import concat\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import get_indexer_indexer\r\nfrom pandas.core.window import (\r\n    Expanding,\r\n    ExponentialMovingWindow,\r\n    Rolling,\r\n    Window,\r\n)\r\n\r\nfrom pandas.io.formats.format import (\r\n    DataFrameFormatter,\r\n    DataFrameRenderer,\r\n)\r\nfrom pandas.io.formats.printing import pprint_thing\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Callable\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterator,\r\n        Mapping,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._libs.tslibs import BaseOffset\r\n    from pandas._typing import P\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        ExcelWriter,\r\n        HDFStore,\r\n        Series,\r\n    )\r\n    from pandas.core.indexers.objects import BaseIndexer\r\n    from pandas.core.resample import Resampler\r\n\r\nimport textwrap\r\n\r\n# goal is to be able to define the docs close to function, while still being\r\n# able to share\r\n_shared_docs = {**_shared_docs}\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"keywords for axes\",\r\n    \"klass\": \"Series/DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\",  # noqa: E501\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        If True, performs operation inplace and returns None.\"\"\",\r\n    \"optional_by\": \"\"\"\r\n        by : str or list of str\r\n            Name or list of names to sort by\"\"\",\r\n}\r\n\r\n\r\nclass NDFrame(PandasObject, indexing.IndexingMixin):\r\n    \"\"\"\r\n    N-dimensional analogue of DataFrame. Store multi-dimensional in a\r\n    size-mutable, labeled data structure\r\n\r\n    Parameters\r\n    ----------\r\n    data : BlockManager\r\n    axes : list\r\n    copy : bool, default False\r\n    \"\"\"\r\n\r\n    _internal_names: list[str] = [\r\n        \"_mgr\",\r\n        \"_item_cache\",\r\n        \"_cache\",\r\n        \"_name\",\r\n        \"_metadata\",\r\n        \"_flags\",\r\n    ]\r\n    _internal_names_set: set[str] = set(_internal_names)\r\n    _accessors: set[str] = set()\r\n    _hidden_attrs: frozenset[str] = frozenset([])\r\n    _metadata: list[str] = []\r\n    _mgr: Manager\r\n    _attrs: dict[Hashable, Any]\r\n    _typ: str\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __init__(self, data: Manager) -> None:\r\n        object.__setattr__(self, \"_mgr\", data)\r\n        object.__setattr__(self, \"_attrs\", {})\r\n        object.__setattr__(self, \"_flags\", Flags(self, allows_duplicate_labels=True))\r\n\r\n"]
[205.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[205.002, "i", "sed -n '1,260p' pandas/core/frame.py\r"]
[205.004, "o", "sed -n '1,260p' pandas/core/frame.py\r\n"]
[205.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nDataFrame\r\n---------\r\nAn efficient 2D container for potentially mixed-type time series or other\r\nlabeled data series.\r\n\r\nSimilar to its R counterpart, data.frame, except providing automatic data\r\nalignment and a host of useful data manipulation methods having to do with the\r\nlabeling information\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom collections import abc\r\nfrom collections.abc import (\r\n    Callable,\r\n    Hashable,\r\n    Iterable,\r\n    Iterator,\r\n    Mapping,\r\n    Sequence,\r\n)\r\nimport functools\r\nfrom io import StringIO\r\nimport itertools\r\nimport operator\r\nimport sys\r\nfrom textwrap import dedent\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\nfrom numpy import ma\r\n\r\nfrom pandas._config import get_option\r\n\r\nfrom pandas._libs import (\r\n    algos as libalgos,\r\n    lib,\r\n    properties,\r\n)\r\nfrom pandas._libs.hashtable import duplicated\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import (\r\n    _chained_assignment_method_msg,\r\n    _chained_assignment_msg,\r\n)\r\nfrom pandas.util._decorators import (\r\n    Appender,\r\n    Substitution,\r\n    deprecate_nonkeyword_arguments,\r\n    doc,\r\n    set_module,\r\n)\r\nfrom pandas.util._exceptions import (\r\n    find_stack_level,\r\n    rewrite_warning,\r\n)\r\nfrom pandas.util._validators import (\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_percentile,\r\n)\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    construct_1d_arraylike_from_scalar,\r\n    construct_2d_arraylike_from_scalar,\r\n    find_common_type,\r\n    infer_dtype_from_scalar,\r\n    invalidate_string_dtypes,\r\n    maybe_downcast_to_dtype,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    infer_dtype_from_object,\r\n    is_1d_only_ea_dtype,\r\n    is_array_like,\r\n    is_bool_dtype,\r\n    is_dataclass,\r\n    is_dict_like,\r\n    is_float,\r\n    is_float_dtype,\r\n    is_hashable,\r\n    is_integer,\r\n    is_integer_dtype,\r\n    is_iterator,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_sequence,\r\n    needs_i8_conversion,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.concat import concat_compat\r\nfrom pandas.core.dtypes.dtypes import (\r\n    ArrowDtype,\r\n    BaseMaskedDtype,\r\n    ExtensionDtype,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms,\r\n    common as com,\r\n    nanops,\r\n    ops,\r\n    roperator,\r\n)\r\nfrom pandas.core.accessor import Accessor\r\nfrom pandas.core.apply import reconstruct_and_relabel_result\r\nfrom pandas.core.array_algos.take import take_2d_multi\r\nfrom pandas.core.arraylike import OpsMixin\r\nfrom pandas.core.arrays import (\r\n    BaseMaskedArray,\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.sparse import SparseFrameAccessor\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    sanitize_array,\r\n    sanitize_masked_array,\r\n)\r\nfrom pandas.core.generic import (\r\n    NDFrame,\r\n    make_doc,\r\n)\r\nfrom pandas.core.indexers import check_key_length\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n    ensure_index_from_sequences,\r\n)\r\nfrom pandas.core.indexes.multi import (\r\n    MultiIndex,\r\n    maybe_droplevels,\r\n)\r\nfrom pandas.core.indexing import (\r\n    check_bool_indexer,\r\n    check_dict_or_set_indexers,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.internals.construction import (\r\n    arrays_to_mgr,\r\n    dataclasses_to_dicts,\r\n    dict_to_mgr,\r\n    ndarray_to_mgr,\r\n    nested_data_to_arrays,\r\n    rec_array_to_mgr,\r\n    reorder_arrays,\r\n    to_arrays,\r\n    treat_as_nested,\r\n)\r\nfrom pandas.core.methods import selectn\r\nfrom pandas.core.reshape.melt import melt\r\nfrom pandas.core.series import Series\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import (\r\n    get_group_index,\r\n    lexsort_indexer,\r\n    nargsort,\r\n)\r\n\r\nfrom pandas.io.common import get_handle\r\nfrom pandas.io.formats import (\r\n    console,\r\n    format as fmt,\r\n)\r\nfrom pandas.io.formats.info import (\r\n    INFO_DOCSTRING,\r\n    DataFrameInfo,\r\n    frame_sub_kwargs,\r\n)\r\nimport pandas.plotting\r\n\r\nif TYPE_CHECKING:\r\n    import datetime\r\n\r\n    from pandas._libs.internals import BlockValuesRefs\r\n    from pandas._typing import (\r\n        AggFuncType,\r\n        AnyAll,\r\n        AnyArrayLike,\r\n        ArrayLike,\r\n        Axes,\r\n        Axis,\r\n        AxisInt,\r\n        ColspaceArgType,\r\n        CompressionOptions,\r\n        CorrelationMethod,\r\n        DropKeep,\r\n        Dtype,\r\n        DtypeObj,\r\n        FilePath,\r\n        FloatFormatType,\r\n        FormattersType,\r\n        Frequency,\r\n        FromDictOrient,\r\n        HashableT,\r\n        HashableT2,\r\n        IgnoreRaise,\r\n        IndexKeyFunc,\r\n        IndexLabel,\r\n        JoinValidate,\r\n        Level,\r\n        ListLike,\r\n        MergeHow,\r\n        MergeValidate,\r\n        MutableMappingT,\r\n        NaPosition,\r\n        NsmallestNlargestKeep,\r\n        PythonFuncType,\r\n        QuantileInterpolation,\r\n        ReadBuffer,\r\n        ReindexMethod,\r\n        Renamer,\r\n        Scalar,\r\n        Self,\r\n        SequenceNotStr,\r\n        SortKind,\r\n        StorageOptions,\r\n        Suffixes,\r\n        T,\r\n        ToStataByteorder,\r\n        ToTimestampHow,\r\n        UpdateJoin,\r\n        ValueKeyFunc,\r\n        WriteBuffer,\r\n        XMLParsers,\r\n        npt,\r\n    )\r\n\r\n    from pandas.core.groupby.generic import DataFrameGroupBy\r\n    from pandas.core.interchange.dataframe_protocol import DataFrame as DataFrameXchg\r\n    from pandas.core.internals.managers import SingleBlockManager\r\n\r\n    from pandas.io.formats.style import Styler\r\n"]
[210.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[210.002, "i", "cd asv_bench\r"]
[210.004, "o", "cd asv_bench\r\n"]
[210.006, "o", "\u001b[?2004l\r\n"]
[215.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[215.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r"]
[215.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r\n"]
[215.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (frame_methods.MaskBool.time_frame_mask_bools--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                            46.9\u00b10.5ms\r\n\r\nWed Oct  1 17:09:37 2025    /tmp/tmpxbc8zmhc\r\n\r\n         83260 function calls (82244 primitive calls) in 0.138 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.138    0.138 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.138    0.138 _base.py:689(method_caller)\r\n        1    0.004    0.004    0.138    0.138 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.134    0.134 generic.py:10068(mask)\r\n        1    0.000    0.000    0.134    0.134 generic.py:9685(_where)\r\n        7    0.000    0.000    0.132    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.132    0.132 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.131    0.131 blocks.py:1211(where)\r\n      500    0.001    0.000    0.087    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.067    0.000 common.py:702(is_integer_dtype)\r\n      500    0.065    0.000    0.065    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.002    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.000    0.000    0.003    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     1001    0.001    0.000    0.001    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:170(is_extension)\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x562bdaa7e640}\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[220.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[220.002, "i", "cd ..\r"]
[220.004, "o", "cd ..\r\n"]
[220.006, "o", "\u001b[?2004l\r\n"]
[225.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[225.002, "i", "grep -R \"def mask\\(\" -n pandas/core | head -n 20\r"]
[225.004, "o", "grep -R \"def mask\\(\" -n pandas/core | head -n 20\r\n"]
[225.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[230.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[230.002, "i", "grep -R \"def where\\(\" -n pandas/core | head -n 30\r"]
[230.004, "o", "grep -R \"def where\\(\" -n pandas/core | head -n 30\r\n"]
[230.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[235.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[235.002, "i", "sed -n '1,320p' pandas/core/generic.py\r"]
[235.004, "o", "sed -n '1,320p' pandas/core/generic.py\r\n"]
[235.006, "o", "\u001b[?2004l\r\n# pyright: reportPropertyTypeMismatch=false\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom copy import deepcopy\r\nimport datetime as dt\r\nfrom functools import partial\r\nfrom json import loads\r\nimport operator\r\nimport pickle\r\nimport re\r\nimport sys\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    ClassVar,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import config\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas._libs.tslibs import (\r\n    Period,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    AlignJoin,\r\n    AnyArrayLike,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    AxisInt,\r\n    CompressionOptions,\r\n    Concatenate,\r\n    DtypeArg,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FilePath,\r\n    FillnaOptions,\r\n    FloatFormatType,\r\n    FormattersType,\r\n    Frequency,\r\n    IgnoreRaise,\r\n    IndexKeyFunc,\r\n    IndexLabel,\r\n    InterpolateOptions,\r\n    IntervalClosedType,\r\n    JSONSerializable,\r\n    Level,\r\n    ListLike,\r\n    Manager,\r\n    NaPosition,\r\n    NDFrameT,\r\n    OpenFileErrors,\r\n    RandomState,\r\n    ReindexMethod,\r\n    Renamer,\r\n    Scalar,\r\n    Self,\r\n    SequenceNotStr,\r\n    SortKind,\r\n    StorageOptions,\r\n    Suffixes,\r\n    T,\r\n    TimeAmbiguous,\r\n    TimedeltaConvertibleTypes,\r\n    TimeNonexistent,\r\n    TimestampConvertibleTypes,\r\n    TimeUnit,\r\n    ValueKeyFunc,\r\n    WriteBuffer,\r\n    WriteExcelBuffer,\r\n    npt,\r\n)\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import _chained_assignment_method_msg\r\nfrom pandas.util._decorators import (\r\n    deprecate_kwarg,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import (\r\n    check_dtype_backend,\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_inclusive,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_is_view\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    ensure_str,\r\n    is_bool,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_extension_array_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_numeric_dtype,\r\n    is_re_compilable,\r\n    is_scalar,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import (\r\n    is_hashable,\r\n    is_nested_list_like,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms as algos,\r\n    arraylike,\r\n    common,\r\n    indexing,\r\n    missing,\r\n    nanops,\r\n    sample,\r\n)\r\nfrom pandas.core.array_algos.replace import should_use_regex\r\nfrom pandas.core.arrays import ExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import extract_array\r\nfrom pandas.core.flags import Flags\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    MultiIndex,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.methods.describe import describe_ndframe\r\nfrom pandas.core.missing import (\r\n    clean_fill_method,\r\n    clean_reindex_fill_method,\r\n    find_valid_index,\r\n)\r\nfrom pandas.core.reshape.concat import concat\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import get_indexer_indexer\r\nfrom pandas.core.window import (\r\n    Expanding,\r\n    ExponentialMovingWindow,\r\n    Rolling,\r\n    Window,\r\n)\r\n\r\nfrom pandas.io.formats.format import (\r\n    DataFrameFormatter,\r\n    DataFrameRenderer,\r\n)\r\nfrom pandas.io.formats.printing import pprint_thing\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Callable\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterator,\r\n        Mapping,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._libs.tslibs import BaseOffset\r\n    from pandas._typing import P\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        ExcelWriter,\r\n        HDFStore,\r\n        Series,\r\n    )\r\n    from pandas.core.indexers.objects import BaseIndexer\r\n    from pandas.core.resample import Resampler\r\n\r\nimport textwrap\r\n\r\n# goal is to be able to define the docs close to function, while still being\r\n# able to share\r\n_shared_docs = {**_shared_docs}\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"keywords for axes\",\r\n    \"klass\": \"Series/DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\",  # noqa: E501\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        If True, performs operation inplace and returns None.\"\"\",\r\n    \"optional_by\": \"\"\"\r\n        by : str or list of str\r\n            Name or list of names to sort by\"\"\",\r\n}\r\n\r\n\r\nclass NDFrame(PandasObject, indexing.IndexingMixin):\r\n    \"\"\"\r\n    N-dimensional analogue of DataFrame. Store multi-dimensional in a\r\n    size-mutable, labeled data structure\r\n\r\n    Parameters\r\n    ----------\r\n    data : BlockManager\r\n    axes : list\r\n    copy : bool, default False\r\n    \"\"\"\r\n\r\n    _internal_names: list[str] = [\r\n        \"_mgr\",\r\n        \"_item_cache\",\r\n        \"_cache\",\r\n        \"_name\",\r\n        \"_metadata\",\r\n        \"_flags\",\r\n    ]\r\n    _internal_names_set: set[str] = set(_internal_names)\r\n    _accessors: set[str] = set()\r\n    _hidden_attrs: frozenset[str] = frozenset([])\r\n    _metadata: list[str] = []\r\n    _mgr: Manager\r\n    _attrs: dict[Hashable, Any]\r\n    _typ: str\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __init__(self, data: Manager) -> None:\r\n        object.__setattr__(self, \"_mgr\", data)\r\n        object.__setattr__(self, \"_attrs\", {})\r\n        object.__setattr__(self, \"_flags\", Flags(self, allows_duplicate_labels=True))\r\n\r\n    @final\r\n    @classmethod\r\n    def _init_mgr(\r\n        cls,\r\n        mgr: Manager,\r\n        axes: dict[Literal[\"index\", \"columns\"], Axes | None],\r\n        dtype: DtypeObj | None = None,\r\n        copy: bool = False,\r\n    ) -> Manager:\r\n        \"\"\"passed a manager and a axes dict\"\"\"\r\n        for a, axe in axes.items():\r\n            if axe is not None:\r\n                axe = ensure_index(axe)\r\n                bm_axis = cls._get_block_manager_axis(a)\r\n                mgr = mgr.reindex_axis(axe, axis=bm_axis)\r\n\r\n        # make a copy if explicitly requested\r\n        if copy:\r\n            mgr = mgr.copy()\r\n        if dtype is not None:\r\n            # avoid further copies if we can\r\n            if (\r\n                isinstance(mgr, BlockManager)\r\n                and len(mgr.blocks) == 1\r\n                and mgr.blocks[0].values.dtype == dtype\r\n            ):\r\n                pass\r\n            else:\r\n                mgr = mgr.astype(dtype=dtype)\r\n        return mgr\r\n\r\n    @final\r\n    @classmethod\r\n    def _from_mgr(cls, mgr: Manager, axes: list[Index]) -> Self:\r\n        \"\"\"\r\n        Construct a new object of this type from a Manager object and axes.\r\n\r\n        Parameters\r\n        ----------\r\n        mgr : Manager\r\n            Must have the same ndim as cls.\r\n        axes : list[Index]\r\n\r\n        Notes\r\n        -----\r\n        The axes must match mgr.axes, but are required for future-proofing\r\n        in the event that axes are refactored out of the Manager objects.\r\n        \"\"\"\r\n        obj = cls.__new__(cls)\r\n        NDFrame.__init__(obj, mgr)\r\n        return obj\r\n\r\n    # ----------------------------------------------------------------------\r\n    # attrs and flags\r\n\r\n    @property\r\n    def attrs(self) -> dict[Hashable, Any]:\r\n        \"\"\"\r\n        Dictionary of global attributes of this dataset.\r\n\r\n"]
[240.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[240.002, "i", "sed -n '1,420p' pandas/core/frame.py\r"]
[240.004, "o", "sed -n '1,420p' pandas/core/frame.py\r\n"]
[240.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nDataFrame\r\n---------\r\nAn efficient 2D container for potentially mixed-type time series or other\r\nlabeled data series.\r\n\r\nSimilar to its R counterpart, data.frame, except providing automatic data\r\nalignment and a host of useful data manipulation methods having to do with the\r\nlabeling information\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom collections import abc\r\nfrom collections.abc import (\r\n    Callable,\r\n    Hashable,\r\n    Iterable,\r\n    Iterator,\r\n    Mapping,\r\n    Sequence,\r\n)\r\nimport functools\r\nfrom io import StringIO\r\nimport itertools\r\nimport operator\r\nimport sys\r\nfrom textwrap import dedent\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\nfrom numpy import ma\r\n\r\nfrom pandas._config import get_option\r\n\r\nfrom pandas._libs import (\r\n    algos as libalgos,\r\n    lib,\r\n    properties,\r\n)\r\nfrom pandas._libs.hashtable import duplicated\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import (\r\n    _chained_assignment_method_msg,\r\n    _chained_assignment_msg,\r\n)\r\nfrom pandas.util._decorators import (\r\n    Appender,\r\n    Substitution,\r\n    deprecate_nonkeyword_arguments,\r\n    doc,\r\n    set_module,\r\n)\r\nfrom pandas.util._exceptions import (\r\n    find_stack_level,\r\n    rewrite_warning,\r\n)\r\nfrom pandas.util._validators import (\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_percentile,\r\n)\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    construct_1d_arraylike_from_scalar,\r\n    construct_2d_arraylike_from_scalar,\r\n    find_common_type,\r\n    infer_dtype_from_scalar,\r\n    invalidate_string_dtypes,\r\n    maybe_downcast_to_dtype,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    infer_dtype_from_object,\r\n    is_1d_only_ea_dtype,\r\n    is_array_like,\r\n    is_bool_dtype,\r\n    is_dataclass,\r\n    is_dict_like,\r\n    is_float,\r\n    is_float_dtype,\r\n    is_hashable,\r\n    is_integer,\r\n    is_integer_dtype,\r\n    is_iterator,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_sequence,\r\n    needs_i8_conversion,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.concat import concat_compat\r\nfrom pandas.core.dtypes.dtypes import (\r\n    ArrowDtype,\r\n    BaseMaskedDtype,\r\n    ExtensionDtype,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms,\r\n    common as com,\r\n    nanops,\r\n    ops,\r\n    roperator,\r\n)\r\nfrom pandas.core.accessor import Accessor\r\nfrom pandas.core.apply import reconstruct_and_relabel_result\r\nfrom pandas.core.array_algos.take import take_2d_multi\r\nfrom pandas.core.arraylike import OpsMixin\r\nfrom pandas.core.arrays import (\r\n    BaseMaskedArray,\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.sparse import SparseFrameAccessor\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    sanitize_array,\r\n    sanitize_masked_array,\r\n)\r\nfrom pandas.core.generic import (\r\n    NDFrame,\r\n    make_doc,\r\n)\r\nfrom pandas.core.indexers import check_key_length\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n    ensure_index_from_sequences,\r\n)\r\nfrom pandas.core.indexes.multi import (\r\n    MultiIndex,\r\n    maybe_droplevels,\r\n)\r\nfrom pandas.core.indexing import (\r\n    check_bool_indexer,\r\n    check_dict_or_set_indexers,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.internals.construction import (\r\n    arrays_to_mgr,\r\n    dataclasses_to_dicts,\r\n    dict_to_mgr,\r\n    ndarray_to_mgr,\r\n    nested_data_to_arrays,\r\n    rec_array_to_mgr,\r\n    reorder_arrays,\r\n    to_arrays,\r\n    treat_as_nested,\r\n)\r\nfrom pandas.core.methods import selectn\r\nfrom pandas.core.reshape.melt import melt\r\nfrom pandas.core.series import Series\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import (\r\n    get_group_index,\r\n    lexsort_indexer,\r\n    nargsort,\r\n)\r\n\r\nfrom pandas.io.common import get_handle\r\nfrom pandas.io.formats import (\r\n    console,\r\n    format as fmt,\r\n)\r\nfrom pandas.io.formats.info import (\r\n    INFO_DOCSTRING,\r\n    DataFrameInfo,\r\n    frame_sub_kwargs,\r\n)\r\nimport pandas.plotting\r\n\r\nif TYPE_CHECKING:\r\n    import datetime\r\n\r\n    from pandas._libs.internals import BlockValuesRefs\r\n    from pandas._typing import (\r\n        AggFuncType,\r\n        AnyAll,\r\n        AnyArrayLike,\r\n        ArrayLike,\r\n        Axes,\r\n        Axis,\r\n        AxisInt,\r\n        ColspaceArgType,\r\n        CompressionOptions,\r\n        CorrelationMethod,\r\n        DropKeep,\r\n        Dtype,\r\n        DtypeObj,\r\n        FilePath,\r\n        FloatFormatType,\r\n        FormattersType,\r\n        Frequency,\r\n        FromDictOrient,\r\n        HashableT,\r\n        HashableT2,\r\n        IgnoreRaise,\r\n        IndexKeyFunc,\r\n        IndexLabel,\r\n        JoinValidate,\r\n        Level,\r\n        ListLike,\r\n        MergeHow,\r\n        MergeValidate,\r\n        MutableMappingT,\r\n        NaPosition,\r\n        NsmallestNlargestKeep,\r\n        PythonFuncType,\r\n        QuantileInterpolation,\r\n        ReadBuffer,\r\n        ReindexMethod,\r\n        Renamer,\r\n        Scalar,\r\n        Self,\r\n        SequenceNotStr,\r\n        SortKind,\r\n        StorageOptions,\r\n        Suffixes,\r\n        T,\r\n        ToStataByteorder,\r\n        ToTimestampHow,\r\n        UpdateJoin,\r\n        ValueKeyFunc,\r\n        WriteBuffer,\r\n        XMLParsers,\r\n        npt,\r\n    )\r\n\r\n    from pandas.core.groupby.generic import DataFrameGroupBy\r\n    from pandas.core.interchange.dataframe_protocol import DataFrame as DataFrameXchg\r\n    from pandas.core.internals.managers import SingleBlockManager\r\n\r\n    from pandas.io.formats.style import Styler\r\n\r\n# ---------------------------------------------------------------------\r\n# Docstring templates\r\n\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"index, columns\",\r\n    \"klass\": \"DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index', 1 or 'columns'}\",\r\n    \"axis\": \"\"\"axis : {0 or 'index', 1 or 'columns'}, default 0\r\n        If 0 or 'index': apply function to each column.\r\n        If 1 or 'columns': apply function to each row.\"\"\",\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        Whether to modify the DataFrame rather than creating a new one.\"\"\",\r\n    \"optional_by\": \"\"\"\r\nby : str or list of str\r\n    Name or list of names to sort by.\r\n\r\n    - if `axis` is 0 or `'index'` then `by` may contain index\r\n      levels and/or column labels.\r\n    - if `axis` is 1 or `'columns'` then `by` may contain column\r\n      levels and/or index labels.\"\"\",\r\n    \"optional_reindex\": \"\"\"\r\nlabels : array-like, optional\r\n    New labels / index to conform the axis specified by 'axis' to.\r\nindex : array-like, optional\r\n    New labels for the index. Preferably an Index object to avoid\r\n    duplicating data.\r\ncolumns : array-like, optional\r\n    New labels for the columns. Preferably an Index object to avoid\r\n    duplicating data.\r\naxis : int or str, optional\r\n    Axis to target. Can be either the axis name ('index', 'columns')\r\n    or number (0, 1).\"\"\",\r\n}\r\n\r\n_merge_doc = \"\"\"\r\nMerge DataFrame or named Series objects with a database-style join.\r\n\r\nA named Series object is treated as a DataFrame with a single named column.\r\n\r\nThe join is done on columns or indexes. If joining columns on\r\ncolumns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\r\non indexes or indexes on a column or columns, the index will be passed on.\r\nWhen performing a cross merge, no column specifications to merge on are\r\nallowed.\r\n\r\n.. warning::\r\n\r\n    If both key columns contain rows where the key is a null value, those\r\n    rows will be matched against each other. This is different from usual SQL\r\n    join behaviour and can lead to unexpected results.\r\n\r\nParameters\r\n----------%s\r\nright : DataFrame or named Series\r\n    Object to merge with.\r\nhow : {'left', 'right', 'outer', 'inner', 'cross', 'left_anti', 'right_anti'},\r\n    default 'inner'\r\n    Type of merge to be performed.\r\n\r\n    * left: use only keys from left frame, similar to a SQL left outer join;\r\n      preserve key order.\r\n    * right: use only keys from right frame, similar to a SQL right outer join;\r\n      preserve key order.\r\n    * outer: use union of keys from both frames, similar to a SQL full outer\r\n      join; sort keys lexicographically.\r\n    * inner: use intersection of keys from both frames, similar to a SQL inner\r\n      join; preserve the order of the left keys.\r\n    * cross: creates the cartesian product from both frames, preserves the order\r\n      of the left keys.\r\n    * left_anti: use only keys from left frame that are not in right frame, similar\r\n      to SQL left anti join; preserve key order.\r\n    * right_anti: use only keys from right frame that are not in left frame, similar\r\n      to SQL right anti join; preserve key order.\r\non : label or list\r\n    Column or index level names to join on. These must be found in both\r\n    DataFrames. If `on` is None and not merging on indexes then this defaults\r\n    to the intersection of the columns in both DataFrames.\r\nleft_on : label or list, or array-like\r\n    Column or index level names to join on in the left DataFrame. Can also\r\n    be an array or list of arrays of the length of the left DataFrame.\r\n    These arrays are treated as if they are columns.\r\nright_on : label or list, or array-like\r\n    Column or index level names to join on in the right DataFrame. Can also\r\n    be an array or list of arrays of the length of the right DataFrame.\r\n    These arrays are treated as if they are columns.\r\nleft_index : bool, default False\r\n    Use the index from the left DataFrame as the join key(s). If it is a\r\n    MultiIndex, the number of keys in the other DataFrame (either the index\r\n    or a number of columns) must match the number of levels.\r\nright_index : bool, default False\r\n    Use the index from the right DataFrame as the join key. Same caveats as\r\n    left_index.\r\nsort : bool, default False\r\n    Sort the join keys lexicographically in the result DataFrame. If False,\r\n    the order of the join keys depends on the join type (how keyword).\r\nsuffixes : list-like, default is (\"_x\", \"_y\")\r\n    A length-2 sequence where each element is optionally a string\r\n    indicating the suffix to add to overlapping column names in\r\n    `left` and `right` respectively. Pass a value of `None` instead\r\n    of a string to indicate that the column name from `left` or\r\n    `right` should be left as-is, with no suffix. At least one of the\r\n    values must not be None.\r\ncopy : bool, default False\r\n    If False, avoid copy if possible.\r\n\r\n    .. note::\r\n        The `copy` keyword will change behavior in pandas 3.0.\r\n        `Copy-on-Write\r\n        <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\r\n        will be enabled by default, which means that all methods with a\r\n        `copy` keyword will use a lazy copy mechanism to defer the copy and\r\n        ignore the `copy` keyword. The `copy` keyword will be removed in a\r\n        future version of pandas.\r\n\r\n        You can already get the future behavior and improvements through\r\n        enabling copy on write ``pd.options.mode.copy_on_write = True``\r\n\r\n    .. deprecated:: 3.0.0\r\nindicator : bool or str, default False\r\n    If True, adds a column to the output DataFrame called \"_merge\" with\r\n    information on the source of each row. The column can be given a different\r\n    name by providing a string argument. The column will have a Categorical\r\n    type with the value of \"left_only\" for observations whose merge key only\r\n    appears in the left DataFrame, \"right_only\" for observations\r\n    whose merge key only appears in the right DataFrame, and \"both\"\r\n    if the observation's merge key is found in both DataFrames.\r\n\r\nvalidate : str, optional\r\n    If specified, checks if merge is of specified type.\r\n\r\n    * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\r\n      left and right datasets.\r\n    * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\r\n      dataset.\r\n    * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\r\n      dataset.\r\n    * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\r\n\r\nReturns\r\n-------\r\nDataFrame\r\n    A DataFrame of the two merged objects.\r\n\r\nSee Also\r\n--------\r\nmerge_ordered : Merge with optional filling/interpolation.\r\nmerge_asof : Merge on nearest keys.\r\nDataFrame.join : Similar method using indices.\r\n\r\nExamples\r\n--------\r\n>>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\r\n...                     'value': [1, 2, 3, 5]})\r\n>>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\r\n...                     'value': [5, 6, 7, 8]})\r\n>>> df1\r\n    lkey value\r\n0   foo      1\r\n"]
[245.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[245.002, "i", "cd asv_bench\r"]
[245.004, "o", "cd asv_bench\r\n"]
[245.006, "o", "\u001b[?2004l\r\n"]
[250.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[250.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r"]
[250.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r\n"]
[250.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (frame_methods.MaskBool.time_frame_mask_bools--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                            48.1\u00b10.4ms\r\n\r\nWed Oct  1 17:11:12 2025    /tmp/tmpcnqx0hwn\r\n\r\n         83260 function calls (82244 primitive calls) in 0.145 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.145    0.145 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.145    0.145 _base.py:689(method_caller)\r\n        1    0.005    0.005    0.145    0.145 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.140    0.140 generic.py:10068(mask)\r\n        1    0.000    0.000    0.140    0.140 generic.py:9685(_where)\r\n        7    0.000    0.000    0.138    0.020 managers.py:392(apply)\r\n        1    0.000    0.000    0.137    0.137 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.137    0.137 blocks.py:1211(where)\r\n      500    0.001    0.000    0.092    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.071    0.000 common.py:702(is_integer_dtype)\r\n      500    0.069    0.000    0.069    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.010    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.003    0.000    0.009    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.001    0.000    0.004    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.003    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n      500    0.002    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     1001    0.001    0.000    0.002    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n      500    0.001    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x561473fc4640}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[255.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[255.002, "i", "cd ..\r"]
[255.004, "o", "cd ..\r\n"]
[255.006, "o", "\u001b[?2004l\r\n"]
[260.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[260.002, "i", "grep -R \"def mask\\(\" -n pandas/core | head -n 50\r"]
[260.004, "o", "grep -R \"def mask\\(\" -n pandas/core | head -n 50\r\n"]
[260.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[265.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[265.002, "i", "grep -R \"def where\\(\" -n pandas/core | head -n 50\r"]
[265.004, "o", "grep -R \"def where\\(\" -n pandas/core | head -n 50\r\n"]
[265.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[270.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[270.002, "i", "grep -R \"where\\(\" -n pandas/core/internals | head -n 50\r"]
[270.004, "o", "grep -R \"where\\(\" -n pandas/core/internals | head -n 50\r\n"]
[270.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[275.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[275.002, "i", "sed -n '1,260p' pandas/core/generic.py\r"]
[275.004, "o", "sed -n '1,260p' pandas/core/generic.py\r\n"]
[275.006, "o", "\u001b[?2004l\r\n# pyright: reportPropertyTypeMismatch=false\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom copy import deepcopy\r\nimport datetime as dt\r\nfrom functools import partial\r\nfrom json import loads\r\nimport operator\r\nimport pickle\r\nimport re\r\nimport sys\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    ClassVar,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import config\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas._libs.tslibs import (\r\n    Period,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    AlignJoin,\r\n    AnyArrayLike,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    AxisInt,\r\n    CompressionOptions,\r\n    Concatenate,\r\n    DtypeArg,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FilePath,\r\n    FillnaOptions,\r\n    FloatFormatType,\r\n    FormattersType,\r\n    Frequency,\r\n    IgnoreRaise,\r\n    IndexKeyFunc,\r\n    IndexLabel,\r\n    InterpolateOptions,\r\n    IntervalClosedType,\r\n    JSONSerializable,\r\n    Level,\r\n    ListLike,\r\n    Manager,\r\n    NaPosition,\r\n    NDFrameT,\r\n    OpenFileErrors,\r\n    RandomState,\r\n    ReindexMethod,\r\n    Renamer,\r\n    Scalar,\r\n    Self,\r\n    SequenceNotStr,\r\n    SortKind,\r\n    StorageOptions,\r\n    Suffixes,\r\n    T,\r\n    TimeAmbiguous,\r\n    TimedeltaConvertibleTypes,\r\n    TimeNonexistent,\r\n    TimestampConvertibleTypes,\r\n    TimeUnit,\r\n    ValueKeyFunc,\r\n    WriteBuffer,\r\n    WriteExcelBuffer,\r\n    npt,\r\n)\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import _chained_assignment_method_msg\r\nfrom pandas.util._decorators import (\r\n    deprecate_kwarg,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import (\r\n    check_dtype_backend,\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_inclusive,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_is_view\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    ensure_str,\r\n    is_bool,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_extension_array_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_numeric_dtype,\r\n    is_re_compilable,\r\n    is_scalar,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import (\r\n    is_hashable,\r\n    is_nested_list_like,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms as algos,\r\n    arraylike,\r\n    common,\r\n    indexing,\r\n    missing,\r\n    nanops,\r\n    sample,\r\n)\r\nfrom pandas.core.array_algos.replace import should_use_regex\r\nfrom pandas.core.arrays import ExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import extract_array\r\nfrom pandas.core.flags import Flags\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    MultiIndex,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.methods.describe import describe_ndframe\r\nfrom pandas.core.missing import (\r\n    clean_fill_method,\r\n    clean_reindex_fill_method,\r\n    find_valid_index,\r\n)\r\nfrom pandas.core.reshape.concat import concat\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import get_indexer_indexer\r\nfrom pandas.core.window import (\r\n    Expanding,\r\n    ExponentialMovingWindow,\r\n    Rolling,\r\n    Window,\r\n)\r\n\r\nfrom pandas.io.formats.format import (\r\n    DataFrameFormatter,\r\n    DataFrameRenderer,\r\n)\r\nfrom pandas.io.formats.printing import pprint_thing\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Callable\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterator,\r\n        Mapping,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._libs.tslibs import BaseOffset\r\n    from pandas._typing import P\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        ExcelWriter,\r\n        HDFStore,\r\n        Series,\r\n    )\r\n    from pandas.core.indexers.objects import BaseIndexer\r\n    from pandas.core.resample import Resampler\r\n\r\nimport textwrap\r\n\r\n# goal is to be able to define the docs close to function, while still being\r\n# able to share\r\n_shared_docs = {**_shared_docs}\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"keywords for axes\",\r\n    \"klass\": \"Series/DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\",  # noqa: E501\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        If True, performs operation inplace and returns None.\"\"\",\r\n    \"optional_by\": \"\"\"\r\n        by : str or list of str\r\n            Name or list of names to sort by\"\"\",\r\n}\r\n\r\n\r\nclass NDFrame(PandasObject, indexing.IndexingMixin):\r\n    \"\"\"\r\n    N-dimensional analogue of DataFrame. Store multi-dimensional in a\r\n    size-mutable, labeled data structure\r\n\r\n    Parameters\r\n    ----------\r\n    data : BlockManager\r\n    axes : list\r\n    copy : bool, default False\r\n    \"\"\"\r\n\r\n    _internal_names: list[str] = [\r\n        \"_mgr\",\r\n        \"_item_cache\",\r\n        \"_cache\",\r\n        \"_name\",\r\n        \"_metadata\",\r\n        \"_flags\",\r\n    ]\r\n    _internal_names_set: set[str] = set(_internal_names)\r\n    _accessors: set[str] = set()\r\n    _hidden_attrs: frozenset[str] = frozenset([])\r\n    _metadata: list[str] = []\r\n    _mgr: Manager\r\n    _attrs: dict[Hashable, Any]\r\n    _typ: str\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __init__(self, data: Manager) -> None:\r\n        object.__setattr__(self, \"_mgr\", data)\r\n        object.__setattr__(self, \"_attrs\", {})\r\n        object.__setattr__(self, \"_flags\", Flags(self, allows_duplicate_labels=True))\r\n\r\n"]
[280.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[280.002, "i", "sed -n '1,340p' pandas/core/frame.py\r"]
[280.004, "o", "sed -n '1,340p' pandas/core/frame.py\r\n"]
[280.006, "o", "\u001b[?2004l\r\n\"\"\"\r\nDataFrame\r\n---------\r\nAn efficient 2D container for potentially mixed-type time series or other\r\nlabeled data series.\r\n\r\nSimilar to its R counterpart, data.frame, except providing automatic data\r\nalignment and a host of useful data manipulation methods having to do with the\r\nlabeling information\r\n\"\"\"\r\n\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom collections import abc\r\nfrom collections.abc import (\r\n    Callable,\r\n    Hashable,\r\n    Iterable,\r\n    Iterator,\r\n    Mapping,\r\n    Sequence,\r\n)\r\nimport functools\r\nfrom io import StringIO\r\nimport itertools\r\nimport operator\r\nimport sys\r\nfrom textwrap import dedent\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\nfrom numpy import ma\r\n\r\nfrom pandas._config import get_option\r\n\r\nfrom pandas._libs import (\r\n    algos as libalgos,\r\n    lib,\r\n    properties,\r\n)\r\nfrom pandas._libs.hashtable import duplicated\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import (\r\n    _chained_assignment_method_msg,\r\n    _chained_assignment_msg,\r\n)\r\nfrom pandas.util._decorators import (\r\n    Appender,\r\n    Substitution,\r\n    deprecate_nonkeyword_arguments,\r\n    doc,\r\n    set_module,\r\n)\r\nfrom pandas.util._exceptions import (\r\n    find_stack_level,\r\n    rewrite_warning,\r\n)\r\nfrom pandas.util._validators import (\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_percentile,\r\n)\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    construct_1d_arraylike_from_scalar,\r\n    construct_2d_arraylike_from_scalar,\r\n    find_common_type,\r\n    infer_dtype_from_scalar,\r\n    invalidate_string_dtypes,\r\n    maybe_downcast_to_dtype,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    infer_dtype_from_object,\r\n    is_1d_only_ea_dtype,\r\n    is_array_like,\r\n    is_bool_dtype,\r\n    is_dataclass,\r\n    is_dict_like,\r\n    is_float,\r\n    is_float_dtype,\r\n    is_hashable,\r\n    is_integer,\r\n    is_integer_dtype,\r\n    is_iterator,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_sequence,\r\n    needs_i8_conversion,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.concat import concat_compat\r\nfrom pandas.core.dtypes.dtypes import (\r\n    ArrowDtype,\r\n    BaseMaskedDtype,\r\n    ExtensionDtype,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms,\r\n    common as com,\r\n    nanops,\r\n    ops,\r\n    roperator,\r\n)\r\nfrom pandas.core.accessor import Accessor\r\nfrom pandas.core.apply import reconstruct_and_relabel_result\r\nfrom pandas.core.array_algos.take import take_2d_multi\r\nfrom pandas.core.arraylike import OpsMixin\r\nfrom pandas.core.arrays import (\r\n    BaseMaskedArray,\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.sparse import SparseFrameAccessor\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    sanitize_array,\r\n    sanitize_masked_array,\r\n)\r\nfrom pandas.core.generic import (\r\n    NDFrame,\r\n    make_doc,\r\n)\r\nfrom pandas.core.indexers import check_key_length\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n    ensure_index_from_sequences,\r\n)\r\nfrom pandas.core.indexes.multi import (\r\n    MultiIndex,\r\n    maybe_droplevels,\r\n)\r\nfrom pandas.core.indexing import (\r\n    check_bool_indexer,\r\n    check_dict_or_set_indexers,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.internals.construction import (\r\n    arrays_to_mgr,\r\n    dataclasses_to_dicts,\r\n    dict_to_mgr,\r\n    ndarray_to_mgr,\r\n    nested_data_to_arrays,\r\n    rec_array_to_mgr,\r\n    reorder_arrays,\r\n    to_arrays,\r\n    treat_as_nested,\r\n)\r\nfrom pandas.core.methods import selectn\r\nfrom pandas.core.reshape.melt import melt\r\nfrom pandas.core.series import Series\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import (\r\n    get_group_index,\r\n    lexsort_indexer,\r\n    nargsort,\r\n)\r\n\r\nfrom pandas.io.common import get_handle\r\nfrom pandas.io.formats import (\r\n    console,\r\n    format as fmt,\r\n)\r\nfrom pandas.io.formats.info import (\r\n    INFO_DOCSTRING,\r\n    DataFrameInfo,\r\n    frame_sub_kwargs,\r\n)\r\nimport pandas.plotting\r\n\r\nif TYPE_CHECKING:\r\n    import datetime\r\n\r\n    from pandas._libs.internals import BlockValuesRefs\r\n    from pandas._typing import (\r\n        AggFuncType,\r\n        AnyAll,\r\n        AnyArrayLike,\r\n        ArrayLike,\r\n        Axes,\r\n        Axis,\r\n        AxisInt,\r\n        ColspaceArgType,\r\n        CompressionOptions,\r\n        CorrelationMethod,\r\n        DropKeep,\r\n        Dtype,\r\n        DtypeObj,\r\n        FilePath,\r\n        FloatFormatType,\r\n        FormattersType,\r\n        Frequency,\r\n        FromDictOrient,\r\n        HashableT,\r\n        HashableT2,\r\n        IgnoreRaise,\r\n        IndexKeyFunc,\r\n        IndexLabel,\r\n        JoinValidate,\r\n        Level,\r\n        ListLike,\r\n        MergeHow,\r\n        MergeValidate,\r\n        MutableMappingT,\r\n        NaPosition,\r\n        NsmallestNlargestKeep,\r\n        PythonFuncType,\r\n        QuantileInterpolation,\r\n        ReadBuffer,\r\n        ReindexMethod,\r\n        Renamer,\r\n        Scalar,\r\n        Self,\r\n        SequenceNotStr,\r\n        SortKind,\r\n        StorageOptions,\r\n        Suffixes,\r\n        T,\r\n        ToStataByteorder,\r\n        ToTimestampHow,\r\n        UpdateJoin,\r\n        ValueKeyFunc,\r\n        WriteBuffer,\r\n        XMLParsers,\r\n        npt,\r\n    )\r\n\r\n    from pandas.core.groupby.generic import DataFrameGroupBy\r\n    from pandas.core.interchange.dataframe_protocol import DataFrame as DataFrameXchg\r\n    from pandas.core.internals.managers import SingleBlockManager\r\n\r\n    from pandas.io.formats.style import Styler\r\n\r\n# ---------------------------------------------------------------------\r\n# Docstring templates\r\n\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"index, columns\",\r\n    \"klass\": \"DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index', 1 or 'columns'}\",\r\n    \"axis\": \"\"\"axis : {0 or 'index', 1 or 'columns'}, default 0\r\n        If 0 or 'index': apply function to each column.\r\n        If 1 or 'columns': apply function to each row.\"\"\",\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        Whether to modify the DataFrame rather than creating a new one.\"\"\",\r\n    \"optional_by\": \"\"\"\r\nby : str or list of str\r\n    Name or list of names to sort by.\r\n\r\n    - if `axis` is 0 or `'index'` then `by` may contain index\r\n      levels and/or column labels.\r\n    - if `axis` is 1 or `'columns'` then `by` may contain column\r\n      levels and/or index labels.\"\"\",\r\n    \"optional_reindex\": \"\"\"\r\nlabels : array-like, optional\r\n    New labels / index to conform the axis specified by 'axis' to.\r\nindex : array-like, optional\r\n    New labels for the index. Preferably an Index object to avoid\r\n    duplicating data.\r\ncolumns : array-like, optional\r\n    New labels for the columns. Preferably an Index object to avoid\r\n    duplicating data.\r\naxis : int or str, optional\r\n    Axis to target. Can be either the axis name ('index', 'columns')\r\n    or number (0, 1).\"\"\",\r\n}\r\n\r\n_merge_doc = \"\"\"\r\nMerge DataFrame or named Series objects with a database-style join.\r\n\r\nA named Series object is treated as a DataFrame with a single named column.\r\n\r\nThe join is done on columns or indexes. If joining columns on\r\ncolumns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\r\non indexes or indexes on a column or columns, the index will be passed on.\r\nWhen performing a cross merge, no column specifications to merge on are\r\nallowed.\r\n\r\n.. warning::\r\n\r\n    If both key columns contain rows where the key is a null value, those\r\n    rows will be matched against each other. This is different from usual SQL\r\n    join behaviour and can lead to unexpected results.\r\n\r\nParameters\r\n----------%s\r\nright : DataFrame or named Series\r\n    Object to merge with.\r\nhow : {'left', 'right', 'outer', 'inner', 'cross', 'left_anti', 'right_anti'},\r\n    default 'inner'\r\n    Type of merge to be performed.\r\n\r\n    * left: use only keys from left frame, similar to a SQL left outer join;\r\n      preserve key order.\r\n    * right: use only keys from right frame, similar to a SQL right outer join;\r\n      preserve key order.\r\n    * outer: use union of keys from both frames, similar to a SQL full outer\r\n      join; sort keys lexicographically.\r\n    * inner: use intersection of keys from both frames, similar to a SQL inner\r\n      join; preserve the order of the left keys.\r\n    * cross: creates the cartesian product from both frames, preserves the order\r\n      of the left keys.\r\n    * left_anti: use only keys from left frame that are not in right frame, similar\r\n      to SQL left anti join; preserve key order.\r\n    * right_anti: use only keys from right frame that are not in left frame, similar\r\n      to SQL right anti join; preserve key order.\r\non : label or list\r\n    Column or index level names to join on. These must be found in both\r\n    DataFrames. If `on` is None and not merging on indexes then this defaults\r\n    to the intersection of the columns in both DataFrames.\r\nleft_on : label or list, or array-like\r\n"]
[285.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[285.002, "i", "cd asv_bench\r"]
[285.004, "o", "cd asv_bench\r\n"]
[285.006, "o", "\u001b[?2004l\r\n"]
[290.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[290.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r"]
[290.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r\n"]
[290.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (frame_methods.MaskBool.time_frame_mask_bools--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                            48.1\u00b10.3ms\r\n\r\nWed Oct  1 17:13:29 2025    /tmp/tmp_n6cqfb_\r\n\r\n         83260 function calls (82244 primitive calls) in 0.148 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.148    0.148 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.148    0.148 _base.py:689(method_caller)\r\n        1    0.005    0.005    0.148    0.148 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.143    0.143 generic.py:10068(mask)\r\n        1    0.000    0.000    0.143    0.143 generic.py:9685(_where)\r\n        7    0.000    0.000    0.141    0.020 managers.py:392(apply)\r\n        1    0.000    0.000    0.141    0.141 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.140    0.140 blocks.py:1211(where)\r\n      500    0.001    0.000    0.096    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.076    0.000 common.py:702(is_integer_dtype)\r\n      500    0.074    0.000    0.074    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.010    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.003    0.000    0.009    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.000    0.000    0.003    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.001    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.001    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x5576299fc640}\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[295.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[295.002, "i", "cd ..\r"]
[295.004, "o", "cd ..\r\n"]
[295.006, "o", "\u001b[?2004l\r\n"]
[300.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[300.002, "i", "grep -R \"def mask\\(\" -n pandas/core | head -n 50\r"]
[300.004, "o", "grep -R \"def mask\\(\" -n pandas/core | head -n 50\r\n"]
[300.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[305.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[305.002, "i", "grep -R \"def where\\(\" -n pandas/core | head -n 50\r"]
[305.004, "o", "grep -R \"def where\\(\" -n pandas/core | head -n 50\r\n"]
[305.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[310.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[310.002, "i", "grep -R \"where(\" -n pandas/core/internals | head -n 50\r"]
[310.004, "o", "grep -R \"where(\" -n pandas/core/internals | head -n 50\r\n"]
[310.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1258:                return block.where(orig_other, cond)\r\npandas/core/internals/blocks.py:1271:                    rbs = nb.where(oth, submask)\r\npandas/core/internals/blocks.py:1281:                    np.where(~icond, values, other)\r\npandas/core/internals/blocks.py:1305:                result = expressions.where(~icond, values, other)\r\npandas/core/internals/blocks.py:1344:            nbs = self.where(value, ~mask.T)\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1684:            res_values = arr._where(cond, other).T\r\npandas/core/internals/blocks.py:1697:                    return blk.where(orig_other, orig_cond)\r\npandas/core/internals/blocks.py:1703:                    return blk.where(orig_other, orig_cond)\r\npandas/core/internals/blocks.py:1720:                    rbs = nb.where(n, submask)\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[315.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[315.002, "i", "sed -n '1,400p' pandas/core/generic.py\r"]
[315.004, "o", "sed -n '1,400p' pandas/core/generic.py\r\n"]
[315.006, "o", "\u001b[?2004l\r\n# pyright: reportPropertyTypeMismatch=false\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom copy import deepcopy\r\nimport datetime as dt\r\nfrom functools import partial\r\nfrom json import loads\r\nimport operator\r\nimport pickle\r\nimport re\r\nimport sys\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    ClassVar,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import config\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas._libs.tslibs import (\r\n    Period,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    AlignJoin,\r\n    AnyArrayLike,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    AxisInt,\r\n    CompressionOptions,\r\n    Concatenate,\r\n    DtypeArg,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FilePath,\r\n    FillnaOptions,\r\n    FloatFormatType,\r\n    FormattersType,\r\n    Frequency,\r\n    IgnoreRaise,\r\n    IndexKeyFunc,\r\n    IndexLabel,\r\n    InterpolateOptions,\r\n    IntervalClosedType,\r\n    JSONSerializable,\r\n    Level,\r\n    ListLike,\r\n    Manager,\r\n    NaPosition,\r\n    NDFrameT,\r\n    OpenFileErrors,\r\n    RandomState,\r\n    ReindexMethod,\r\n    Renamer,\r\n    Scalar,\r\n    Self,\r\n    SequenceNotStr,\r\n    SortKind,\r\n    StorageOptions,\r\n    Suffixes,\r\n    T,\r\n    TimeAmbiguous,\r\n    TimedeltaConvertibleTypes,\r\n    TimeNonexistent,\r\n    TimestampConvertibleTypes,\r\n    TimeUnit,\r\n    ValueKeyFunc,\r\n    WriteBuffer,\r\n    WriteExcelBuffer,\r\n    npt,\r\n)\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import _chained_assignment_method_msg\r\nfrom pandas.util._decorators import (\r\n    deprecate_kwarg,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import (\r\n    check_dtype_backend,\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_inclusive,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_is_view\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    ensure_str,\r\n    is_bool,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_extension_array_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_numeric_dtype,\r\n    is_re_compilable,\r\n    is_scalar,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import (\r\n    is_hashable,\r\n    is_nested_list_like,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms as algos,\r\n    arraylike,\r\n    common,\r\n    indexing,\r\n    missing,\r\n    nanops,\r\n    sample,\r\n)\r\nfrom pandas.core.array_algos.replace import should_use_regex\r\nfrom pandas.core.arrays import ExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import extract_array\r\nfrom pandas.core.flags import Flags\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    MultiIndex,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.methods.describe import describe_ndframe\r\nfrom pandas.core.missing import (\r\n    clean_fill_method,\r\n    clean_reindex_fill_method,\r\n    find_valid_index,\r\n)\r\nfrom pandas.core.reshape.concat import concat\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import get_indexer_indexer\r\nfrom pandas.core.window import (\r\n    Expanding,\r\n    ExponentialMovingWindow,\r\n    Rolling,\r\n    Window,\r\n)\r\n\r\nfrom pandas.io.formats.format import (\r\n    DataFrameFormatter,\r\n    DataFrameRenderer,\r\n)\r\nfrom pandas.io.formats.printing import pprint_thing\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Callable\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterator,\r\n        Mapping,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._libs.tslibs import BaseOffset\r\n    from pandas._typing import P\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        ExcelWriter,\r\n        HDFStore,\r\n        Series,\r\n    )\r\n    from pandas.core.indexers.objects import BaseIndexer\r\n    from pandas.core.resample import Resampler\r\n\r\nimport textwrap\r\n\r\n# goal is to be able to define the docs close to function, while still being\r\n# able to share\r\n_shared_docs = {**_shared_docs}\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"keywords for axes\",\r\n    \"klass\": \"Series/DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\",  # noqa: E501\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        If True, performs operation inplace and returns None.\"\"\",\r\n    \"optional_by\": \"\"\"\r\n        by : str or list of str\r\n            Name or list of names to sort by\"\"\",\r\n}\r\n\r\n\r\nclass NDFrame(PandasObject, indexing.IndexingMixin):\r\n    \"\"\"\r\n    N-dimensional analogue of DataFrame. Store multi-dimensional in a\r\n    size-mutable, labeled data structure\r\n\r\n    Parameters\r\n    ----------\r\n    data : BlockManager\r\n    axes : list\r\n    copy : bool, default False\r\n    \"\"\"\r\n\r\n    _internal_names: list[str] = [\r\n        \"_mgr\",\r\n        \"_item_cache\",\r\n        \"_cache\",\r\n        \"_name\",\r\n        \"_metadata\",\r\n        \"_flags\",\r\n    ]\r\n    _internal_names_set: set[str] = set(_internal_names)\r\n    _accessors: set[str] = set()\r\n    _hidden_attrs: frozenset[str] = frozenset([])\r\n    _metadata: list[str] = []\r\n    _mgr: Manager\r\n    _attrs: dict[Hashable, Any]\r\n    _typ: str\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __init__(self, data: Manager) -> None:\r\n        object.__setattr__(self, \"_mgr\", data)\r\n        object.__setattr__(self, \"_attrs\", {})\r\n        object.__setattr__(self, \"_flags\", Flags(self, allows_duplicate_labels=True))\r\n\r\n    @final\r\n    @classmethod\r\n    def _init_mgr(\r\n        cls,\r\n        mgr: Manager,\r\n        axes: dict[Literal[\"index\", \"columns\"], Axes | None],\r\n        dtype: DtypeObj | None = None,\r\n        copy: bool = False,\r\n    ) -> Manager:\r\n        \"\"\"passed a manager and a axes dict\"\"\"\r\n        for a, axe in axes.items():\r\n            if axe is not None:\r\n                axe = ensure_index(axe)\r\n                bm_axis = cls._get_block_manager_axis(a)\r\n                mgr = mgr.reindex_axis(axe, axis=bm_axis)\r\n\r\n        # make a copy if explicitly requested\r\n        if copy:\r\n            mgr = mgr.copy()\r\n        if dtype is not None:\r\n            # avoid further copies if we can\r\n            if (\r\n                isinstance(mgr, BlockManager)\r\n                and len(mgr.blocks) == 1\r\n                and mgr.blocks[0].values.dtype == dtype\r\n            ):\r\n                pass\r\n            else:\r\n                mgr = mgr.astype(dtype=dtype)\r\n        return mgr\r\n\r\n    @final\r\n    @classmethod\r\n    def _from_mgr(cls, mgr: Manager, axes: list[Index]) -> Self:\r\n        \"\"\"\r\n        Construct a new object of this type from a Manager object and axes.\r\n\r\n        Parameters\r\n        ----------\r\n        mgr : Manager\r\n            Must have the same ndim as cls.\r\n        axes : list[Index]\r\n\r\n        Notes\r\n        -----\r\n        The axes must match mgr.axes, but are required for future-proofing\r\n        in the event that axes are refactored out of the Manager objects.\r\n        \"\"\"\r\n        obj = cls.__new__(cls)\r\n        NDFrame.__init__(obj, mgr)\r\n        return obj\r\n\r\n    # ----------------------------------------------------------------------\r\n    # attrs and flags\r\n\r\n    @property\r\n    def attrs(self) -> dict[Hashable, Any]:\r\n        \"\"\"\r\n        Dictionary of global attributes of this dataset.\r\n\r\n        .. warning::\r\n\r\n           attrs is experimental and may change without warning.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.flags : Global flags applying to this object.\r\n\r\n        Notes\r\n        -----\r\n        Many operations that create new datasets will copy ``attrs``. Copies\r\n        are always deep so that changing ``attrs`` will only affect the\r\n        present dataset. ``pandas.concat`` copies ``attrs`` only if all input\r\n        datasets have the same ``attrs``.\r\n\r\n        Examples\r\n        --------\r\n        For Series:\r\n\r\n        >>> ser = pd.Series([1, 2, 3])\r\n        >>> ser.attrs = {\"A\": [10, 20, 30]}\r\n        >>> ser.attrs\r\n        {'A': [10, 20, 30]}\r\n\r\n        For DataFrame:\r\n\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n        >>> df.attrs = {\"A\": [10, 20, 30]}\r\n        >>> df.attrs\r\n        {'A': [10, 20, 30]}\r\n        \"\"\"\r\n        return self._attrs\r\n\r\n    @attrs.setter\r\n    def attrs(self, value: Mapping[Hashable, Any]) -> None:\r\n        self._attrs = dict(value)\r\n\r\n    @final\r\n    @property\r\n    def flags(self) -> Flags:\r\n        \"\"\"\r\n        Get the properties associated with this pandas object.\r\n\r\n        The available flags are\r\n\r\n        * :attr:`Flags.allows_duplicate_labels`\r\n\r\n        See Also\r\n        --------\r\n        Flags : Flags that apply to pandas objects.\r\n        DataFrame.attrs : Global metadata applying to this dataset.\r\n\r\n        Notes\r\n        -----\r\n        \"Flags\" differ from \"metadata\". Flags reflect properties of the\r\n        pandas object (the Series or DataFrame). Metadata refer to properties\r\n        of the dataset, and should be stored in :attr:`DataFrame.attrs`.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2]})\r\n        >>> df.flags\r\n        <Flags(allows_duplicate_labels=True)>\r\n\r\n        Flags can be get or set using ``.``\r\n\r\n        >>> df.flags.allows_duplicate_labels\r\n        True\r\n        >>> df.flags.allows_duplicate_labels = False\r\n\r\n        Or by slicing with a key\r\n\r\n        >>> df.flags[\"allows_duplicate_labels\"]\r\n        False\r\n        >>> df.flags[\"allows_duplicate_labels\"] = True\r\n        \"\"\"\r\n        return self._flags\r\n\r\n    @final\r\n    def set_flags(\r\n"]
[320.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[320.002, "i", "grep -n \"class DataFrame\" pandas/core/frame.py\r"]
[320.004, "o", "grep -n \"class DataFrame\" pandas/core/frame.py\r\n"]
[320.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K510\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kclass DataFrame\u001b[m\u001b[K(NDFrame, OpsMixin):\r\n"]
[325.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[325.002, "i", "grep -n \"def where\\(\" pandas/core/frame.py\r"]
[325.004, "o", "grep -n \"def where\\(\" pandas/core/frame.py\r\n"]
[325.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[330.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[330.002, "i", "cd asv_bench\r"]
[330.004, "o", "cd asv_bench\r\n"]
[330.006, "o", "\u001b[?2004l\r\n"]
[335.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[335.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r"]
[335.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r\n"]
[335.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (frame_methods.MaskBool.time_frame_mask_bools--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                            47.7\u00b10.2ms\r\n\r\nWed Oct  1 17:15:34 2025    /tmp/tmpwqp4bys8\r\n\r\n         83260 function calls (82244 primitive calls) in 0.141 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.141    0.141 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.141    0.141 _base.py:689(method_caller)\r\n        1    0.005    0.005    0.141    0.141 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.136    0.136 generic.py:10068(mask)\r\n        1    0.000    0.000    0.136    0.136 generic.py:9685(_where)\r\n        7    0.000    0.000    0.134    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.134    0.134 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.133    0.133 blocks.py:1211(where)\r\n      500    0.001    0.000    0.089    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.069    0.000 common.py:702(is_integer_dtype)\r\n      500    0.067    0.000    0.067    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.010    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.003    0.000    0.009    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.000    0.000    0.003    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     1001    0.001    0.000    0.001    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x561a3ff28640}\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[340.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[340.002, "i", "cd ..\r"]
[340.004, "o", "cd ..\r\n"]
[340.006, "o", "\u001b[?2004l\r\n"]
[345.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[345.002, "i", "grep -R -n \"def mask\\(\" pandas/core | head -n 50\r"]
[345.004, "o", "grep -R -n \"def mask\\(\" pandas/core | head -n 50\r\n"]
[345.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[350.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[350.002, "i", "grep -R -n \"def where\\(\" pandas/core | head -n 50\r"]
[350.004, "o", "grep -R -n \"def where\\(\" pandas/core | head -n 50\r\n"]
[350.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[355.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[355.002, "i", "grep -R -n \"where\\(\" pandas/core/internals | head -n 50\r"]
[355.004, "o", "grep -R -n \"where\\(\" pandas/core/internals | head -n 50\r\n"]
[355.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[360.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[360.002, "i", "grep -R -n \"putmask\\(\" pandas/core/internals | head -n 50\r"]
[360.004, "o", "grep -R -n \"putmask\\(\" pandas/core/internals | head -n 50\r\n"]
[360.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[365.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[365.002, "i", "cd asv_bench\r"]
[365.004, "o", "cd asv_bench\r\n"]
[365.006, "o", "\u001b[?2004l\r\n"]
[370.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[370.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r"]
[370.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools\r\n"]
[370.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n\u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (frame_methods.MaskBool.time_frame_mask_bools--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                            48.1\u00b10.3ms\r\n\r\nWed Oct  1 17:17:25 2025    /tmp/tmpzfn45rc6\r\n\r\n         83260 function calls (82244 primitive calls) in 0.144 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.144    0.144 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.144    0.144 _base.py:689(method_caller)\r\n        1    0.005    0.005    0.144    0.144 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.139    0.139 generic.py:10068(mask)\r\n        1    0.000    0.000    0.139    0.139 generic.py:9685(_where)\r\n        7    0.000    0.000    0.137    0.020 managers.py:392(apply)\r\n        1    0.000    0.000    0.137    0.137 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.136    0.136 blocks.py:1211(where)\r\n      500    0.001    0.000    0.092    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.071    0.000 common.py:702(is_integer_dtype)\r\n      500    0.069    0.000    0.069    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.010    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.002    0.000    0.009    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.001    0.000    0.004    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.003    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     1001    0.001    0.000    0.002    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55c3a7f37640}\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[375.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[375.002, "i", "cd ..\r"]
[375.004, "o", "cd ..\r\n"]
[375.006, "o", "\u001b[?2004l\r\n"]
[380.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[380.002, "i", "grep -R -n -F \"def mask(\" pandas/core | head -n 50\r"]
[380.004, "o", "grep -R -n -F \"def mask(\" pandas/core | head -n 50\r\n"]
[380.006, "o", "\u001b[?2004l\r\npandas/core/generic.py:10036:    def mask(\r\npandas/core/generic.py:10047:    def mask(\r\npandas/core/generic.py:10058:    def mask(\r\npandas/core/generic.py:10077:    def mask(\r\n"]
[385.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[385.002, "i", "grep -R -n -F \"def where(\" pandas/core | head -n 50\r"]
[385.004, "o", "grep -R -n -F \"def where(\" pandas/core | head -n 50\r\n"]
[385.006, "o", "\u001b[?2004l\r\npandas/core/computation/expressions.py:247:def where(cond, left_op, right_op, use_numexpr: bool = True):\r\npandas/core/generic.py:9831:    def where(\r\npandas/core/generic.py:9842:    def where(\r\npandas/core/generic.py:9853:    def where(\r\npandas/core/generic.py:9871:    def where(\r\npandas/core/indexes/base.py:5069:    def where(self, cond, other=None) -> Index:\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[390.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[390.002, "i", "grep -R -n -F \" where(\" pandas/core | head -n 50\r"]
[390.004, "o", "grep -R -n -F \" where(\" pandas/core | head -n 50\r\n"]
[390.006, "o", "\u001b[?2004l\r\npandas/core/computation/expressions.py:247:def where(cond, left_op, right_op, use_numexpr: bool = True):\r\npandas/core/generic.py:9831:    def where(\r\npandas/core/generic.py:9842:    def where(\r\npandas/core/generic.py:9853:    def where(\r\npandas/core/generic.py:9871:    def where(\r\npandas/core/indexes/base.py:5069:    def where(self, cond, other=None) -> Index:\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[395.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[395.002, "i", "sed -n '1,500p' pandas/core/generic.py\r"]
[395.004, "o", "sed -n '1,500p' pandas/core/generic.py\r\n"]
[395.006, "o", "\u001b[?2004l\r\n# pyright: reportPropertyTypeMismatch=false\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom copy import deepcopy\r\nimport datetime as dt\r\nfrom functools import partial\r\nfrom json import loads\r\nimport operator\r\nimport pickle\r\nimport re\r\nimport sys\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    ClassVar,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import config\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas._libs.tslibs import (\r\n    Period,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    AlignJoin,\r\n    AnyArrayLike,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    AxisInt,\r\n    CompressionOptions,\r\n    Concatenate,\r\n    DtypeArg,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FilePath,\r\n    FillnaOptions,\r\n    FloatFormatType,\r\n    FormattersType,\r\n    Frequency,\r\n    IgnoreRaise,\r\n    IndexKeyFunc,\r\n    IndexLabel,\r\n    InterpolateOptions,\r\n    IntervalClosedType,\r\n    JSONSerializable,\r\n    Level,\r\n    ListLike,\r\n    Manager,\r\n    NaPosition,\r\n    NDFrameT,\r\n    OpenFileErrors,\r\n    RandomState,\r\n    ReindexMethod,\r\n    Renamer,\r\n    Scalar,\r\n    Self,\r\n    SequenceNotStr,\r\n    SortKind,\r\n    StorageOptions,\r\n    Suffixes,\r\n    T,\r\n    TimeAmbiguous,\r\n    TimedeltaConvertibleTypes,\r\n    TimeNonexistent,\r\n    TimestampConvertibleTypes,\r\n    TimeUnit,\r\n    ValueKeyFunc,\r\n    WriteBuffer,\r\n    WriteExcelBuffer,\r\n    npt,\r\n)\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import _chained_assignment_method_msg\r\nfrom pandas.util._decorators import (\r\n    deprecate_kwarg,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import (\r\n    check_dtype_backend,\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_inclusive,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_is_view\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    ensure_str,\r\n    is_bool,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_extension_array_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_numeric_dtype,\r\n    is_re_compilable,\r\n    is_scalar,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import (\r\n    is_hashable,\r\n    is_nested_list_like,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms as algos,\r\n    arraylike,\r\n    common,\r\n    indexing,\r\n    missing,\r\n    nanops,\r\n    sample,\r\n)\r\nfrom pandas.core.array_algos.replace import should_use_regex\r\nfrom pandas.core.arrays import ExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import extract_array\r\nfrom pandas.core.flags import Flags\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    MultiIndex,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.methods.describe import describe_ndframe\r\nfrom pandas.core.missing import (\r\n    clean_fill_method,\r\n    clean_reindex_fill_method,\r\n    find_valid_index,\r\n)\r\nfrom pandas.core.reshape.concat import concat\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import get_indexer_indexer\r\nfrom pandas.core.window import (\r\n    Expanding,\r\n    ExponentialMovingWindow,\r\n    Rolling,\r\n    Window,\r\n)\r\n\r\nfrom pandas.io.formats.format import (\r\n    DataFrameFormatter,\r\n    DataFrameRenderer,\r\n)\r\nfrom pandas.io.formats.printing import pprint_thing\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Callable\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterator,\r\n        Mapping,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._libs.tslibs import BaseOffset\r\n    from pandas._typing import P\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        ExcelWriter,\r\n        HDFStore,\r\n        Series,\r\n    )\r\n    from pandas.core.indexers.objects import BaseIndexer\r\n    from pandas.core.resample import Resampler\r\n\r\nimport textwrap\r\n\r\n# goal is to be able to define the docs close to function, while still being\r\n# able to share\r\n_shared_docs = {**_shared_docs}\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"keywords for axes\",\r\n    \"klass\": \"Series/DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\",  # noqa: E501\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        If True, performs operation inplace and returns None.\"\"\",\r\n    \"optional_by\": \"\"\"\r\n        by : str or list of str\r\n            Name or list of names to sort by\"\"\",\r\n}\r\n\r\n\r\nclass NDFrame(PandasObject, indexing.IndexingMixin):\r\n    \"\"\"\r\n    N-dimensional analogue of DataFrame. Store multi-dimensional in a\r\n    size-mutable, labeled data structure\r\n\r\n    Parameters\r\n    ----------\r\n    data : BlockManager\r\n    axes : list\r\n    copy : bool, default False\r\n    \"\"\"\r\n\r\n    _internal_names: list[str] = [\r\n        \"_mgr\",\r\n        \"_item_cache\",\r\n        \"_cache\",\r\n        \"_name\",\r\n        \"_metadata\",\r\n        \"_flags\",\r\n    ]\r\n    _internal_names_set: set[str] = set(_internal_names)\r\n    _accessors: set[str] = set()\r\n    _hidden_attrs: frozenset[str] = frozenset([])\r\n    _metadata: list[str] = []\r\n    _mgr: Manager\r\n    _attrs: dict[Hashable, Any]\r\n    _typ: str\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __init__(self, data: Manager) -> None:\r\n        object.__setattr__(self, \"_mgr\", data)\r\n        object.__setattr__(self, \"_attrs\", {})\r\n        object.__setattr__(self, \"_flags\", Flags(self, allows_duplicate_labels=True))\r\n\r\n    @final\r\n    @classmethod\r\n    def _init_mgr(\r\n        cls,\r\n        mgr: Manager,\r\n        axes: dict[Literal[\"index\", \"columns\"], Axes | None],\r\n        dtype: DtypeObj | None = None,\r\n        copy: bool = False,\r\n    ) -> Manager:\r\n        \"\"\"passed a manager and a axes dict\"\"\"\r\n        for a, axe in axes.items():\r\n            if axe is not None:\r\n                axe = ensure_index(axe)\r\n                bm_axis = cls._get_block_manager_axis(a)\r\n                mgr = mgr.reindex_axis(axe, axis=bm_axis)\r\n\r\n        # make a copy if explicitly requested\r\n        if copy:\r\n            mgr = mgr.copy()\r\n        if dtype is not None:\r\n            # avoid further copies if we can\r\n            if (\r\n                isinstance(mgr, BlockManager)\r\n                and len(mgr.blocks) == 1\r\n                and mgr.blocks[0].values.dtype == dtype\r\n            ):\r\n                pass\r\n            else:\r\n                mgr = mgr.astype(dtype=dtype)\r\n        return mgr\r\n\r\n    @final\r\n    @classmethod\r\n    def _from_mgr(cls, mgr: Manager, axes: list[Index]) -> Self:\r\n        \"\"\"\r\n        Construct a new object of this type from a Manager object and axes.\r\n\r\n        Parameters\r\n        ----------\r\n        mgr : Manager\r\n            Must have the same ndim as cls.\r\n        axes : list[Index]\r\n\r\n        Notes\r\n        -----\r\n        The axes must match mgr.axes, but are required for future-proofing\r\n        in the event that axes are refactored out of the Manager objects.\r\n        \"\"\"\r\n        obj = cls.__new__(cls)\r\n        NDFrame.__init__(obj, mgr)\r\n        return obj\r\n\r\n    # ----------------------------------------------------------------------\r\n    # attrs and flags\r\n\r\n    @property\r\n    def attrs(self) -> dict[Hashable, Any]:\r\n        \"\"\"\r\n        Dictionary of global attributes of this dataset.\r\n\r\n        .. warning::\r\n\r\n           attrs is experimental and may change without warning.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.flags : Global flags applying to this object.\r\n\r\n        Notes\r\n        -----\r\n        Many operations that create new datasets will copy ``attrs``. Copies\r\n        are always deep so that changing ``attrs`` will only affect the\r\n        present dataset. ``pandas.concat`` copies ``attrs`` only if all input\r\n        datasets have the same ``attrs``.\r\n\r\n        Examples\r\n        --------\r\n        For Series:\r\n\r\n        >>> ser = pd.Series([1, 2, 3])\r\n        >>> ser.attrs = {\"A\": [10, 20, 30]}\r\n        >>> ser.attrs\r\n        {'A': [10, 20, 30]}\r\n\r\n        For DataFrame:\r\n\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n        >>> df.attrs = {\"A\": [10, 20, 30]}\r\n        >>> df.attrs\r\n        {'A': [10, 20, 30]}\r\n        \"\"\"\r\n        return self._attrs\r\n\r\n    @attrs.setter\r\n    def attrs(self, value: Mapping[Hashable, Any]) -> None:\r\n        self._attrs = dict(value)\r\n\r\n    @final\r\n    @property\r\n    def flags(self) -> Flags:\r\n        \"\"\"\r\n        Get the properties associated with this pandas object.\r\n\r\n        The available flags are\r\n\r\n        * :attr:`Flags.allows_duplicate_labels`\r\n\r\n        See Also\r\n        --------\r\n        Flags : Flags that apply to pandas objects.\r\n        DataFrame.attrs : Global metadata applying to this dataset.\r\n\r\n        Notes\r\n        -----\r\n        \"Flags\" differ from \"metadata\". Flags reflect properties of the\r\n        pandas object (the Series or DataFrame). Metadata refer to properties\r\n        of the dataset, and should be stored in :attr:`DataFrame.attrs`.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2]})\r\n        >>> df.flags\r\n        <Flags(allows_duplicate_labels=True)>\r\n\r\n        Flags can be get or set using ``.``\r\n\r\n        >>> df.flags.allows_duplicate_labels\r\n        True\r\n        >>> df.flags.allows_duplicate_labels = False\r\n\r\n        Or by slicing with a key\r\n\r\n        >>> df.flags[\"allows_duplicate_labels\"]\r\n        False\r\n        >>> df.flags[\"allows_duplicate_labels\"] = True\r\n        \"\"\"\r\n        return self._flags\r\n\r\n    @final\r\n    def set_flags(\r\n        self,\r\n        *,\r\n        copy: bool | lib.NoDefault = lib.no_default,\r\n        allows_duplicate_labels: bool | None = None,\r\n    ) -> Self:\r\n        \"\"\"\r\n        Return a new object with updated flags.\r\n\r\n        This method creates a shallow copy of the original object, preserving its\r\n        underlying data while modifying its global flags. In particular, it allows\r\n        you to update properties such as whether duplicate labels are permitted. This\r\n        behavior is especially useful in method chains, where one wishes to\r\n        adjust DataFrame or Series characteristics without altering the original object.\r\n\r\n        Parameters\r\n        ----------\r\n        copy : bool, default False\r\n            Specify if a copy of the object should be made.\r\n\r\n            .. note::\r\n                The `copy` keyword will change behavior in pandas 3.0.\r\n                `Copy-on-Write\r\n                <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\r\n                will be enabled by default, which means that all methods with a\r\n                `copy` keyword will use a lazy copy mechanism to defer the copy and\r\n                ignore the `copy` keyword. The `copy` keyword will be removed in a\r\n                future version of pandas.\r\n\r\n                You can already get the future behavior and improvements through\r\n                enabling copy on write ``pd.options.mode.copy_on_write = True``\r\n\r\n            .. deprecated:: 3.0.0\r\n        allows_duplicate_labels : bool, optional\r\n            Whether the returned object allows duplicate labels.\r\n\r\n        Returns\r\n        -------\r\n        Series or DataFrame\r\n            The same type as the caller.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.attrs : Global metadata applying to this dataset.\r\n        DataFrame.flags : Global flags applying to this object.\r\n\r\n        Notes\r\n        -----\r\n        This method returns a new object that's a view on the same data\r\n        as the input. Mutating the input or the output values will be reflected\r\n        in the other.\r\n\r\n        This method is intended to be used in method chains.\r\n\r\n        \"Flags\" differ from \"metadata\". Flags reflect properties of the\r\n        pandas object (the Series or DataFrame). Metadata refer to properties\r\n        of the dataset, and should be stored in :attr:`DataFrame.attrs`.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2]})\r\n        >>> df.flags.allows_duplicate_labels\r\n        True\r\n        >>> df2 = df.set_flags(allows_duplicate_labels=False)\r\n        >>> df2.flags.allows_duplicate_labels\r\n        False\r\n        \"\"\"\r\n        self._check_copy_deprecation(copy)\r\n        df = self.copy(deep=False)\r\n        if allows_duplicate_labels is not None:\r\n            df.flags[\"allows_duplicate_labels\"] = allows_duplicate_labels\r\n        return df\r\n\r\n    @final\r\n    @classmethod\r\n    def _validate_dtype(cls, dtype) -> DtypeObj | None:\r\n        \"\"\"validate the passed dtype\"\"\"\r\n        if dtype is not None:\r\n            dtype = pandas_dtype(dtype)\r\n\r\n            # a compound dtype\r\n            if dtype.kind == \"V\":\r\n                raise NotImplementedError(\r\n                    \"compound dtypes are not implemented \"\r\n                    f\"in the {cls.__name__} constructor\"\r\n                )\r\n\r\n        return dtype\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Construction\r\n\r\n    # error: Signature of \"_constructor\" incompatible with supertype \"PandasObject\"\r\n    @property\r\n    def _constructor(self) -> Callable[..., Self]:  # type: ignore[override]\r\n        \"\"\"\r\n        Used when a manipulation result has the same dimensions as the\r\n        original.\r\n        \"\"\"\r\n        raise AbstractMethodError(self)\r\n\r\n"]
[400.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[400.002, "i", "sed -n '1,500p' pandas/core/internals/blocks.py\r"]
[400.004, "o", "sed -n '1,500p' pandas/core/internals/blocks.py\r\n"]
[400.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nimport inspect\r\nimport re\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    final,\r\n)\r\nimport warnings\r\nimport weakref\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    internals as libinternals,\r\n    lib,\r\n)\r\nfrom pandas._libs.internals import (\r\n    BlockPlacement,\r\n    BlockValuesRefs,\r\n)\r\nfrom pandas._libs.missing import NA\r\nfrom pandas._typing import (\r\n    ArrayLike,\r\n    AxisInt,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FillnaOptions,\r\n    IgnoreRaise,\r\n    InterpolateOptions,\r\n    QuantileInterpolation,\r\n    Self,\r\n    Shape,\r\n    npt,\r\n)\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    OutOfBoundsDatetime,\r\n)\r\nfrom pandas.util._decorators import cache_readonly\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import validate_bool_kwarg\r\n\r\nfrom pandas.core.dtypes.astype import (\r\n    astype_array_safe,\r\n    astype_is_view,\r\n)\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    convert_dtypes,\r\n    find_result_type,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    is_1d_only_ea_dtype,\r\n    is_float_dtype,\r\n    is_integer_dtype,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_string_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    IntervalDtype,\r\n    NumpyEADtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCIndex,\r\n    ABCNumpyExtensionArray,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import is_re\r\nfrom pandas.core.dtypes.missing import (\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n    na_value_for_dtype,\r\n)\r\n\r\nfrom pandas.core import missing\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.array_algos.putmask import (\r\n    extract_bool_array,\r\n    putmask_inplace,\r\n    putmask_without_repeat,\r\n    setitem_datetimelike_compat,\r\n    validate_putmask,\r\n)\r\nfrom pandas.core.array_algos.quantile import quantile_compat\r\nfrom pandas.core.array_algos.replace import (\r\n    compare_or_regex_search,\r\n    replace_regex,\r\n    should_use_regex,\r\n)\r\nfrom pandas.core.array_algos.transforms import shift\r\nfrom pandas.core.arrays import (\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    IntervalArray,\r\n    NumpyExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.string_ import StringDtype\r\nfrom pandas.core.base import PandasObject\r\nimport pandas.core.common as com\r\nfrom pandas.core.computation import expressions\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n)\r\nfrom pandas.core.indexers import check_setitem_lengths\r\nfrom pandas.core.indexes.base import get_values_for_csv\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Callable,\r\n        Generator,\r\n        Iterable,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas.core.api import Index\r\n    from pandas.core.arrays._mixins import NDArrayBackedExtensionArray\r\n\r\n# comparison is faster than is_object_dtype\r\n_dtype_obj = np.dtype(\"object\")\r\n\r\n\r\nclass Block(PandasObject, libinternals.Block):\r\n    \"\"\"\r\n    Canonical n-dimensional unit of homogeneous dtype contained in a pandas\r\n    data structure\r\n\r\n    Index-ignorant; let the container take care of that\r\n    \"\"\"\r\n\r\n    values: np.ndarray | ExtensionArray\r\n    ndim: int\r\n    refs: BlockValuesRefs\r\n    __init__: Callable\r\n\r\n    __slots__ = ()\r\n    is_numeric = False\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _validate_ndim(self) -> bool:\r\n        \"\"\"\r\n        We validate dimension for blocks that can hold 2D values, which for now\r\n        means numpy dtypes or DatetimeTZDtype.\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        return not isinstance(dtype, ExtensionDtype) or isinstance(\r\n            dtype, DatetimeTZDtype\r\n        )\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_object(self) -> bool:\r\n        return self.values.dtype == _dtype_obj\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_extension(self) -> bool:\r\n        return not lib.is_np_dtype(self.values.dtype)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_consolidate(self) -> bool:\r\n        # We _could_ consolidate for DatetimeTZDtype but don't for now.\r\n        return not self.is_extension\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _consolidate_key(self):\r\n        return self._can_consolidate, self.dtype.name\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_hold_na(self) -> bool:\r\n        \"\"\"\r\n        Can we store NA values in this Block?\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        if isinstance(dtype, np.dtype):\r\n            return dtype.kind not in \"iub\"\r\n        return dtype._can_hold_na\r\n\r\n    @final\r\n    @property\r\n    def is_bool(self) -> bool:\r\n        \"\"\"\r\n        We can be bool if a) we are bool dtype or b) object dtype with bool objects.\r\n        \"\"\"\r\n        return self.values.dtype == np.dtype(bool)\r\n\r\n    @final\r\n    def external_values(self):\r\n        return external_values(self.values)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        return na_value_for_dtype(self.dtype, compat=False)\r\n\r\n    @final\r\n    def _standardize_fill_value(self, value):\r\n        # if we are passed a scalar None, convert it here\r\n        if self.dtype != _dtype_obj and is_valid_na_for_dtype(value, self.dtype):\r\n            value = self.fill_value\r\n        return value\r\n\r\n    @property\r\n    def mgr_locs(self) -> BlockPlacement:\r\n        return self._mgr_locs\r\n\r\n    @mgr_locs.setter\r\n    def mgr_locs(self, new_mgr_locs: BlockPlacement) -> None:\r\n        self._mgr_locs = new_mgr_locs\r\n\r\n    @final\r\n    def make_block(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Create a new block, with type inference propagate any values that are\r\n        not specified\r\n        \"\"\"\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n        if self.is_extension:\r\n            values = ensure_block_shape(values, ndim=self.ndim)\r\n\r\n        return new_block(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def make_block_same_class(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Self:\r\n        \"\"\"Wrap given values in a block of same type as self.\"\"\"\r\n        # Pre-2.0 we called ensure_wrapped_if_datetimelike because fastparquet\r\n        #  relied on it, as of 2.0 the caller is responsible for this.\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n\r\n        # We assume maybe_coerce_values has already been called\r\n        return type(self)(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def __repr__(self) -> str:\r\n        # don't want to print out all of the items here\r\n        name = type(self).__name__\r\n        if self.ndim == 1:\r\n            result = f\"{name}: {len(self)} dtype: {self.dtype}\"\r\n        else:\r\n            shape = \" x \".join([str(s) for s in self.shape])\r\n            result = f\"{name}: {self.mgr_locs.indexer}, {shape}, dtype: {self.dtype}\"\r\n\r\n        return result\r\n\r\n    @final\r\n    def __len__(self) -> int:\r\n        return len(self.values)\r\n\r\n    @final\r\n    def slice_block_columns(self, slc: slice) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n        \"\"\"\r\n        new_mgr_locs = self._mgr_locs[slc]\r\n\r\n        new_values = self._slice(slc)\r\n        refs = self.refs\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def take_block_columns(self, indices: npt.NDArray[np.intp]) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        # Note: only called from is from internals.concat, and we can verify\r\n        #  that never happens with 1-column blocks, i.e. never for ExtensionBlock.\r\n\r\n        new_mgr_locs = self._mgr_locs[indices]\r\n\r\n        new_values = self._slice(indices)\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=None)\r\n\r\n    @final\r\n    def getitem_block_columns(\r\n        self, slicer: slice, new_mgr_locs: BlockPlacement, ref_inplace_op: bool = False\r\n    ) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        new_values = self._slice(slicer)\r\n        refs = self.refs if not ref_inplace_op or self.refs.has_reference() else None\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def _can_hold_element(self, element: Any) -> bool:\r\n        \"\"\"require the same dtype as ourselves\"\"\"\r\n        element = extract_array(element, extract_numpy=True)\r\n        return can_hold_element(self.values, element)\r\n\r\n    @final\r\n    def should_store(self, value: ArrayLike) -> bool:\r\n        \"\"\"\r\n        Should we set self.values[indexer] = value inplace or do we need to cast?\r\n\r\n        Parameters\r\n        ----------\r\n        value : np.ndarray or ExtensionArray\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n        \"\"\"\r\n        return value.dtype == self.dtype\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Apply/Reduce and Helpers\r\n\r\n    @final\r\n    def apply(self, func, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        apply the function to my values; return a block if we are not\r\n        one\r\n        \"\"\"\r\n        result = func(self.values, **kwargs)\r\n\r\n        result = maybe_coerce_values(result)\r\n        return self._split_op_result(result)\r\n\r\n    @final\r\n    def reduce(self, func) -> list[Block]:\r\n        # We will apply the function and reshape the result into a single-row\r\n        #  Block with the same mgr_locs; squeezing will be done at a higher level\r\n        assert self.ndim == 2\r\n\r\n        result = func(self.values)\r\n\r\n        if self.values.ndim == 1:\r\n            res_values = result\r\n        else:\r\n            res_values = result.reshape(-1, 1)\r\n\r\n        nb = self.make_block(res_values)\r\n        return [nb]\r\n\r\n    @final\r\n    def _split_op_result(self, result: ArrayLike) -> list[Block]:\r\n        # See also: split_and_operate\r\n        if result.ndim > 1 and isinstance(result.dtype, ExtensionDtype):\r\n            # TODO(EA2D): unnecessary with 2D EAs\r\n            # if we get a 2D ExtensionArray, we need to split it into 1D pieces\r\n            nbs = []\r\n            for i, loc in enumerate(self._mgr_locs):\r\n                if not is_1d_only_ea_dtype(result.dtype):\r\n                    vals = result[i : i + 1]\r\n                else:\r\n                    vals = result[i]\r\n\r\n                bp = BlockPlacement(loc)\r\n                block = self.make_block(values=vals, placement=bp)\r\n                nbs.append(block)\r\n            return nbs\r\n\r\n        nb = self.make_block(result)\r\n\r\n        return [nb]\r\n\r\n    @final\r\n    def _split(self) -> Generator[Block]:\r\n        \"\"\"\r\n        Split a block into a list of single-column blocks.\r\n        \"\"\"\r\n        assert self.ndim == 2\r\n\r\n        for i, ref_loc in enumerate(self._mgr_locs):\r\n            vals = self.values[slice(i, i + 1)]\r\n\r\n            bp = BlockPlacement(ref_loc)\r\n            nb = type(self)(vals, placement=bp, ndim=2, refs=self.refs)\r\n            yield nb\r\n\r\n    @final\r\n    def split_and_operate(self, func, *args, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        Split the block and apply func column-by-column.\r\n\r\n        Parameters\r\n        ----------\r\n        func : Block method\r\n        *args\r\n        **kwargs\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        assert self.ndim == 2 and self.shape[0] != 1\r\n\r\n        res_blocks = []\r\n        for nb in self._split():\r\n            rbs = func(nb, *args, **kwargs)\r\n            res_blocks.extend(rbs)\r\n        return res_blocks\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Up/Down-casting\r\n\r\n    @final\r\n    def coerce_to_target_dtype(self, other, raise_on_upcast: bool) -> Block:\r\n        \"\"\"\r\n        coerce the current block to a dtype compat for other\r\n        we will return a block, possibly object, and not raise\r\n\r\n        we can also safely try to coerce to the same dtype\r\n        and will receive the same block\r\n        \"\"\"\r\n        new_dtype = find_result_type(self.values.dtype, other)\r\n        if new_dtype == self.dtype:\r\n            # GH#52927 avoid RecursionError\r\n            raise AssertionError(\r\n                \"Something has gone wrong, please report a bug at \"\r\n                \"https://github.com/pandas-dev/pandas/issues\"\r\n            )\r\n\r\n        # In a future version of pandas, the default will be that\r\n        # setting `nan` into an integer series won't raise.\r\n        if (\r\n            is_scalar(other)\r\n            and is_integer_dtype(self.values.dtype)\r\n            and isna(other)\r\n            and other is not NaT\r\n            and not (\r\n                isinstance(other, (np.datetime64, np.timedelta64)) and np.isnat(other)\r\n            )\r\n        ):\r\n            raise_on_upcast = False\r\n        elif (\r\n            isinstance(other, np.ndarray)\r\n            and other.ndim == 1\r\n            and is_integer_dtype(self.values.dtype)\r\n            and is_float_dtype(other.dtype)\r\n            and lib.has_only_ints_or_nan(other)\r\n        ):\r\n            raise_on_upcast = False\r\n\r\n        if raise_on_upcast:\r\n            raise TypeError(f\"Invalid value '{other}' for dtype '{self.values.dtype}'\")\r\n        if self.values.dtype == new_dtype:\r\n            raise AssertionError(\r\n                f\"Did not expect new dtype {new_dtype} to equal self.dtype \"\r\n                f\"{self.values.dtype}. Please report a bug at \"\r\n                \"https://github.com/pandas-dev/pandas/issues.\"\r\n            )\r\n        try:\r\n            return self.astype(new_dtype)\r\n        except OutOfBoundsDatetime as err:\r\n            # e.g. GH#56419 if self.dtype is a low-resolution dt64 and we try to\r\n            #  upcast to a higher-resolution dt64, we may have entries that are\r\n            #  out of bounds for the higher resolution.\r\n            #  Re-raise with a more informative message.\r\n            raise OutOfBoundsDatetime(\r\n                f\"Incompatible (high-resolution) value for dtype='{self.dtype}'. \"\r\n                \"Explicitly cast before operating.\"\r\n            ) from err\r\n\r\n    @final\r\n    def convert(self) -> list[Block]:\r\n        \"\"\"\r\n        Attempt to coerce any object types to better types. Return a copy\r\n        of the block (if copy = True).\r\n        \"\"\"\r\n        if not self.is_object:\r\n            return [self.copy(deep=False)]\r\n\r\n        if self.ndim != 1 and self.shape[0] != 1:\r\n            blocks = self.split_and_operate(Block.convert)\r\n"]
[405.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[405.002, "i", "cd asv_bench\r"]
[405.004, "o", "cd asv_bench\r\n"]
[405.006, "o", "\u001b[?2004l\r\n"]
[410.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[410.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools | tee ../pr\r"]
[410.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools | tee ../pr\r\n"]
[410.006, "o", "rofile_maskbool.txt\r\n\u001b[?2004l\r\n\u00b7 Discovering benchmarks\r\n\u00b7 Profile data does not already exist. Running profiler now.\r\n\u00b7\u00b7 Benchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\r\n\u00b7\u00b7\u00b7 Importing benchmark suite produced output:\r\n\u00b7\u00b7\u00b7\u00b7 meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 Running (frame_methods.MaskBool.time_frame_mask_bools--).\r\n\u00b7\u00b7\u00b7 frame_methods.MaskBool.time_frame_mask_bools            48.0\u00b10.1ms\r\n\r\nWed Oct  1 17:19:38 2025    /tmp/tmps_vfixw8\r\n\r\n         83260 function calls (82244 primitive calls) in 0.142 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.142    0.142 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.142    0.142 _base.py:689(method_caller)\r\n        1    0.005    0.005    0.142    0.142 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.137    0.137 generic.py:10068(mask)\r\n        1    0.000    0.000    0.137    0.137 generic.py:9685(_where)\r\n        7    0.000    0.000    0.135    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.135    0.135 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.134    0.134 blocks.py:1211(where)\r\n      500    0.001    0.000    0.090    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.070    0.000 common.py:702(is_integer_dtype)\r\n      500    0.068    0.000    0.068    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.003    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.001    0.000    0.004    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.002    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.002    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55e22b0c8640}\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[415.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[415.002, "i", "cd ..\r"]
[415.004, "o", "cd ..\r\n"]
[415.006, "o", "\u001b[?2004l\r\n"]
[420.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[420.002, "i", "sed -n '1,200p' profile_maskbool.txt\r"]
[420.004, "o", "sed -n '1,200p' profile_maskbool.txt\r\n"]
[420.006, "o", "\u001b[?2004l\r\n\u00b7 Discovering benchmarks\r\n\u00b7 Profile data does not already exist. Running profiler now.\r\n\u00b7\u00b7 Benchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\r\n\u00b7\u00b7\u00b7 Importing benchmark suite produced output:\r\n\u00b7\u00b7\u00b7\u00b7 meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 Running (frame_methods.MaskBool.time_frame_mask_bools--).\r\n\u00b7\u00b7\u00b7 frame_methods.MaskBool.time_frame_mask_bools            48.0\u00b10.1ms\r\n\r\nWed Oct  1 17:19:38 2025    /tmp/tmps_vfixw8\r\n\r\n         83260 function calls (82244 primitive calls) in 0.142 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.142    0.142 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.142    0.142 _base.py:689(method_caller)\r\n        1    0.005    0.005    0.142    0.142 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.137    0.137 generic.py:10068(mask)\r\n        1    0.000    0.000    0.137    0.137 generic.py:9685(_where)\r\n        7    0.000    0.000    0.135    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.135    0.135 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.134    0.134 blocks.py:1211(where)\r\n      500    0.001    0.000    0.090    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.070    0.000 common.py:702(is_integer_dtype)\r\n      500    0.068    0.000    0.068    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.003    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.001    0.000    0.004    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.002    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.002    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55e22b0c8640}\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n"]
[425.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[425.002, "i", "grep -R -n -F \"def mask(\" pandas/core | head -n 50\r"]
[425.004, "o", "grep -R -n -F \"def mask(\" pandas/core | head -n 50\r\n"]
[425.006, "o", "\u001b[?2004l\r\npandas/core/generic.py:10036:    def mask(\r\npandas/core/generic.py:10047:    def mask(\r\npandas/core/generic.py:10058:    def mask(\r\npandas/core/generic.py:10077:    def mask(\r\n"]
[430.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[430.002, "i", "grep -R -n -F \"def where(\" pandas/core | head -n 50\r"]
[430.004, "o", "grep -R -n -F \"def where(\" pandas/core | head -n 50\r\n"]
[430.006, "o", "\u001b[?2004l\r\npandas/core/computation/expressions.py:247:def where(cond, left_op, right_op, use_numexpr: bool = True):\r\npandas/core/generic.py:9831:    def where(\r\npandas/core/generic.py:9842:    def where(\r\npandas/core/generic.py:9853:    def where(\r\npandas/core/generic.py:9871:    def where(\r\npandas/core/indexes/base.py:5069:    def where(self, cond, other=None) -> Index:\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[435.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[435.002, "i", "grep -R -n \" def where\" pandas/core/internals | head -n 50\r"]
[435.004, "o", "grep -R -n \" def where\" pandas/core/internals | head -n 50\r\n"]
[435.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[440.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[440.002, "i", "grep -R -n \" def putmask\" pandas/core/internals | head -n 50\r"]
[440.004, "o", "grep -R -n \" def putmask\" pandas/core/internals | head -n 50\r\n"]
[440.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1144:    def putmask(self, mask, new) -> list[Block]:\r\npandas/core/internals/blocks.py:1728:    def putmask(self, mask, new) -> list[Block]:\r\npandas/core/internals/managers.py:477:    def putmask(self, mask, new, align: bool = True) -> Self:\r\n"]
[445.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[445.002, "i", "sed -n '1,240p' pandas/core/generic.py\r"]
[445.004, "o", "sed -n '1,240p' pandas/core/generic.py\r\n"]
[445.006, "o", "\u001b[?2004l\r\n# pyright: reportPropertyTypeMismatch=false\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom copy import deepcopy\r\nimport datetime as dt\r\nfrom functools import partial\r\nfrom json import loads\r\nimport operator\r\nimport pickle\r\nimport re\r\nimport sys\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    ClassVar,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import config\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas._libs.tslibs import (\r\n    Period,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    AlignJoin,\r\n    AnyArrayLike,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    AxisInt,\r\n    CompressionOptions,\r\n    Concatenate,\r\n    DtypeArg,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FilePath,\r\n    FillnaOptions,\r\n    FloatFormatType,\r\n    FormattersType,\r\n    Frequency,\r\n    IgnoreRaise,\r\n    IndexKeyFunc,\r\n    IndexLabel,\r\n    InterpolateOptions,\r\n    IntervalClosedType,\r\n    JSONSerializable,\r\n    Level,\r\n    ListLike,\r\n    Manager,\r\n    NaPosition,\r\n    NDFrameT,\r\n    OpenFileErrors,\r\n    RandomState,\r\n    ReindexMethod,\r\n    Renamer,\r\n    Scalar,\r\n    Self,\r\n    SequenceNotStr,\r\n    SortKind,\r\n    StorageOptions,\r\n    Suffixes,\r\n    T,\r\n    TimeAmbiguous,\r\n    TimedeltaConvertibleTypes,\r\n    TimeNonexistent,\r\n    TimestampConvertibleTypes,\r\n    TimeUnit,\r\n    ValueKeyFunc,\r\n    WriteBuffer,\r\n    WriteExcelBuffer,\r\n    npt,\r\n)\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import _chained_assignment_method_msg\r\nfrom pandas.util._decorators import (\r\n    deprecate_kwarg,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import (\r\n    check_dtype_backend,\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_inclusive,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_is_view\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    ensure_str,\r\n    is_bool,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_extension_array_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_numeric_dtype,\r\n    is_re_compilable,\r\n    is_scalar,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import (\r\n    is_hashable,\r\n    is_nested_list_like,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms as algos,\r\n    arraylike,\r\n    common,\r\n    indexing,\r\n    missing,\r\n    nanops,\r\n    sample,\r\n)\r\nfrom pandas.core.array_algos.replace import should_use_regex\r\nfrom pandas.core.arrays import ExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import extract_array\r\nfrom pandas.core.flags import Flags\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    MultiIndex,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.methods.describe import describe_ndframe\r\nfrom pandas.core.missing import (\r\n    clean_fill_method,\r\n    clean_reindex_fill_method,\r\n    find_valid_index,\r\n)\r\nfrom pandas.core.reshape.concat import concat\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import get_indexer_indexer\r\nfrom pandas.core.window import (\r\n    Expanding,\r\n    ExponentialMovingWindow,\r\n    Rolling,\r\n    Window,\r\n)\r\n\r\nfrom pandas.io.formats.format import (\r\n    DataFrameFormatter,\r\n    DataFrameRenderer,\r\n)\r\nfrom pandas.io.formats.printing import pprint_thing\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Callable\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterator,\r\n        Mapping,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._libs.tslibs import BaseOffset\r\n    from pandas._typing import P\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        ExcelWriter,\r\n        HDFStore,\r\n        Series,\r\n    )\r\n    from pandas.core.indexers.objects import BaseIndexer\r\n    from pandas.core.resample import Resampler\r\n\r\nimport textwrap\r\n\r\n# goal is to be able to define the docs close to function, while still being\r\n# able to share\r\n_shared_docs = {**_shared_docs}\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"keywords for axes\",\r\n    \"klass\": \"Series/DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\",  # noqa: E501\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        If True, performs operation inplace and returns None.\"\"\",\r\n    \"optional_by\": \"\"\"\r\n        by : str or list of str\r\n            Name or list of names to sort by\"\"\",\r\n}\r\n\r\n\r\nclass NDFrame(PandasObject, indexing.IndexingMixin):\r\n    \"\"\"\r\n    N-dimensional analogue of DataFrame. Store multi-dimensional in a\r\n    size-mutable, labeled data structure\r\n\r\n    Parameters\r\n    ----------\r\n    data : BlockManager\r\n    axes : list\r\n    copy : bool, default False\r\n    \"\"\"\r\n\r\n    _internal_names: list[str] = [\r\n        \"_mgr\",\r\n        \"_item_cache\",\r\n        \"_cache\",\r\n"]
[450.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[450.002, "i", "sed -n '1,400p' pandas/core/internals/blocks.py\r"]
[450.004, "o", "sed -n '1,400p' pandas/core/internals/blocks.py\r\n"]
[450.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nimport inspect\r\nimport re\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    final,\r\n)\r\nimport warnings\r\nimport weakref\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    internals as libinternals,\r\n    lib,\r\n)\r\nfrom pandas._libs.internals import (\r\n    BlockPlacement,\r\n    BlockValuesRefs,\r\n)\r\nfrom pandas._libs.missing import NA\r\nfrom pandas._typing import (\r\n    ArrayLike,\r\n    AxisInt,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FillnaOptions,\r\n    IgnoreRaise,\r\n    InterpolateOptions,\r\n    QuantileInterpolation,\r\n    Self,\r\n    Shape,\r\n    npt,\r\n)\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    OutOfBoundsDatetime,\r\n)\r\nfrom pandas.util._decorators import cache_readonly\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import validate_bool_kwarg\r\n\r\nfrom pandas.core.dtypes.astype import (\r\n    astype_array_safe,\r\n    astype_is_view,\r\n)\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    convert_dtypes,\r\n    find_result_type,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    is_1d_only_ea_dtype,\r\n    is_float_dtype,\r\n    is_integer_dtype,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_string_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    IntervalDtype,\r\n    NumpyEADtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCIndex,\r\n    ABCNumpyExtensionArray,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import is_re\r\nfrom pandas.core.dtypes.missing import (\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n    na_value_for_dtype,\r\n)\r\n\r\nfrom pandas.core import missing\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.array_algos.putmask import (\r\n    extract_bool_array,\r\n    putmask_inplace,\r\n    putmask_without_repeat,\r\n    setitem_datetimelike_compat,\r\n    validate_putmask,\r\n)\r\nfrom pandas.core.array_algos.quantile import quantile_compat\r\nfrom pandas.core.array_algos.replace import (\r\n    compare_or_regex_search,\r\n    replace_regex,\r\n    should_use_regex,\r\n)\r\nfrom pandas.core.array_algos.transforms import shift\r\nfrom pandas.core.arrays import (\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    IntervalArray,\r\n    NumpyExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.string_ import StringDtype\r\nfrom pandas.core.base import PandasObject\r\nimport pandas.core.common as com\r\nfrom pandas.core.computation import expressions\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n)\r\nfrom pandas.core.indexers import check_setitem_lengths\r\nfrom pandas.core.indexes.base import get_values_for_csv\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Callable,\r\n        Generator,\r\n        Iterable,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas.core.api import Index\r\n    from pandas.core.arrays._mixins import NDArrayBackedExtensionArray\r\n\r\n# comparison is faster than is_object_dtype\r\n_dtype_obj = np.dtype(\"object\")\r\n\r\n\r\nclass Block(PandasObject, libinternals.Block):\r\n    \"\"\"\r\n    Canonical n-dimensional unit of homogeneous dtype contained in a pandas\r\n    data structure\r\n\r\n    Index-ignorant; let the container take care of that\r\n    \"\"\"\r\n\r\n    values: np.ndarray | ExtensionArray\r\n    ndim: int\r\n    refs: BlockValuesRefs\r\n    __init__: Callable\r\n\r\n    __slots__ = ()\r\n    is_numeric = False\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _validate_ndim(self) -> bool:\r\n        \"\"\"\r\n        We validate dimension for blocks that can hold 2D values, which for now\r\n        means numpy dtypes or DatetimeTZDtype.\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        return not isinstance(dtype, ExtensionDtype) or isinstance(\r\n            dtype, DatetimeTZDtype\r\n        )\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_object(self) -> bool:\r\n        return self.values.dtype == _dtype_obj\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_extension(self) -> bool:\r\n        return not lib.is_np_dtype(self.values.dtype)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_consolidate(self) -> bool:\r\n        # We _could_ consolidate for DatetimeTZDtype but don't for now.\r\n        return not self.is_extension\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _consolidate_key(self):\r\n        return self._can_consolidate, self.dtype.name\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_hold_na(self) -> bool:\r\n        \"\"\"\r\n        Can we store NA values in this Block?\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        if isinstance(dtype, np.dtype):\r\n            return dtype.kind not in \"iub\"\r\n        return dtype._can_hold_na\r\n\r\n    @final\r\n    @property\r\n    def is_bool(self) -> bool:\r\n        \"\"\"\r\n        We can be bool if a) we are bool dtype or b) object dtype with bool objects.\r\n        \"\"\"\r\n        return self.values.dtype == np.dtype(bool)\r\n\r\n    @final\r\n    def external_values(self):\r\n        return external_values(self.values)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        return na_value_for_dtype(self.dtype, compat=False)\r\n\r\n    @final\r\n    def _standardize_fill_value(self, value):\r\n        # if we are passed a scalar None, convert it here\r\n        if self.dtype != _dtype_obj and is_valid_na_for_dtype(value, self.dtype):\r\n            value = self.fill_value\r\n        return value\r\n\r\n    @property\r\n    def mgr_locs(self) -> BlockPlacement:\r\n        return self._mgr_locs\r\n\r\n    @mgr_locs.setter\r\n    def mgr_locs(self, new_mgr_locs: BlockPlacement) -> None:\r\n        self._mgr_locs = new_mgr_locs\r\n\r\n    @final\r\n    def make_block(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Create a new block, with type inference propagate any values that are\r\n        not specified\r\n        \"\"\"\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n        if self.is_extension:\r\n            values = ensure_block_shape(values, ndim=self.ndim)\r\n\r\n        return new_block(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def make_block_same_class(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Self:\r\n        \"\"\"Wrap given values in a block of same type as self.\"\"\"\r\n        # Pre-2.0 we called ensure_wrapped_if_datetimelike because fastparquet\r\n        #  relied on it, as of 2.0 the caller is responsible for this.\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n\r\n        # We assume maybe_coerce_values has already been called\r\n        return type(self)(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def __repr__(self) -> str:\r\n        # don't want to print out all of the items here\r\n        name = type(self).__name__\r\n        if self.ndim == 1:\r\n            result = f\"{name}: {len(self)} dtype: {self.dtype}\"\r\n        else:\r\n            shape = \" x \".join([str(s) for s in self.shape])\r\n            result = f\"{name}: {self.mgr_locs.indexer}, {shape}, dtype: {self.dtype}\"\r\n\r\n        return result\r\n\r\n    @final\r\n    def __len__(self) -> int:\r\n        return len(self.values)\r\n\r\n    @final\r\n    def slice_block_columns(self, slc: slice) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n        \"\"\"\r\n        new_mgr_locs = self._mgr_locs[slc]\r\n\r\n        new_values = self._slice(slc)\r\n        refs = self.refs\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def take_block_columns(self, indices: npt.NDArray[np.intp]) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        # Note: only called from is from internals.concat, and we can verify\r\n        #  that never happens with 1-column blocks, i.e. never for ExtensionBlock.\r\n\r\n        new_mgr_locs = self._mgr_locs[indices]\r\n\r\n        new_values = self._slice(indices)\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=None)\r\n\r\n    @final\r\n    def getitem_block_columns(\r\n        self, slicer: slice, new_mgr_locs: BlockPlacement, ref_inplace_op: bool = False\r\n    ) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        new_values = self._slice(slicer)\r\n        refs = self.refs if not ref_inplace_op or self.refs.has_reference() else None\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def _can_hold_element(self, element: Any) -> bool:\r\n        \"\"\"require the same dtype as ourselves\"\"\"\r\n        element = extract_array(element, extract_numpy=True)\r\n        return can_hold_element(self.values, element)\r\n\r\n    @final\r\n    def should_store(self, value: ArrayLike) -> bool:\r\n        \"\"\"\r\n        Should we set self.values[indexer] = value inplace or do we need to cast?\r\n\r\n        Parameters\r\n        ----------\r\n        value : np.ndarray or ExtensionArray\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n        \"\"\"\r\n        return value.dtype == self.dtype\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Apply/Reduce and Helpers\r\n\r\n    @final\r\n    def apply(self, func, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        apply the function to my values; return a block if we are not\r\n        one\r\n        \"\"\"\r\n        result = func(self.values, **kwargs)\r\n\r\n        result = maybe_coerce_values(result)\r\n        return self._split_op_result(result)\r\n\r\n    @final\r\n    def reduce(self, func) -> list[Block]:\r\n        # We will apply the function and reshape the result into a single-row\r\n        #  Block with the same mgr_locs; squeezing will be done at a higher level\r\n        assert self.ndim == 2\r\n\r\n        result = func(self.values)\r\n\r\n        if self.values.ndim == 1:\r\n            res_values = result\r\n        else:\r\n            res_values = result.reshape(-1, 1)\r\n\r\n        nb = self.make_block(res_values)\r\n        return [nb]\r\n\r\n    @final\r\n    def _split_op_result(self, result: ArrayLike) -> list[Block]:\r\n        # See also: split_and_operate\r\n        if result.ndim > 1 and isinstance(result.dtype, ExtensionDtype):\r\n            # TODO(EA2D): unnecessary with 2D EAs\r\n            # if we get a 2D ExtensionArray, we need to split it into 1D pieces\r\n            nbs = []\r\n            for i, loc in enumerate(self._mgr_locs):\r\n                if not is_1d_only_ea_dtype(result.dtype):\r\n                    vals = result[i : i + 1]\r\n                else:\r\n                    vals = result[i]\r\n\r\n                bp = BlockPlacement(loc)\r\n                block = self.make_block(values=vals, placement=bp)\r\n                nbs.append(block)\r\n            return nbs\r\n\r\n        nb = self.make_block(result)\r\n\r\n        return [nb]\r\n\r\n    @final\r\n    def _split(self) -> Generator[Block]:\r\n        \"\"\"\r\n        Split a block into a list of single-column blocks.\r\n        \"\"\"\r\n        assert self.ndim == 2\r\n\r\n        for i, ref_loc in enumerate(self._mgr_locs):\r\n            vals = self.values[slice(i, i + 1)]\r\n"]
[455.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[455.002, "i", "cd asv_bench\r"]
[455.004, "o", "cd asv_bench\r\n"]
[455.006, "o", "\u001b[?2004l\r\n"]
[460.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[460.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools | tee ../pr\r"]
[460.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools | tee ../pr\r\n"]
[460.006, "o", "rofile_maskbool.txt\r\n\u001b[?2004l\r\n\u00b7 Discovering benchmarks\r\n\u00b7 Profile data does not already exist. Running profiler now.\r\n\u00b7\u00b7 Benchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\r\n\u00b7\u00b7\u00b7 Importing benchmark suite produced output:\r\n\u00b7\u00b7\u00b7\u00b7 meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 Running (frame_methods.MaskBool.time_frame_mask_bools--).\r\n\u00b7\u00b7\u00b7 frame_methods.MaskBool.time_frame_mask_bools            47.7\u00b10.2ms\r\n\r\nWed Oct  1 17:21:50 2025    /tmp/tmpn5zcnjzo\r\n\r\n         83260 function calls (82244 primitive calls) in 0.138 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.138    0.138 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.138    0.138 _base.py:689(method_caller)\r\n        1    0.004    0.004    0.138    0.138 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.134    0.134 generic.py:10068(mask)\r\n        1    0.000    0.000    0.134    0.134 generic.py:9685(_where)\r\n        7    0.000    0.000    0.132    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.132    0.132 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.132    0.132 blocks.py:1211(where)\r\n      500    0.001    0.000    0.088    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.067    0.000 common.py:702(is_integer_dtype)\r\n      500    0.065    0.000    0.065    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.010    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.003    0.000    0.009    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.001    0.000    0.004    0.000 _methods.py:59(_any)\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     1001    0.001    0.000    0.001    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     1501    0.001    0.000    0.001    0.000 blocks.py:957(shape)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x562842f74640}\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[465.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[465.002, "i", "cd ..\r"]
[465.004, "o", "cd ..\r\n"]
[465.006, "o", "\u001b[?2004l\r\n"]
[470.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[470.002, "i", "sed -n '1,120p' profile_maskbool.txt\r"]
[470.004, "o", "sed -n '1,120p' profile_maskbool.txt\r\n"]
[470.006, "o", "\u001b[?2004l\r\n\u00b7 Discovering benchmarks\r\n\u00b7 Profile data does not already exist. Running profiler now.\r\n\u00b7\u00b7 Benchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\r\n\u00b7\u00b7\u00b7 Importing benchmark suite produced output:\r\n\u00b7\u00b7\u00b7\u00b7 meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 Running (frame_methods.MaskBool.time_frame_mask_bools--).\r\n\u00b7\u00b7\u00b7 frame_methods.MaskBool.time_frame_mask_bools            47.7\u00b10.2ms\r\n\r\nWed Oct  1 17:21:50 2025    /tmp/tmpn5zcnjzo\r\n\r\n         83260 function calls (82244 primitive calls) in 0.138 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.138    0.138 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.138    0.138 _base.py:689(method_caller)\r\n        1    0.004    0.004    0.138    0.138 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.134    0.134 generic.py:10068(mask)\r\n        1    0.000    0.000    0.134    0.134 generic.py:9685(_where)\r\n        7    0.000    0.000    0.132    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.132    0.132 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.132    0.132 blocks.py:1211(where)\r\n      500    0.001    0.000    0.088    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.067    0.000 common.py:702(is_integer_dtype)\r\n      500    0.065    0.000    0.065    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.010    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.003    0.000    0.009    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.001    0.000    0.004    0.000 _methods.py:59(_any)\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     1001    0.001    0.000    0.001    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     1501    0.001    0.000    0.001    0.000 blocks.py:957(shape)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n"]
[475.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[475.002, "i", "grep -R -n -F \"def where\" pandas/core | head -n 50\r"]
[475.004, "o", "grep -R -n -F \"def where\" pandas/core | head -n 50\r\n"]
[475.006, "o", "\u001b[?2004l\r\npandas/core/computation/expressions.py:247:def where(cond, left_op, right_op, use_numexpr: bool = True):\r\npandas/core/generic.py:9831:    def where(\r\npandas/core/generic.py:9842:    def where(\r\npandas/core/generic.py:9853:    def where(\r\npandas/core/generic.py:9871:    def where(\r\npandas/core/indexes/base.py:5069:    def where(self, cond, other=None) -> Index:\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[480.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[480.002, "i", "grep -R -n -F \"def mask\" pandas/core | head -n 50\r"]
[480.004, "o", "grep -R -n -F \"def mask\" pandas/core | head -n 50\r\n"]
[480.006, "o", "\u001b[?2004l\r\npandas/core/ops/missing.py:72:def mask_zero_div_zero(x, y, result: np.ndarray) -> np.ndarray:\r\npandas/core/reshape/reshape.py:225:    def mask_all(self) -> bool:\r\npandas/core/missing.py:67:def mask_missing(arr: ArrayLike, values_to_mask) -> npt.NDArray[np.bool_]:\r\npandas/core/generic.py:10036:    def mask(\r\npandas/core/generic.py:10047:    def mask(\r\npandas/core/generic.py:10058:    def mask(\r\npandas/core/generic.py:10077:    def mask(\r\n"]
[485.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[485.002, "i", "grep -R -n \" def where\" pandas/core/internals | head -n 50\r"]
[485.004, "o", "grep -R -n \" def where\" pandas/core/internals | head -n 50\r\n"]
[485.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[490.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[490.002, "i", "grep -R -n \" def putmask\" pandas/core/internals | head -n 50\r"]
[490.004, "o", "grep -R -n \" def putmask\" pandas/core/internals | head -n 50\r\n"]
[490.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1144:    def putmask(self, mask, new) -> list[Block]:\r\npandas/core/internals/blocks.py:1728:    def putmask(self, mask, new) -> list[Block]:\r\npandas/core/internals/managers.py:477:    def putmask(self, mask, new, align: bool = True) -> Self:\r\n"]
[495.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[495.002, "i", "sed -n '1,260p' pandas/core/generic.py\r"]
[495.004, "o", "sed -n '1,260p' pandas/core/generic.py\r\n"]
[495.006, "o", "\u001b[?2004l\r\n# pyright: reportPropertyTypeMismatch=false\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom copy import deepcopy\r\nimport datetime as dt\r\nfrom functools import partial\r\nfrom json import loads\r\nimport operator\r\nimport pickle\r\nimport re\r\nimport sys\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    ClassVar,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import config\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas._libs.tslibs import (\r\n    Period,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    AlignJoin,\r\n    AnyArrayLike,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    AxisInt,\r\n    CompressionOptions,\r\n    Concatenate,\r\n    DtypeArg,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FilePath,\r\n    FillnaOptions,\r\n    FloatFormatType,\r\n    FormattersType,\r\n    Frequency,\r\n    IgnoreRaise,\r\n    IndexKeyFunc,\r\n    IndexLabel,\r\n    InterpolateOptions,\r\n    IntervalClosedType,\r\n    JSONSerializable,\r\n    Level,\r\n    ListLike,\r\n    Manager,\r\n    NaPosition,\r\n    NDFrameT,\r\n    OpenFileErrors,\r\n    RandomState,\r\n    ReindexMethod,\r\n    Renamer,\r\n    Scalar,\r\n    Self,\r\n    SequenceNotStr,\r\n    SortKind,\r\n    StorageOptions,\r\n    Suffixes,\r\n    T,\r\n    TimeAmbiguous,\r\n    TimedeltaConvertibleTypes,\r\n    TimeNonexistent,\r\n    TimestampConvertibleTypes,\r\n    TimeUnit,\r\n    ValueKeyFunc,\r\n    WriteBuffer,\r\n    WriteExcelBuffer,\r\n    npt,\r\n)\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import _chained_assignment_method_msg\r\nfrom pandas.util._decorators import (\r\n    deprecate_kwarg,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import (\r\n    check_dtype_backend,\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_inclusive,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_is_view\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    ensure_str,\r\n    is_bool,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_extension_array_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_numeric_dtype,\r\n    is_re_compilable,\r\n    is_scalar,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import (\r\n    is_hashable,\r\n    is_nested_list_like,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms as algos,\r\n    arraylike,\r\n    common,\r\n    indexing,\r\n    missing,\r\n    nanops,\r\n    sample,\r\n)\r\nfrom pandas.core.array_algos.replace import should_use_regex\r\nfrom pandas.core.arrays import ExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import extract_array\r\nfrom pandas.core.flags import Flags\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    MultiIndex,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.methods.describe import describe_ndframe\r\nfrom pandas.core.missing import (\r\n    clean_fill_method,\r\n    clean_reindex_fill_method,\r\n    find_valid_index,\r\n)\r\nfrom pandas.core.reshape.concat import concat\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import get_indexer_indexer\r\nfrom pandas.core.window import (\r\n    Expanding,\r\n    ExponentialMovingWindow,\r\n    Rolling,\r\n    Window,\r\n)\r\n\r\nfrom pandas.io.formats.format import (\r\n    DataFrameFormatter,\r\n    DataFrameRenderer,\r\n)\r\nfrom pandas.io.formats.printing import pprint_thing\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Callable\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterator,\r\n        Mapping,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._libs.tslibs import BaseOffset\r\n    from pandas._typing import P\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        ExcelWriter,\r\n        HDFStore,\r\n        Series,\r\n    )\r\n    from pandas.core.indexers.objects import BaseIndexer\r\n    from pandas.core.resample import Resampler\r\n\r\nimport textwrap\r\n\r\n# goal is to be able to define the docs close to function, while still being\r\n# able to share\r\n_shared_docs = {**_shared_docs}\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"keywords for axes\",\r\n    \"klass\": \"Series/DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\",  # noqa: E501\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        If True, performs operation inplace and returns None.\"\"\",\r\n    \"optional_by\": \"\"\"\r\n        by : str or list of str\r\n            Name or list of names to sort by\"\"\",\r\n}\r\n\r\n\r\nclass NDFrame(PandasObject, indexing.IndexingMixin):\r\n    \"\"\"\r\n    N-dimensional analogue of DataFrame. Store multi-dimensional in a\r\n    size-mutable, labeled data structure\r\n\r\n    Parameters\r\n    ----------\r\n    data : BlockManager\r\n    axes : list\r\n    copy : bool, default False\r\n    \"\"\"\r\n\r\n    _internal_names: list[str] = [\r\n        \"_mgr\",\r\n        \"_item_cache\",\r\n        \"_cache\",\r\n        \"_name\",\r\n        \"_metadata\",\r\n        \"_flags\",\r\n    ]\r\n    _internal_names_set: set[str] = set(_internal_names)\r\n    _accessors: set[str] = set()\r\n    _hidden_attrs: frozenset[str] = frozenset([])\r\n    _metadata: list[str] = []\r\n    _mgr: Manager\r\n    _attrs: dict[Hashable, Any]\r\n    _typ: str\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __init__(self, data: Manager) -> None:\r\n        object.__setattr__(self, \"_mgr\", data)\r\n        object.__setattr__(self, \"_attrs\", {})\r\n        object.__setattr__(self, \"_flags\", Flags(self, allows_duplicate_labels=True))\r\n\r\n"]
[500.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[500.002, "i", "sed -n '1,420p' pandas/core/internals/blocks.py\r"]
[500.004, "o", "sed -n '1,420p' pandas/core/internals/blocks.py\r\n"]
[500.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nimport inspect\r\nimport re\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    final,\r\n)\r\nimport warnings\r\nimport weakref\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    internals as libinternals,\r\n    lib,\r\n)\r\nfrom pandas._libs.internals import (\r\n    BlockPlacement,\r\n    BlockValuesRefs,\r\n)\r\nfrom pandas._libs.missing import NA\r\nfrom pandas._typing import (\r\n    ArrayLike,\r\n    AxisInt,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FillnaOptions,\r\n    IgnoreRaise,\r\n    InterpolateOptions,\r\n    QuantileInterpolation,\r\n    Self,\r\n    Shape,\r\n    npt,\r\n)\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    OutOfBoundsDatetime,\r\n)\r\nfrom pandas.util._decorators import cache_readonly\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import validate_bool_kwarg\r\n\r\nfrom pandas.core.dtypes.astype import (\r\n    astype_array_safe,\r\n    astype_is_view,\r\n)\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    convert_dtypes,\r\n    find_result_type,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    is_1d_only_ea_dtype,\r\n    is_float_dtype,\r\n    is_integer_dtype,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_string_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    IntervalDtype,\r\n    NumpyEADtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCIndex,\r\n    ABCNumpyExtensionArray,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import is_re\r\nfrom pandas.core.dtypes.missing import (\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n    na_value_for_dtype,\r\n)\r\n\r\nfrom pandas.core import missing\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.array_algos.putmask import (\r\n    extract_bool_array,\r\n    putmask_inplace,\r\n    putmask_without_repeat,\r\n    setitem_datetimelike_compat,\r\n    validate_putmask,\r\n)\r\nfrom pandas.core.array_algos.quantile import quantile_compat\r\nfrom pandas.core.array_algos.replace import (\r\n    compare_or_regex_search,\r\n    replace_regex,\r\n    should_use_regex,\r\n)\r\nfrom pandas.core.array_algos.transforms import shift\r\nfrom pandas.core.arrays import (\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    IntervalArray,\r\n    NumpyExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.string_ import StringDtype\r\nfrom pandas.core.base import PandasObject\r\nimport pandas.core.common as com\r\nfrom pandas.core.computation import expressions\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n)\r\nfrom pandas.core.indexers import check_setitem_lengths\r\nfrom pandas.core.indexes.base import get_values_for_csv\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Callable,\r\n        Generator,\r\n        Iterable,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas.core.api import Index\r\n    from pandas.core.arrays._mixins import NDArrayBackedExtensionArray\r\n\r\n# comparison is faster than is_object_dtype\r\n_dtype_obj = np.dtype(\"object\")\r\n\r\n\r\nclass Block(PandasObject, libinternals.Block):\r\n    \"\"\"\r\n    Canonical n-dimensional unit of homogeneous dtype contained in a pandas\r\n    data structure\r\n\r\n    Index-ignorant; let the container take care of that\r\n    \"\"\"\r\n\r\n    values: np.ndarray | ExtensionArray\r\n    ndim: int\r\n    refs: BlockValuesRefs\r\n    __init__: Callable\r\n\r\n    __slots__ = ()\r\n    is_numeric = False\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _validate_ndim(self) -> bool:\r\n        \"\"\"\r\n        We validate dimension for blocks that can hold 2D values, which for now\r\n        means numpy dtypes or DatetimeTZDtype.\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        return not isinstance(dtype, ExtensionDtype) or isinstance(\r\n            dtype, DatetimeTZDtype\r\n        )\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_object(self) -> bool:\r\n        return self.values.dtype == _dtype_obj\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_extension(self) -> bool:\r\n        return not lib.is_np_dtype(self.values.dtype)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_consolidate(self) -> bool:\r\n        # We _could_ consolidate for DatetimeTZDtype but don't for now.\r\n        return not self.is_extension\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _consolidate_key(self):\r\n        return self._can_consolidate, self.dtype.name\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_hold_na(self) -> bool:\r\n        \"\"\"\r\n        Can we store NA values in this Block?\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        if isinstance(dtype, np.dtype):\r\n            return dtype.kind not in \"iub\"\r\n        return dtype._can_hold_na\r\n\r\n    @final\r\n    @property\r\n    def is_bool(self) -> bool:\r\n        \"\"\"\r\n        We can be bool if a) we are bool dtype or b) object dtype with bool objects.\r\n        \"\"\"\r\n        return self.values.dtype == np.dtype(bool)\r\n\r\n    @final\r\n    def external_values(self):\r\n        return external_values(self.values)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        return na_value_for_dtype(self.dtype, compat=False)\r\n\r\n    @final\r\n    def _standardize_fill_value(self, value):\r\n        # if we are passed a scalar None, convert it here\r\n        if self.dtype != _dtype_obj and is_valid_na_for_dtype(value, self.dtype):\r\n            value = self.fill_value\r\n        return value\r\n\r\n    @property\r\n    def mgr_locs(self) -> BlockPlacement:\r\n        return self._mgr_locs\r\n\r\n    @mgr_locs.setter\r\n    def mgr_locs(self, new_mgr_locs: BlockPlacement) -> None:\r\n        self._mgr_locs = new_mgr_locs\r\n\r\n    @final\r\n    def make_block(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Create a new block, with type inference propagate any values that are\r\n        not specified\r\n        \"\"\"\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n        if self.is_extension:\r\n            values = ensure_block_shape(values, ndim=self.ndim)\r\n\r\n        return new_block(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def make_block_same_class(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Self:\r\n        \"\"\"Wrap given values in a block of same type as self.\"\"\"\r\n        # Pre-2.0 we called ensure_wrapped_if_datetimelike because fastparquet\r\n        #  relied on it, as of 2.0 the caller is responsible for this.\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n\r\n        # We assume maybe_coerce_values has already been called\r\n        return type(self)(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def __repr__(self) -> str:\r\n        # don't want to print out all of the items here\r\n        name = type(self).__name__\r\n        if self.ndim == 1:\r\n            result = f\"{name}: {len(self)} dtype: {self.dtype}\"\r\n        else:\r\n            shape = \" x \".join([str(s) for s in self.shape])\r\n            result = f\"{name}: {self.mgr_locs.indexer}, {shape}, dtype: {self.dtype}\"\r\n\r\n        return result\r\n\r\n    @final\r\n    def __len__(self) -> int:\r\n        return len(self.values)\r\n\r\n    @final\r\n    def slice_block_columns(self, slc: slice) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n        \"\"\"\r\n        new_mgr_locs = self._mgr_locs[slc]\r\n\r\n        new_values = self._slice(slc)\r\n        refs = self.refs\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def take_block_columns(self, indices: npt.NDArray[np.intp]) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        # Note: only called from is from internals.concat, and we can verify\r\n        #  that never happens with 1-column blocks, i.e. never for ExtensionBlock.\r\n\r\n        new_mgr_locs = self._mgr_locs[indices]\r\n\r\n        new_values = self._slice(indices)\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=None)\r\n\r\n    @final\r\n    def getitem_block_columns(\r\n        self, slicer: slice, new_mgr_locs: BlockPlacement, ref_inplace_op: bool = False\r\n    ) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        new_values = self._slice(slicer)\r\n        refs = self.refs if not ref_inplace_op or self.refs.has_reference() else None\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def _can_hold_element(self, element: Any) -> bool:\r\n        \"\"\"require the same dtype as ourselves\"\"\"\r\n        element = extract_array(element, extract_numpy=True)\r\n        return can_hold_element(self.values, element)\r\n\r\n    @final\r\n    def should_store(self, value: ArrayLike) -> bool:\r\n        \"\"\"\r\n        Should we set self.values[indexer] = value inplace or do we need to cast?\r\n\r\n        Parameters\r\n        ----------\r\n        value : np.ndarray or ExtensionArray\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n        \"\"\"\r\n        return value.dtype == self.dtype\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Apply/Reduce and Helpers\r\n\r\n    @final\r\n    def apply(self, func, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        apply the function to my values; return a block if we are not\r\n        one\r\n        \"\"\"\r\n        result = func(self.values, **kwargs)\r\n\r\n        result = maybe_coerce_values(result)\r\n        return self._split_op_result(result)\r\n\r\n    @final\r\n    def reduce(self, func) -> list[Block]:\r\n        # We will apply the function and reshape the result into a single-row\r\n        #  Block with the same mgr_locs; squeezing will be done at a higher level\r\n        assert self.ndim == 2\r\n\r\n        result = func(self.values)\r\n\r\n        if self.values.ndim == 1:\r\n            res_values = result\r\n        else:\r\n            res_values = result.reshape(-1, 1)\r\n\r\n        nb = self.make_block(res_values)\r\n        return [nb]\r\n\r\n    @final\r\n    def _split_op_result(self, result: ArrayLike) -> list[Block]:\r\n        # See also: split_and_operate\r\n        if result.ndim > 1 and isinstance(result.dtype, ExtensionDtype):\r\n            # TODO(EA2D): unnecessary with 2D EAs\r\n            # if we get a 2D ExtensionArray, we need to split it into 1D pieces\r\n            nbs = []\r\n            for i, loc in enumerate(self._mgr_locs):\r\n                if not is_1d_only_ea_dtype(result.dtype):\r\n                    vals = result[i : i + 1]\r\n                else:\r\n                    vals = result[i]\r\n\r\n                bp = BlockPlacement(loc)\r\n                block = self.make_block(values=vals, placement=bp)\r\n                nbs.append(block)\r\n            return nbs\r\n\r\n        nb = self.make_block(result)\r\n\r\n        return [nb]\r\n\r\n    @final\r\n    def _split(self) -> Generator[Block]:\r\n        \"\"\"\r\n        Split a block into a list of single-column blocks.\r\n        \"\"\"\r\n        assert self.ndim == 2\r\n\r\n        for i, ref_loc in enumerate(self._mgr_locs):\r\n            vals = self.values[slice(i, i + 1)]\r\n\r\n            bp = BlockPlacement(ref_loc)\r\n            nb = type(self)(vals, placement=bp, ndim=2, refs=self.refs)\r\n            yield nb\r\n\r\n    @final\r\n    def split_and_operate(self, func, *args, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        Split the block and apply func column-by-column.\r\n\r\n        Parameters\r\n        ----------\r\n        func : Block method\r\n        *args\r\n        **kwargs\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n"]
[505.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[505.002, "i", "cd asv_bench\r"]
[505.004, "o", "cd asv_bench\r\n"]
[505.006, "o", "\u001b[?2004l\r\n"]
[510.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[510.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools | tee ../pr\r"]
[510.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools | tee ../pr\r\n"]
[510.006, "o", "rofile_maskbool.txt\r\n\u001b[?2004l\r\n\u00b7 Discovering benchmarks\r\n\u00b7 Profile data does not already exist. Running profiler now.\r\n\u00b7\u00b7 Benchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\r\n\u00b7\u00b7\u00b7 Importing benchmark suite produced output:\r\n\u00b7\u00b7\u00b7\u00b7 meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 Running (frame_methods.MaskBool.time_frame_mask_bools--).\r\n\u00b7\u00b7\u00b7 frame_methods.MaskBool.time_frame_mask_bools            47.4\u00b10.2ms\r\n\r\nWed Oct  1 17:23:53 2025    /tmp/tmp2h8s3oz0\r\n\r\n         83260 function calls (82244 primitive calls) in 0.136 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.136    0.136 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.136    0.136 _base.py:689(method_caller)\r\n        1    0.004    0.004    0.136    0.136 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.132    0.132 generic.py:10068(mask)\r\n        1    0.000    0.000    0.132    0.132 generic.py:9685(_where)\r\n        7    0.000    0.000    0.130    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.130    0.130 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.129    0.129 blocks.py:1211(where)\r\n      500    0.001    0.000    0.086    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.065    0.000 common.py:702(is_integer_dtype)\r\n      500    0.063    0.000    0.063    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.002    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.000    0.000    0.003    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     1001    0.001    0.000    0.002    0.000 cast.py:1770(np_can_hold_element)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55c7f255f640}\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[515.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[515.002, "i", "cd ..\r"]
[515.004, "o", "cd ..\r\n"]
[515.006, "o", "\u001b[?2004l\r\n"]
[520.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[520.002, "i", "sed -n '1,200p' profile_maskbool.txt\r"]
[520.004, "o", "sed -n '1,200p' profile_maskbool.txt\r\n"]
[520.006, "o", "\u001b[?2004l\r\n\u00b7 Discovering benchmarks\r\n\u00b7 Profile data does not already exist. Running profiler now.\r\n\u00b7\u00b7 Benchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\r\n\u00b7\u00b7\u00b7 Importing benchmark suite produced output:\r\n\u00b7\u00b7\u00b7\u00b7 meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 Running (frame_methods.MaskBool.time_frame_mask_bools--).\r\n\u00b7\u00b7\u00b7 frame_methods.MaskBool.time_frame_mask_bools            47.4\u00b10.2ms\r\n\r\nWed Oct  1 17:23:53 2025    /tmp/tmp2h8s3oz0\r\n\r\n         83260 function calls (82244 primitive calls) in 0.136 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.136    0.136 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.136    0.136 _base.py:689(method_caller)\r\n        1    0.004    0.004    0.136    0.136 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.132    0.132 generic.py:10068(mask)\r\n        1    0.000    0.000    0.132    0.132 generic.py:9685(_where)\r\n        7    0.000    0.000    0.130    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.130    0.130 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.129    0.129 blocks.py:1211(where)\r\n      500    0.001    0.000    0.086    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.065    0.000 common.py:702(is_integer_dtype)\r\n      500    0.063    0.000    0.063    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.002    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.000    0.000    0.003    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     1001    0.001    0.000    0.002    0.000 cast.py:1770(np_can_hold_element)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55c7f255f640}\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n"]
[525.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[525.002, "i", "grep -R -n -F \"def where(\" pandas/core | head -n 50\r"]
[525.004, "o", "grep -R -n -F \"def where(\" pandas/core | head -n 50\r\n"]
[525.006, "o", "\u001b[?2004l\r\npandas/core/computation/expressions.py:247:def where(cond, left_op, right_op, use_numexpr: bool = True):\r\npandas/core/generic.py:9831:    def where(\r\npandas/core/generic.py:9842:    def where(\r\npandas/core/generic.py:9853:    def where(\r\npandas/core/generic.py:9871:    def where(\r\npandas/core/indexes/base.py:5069:    def where(self, cond, other=None) -> Index:\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[530.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[530.002, "i", "grep -R -n -F \"def mask(\" pandas/core | head -n 50\r"]
[530.004, "o", "grep -R -n -F \"def mask(\" pandas/core | head -n 50\r\n"]
[530.006, "o", "\u001b[?2004l\r\npandas/core/generic.py:10036:    def mask(\r\npandas/core/generic.py:10047:    def mask(\r\npandas/core/generic.py:10058:    def mask(\r\npandas/core/generic.py:10077:    def mask(\r\n"]
[535.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[535.002, "i", "grep -R -n -F \"def where(\" pandas/core/internals | head -n 50\r"]
[535.004, "o", "grep -R -n -F \"def where(\" pandas/core/internals | head -n 50\r\n"]
[535.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[540.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[540.002, "i", "grep -R -n -F \"def putmask(\" pandas/core/internals | head -n 50\r"]
[540.004, "o", "grep -R -n -F \"def putmask(\" pandas/core/internals | head -n 50\r\n"]
[540.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1144:    def putmask(self, mask, new) -> list[Block]:\r\npandas/core/internals/blocks.py:1728:    def putmask(self, mask, new) -> list[Block]:\r\npandas/core/internals/managers.py:477:    def putmask(self, mask, new, align: bool = True) -> Self:\r\n"]
[545.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[545.002, "i", "sed -n '1,320p' pandas/core/generic.py\r"]
[545.004, "o", "sed -n '1,320p' pandas/core/generic.py\r\n"]
[545.006, "o", "\u001b[?2004l\r\n# pyright: reportPropertyTypeMismatch=false\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom copy import deepcopy\r\nimport datetime as dt\r\nfrom functools import partial\r\nfrom json import loads\r\nimport operator\r\nimport pickle\r\nimport re\r\nimport sys\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    ClassVar,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import config\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas._libs.tslibs import (\r\n    Period,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    AlignJoin,\r\n    AnyArrayLike,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    AxisInt,\r\n    CompressionOptions,\r\n    Concatenate,\r\n    DtypeArg,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FilePath,\r\n    FillnaOptions,\r\n    FloatFormatType,\r\n    FormattersType,\r\n    Frequency,\r\n    IgnoreRaise,\r\n    IndexKeyFunc,\r\n    IndexLabel,\r\n    InterpolateOptions,\r\n    IntervalClosedType,\r\n    JSONSerializable,\r\n    Level,\r\n    ListLike,\r\n    Manager,\r\n    NaPosition,\r\n    NDFrameT,\r\n    OpenFileErrors,\r\n    RandomState,\r\n    ReindexMethod,\r\n    Renamer,\r\n    Scalar,\r\n    Self,\r\n    SequenceNotStr,\r\n    SortKind,\r\n    StorageOptions,\r\n    Suffixes,\r\n    T,\r\n    TimeAmbiguous,\r\n    TimedeltaConvertibleTypes,\r\n    TimeNonexistent,\r\n    TimestampConvertibleTypes,\r\n    TimeUnit,\r\n    ValueKeyFunc,\r\n    WriteBuffer,\r\n    WriteExcelBuffer,\r\n    npt,\r\n)\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import _chained_assignment_method_msg\r\nfrom pandas.util._decorators import (\r\n    deprecate_kwarg,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import (\r\n    check_dtype_backend,\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_inclusive,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_is_view\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    ensure_str,\r\n    is_bool,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_extension_array_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_numeric_dtype,\r\n    is_re_compilable,\r\n    is_scalar,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import (\r\n    is_hashable,\r\n    is_nested_list_like,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms as algos,\r\n    arraylike,\r\n    common,\r\n    indexing,\r\n    missing,\r\n    nanops,\r\n    sample,\r\n)\r\nfrom pandas.core.array_algos.replace import should_use_regex\r\nfrom pandas.core.arrays import ExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import extract_array\r\nfrom pandas.core.flags import Flags\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    MultiIndex,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.methods.describe import describe_ndframe\r\nfrom pandas.core.missing import (\r\n    clean_fill_method,\r\n    clean_reindex_fill_method,\r\n    find_valid_index,\r\n)\r\nfrom pandas.core.reshape.concat import concat\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import get_indexer_indexer\r\nfrom pandas.core.window import (\r\n    Expanding,\r\n    ExponentialMovingWindow,\r\n    Rolling,\r\n    Window,\r\n)\r\n\r\nfrom pandas.io.formats.format import (\r\n    DataFrameFormatter,\r\n    DataFrameRenderer,\r\n)\r\nfrom pandas.io.formats.printing import pprint_thing\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Callable\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterator,\r\n        Mapping,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._libs.tslibs import BaseOffset\r\n    from pandas._typing import P\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        ExcelWriter,\r\n        HDFStore,\r\n        Series,\r\n    )\r\n    from pandas.core.indexers.objects import BaseIndexer\r\n    from pandas.core.resample import Resampler\r\n\r\nimport textwrap\r\n\r\n# goal is to be able to define the docs close to function, while still being\r\n# able to share\r\n_shared_docs = {**_shared_docs}\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"keywords for axes\",\r\n    \"klass\": \"Series/DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\",  # noqa: E501\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        If True, performs operation inplace and returns None.\"\"\",\r\n    \"optional_by\": \"\"\"\r\n        by : str or list of str\r\n            Name or list of names to sort by\"\"\",\r\n}\r\n\r\n\r\nclass NDFrame(PandasObject, indexing.IndexingMixin):\r\n    \"\"\"\r\n    N-dimensional analogue of DataFrame. Store multi-dimensional in a\r\n    size-mutable, labeled data structure\r\n\r\n    Parameters\r\n    ----------\r\n    data : BlockManager\r\n    axes : list\r\n    copy : bool, default False\r\n    \"\"\"\r\n\r\n    _internal_names: list[str] = [\r\n        \"_mgr\",\r\n        \"_item_cache\",\r\n        \"_cache\",\r\n        \"_name\",\r\n        \"_metadata\",\r\n        \"_flags\",\r\n    ]\r\n    _internal_names_set: set[str] = set(_internal_names)\r\n    _accessors: set[str] = set()\r\n    _hidden_attrs: frozenset[str] = frozenset([])\r\n    _metadata: list[str] = []\r\n    _mgr: Manager\r\n    _attrs: dict[Hashable, Any]\r\n    _typ: str\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __init__(self, data: Manager) -> None:\r\n        object.__setattr__(self, \"_mgr\", data)\r\n        object.__setattr__(self, \"_attrs\", {})\r\n        object.__setattr__(self, \"_flags\", Flags(self, allows_duplicate_labels=True))\r\n\r\n    @final\r\n    @classmethod\r\n    def _init_mgr(\r\n        cls,\r\n        mgr: Manager,\r\n        axes: dict[Literal[\"index\", \"columns\"], Axes | None],\r\n        dtype: DtypeObj | None = None,\r\n        copy: bool = False,\r\n    ) -> Manager:\r\n        \"\"\"passed a manager and a axes dict\"\"\"\r\n        for a, axe in axes.items():\r\n            if axe is not None:\r\n                axe = ensure_index(axe)\r\n                bm_axis = cls._get_block_manager_axis(a)\r\n                mgr = mgr.reindex_axis(axe, axis=bm_axis)\r\n\r\n        # make a copy if explicitly requested\r\n        if copy:\r\n            mgr = mgr.copy()\r\n        if dtype is not None:\r\n            # avoid further copies if we can\r\n            if (\r\n                isinstance(mgr, BlockManager)\r\n                and len(mgr.blocks) == 1\r\n                and mgr.blocks[0].values.dtype == dtype\r\n            ):\r\n                pass\r\n            else:\r\n                mgr = mgr.astype(dtype=dtype)\r\n        return mgr\r\n\r\n    @final\r\n    @classmethod\r\n    def _from_mgr(cls, mgr: Manager, axes: list[Index]) -> Self:\r\n        \"\"\"\r\n        Construct a new object of this type from a Manager object and axes.\r\n\r\n        Parameters\r\n        ----------\r\n        mgr : Manager\r\n            Must have the same ndim as cls.\r\n        axes : list[Index]\r\n\r\n        Notes\r\n        -----\r\n        The axes must match mgr.axes, but are required for future-proofing\r\n        in the event that axes are refactored out of the Manager objects.\r\n        \"\"\"\r\n        obj = cls.__new__(cls)\r\n        NDFrame.__init__(obj, mgr)\r\n        return obj\r\n\r\n    # ----------------------------------------------------------------------\r\n    # attrs and flags\r\n\r\n    @property\r\n    def attrs(self) -> dict[Hashable, Any]:\r\n        \"\"\"\r\n        Dictionary of global attributes of this dataset.\r\n\r\n"]
[550.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[550.002, "i", "sed -n '1,500p' pandas/core/internals/blocks.py\r"]
[550.004, "o", "sed -n '1,500p' pandas/core/internals/blocks.py\r\n"]
[550.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nimport inspect\r\nimport re\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    final,\r\n)\r\nimport warnings\r\nimport weakref\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    internals as libinternals,\r\n    lib,\r\n)\r\nfrom pandas._libs.internals import (\r\n    BlockPlacement,\r\n    BlockValuesRefs,\r\n)\r\nfrom pandas._libs.missing import NA\r\nfrom pandas._typing import (\r\n    ArrayLike,\r\n    AxisInt,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FillnaOptions,\r\n    IgnoreRaise,\r\n    InterpolateOptions,\r\n    QuantileInterpolation,\r\n    Self,\r\n    Shape,\r\n    npt,\r\n)\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    OutOfBoundsDatetime,\r\n)\r\nfrom pandas.util._decorators import cache_readonly\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import validate_bool_kwarg\r\n\r\nfrom pandas.core.dtypes.astype import (\r\n    astype_array_safe,\r\n    astype_is_view,\r\n)\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    convert_dtypes,\r\n    find_result_type,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    is_1d_only_ea_dtype,\r\n    is_float_dtype,\r\n    is_integer_dtype,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_string_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    IntervalDtype,\r\n    NumpyEADtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCIndex,\r\n    ABCNumpyExtensionArray,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import is_re\r\nfrom pandas.core.dtypes.missing import (\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n    na_value_for_dtype,\r\n)\r\n\r\nfrom pandas.core import missing\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.array_algos.putmask import (\r\n    extract_bool_array,\r\n    putmask_inplace,\r\n    putmask_without_repeat,\r\n    setitem_datetimelike_compat,\r\n    validate_putmask,\r\n)\r\nfrom pandas.core.array_algos.quantile import quantile_compat\r\nfrom pandas.core.array_algos.replace import (\r\n    compare_or_regex_search,\r\n    replace_regex,\r\n    should_use_regex,\r\n)\r\nfrom pandas.core.array_algos.transforms import shift\r\nfrom pandas.core.arrays import (\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    IntervalArray,\r\n    NumpyExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.string_ import StringDtype\r\nfrom pandas.core.base import PandasObject\r\nimport pandas.core.common as com\r\nfrom pandas.core.computation import expressions\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n)\r\nfrom pandas.core.indexers import check_setitem_lengths\r\nfrom pandas.core.indexes.base import get_values_for_csv\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Callable,\r\n        Generator,\r\n        Iterable,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas.core.api import Index\r\n    from pandas.core.arrays._mixins import NDArrayBackedExtensionArray\r\n\r\n# comparison is faster than is_object_dtype\r\n_dtype_obj = np.dtype(\"object\")\r\n\r\n\r\nclass Block(PandasObject, libinternals.Block):\r\n    \"\"\"\r\n    Canonical n-dimensional unit of homogeneous dtype contained in a pandas\r\n    data structure\r\n\r\n    Index-ignorant; let the container take care of that\r\n    \"\"\"\r\n\r\n    values: np.ndarray | ExtensionArray\r\n    ndim: int\r\n    refs: BlockValuesRefs\r\n    __init__: Callable\r\n\r\n    __slots__ = ()\r\n    is_numeric = False\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _validate_ndim(self) -> bool:\r\n        \"\"\"\r\n        We validate dimension for blocks that can hold 2D values, which for now\r\n        means numpy dtypes or DatetimeTZDtype.\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        return not isinstance(dtype, ExtensionDtype) or isinstance(\r\n            dtype, DatetimeTZDtype\r\n        )\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_object(self) -> bool:\r\n        return self.values.dtype == _dtype_obj\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_extension(self) -> bool:\r\n        return not lib.is_np_dtype(self.values.dtype)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_consolidate(self) -> bool:\r\n        # We _could_ consolidate for DatetimeTZDtype but don't for now.\r\n        return not self.is_extension\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _consolidate_key(self):\r\n        return self._can_consolidate, self.dtype.name\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_hold_na(self) -> bool:\r\n        \"\"\"\r\n        Can we store NA values in this Block?\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        if isinstance(dtype, np.dtype):\r\n            return dtype.kind not in \"iub\"\r\n        return dtype._can_hold_na\r\n\r\n    @final\r\n    @property\r\n    def is_bool(self) -> bool:\r\n        \"\"\"\r\n        We can be bool if a) we are bool dtype or b) object dtype with bool objects.\r\n        \"\"\"\r\n        return self.values.dtype == np.dtype(bool)\r\n\r\n    @final\r\n    def external_values(self):\r\n        return external_values(self.values)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        return na_value_for_dtype(self.dtype, compat=False)\r\n\r\n    @final\r\n    def _standardize_fill_value(self, value):\r\n        # if we are passed a scalar None, convert it here\r\n        if self.dtype != _dtype_obj and is_valid_na_for_dtype(value, self.dtype):\r\n            value = self.fill_value\r\n        return value\r\n\r\n    @property\r\n    def mgr_locs(self) -> BlockPlacement:\r\n        return self._mgr_locs\r\n\r\n    @mgr_locs.setter\r\n    def mgr_locs(self, new_mgr_locs: BlockPlacement) -> None:\r\n        self._mgr_locs = new_mgr_locs\r\n\r\n    @final\r\n    def make_block(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Create a new block, with type inference propagate any values that are\r\n        not specified\r\n        \"\"\"\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n        if self.is_extension:\r\n            values = ensure_block_shape(values, ndim=self.ndim)\r\n\r\n        return new_block(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def make_block_same_class(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Self:\r\n        \"\"\"Wrap given values in a block of same type as self.\"\"\"\r\n        # Pre-2.0 we called ensure_wrapped_if_datetimelike because fastparquet\r\n        #  relied on it, as of 2.0 the caller is responsible for this.\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n\r\n        # We assume maybe_coerce_values has already been called\r\n        return type(self)(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def __repr__(self) -> str:\r\n        # don't want to print out all of the items here\r\n        name = type(self).__name__\r\n        if self.ndim == 1:\r\n            result = f\"{name}: {len(self)} dtype: {self.dtype}\"\r\n        else:\r\n            shape = \" x \".join([str(s) for s in self.shape])\r\n            result = f\"{name}: {self.mgr_locs.indexer}, {shape}, dtype: {self.dtype}\"\r\n\r\n        return result\r\n\r\n    @final\r\n    def __len__(self) -> int:\r\n        return len(self.values)\r\n\r\n    @final\r\n    def slice_block_columns(self, slc: slice) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n        \"\"\"\r\n        new_mgr_locs = self._mgr_locs[slc]\r\n\r\n        new_values = self._slice(slc)\r\n        refs = self.refs\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def take_block_columns(self, indices: npt.NDArray[np.intp]) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        # Note: only called from is from internals.concat, and we can verify\r\n        #  that never happens with 1-column blocks, i.e. never for ExtensionBlock.\r\n\r\n        new_mgr_locs = self._mgr_locs[indices]\r\n\r\n        new_values = self._slice(indices)\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=None)\r\n\r\n    @final\r\n    def getitem_block_columns(\r\n        self, slicer: slice, new_mgr_locs: BlockPlacement, ref_inplace_op: bool = False\r\n    ) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        new_values = self._slice(slicer)\r\n        refs = self.refs if not ref_inplace_op or self.refs.has_reference() else None\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def _can_hold_element(self, element: Any) -> bool:\r\n        \"\"\"require the same dtype as ourselves\"\"\"\r\n        element = extract_array(element, extract_numpy=True)\r\n        return can_hold_element(self.values, element)\r\n\r\n    @final\r\n    def should_store(self, value: ArrayLike) -> bool:\r\n        \"\"\"\r\n        Should we set self.values[indexer] = value inplace or do we need to cast?\r\n\r\n        Parameters\r\n        ----------\r\n        value : np.ndarray or ExtensionArray\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n        \"\"\"\r\n        return value.dtype == self.dtype\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Apply/Reduce and Helpers\r\n\r\n    @final\r\n    def apply(self, func, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        apply the function to my values; return a block if we are not\r\n        one\r\n        \"\"\"\r\n        result = func(self.values, **kwargs)\r\n\r\n        result = maybe_coerce_values(result)\r\n        return self._split_op_result(result)\r\n\r\n    @final\r\n    def reduce(self, func) -> list[Block]:\r\n        # We will apply the function and reshape the result into a single-row\r\n        #  Block with the same mgr_locs; squeezing will be done at a higher level\r\n        assert self.ndim == 2\r\n\r\n        result = func(self.values)\r\n\r\n        if self.values.ndim == 1:\r\n            res_values = result\r\n        else:\r\n            res_values = result.reshape(-1, 1)\r\n\r\n        nb = self.make_block(res_values)\r\n        return [nb]\r\n\r\n    @final\r\n    def _split_op_result(self, result: ArrayLike) -> list[Block]:\r\n        # See also: split_and_operate\r\n        if result.ndim > 1 and isinstance(result.dtype, ExtensionDtype):\r\n            # TODO(EA2D): unnecessary with 2D EAs\r\n            # if we get a 2D ExtensionArray, we need to split it into 1D pieces\r\n            nbs = []\r\n            for i, loc in enumerate(self._mgr_locs):\r\n                if not is_1d_only_ea_dtype(result.dtype):\r\n                    vals = result[i : i + 1]\r\n                else:\r\n                    vals = result[i]\r\n\r\n                bp = BlockPlacement(loc)\r\n                block = self.make_block(values=vals, placement=bp)\r\n                nbs.append(block)\r\n            return nbs\r\n\r\n        nb = self.make_block(result)\r\n\r\n        return [nb]\r\n\r\n    @final\r\n    def _split(self) -> Generator[Block]:\r\n        \"\"\"\r\n        Split a block into a list of single-column blocks.\r\n        \"\"\"\r\n        assert self.ndim == 2\r\n\r\n        for i, ref_loc in enumerate(self._mgr_locs):\r\n            vals = self.values[slice(i, i + 1)]\r\n\r\n            bp = BlockPlacement(ref_loc)\r\n            nb = type(self)(vals, placement=bp, ndim=2, refs=self.refs)\r\n            yield nb\r\n\r\n    @final\r\n    def split_and_operate(self, func, *args, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        Split the block and apply func column-by-column.\r\n\r\n        Parameters\r\n        ----------\r\n        func : Block method\r\n        *args\r\n        **kwargs\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        assert self.ndim == 2 and self.shape[0] != 1\r\n\r\n        res_blocks = []\r\n        for nb in self._split():\r\n            rbs = func(nb, *args, **kwargs)\r\n            res_blocks.extend(rbs)\r\n        return res_blocks\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Up/Down-casting\r\n\r\n    @final\r\n    def coerce_to_target_dtype(self, other, raise_on_upcast: bool) -> Block:\r\n        \"\"\"\r\n        coerce the current block to a dtype compat for other\r\n        we will return a block, possibly object, and not raise\r\n\r\n        we can also safely try to coerce to the same dtype\r\n        and will receive the same block\r\n        \"\"\"\r\n        new_dtype = find_result_type(self.values.dtype, other)\r\n        if new_dtype == self.dtype:\r\n            # GH#52927 avoid RecursionError\r\n            raise AssertionError(\r\n                \"Something has gone wrong, please report a bug at \"\r\n                \"https://github.com/pandas-dev/pandas/issues\"\r\n            )\r\n\r\n        # In a future version of pandas, the default will be that\r\n        # setting `nan` into an integer series won't raise.\r\n        if (\r\n            is_scalar(other)\r\n            and is_integer_dtype(self.values.dtype)\r\n            and isna(other)\r\n            and other is not NaT\r\n            and not (\r\n                isinstance(other, (np.datetime64, np.timedelta64)) and np.isnat(other)\r\n            )\r\n        ):\r\n            raise_on_upcast = False\r\n        elif (\r\n            isinstance(other, np.ndarray)\r\n            and other.ndim == 1\r\n            and is_integer_dtype(self.values.dtype)\r\n            and is_float_dtype(other.dtype)\r\n            and lib.has_only_ints_or_nan(other)\r\n        ):\r\n            raise_on_upcast = False\r\n\r\n        if raise_on_upcast:\r\n            raise TypeError(f\"Invalid value '{other}' for dtype '{self.values.dtype}'\")\r\n        if self.values.dtype == new_dtype:\r\n            raise AssertionError(\r\n                f\"Did not expect new dtype {new_dtype} to equal self.dtype \"\r\n                f\"{self.values.dtype}. Please report a bug at \"\r\n                \"https://github.com/pandas-dev/pandas/issues.\"\r\n            )\r\n        try:\r\n            return self.astype(new_dtype)\r\n        except OutOfBoundsDatetime as err:\r\n            # e.g. GH#56419 if self.dtype is a low-resolution dt64 and we try to\r\n            #  upcast to a higher-resolution dt64, we may have entries that are\r\n            #  out of bounds for the higher resolution.\r\n            #  Re-raise with a more informative message.\r\n            raise OutOfBoundsDatetime(\r\n                f\"Incompatible (high-resolution) value for dtype='{self.dtype}'. \"\r\n                \"Explicitly cast before operating.\"\r\n            ) from err\r\n\r\n    @final\r\n    def convert(self) -> list[Block]:\r\n        \"\"\"\r\n        Attempt to coerce any object types to better types. Return a copy\r\n        of the block (if copy = True).\r\n        \"\"\"\r\n        if not self.is_object:\r\n            return [self.copy(deep=False)]\r\n\r\n        if self.ndim != 1 and self.shape[0] != 1:\r\n            blocks = self.split_and_operate(Block.convert)\r\n"]
[555.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[555.002, "i", "cd asv_bench\r"]
[555.004, "o", "cd asv_bench\r\n"]
[555.006, "o", "\u001b[?2004l\r\n"]
[560.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[560.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools | tee ../pr\r"]
[560.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools | tee ../pr\r\n"]
[560.006, "o", "rofile_maskbool.txt\r\n\u001b[?2004l\r\n\u00b7 Discovering benchmarks\r\n\u00b7 Profile data does not already exist. Running profiler now.\r\n\u00b7\u00b7 Benchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\r\n\u00b7\u00b7\u00b7 Importing benchmark suite produced output:\r\n\u00b7\u00b7\u00b7\u00b7 meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 Running (frame_methods.MaskBool.time_frame_mask_bools--).\r\n\u00b7\u00b7\u00b7 frame_methods.MaskBool.time_frame_mask_bools            47.0\u00b10.1ms\r\n\r\nWed Oct  1 17:25:59 2025    /tmp/tmpe1fyq1s3\r\n\r\n         83260 function calls (82244 primitive calls) in 0.139 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.139    0.139 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.139    0.139 _base.py:689(method_caller)\r\n        1    0.005    0.005    0.139    0.139 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.134    0.134 generic.py:10068(mask)\r\n        1    0.000    0.000    0.134    0.134 generic.py:9685(_where)\r\n        7    0.000    0.000    0.132    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.132    0.132 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.131    0.131 blocks.py:1211(where)\r\n      500    0.001    0.000    0.088    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.068    0.000 common.py:702(is_integer_dtype)\r\n      500    0.066    0.000    0.066    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.002    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.000    0.000    0.003    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     1001    0.001    0.000    0.002    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.001    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55b598916640}\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[565.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[565.002, "i", "cd ..\r"]
[565.004, "o", "cd ..\r\n"]
[565.006, "o", "\u001b[?2004l\r\n"]
[570.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[570.002, "i", "sed -n '1,120p' profile_maskbool.txt\r"]
[570.004, "o", "sed -n '1,120p' profile_maskbool.txt\r\n"]
[570.006, "o", "\u001b[?2004l\r\n\u00b7 Discovering benchmarks\r\n\u00b7 Profile data does not already exist. Running profiler now.\r\n\u00b7\u00b7 Benchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\r\n\u00b7\u00b7\u00b7 Importing benchmark suite produced output:\r\n\u00b7\u00b7\u00b7\u00b7 meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 Running (frame_methods.MaskBool.time_frame_mask_bools--).\r\n\u00b7\u00b7\u00b7 frame_methods.MaskBool.time_frame_mask_bools            47.0\u00b10.1ms\r\n\r\nWed Oct  1 17:25:59 2025    /tmp/tmpe1fyq1s3\r\n\r\n         83260 function calls (82244 primitive calls) in 0.139 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.139    0.139 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.139    0.139 _base.py:689(method_caller)\r\n        1    0.005    0.005    0.139    0.139 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.134    0.134 generic.py:10068(mask)\r\n        1    0.000    0.000    0.134    0.134 generic.py:9685(_where)\r\n        7    0.000    0.000    0.132    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.132    0.132 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.131    0.131 blocks.py:1211(where)\r\n      500    0.001    0.000    0.088    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.068    0.000 common.py:702(is_integer_dtype)\r\n      500    0.066    0.000    0.066    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.002    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.007    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.000    0.000    0.003    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.003    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     1001    0.001    0.000    0.002    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.001    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n"]
[575.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[575.002, "i", "grep -R -n -F \"def where\" pandas/core | head -n 50\r"]
[575.004, "o", "grep -R -n -F \"def where\" pandas/core | head -n 50\r\n"]
[575.006, "o", "\u001b[?2004l\r\npandas/core/computation/expressions.py:247:def where(cond, left_op, right_op, use_numexpr: bool = True):\r\npandas/core/generic.py:9831:    def where(\r\npandas/core/generic.py:9842:    def where(\r\npandas/core/generic.py:9853:    def where(\r\npandas/core/generic.py:9871:    def where(\r\npandas/core/indexes/base.py:5069:    def where(self, cond, other=None) -> Index:\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[580.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[580.002, "i", "grep -R -n -F \"def mask\" pandas/core | head -n 50\r"]
[580.004, "o", "grep -R -n -F \"def mask\" pandas/core | head -n 50\r\n"]
[580.006, "o", "\u001b[?2004l\r\npandas/core/ops/missing.py:72:def mask_zero_div_zero(x, y, result: np.ndarray) -> np.ndarray:\r\npandas/core/reshape/reshape.py:225:    def mask_all(self) -> bool:\r\npandas/core/missing.py:67:def mask_missing(arr: ArrayLike, values_to_mask) -> npt.NDArray[np.bool_]:\r\npandas/core/generic.py:10036:    def mask(\r\npandas/core/generic.py:10047:    def mask(\r\npandas/core/generic.py:10058:    def mask(\r\npandas/core/generic.py:10077:    def mask(\r\n"]
[585.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[585.002, "i", "grep -R -n -F \"def where\" pandas/core/internals | head -n 50\r"]
[585.004, "o", "grep -R -n -F \"def where\" pandas/core/internals | head -n 50\r\n"]
[585.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[590.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[590.002, "i", "grep -R -n -F \"def putmask\" pandas/core/internals | head -n 50\r"]
[590.004, "o", "grep -R -n -F \"def putmask\" pandas/core/internals | head -n 50\r\n"]
[590.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1144:    def putmask(self, mask, new) -> list[Block]:\r\npandas/core/internals/blocks.py:1728:    def putmask(self, mask, new) -> list[Block]:\r\npandas/core/internals/managers.py:477:    def putmask(self, mask, new, align: bool = True) -> Self:\r\n"]
[595.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[595.002, "i", "sed -n '1,500p' pandas/core/generic.py\r"]
[595.004, "o", "sed -n '1,500p' pandas/core/generic.py\r\n"]
[595.006, "o", "\u001b[?2004l\r\n# pyright: reportPropertyTypeMismatch=false\r\nfrom __future__ import annotations\r\n\r\nimport collections\r\nfrom copy import deepcopy\r\nimport datetime as dt\r\nfrom functools import partial\r\nfrom json import loads\r\nimport operator\r\nimport pickle\r\nimport re\r\nimport sys\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    ClassVar,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import config\r\n\r\nfrom pandas._libs import lib\r\nfrom pandas._libs.lib import is_range_indexer\r\nfrom pandas._libs.tslibs import (\r\n    Period,\r\n    Timestamp,\r\n    to_offset,\r\n)\r\nfrom pandas._typing import (\r\n    AlignJoin,\r\n    AnyArrayLike,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    AxisInt,\r\n    CompressionOptions,\r\n    Concatenate,\r\n    DtypeArg,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FilePath,\r\n    FillnaOptions,\r\n    FloatFormatType,\r\n    FormattersType,\r\n    Frequency,\r\n    IgnoreRaise,\r\n    IndexKeyFunc,\r\n    IndexLabel,\r\n    InterpolateOptions,\r\n    IntervalClosedType,\r\n    JSONSerializable,\r\n    Level,\r\n    ListLike,\r\n    Manager,\r\n    NaPosition,\r\n    NDFrameT,\r\n    OpenFileErrors,\r\n    RandomState,\r\n    ReindexMethod,\r\n    Renamer,\r\n    Scalar,\r\n    Self,\r\n    SequenceNotStr,\r\n    SortKind,\r\n    StorageOptions,\r\n    Suffixes,\r\n    T,\r\n    TimeAmbiguous,\r\n    TimedeltaConvertibleTypes,\r\n    TimeNonexistent,\r\n    TimestampConvertibleTypes,\r\n    TimeUnit,\r\n    ValueKeyFunc,\r\n    WriteBuffer,\r\n    WriteExcelBuffer,\r\n    npt,\r\n)\r\nfrom pandas.compat import PYPY\r\nfrom pandas.compat._constants import REF_COUNT\r\nfrom pandas.compat._optional import import_optional_dependency\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    ChainedAssignmentError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.errors.cow import _chained_assignment_method_msg\r\nfrom pandas.util._decorators import (\r\n    deprecate_kwarg,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import (\r\n    check_dtype_backend,\r\n    validate_ascending,\r\n    validate_bool_kwarg,\r\n    validate_inclusive,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_is_view\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    ensure_str,\r\n    is_bool,\r\n    is_bool_dtype,\r\n    is_dict_like,\r\n    is_extension_array_dtype,\r\n    is_list_like,\r\n    is_number,\r\n    is_numeric_dtype,\r\n    is_re_compilable,\r\n    is_scalar,\r\n    pandas_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import (\r\n    is_hashable,\r\n    is_nested_list_like,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    isna,\r\n    notna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    algorithms as algos,\r\n    arraylike,\r\n    common,\r\n    indexing,\r\n    missing,\r\n    nanops,\r\n    sample,\r\n)\r\nfrom pandas.core.array_algos.replace import should_use_regex\r\nfrom pandas.core.arrays import ExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import extract_array\r\nfrom pandas.core.flags import Flags\r\nfrom pandas.core.indexes.api import (\r\n    DatetimeIndex,\r\n    Index,\r\n    MultiIndex,\r\n    PeriodIndex,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals import BlockManager\r\nfrom pandas.core.methods.describe import describe_ndframe\r\nfrom pandas.core.missing import (\r\n    clean_fill_method,\r\n    clean_reindex_fill_method,\r\n    find_valid_index,\r\n)\r\nfrom pandas.core.reshape.concat import concat\r\nfrom pandas.core.shared_docs import _shared_docs\r\nfrom pandas.core.sorting import get_indexer_indexer\r\nfrom pandas.core.window import (\r\n    Expanding,\r\n    ExponentialMovingWindow,\r\n    Rolling,\r\n    Window,\r\n)\r\n\r\nfrom pandas.io.formats.format import (\r\n    DataFrameFormatter,\r\n    DataFrameRenderer,\r\n)\r\nfrom pandas.io.formats.printing import pprint_thing\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Callable\r\n    from collections.abc import (\r\n        Hashable,\r\n        Iterator,\r\n        Mapping,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas._libs.tslibs import BaseOffset\r\n    from pandas._typing import P\r\n\r\n    from pandas import (\r\n        DataFrame,\r\n        ExcelWriter,\r\n        HDFStore,\r\n        Series,\r\n    )\r\n    from pandas.core.indexers.objects import BaseIndexer\r\n    from pandas.core.resample import Resampler\r\n\r\nimport textwrap\r\n\r\n# goal is to be able to define the docs close to function, while still being\r\n# able to share\r\n_shared_docs = {**_shared_docs}\r\n_shared_doc_kwargs = {\r\n    \"axes\": \"keywords for axes\",\r\n    \"klass\": \"Series/DataFrame\",\r\n    \"axes_single_arg\": \"{0 or 'index'} for Series, {0 or 'index', 1 or 'columns'} for DataFrame\",  # noqa: E501\r\n    \"inplace\": \"\"\"\r\n    inplace : bool, default False\r\n        If True, performs operation inplace and returns None.\"\"\",\r\n    \"optional_by\": \"\"\"\r\n        by : str or list of str\r\n            Name or list of names to sort by\"\"\",\r\n}\r\n\r\n\r\nclass NDFrame(PandasObject, indexing.IndexingMixin):\r\n    \"\"\"\r\n    N-dimensional analogue of DataFrame. Store multi-dimensional in a\r\n    size-mutable, labeled data structure\r\n\r\n    Parameters\r\n    ----------\r\n    data : BlockManager\r\n    axes : list\r\n    copy : bool, default False\r\n    \"\"\"\r\n\r\n    _internal_names: list[str] = [\r\n        \"_mgr\",\r\n        \"_item_cache\",\r\n        \"_cache\",\r\n        \"_name\",\r\n        \"_metadata\",\r\n        \"_flags\",\r\n    ]\r\n    _internal_names_set: set[str] = set(_internal_names)\r\n    _accessors: set[str] = set()\r\n    _hidden_attrs: frozenset[str] = frozenset([])\r\n    _metadata: list[str] = []\r\n    _mgr: Manager\r\n    _attrs: dict[Hashable, Any]\r\n    _typ: str\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __init__(self, data: Manager) -> None:\r\n        object.__setattr__(self, \"_mgr\", data)\r\n        object.__setattr__(self, \"_attrs\", {})\r\n        object.__setattr__(self, \"_flags\", Flags(self, allows_duplicate_labels=True))\r\n\r\n    @final\r\n    @classmethod\r\n    def _init_mgr(\r\n        cls,\r\n        mgr: Manager,\r\n        axes: dict[Literal[\"index\", \"columns\"], Axes | None],\r\n        dtype: DtypeObj | None = None,\r\n        copy: bool = False,\r\n    ) -> Manager:\r\n        \"\"\"passed a manager and a axes dict\"\"\"\r\n        for a, axe in axes.items():\r\n            if axe is not None:\r\n                axe = ensure_index(axe)\r\n                bm_axis = cls._get_block_manager_axis(a)\r\n                mgr = mgr.reindex_axis(axe, axis=bm_axis)\r\n\r\n        # make a copy if explicitly requested\r\n        if copy:\r\n            mgr = mgr.copy()\r\n        if dtype is not None:\r\n            # avoid further copies if we can\r\n            if (\r\n                isinstance(mgr, BlockManager)\r\n                and len(mgr.blocks) == 1\r\n                and mgr.blocks[0].values.dtype == dtype\r\n            ):\r\n                pass\r\n            else:\r\n                mgr = mgr.astype(dtype=dtype)\r\n        return mgr\r\n\r\n    @final\r\n    @classmethod\r\n    def _from_mgr(cls, mgr: Manager, axes: list[Index]) -> Self:\r\n        \"\"\"\r\n        Construct a new object of this type from a Manager object and axes.\r\n\r\n        Parameters\r\n        ----------\r\n        mgr : Manager\r\n            Must have the same ndim as cls.\r\n        axes : list[Index]\r\n\r\n        Notes\r\n        -----\r\n        The axes must match mgr.axes, but are required for future-proofing\r\n        in the event that axes are refactored out of the Manager objects.\r\n        \"\"\"\r\n        obj = cls.__new__(cls)\r\n        NDFrame.__init__(obj, mgr)\r\n        return obj\r\n\r\n    # ----------------------------------------------------------------------\r\n    # attrs and flags\r\n\r\n    @property\r\n    def attrs(self) -> dict[Hashable, Any]:\r\n        \"\"\"\r\n        Dictionary of global attributes of this dataset.\r\n\r\n        .. warning::\r\n\r\n           attrs is experimental and may change without warning.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.flags : Global flags applying to this object.\r\n\r\n        Notes\r\n        -----\r\n        Many operations that create new datasets will copy ``attrs``. Copies\r\n        are always deep so that changing ``attrs`` will only affect the\r\n        present dataset. ``pandas.concat`` copies ``attrs`` only if all input\r\n        datasets have the same ``attrs``.\r\n\r\n        Examples\r\n        --------\r\n        For Series:\r\n\r\n        >>> ser = pd.Series([1, 2, 3])\r\n        >>> ser.attrs = {\"A\": [10, 20, 30]}\r\n        >>> ser.attrs\r\n        {'A': [10, 20, 30]}\r\n\r\n        For DataFrame:\r\n\r\n        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\r\n        >>> df.attrs = {\"A\": [10, 20, 30]}\r\n        >>> df.attrs\r\n        {'A': [10, 20, 30]}\r\n        \"\"\"\r\n        return self._attrs\r\n\r\n    @attrs.setter\r\n    def attrs(self, value: Mapping[Hashable, Any]) -> None:\r\n        self._attrs = dict(value)\r\n\r\n    @final\r\n    @property\r\n    def flags(self) -> Flags:\r\n        \"\"\"\r\n        Get the properties associated with this pandas object.\r\n\r\n        The available flags are\r\n\r\n        * :attr:`Flags.allows_duplicate_labels`\r\n\r\n        See Also\r\n        --------\r\n        Flags : Flags that apply to pandas objects.\r\n        DataFrame.attrs : Global metadata applying to this dataset.\r\n\r\n        Notes\r\n        -----\r\n        \"Flags\" differ from \"metadata\". Flags reflect properties of the\r\n        pandas object (the Series or DataFrame). Metadata refer to properties\r\n        of the dataset, and should be stored in :attr:`DataFrame.attrs`.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2]})\r\n        >>> df.flags\r\n        <Flags(allows_duplicate_labels=True)>\r\n\r\n        Flags can be get or set using ``.``\r\n\r\n        >>> df.flags.allows_duplicate_labels\r\n        True\r\n        >>> df.flags.allows_duplicate_labels = False\r\n\r\n        Or by slicing with a key\r\n\r\n        >>> df.flags[\"allows_duplicate_labels\"]\r\n        False\r\n        >>> df.flags[\"allows_duplicate_labels\"] = True\r\n        \"\"\"\r\n        return self._flags\r\n\r\n    @final\r\n    def set_flags(\r\n        self,\r\n        *,\r\n        copy: bool | lib.NoDefault = lib.no_default,\r\n        allows_duplicate_labels: bool | None = None,\r\n    ) -> Self:\r\n        \"\"\"\r\n        Return a new object with updated flags.\r\n\r\n        This method creates a shallow copy of the original object, preserving its\r\n        underlying data while modifying its global flags. In particular, it allows\r\n        you to update properties such as whether duplicate labels are permitted. This\r\n        behavior is especially useful in method chains, where one wishes to\r\n        adjust DataFrame or Series characteristics without altering the original object.\r\n\r\n        Parameters\r\n        ----------\r\n        copy : bool, default False\r\n            Specify if a copy of the object should be made.\r\n\r\n            .. note::\r\n                The `copy` keyword will change behavior in pandas 3.0.\r\n                `Copy-on-Write\r\n                <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\r\n                will be enabled by default, which means that all methods with a\r\n                `copy` keyword will use a lazy copy mechanism to defer the copy and\r\n                ignore the `copy` keyword. The `copy` keyword will be removed in a\r\n                future version of pandas.\r\n\r\n                You can already get the future behavior and improvements through\r\n                enabling copy on write ``pd.options.mode.copy_on_write = True``\r\n\r\n            .. deprecated:: 3.0.0\r\n        allows_duplicate_labels : bool, optional\r\n            Whether the returned object allows duplicate labels.\r\n\r\n        Returns\r\n        -------\r\n        Series or DataFrame\r\n            The same type as the caller.\r\n\r\n        See Also\r\n        --------\r\n        DataFrame.attrs : Global metadata applying to this dataset.\r\n        DataFrame.flags : Global flags applying to this object.\r\n\r\n        Notes\r\n        -----\r\n        This method returns a new object that's a view on the same data\r\n        as the input. Mutating the input or the output values will be reflected\r\n        in the other.\r\n\r\n        This method is intended to be used in method chains.\r\n\r\n        \"Flags\" differ from \"metadata\". Flags reflect properties of the\r\n        pandas object (the Series or DataFrame). Metadata refer to properties\r\n        of the dataset, and should be stored in :attr:`DataFrame.attrs`.\r\n\r\n        Examples\r\n        --------\r\n        >>> df = pd.DataFrame({\"A\": [1, 2]})\r\n        >>> df.flags.allows_duplicate_labels\r\n        True\r\n        >>> df2 = df.set_flags(allows_duplicate_labels=False)\r\n        >>> df2.flags.allows_duplicate_labels\r\n        False\r\n        \"\"\"\r\n        self._check_copy_deprecation(copy)\r\n        df = self.copy(deep=False)\r\n        if allows_duplicate_labels is not None:\r\n            df.flags[\"allows_duplicate_labels\"] = allows_duplicate_labels\r\n        return df\r\n\r\n    @final\r\n    @classmethod\r\n    def _validate_dtype(cls, dtype) -> DtypeObj | None:\r\n        \"\"\"validate the passed dtype\"\"\"\r\n        if dtype is not None:\r\n            dtype = pandas_dtype(dtype)\r\n\r\n            # a compound dtype\r\n            if dtype.kind == \"V\":\r\n                raise NotImplementedError(\r\n                    \"compound dtypes are not implemented \"\r\n                    f\"in the {cls.__name__} constructor\"\r\n                )\r\n\r\n        return dtype\r\n\r\n    # ----------------------------------------------------------------------\r\n    # Construction\r\n\r\n    # error: Signature of \"_constructor\" incompatible with supertype \"PandasObject\"\r\n    @property\r\n    def _constructor(self) -> Callable[..., Self]:  # type: ignore[override]\r\n        \"\"\"\r\n        Used when a manipulation result has the same dimensions as the\r\n        original.\r\n        \"\"\"\r\n        raise AbstractMethodError(self)\r\n\r\n"]
[600.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[600.002, "i", "sed -n '1,800p' pandas/core/internals/blocks.py\r"]
[600.004, "o", "sed -n '1,800p' pandas/core/internals/blocks.py\r\n"]
[600.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nimport inspect\r\nimport re\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    final,\r\n)\r\nimport warnings\r\nimport weakref\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    internals as libinternals,\r\n    lib,\r\n)\r\nfrom pandas._libs.internals import (\r\n    BlockPlacement,\r\n    BlockValuesRefs,\r\n)\r\nfrom pandas._libs.missing import NA\r\nfrom pandas._typing import (\r\n    ArrayLike,\r\n    AxisInt,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FillnaOptions,\r\n    IgnoreRaise,\r\n    InterpolateOptions,\r\n    QuantileInterpolation,\r\n    Self,\r\n    Shape,\r\n    npt,\r\n)\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    OutOfBoundsDatetime,\r\n)\r\nfrom pandas.util._decorators import cache_readonly\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import validate_bool_kwarg\r\n\r\nfrom pandas.core.dtypes.astype import (\r\n    astype_array_safe,\r\n    astype_is_view,\r\n)\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    convert_dtypes,\r\n    find_result_type,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    is_1d_only_ea_dtype,\r\n    is_float_dtype,\r\n    is_integer_dtype,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_string_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    IntervalDtype,\r\n    NumpyEADtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCIndex,\r\n    ABCNumpyExtensionArray,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import is_re\r\nfrom pandas.core.dtypes.missing import (\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n    na_value_for_dtype,\r\n)\r\n\r\nfrom pandas.core import missing\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.array_algos.putmask import (\r\n    extract_bool_array,\r\n    putmask_inplace,\r\n    putmask_without_repeat,\r\n    setitem_datetimelike_compat,\r\n    validate_putmask,\r\n)\r\nfrom pandas.core.array_algos.quantile import quantile_compat\r\nfrom pandas.core.array_algos.replace import (\r\n    compare_or_regex_search,\r\n    replace_regex,\r\n    should_use_regex,\r\n)\r\nfrom pandas.core.array_algos.transforms import shift\r\nfrom pandas.core.arrays import (\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    IntervalArray,\r\n    NumpyExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.string_ import StringDtype\r\nfrom pandas.core.base import PandasObject\r\nimport pandas.core.common as com\r\nfrom pandas.core.computation import expressions\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n)\r\nfrom pandas.core.indexers import check_setitem_lengths\r\nfrom pandas.core.indexes.base import get_values_for_csv\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Callable,\r\n        Generator,\r\n        Iterable,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas.core.api import Index\r\n    from pandas.core.arrays._mixins import NDArrayBackedExtensionArray\r\n\r\n# comparison is faster than is_object_dtype\r\n_dtype_obj = np.dtype(\"object\")\r\n\r\n\r\nclass Block(PandasObject, libinternals.Block):\r\n    \"\"\"\r\n    Canonical n-dimensional unit of homogeneous dtype contained in a pandas\r\n    data structure\r\n\r\n    Index-ignorant; let the container take care of that\r\n    \"\"\"\r\n\r\n    values: np.ndarray | ExtensionArray\r\n    ndim: int\r\n    refs: BlockValuesRefs\r\n    __init__: Callable\r\n\r\n    __slots__ = ()\r\n    is_numeric = False\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _validate_ndim(self) -> bool:\r\n        \"\"\"\r\n        We validate dimension for blocks that can hold 2D values, which for now\r\n        means numpy dtypes or DatetimeTZDtype.\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        return not isinstance(dtype, ExtensionDtype) or isinstance(\r\n            dtype, DatetimeTZDtype\r\n        )\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_object(self) -> bool:\r\n        return self.values.dtype == _dtype_obj\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_extension(self) -> bool:\r\n        return not lib.is_np_dtype(self.values.dtype)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_consolidate(self) -> bool:\r\n        # We _could_ consolidate for DatetimeTZDtype but don't for now.\r\n        return not self.is_extension\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _consolidate_key(self):\r\n        return self._can_consolidate, self.dtype.name\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_hold_na(self) -> bool:\r\n        \"\"\"\r\n        Can we store NA values in this Block?\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        if isinstance(dtype, np.dtype):\r\n            return dtype.kind not in \"iub\"\r\n        return dtype._can_hold_na\r\n\r\n    @final\r\n    @property\r\n    def is_bool(self) -> bool:\r\n        \"\"\"\r\n        We can be bool if a) we are bool dtype or b) object dtype with bool objects.\r\n        \"\"\"\r\n        return self.values.dtype == np.dtype(bool)\r\n\r\n    @final\r\n    def external_values(self):\r\n        return external_values(self.values)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        return na_value_for_dtype(self.dtype, compat=False)\r\n\r\n    @final\r\n    def _standardize_fill_value(self, value):\r\n        # if we are passed a scalar None, convert it here\r\n        if self.dtype != _dtype_obj and is_valid_na_for_dtype(value, self.dtype):\r\n            value = self.fill_value\r\n        return value\r\n\r\n    @property\r\n    def mgr_locs(self) -> BlockPlacement:\r\n        return self._mgr_locs\r\n\r\n    @mgr_locs.setter\r\n    def mgr_locs(self, new_mgr_locs: BlockPlacement) -> None:\r\n        self._mgr_locs = new_mgr_locs\r\n\r\n    @final\r\n    def make_block(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Create a new block, with type inference propagate any values that are\r\n        not specified\r\n        \"\"\"\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n        if self.is_extension:\r\n            values = ensure_block_shape(values, ndim=self.ndim)\r\n\r\n        return new_block(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def make_block_same_class(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Self:\r\n        \"\"\"Wrap given values in a block of same type as self.\"\"\"\r\n        # Pre-2.0 we called ensure_wrapped_if_datetimelike because fastparquet\r\n        #  relied on it, as of 2.0 the caller is responsible for this.\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n\r\n        # We assume maybe_coerce_values has already been called\r\n        return type(self)(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def __repr__(self) -> str:\r\n        # don't want to print out all of the items here\r\n        name = type(self).__name__\r\n        if self.ndim == 1:\r\n            result = f\"{name}: {len(self)} dtype: {self.dtype}\"\r\n        else:\r\n            shape = \" x \".join([str(s) for s in self.shape])\r\n            result = f\"{name}: {self.mgr_locs.indexer}, {shape}, dtype: {self.dtype}\"\r\n\r\n        return result\r\n\r\n    @final\r\n    def __len__(self) -> int:\r\n        return len(self.values)\r\n\r\n    @final\r\n    def slice_block_columns(self, slc: slice) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n        \"\"\"\r\n        new_mgr_locs = self._mgr_locs[slc]\r\n\r\n        new_values = self._slice(slc)\r\n        refs = self.refs\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def take_block_columns(self, indices: npt.NDArray[np.intp]) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        # Note: only called from is from internals.concat, and we can verify\r\n        #  that never happens with 1-column blocks, i.e. never for ExtensionBlock.\r\n\r\n        new_mgr_locs = self._mgr_locs[indices]\r\n\r\n        new_values = self._slice(indices)\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=None)\r\n\r\n    @final\r\n    def getitem_block_columns(\r\n        self, slicer: slice, new_mgr_locs: BlockPlacement, ref_inplace_op: bool = False\r\n    ) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        new_values = self._slice(slicer)\r\n        refs = self.refs if not ref_inplace_op or self.refs.has_reference() else None\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def _can_hold_element(self, element: Any) -> bool:\r\n        \"\"\"require the same dtype as ourselves\"\"\"\r\n        element = extract_array(element, extract_numpy=True)\r\n        return can_hold_element(self.values, element)\r\n\r\n    @final\r\n    def should_store(self, value: ArrayLike) -> bool:\r\n        \"\"\"\r\n        Should we set self.values[indexer] = value inplace or do we need to cast?\r\n\r\n        Parameters\r\n        ----------\r\n        value : np.ndarray or ExtensionArray\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n        \"\"\"\r\n        return value.dtype == self.dtype\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Apply/Reduce and Helpers\r\n\r\n    @final\r\n    def apply(self, func, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        apply the function to my values; return a block if we are not\r\n        one\r\n        \"\"\"\r\n        result = func(self.values, **kwargs)\r\n\r\n        result = maybe_coerce_values(result)\r\n        return self._split_op_result(result)\r\n\r\n    @final\r\n    def reduce(self, func) -> list[Block]:\r\n        # We will apply the function and reshape the result into a single-row\r\n        #  Block with the same mgr_locs; squeezing will be done at a higher level\r\n        assert self.ndim == 2\r\n\r\n        result = func(self.values)\r\n\r\n        if self.values.ndim == 1:\r\n            res_values = result\r\n        else:\r\n            res_values = result.reshape(-1, 1)\r\n\r\n        nb = self.make_block(res_values)\r\n        return [nb]\r\n\r\n    @final\r\n    def _split_op_result(self, result: ArrayLike) -> list[Block]:\r\n        # See also: split_and_operate\r\n        if result.ndim > 1 and isinstance(result.dtype, ExtensionDtype):\r\n            # TODO(EA2D): unnecessary with 2D EAs\r\n            # if we get a 2D ExtensionArray, we need to split it into 1D pieces\r\n            nbs = []\r\n            for i, loc in enumerate(self._mgr_locs):\r\n                if not is_1d_only_ea_dtype(result.dtype):\r\n                    vals = result[i : i + 1]\r\n                else:\r\n                    vals = result[i]\r\n\r\n                bp = BlockPlacement(loc)\r\n                block = self.make_block(values=vals, placement=bp)\r\n                nbs.append(block)\r\n            return nbs\r\n\r\n        nb = self.make_block(result)\r\n\r\n        return [nb]\r\n\r\n    @final\r\n    def _split(self) -> Generator[Block]:\r\n        \"\"\"\r\n        Split a block into a list of single-column blocks.\r\n        \"\"\"\r\n        assert self.ndim == 2\r\n\r\n        for i, ref_loc in enumerate(self._mgr_locs):\r\n            vals = self.values[slice(i, i + 1)]\r\n\r\n            bp = BlockPlacement(ref_loc)\r\n            nb = type(self)(vals, placement=bp, ndim=2, refs=self.refs)\r\n            yield nb\r\n\r\n    @final\r\n    def split_and_operate(self, func, *args, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        Split the block and apply func column-by-column.\r\n\r\n        Parameters\r\n        ----------\r\n        func : Block method\r\n        *args\r\n        **kwargs\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        assert self.ndim == 2 and self.shape[0] != 1\r\n\r\n        res_blocks = []\r\n        for nb in self._split():\r\n            rbs = func(nb, *args, **kwargs)\r\n            res_blocks.extend(rbs)\r\n        return res_blocks\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Up/Down-casting\r\n\r\n    @final\r\n    def coerce_to_target_dtype(self, other, raise_on_upcast: bool) -> Block:\r\n        \"\"\"\r\n        coerce the current block to a dtype compat for other\r\n        we will return a block, possibly object, and not raise\r\n\r\n        we can also safely try to coerce to the same dtype\r\n        and will receive the same block\r\n        \"\"\"\r\n        new_dtype = find_result_type(self.values.dtype, other)\r\n        if new_dtype == self.dtype:\r\n            # GH#52927 avoid RecursionError\r\n            raise AssertionError(\r\n                \"Something has gone wrong, please report a bug at \"\r\n                \"https://github.com/pandas-dev/pandas/issues\"\r\n            )\r\n\r\n        # In a future version of pandas, the default will be that\r\n        # setting `nan` into an integer series won't raise.\r\n        if (\r\n            is_scalar(other)\r\n            and is_integer_dtype(self.values.dtype)\r\n            and isna(other)\r\n            and other is not NaT\r\n            and not (\r\n                isinstance(other, (np.datetime64, np.timedelta64)) and np.isnat(other)\r\n            )\r\n        ):\r\n            raise_on_upcast = False\r\n        elif (\r\n            isinstance(other, np.ndarray)\r\n            and other.ndim == 1\r\n            and is_integer_dtype(self.values.dtype)\r\n            and is_float_dtype(other.dtype)\r\n            and lib.has_only_ints_or_nan(other)\r\n        ):\r\n            raise_on_upcast = False\r\n\r\n        if raise_on_upcast:\r\n            raise TypeError(f\"Invalid value '{other}' for dtype '{self.values.dtype}'\")\r\n        if self.values.dtype == new_dtype:\r\n            raise AssertionError(\r\n                f\"Did not expect new dtype {new_dtype} to equal self.dtype \"\r\n                f\"{self.values.dtype}. Please report a bug at \"\r\n                \"https://github.com/pandas-dev/pandas/issues.\"\r\n            )\r\n        try:\r\n            return self.astype(new_dtype)\r\n        except OutOfBoundsDatetime as err:\r\n            # e.g. GH#56419 if self.dtype is a low-resolution dt64 and we try to\r\n            #  upcast to a higher-resolution dt64, we may have entries that are\r\n            #  out of bounds for the higher resolution.\r\n            #  Re-raise with a more informative message.\r\n            raise OutOfBoundsDatetime(\r\n                f\"Incompatible (high-resolution) value for dtype='{self.dtype}'. \"\r\n                \"Explicitly cast before operating.\"\r\n            ) from err\r\n\r\n    @final\r\n    def convert(self) -> list[Block]:\r\n        \"\"\"\r\n        Attempt to coerce any object types to better types. Return a copy\r\n        of the block (if copy = True).\r\n        \"\"\"\r\n        if not self.is_object:\r\n            return [self.copy(deep=False)]\r\n\r\n        if self.ndim != 1 and self.shape[0] != 1:\r\n            blocks = self.split_and_operate(Block.convert)\r\n            if all(blk.dtype.kind == \"O\" for blk in blocks):\r\n                # Avoid fragmenting the block if convert is a no-op\r\n                return [self.copy(deep=False)]\r\n            return blocks\r\n\r\n        values = self.values\r\n        if values.ndim == 2:\r\n            # the check above ensures we only get here with values.shape[0] == 1,\r\n            # avoid doing .ravel as that might make a copy\r\n            values = values[0]\r\n\r\n        res_values = lib.maybe_convert_objects(\r\n            values,  # type: ignore[arg-type]\r\n            convert_non_numeric=True,\r\n        )\r\n        refs = None\r\n        if res_values is values or (\r\n            isinstance(res_values, NumpyExtensionArray)\r\n            and res_values._ndarray is values\r\n        ):\r\n            refs = self.refs\r\n\r\n        res_values = ensure_block_shape(res_values, self.ndim)\r\n        res_values = maybe_coerce_values(res_values)\r\n        return [self.make_block(res_values, refs=refs)]\r\n\r\n    def convert_dtypes(\r\n        self,\r\n        infer_objects: bool = True,\r\n        convert_string: bool = True,\r\n        convert_integer: bool = True,\r\n        convert_boolean: bool = True,\r\n        convert_floating: bool = True,\r\n        dtype_backend: DtypeBackend = \"numpy_nullable\",\r\n    ) -> list[Block]:\r\n        if infer_objects and self.is_object:\r\n            blks = self.convert()\r\n        else:\r\n            blks = [self]\r\n\r\n        if not any(\r\n            [convert_floating, convert_integer, convert_boolean, convert_string]\r\n        ):\r\n            return [b.copy(deep=False) for b in blks]\r\n\r\n        rbs = []\r\n        for blk in blks:\r\n            # Determine dtype column by column\r\n            sub_blks = (\r\n                [blk] if blk.ndim == 1 or self.shape[0] == 1 else list(blk._split())\r\n            )\r\n            dtypes = [\r\n                convert_dtypes(\r\n                    b.values,\r\n                    convert_string,\r\n                    convert_integer,\r\n                    convert_boolean,\r\n                    convert_floating,\r\n                    infer_objects,\r\n                    dtype_backend,\r\n                )\r\n                for b in sub_blks\r\n            ]\r\n            if all(dtype == self.dtype for dtype in dtypes):\r\n                # Avoid block splitting if no dtype changes\r\n                rbs.append(blk.copy(deep=False))\r\n                continue\r\n\r\n            for dtype, b in zip(dtypes, sub_blks):\r\n                rbs.append(b.astype(dtype=dtype, squeeze=b.ndim != 1))\r\n        return rbs\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Array-Like Methods\r\n\r\n    @final\r\n    @cache_readonly\r\n    def dtype(self) -> DtypeObj:\r\n        return self.values.dtype\r\n\r\n    @final\r\n    def astype(\r\n        self,\r\n        dtype: DtypeObj,\r\n        errors: IgnoreRaise = \"raise\",\r\n        squeeze: bool = False,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Coerce to the new dtype.\r\n\r\n        Parameters\r\n        ----------\r\n        dtype : np.dtype or ExtensionDtype\r\n        errors : str, {'raise', 'ignore'}, default 'raise'\r\n            - ``raise`` : allow exceptions to be raised\r\n            - ``ignore`` : suppress exceptions. On error return original object\r\n        squeeze : bool, default False\r\n            squeeze values to ndim=1 if only one column is given\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n        \"\"\"\r\n        values = self.values\r\n        if squeeze and values.ndim == 2 and is_1d_only_ea_dtype(dtype):\r\n            if values.shape[0] != 1:\r\n                raise ValueError(\"Can not squeeze with more than one column.\")\r\n            values = values[0, :]  # type: ignore[call-overload]\r\n\r\n        new_values = astype_array_safe(values, dtype, errors=errors)\r\n\r\n        new_values = maybe_coerce_values(new_values)\r\n\r\n        refs = None\r\n        if astype_is_view(values.dtype, new_values.dtype):\r\n            refs = self.refs\r\n\r\n        newb = self.make_block(new_values, refs=refs)\r\n        if newb.shape != self.shape:\r\n            raise TypeError(\r\n                f\"cannot set astype for dtype \"\r\n                f\"({self.dtype.name} [{self.shape}]) to different shape \"\r\n                f\"({newb.dtype.name} [{newb.shape}])\"\r\n            )\r\n        return newb\r\n\r\n    @final\r\n    def get_values_for_csv(\r\n        self, *, float_format, date_format, decimal, na_rep: str = \"nan\", quoting=None\r\n    ) -> Block:\r\n        \"\"\"convert to our native types format\"\"\"\r\n        result = get_values_for_csv(\r\n            self.values,\r\n            na_rep=na_rep,\r\n            quoting=quoting,\r\n            float_format=float_format,\r\n            date_format=date_format,\r\n            decimal=decimal,\r\n        )\r\n        return self.make_block(result)\r\n\r\n    @final\r\n    def copy(self, deep: bool = True) -> Self:\r\n        \"\"\"copy constructor\"\"\"\r\n        values = self.values\r\n        refs: BlockValuesRefs | None\r\n        if deep:\r\n            values = values.copy()\r\n            refs = None\r\n        else:\r\n            refs = self.refs\r\n        return type(self)(values, placement=self._mgr_locs, ndim=self.ndim, refs=refs)\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Copy-on-Write Helpers\r\n\r\n    def _maybe_copy(self, inplace: bool) -> Self:\r\n        if inplace:\r\n            deep = self.refs.has_reference()\r\n            return self.copy(deep=deep)\r\n        return self.copy()\r\n\r\n    @final\r\n    def _get_refs_and_copy(self, inplace: bool):\r\n        refs = None\r\n        copy = not inplace\r\n        if inplace:\r\n            if self.refs.has_reference():\r\n                copy = True\r\n            else:\r\n                refs = self.refs\r\n        return copy, refs\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Replace\r\n\r\n    @final\r\n    def replace(\r\n        self,\r\n        to_replace,\r\n        value,\r\n        inplace: bool = False,\r\n        # mask may be pre-computed if we're called from replace_list\r\n        mask: npt.NDArray[np.bool_] | None = None,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n        replace the to_replace value with value, possible to create new\r\n        blocks here this is just a call to putmask.\r\n        \"\"\"\r\n\r\n        # Note: the checks we do in NDFrame.replace ensure we never get\r\n        #  here with listlike to_replace or value, as those cases\r\n        #  go through replace_list\r\n        values = self.values\r\n\r\n        if not self._can_hold_element(to_replace):\r\n            # We cannot hold `to_replace`, so we know immediately that\r\n            #  replacing it is a no-op.\r\n            # Note: If to_replace were a list, NDFrame.replace would call\r\n            #  replace_list instead of replace.\r\n            return [self.copy(deep=False)]\r\n\r\n        if mask is None:\r\n            mask = missing.mask_missing(values, to_replace)\r\n        if not mask.any():\r\n            # Note: we get here with test_replace_extension_other incorrectly\r\n            #  bc _can_hold_element is incorrect.\r\n            return [self.copy(deep=False)]\r\n\r\n        elif self._can_hold_element(value) or (self.dtype == \"string\" and is_re(value)):\r\n            # TODO(CoW): Maybe split here as well into columns where mask has True\r\n            # and rest?\r\n            blk = self._maybe_copy(inplace)\r\n            putmask_inplace(blk.values, mask, value)\r\n            return [blk]\r\n\r\n        elif self.ndim == 1 or self.shape[0] == 1:\r\n            if value is None or value is NA:\r\n                blk = self.astype(np.dtype(object))\r\n            else:\r\n                blk = self.coerce_to_target_dtype(value, raise_on_upcast=False)\r\n            return blk.replace(\r\n                to_replace=to_replace,\r\n                value=value,\r\n                inplace=True,\r\n                mask=mask,\r\n            )\r\n\r\n        else:\r\n            # split so that we only upcast where necessary\r\n            blocks = []\r\n            for i, nb in enumerate(self._split()):\r\n                blocks.extend(\r\n                    type(self).replace(\r\n                        nb,\r\n                        to_replace=to_replace,\r\n                        value=value,\r\n                        inplace=True,\r\n                        mask=mask[i : i + 1],\r\n                    )\r\n                )\r\n            return blocks\r\n\r\n    @final\r\n    def _replace_regex(\r\n        self,\r\n        to_replace,\r\n        value,\r\n        inplace: bool = False,\r\n        mask=None,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n        Replace elements by the given value.\r\n\r\n        Parameters\r\n        ----------\r\n        to_replace : object or pattern\r\n            Scalar to replace or regular expression to match.\r\n        value : object\r\n            Replacement object.\r\n        inplace : bool, default False\r\n            Perform inplace modification.\r\n        mask : array-like of bool, optional\r\n            True indicate corresponding element is ignored.\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        if not is_re(to_replace) and not self._can_hold_element(to_replace):\r\n            # i.e. only if self.is_object is True, but could in principle include a\r\n            #  String ExtensionBlock\r\n            return [self.copy(deep=False)]\r\n\r\n        if is_re(to_replace) and self.dtype not in [object, \"string\"]:\r\n            # only object or string dtype can hold strings, and a regex object\r\n            # will only match strings\r\n            return [self.copy(deep=False)]\r\n\r\n        if not (\r\n            self._can_hold_element(value) or (self.dtype == \"string\" and is_re(value))\r\n        ):\r\n            block = self.astype(np.dtype(object))\r\n        else:\r\n            block = self._maybe_copy(inplace)\r\n\r\n        rx = re.compile(to_replace)\r\n\r\n        replace_regex(block.values, rx, value, mask)\r\n        return [block]\r\n\r\n    @final\r\n    def replace_list(\r\n        self,\r\n        src_list: Iterable[Any],\r\n        dest_list: Sequence[Any],\r\n        inplace: bool = False,\r\n        regex: bool = False,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n"]
[605.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[605.002, "i", "cd asv_bench\r"]
[605.004, "o", "cd asv_bench\r\n"]
[605.006, "o", "\u001b[?2004l\r\n"]
[610.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[610.002, "i", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools | tee ../pr\r"]
[610.004, "o", "asv profile --python=same --config=asv.conf.json frame_methods.MaskBool.time_frame_mask_bools | tee ../pr\r\n"]
[610.006, "o", "rofile_maskbool.txt\r\n\u001b[?2004l\r\n\u00b7 Discovering benchmarks\r\n\u00b7 Profile data does not already exist. Running profiler now.\r\n\u00b7\u00b7 Benchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\r\n\u00b7\u00b7\u00b7 Importing benchmark suite produced output:\r\n\u00b7\u00b7\u00b7\u00b7 meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 Running (frame_methods.MaskBool.time_frame_mask_bools--).\r\n\u00b7\u00b7\u00b7 frame_methods.MaskBool.time_frame_mask_bools            46.3\u00b10.3ms\r\n\r\nWed Oct  1 17:28:18 2025    /tmp/tmp88rtfagr\r\n\r\n         83260 function calls (82244 primitive calls) in 0.136 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.136    0.136 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.136    0.136 _base.py:689(method_caller)\r\n        1    0.004    0.004    0.136    0.136 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.132    0.132 generic.py:10068(mask)\r\n        1    0.000    0.000    0.131    0.131 generic.py:9685(_where)\r\n        7    0.000    0.000    0.130    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.130    0.130 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.129    0.129 blocks.py:1211(where)\r\n      500    0.001    0.000    0.086    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.066    0.000 common.py:702(is_integer_dtype)\r\n      500    0.064    0.000    0.064    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.003    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.006    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.000    0.000    0.003    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.002    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     1001    0.001    0.000    0.001    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:966(_validate_tuple_indexer)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:69(_wrapreduction)\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        9    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n        1    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6634(infer_objects)\r\n        6    0.000    0.000    0.000    0.000 range.py:551(_view)\r\n        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n      4/3    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 managers.py:851(_slice_take_blocks_ax0)\r\n        7    0.000    0.000    0.000    0.000 range.py:237(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 managers.py:448(fillna)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1581(_validate_key)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6119(__setattr__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5387(<genexpr>)\r\n    33/21    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        7    0.000    0.000    0.000    0.000 managers.py:1085(from_blocks)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1040(_getitem_lowerdim)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n        2    0.000    0.000    0.000    0.000 common.py:101(is_bool_indexer)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:5501(identical)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1953(empty)\r\n        1    0.000    0.000    0.000    0.000 managers.py:590(convert)\r\n        2    0.000    0.000    0.000    0.000 managers.py:214(shape)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n        1    0.000    0.000    0.000    0.000 base.py:882(__iter__)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:370(_split_op_result)\r\n       10    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2741(check_dict_or_set_indexers)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n        1    0.000    0.000    0.000    0.000 series.py:734(name)\r\n        3    0.000    0.000    0.000    0.000 generic.py:2011(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:1314(fillna)\r\n        5    0.000    0.000    0.000    0.000 blocks.py:642(copy)\r\n        5    0.000    0.000    0.000    0.000 common.py:376(apply_if_callable)\r\n       12    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n        3    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1186(<genexpr>)\r\n        5    0.000    0.000    0.000    0.000 generic.py:536(_get_axis)\r\n        6    0.000    0.000    0.000    0.000 managers.py:216(<genexpr>)\r\n        5    0.000    0.000    0.000    0.000 generic.py:542(_get_block_manager_axis)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1658(_is_scalar_access)\r\n        1    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\r\n        1    0.000    0.000    0.000    0.000 range.py:1209(_getitem_slice)\r\n        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 managers.py:612(any_extension_types)\r\n        3    0.000    0.000    0.000    0.000 series.py:780(_values)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1019(shape)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:982(_is_nested_tuple_indexer)\r\n       13    0.000    0.000    0.000    0.000 generic.py:520(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 series.py:683(name)\r\n        1    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n        1    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n        2    0.000    0.000    0.000    0.000 base.py:5537(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:306(getitem_block_columns)\r\n        4    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 base.py:7642(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:944(_expand_ellipsis)\r\n       15    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x56519d592640}\r\n        1    0.000    0.000    0.000    0.000 base.py:3981(_validate_positional_slice)\r\n        1    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:490(convert)\r\n       20    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n        2    0.000    0.000    0.000    0.000 base.py:552(find)\r\n        3    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n        4    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\r\n        2    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n        3    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n        2    0.000    0.000    0.000    0.000 managers.py:615(<genexpr>)\r\n        7    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:186(_can_hold_na)\r\n        1    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n       10    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n        3    0.000    0.000    0.000    0.000 range.py:664(equals)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        2    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n       10    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n        1    0.000    0.000    0.000    0.000 frame.py:1087(_values)\r\n        1    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6102(__getattr__)\r\n        7    0.000    0.000    0.000    0.000 generic.py:639(ndim)\r\n        1    0.000    0.000    0.000    0.000 common.py:593(require_length_match)\r\n        8    0.000    0.000    0.000    0.000 managers.py:1050(__init__)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n        2    0.000    0.000    0.000    0.000 generic.py:618(_info_axis)\r\n        3    0.000    0.000    0.000    0.000 base.py:6590(_validate_indexer)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:970(_slice)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1000(_validate_key_length)\r\n        2    0.000    0.000    0.000    0.000 common.py:314(is_null_slice)\r\n        7    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\r\n        2    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 indexing.py:156(iloc)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2446(_preprocess_slice_or_indexer)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2753(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:1185(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n        3    0.000    0.000    0.000    0.000 generic.py:4368(_check_copy_deprecation)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:989(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:2746(<genexpr>)\r\n        2    0.000    0.000    0.000    0.000 base.py:7558(ensure_index)\r\n        2    0.000    0.000    0.000    0.000 base.py:1729(name)\r\n        1    0.000    0.000    0.000    0.000 managers.py:338(<listcomp>)\r\n        3    0.000    0.000    0.000    0.000 indexing.py:950(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:291(is_single_block)\r\n        2    0.000    0.000    0.000    0.000 indexing.py:2714(is_label_like)\r\n        6    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n        2    0.000    0.000    0.000    0.000 indexing.py:1671(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:165(is_object)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:426(__exit__)\r\n        1    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 frame.py:997(axes)\r\n        1    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n        2    0.000    0.000    0.000    0.000 range.py:442(dtype)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:420(__init__)\r\n        2    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n        3    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 missing.py:1029(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3364(_prod_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n        2    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 indexing.py:2728(need_slice)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:222(mgr_locs)\r\n        1    0.000    0.000    0.000    0.000 contextlib.py:423(__enter__)\r\n\r\n\r\n"]
[615.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[615.002, "i", "cd ..\r"]
[615.004, "o", "cd ..\r\n"]
[615.006, "o", "\u001b[?2004l\r\n"]
[620.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[620.002, "i", "sed -n '1,120p' profile_maskbool.txt\r"]
[620.004, "o", "sed -n '1,120p' profile_maskbool.txt\r\n"]
[620.006, "o", "\u001b[?2004l\r\n\u00b7 Discovering benchmarks\r\n\u00b7 Profile data does not already exist. Running profiler now.\r\n\u00b7\u00b7 Benchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\r\n\u00b7\u00b7\u00b7 Importing benchmark suite produced output:\r\n\u00b7\u00b7\u00b7\u00b7 meson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\r\n     [1/1] Generating write_version_file with a custom command\r\n\r\n\u00b7\u00b7\u00b7 Running (frame_methods.MaskBool.time_frame_mask_bools--).\r\n\u00b7\u00b7\u00b7 frame_methods.MaskBool.time_frame_mask_bools            46.3\u00b10.3ms\r\n\r\nWed Oct  1 17:28:18 2025    /tmp/tmp88rtfagr\r\n\r\n         83260 function calls (82244 primitive calls) in 0.136 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.136    0.136 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.136    0.136 _base.py:689(method_caller)\r\n        1    0.004    0.004    0.136    0.136 frame_methods.py:365(time_frame_mask_bools)\r\n        1    0.000    0.000    0.132    0.132 generic.py:10068(mask)\r\n        1    0.000    0.000    0.131    0.131 generic.py:9685(_where)\r\n        7    0.000    0.000    0.130    0.019 managers.py:392(apply)\r\n        1    0.000    0.000    0.130    0.130 managers.py:461(where)\r\n   1001/1    0.010    0.000    0.129    0.129 blocks.py:1211(where)\r\n      500    0.001    0.000    0.086    0.000 blocks.py:432(coerce_to_target_dtype)\r\n      500    0.001    0.000    0.066    0.000 common.py:702(is_integer_dtype)\r\n      500    0.064    0.000    0.064    0.000 common.py:129(_classes_and_not_datetimelike)\r\n      500    0.001    0.000    0.017    0.000 blocks.py:581(astype)\r\n      500    0.001    0.000    0.011    0.000 astype.py:188(astype_array_safe)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:247(where)\r\n      500    0.000    0.000    0.010    0.000 expressions.py:178(_where_numexpr)\r\n      500    0.001    0.000    0.009    0.000 astype.py:154(astype_array)\r\n      500    0.009    0.000    0.009    0.000 expressions.py:173(_where_standard)\r\n      500    0.003    0.000    0.008    0.000 astype.py:53(_astype_nansafe)\r\n23131/23128    0.004    0.000    0.006    0.000 {built-in method builtins.isinstance}\r\n     1001    0.001    0.000    0.006    0.000 putmask.py:102(validate_putmask)\r\n     1502    0.005    0.000    0.005    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:230(make_block)\r\n     1001    0.000    0.000    0.004    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n     1001    0.001    0.000    0.004    0.000 blocks.py:215(_standardize_fill_value)\r\n     1001    0.000    0.000    0.003    0.000 _methods.py:59(_any)\r\n      501    0.003    0.000    0.003    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n      500    0.001    0.000    0.003    0.000 putmask.py:130(setitem_datetimelike_compat)\r\n     3520    0.001    0.000    0.002    0.000 generic.py:43(_instancecheck)\r\n      500    0.000    0.000    0.002    0.000 {method 'sum' of 'numpy.ndarray' objects}\r\n      500    0.000    0.000    0.002    0.000 _methods.py:51(_sum)\r\n      500    0.000    0.000    0.002    0.000 cast.py:761(infer_dtype_from)\r\n     1002    0.001    0.000    0.002    0.000 blocks.py:2231(new_block)\r\n     2002    0.001    0.000    0.002    0.000 putmask.py:116(extract_bool_array)\r\n      500    0.001    0.000    0.002    0.000 cast.py:1292(find_result_type)\r\n     1001    0.001    0.000    0.002    0.000 missing.py:660(is_valid_na_for_dtype)\r\n      500    0.001    0.000    0.002    0.000 cast.py:774(infer_dtype_from_scalar)\r\n     1001    0.001    0.000    0.001    0.000 cast.py:1770(np_can_hold_element)\r\n     3520    0.001    0.000    0.001    0.000 generic.py:38(_check)\r\n      500    0.001    0.000    0.001    0.000 _dtype.py:350(_name_get)\r\n      500    0.001    0.000    0.001    0.000 numerictypes.py:471(issubdtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1356(is_bool_dtype)\r\n      502    0.001    0.000    0.001    0.000 blocks.py:2160(maybe_coerce_values)\r\n     1002    0.001    0.000    0.001    0.000 blocks.py:2189(get_block_type)\r\n      501    0.001    0.000    0.001    0.000 blocks.py:392(_split)\r\n      501    0.001    0.000    0.001    0.000 astype.py:246(astype_is_view)\r\n      500    0.000    0.000    0.001    0.000 common.py:1561(_is_dtype)\r\n      500    0.000    0.000    0.001    0.000 common.py:1620(_is_dtype_type)\r\n      501    0.000    0.000    0.001    0.000 blocks.py:209(fill_value)\r\n     1000    0.000    0.000    0.001    0.000 numerictypes.py:289(issubclass_)\r\n     1001    0.000    0.000    0.001    0.000 missing.py:97(isna)\r\n     4506    0.001    0.000    0.001    0.000 {built-in method builtins.issubclass}\r\n      502    0.000    0.000    0.001    0.000 common.py:1782(pandas_dtype)\r\n     2002    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\r\n     1000    0.000    0.000    0.001    0.000 common.py:1585(_get_dtype)\r\n      501    0.000    0.000    0.000    0.000 missing.py:603(na_value_for_dtype)\r\n     1002    0.000    0.000    0.000    0.000 blocks.py:170(is_extension)\r\n     1501    0.000    0.000    0.000    0.000 blocks.py:957(shape)\r\n      503    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n     1001    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n     3537    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n      501    0.000    0.000    0.000    0.000 cast.py:921(_maybe_infer_dtype_type)\r\n      500    0.000    0.000    0.000    0.000 common.py:134(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 cast.py:522(ensure_dtype_can_hold_na)\r\n     1003    0.000    0.000    0.000    0.000 blocks.py:576(dtype)\r\n        7    0.000    0.000    0.000    0.000 blocks.py:2309(extend_blocks)\r\n      500    0.000    0.000    0.000    0.000 expressions.py:77(_can_use_numexpr)\r\n      500    0.000    0.000    0.000    0.000 common.py:764(<lambda>)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n      500    0.000    0.000    0.000    0.000 inspect.py:191(isclass)\r\n      500    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6232(dtypes)\r\n     1004    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n        1    0.000    0.000    0.000    0.000 generic.py:1490(__invert__)\r\n        1    0.000    0.000    0.000    0.000 series.py:366(__init__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1181(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1695(_getitem_tuple)\r\n        1    0.000    0.000    0.000    0.000 generic.py:9364(align)\r\n      500    0.000    0.000    0.000    0.000 multiarray.py:363(where)\r\n      500    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:9540(_align_frame)\r\n        8    0.000    0.000    0.000    0.000 frame.py:663(_constructor_from_mgr)\r\n      502    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        2    0.000    0.000    0.000    0.000 generic.py:5448(_reindex_with_indexers)\r\n        8    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n        1    0.000    0.000    0.000    0.000 frame.py:5203(reindex)\r\n        3    0.000    0.000    0.000    0.000 managers.py:693(copy)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5127(reindex)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1012(_getitem_tuple_same_dim)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:343(apply)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1725(_getitem_axis)\r\n       10    0.000    0.000    0.000    0.000 generic.py:6055(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 indexing.py:1762(_get_slice_axis)\r\n        9    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n        1    0.000    0.000    0.000    0.000 generic.py:4244(_slice)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6476(copy)\r\n        1    0.000    0.000    0.000    0.000 {built-in method _operator.invert}\r\n      506    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\r\n        1    0.000    0.000    0.000    0.000 generic.py:663(size)\r\n        1    0.000    0.000    0.000    0.000 managers.py:337(get_dtypes)\r\n        1    0.000    0.000    0.000    0.000 generic.py:6919(fillna)\r\n        3    0.000    0.000    0.000    0.000 managers.py:716(<listcomp>)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:3369(prod)\r\n        6    0.000    0.000    0.000    0.000 base.py:1025(view)\r\n"]
[625.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[625.002, "i", "grep -R -n -F \"def where\" pandas/core | head -n 50\r"]
[625.004, "o", "grep -R -n -F \"def where\" pandas/core | head -n 50\r\n"]
[625.006, "o", "\u001b[?2004l\r\npandas/core/computation/expressions.py:247:def where(cond, left_op, right_op, use_numexpr: bool = True):\r\npandas/core/generic.py:9831:    def where(\r\npandas/core/generic.py:9842:    def where(\r\npandas/core/generic.py:9853:    def where(\r\npandas/core/generic.py:9871:    def where(\r\npandas/core/indexes/base.py:5069:    def where(self, cond, other=None) -> Index:\r\npandas/core/internals/blocks.py:1211:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1664:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[630.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[630.002, "i", "grep -R -n -F \"def mask\" pandas/core | head -n 50\r"]
[630.004, "o", "grep -R -n -F \"def mask\" pandas/core | head -n 50\r\n"]
[630.006, "o", "\u001b[?2004l\r\npandas/core/ops/missing.py:72:def mask_zero_div_zero(x, y, result: np.ndarray) -> np.ndarray:\r\npandas/core/reshape/reshape.py:225:    def mask_all(self) -> bool:\r\npandas/core/missing.py:67:def mask_missing(arr: ArrayLike, values_to_mask) -> npt.NDArray[np.bool_]:\r\npandas/core/generic.py:10036:    def mask(\r\npandas/core/generic.py:10047:    def mask(\r\npandas/core/generic.py:10058:    def mask(\r\npandas/core/generic.py:10077:    def mask(\r\n"]
[635.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[635.002, "i", "grep -n \"class Boolean\" pandas/core/internals/blocks.py\r"]
[635.004, "o", "grep -n \"class Boolean\" pandas/core/internals/blocks.py\r\n"]
[635.006, "o", "\u001b[?2004l\r\n"]
[640.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[640.002, "i", "grep -n -F \"def where\" pandas/core/internals/blocks.py\r"]
[640.004, "o", "grep -n -F \"def where\" pandas/core/internals/blocks.py\r\n"]
[640.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K1211\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(self, other, cond) -> list[Block]:\r\n\u001b[32m\u001b[K1664\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(self, other, cond) -> list[Block]:\r\n"]
[645.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[645.002, "i", "sed -n '1,1200p' pandas/core/internals/blocks.py\r"]
[645.004, "o", "sed -n '1,1200p' pandas/core/internals/blocks.py\r\n"]
[645.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nimport inspect\r\nimport re\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    cast,\r\n    final,\r\n)\r\nimport warnings\r\nimport weakref\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    internals as libinternals,\r\n    lib,\r\n)\r\nfrom pandas._libs.internals import (\r\n    BlockPlacement,\r\n    BlockValuesRefs,\r\n)\r\nfrom pandas._libs.missing import NA\r\nfrom pandas._typing import (\r\n    ArrayLike,\r\n    AxisInt,\r\n    DtypeBackend,\r\n    DtypeObj,\r\n    FillnaOptions,\r\n    IgnoreRaise,\r\n    InterpolateOptions,\r\n    QuantileInterpolation,\r\n    Self,\r\n    Shape,\r\n    npt,\r\n)\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    OutOfBoundsDatetime,\r\n)\r\nfrom pandas.util._decorators import cache_readonly\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import validate_bool_kwarg\r\n\r\nfrom pandas.core.dtypes.astype import (\r\n    astype_array_safe,\r\n    astype_is_view,\r\n)\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    convert_dtypes,\r\n    find_result_type,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    is_1d_only_ea_dtype,\r\n    is_float_dtype,\r\n    is_integer_dtype,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_string_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    IntervalDtype,\r\n    NumpyEADtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCIndex,\r\n    ABCNumpyExtensionArray,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.inference import is_re\r\nfrom pandas.core.dtypes.missing import (\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n    na_value_for_dtype,\r\n)\r\n\r\nfrom pandas.core import missing\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.array_algos.putmask import (\r\n    extract_bool_array,\r\n    putmask_inplace,\r\n    putmask_without_repeat,\r\n    setitem_datetimelike_compat,\r\n    validate_putmask,\r\n)\r\nfrom pandas.core.array_algos.quantile import quantile_compat\r\nfrom pandas.core.array_algos.replace import (\r\n    compare_or_regex_search,\r\n    replace_regex,\r\n    should_use_regex,\r\n)\r\nfrom pandas.core.array_algos.transforms import shift\r\nfrom pandas.core.arrays import (\r\n    DatetimeArray,\r\n    ExtensionArray,\r\n    IntervalArray,\r\n    NumpyExtensionArray,\r\n    PeriodArray,\r\n    TimedeltaArray,\r\n)\r\nfrom pandas.core.arrays.string_ import StringDtype\r\nfrom pandas.core.base import PandasObject\r\nimport pandas.core.common as com\r\nfrom pandas.core.computation import expressions\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n)\r\nfrom pandas.core.indexers import check_setitem_lengths\r\nfrom pandas.core.indexes.base import get_values_for_csv\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import (\r\n        Callable,\r\n        Generator,\r\n        Iterable,\r\n        Sequence,\r\n    )\r\n\r\n    from pandas.core.api import Index\r\n    from pandas.core.arrays._mixins import NDArrayBackedExtensionArray\r\n\r\n# comparison is faster than is_object_dtype\r\n_dtype_obj = np.dtype(\"object\")\r\n\r\n\r\nclass Block(PandasObject, libinternals.Block):\r\n    \"\"\"\r\n    Canonical n-dimensional unit of homogeneous dtype contained in a pandas\r\n    data structure\r\n\r\n    Index-ignorant; let the container take care of that\r\n    \"\"\"\r\n\r\n    values: np.ndarray | ExtensionArray\r\n    ndim: int\r\n    refs: BlockValuesRefs\r\n    __init__: Callable\r\n\r\n    __slots__ = ()\r\n    is_numeric = False\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _validate_ndim(self) -> bool:\r\n        \"\"\"\r\n        We validate dimension for blocks that can hold 2D values, which for now\r\n        means numpy dtypes or DatetimeTZDtype.\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        return not isinstance(dtype, ExtensionDtype) or isinstance(\r\n            dtype, DatetimeTZDtype\r\n        )\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_object(self) -> bool:\r\n        return self.values.dtype == _dtype_obj\r\n\r\n    @final\r\n    @cache_readonly\r\n    def is_extension(self) -> bool:\r\n        return not lib.is_np_dtype(self.values.dtype)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_consolidate(self) -> bool:\r\n        # We _could_ consolidate for DatetimeTZDtype but don't for now.\r\n        return not self.is_extension\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _consolidate_key(self):\r\n        return self._can_consolidate, self.dtype.name\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _can_hold_na(self) -> bool:\r\n        \"\"\"\r\n        Can we store NA values in this Block?\r\n        \"\"\"\r\n        dtype = self.dtype\r\n        if isinstance(dtype, np.dtype):\r\n            return dtype.kind not in \"iub\"\r\n        return dtype._can_hold_na\r\n\r\n    @final\r\n    @property\r\n    def is_bool(self) -> bool:\r\n        \"\"\"\r\n        We can be bool if a) we are bool dtype or b) object dtype with bool objects.\r\n        \"\"\"\r\n        return self.values.dtype == np.dtype(bool)\r\n\r\n    @final\r\n    def external_values(self):\r\n        return external_values(self.values)\r\n\r\n    @final\r\n    @cache_readonly\r\n    def fill_value(self):\r\n        # Used in reindex_indexer\r\n        return na_value_for_dtype(self.dtype, compat=False)\r\n\r\n    @final\r\n    def _standardize_fill_value(self, value):\r\n        # if we are passed a scalar None, convert it here\r\n        if self.dtype != _dtype_obj and is_valid_na_for_dtype(value, self.dtype):\r\n            value = self.fill_value\r\n        return value\r\n\r\n    @property\r\n    def mgr_locs(self) -> BlockPlacement:\r\n        return self._mgr_locs\r\n\r\n    @mgr_locs.setter\r\n    def mgr_locs(self, new_mgr_locs: BlockPlacement) -> None:\r\n        self._mgr_locs = new_mgr_locs\r\n\r\n    @final\r\n    def make_block(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Create a new block, with type inference propagate any values that are\r\n        not specified\r\n        \"\"\"\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n        if self.is_extension:\r\n            values = ensure_block_shape(values, ndim=self.ndim)\r\n\r\n        return new_block(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def make_block_same_class(\r\n        self,\r\n        values,\r\n        placement: BlockPlacement | None = None,\r\n        refs: BlockValuesRefs | None = None,\r\n    ) -> Self:\r\n        \"\"\"Wrap given values in a block of same type as self.\"\"\"\r\n        # Pre-2.0 we called ensure_wrapped_if_datetimelike because fastparquet\r\n        #  relied on it, as of 2.0 the caller is responsible for this.\r\n        if placement is None:\r\n            placement = self._mgr_locs\r\n\r\n        # We assume maybe_coerce_values has already been called\r\n        return type(self)(values, placement=placement, ndim=self.ndim, refs=refs)\r\n\r\n    @final\r\n    def __repr__(self) -> str:\r\n        # don't want to print out all of the items here\r\n        name = type(self).__name__\r\n        if self.ndim == 1:\r\n            result = f\"{name}: {len(self)} dtype: {self.dtype}\"\r\n        else:\r\n            shape = \" x \".join([str(s) for s in self.shape])\r\n            result = f\"{name}: {self.mgr_locs.indexer}, {shape}, dtype: {self.dtype}\"\r\n\r\n        return result\r\n\r\n    @final\r\n    def __len__(self) -> int:\r\n        return len(self.values)\r\n\r\n    @final\r\n    def slice_block_columns(self, slc: slice) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n        \"\"\"\r\n        new_mgr_locs = self._mgr_locs[slc]\r\n\r\n        new_values = self._slice(slc)\r\n        refs = self.refs\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def take_block_columns(self, indices: npt.NDArray[np.intp]) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        # Note: only called from is from internals.concat, and we can verify\r\n        #  that never happens with 1-column blocks, i.e. never for ExtensionBlock.\r\n\r\n        new_mgr_locs = self._mgr_locs[indices]\r\n\r\n        new_values = self._slice(indices)\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=None)\r\n\r\n    @final\r\n    def getitem_block_columns(\r\n        self, slicer: slice, new_mgr_locs: BlockPlacement, ref_inplace_op: bool = False\r\n    ) -> Self:\r\n        \"\"\"\r\n        Perform __getitem__-like, return result as block.\r\n\r\n        Only supports slices that preserve dimensionality.\r\n        \"\"\"\r\n        new_values = self._slice(slicer)\r\n        refs = self.refs if not ref_inplace_op or self.refs.has_reference() else None\r\n        return type(self)(new_values, new_mgr_locs, self.ndim, refs=refs)\r\n\r\n    @final\r\n    def _can_hold_element(self, element: Any) -> bool:\r\n        \"\"\"require the same dtype as ourselves\"\"\"\r\n        element = extract_array(element, extract_numpy=True)\r\n        return can_hold_element(self.values, element)\r\n\r\n    @final\r\n    def should_store(self, value: ArrayLike) -> bool:\r\n        \"\"\"\r\n        Should we set self.values[indexer] = value inplace or do we need to cast?\r\n\r\n        Parameters\r\n        ----------\r\n        value : np.ndarray or ExtensionArray\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n        \"\"\"\r\n        return value.dtype == self.dtype\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Apply/Reduce and Helpers\r\n\r\n    @final\r\n    def apply(self, func, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        apply the function to my values; return a block if we are not\r\n        one\r\n        \"\"\"\r\n        result = func(self.values, **kwargs)\r\n\r\n        result = maybe_coerce_values(result)\r\n        return self._split_op_result(result)\r\n\r\n    @final\r\n    def reduce(self, func) -> list[Block]:\r\n        # We will apply the function and reshape the result into a single-row\r\n        #  Block with the same mgr_locs; squeezing will be done at a higher level\r\n        assert self.ndim == 2\r\n\r\n        result = func(self.values)\r\n\r\n        if self.values.ndim == 1:\r\n            res_values = result\r\n        else:\r\n            res_values = result.reshape(-1, 1)\r\n\r\n        nb = self.make_block(res_values)\r\n        return [nb]\r\n\r\n    @final\r\n    def _split_op_result(self, result: ArrayLike) -> list[Block]:\r\n        # See also: split_and_operate\r\n        if result.ndim > 1 and isinstance(result.dtype, ExtensionDtype):\r\n            # TODO(EA2D): unnecessary with 2D EAs\r\n            # if we get a 2D ExtensionArray, we need to split it into 1D pieces\r\n            nbs = []\r\n            for i, loc in enumerate(self._mgr_locs):\r\n                if not is_1d_only_ea_dtype(result.dtype):\r\n                    vals = result[i : i + 1]\r\n                else:\r\n                    vals = result[i]\r\n\r\n                bp = BlockPlacement(loc)\r\n                block = self.make_block(values=vals, placement=bp)\r\n                nbs.append(block)\r\n            return nbs\r\n\r\n        nb = self.make_block(result)\r\n\r\n        return [nb]\r\n\r\n    @final\r\n    def _split(self) -> Generator[Block]:\r\n        \"\"\"\r\n        Split a block into a list of single-column blocks.\r\n        \"\"\"\r\n        assert self.ndim == 2\r\n\r\n        for i, ref_loc in enumerate(self._mgr_locs):\r\n            vals = self.values[slice(i, i + 1)]\r\n\r\n            bp = BlockPlacement(ref_loc)\r\n            nb = type(self)(vals, placement=bp, ndim=2, refs=self.refs)\r\n            yield nb\r\n\r\n    @final\r\n    def split_and_operate(self, func, *args, **kwargs) -> list[Block]:\r\n        \"\"\"\r\n        Split the block and apply func column-by-column.\r\n\r\n        Parameters\r\n        ----------\r\n        func : Block method\r\n        *args\r\n        **kwargs\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        assert self.ndim == 2 and self.shape[0] != 1\r\n\r\n        res_blocks = []\r\n        for nb in self._split():\r\n            rbs = func(nb, *args, **kwargs)\r\n            res_blocks.extend(rbs)\r\n        return res_blocks\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Up/Down-casting\r\n\r\n    @final\r\n    def coerce_to_target_dtype(self, other, raise_on_upcast: bool) -> Block:\r\n        \"\"\"\r\n        coerce the current block to a dtype compat for other\r\n        we will return a block, possibly object, and not raise\r\n\r\n        we can also safely try to coerce to the same dtype\r\n        and will receive the same block\r\n        \"\"\"\r\n        new_dtype = find_result_type(self.values.dtype, other)\r\n        if new_dtype == self.dtype:\r\n            # GH#52927 avoid RecursionError\r\n            raise AssertionError(\r\n                \"Something has gone wrong, please report a bug at \"\r\n                \"https://github.com/pandas-dev/pandas/issues\"\r\n            )\r\n\r\n        # In a future version of pandas, the default will be that\r\n        # setting `nan` into an integer series won't raise.\r\n        if (\r\n            is_scalar(other)\r\n            and is_integer_dtype(self.values.dtype)\r\n            and isna(other)\r\n            and other is not NaT\r\n            and not (\r\n                isinstance(other, (np.datetime64, np.timedelta64)) and np.isnat(other)\r\n            )\r\n        ):\r\n            raise_on_upcast = False\r\n        elif (\r\n            isinstance(other, np.ndarray)\r\n            and other.ndim == 1\r\n            and is_integer_dtype(self.values.dtype)\r\n            and is_float_dtype(other.dtype)\r\n            and lib.has_only_ints_or_nan(other)\r\n        ):\r\n            raise_on_upcast = False\r\n\r\n        if raise_on_upcast:\r\n            raise TypeError(f\"Invalid value '{other}' for dtype '{self.values.dtype}'\")\r\n        if self.values.dtype == new_dtype:\r\n            raise AssertionError(\r\n                f\"Did not expect new dtype {new_dtype} to equal self.dtype \"\r\n                f\"{self.values.dtype}. Please report a bug at \"\r\n                \"https://github.com/pandas-dev/pandas/issues.\"\r\n            )\r\n        try:\r\n            return self.astype(new_dtype)\r\n        except OutOfBoundsDatetime as err:\r\n            # e.g. GH#56419 if self.dtype is a low-resolution dt64 and we try to\r\n            #  upcast to a higher-resolution dt64, we may have entries that are\r\n            #  out of bounds for the higher resolution.\r\n            #  Re-raise with a more informative message.\r\n            raise OutOfBoundsDatetime(\r\n                f\"Incompatible (high-resolution) value for dtype='{self.dtype}'. \"\r\n                \"Explicitly cast before operating.\"\r\n            ) from err\r\n\r\n    @final\r\n    def convert(self) -> list[Block]:\r\n        \"\"\"\r\n        Attempt to coerce any object types to better types. Return a copy\r\n        of the block (if copy = True).\r\n        \"\"\"\r\n        if not self.is_object:\r\n            return [self.copy(deep=False)]\r\n\r\n        if self.ndim != 1 and self.shape[0] != 1:\r\n            blocks = self.split_and_operate(Block.convert)\r\n            if all(blk.dtype.kind == \"O\" for blk in blocks):\r\n                # Avoid fragmenting the block if convert is a no-op\r\n                return [self.copy(deep=False)]\r\n            return blocks\r\n\r\n        values = self.values\r\n        if values.ndim == 2:\r\n            # the check above ensures we only get here with values.shape[0] == 1,\r\n            # avoid doing .ravel as that might make a copy\r\n            values = values[0]\r\n\r\n        res_values = lib.maybe_convert_objects(\r\n            values,  # type: ignore[arg-type]\r\n            convert_non_numeric=True,\r\n        )\r\n        refs = None\r\n        if res_values is values or (\r\n            isinstance(res_values, NumpyExtensionArray)\r\n            and res_values._ndarray is values\r\n        ):\r\n            refs = self.refs\r\n\r\n        res_values = ensure_block_shape(res_values, self.ndim)\r\n        res_values = maybe_coerce_values(res_values)\r\n        return [self.make_block(res_values, refs=refs)]\r\n\r\n    def convert_dtypes(\r\n        self,\r\n        infer_objects: bool = True,\r\n        convert_string: bool = True,\r\n        convert_integer: bool = True,\r\n        convert_boolean: bool = True,\r\n        convert_floating: bool = True,\r\n        dtype_backend: DtypeBackend = \"numpy_nullable\",\r\n    ) -> list[Block]:\r\n        if infer_objects and self.is_object:\r\n            blks = self.convert()\r\n        else:\r\n            blks = [self]\r\n\r\n        if not any(\r\n            [convert_floating, convert_integer, convert_boolean, convert_string]\r\n        ):\r\n            return [b.copy(deep=False) for b in blks]\r\n\r\n        rbs = []\r\n        for blk in blks:\r\n            # Determine dtype column by column\r\n            sub_blks = (\r\n                [blk] if blk.ndim == 1 or self.shape[0] == 1 else list(blk._split())\r\n            )\r\n            dtypes = [\r\n                convert_dtypes(\r\n                    b.values,\r\n                    convert_string,\r\n                    convert_integer,\r\n                    convert_boolean,\r\n                    convert_floating,\r\n                    infer_objects,\r\n                    dtype_backend,\r\n                )\r\n                for b in sub_blks\r\n            ]\r\n            if all(dtype == self.dtype for dtype in dtypes):\r\n                # Avoid block splitting if no dtype changes\r\n                rbs.append(blk.copy(deep=False))\r\n                continue\r\n\r\n            for dtype, b in zip(dtypes, sub_blks):\r\n                rbs.append(b.astype(dtype=dtype, squeeze=b.ndim != 1))\r\n        return rbs\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Array-Like Methods\r\n\r\n    @final\r\n    @cache_readonly\r\n    def dtype(self) -> DtypeObj:\r\n        return self.values.dtype\r\n\r\n    @final\r\n    def astype(\r\n        self,\r\n        dtype: DtypeObj,\r\n        errors: IgnoreRaise = \"raise\",\r\n        squeeze: bool = False,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Coerce to the new dtype.\r\n\r\n        Parameters\r\n        ----------\r\n        dtype : np.dtype or ExtensionDtype\r\n        errors : str, {'raise', 'ignore'}, default 'raise'\r\n            - ``raise`` : allow exceptions to be raised\r\n            - ``ignore`` : suppress exceptions. On error return original object\r\n        squeeze : bool, default False\r\n            squeeze values to ndim=1 if only one column is given\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n        \"\"\"\r\n        values = self.values\r\n        if squeeze and values.ndim == 2 and is_1d_only_ea_dtype(dtype):\r\n            if values.shape[0] != 1:\r\n                raise ValueError(\"Can not squeeze with more than one column.\")\r\n            values = values[0, :]  # type: ignore[call-overload]\r\n\r\n        new_values = astype_array_safe(values, dtype, errors=errors)\r\n\r\n        new_values = maybe_coerce_values(new_values)\r\n\r\n        refs = None\r\n        if astype_is_view(values.dtype, new_values.dtype):\r\n            refs = self.refs\r\n\r\n        newb = self.make_block(new_values, refs=refs)\r\n        if newb.shape != self.shape:\r\n            raise TypeError(\r\n                f\"cannot set astype for dtype \"\r\n                f\"({self.dtype.name} [{self.shape}]) to different shape \"\r\n                f\"({newb.dtype.name} [{newb.shape}])\"\r\n            )\r\n        return newb\r\n\r\n    @final\r\n    def get_values_for_csv(\r\n        self, *, float_format, date_format, decimal, na_rep: str = \"nan\", quoting=None\r\n    ) -> Block:\r\n        \"\"\"convert to our native types format\"\"\"\r\n        result = get_values_for_csv(\r\n            self.values,\r\n            na_rep=na_rep,\r\n            quoting=quoting,\r\n            float_format=float_format,\r\n            date_format=date_format,\r\n            decimal=decimal,\r\n        )\r\n        return self.make_block(result)\r\n\r\n    @final\r\n    def copy(self, deep: bool = True) -> Self:\r\n        \"\"\"copy constructor\"\"\"\r\n        values = self.values\r\n        refs: BlockValuesRefs | None\r\n        if deep:\r\n            values = values.copy()\r\n            refs = None\r\n        else:\r\n            refs = self.refs\r\n        return type(self)(values, placement=self._mgr_locs, ndim=self.ndim, refs=refs)\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Copy-on-Write Helpers\r\n\r\n    def _maybe_copy(self, inplace: bool) -> Self:\r\n        if inplace:\r\n            deep = self.refs.has_reference()\r\n            return self.copy(deep=deep)\r\n        return self.copy()\r\n\r\n    @final\r\n    def _get_refs_and_copy(self, inplace: bool):\r\n        refs = None\r\n        copy = not inplace\r\n        if inplace:\r\n            if self.refs.has_reference():\r\n                copy = True\r\n            else:\r\n                refs = self.refs\r\n        return copy, refs\r\n\r\n    # ---------------------------------------------------------------------\r\n    # Replace\r\n\r\n    @final\r\n    def replace(\r\n        self,\r\n        to_replace,\r\n        value,\r\n        inplace: bool = False,\r\n        # mask may be pre-computed if we're called from replace_list\r\n        mask: npt.NDArray[np.bool_] | None = None,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n        replace the to_replace value with value, possible to create new\r\n        blocks here this is just a call to putmask.\r\n        \"\"\"\r\n\r\n        # Note: the checks we do in NDFrame.replace ensure we never get\r\n        #  here with listlike to_replace or value, as those cases\r\n        #  go through replace_list\r\n        values = self.values\r\n\r\n        if not self._can_hold_element(to_replace):\r\n            # We cannot hold `to_replace`, so we know immediately that\r\n            #  replacing it is a no-op.\r\n            # Note: If to_replace were a list, NDFrame.replace would call\r\n            #  replace_list instead of replace.\r\n            return [self.copy(deep=False)]\r\n\r\n        if mask is None:\r\n            mask = missing.mask_missing(values, to_replace)\r\n        if not mask.any():\r\n            # Note: we get here with test_replace_extension_other incorrectly\r\n            #  bc _can_hold_element is incorrect.\r\n            return [self.copy(deep=False)]\r\n\r\n        elif self._can_hold_element(value) or (self.dtype == \"string\" and is_re(value)):\r\n            # TODO(CoW): Maybe split here as well into columns where mask has True\r\n            # and rest?\r\n            blk = self._maybe_copy(inplace)\r\n            putmask_inplace(blk.values, mask, value)\r\n            return [blk]\r\n\r\n        elif self.ndim == 1 or self.shape[0] == 1:\r\n            if value is None or value is NA:\r\n                blk = self.astype(np.dtype(object))\r\n            else:\r\n                blk = self.coerce_to_target_dtype(value, raise_on_upcast=False)\r\n            return blk.replace(\r\n                to_replace=to_replace,\r\n                value=value,\r\n                inplace=True,\r\n                mask=mask,\r\n            )\r\n\r\n        else:\r\n            # split so that we only upcast where necessary\r\n            blocks = []\r\n            for i, nb in enumerate(self._split()):\r\n                blocks.extend(\r\n                    type(self).replace(\r\n                        nb,\r\n                        to_replace=to_replace,\r\n                        value=value,\r\n                        inplace=True,\r\n                        mask=mask[i : i + 1],\r\n                    )\r\n                )\r\n            return blocks\r\n\r\n    @final\r\n    def _replace_regex(\r\n        self,\r\n        to_replace,\r\n        value,\r\n        inplace: bool = False,\r\n        mask=None,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n        Replace elements by the given value.\r\n\r\n        Parameters\r\n        ----------\r\n        to_replace : object or pattern\r\n            Scalar to replace or regular expression to match.\r\n        value : object\r\n            Replacement object.\r\n        inplace : bool, default False\r\n            Perform inplace modification.\r\n        mask : array-like of bool, optional\r\n            True indicate corresponding element is ignored.\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        if not is_re(to_replace) and not self._can_hold_element(to_replace):\r\n            # i.e. only if self.is_object is True, but could in principle include a\r\n            #  String ExtensionBlock\r\n            return [self.copy(deep=False)]\r\n\r\n        if is_re(to_replace) and self.dtype not in [object, \"string\"]:\r\n            # only object or string dtype can hold strings, and a regex object\r\n            # will only match strings\r\n            return [self.copy(deep=False)]\r\n\r\n        if not (\r\n            self._can_hold_element(value) or (self.dtype == \"string\" and is_re(value))\r\n        ):\r\n            block = self.astype(np.dtype(object))\r\n        else:\r\n            block = self._maybe_copy(inplace)\r\n\r\n        rx = re.compile(to_replace)\r\n\r\n        replace_regex(block.values, rx, value, mask)\r\n        return [block]\r\n\r\n    @final\r\n    def replace_list(\r\n        self,\r\n        src_list: Iterable[Any],\r\n        dest_list: Sequence[Any],\r\n        inplace: bool = False,\r\n        regex: bool = False,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n        See BlockManager.replace_list docstring.\r\n        \"\"\"\r\n        values = self.values\r\n\r\n        # Exclude anything that we know we won't contain\r\n        pairs = [\r\n            (x, y)\r\n            for x, y in zip(src_list, dest_list)\r\n            if (self._can_hold_element(x) or (self.dtype == \"string\" and is_re(x)))\r\n        ]\r\n        if not len(pairs):\r\n            return [self.copy(deep=False)]\r\n\r\n        src_len = len(pairs) - 1\r\n\r\n        if is_string_dtype(values.dtype):\r\n            # Calculate the mask once, prior to the call of comp\r\n            # in order to avoid repeating the same computations\r\n            na_mask = ~isna(values)\r\n            masks: Iterable[npt.NDArray[np.bool_]] = (\r\n                extract_bool_array(\r\n                    cast(\r\n                        ArrayLike,\r\n                        compare_or_regex_search(\r\n                            values, s[0], regex=regex, mask=na_mask\r\n                        ),\r\n                    )\r\n                )\r\n                for s in pairs\r\n            )\r\n        else:\r\n            # GH#38086 faster if we know we dont need to check for regex\r\n            masks = (missing.mask_missing(values, s[0]) for s in pairs)\r\n        # Materialize if inplace = True, since the masks can change\r\n        # as we replace\r\n        if inplace:\r\n            masks = list(masks)\r\n\r\n        # Don't set up refs here, otherwise we will think that we have\r\n        # references when we check again later\r\n        rb = [self]\r\n\r\n        for i, ((src, dest), mask) in enumerate(zip(pairs, masks)):\r\n            new_rb: list[Block] = []\r\n\r\n            # GH-39338: _replace_coerce can split a block into\r\n            # single-column blocks, so track the index so we know\r\n            # where to index into the mask\r\n            for blk_num, blk in enumerate(rb):\r\n                if len(rb) == 1:\r\n                    m = mask\r\n                else:\r\n                    mib = mask\r\n                    assert not isinstance(mib, bool)\r\n                    m = mib[blk_num : blk_num + 1]\r\n\r\n                # error: Argument \"mask\" to \"_replace_coerce\" of \"Block\" has\r\n                # incompatible type \"Union[ExtensionArray, ndarray[Any, Any], bool]\";\r\n                # expected \"ndarray[Any, dtype[bool_]]\"\r\n                result = blk._replace_coerce(\r\n                    to_replace=src,\r\n                    value=dest,\r\n                    mask=m,\r\n                    inplace=inplace,\r\n                    regex=regex,\r\n                )\r\n\r\n                if i != src_len:\r\n                    # This is ugly, but we have to get rid of intermediate refs\r\n                    # that did not go out of scope yet, otherwise we will trigger\r\n                    # many unnecessary copies\r\n                    for b in result:\r\n                        ref = weakref.ref(b)\r\n                        b.refs.referenced_blocks.pop(\r\n                            b.refs.referenced_blocks.index(ref)\r\n                        )\r\n                new_rb.extend(result)\r\n            rb = new_rb\r\n        return rb\r\n\r\n    @final\r\n    def _replace_coerce(\r\n        self,\r\n        to_replace,\r\n        value,\r\n        mask: npt.NDArray[np.bool_],\r\n        inplace: bool = True,\r\n        regex: bool = False,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n        Replace value corresponding to the given boolean array with another\r\n        value.\r\n\r\n        Parameters\r\n        ----------\r\n        to_replace : object or pattern\r\n            Scalar to replace or regular expression to match.\r\n        value : object\r\n            Replacement object.\r\n        mask : np.ndarray[bool]\r\n            True indicate corresponding element is ignored.\r\n        inplace : bool, default True\r\n            Perform inplace modification.\r\n        regex : bool, default False\r\n            If true, perform regular expression substitution.\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        if should_use_regex(regex, to_replace):\r\n            return self._replace_regex(\r\n                to_replace,\r\n                value,\r\n                inplace=inplace,\r\n                mask=mask,\r\n            )\r\n        else:\r\n            if value is None:\r\n                # gh-45601, gh-45836, gh-46634\r\n                if mask.any():\r\n                    has_ref = self.refs.has_reference()\r\n                    nb = self.astype(np.dtype(object))\r\n                    if not inplace:\r\n                        nb = nb.copy()\r\n                    elif inplace and has_ref and nb.refs.has_reference():\r\n                        # no copy in astype and we had refs before\r\n                        nb = nb.copy()\r\n                    putmask_inplace(nb.values, mask, value)\r\n                    return [nb]\r\n                return [self.copy(deep=False)]\r\n            return self.replace(\r\n                to_replace=to_replace,\r\n                value=value,\r\n                inplace=inplace,\r\n                mask=mask,\r\n            )\r\n\r\n    # ---------------------------------------------------------------------\r\n    # 2D Methods - Shared by NumpyBlock and NDArrayBackedExtensionBlock\r\n    #  but not ExtensionBlock\r\n\r\n    def _maybe_squeeze_arg(self, arg: np.ndarray) -> np.ndarray:\r\n        \"\"\"\r\n        For compatibility with 1D-only ExtensionArrays.\r\n        \"\"\"\r\n        return arg\r\n\r\n    def _unwrap_setitem_indexer(self, indexer):\r\n        \"\"\"\r\n        For compatibility with 1D-only ExtensionArrays.\r\n        \"\"\"\r\n        return indexer\r\n\r\n    # NB: this cannot be made cache_readonly because in mgr.set_values we pin\r\n    #  new .values that can have different shape GH#42631\r\n    @property\r\n    def shape(self) -> Shape:\r\n        return self.values.shape\r\n\r\n    def iget(self, i: int | tuple[int, int] | tuple[slice, int]) -> np.ndarray:\r\n        # In the case where we have a tuple[slice, int], the slice will always\r\n        #  be slice(None)\r\n        # Note: only reached with self.ndim == 2\r\n        # Invalid index type \"Union[int, Tuple[int, int], Tuple[slice, int]]\"\r\n        # for \"Union[ndarray[Any, Any], ExtensionArray]\"; expected type\r\n        # \"Union[int, integer[Any]]\"\r\n        return self.values[i]  # type: ignore[index]\r\n\r\n    def _slice(\r\n        self, slicer: slice | npt.NDArray[np.bool_] | npt.NDArray[np.intp]\r\n    ) -> ArrayLike:\r\n        \"\"\"return a slice of my values\"\"\"\r\n\r\n        return self.values[slicer]\r\n\r\n    def set_inplace(self, locs, values: ArrayLike, copy: bool = False) -> None:\r\n        \"\"\"\r\n        Modify block values in-place with new item value.\r\n\r\n        If copy=True, first copy the underlying values in place before modifying\r\n        (for Copy-on-Write).\r\n\r\n        Notes\r\n        -----\r\n        `set_inplace` never creates a new array or new Block, whereas `setitem`\r\n        _may_ create a new array and always creates a new Block.\r\n\r\n        Caller is responsible for checking values.dtype == self.dtype.\r\n        \"\"\"\r\n        if copy:\r\n            self.values = self.values.copy()\r\n        self.values[locs] = values\r\n\r\n    @final\r\n    def take_nd(\r\n        self,\r\n        indexer: npt.NDArray[np.intp],\r\n        axis: AxisInt,\r\n        new_mgr_locs: BlockPlacement | None = None,\r\n        fill_value=lib.no_default,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Take values according to indexer and return them as a block.\r\n        \"\"\"\r\n        values = self.values\r\n\r\n        if fill_value is lib.no_default:\r\n            fill_value = self.fill_value\r\n            allow_fill = False\r\n        else:\r\n            allow_fill = True\r\n\r\n        # Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\r\n        new_values = algos.take_nd(\r\n            values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\r\n        )\r\n\r\n        # Called from three places in managers, all of which satisfy\r\n        #  these assertions\r\n        if isinstance(self, ExtensionBlock):\r\n            # NB: in this case, the 'axis' kwarg will be ignored in the\r\n            #  algos.take_nd call above.\r\n            assert not (self.ndim == 1 and new_mgr_locs is None)\r\n        assert not (axis == 0 and new_mgr_locs is None)\r\n\r\n        if new_mgr_locs is None:\r\n            new_mgr_locs = self._mgr_locs\r\n\r\n        if new_values.dtype != self.dtype:\r\n            return self.make_block(new_values, new_mgr_locs)\r\n        else:\r\n            return self.make_block_same_class(new_values, new_mgr_locs)\r\n\r\n    def _unstack(\r\n        self,\r\n        unstacker,\r\n        fill_value,\r\n        new_placement: npt.NDArray[np.intp],\r\n        needs_masking: npt.NDArray[np.bool_],\r\n    ):\r\n        \"\"\"\r\n        Return a list of unstacked blocks of self\r\n\r\n        Parameters\r\n        ----------\r\n        unstacker : reshape._Unstacker\r\n        fill_value : int\r\n            Only used in ExtensionBlock._unstack\r\n        new_placement : np.ndarray[np.intp]\r\n        allow_fill : bool\r\n        needs_masking : np.ndarray[bool]\r\n\r\n        Returns\r\n        -------\r\n        blocks : list of Block\r\n            New blocks of unstacked values.\r\n        mask : array-like of bool\r\n            The mask of columns of `blocks` we should keep.\r\n        \"\"\"\r\n        new_values, mask = unstacker.get_new_values(\r\n            self.values.T, fill_value=fill_value\r\n        )\r\n\r\n        mask = mask.any(0)\r\n        # TODO: in all tests we have mask.all(); can we rely on that?\r\n\r\n        # Note: these next two lines ensure that\r\n        #  mask.sum() == sum(len(nb.mgr_locs) for nb in blocks)\r\n        #  which the calling function needs in order to pass verify_integrity=False\r\n        #  to the BlockManager constructor\r\n        new_values = new_values.T[mask]\r\n        new_placement = new_placement[mask]\r\n\r\n        bp = BlockPlacement(new_placement)\r\n        blocks = [new_block_2d(new_values, placement=bp)]\r\n        return blocks, mask\r\n\r\n    # ---------------------------------------------------------------------\r\n\r\n    def setitem(self, indexer, value) -> Block:\r\n        \"\"\"\r\n        Attempt self.values[indexer] = value, possibly creating a new array.\r\n\r\n        Parameters\r\n        ----------\r\n        indexer : tuple, list-like, array-like, slice, int\r\n            The subset of self.values to set\r\n        value : object\r\n            The value being set\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n\r\n        Notes\r\n        -----\r\n        `indexer` is a direct slice/positional indexer. `value` must\r\n        be a compatible shape.\r\n        \"\"\"\r\n\r\n        value = self._standardize_fill_value(value)\r\n\r\n        values = cast(np.ndarray, self.values)\r\n        if self.ndim == 2:\r\n            values = values.T\r\n\r\n        # length checking\r\n        check_setitem_lengths(indexer, value, values)\r\n\r\n        if self.dtype != _dtype_obj:\r\n            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n            value = extract_array(value, extract_numpy=True)\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, value)\r\n        except LossySetitemError:\r\n            # current dtype cannot store value, coerce to common dtype\r\n            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n            return nb.setitem(indexer, value)\r\n        else:\r\n            if self.dtype == _dtype_obj:\r\n                # TODO: avoid having to construct values[indexer]\r\n                vi = values[indexer]\r\n                if lib.is_list_like(vi):\r\n                    # checking lib.is_scalar here fails on\r\n                    #  test_iloc_setitem_custom_object\r\n                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values.T)\r\n            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n                casted = casted[0, ...]\r\n            try:\r\n                values[indexer] = casted\r\n            except (TypeError, ValueError) as err:\r\n                if is_list_like(casted):\r\n                    raise ValueError(\r\n                        \"setting an array element with a sequence.\"\r\n                    ) from err\r\n                raise\r\n        return self\r\n\r\n    def putmask(self, mask, new) -> list[Block]:\r\n        \"\"\"\r\n        putmask the data to the block; it is possible that we may create a\r\n        new dtype of block\r\n\r\n        Return the resulting block(s).\r\n\r\n        Parameters\r\n        ----------\r\n        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n        new : a ndarray/object\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        orig_mask = mask\r\n        values = cast(np.ndarray, self.values)\r\n        mask, noop = validate_putmask(values.T, mask)\r\n        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        if new is lib.no_default:\r\n            new = self.fill_value\r\n\r\n        new = self._standardize_fill_value(new)\r\n        new = extract_array(new, extract_numpy=True)\r\n\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, new)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values)\r\n\r\n            putmask_without_repeat(values.T, mask, casted)\r\n            return [self]\r\n        except LossySetitemError:\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                if not is_list_like(new):\r\n                    # using just new[indexer] can't save us the need to cast\r\n                    return self.coerce_to_target_dtype(\r\n                        new, raise_on_upcast=True\r\n                    ).putmask(mask, new)\r\n                else:\r\n                    indexer = mask.nonzero()[0]\r\n                    nb = self.setitem(indexer, new[indexer])\r\n                    return [nb]\r\n\r\n            else:\r\n                is_array = isinstance(new, np.ndarray)\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n"]
[650.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[650.002, "i", "applypatch << 'PATCH'\r"]
[650.004, "o", "applypatch << 'PATCH'\r\n"]
[650.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> *** Begin Patch\r\n\u001b[?2004l\r\n\u001b[?2004h> *** Update File: pandas/core/internals/blocks.py\r\n\u001b[?2004l\r\n\u001b[?2004h> @@\r\n\u001b[?2004l\r\n\u001b[?2004h> -            else:\r\n\u001b[?2004l\r\n\u001b[?2004h> -                is_array = isinstance(new, np.ndarray)\r\n\u001b[?2004l\r\n\u001b[?2004h> -\r\n\u001b[?2004l\r\n\u001b[?2004h> -                res_blocks = []\r\n\u001b[?2004l\r\n\u001b[?2004h> -                for i, nb in enumerate(self._split()):\r\n\u001b[?2004l\r\n\u001b[?2004h> +            else:\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # Fastpath: if we cannot hold the new value in the current dtype\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # (e.g., boolean block with a NA/NaN replacement) and we have a\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # 2D block, avoid the expensive column-by-column split/setitem.\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # Instead, upcast the entire block once and apply the mask in a\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # single vectorized operation. This preserves correctness while\r\n\u001b[?2004l\r\n\u001b[?2004h> +                # significantly reducing Python-level overhead.\r\n\u001b[?2004l\r\n\u001b[?2004h> +                if not is_list_like(new) or (\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    isinstance(new, np.ndarray) and new.ndim == 0\r\n\u001b[?2004l\r\n\u001b[?2004h> +                ):\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    # Upcast to object and apply mask across the whole block\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    obj_block = self.astype(np.dtype(object))\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    obj_vals = cast(np.ndarray, obj_block.values)\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    # Apply putmask over transposed 2D for column-major placement\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    putmask_without_repeat(obj_vals.T, mask, new)\r\n\u001b[?2004l\r\n\u001b[?2004h> +                    return [obj_block]\r\n\u001b[?2004l\r\n\u001b[?2004h> +\r\n\u001b[?2004l\r\n\u001b[?2004h> +                is_array = isinstance(new, np.ndarray)\r\n\u001b[?2004l\r\n\u001b[?2004h> +\r\n\u001b[?2004l\r\n\u001b[?2004h> +                res_blocks = []\r\n\u001b[?2004l\r\n\u001b[?2004h> +                for i, nb in enumerate(self._split()):\r\n\u001b[?2004l\r\n\u001b[?2004h> *** End Patch\r\n\u001b[?2004l\r\n\u001b[?2004h> PATCH\r\n\u001b[?2004l\r\n-bash: applypatch: command not found\r\n"]
[655.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[655.002, "i", "cd asv_bench\r"]
[655.004, "o", "cd asv_bench\r\n"]
[655.006, "o", "\u001b[?2004l\r\n"]
[660.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[660.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[660.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[660.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              52.0\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             3.95\u00b10ms\r\n"]
[665.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[665.002, "i", "grep -n \"def putmask\" pandas/core/internals/blocks.py\r"]
[665.004, "o", "grep -n \"def putmask\" pandas/core/internals/blocks.py\r\n"]
[665.006, "o", "\u001b[?2004l\r\ngrep: pandas/core/internals/blocks.py: No such file or directory\r\n"]
[670.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[670.002, "i", "nl -ba pandas/core/internals/blocks.py | sed -n '1,1200p' | sed -n '$(grep -n \"def putmask\" -n pandas/cor\r"]
[670.004, "o", "nl -ba pandas/core/internals/blocks.py | sed -n '1,1200p' | sed -n '$(grep -n \"def putmask\" -n pandas/cor\r\n"]
[670.006, "o", "re/internals/blocks.py | cut -d: -f1),+200p'\r\n\u001b[?2004l\r\nsed: -e expression #1, char 2: unknown command: `('\r\nnl: pandas/core/internals/blocks.py: No such file or directory\r\n"]
[675.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[675.002, "i", "cp pandas/core/internals/blocks.py pandas/core/internals/blocks.py.bak\r"]
[675.004, "o", "cp pandas/core/internals/blocks.py pandas/core/internals/blocks.py.bak\r\n"]
[675.006, "o", "\u001b[?2004l\r\ncp: cannot stat 'pandas/core/internals/blocks.py': No such file or directory\r\n"]
[680.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[680.002, "i", "python - << 'PY'\r"]
[680.004, "o", "python - << 'PY'\r\n"]
[680.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import io,sys,re\r\n\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p=Path('pandas/core/internals/blocks.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s=p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find the LossySetitemError except branch and the ndim>1 else block\r\n\u001b[?2004l\r\n\u001b[?2004h> pat = re.compile(r\"except\\s+LossySetitemError:\\n(\\s*)if\\s+self\\.ndim\\s*==\\s*1\\s*or\\s*self\\.shape\\[0\\]\\s*==\\s*1:\\n(?P<block1>(?:\\1\\s+.*\\n)+?)\\s*else:\\n(?P<block\r\nk2>(?:\\1\\s+.*\\n)+?)\\s*\\n\", re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h> m = pat.search(s)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Pattern not found', file=sys.stderr); sys.exit(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> indent = m.group(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> block2 = m.group('block2')\r\n\u001b[?2004l\r\n\u001b[?2004h> # Insert fastpath at start of else-branch\r\n\u001b[?2004l\r\n\u001b[?2004h> fast = f\"{indent}else:\\n{indent}    # Fastpath: if we cannot hold the new value in the current dtype\\n{indent}    # (e.g., boolean block with a NA/NaN replacem\r\nment) and we have a\\n{indent}    # 2D block, avoid the expensive column-by-column split/setitem.\\n{indent}    # Instead, upcast the entire block once and apply t\r\nthe mask in a\\n{indent}    # single vectorized operation. This preserves correctness while\\n{indent}    # significantly reducing Python-level overhead.\\n{indent}\r\n}    if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\\n{indent}        obj_block = self.astype(np.dtype(object))\\n{indent}        obj\r\nj_vals = cast(np.ndarray, obj_block.values)\\n{indent}        putmask_without_repeat(obj_vals.T, mask, new)\\n{indent}        return [obj_block]\\n\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> # Reconstruct else-branch: our fastpath plus original remainder\r\n\u001b[?2004l\r\n\u001b[?2004h> new_block2 = fast + indent + block2\r\n\u001b[?2004l\r\n\u001b[?2004h> s2 = s[:m.start()] + f\"except LossySetitemError:\\n\" + s[m.start()+len(\"except LossySetitemError:\\n\"):m.start(2)] + new_block2 + s[m.end():]\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(s2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Patched successfully')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 4, in <module>\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/pathlib.py\", line 1134, in read_text\r\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/pathlib.py\", line 1119, in open\r\n    return self._accessor.open(self, mode, buffering, encoding, errors,\r\nFileNotFoundError: [Errno 2] No such file or directory: 'pandas/core/internals/blocks.py'\r\n"]
[685.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[685.002, "i", "git diff -- pandas/core/internals/blocks.py | sed -n '1,200p'\r"]
[685.004, "o", "git diff -- pandas/core/internals/blocks.py | sed -n '1,200p'\r\n"]
[685.006, "o", "\u001b[?2004l\r\n"]
[690.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[690.002, "i", "cd asv_bench\r"]
[690.004, "o", "cd asv_bench\r\n"]
[690.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[695.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[695.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[695.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[695.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              51.7\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             3.92\u00b10ms\r\n"]
[700.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[700.002, "i", "cd ..\r"]
[700.004, "o", "cd ..\r\n"]
[700.006, "o", "\u001b[?2004l\r\n"]
[705.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[705.002, "i", "grep -n \"LossySetitemError\" pandas/core/internals/blocks.py\r"]
[705.004, "o", "grep -n \"LossySetitemError\" pandas/core/internals/blocks.py\r\n"]
[705.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K53\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K,\r\n\u001b[32m\u001b[K1116\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n\u001b[32m\u001b[K1182\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n\u001b[32m\u001b[K1251\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except (ValueError, TypeError, \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K):\r\n\u001b[32m\u001b[K1450\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n"]
[710.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[710.002, "i", "sed -n '1,2000p' pandas/core/internals/blocks.py | sed -n '$(grep -n \"LossySetitemError\" pandas/core/internals/bloc\r"]
[710.004, "o", "sed -n '1,2000p' pandas/core/internals/blocks.py | sed -n '$(grep -n \"LossySetitemError\" pandas/core/internals/bloc\r\n"]
[710.006, "o", "cks.py | head -n1 | cut -d: -f1),+120p'\r\n\u001b[?2004l\r\nsed: -e expression #1, char 2: unknown command: `('\r\n"]
[715.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[715.002, "i", "python - << 'PY'\r"]
[715.004, "o", "python - << 'PY'\r\n"]
[715.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/internals/blocks.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Insert a fastpath in the ndim>1 branch after 'else:' in the LossySetitemError except block\r\n\u001b[?2004l\r\n\u001b[?2004h> pattern = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     r\"except\\s+LossySetitemError:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     r\"(\\s*)if\\s+self\\.ndim\\s*==\\s*1\\s*or\\s*self\\.shape\\[0\\]\\s*==\\s*1:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> m = re.search(pattern, s)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('Could not find LossySetitemError branch start')\r\n\u001b[?2004l\r\n\u001b[?2004h> indent = m.group(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find the corresponding else: following that if\r\n\u001b[?2004l\r\n\u001b[?2004h> start = m.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> # We look for the first line starting with same indent + 'else:' after the if-block\r\n\u001b[?2004l\r\n\u001b[?2004h> else_match = re.search(rf\"^{indent}else:\\n\", s[start:], flags=re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not else_match:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('Could not find else: branch for ndim>1')\r\n\u001b[?2004l\r\n\u001b[?2004h> else_pos = start + else_match.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> # After else:, insert our fastpath\r\n\u001b[?2004l\r\n\u001b[?2004h> fastpath = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        obj_block = self.astype(np.dtype(object))\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        obj_vals = cast(np.ndarray, obj_block.values)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        putmask_without_repeat(obj_vals.T, mask, new)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        return [obj_block]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> s2 = s[:else_pos] + fastpath + s[else_pos:]\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(s2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Patched blocks.py with boolean mask fastpath')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nPatched blocks.py with boolean mask fastpath\r\n"]
[720.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[720.002, "i", "git diff -- pandas/core/internals/blocks.py | sed -n '1,200p'\r"]
[720.004, "o", "git diff -- pandas/core/internals/blocks.py | sed -n '1,200p'\r\n"]
[720.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/internals/blocks.py b/pandas/core/internals/blocks.py\r\nindex d1a9081b23..806a9117c3 100644\r\n--- a/pandas/core/internals/blocks.py\r\n+++ b/pandas/core/internals/blocks.py\r\n@@ -1194,6 +1194,12 @@ class Block(PandasObject, libinternals.Block):\r\n                     return [nb]\r\n \r\n             else:\r\n+                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n+                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n+                    obj_block = self.astype(np.dtype(object))\r\n+                    obj_vals = cast(np.ndarray, obj_block.values)\r\n+                    putmask_without_repeat(obj_vals.T, mask, new)\r\n+                    return [obj_block]\r\n                 is_array = isinstance(new, np.ndarray)\r\n \r\n                 res_blocks = []\r\n"]
[725.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[725.002, "i", "cd asv_bench\r"]
[725.004, "o", "cd asv_bench\r\n"]
[725.006, "o", "\u001b[?2004l\r\n"]
[730.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[730.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[730.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[730.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              51.6\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             3.88\u00b10ms\r\n"]
[735.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[735.002, "i", "grep -n -F \"def where\" pandas/core/internals/blocks.py\r"]
[735.004, "o", "grep -n -F \"def where\" pandas/core/internals/blocks.py\r\n"]
[735.006, "o", "\u001b[?2004l\r\ngrep: pandas/core/internals/blocks.py: No such file or directory\r\n"]
[740.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[740.002, "i", "sed -n '1,2200p' pandas/core/internals/blocks.py | sed -n '1100,1500p'\r"]
[740.004, "o", "sed -n '1,2200p' pandas/core/internals/blocks.py | sed -n '1100,1500p'\r\n"]
[740.006, "o", "\u001b[?2004l\r\nsed: can't read pandas/core/internals/blocks.py: No such file or directory\r\n"]
[745.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[745.002, "i", "python - << 'PY'\r"]
[745.004, "o", "python - << 'PY'\r\n"]
[745.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/internals/blocks.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # We target the first Block.where LossySetitemError branch (around line ~1116 per grep)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Insert a fastpath in the ndim>1 else: branch similar to putmask fix\r\n\u001b[?2004l\r\n\u001b[?2004h> pattern = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     r\"def\\s+where\\(.*?\\):[\\s\\S]*?except\\s+LossySetitemError:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     r\"(\\s*)if\\s+self\\.ndim\\s*==\\s*1\\s*or\\s*self\\.shape\\[0\\]\\s*==\\s*1:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> m = re.search(pattern, s)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('Could not locate where() LossySetitemError branch')\r\n\u001b[?2004l\r\n\u001b[?2004h> indent = m.group(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> start = m.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> else_match = re.search(rf\"^{indent}else:\\n\", s[start:], flags=re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not else_match:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('Could not find else: branch in where()')\r\n\u001b[?2004l\r\n\u001b[?2004h> else_pos = start + else_match.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> fastpath = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    # Fastpath: for 2D blocks where we cannot hold 'other' (e.g. bool -> NaN),\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    # upcast once and apply mask vectorized instead of splitting columns.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    if not is_list_like(other) or (isinstance(other, np.ndarray) and other.ndim == 0):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        obj_block = self.astype(np.dtype(object))\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        vals = obj_block.values\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        # cond True -> keep original, False -> take 'other'\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        # Use transpose to align with column-wise memory layout in helpers\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        putmask_without_repeat(vals.T, ~cond, other)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        return [obj_block]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> s2 = s[:else_pos] + fastpath + s[else_pos:]\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(s2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Patched where() with 2D fastpath for scalar other')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 4, in <module>\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/pathlib.py\", line 1134, in read_text\r\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n  File \"/opt/conda/envs/asv_3.10/lib/python3.10/pathlib.py\", line 1119, in open\r\n    return self._accessor.open(self, mode, buffering, encoding, errors,\r\nFileNotFoundError: [Errno 2] No such file or directory: 'pandas/core/internals/blocks.py'\r\n"]
[750.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[750.002, "i", "git diff -- pandas/core/internals/blocks.py | sed -n '1,200p'\r"]
[750.004, "o", "git diff -- pandas/core/internals/blocks.py | sed -n '1,200p'\r\n"]
[750.006, "o", "\u001b[?2004l\r\n"]
[755.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[755.002, "i", "cd asv_bench\r"]
[755.004, "o", "cd asv_bench\r\n"]
[755.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[760.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[760.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[760.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[760.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              53.8\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             4.10\u00b10ms\r\n"]
[765.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[765.002, "i", "cd ..\r"]
[765.004, "o", "cd ..\r\n"]
[765.006, "o", "\u001b[?2004l\r\n"]
[770.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[770.002, "i", "grep -n -F \"def where\" pandas/core/internals/blocks.py\r"]
[770.004, "o", "grep -n -F \"def where\" pandas/core/internals/blocks.py\r\n"]
[770.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K1217\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(self, other, cond) -> list[Block]:\r\n\u001b[32m\u001b[K1670\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(self, other, cond) -> list[Block]:\r\n"]
[775.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[775.002, "i", "sed -n '1050,1220p' pandas/core/internals/blocks.py\r"]
[775.004, "o", "sed -n '1050,1220p' pandas/core/internals/blocks.py\r\n"]
[775.006, "o", "\u001b[?2004l\r\n        new_placement : np.ndarray[np.intp]\r\n        allow_fill : bool\r\n        needs_masking : np.ndarray[bool]\r\n\r\n        Returns\r\n        -------\r\n        blocks : list of Block\r\n            New blocks of unstacked values.\r\n        mask : array-like of bool\r\n            The mask of columns of `blocks` we should keep.\r\n        \"\"\"\r\n        new_values, mask = unstacker.get_new_values(\r\n            self.values.T, fill_value=fill_value\r\n        )\r\n\r\n        mask = mask.any(0)\r\n        # TODO: in all tests we have mask.all(); can we rely on that?\r\n\r\n        # Note: these next two lines ensure that\r\n        #  mask.sum() == sum(len(nb.mgr_locs) for nb in blocks)\r\n        #  which the calling function needs in order to pass verify_integrity=False\r\n        #  to the BlockManager constructor\r\n        new_values = new_values.T[mask]\r\n        new_placement = new_placement[mask]\r\n\r\n        bp = BlockPlacement(new_placement)\r\n        blocks = [new_block_2d(new_values, placement=bp)]\r\n        return blocks, mask\r\n\r\n    # ---------------------------------------------------------------------\r\n\r\n    def setitem(self, indexer, value) -> Block:\r\n        \"\"\"\r\n        Attempt self.values[indexer] = value, possibly creating a new array.\r\n\r\n        Parameters\r\n        ----------\r\n        indexer : tuple, list-like, array-like, slice, int\r\n            The subset of self.values to set\r\n        value : object\r\n            The value being set\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n\r\n        Notes\r\n        -----\r\n        `indexer` is a direct slice/positional indexer. `value` must\r\n        be a compatible shape.\r\n        \"\"\"\r\n\r\n        value = self._standardize_fill_value(value)\r\n\r\n        values = cast(np.ndarray, self.values)\r\n        if self.ndim == 2:\r\n            values = values.T\r\n\r\n        # length checking\r\n        check_setitem_lengths(indexer, value, values)\r\n\r\n        if self.dtype != _dtype_obj:\r\n            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n            value = extract_array(value, extract_numpy=True)\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, value)\r\n        except LossySetitemError:\r\n            # current dtype cannot store value, coerce to common dtype\r\n            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n            return nb.setitem(indexer, value)\r\n        else:\r\n            if self.dtype == _dtype_obj:\r\n                # TODO: avoid having to construct values[indexer]\r\n                vi = values[indexer]\r\n                if lib.is_list_like(vi):\r\n                    # checking lib.is_scalar here fails on\r\n                    #  test_iloc_setitem_custom_object\r\n                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values.T)\r\n            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n                casted = casted[0, ...]\r\n            try:\r\n                values[indexer] = casted\r\n            except (TypeError, ValueError) as err:\r\n                if is_list_like(casted):\r\n                    raise ValueError(\r\n                        \"setting an array element with a sequence.\"\r\n                    ) from err\r\n                raise\r\n        return self\r\n\r\n    def putmask(self, mask, new) -> list[Block]:\r\n        \"\"\"\r\n        putmask the data to the block; it is possible that we may create a\r\n        new dtype of block\r\n\r\n        Return the resulting block(s).\r\n\r\n        Parameters\r\n        ----------\r\n        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n        new : a ndarray/object\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        orig_mask = mask\r\n        values = cast(np.ndarray, self.values)\r\n        mask, noop = validate_putmask(values.T, mask)\r\n        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        if new is lib.no_default:\r\n            new = self.fill_value\r\n\r\n        new = self._standardize_fill_value(new)\r\n        new = extract_array(new, extract_numpy=True)\r\n\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, new)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values)\r\n\r\n            putmask_without_repeat(values.T, mask, casted)\r\n            return [self]\r\n        except LossySetitemError:\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                if not is_list_like(new):\r\n                    # using just new[indexer] can't save us the need to cast\r\n                    return self.coerce_to_target_dtype(\r\n                        new, raise_on_upcast=True\r\n                    ).putmask(mask, new)\r\n                else:\r\n                    indexer = mask.nonzero()[0]\r\n                    nb = self.setitem(indexer, new[indexer])\r\n                    return [nb]\r\n\r\n            else:\r\n                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n                    obj_block = self.astype(np.dtype(object))\r\n                    obj_vals = cast(np.ndarray, obj_block.values)\r\n                    putmask_without_repeat(obj_vals.T, mask, new)\r\n                    return [obj_block]\r\n                is_array = isinstance(new, np.ndarray)\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    n = new\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        n = new[:, i : i + 1]\r\n\r\n                    submask = orig_mask[:, i : i + 1]\r\n                    rbs = nb.putmask(submask, n)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n    def where(self, other, cond) -> list[Block]:\r\n        \"\"\"\r\n        evaluate the block; return result block(s) from the result\r\n\r\n"]
[780.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[780.002, "i", "python - << 'PY'\r"]
[780.004, "o", "python - << 'PY'\r\n"]
[780.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/internals/blocks.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Insert fastpath into Block.where() LossySetitemError 2D-else branch\r\n\u001b[?2004l\r\n\u001b[?2004h> pattern = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     r\"def\\s+where\\(.*?\\):[\\s\\S]*?except\\s+LossySetitemError:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     r\"(\\s*)if\\s+self\\.ndim\\s*==\\s*1\\s*or\\s*self\\.shape\\[0\\]\\s*==\\s*1:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> m = re.search(pattern, s)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('Could not locate where() LossySetitemError branch')\r\n\u001b[?2004l\r\n\u001b[?2004h> indent = m.group(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> start = m.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> else_match = re.search(rf\"^{indent}else:\\n\", s[start:], flags=re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not else_match:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('Could not find else: branch in where()')\r\n\u001b[?2004l\r\n\u001b[?2004h> else_pos = start + else_match.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> fastpath = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    # Fastpath: for 2D blocks where dtype cannot hold 'other' (e.g., bool -> NaN),\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    # upcast once and apply assignment vectorized instead of splitting columns.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    if not is_list_like(other) or (isinstance(other, np.ndarray) and other.ndim == 0):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        obj_block = self.astype(np.dtype(object))\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        vals = obj_block.values\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        # where(cond, other): replace where cond is False\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        putmask_without_repeat(vals.T, ~cond, other)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        return [obj_block]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> s2 = s[:else_pos] + fastpath + s[else_pos:]\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(s2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Patched where() with 2D scalar fastpath')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nCould not locate where() LossySetitemError branch\r\n"]
[785.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[785.002, "i", "git diff -- pandas/core/internals/blocks.py | sed -n '1,200p'\r"]
[785.004, "o", "git diff -- pandas/core/internals/blocks.py | sed -n '1,200p'\r\n"]
[785.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/internals/blocks.py b/pandas/core/internals/blocks.py\r\nindex d1a9081b23..806a9117c3 100644\r\n--- a/pandas/core/internals/blocks.py\r\n+++ b/pandas/core/internals/blocks.py\r\n@@ -1194,6 +1194,12 @@ class Block(PandasObject, libinternals.Block):\r\n                     return [nb]\r\n \r\n             else:\r\n+                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n+                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n+                    obj_block = self.astype(np.dtype(object))\r\n+                    obj_vals = cast(np.ndarray, obj_block.values)\r\n+                    putmask_without_repeat(obj_vals.T, mask, new)\r\n+                    return [obj_block]\r\n                 is_array = isinstance(new, np.ndarray)\r\n \r\n                 res_blocks = []\r\n"]
[790.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[790.002, "i", "cd asv_bench\r"]
[790.004, "o", "cd asv_bench\r\n"]
[790.006, "o", "\u001b[?2004l\r\n"]
[795.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[795.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[795.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[795.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              55.0\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             4.33\u00b10ms\r\n"]
[800.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[800.002, "i", "cd ..\r"]
[800.004, "o", "cd ..\r\n"]
[800.006, "o", "\u001b[?2004l\r\n"]
[805.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[805.002, "i", "grep -n -F \"def where\" pandas/core/internals/blocks.py\r"]
[805.004, "o", "grep -n -F \"def where\" pandas/core/internals/blocks.py\r\n"]
[805.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K1217\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(self, other, cond) -> list[Block]:\r\n\u001b[32m\u001b[K1670\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(self, other, cond) -> list[Block]:\r\n"]
[810.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[810.002, "i", "sed -n '1080,1220p' pandas/core/internals/blocks.py\r"]
[810.004, "o", "sed -n '1080,1220p' pandas/core/internals/blocks.py\r\n"]
[810.006, "o", "\u001b[?2004l\r\n\r\n    def setitem(self, indexer, value) -> Block:\r\n        \"\"\"\r\n        Attempt self.values[indexer] = value, possibly creating a new array.\r\n\r\n        Parameters\r\n        ----------\r\n        indexer : tuple, list-like, array-like, slice, int\r\n            The subset of self.values to set\r\n        value : object\r\n            The value being set\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n\r\n        Notes\r\n        -----\r\n        `indexer` is a direct slice/positional indexer. `value` must\r\n        be a compatible shape.\r\n        \"\"\"\r\n\r\n        value = self._standardize_fill_value(value)\r\n\r\n        values = cast(np.ndarray, self.values)\r\n        if self.ndim == 2:\r\n            values = values.T\r\n\r\n        # length checking\r\n        check_setitem_lengths(indexer, value, values)\r\n\r\n        if self.dtype != _dtype_obj:\r\n            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n            value = extract_array(value, extract_numpy=True)\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, value)\r\n        except LossySetitemError:\r\n            # current dtype cannot store value, coerce to common dtype\r\n            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n            return nb.setitem(indexer, value)\r\n        else:\r\n            if self.dtype == _dtype_obj:\r\n                # TODO: avoid having to construct values[indexer]\r\n                vi = values[indexer]\r\n                if lib.is_list_like(vi):\r\n                    # checking lib.is_scalar here fails on\r\n                    #  test_iloc_setitem_custom_object\r\n                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values.T)\r\n            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n                casted = casted[0, ...]\r\n            try:\r\n                values[indexer] = casted\r\n            except (TypeError, ValueError) as err:\r\n                if is_list_like(casted):\r\n                    raise ValueError(\r\n                        \"setting an array element with a sequence.\"\r\n                    ) from err\r\n                raise\r\n        return self\r\n\r\n    def putmask(self, mask, new) -> list[Block]:\r\n        \"\"\"\r\n        putmask the data to the block; it is possible that we may create a\r\n        new dtype of block\r\n\r\n        Return the resulting block(s).\r\n\r\n        Parameters\r\n        ----------\r\n        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n        new : a ndarray/object\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        orig_mask = mask\r\n        values = cast(np.ndarray, self.values)\r\n        mask, noop = validate_putmask(values.T, mask)\r\n        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        if new is lib.no_default:\r\n            new = self.fill_value\r\n\r\n        new = self._standardize_fill_value(new)\r\n        new = extract_array(new, extract_numpy=True)\r\n\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, new)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values)\r\n\r\n            putmask_without_repeat(values.T, mask, casted)\r\n            return [self]\r\n        except LossySetitemError:\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                if not is_list_like(new):\r\n                    # using just new[indexer] can't save us the need to cast\r\n                    return self.coerce_to_target_dtype(\r\n                        new, raise_on_upcast=True\r\n                    ).putmask(mask, new)\r\n                else:\r\n                    indexer = mask.nonzero()[0]\r\n                    nb = self.setitem(indexer, new[indexer])\r\n                    return [nb]\r\n\r\n            else:\r\n                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n                    obj_block = self.astype(np.dtype(object))\r\n                    obj_vals = cast(np.ndarray, obj_block.values)\r\n                    putmask_without_repeat(obj_vals.T, mask, new)\r\n                    return [obj_block]\r\n                is_array = isinstance(new, np.ndarray)\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    n = new\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        n = new[:, i : i + 1]\r\n\r\n                    submask = orig_mask[:, i : i + 1]\r\n                    rbs = nb.putmask(submask, n)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n    def where(self, other, cond) -> list[Block]:\r\n        \"\"\"\r\n        evaluate the block; return result block(s) from the result\r\n\r\n"]
[815.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[815.002, "i", "sed -n '1220,1500p' pandas/core/internals/blocks.py\r"]
[815.004, "o", "sed -n '1220,1500p' pandas/core/internals/blocks.py\r\n"]
[815.006, "o", "\u001b[?2004l\r\n\r\n        Parameters\r\n        ----------\r\n        other : a ndarray/object\r\n        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        assert cond.ndim == self.ndim\r\n        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        transpose = self.ndim == 2\r\n\r\n        cond = extract_bool_array(cond)\r\n\r\n        # EABlocks override where\r\n        values = cast(np.ndarray, self.values)\r\n        orig_other = other\r\n        if transpose:\r\n            values = values.T\r\n\r\n        icond, noop = validate_putmask(values, ~cond)\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        if other is lib.no_default:\r\n            other = self.fill_value\r\n\r\n        other = self._standardize_fill_value(other)\r\n\r\n        try:\r\n            # try/except here is equivalent to a self._can_hold_element check,\r\n            #  but this gets us back 'casted' which we will reuse below;\r\n            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n            casted = np_can_hold_element(values.dtype, other)\r\n        except (ValueError, TypeError, LossySetitemError):\r\n            # we cannot coerce, return a compat dtype\r\n\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                block = self.coerce_to_target_dtype(other, raise_on_upcast=False)\r\n                return block.where(orig_other, cond)\r\n\r\n            else:\r\n                is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    oth = other\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        oth = other[:, i : i + 1]\r\n\r\n                    submask = cond[:, i : i + 1]\r\n                    rbs = nb.where(oth, submask)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n        else:\r\n            other = casted\r\n            alt = setitem_datetimelike_compat(values, icond.sum(), other)\r\n            if alt is not other:\r\n                if is_list_like(other) and len(other) < len(values):\r\n                    # call np.where with other to get the appropriate ValueError\r\n                    np.where(~icond, values, other)\r\n                    raise NotImplementedError(\r\n                        \"This should not be reached; call to np.where above is \"\r\n                        \"expected to raise ValueError. Please report a bug at \"\r\n                        \"github.com/pandas-dev/pandas\"\r\n                    )\r\n                result = values.copy()\r\n                np.putmask(result, icond, alt)\r\n            else:\r\n                # By the time we get here, we should have all Series/Index\r\n                #  args extracted to ndarray\r\n                if (\r\n                    is_list_like(other)\r\n                    and not isinstance(other, np.ndarray)\r\n                    and len(other) == self.shape[-1]\r\n                ):\r\n                    # If we don't do this broadcasting here, then expressions.where\r\n                    #  will broadcast a 1D other to be row-like instead of\r\n                    #  column-like.\r\n                    other = np.array(other).reshape(values.shape)\r\n                    # If lengths don't match (or len(other)==1), we will raise\r\n                    #  inside expressions.where, see test_series_where\r\n\r\n                # Note: expressions.where may upcast.\r\n                result = expressions.where(~icond, values, other)\r\n                # The np_can_hold_element check _should_ ensure that we always\r\n                #  have result.dtype == self.dtype here.\r\n\r\n        if transpose:\r\n            result = result.T\r\n\r\n        return [self.make_block(result)]\r\n\r\n    def fillna(\r\n        self,\r\n        value,\r\n        limit: int | None = None,\r\n        inplace: bool = False,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n        fillna on the block with the value. If we fail, then convert to\r\n        block to hold objects instead and try again\r\n        \"\"\"\r\n        # Caller is responsible for validating limit; if int it is strictly positive\r\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n\r\n        if not self._can_hold_na:\r\n            # can short-circuit the isna call\r\n            noop = True\r\n        else:\r\n            mask = isna(self.values)\r\n            mask, noop = validate_putmask(self.values, mask)\r\n\r\n        if noop:\r\n            # we can't process the value, but nothing to do\r\n            return [self.copy(deep=False)]\r\n\r\n        if limit is not None:\r\n            mask[mask.cumsum(self.values.ndim - 1) > limit] = False\r\n\r\n        if inplace:\r\n            nbs = self.putmask(mask.T, value)\r\n        else:\r\n            nbs = self.where(value, ~mask.T)\r\n        return extend_blocks(nbs)\r\n\r\n    def pad_or_backfill(\r\n        self,\r\n        *,\r\n        method: FillnaOptions,\r\n        inplace: bool = False,\r\n        limit: int | None = None,\r\n        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n    ) -> list[Block]:\r\n        if not self._can_hold_na:\r\n            # If there are no NAs, then interpolate is a no-op\r\n            return [self.copy(deep=False)]\r\n\r\n        copy, refs = self._get_refs_and_copy(inplace)\r\n\r\n        # Dispatch to the NumpyExtensionArray method.\r\n        # We know self.array_values is a NumpyExtensionArray bc EABlock overrides\r\n        vals = cast(NumpyExtensionArray, self.array_values)\r\n        new_values = vals.T._pad_or_backfill(\r\n            method=method,\r\n            limit=limit,\r\n            limit_area=limit_area,\r\n            copy=copy,\r\n        ).T\r\n\r\n        data = extract_array(new_values, extract_numpy=True)\r\n        return [self.make_block_same_class(data, refs=refs)]\r\n\r\n    @final\r\n    def interpolate(\r\n        self,\r\n        *,\r\n        method: InterpolateOptions,\r\n        index: Index,\r\n        inplace: bool = False,\r\n        limit: int | None = None,\r\n        limit_direction: Literal[\"forward\", \"backward\", \"both\"] = \"forward\",\r\n        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n        **kwargs,\r\n    ) -> list[Block]:\r\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n        # error: Non-overlapping equality check [...]\r\n        if method == \"asfreq\":  # type: ignore[comparison-overlap]\r\n            # clean_fill_method used to allow this\r\n            missing.clean_fill_method(method)\r\n\r\n        if not self._can_hold_na:\r\n            # If there are no NAs, then interpolate is a no-op\r\n            return [self.copy(deep=False)]\r\n\r\n        if self.dtype == _dtype_obj:\r\n            # GH#53631\r\n            name = {1: \"Series\", 2: \"DataFrame\"}[self.ndim]\r\n            raise TypeError(f\"{name} cannot interpolate with object dtype.\")\r\n\r\n        copy, refs = self._get_refs_and_copy(inplace)\r\n\r\n        # Dispatch to the EA method.\r\n        new_values = self.array_values.interpolate(\r\n            method=method,\r\n            axis=self.ndim - 1,\r\n            index=index,\r\n            limit=limit,\r\n            limit_direction=limit_direction,\r\n            limit_area=limit_area,\r\n            copy=copy,\r\n            **kwargs,\r\n        )\r\n        data = extract_array(new_values, extract_numpy=True)\r\n        return [self.make_block_same_class(data, refs=refs)]\r\n\r\n    @final\r\n    def diff(self, n: int) -> list[Block]:\r\n        \"\"\"return block for the diff of the values\"\"\"\r\n        # only reached with ndim == 2\r\n        # TODO(EA2D): transpose will be unnecessary with 2D EAs\r\n        new_values = algos.diff(self.values.T, n, axis=0).T\r\n        return [self.make_block(values=new_values)]\r\n\r\n    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:\r\n        \"\"\"shift the block by periods, possibly upcast\"\"\"\r\n        # convert integer to float if necessary. need to do a lot more than\r\n        # that, handle boolean etc also\r\n        axis = self.ndim - 1\r\n\r\n        # Note: periods is never 0 here, as that is handled at the top of\r\n        #  NDFrame.shift.  If that ever changes, we can do a check for periods=0\r\n        #  and possibly avoid coercing.\r\n\r\n        if not lib.is_scalar(fill_value) and self.dtype != _dtype_obj:\r\n            # with object dtype there is nothing to promote, and the user can\r\n            #  pass pretty much any weird fill_value they like\r\n            # see test_shift_object_non_scalar_fill\r\n            raise ValueError(\"fill_value must be a scalar\")\r\n\r\n        fill_value = self._standardize_fill_value(fill_value)\r\n\r\n        try:\r\n            # error: Argument 1 to \"np_can_hold_element\" has incompatible type\r\n            # \"Union[dtype[Any], ExtensionDtype]\"; expected \"dtype[Any]\"\r\n            casted = np_can_hold_element(\r\n                self.dtype,  # type: ignore[arg-type]\r\n                fill_value,\r\n            )\r\n        except LossySetitemError:\r\n            nb = self.coerce_to_target_dtype(fill_value, raise_on_upcast=False)\r\n            return nb.shift(periods, fill_value=fill_value)\r\n\r\n        else:\r\n            values = cast(np.ndarray, self.values)\r\n            new_values = shift(values, periods, axis, casted)\r\n            return [self.make_block_same_class(new_values)]\r\n\r\n    @final\r\n    def quantile(\r\n        self,\r\n        qs: Index,  # with dtype float64\r\n        interpolation: QuantileInterpolation = \"linear\",\r\n    ) -> Block:\r\n        \"\"\"\r\n        compute the quantiles of the\r\n\r\n        Parameters\r\n        ----------\r\n        qs : Index\r\n            The quantiles to be computed in float64.\r\n        interpolation : str, default 'linear'\r\n            Type of interpolation.\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n        \"\"\"\r\n        # We should always have ndim == 2 because Series dispatches to DataFrame\r\n        assert self.ndim == 2\r\n        assert is_list_like(qs)  # caller is responsible for this\r\n\r\n        result = quantile_compat(self.values, np.asarray(qs._values), interpolation)\r\n        # ensure_block_shape needed for cases where we start with EA and result\r\n        #  is ndarray, e.g. IntegerArray, SparseArray\r\n        result = ensure_block_shape(result, ndim=2)\r\n        return new_block_2d(result, placement=self._mgr_locs)\r\n\r\n    @final\r\n    def round(self, decimals: int) -> Self:\r\n        \"\"\"\r\n        Rounds the values.\r\n        If the block is not of an integer or float dtype, nothing happens.\r\n        This is consistent with DataFrame.round behavior.\r\n"]
[820.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[820.002, "i", "python - << 'PY'\r"]
[820.004, "o", "python - << 'PY'\r\n"]
[820.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/internals/blocks.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find the first LossySetitemError branch inside where()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Locate def where signature first\r\n\u001b[?2004l\r\n\u001b[?2004h> m_def = re.search(r\"^\\s*def\\s+where\\(.*\\):\", s, flags=re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m_def:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('def where not found')\r\n\u001b[?2004l\r\n\u001b[?2004h> start_def = m_def.start()\r\n\u001b[?2004l\r\n\u001b[?2004h> # From there to next except LossySetitemError inside where\r\n\u001b[?2004l\r\n\u001b[?2004h> m_exc = re.search(r\"except\\s+LossySetitemError:\\n(\\s*)if\\s+self\\.ndim\\s*==\\s*1\\s*or\\s*self\\.shape\\[0\\]\\s*==\\s*1:\\n\", s[start_def:])\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m_exc:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('LossySetitemError branch in where() not found')\r\n\u001b[?2004l\r\n\u001b[?2004h> indent = m_exc.group(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> block_start = start_def + m_exc.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find the else: following that if\r\n\u001b[?2004l\r\n\u001b[?2004h> else_match = re.search(rf\"^{indent}else:\\n\", s[block_start:], flags=re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not else_match:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('else: branch after where() LossySetitemError if not found')\r\n\u001b[?2004l\r\n\u001b[?2004h> else_pos = block_start + else_match.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> fastpath = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    # Fastpath: for 2D blocks where dtype cannot hold 'other' (e.g., bool -> NaN),\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    # upcast once and apply assignment vectorized instead of splitting columns.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    if not is_list_like(other) or (isinstance(other, np.ndarray) and other.ndim == 0):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        obj_block = self.astype(np.dtype(object))\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        vals = obj_block.values\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        # where(cond, other): replace where cond is False\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        putmask_without_repeat(vals.T, ~cond, other)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        return [obj_block]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> s2 = s[:else_pos] + fastpath + s[else_pos:]\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(s2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Patched where() with 2D scalar fastpath')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\ndef where not found\r\n"]
[825.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[825.002, "i", "git diff -- pandas/core/internals/blocks.py | sed -n '1,220p'\r"]
[825.004, "o", "git diff -- pandas/core/internals/blocks.py | sed -n '1,220p'\r\n"]
[825.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/internals/blocks.py b/pandas/core/internals/blocks.py\r\nindex d1a9081b23..806a9117c3 100644\r\n--- a/pandas/core/internals/blocks.py\r\n+++ b/pandas/core/internals/blocks.py\r\n@@ -1194,6 +1194,12 @@ class Block(PandasObject, libinternals.Block):\r\n                     return [nb]\r\n \r\n             else:\r\n+                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n+                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n+                    obj_block = self.astype(np.dtype(object))\r\n+                    obj_vals = cast(np.ndarray, obj_block.values)\r\n+                    putmask_without_repeat(obj_vals.T, mask, new)\r\n+                    return [obj_block]\r\n                 is_array = isinstance(new, np.ndarray)\r\n \r\n                 res_blocks = []\r\n"]
[830.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[830.002, "i", "cd asv_bench\r"]
[830.004, "o", "cd asv_bench\r\n"]
[830.006, "o", "\u001b[?2004l\r\n"]
[835.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[835.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[835.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[835.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              54.1\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             4.34\u00b10ms\r\n"]
[840.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[840.002, "i", "cd /workspace/repo\r"]
[840.004, "o", "cd /workspace/repo\r\n"]
[840.006, "o", "\u001b[?2004l\r\n"]
[845.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[845.002, "i", "grep -R -n -F \"def where(\" pandas/core | head -n 50\r"]
[845.004, "o", "grep -R -n -F \"def where(\" pandas/core | head -n 50\r\n"]
[845.006, "o", "\u001b[?2004l\r\npandas/core/computation/expressions.py:247:def where(cond, left_op, right_op, use_numexpr: bool = True):\r\npandas/core/generic.py:9831:    def where(\r\npandas/core/generic.py:9842:    def where(\r\npandas/core/generic.py:9853:    def where(\r\npandas/core/generic.py:9871:    def where(\r\npandas/core/indexes/base.py:5069:    def where(self, cond, other=None) -> Index:\r\npandas/core/internals/blocks.py:1217:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1670:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[850.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[850.002, "i", "grep -R -n -F \"def where(\" pandas/core/internals | head -n 50\r"]
[850.004, "o", "grep -R -n -F \"def where(\" pandas/core/internals | head -n 50\r\n"]
[850.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1217:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1670:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[855.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[855.002, "i", "grep -R -n \"where(\" pandas/core/internals | head -n 50\r"]
[855.004, "o", "grep -R -n \"where(\" pandas/core/internals | head -n 50\r\n"]
[855.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1217:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1264:                return block.where(orig_other, cond)\r\npandas/core/internals/blocks.py:1277:                    rbs = nb.where(oth, submask)\r\npandas/core/internals/blocks.py:1287:                    np.where(~icond, values, other)\r\npandas/core/internals/blocks.py:1311:                result = expressions.where(~icond, values, other)\r\npandas/core/internals/blocks.py:1350:            nbs = self.where(value, ~mask.T)\r\npandas/core/internals/blocks.py:1670:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1690:            res_values = arr._where(cond, other).T\r\npandas/core/internals/blocks.py:1703:                    return blk.where(orig_other, orig_cond)\r\npandas/core/internals/blocks.py:1709:                    return blk.where(orig_other, orig_cond)\r\npandas/core/internals/blocks.py:1726:                    rbs = nb.where(n, submask)\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[860.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[860.002, "i", "sed -n '1000,1350p' pandas/core/internals/blocks.py\r"]
[860.004, "o", "sed -n '1000,1350p' pandas/core/internals/blocks.py\r\n"]
[860.006, "o", "\u001b[?2004l\r\n        new_mgr_locs: BlockPlacement | None = None,\r\n        fill_value=lib.no_default,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Take values according to indexer and return them as a block.\r\n        \"\"\"\r\n        values = self.values\r\n\r\n        if fill_value is lib.no_default:\r\n            fill_value = self.fill_value\r\n            allow_fill = False\r\n        else:\r\n            allow_fill = True\r\n\r\n        # Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\r\n        new_values = algos.take_nd(\r\n            values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\r\n        )\r\n\r\n        # Called from three places in managers, all of which satisfy\r\n        #  these assertions\r\n        if isinstance(self, ExtensionBlock):\r\n            # NB: in this case, the 'axis' kwarg will be ignored in the\r\n            #  algos.take_nd call above.\r\n            assert not (self.ndim == 1 and new_mgr_locs is None)\r\n        assert not (axis == 0 and new_mgr_locs is None)\r\n\r\n        if new_mgr_locs is None:\r\n            new_mgr_locs = self._mgr_locs\r\n\r\n        if new_values.dtype != self.dtype:\r\n            return self.make_block(new_values, new_mgr_locs)\r\n        else:\r\n            return self.make_block_same_class(new_values, new_mgr_locs)\r\n\r\n    def _unstack(\r\n        self,\r\n        unstacker,\r\n        fill_value,\r\n        new_placement: npt.NDArray[np.intp],\r\n        needs_masking: npt.NDArray[np.bool_],\r\n    ):\r\n        \"\"\"\r\n        Return a list of unstacked blocks of self\r\n\r\n        Parameters\r\n        ----------\r\n        unstacker : reshape._Unstacker\r\n        fill_value : int\r\n            Only used in ExtensionBlock._unstack\r\n        new_placement : np.ndarray[np.intp]\r\n        allow_fill : bool\r\n        needs_masking : np.ndarray[bool]\r\n\r\n        Returns\r\n        -------\r\n        blocks : list of Block\r\n            New blocks of unstacked values.\r\n        mask : array-like of bool\r\n            The mask of columns of `blocks` we should keep.\r\n        \"\"\"\r\n        new_values, mask = unstacker.get_new_values(\r\n            self.values.T, fill_value=fill_value\r\n        )\r\n\r\n        mask = mask.any(0)\r\n        # TODO: in all tests we have mask.all(); can we rely on that?\r\n\r\n        # Note: these next two lines ensure that\r\n        #  mask.sum() == sum(len(nb.mgr_locs) for nb in blocks)\r\n        #  which the calling function needs in order to pass verify_integrity=False\r\n        #  to the BlockManager constructor\r\n        new_values = new_values.T[mask]\r\n        new_placement = new_placement[mask]\r\n\r\n        bp = BlockPlacement(new_placement)\r\n        blocks = [new_block_2d(new_values, placement=bp)]\r\n        return blocks, mask\r\n\r\n    # ---------------------------------------------------------------------\r\n\r\n    def setitem(self, indexer, value) -> Block:\r\n        \"\"\"\r\n        Attempt self.values[indexer] = value, possibly creating a new array.\r\n\r\n        Parameters\r\n        ----------\r\n        indexer : tuple, list-like, array-like, slice, int\r\n            The subset of self.values to set\r\n        value : object\r\n            The value being set\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n\r\n        Notes\r\n        -----\r\n        `indexer` is a direct slice/positional indexer. `value` must\r\n        be a compatible shape.\r\n        \"\"\"\r\n\r\n        value = self._standardize_fill_value(value)\r\n\r\n        values = cast(np.ndarray, self.values)\r\n        if self.ndim == 2:\r\n            values = values.T\r\n\r\n        # length checking\r\n        check_setitem_lengths(indexer, value, values)\r\n\r\n        if self.dtype != _dtype_obj:\r\n            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n            value = extract_array(value, extract_numpy=True)\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, value)\r\n        except LossySetitemError:\r\n            # current dtype cannot store value, coerce to common dtype\r\n            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n            return nb.setitem(indexer, value)\r\n        else:\r\n            if self.dtype == _dtype_obj:\r\n                # TODO: avoid having to construct values[indexer]\r\n                vi = values[indexer]\r\n                if lib.is_list_like(vi):\r\n                    # checking lib.is_scalar here fails on\r\n                    #  test_iloc_setitem_custom_object\r\n                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values.T)\r\n            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n                casted = casted[0, ...]\r\n            try:\r\n                values[indexer] = casted\r\n            except (TypeError, ValueError) as err:\r\n                if is_list_like(casted):\r\n                    raise ValueError(\r\n                        \"setting an array element with a sequence.\"\r\n                    ) from err\r\n                raise\r\n        return self\r\n\r\n    def putmask(self, mask, new) -> list[Block]:\r\n        \"\"\"\r\n        putmask the data to the block; it is possible that we may create a\r\n        new dtype of block\r\n\r\n        Return the resulting block(s).\r\n\r\n        Parameters\r\n        ----------\r\n        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n        new : a ndarray/object\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        orig_mask = mask\r\n        values = cast(np.ndarray, self.values)\r\n        mask, noop = validate_putmask(values.T, mask)\r\n        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        if new is lib.no_default:\r\n            new = self.fill_value\r\n\r\n        new = self._standardize_fill_value(new)\r\n        new = extract_array(new, extract_numpy=True)\r\n\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, new)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values)\r\n\r\n            putmask_without_repeat(values.T, mask, casted)\r\n            return [self]\r\n        except LossySetitemError:\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                if not is_list_like(new):\r\n                    # using just new[indexer] can't save us the need to cast\r\n                    return self.coerce_to_target_dtype(\r\n                        new, raise_on_upcast=True\r\n                    ).putmask(mask, new)\r\n                else:\r\n                    indexer = mask.nonzero()[0]\r\n                    nb = self.setitem(indexer, new[indexer])\r\n                    return [nb]\r\n\r\n            else:\r\n                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n                    obj_block = self.astype(np.dtype(object))\r\n                    obj_vals = cast(np.ndarray, obj_block.values)\r\n                    putmask_without_repeat(obj_vals.T, mask, new)\r\n                    return [obj_block]\r\n                is_array = isinstance(new, np.ndarray)\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    n = new\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        n = new[:, i : i + 1]\r\n\r\n                    submask = orig_mask[:, i : i + 1]\r\n                    rbs = nb.putmask(submask, n)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n    def where(self, other, cond) -> list[Block]:\r\n        \"\"\"\r\n        evaluate the block; return result block(s) from the result\r\n\r\n        Parameters\r\n        ----------\r\n        other : a ndarray/object\r\n        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        assert cond.ndim == self.ndim\r\n        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        transpose = self.ndim == 2\r\n\r\n        cond = extract_bool_array(cond)\r\n\r\n        # EABlocks override where\r\n        values = cast(np.ndarray, self.values)\r\n        orig_other = other\r\n        if transpose:\r\n            values = values.T\r\n\r\n        icond, noop = validate_putmask(values, ~cond)\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        if other is lib.no_default:\r\n            other = self.fill_value\r\n\r\n        other = self._standardize_fill_value(other)\r\n\r\n        try:\r\n            # try/except here is equivalent to a self._can_hold_element check,\r\n            #  but this gets us back 'casted' which we will reuse below;\r\n            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n            casted = np_can_hold_element(values.dtype, other)\r\n        except (ValueError, TypeError, LossySetitemError):\r\n            # we cannot coerce, return a compat dtype\r\n\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                block = self.coerce_to_target_dtype(other, raise_on_upcast=False)\r\n                return block.where(orig_other, cond)\r\n\r\n            else:\r\n                is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    oth = other\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        oth = other[:, i : i + 1]\r\n\r\n                    submask = cond[:, i : i + 1]\r\n                    rbs = nb.where(oth, submask)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n        else:\r\n            other = casted\r\n            alt = setitem_datetimelike_compat(values, icond.sum(), other)\r\n            if alt is not other:\r\n                if is_list_like(other) and len(other) < len(values):\r\n                    # call np.where with other to get the appropriate ValueError\r\n                    np.where(~icond, values, other)\r\n                    raise NotImplementedError(\r\n                        \"This should not be reached; call to np.where above is \"\r\n                        \"expected to raise ValueError. Please report a bug at \"\r\n                        \"github.com/pandas-dev/pandas\"\r\n                    )\r\n                result = values.copy()\r\n                np.putmask(result, icond, alt)\r\n            else:\r\n                # By the time we get here, we should have all Series/Index\r\n                #  args extracted to ndarray\r\n                if (\r\n                    is_list_like(other)\r\n                    and not isinstance(other, np.ndarray)\r\n                    and len(other) == self.shape[-1]\r\n                ):\r\n                    # If we don't do this broadcasting here, then expressions.where\r\n                    #  will broadcast a 1D other to be row-like instead of\r\n                    #  column-like.\r\n                    other = np.array(other).reshape(values.shape)\r\n                    # If lengths don't match (or len(other)==1), we will raise\r\n                    #  inside expressions.where, see test_series_where\r\n\r\n                # Note: expressions.where may upcast.\r\n                result = expressions.where(~icond, values, other)\r\n                # The np_can_hold_element check _should_ ensure that we always\r\n                #  have result.dtype == self.dtype here.\r\n\r\n        if transpose:\r\n            result = result.T\r\n\r\n        return [self.make_block(result)]\r\n\r\n    def fillna(\r\n        self,\r\n        value,\r\n        limit: int | None = None,\r\n        inplace: bool = False,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n        fillna on the block with the value. If we fail, then convert to\r\n        block to hold objects instead and try again\r\n        \"\"\"\r\n        # Caller is responsible for validating limit; if int it is strictly positive\r\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n\r\n        if not self._can_hold_na:\r\n            # can short-circuit the isna call\r\n            noop = True\r\n        else:\r\n            mask = isna(self.values)\r\n            mask, noop = validate_putmask(self.values, mask)\r\n\r\n        if noop:\r\n            # we can't process the value, but nothing to do\r\n            return [self.copy(deep=False)]\r\n\r\n        if limit is not None:\r\n            mask[mask.cumsum(self.values.ndim - 1) > limit] = False\r\n\r\n        if inplace:\r\n            nbs = self.putmask(mask.T, value)\r\n        else:\r\n            nbs = self.where(value, ~mask.T)\r\n"]
[865.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[865.002, "i", "sed -n '1,260p' pandas/core/internals/managers.py\r"]
[865.004, "o", "sed -n '1,260p' pandas/core/internals/managers.py\r\n"]
[865.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nfrom collections.abc import (\r\n    Callable,\r\n    Hashable,\r\n    Sequence,\r\n)\r\nimport itertools\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config.config import get_option\r\n\r\nfrom pandas._libs import (\r\n    algos as libalgos,\r\n    internals as libinternals,\r\n    lib,\r\n)\r\nfrom pandas._libs.internals import (\r\n    BlockPlacement,\r\n    BlockValuesRefs,\r\n)\r\nfrom pandas._libs.tslibs import Timestamp\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    PerformanceWarning,\r\n)\r\nfrom pandas.util._decorators import cache_readonly\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import validate_bool_kwarg\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    find_common_type,\r\n    infer_dtype_from_scalar,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_platform_int,\r\n    is_1d_only_ea_dtype,\r\n    is_list_like,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    SparseDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    array_equals,\r\n    isna,\r\n)\r\n\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.arrays import DatetimeArray\r\nfrom pandas.core.arrays._mixins import NDArrayBackedExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n)\r\nfrom pandas.core.indexers import maybe_convert_indices\r\nfrom pandas.core.indexes.api import (\r\n    Index,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals.blocks import (\r\n    Block,\r\n    NumpyBlock,\r\n    ensure_block_shape,\r\n    extend_blocks,\r\n    get_block_type,\r\n    maybe_coerce_values,\r\n    new_block,\r\n    new_block_2d,\r\n)\r\nfrom pandas.core.internals.ops import (\r\n    blockwise_all,\r\n    operate_blockwise,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Generator\r\n\r\n    from pandas._typing import (\r\n        ArrayLike,\r\n        AxisInt,\r\n        DtypeObj,\r\n        QuantileInterpolation,\r\n        Self,\r\n        Shape,\r\n        npt,\r\n    )\r\n\r\n    from pandas.api.extensions import ExtensionArray\r\n\r\n\r\ndef interleaved_dtype(dtypes: list[DtypeObj]) -> DtypeObj | None:\r\n    \"\"\"\r\n    Find the common dtype for `blocks`.\r\n\r\n    Parameters\r\n    ----------\r\n    blocks : List[DtypeObj]\r\n\r\n    Returns\r\n    -------\r\n    dtype : np.dtype, ExtensionDtype, or None\r\n        None is returned when `blocks` is empty.\r\n    \"\"\"\r\n    if not len(dtypes):\r\n        return None\r\n\r\n    return find_common_type(dtypes)\r\n\r\n\r\ndef ensure_np_dtype(dtype: DtypeObj) -> np.dtype:\r\n    # TODO: https://github.com/pandas-dev/pandas/issues/22791\r\n    # Give EAs some input on what happens here. Sparse needs this.\r\n    if isinstance(dtype, SparseDtype):\r\n        dtype = dtype.subtype\r\n        dtype = cast(np.dtype, dtype)\r\n    elif isinstance(dtype, ExtensionDtype):\r\n        dtype = np.dtype(\"object\")\r\n    elif dtype == np.dtype(str):\r\n        dtype = np.dtype(\"object\")\r\n    return dtype\r\n\r\n\r\nclass BaseBlockManager(PandasObject):\r\n    \"\"\"\r\n    Core internal data structure to implement DataFrame, Series, etc.\r\n\r\n    Manage a bunch of labeled 2D mixed-type ndarrays. Essentially it's a\r\n    lightweight blocked set of labeled data to be manipulated by the DataFrame\r\n    public API class\r\n\r\n    Attributes\r\n    ----------\r\n    shape\r\n    ndim\r\n    axes\r\n    values\r\n    items\r\n\r\n    Methods\r\n    -------\r\n    set_axis(axis, new_labels)\r\n    copy(deep=True)\r\n\r\n    get_dtypes\r\n\r\n    apply(func, axes, block_filter_fn)\r\n\r\n    get_bool_data\r\n    get_numeric_data\r\n\r\n    get_slice(slice_like, axis)\r\n    get(label)\r\n    iget(loc)\r\n\r\n    take(indexer, axis)\r\n    reindex_axis(new_labels, axis)\r\n    reindex_indexer(new_labels, indexer, axis)\r\n\r\n    delete(label)\r\n    insert(loc, label, value)\r\n    set(label, value)\r\n\r\n    Parameters\r\n    ----------\r\n    blocks: Sequence of Block\r\n    axes: Sequence of Index\r\n    verify_integrity: bool, default True\r\n\r\n    Notes\r\n    -----\r\n    This is *not* a public API class\r\n    \"\"\"\r\n\r\n    __slots__ = ()\r\n\r\n    _blknos: npt.NDArray[np.intp]\r\n    _blklocs: npt.NDArray[np.intp]\r\n    blocks: tuple[Block, ...]\r\n    axes: list[Index]\r\n\r\n    @property\r\n    def ndim(self) -> int:\r\n        raise NotImplementedError\r\n\r\n    _known_consolidated: bool\r\n    _is_consolidated: bool\r\n\r\n    def __init__(self, blocks, axes, verify_integrity: bool = True) -> None:\r\n        raise NotImplementedError\r\n\r\n    @final\r\n    def __len__(self) -> int:\r\n        return len(self.items)\r\n\r\n    @property\r\n    def shape(self) -> Shape:\r\n        return tuple(len(ax) for ax in self.axes)\r\n\r\n    @classmethod\r\n    def from_blocks(cls, blocks: list[Block], axes: list[Index]) -> Self:\r\n        raise NotImplementedError\r\n\r\n    @property\r\n    def blknos(self) -> npt.NDArray[np.intp]:\r\n        \"\"\"\r\n        Suppose we want to find the array corresponding to our i'th column.\r\n\r\n        blknos[i] identifies the block from self.blocks that contains this column.\r\n\r\n        blklocs[i] identifies the column of interest within\r\n        self.blocks[self.blknos[i]]\r\n        \"\"\"\r\n        if self._blknos is None:\r\n            # Note: these can be altered by other BlockManager methods.\r\n            self._rebuild_blknos_and_blklocs()\r\n\r\n        return self._blknos\r\n\r\n    @property\r\n    def blklocs(self) -> npt.NDArray[np.intp]:\r\n        \"\"\"\r\n        See blknos.__doc__\r\n        \"\"\"\r\n        if self._blklocs is None:\r\n            # Note: these can be altered by other BlockManager methods.\r\n            self._rebuild_blknos_and_blklocs()\r\n\r\n        return self._blklocs\r\n\r\n    def make_empty(self, axes=None) -> Self:\r\n        \"\"\"return an empty BlockManager with the items axis of len 0\"\"\"\r\n        if axes is None:\r\n            axes = [default_index(0)] + self.axes[1:]\r\n\r\n        # preserve dtype if possible\r\n        if self.ndim == 1:\r\n            assert isinstance(self, SingleBlockManager)  # for mypy\r\n            blk = self.blocks[0]\r\n            arr = blk.values[:0]\r\n            bp = BlockPlacement(slice(0, 0))\r\n            nb = blk.make_block_same_class(arr, placement=bp)\r\n"]
[870.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[870.002, "i", "grep -R -n -F \"LossySetitemError\" pandas/core/internals/blocks.py\r"]
[870.004, "o", "grep -R -n -F \"LossySetitemError\" pandas/core/internals/blocks.py\r\n"]
[870.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K53\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K,\r\n\u001b[32m\u001b[K1116\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n\u001b[32m\u001b[K1182\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n\u001b[32m\u001b[K1257\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except (ValueError, TypeError, \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K):\r\n\u001b[32m\u001b[K1456\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n"]
[875.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[875.002, "i", "sed -n '1080,1220p' pandas/core/internals/blocks.py\r"]
[875.004, "o", "sed -n '1080,1220p' pandas/core/internals/blocks.py\r\n"]
[875.006, "o", "\u001b[?2004l\r\n\r\n    def setitem(self, indexer, value) -> Block:\r\n        \"\"\"\r\n        Attempt self.values[indexer] = value, possibly creating a new array.\r\n\r\n        Parameters\r\n        ----------\r\n        indexer : tuple, list-like, array-like, slice, int\r\n            The subset of self.values to set\r\n        value : object\r\n            The value being set\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n\r\n        Notes\r\n        -----\r\n        `indexer` is a direct slice/positional indexer. `value` must\r\n        be a compatible shape.\r\n        \"\"\"\r\n\r\n        value = self._standardize_fill_value(value)\r\n\r\n        values = cast(np.ndarray, self.values)\r\n        if self.ndim == 2:\r\n            values = values.T\r\n\r\n        # length checking\r\n        check_setitem_lengths(indexer, value, values)\r\n\r\n        if self.dtype != _dtype_obj:\r\n            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n            value = extract_array(value, extract_numpy=True)\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, value)\r\n        except LossySetitemError:\r\n            # current dtype cannot store value, coerce to common dtype\r\n            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n            return nb.setitem(indexer, value)\r\n        else:\r\n            if self.dtype == _dtype_obj:\r\n                # TODO: avoid having to construct values[indexer]\r\n                vi = values[indexer]\r\n                if lib.is_list_like(vi):\r\n                    # checking lib.is_scalar here fails on\r\n                    #  test_iloc_setitem_custom_object\r\n                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values.T)\r\n            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n                casted = casted[0, ...]\r\n            try:\r\n                values[indexer] = casted\r\n            except (TypeError, ValueError) as err:\r\n                if is_list_like(casted):\r\n                    raise ValueError(\r\n                        \"setting an array element with a sequence.\"\r\n                    ) from err\r\n                raise\r\n        return self\r\n\r\n    def putmask(self, mask, new) -> list[Block]:\r\n        \"\"\"\r\n        putmask the data to the block; it is possible that we may create a\r\n        new dtype of block\r\n\r\n        Return the resulting block(s).\r\n\r\n        Parameters\r\n        ----------\r\n        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n        new : a ndarray/object\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        orig_mask = mask\r\n        values = cast(np.ndarray, self.values)\r\n        mask, noop = validate_putmask(values.T, mask)\r\n        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        if new is lib.no_default:\r\n            new = self.fill_value\r\n\r\n        new = self._standardize_fill_value(new)\r\n        new = extract_array(new, extract_numpy=True)\r\n\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, new)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values)\r\n\r\n            putmask_without_repeat(values.T, mask, casted)\r\n            return [self]\r\n        except LossySetitemError:\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                if not is_list_like(new):\r\n                    # using just new[indexer] can't save us the need to cast\r\n                    return self.coerce_to_target_dtype(\r\n                        new, raise_on_upcast=True\r\n                    ).putmask(mask, new)\r\n                else:\r\n                    indexer = mask.nonzero()[0]\r\n                    nb = self.setitem(indexer, new[indexer])\r\n                    return [nb]\r\n\r\n            else:\r\n                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n                    obj_block = self.astype(np.dtype(object))\r\n                    obj_vals = cast(np.ndarray, obj_block.values)\r\n                    putmask_without_repeat(obj_vals.T, mask, new)\r\n                    return [obj_block]\r\n                is_array = isinstance(new, np.ndarray)\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    n = new\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        n = new[:, i : i + 1]\r\n\r\n                    submask = orig_mask[:, i : i + 1]\r\n                    rbs = nb.putmask(submask, n)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n    def where(self, other, cond) -> list[Block]:\r\n        \"\"\"\r\n        evaluate the block; return result block(s) from the result\r\n\r\n"]
[880.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[880.002, "i", "sed -n '1220,1500p' pandas/core/internals/blocks.py\r"]
[880.004, "o", "sed -n '1220,1500p' pandas/core/internals/blocks.py\r\n"]
[880.006, "o", "\u001b[?2004l\r\n\r\n        Parameters\r\n        ----------\r\n        other : a ndarray/object\r\n        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        assert cond.ndim == self.ndim\r\n        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        transpose = self.ndim == 2\r\n\r\n        cond = extract_bool_array(cond)\r\n\r\n        # EABlocks override where\r\n        values = cast(np.ndarray, self.values)\r\n        orig_other = other\r\n        if transpose:\r\n            values = values.T\r\n\r\n        icond, noop = validate_putmask(values, ~cond)\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        if other is lib.no_default:\r\n            other = self.fill_value\r\n\r\n        other = self._standardize_fill_value(other)\r\n\r\n        try:\r\n            # try/except here is equivalent to a self._can_hold_element check,\r\n            #  but this gets us back 'casted' which we will reuse below;\r\n            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n            casted = np_can_hold_element(values.dtype, other)\r\n        except (ValueError, TypeError, LossySetitemError):\r\n            # we cannot coerce, return a compat dtype\r\n\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                block = self.coerce_to_target_dtype(other, raise_on_upcast=False)\r\n                return block.where(orig_other, cond)\r\n\r\n            else:\r\n                is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    oth = other\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        oth = other[:, i : i + 1]\r\n\r\n                    submask = cond[:, i : i + 1]\r\n                    rbs = nb.where(oth, submask)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n        else:\r\n            other = casted\r\n            alt = setitem_datetimelike_compat(values, icond.sum(), other)\r\n            if alt is not other:\r\n                if is_list_like(other) and len(other) < len(values):\r\n                    # call np.where with other to get the appropriate ValueError\r\n                    np.where(~icond, values, other)\r\n                    raise NotImplementedError(\r\n                        \"This should not be reached; call to np.where above is \"\r\n                        \"expected to raise ValueError. Please report a bug at \"\r\n                        \"github.com/pandas-dev/pandas\"\r\n                    )\r\n                result = values.copy()\r\n                np.putmask(result, icond, alt)\r\n            else:\r\n                # By the time we get here, we should have all Series/Index\r\n                #  args extracted to ndarray\r\n                if (\r\n                    is_list_like(other)\r\n                    and not isinstance(other, np.ndarray)\r\n                    and len(other) == self.shape[-1]\r\n                ):\r\n                    # If we don't do this broadcasting here, then expressions.where\r\n                    #  will broadcast a 1D other to be row-like instead of\r\n                    #  column-like.\r\n                    other = np.array(other).reshape(values.shape)\r\n                    # If lengths don't match (or len(other)==1), we will raise\r\n                    #  inside expressions.where, see test_series_where\r\n\r\n                # Note: expressions.where may upcast.\r\n                result = expressions.where(~icond, values, other)\r\n                # The np_can_hold_element check _should_ ensure that we always\r\n                #  have result.dtype == self.dtype here.\r\n\r\n        if transpose:\r\n            result = result.T\r\n\r\n        return [self.make_block(result)]\r\n\r\n    def fillna(\r\n        self,\r\n        value,\r\n        limit: int | None = None,\r\n        inplace: bool = False,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n        fillna on the block with the value. If we fail, then convert to\r\n        block to hold objects instead and try again\r\n        \"\"\"\r\n        # Caller is responsible for validating limit; if int it is strictly positive\r\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n\r\n        if not self._can_hold_na:\r\n            # can short-circuit the isna call\r\n            noop = True\r\n        else:\r\n            mask = isna(self.values)\r\n            mask, noop = validate_putmask(self.values, mask)\r\n\r\n        if noop:\r\n            # we can't process the value, but nothing to do\r\n            return [self.copy(deep=False)]\r\n\r\n        if limit is not None:\r\n            mask[mask.cumsum(self.values.ndim - 1) > limit] = False\r\n\r\n        if inplace:\r\n            nbs = self.putmask(mask.T, value)\r\n        else:\r\n            nbs = self.where(value, ~mask.T)\r\n        return extend_blocks(nbs)\r\n\r\n    def pad_or_backfill(\r\n        self,\r\n        *,\r\n        method: FillnaOptions,\r\n        inplace: bool = False,\r\n        limit: int | None = None,\r\n        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n    ) -> list[Block]:\r\n        if not self._can_hold_na:\r\n            # If there are no NAs, then interpolate is a no-op\r\n            return [self.copy(deep=False)]\r\n\r\n        copy, refs = self._get_refs_and_copy(inplace)\r\n\r\n        # Dispatch to the NumpyExtensionArray method.\r\n        # We know self.array_values is a NumpyExtensionArray bc EABlock overrides\r\n        vals = cast(NumpyExtensionArray, self.array_values)\r\n        new_values = vals.T._pad_or_backfill(\r\n            method=method,\r\n            limit=limit,\r\n            limit_area=limit_area,\r\n            copy=copy,\r\n        ).T\r\n\r\n        data = extract_array(new_values, extract_numpy=True)\r\n        return [self.make_block_same_class(data, refs=refs)]\r\n\r\n    @final\r\n    def interpolate(\r\n        self,\r\n        *,\r\n        method: InterpolateOptions,\r\n        index: Index,\r\n        inplace: bool = False,\r\n        limit: int | None = None,\r\n        limit_direction: Literal[\"forward\", \"backward\", \"both\"] = \"forward\",\r\n        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n        **kwargs,\r\n    ) -> list[Block]:\r\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n        # error: Non-overlapping equality check [...]\r\n        if method == \"asfreq\":  # type: ignore[comparison-overlap]\r\n            # clean_fill_method used to allow this\r\n            missing.clean_fill_method(method)\r\n\r\n        if not self._can_hold_na:\r\n            # If there are no NAs, then interpolate is a no-op\r\n            return [self.copy(deep=False)]\r\n\r\n        if self.dtype == _dtype_obj:\r\n            # GH#53631\r\n            name = {1: \"Series\", 2: \"DataFrame\"}[self.ndim]\r\n            raise TypeError(f\"{name} cannot interpolate with object dtype.\")\r\n\r\n        copy, refs = self._get_refs_and_copy(inplace)\r\n\r\n        # Dispatch to the EA method.\r\n        new_values = self.array_values.interpolate(\r\n            method=method,\r\n            axis=self.ndim - 1,\r\n            index=index,\r\n            limit=limit,\r\n            limit_direction=limit_direction,\r\n            limit_area=limit_area,\r\n            copy=copy,\r\n            **kwargs,\r\n        )\r\n        data = extract_array(new_values, extract_numpy=True)\r\n        return [self.make_block_same_class(data, refs=refs)]\r\n\r\n    @final\r\n    def diff(self, n: int) -> list[Block]:\r\n        \"\"\"return block for the diff of the values\"\"\"\r\n        # only reached with ndim == 2\r\n        # TODO(EA2D): transpose will be unnecessary with 2D EAs\r\n        new_values = algos.diff(self.values.T, n, axis=0).T\r\n        return [self.make_block(values=new_values)]\r\n\r\n    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:\r\n        \"\"\"shift the block by periods, possibly upcast\"\"\"\r\n        # convert integer to float if necessary. need to do a lot more than\r\n        # that, handle boolean etc also\r\n        axis = self.ndim - 1\r\n\r\n        # Note: periods is never 0 here, as that is handled at the top of\r\n        #  NDFrame.shift.  If that ever changes, we can do a check for periods=0\r\n        #  and possibly avoid coercing.\r\n\r\n        if not lib.is_scalar(fill_value) and self.dtype != _dtype_obj:\r\n            # with object dtype there is nothing to promote, and the user can\r\n            #  pass pretty much any weird fill_value they like\r\n            # see test_shift_object_non_scalar_fill\r\n            raise ValueError(\"fill_value must be a scalar\")\r\n\r\n        fill_value = self._standardize_fill_value(fill_value)\r\n\r\n        try:\r\n            # error: Argument 1 to \"np_can_hold_element\" has incompatible type\r\n            # \"Union[dtype[Any], ExtensionDtype]\"; expected \"dtype[Any]\"\r\n            casted = np_can_hold_element(\r\n                self.dtype,  # type: ignore[arg-type]\r\n                fill_value,\r\n            )\r\n        except LossySetitemError:\r\n            nb = self.coerce_to_target_dtype(fill_value, raise_on_upcast=False)\r\n            return nb.shift(periods, fill_value=fill_value)\r\n\r\n        else:\r\n            values = cast(np.ndarray, self.values)\r\n            new_values = shift(values, periods, axis, casted)\r\n            return [self.make_block_same_class(new_values)]\r\n\r\n    @final\r\n    def quantile(\r\n        self,\r\n        qs: Index,  # with dtype float64\r\n        interpolation: QuantileInterpolation = \"linear\",\r\n    ) -> Block:\r\n        \"\"\"\r\n        compute the quantiles of the\r\n\r\n        Parameters\r\n        ----------\r\n        qs : Index\r\n            The quantiles to be computed in float64.\r\n        interpolation : str, default 'linear'\r\n            Type of interpolation.\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n        \"\"\"\r\n        # We should always have ndim == 2 because Series dispatches to DataFrame\r\n        assert self.ndim == 2\r\n        assert is_list_like(qs)  # caller is responsible for this\r\n\r\n        result = quantile_compat(self.values, np.asarray(qs._values), interpolation)\r\n        # ensure_block_shape needed for cases where we start with EA and result\r\n        #  is ndarray, e.g. IntegerArray, SparseArray\r\n        result = ensure_block_shape(result, ndim=2)\r\n        return new_block_2d(result, placement=self._mgr_locs)\r\n\r\n    @final\r\n    def round(self, decimals: int) -> Self:\r\n        \"\"\"\r\n        Rounds the values.\r\n        If the block is not of an integer or float dtype, nothing happens.\r\n        This is consistent with DataFrame.round behavior.\r\n"]
[885.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[885.002, "i", "python - << 'PY'\r"]
[885.004, "o", "python - << 'PY'\r\n"]
[885.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/internals/blocks.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Try to patch where(): find def where and its LossySetitemError branch\r\n\u001b[?2004l\r\n\u001b[?2004h> m_def = re.search(r\"^\\s*def\\s+where\\(.*\\):\", s, flags=re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h> if m_def:\r\n\u001b[?2004l\r\n\u001b[?2004h>     start_def = m_def.start()\r\n\u001b[?2004l\r\n\u001b[?2004h>     m_exc = re.search(r\"except\\s+LossySetitemError:\\n(\\s*)if\\s+self\\.ndim\\s*==\\s*1\\s*or\\s*self\\.shape\\[0\\]\\s*==\\s*1:\\n\", s[start_def:])\r\n\u001b[?2004l\r\n\u001b[?2004h>     if m_exc:\r\n\u001b[?2004l\r\n\u001b[?2004h>         indent = m_exc.group(1)\r\n\u001b[?2004l\r\n\u001b[?2004h>         block_start = start_def + m_exc.end()\r\n\u001b[?2004l\r\n\u001b[?2004h>         else_match = re.search(rf\"^{indent}else:\\n\", s[block_start:], flags=re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h>         if else_match:\r\n\u001b[?2004l\r\n\u001b[?2004h>             else_pos = block_start + else_match.end()\r\n\u001b[?2004l\r\n\u001b[?2004h>             fastpath = (\r\n\u001b[?2004l\r\n\u001b[?2004h>                 f\"{indent}    # Fastpath: for 2D blocks where dtype cannot hold 'other' (e.g., bool -> NaN),\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 f\"{indent}    # upcast once and apply assignment vectorized instead of splitting columns.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 f\"{indent}    if not is_list_like(other) or (isinstance(other, np.ndarray) and other.ndim == 0):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 f\"{indent}        obj_block = self.astype(np.dtype(object))\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 f\"{indent}        vals = obj_block.values\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 f\"{indent}        # where(cond, other): replace where cond is False\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 f\"{indent}        putmask_without_repeat(vals.T, ~cond, other)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 f\"{indent}        return [obj_block]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             )\r\n\u001b[?2004l\r\n\u001b[?2004h>             s2 = s[:else_pos] + fastpath + s[else_pos:]\r\n\u001b[?2004l\r\n\u001b[?2004h>             p.write_text(s2)\r\n\u001b[?2004l\r\n\u001b[?2004h>             print('Patched where() fastpath')\r\n\u001b[?2004l\r\n\u001b[?2004h>         else:\r\n\u001b[?2004l\r\n\u001b[?2004h>             print('else: after LossySetitemError not found in where()', flush=True)\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('LossySetitemError branch not found within where()')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('def where() not found in blocks.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\ndef where() not found in blocks.py\r\n"]
[890.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[890.002, "i", "git diff -- pandas/core/internals/blocks.py | sed -n '1,220p'\r"]
[890.004, "o", "git diff -- pandas/core/internals/blocks.py | sed -n '1,220p'\r\n"]
[890.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/internals/blocks.py b/pandas/core/internals/blocks.py\r\nindex d1a9081b23..806a9117c3 100644\r\n--- a/pandas/core/internals/blocks.py\r\n+++ b/pandas/core/internals/blocks.py\r\n@@ -1194,6 +1194,12 @@ class Block(PandasObject, libinternals.Block):\r\n                     return [nb]\r\n \r\n             else:\r\n+                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n+                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n+                    obj_block = self.astype(np.dtype(object))\r\n+                    obj_vals = cast(np.ndarray, obj_block.values)\r\n+                    putmask_without_repeat(obj_vals.T, mask, new)\r\n+                    return [obj_block]\r\n                 is_array = isinstance(new, np.ndarray)\r\n \r\n                 res_blocks = []\r\n"]
[895.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[895.002, "i", "cd asv_bench\r"]
[895.004, "o", "cd asv_bench\r\n"]
[895.006, "o", "\u001b[?2004l\r\n"]
[900.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[900.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[900.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[900.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              54.9\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             4.09\u00b10ms\r\n"]
[905.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[905.002, "i", "cd /workspace/repo\r"]
[905.004, "o", "cd /workspace/repo\r\n"]
[905.006, "o", "\u001b[?2004l\r\n"]
[910.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[910.002, "i", "sed -n '1000,1300p' pandas/core/internals/blocks.py | sed -n '1,400p'\r"]
[910.004, "o", "sed -n '1000,1300p' pandas/core/internals/blocks.py | sed -n '1,400p'\r\n"]
[910.006, "o", "\u001b[?2004l\r\n        new_mgr_locs: BlockPlacement | None = None,\r\n        fill_value=lib.no_default,\r\n    ) -> Block:\r\n        \"\"\"\r\n        Take values according to indexer and return them as a block.\r\n        \"\"\"\r\n        values = self.values\r\n\r\n        if fill_value is lib.no_default:\r\n            fill_value = self.fill_value\r\n            allow_fill = False\r\n        else:\r\n            allow_fill = True\r\n\r\n        # Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\r\n        new_values = algos.take_nd(\r\n            values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\r\n        )\r\n\r\n        # Called from three places in managers, all of which satisfy\r\n        #  these assertions\r\n        if isinstance(self, ExtensionBlock):\r\n            # NB: in this case, the 'axis' kwarg will be ignored in the\r\n            #  algos.take_nd call above.\r\n            assert not (self.ndim == 1 and new_mgr_locs is None)\r\n        assert not (axis == 0 and new_mgr_locs is None)\r\n\r\n        if new_mgr_locs is None:\r\n            new_mgr_locs = self._mgr_locs\r\n\r\n        if new_values.dtype != self.dtype:\r\n            return self.make_block(new_values, new_mgr_locs)\r\n        else:\r\n            return self.make_block_same_class(new_values, new_mgr_locs)\r\n\r\n    def _unstack(\r\n        self,\r\n        unstacker,\r\n        fill_value,\r\n        new_placement: npt.NDArray[np.intp],\r\n        needs_masking: npt.NDArray[np.bool_],\r\n    ):\r\n        \"\"\"\r\n        Return a list of unstacked blocks of self\r\n\r\n        Parameters\r\n        ----------\r\n        unstacker : reshape._Unstacker\r\n        fill_value : int\r\n            Only used in ExtensionBlock._unstack\r\n        new_placement : np.ndarray[np.intp]\r\n        allow_fill : bool\r\n        needs_masking : np.ndarray[bool]\r\n\r\n        Returns\r\n        -------\r\n        blocks : list of Block\r\n            New blocks of unstacked values.\r\n        mask : array-like of bool\r\n            The mask of columns of `blocks` we should keep.\r\n        \"\"\"\r\n        new_values, mask = unstacker.get_new_values(\r\n            self.values.T, fill_value=fill_value\r\n        )\r\n\r\n        mask = mask.any(0)\r\n        # TODO: in all tests we have mask.all(); can we rely on that?\r\n\r\n        # Note: these next two lines ensure that\r\n        #  mask.sum() == sum(len(nb.mgr_locs) for nb in blocks)\r\n        #  which the calling function needs in order to pass verify_integrity=False\r\n        #  to the BlockManager constructor\r\n        new_values = new_values.T[mask]\r\n        new_placement = new_placement[mask]\r\n\r\n        bp = BlockPlacement(new_placement)\r\n        blocks = [new_block_2d(new_values, placement=bp)]\r\n        return blocks, mask\r\n\r\n    # ---------------------------------------------------------------------\r\n\r\n    def setitem(self, indexer, value) -> Block:\r\n        \"\"\"\r\n        Attempt self.values[indexer] = value, possibly creating a new array.\r\n\r\n        Parameters\r\n        ----------\r\n        indexer : tuple, list-like, array-like, slice, int\r\n            The subset of self.values to set\r\n        value : object\r\n            The value being set\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n\r\n        Notes\r\n        -----\r\n        `indexer` is a direct slice/positional indexer. `value` must\r\n        be a compatible shape.\r\n        \"\"\"\r\n\r\n        value = self._standardize_fill_value(value)\r\n\r\n        values = cast(np.ndarray, self.values)\r\n        if self.ndim == 2:\r\n            values = values.T\r\n\r\n        # length checking\r\n        check_setitem_lengths(indexer, value, values)\r\n\r\n        if self.dtype != _dtype_obj:\r\n            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n            value = extract_array(value, extract_numpy=True)\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, value)\r\n        except LossySetitemError:\r\n            # current dtype cannot store value, coerce to common dtype\r\n            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n            return nb.setitem(indexer, value)\r\n        else:\r\n            if self.dtype == _dtype_obj:\r\n                # TODO: avoid having to construct values[indexer]\r\n                vi = values[indexer]\r\n                if lib.is_list_like(vi):\r\n                    # checking lib.is_scalar here fails on\r\n                    #  test_iloc_setitem_custom_object\r\n                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values.T)\r\n            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n                casted = casted[0, ...]\r\n            try:\r\n                values[indexer] = casted\r\n            except (TypeError, ValueError) as err:\r\n                if is_list_like(casted):\r\n                    raise ValueError(\r\n                        \"setting an array element with a sequence.\"\r\n                    ) from err\r\n                raise\r\n        return self\r\n\r\n    def putmask(self, mask, new) -> list[Block]:\r\n        \"\"\"\r\n        putmask the data to the block; it is possible that we may create a\r\n        new dtype of block\r\n\r\n        Return the resulting block(s).\r\n\r\n        Parameters\r\n        ----------\r\n        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n        new : a ndarray/object\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        orig_mask = mask\r\n        values = cast(np.ndarray, self.values)\r\n        mask, noop = validate_putmask(values.T, mask)\r\n        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        if new is lib.no_default:\r\n            new = self.fill_value\r\n\r\n        new = self._standardize_fill_value(new)\r\n        new = extract_array(new, extract_numpy=True)\r\n\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, new)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values)\r\n\r\n            putmask_without_repeat(values.T, mask, casted)\r\n            return [self]\r\n        except LossySetitemError:\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                if not is_list_like(new):\r\n                    # using just new[indexer] can't save us the need to cast\r\n                    return self.coerce_to_target_dtype(\r\n                        new, raise_on_upcast=True\r\n                    ).putmask(mask, new)\r\n                else:\r\n                    indexer = mask.nonzero()[0]\r\n                    nb = self.setitem(indexer, new[indexer])\r\n                    return [nb]\r\n\r\n            else:\r\n                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n                    obj_block = self.astype(np.dtype(object))\r\n                    obj_vals = cast(np.ndarray, obj_block.values)\r\n                    putmask_without_repeat(obj_vals.T, mask, new)\r\n                    return [obj_block]\r\n                is_array = isinstance(new, np.ndarray)\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    n = new\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        n = new[:, i : i + 1]\r\n\r\n                    submask = orig_mask[:, i : i + 1]\r\n                    rbs = nb.putmask(submask, n)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n    def where(self, other, cond) -> list[Block]:\r\n        \"\"\"\r\n        evaluate the block; return result block(s) from the result\r\n\r\n        Parameters\r\n        ----------\r\n        other : a ndarray/object\r\n        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        assert cond.ndim == self.ndim\r\n        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        transpose = self.ndim == 2\r\n\r\n        cond = extract_bool_array(cond)\r\n\r\n        # EABlocks override where\r\n        values = cast(np.ndarray, self.values)\r\n        orig_other = other\r\n        if transpose:\r\n            values = values.T\r\n\r\n        icond, noop = validate_putmask(values, ~cond)\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        if other is lib.no_default:\r\n            other = self.fill_value\r\n\r\n        other = self._standardize_fill_value(other)\r\n\r\n        try:\r\n            # try/except here is equivalent to a self._can_hold_element check,\r\n            #  but this gets us back 'casted' which we will reuse below;\r\n            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n            casted = np_can_hold_element(values.dtype, other)\r\n        except (ValueError, TypeError, LossySetitemError):\r\n            # we cannot coerce, return a compat dtype\r\n\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                block = self.coerce_to_target_dtype(other, raise_on_upcast=False)\r\n                return block.where(orig_other, cond)\r\n\r\n            else:\r\n                is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    oth = other\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        oth = other[:, i : i + 1]\r\n\r\n                    submask = cond[:, i : i + 1]\r\n                    rbs = nb.where(oth, submask)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n        else:\r\n            other = casted\r\n            alt = setitem_datetimelike_compat(values, icond.sum(), other)\r\n            if alt is not other:\r\n                if is_list_like(other) and len(other) < len(values):\r\n                    # call np.where with other to get the appropriate ValueError\r\n                    np.where(~icond, values, other)\r\n                    raise NotImplementedError(\r\n                        \"This should not be reached; call to np.where above is \"\r\n                        \"expected to raise ValueError. Please report a bug at \"\r\n                        \"github.com/pandas-dev/pandas\"\r\n                    )\r\n                result = values.copy()\r\n                np.putmask(result, icond, alt)\r\n            else:\r\n                # By the time we get here, we should have all Series/Index\r\n                #  args extracted to ndarray\r\n                if (\r\n                    is_list_like(other)\r\n                    and not isinstance(other, np.ndarray)\r\n"]
[915.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[915.002, "i", "nl -ba pandas/core/internals/blocks.py | sed -n '1080,1220p'\r"]
[915.004, "o", "nl -ba pandas/core/internals/blocks.py | sed -n '1080,1220p'\r\n"]
[915.006, "o", "\u001b[?2004l\r\n  1080\t\r\n  1081\t    def setitem(self, indexer, value) -> Block:\r\n  1082\t        \"\"\"\r\n  1083\t        Attempt self.values[indexer] = value, possibly creating a new array.\r\n  1084\t\r\n  1085\t        Parameters\r\n  1086\t        ----------\r\n  1087\t        indexer : tuple, list-like, array-like, slice, int\r\n  1088\t            The subset of self.values to set\r\n  1089\t        value : object\r\n  1090\t            The value being set\r\n  1091\t\r\n  1092\t        Returns\r\n  1093\t        -------\r\n  1094\t        Block\r\n  1095\t\r\n  1096\t        Notes\r\n  1097\t        -----\r\n  1098\t        `indexer` is a direct slice/positional indexer. `value` must\r\n  1099\t        be a compatible shape.\r\n  1100\t        \"\"\"\r\n  1101\t\r\n  1102\t        value = self._standardize_fill_value(value)\r\n  1103\t\r\n  1104\t        values = cast(np.ndarray, self.values)\r\n  1105\t        if self.ndim == 2:\r\n  1106\t            values = values.T\r\n  1107\t\r\n  1108\t        # length checking\r\n  1109\t        check_setitem_lengths(indexer, value, values)\r\n  1110\t\r\n  1111\t        if self.dtype != _dtype_obj:\r\n  1112\t            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n  1113\t            value = extract_array(value, extract_numpy=True)\r\n  1114\t        try:\r\n  1115\t            casted = np_can_hold_element(values.dtype, value)\r\n  1116\t        except LossySetitemError:\r\n  1117\t            # current dtype cannot store value, coerce to common dtype\r\n  1118\t            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n  1119\t            return nb.setitem(indexer, value)\r\n  1120\t        else:\r\n  1121\t            if self.dtype == _dtype_obj:\r\n  1122\t                # TODO: avoid having to construct values[indexer]\r\n  1123\t                vi = values[indexer]\r\n  1124\t                if lib.is_list_like(vi):\r\n  1125\t                    # checking lib.is_scalar here fails on\r\n  1126\t                    #  test_iloc_setitem_custom_object\r\n  1127\t                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n  1128\t\r\n  1129\t            self = self._maybe_copy(inplace=True)\r\n  1130\t            values = cast(np.ndarray, self.values.T)\r\n  1131\t            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n  1132\t                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n  1133\t                casted = casted[0, ...]\r\n  1134\t            try:\r\n  1135\t                values[indexer] = casted\r\n  1136\t            except (TypeError, ValueError) as err:\r\n  1137\t                if is_list_like(casted):\r\n  1138\t                    raise ValueError(\r\n  1139\t                        \"setting an array element with a sequence.\"\r\n  1140\t                    ) from err\r\n  1141\t                raise\r\n  1142\t        return self\r\n  1143\t\r\n  1144\t    def putmask(self, mask, new) -> list[Block]:\r\n  1145\t        \"\"\"\r\n  1146\t        putmask the data to the block; it is possible that we may create a\r\n  1147\t        new dtype of block\r\n  1148\t\r\n  1149\t        Return the resulting block(s).\r\n  1150\t\r\n  1151\t        Parameters\r\n  1152\t        ----------\r\n  1153\t        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n  1154\t        new : a ndarray/object\r\n  1155\t\r\n  1156\t        Returns\r\n  1157\t        -------\r\n  1158\t        List[Block]\r\n  1159\t        \"\"\"\r\n  1160\t        orig_mask = mask\r\n  1161\t        values = cast(np.ndarray, self.values)\r\n  1162\t        mask, noop = validate_putmask(values.T, mask)\r\n  1163\t        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n  1164\t\r\n  1165\t        if new is lib.no_default:\r\n  1166\t            new = self.fill_value\r\n  1167\t\r\n  1168\t        new = self._standardize_fill_value(new)\r\n  1169\t        new = extract_array(new, extract_numpy=True)\r\n  1170\t\r\n  1171\t        if noop:\r\n  1172\t            return [self.copy(deep=False)]\r\n  1173\t\r\n  1174\t        try:\r\n  1175\t            casted = np_can_hold_element(values.dtype, new)\r\n  1176\t\r\n  1177\t            self = self._maybe_copy(inplace=True)\r\n  1178\t            values = cast(np.ndarray, self.values)\r\n  1179\t\r\n  1180\t            putmask_without_repeat(values.T, mask, casted)\r\n  1181\t            return [self]\r\n  1182\t        except LossySetitemError:\r\n  1183\t            if self.ndim == 1 or self.shape[0] == 1:\r\n  1184\t                # no need to split columns\r\n  1185\t\r\n  1186\t                if not is_list_like(new):\r\n  1187\t                    # using just new[indexer] can't save us the need to cast\r\n  1188\t                    return self.coerce_to_target_dtype(\r\n  1189\t                        new, raise_on_upcast=True\r\n  1190\t                    ).putmask(mask, new)\r\n  1191\t                else:\r\n  1192\t                    indexer = mask.nonzero()[0]\r\n  1193\t                    nb = self.setitem(indexer, new[indexer])\r\n  1194\t                    return [nb]\r\n  1195\t\r\n  1196\t            else:\r\n  1197\t                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n  1198\t                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n  1199\t                    obj_block = self.astype(np.dtype(object))\r\n  1200\t                    obj_vals = cast(np.ndarray, obj_block.values)\r\n  1201\t                    putmask_without_repeat(obj_vals.T, mask, new)\r\n  1202\t                    return [obj_block]\r\n  1203\t                is_array = isinstance(new, np.ndarray)\r\n  1204\t\r\n  1205\t                res_blocks = []\r\n  1206\t                for i, nb in enumerate(self._split()):\r\n  1207\t                    n = new\r\n  1208\t                    if is_array:\r\n  1209\t                        # we have a different value per-column\r\n  1210\t                        n = new[:, i : i + 1]\r\n  1211\t\r\n  1212\t                    submask = orig_mask[:, i : i + 1]\r\n  1213\t                    rbs = nb.putmask(submask, n)\r\n  1214\t                    res_blocks.extend(rbs)\r\n  1215\t                return res_blocks\r\n  1216\t\r\n  1217\t    def where(self, other, cond) -> list[Block]:\r\n  1218\t        \"\"\"\r\n  1219\t        evaluate the block; return result block(s) from the result\r\n  1220\t\r\n"]
[920.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[920.002, "i", "nl -ba pandas/core/internals/blocks.py | sed -n '1220,1500p'\r"]
[920.004, "o", "nl -ba pandas/core/internals/blocks.py | sed -n '1220,1500p'\r\n"]
[920.006, "o", "\u001b[?2004l\r\n  1220\t\r\n  1221\t        Parameters\r\n  1222\t        ----------\r\n  1223\t        other : a ndarray/object\r\n  1224\t        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n  1225\t\r\n  1226\t        Returns\r\n  1227\t        -------\r\n  1228\t        List[Block]\r\n  1229\t        \"\"\"\r\n  1230\t        assert cond.ndim == self.ndim\r\n  1231\t        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\r\n  1232\t\r\n  1233\t        transpose = self.ndim == 2\r\n  1234\t\r\n  1235\t        cond = extract_bool_array(cond)\r\n  1236\t\r\n  1237\t        # EABlocks override where\r\n  1238\t        values = cast(np.ndarray, self.values)\r\n  1239\t        orig_other = other\r\n  1240\t        if transpose:\r\n  1241\t            values = values.T\r\n  1242\t\r\n  1243\t        icond, noop = validate_putmask(values, ~cond)\r\n  1244\t        if noop:\r\n  1245\t            return [self.copy(deep=False)]\r\n  1246\t\r\n  1247\t        if other is lib.no_default:\r\n  1248\t            other = self.fill_value\r\n  1249\t\r\n  1250\t        other = self._standardize_fill_value(other)\r\n  1251\t\r\n  1252\t        try:\r\n  1253\t            # try/except here is equivalent to a self._can_hold_element check,\r\n  1254\t            #  but this gets us back 'casted' which we will reuse below;\r\n  1255\t            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n  1256\t            casted = np_can_hold_element(values.dtype, other)\r\n  1257\t        except (ValueError, TypeError, LossySetitemError):\r\n  1258\t            # we cannot coerce, return a compat dtype\r\n  1259\t\r\n  1260\t            if self.ndim == 1 or self.shape[0] == 1:\r\n  1261\t                # no need to split columns\r\n  1262\t\r\n  1263\t                block = self.coerce_to_target_dtype(other, raise_on_upcast=False)\r\n  1264\t                return block.where(orig_other, cond)\r\n  1265\t\r\n  1266\t            else:\r\n  1267\t                is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n  1268\t\r\n  1269\t                res_blocks = []\r\n  1270\t                for i, nb in enumerate(self._split()):\r\n  1271\t                    oth = other\r\n  1272\t                    if is_array:\r\n  1273\t                        # we have a different value per-column\r\n  1274\t                        oth = other[:, i : i + 1]\r\n  1275\t\r\n  1276\t                    submask = cond[:, i : i + 1]\r\n  1277\t                    rbs = nb.where(oth, submask)\r\n  1278\t                    res_blocks.extend(rbs)\r\n  1279\t                return res_blocks\r\n  1280\t\r\n  1281\t        else:\r\n  1282\t            other = casted\r\n  1283\t            alt = setitem_datetimelike_compat(values, icond.sum(), other)\r\n  1284\t            if alt is not other:\r\n  1285\t                if is_list_like(other) and len(other) < len(values):\r\n  1286\t                    # call np.where with other to get the appropriate ValueError\r\n  1287\t                    np.where(~icond, values, other)\r\n  1288\t                    raise NotImplementedError(\r\n  1289\t                        \"This should not be reached; call to np.where above is \"\r\n  1290\t                        \"expected to raise ValueError. Please report a bug at \"\r\n  1291\t                        \"github.com/pandas-dev/pandas\"\r\n  1292\t                    )\r\n  1293\t                result = values.copy()\r\n  1294\t                np.putmask(result, icond, alt)\r\n  1295\t            else:\r\n  1296\t                # By the time we get here, we should have all Series/Index\r\n  1297\t                #  args extracted to ndarray\r\n  1298\t                if (\r\n  1299\t                    is_list_like(other)\r\n  1300\t                    and not isinstance(other, np.ndarray)\r\n  1301\t                    and len(other) == self.shape[-1]\r\n  1302\t                ):\r\n  1303\t                    # If we don't do this broadcasting here, then expressions.where\r\n  1304\t                    #  will broadcast a 1D other to be row-like instead of\r\n  1305\t                    #  column-like.\r\n  1306\t                    other = np.array(other).reshape(values.shape)\r\n  1307\t                    # If lengths don't match (or len(other)==1), we will raise\r\n  1308\t                    #  inside expressions.where, see test_series_where\r\n  1309\t\r\n  1310\t                # Note: expressions.where may upcast.\r\n  1311\t                result = expressions.where(~icond, values, other)\r\n  1312\t                # The np_can_hold_element check _should_ ensure that we always\r\n  1313\t                #  have result.dtype == self.dtype here.\r\n  1314\t\r\n  1315\t        if transpose:\r\n  1316\t            result = result.T\r\n  1317\t\r\n  1318\t        return [self.make_block(result)]\r\n  1319\t\r\n  1320\t    def fillna(\r\n  1321\t        self,\r\n  1322\t        value,\r\n  1323\t        limit: int | None = None,\r\n  1324\t        inplace: bool = False,\r\n  1325\t    ) -> list[Block]:\r\n  1326\t        \"\"\"\r\n  1327\t        fillna on the block with the value. If we fail, then convert to\r\n  1328\t        block to hold objects instead and try again\r\n  1329\t        \"\"\"\r\n  1330\t        # Caller is responsible for validating limit; if int it is strictly positive\r\n  1331\t        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n  1332\t\r\n  1333\t        if not self._can_hold_na:\r\n  1334\t            # can short-circuit the isna call\r\n  1335\t            noop = True\r\n  1336\t        else:\r\n  1337\t            mask = isna(self.values)\r\n  1338\t            mask, noop = validate_putmask(self.values, mask)\r\n  1339\t\r\n  1340\t        if noop:\r\n  1341\t            # we can't process the value, but nothing to do\r\n  1342\t            return [self.copy(deep=False)]\r\n  1343\t\r\n  1344\t        if limit is not None:\r\n  1345\t            mask[mask.cumsum(self.values.ndim - 1) > limit] = False\r\n  1346\t\r\n  1347\t        if inplace:\r\n  1348\t            nbs = self.putmask(mask.T, value)\r\n  1349\t        else:\r\n  1350\t            nbs = self.where(value, ~mask.T)\r\n  1351\t        return extend_blocks(nbs)\r\n  1352\t\r\n  1353\t    def pad_or_backfill(\r\n  1354\t        self,\r\n  1355\t        *,\r\n  1356\t        method: FillnaOptions,\r\n  1357\t        inplace: bool = False,\r\n  1358\t        limit: int | None = None,\r\n  1359\t        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n  1360\t    ) -> list[Block]:\r\n  1361\t        if not self._can_hold_na:\r\n  1362\t            # If there are no NAs, then interpolate is a no-op\r\n  1363\t            return [self.copy(deep=False)]\r\n  1364\t\r\n  1365\t        copy, refs = self._get_refs_and_copy(inplace)\r\n  1366\t\r\n  1367\t        # Dispatch to the NumpyExtensionArray method.\r\n  1368\t        # We know self.array_values is a NumpyExtensionArray bc EABlock overrides\r\n  1369\t        vals = cast(NumpyExtensionArray, self.array_values)\r\n  1370\t        new_values = vals.T._pad_or_backfill(\r\n  1371\t            method=method,\r\n  1372\t            limit=limit,\r\n  1373\t            limit_area=limit_area,\r\n  1374\t            copy=copy,\r\n  1375\t        ).T\r\n  1376\t\r\n  1377\t        data = extract_array(new_values, extract_numpy=True)\r\n  1378\t        return [self.make_block_same_class(data, refs=refs)]\r\n  1379\t\r\n  1380\t    @final\r\n  1381\t    def interpolate(\r\n  1382\t        self,\r\n  1383\t        *,\r\n  1384\t        method: InterpolateOptions,\r\n  1385\t        index: Index,\r\n  1386\t        inplace: bool = False,\r\n  1387\t        limit: int | None = None,\r\n  1388\t        limit_direction: Literal[\"forward\", \"backward\", \"both\"] = \"forward\",\r\n  1389\t        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n  1390\t        **kwargs,\r\n  1391\t    ) -> list[Block]:\r\n  1392\t        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n  1393\t        # error: Non-overlapping equality check [...]\r\n  1394\t        if method == \"asfreq\":  # type: ignore[comparison-overlap]\r\n  1395\t            # clean_fill_method used to allow this\r\n  1396\t            missing.clean_fill_method(method)\r\n  1397\t\r\n  1398\t        if not self._can_hold_na:\r\n  1399\t            # If there are no NAs, then interpolate is a no-op\r\n  1400\t            return [self.copy(deep=False)]\r\n  1401\t\r\n  1402\t        if self.dtype == _dtype_obj:\r\n  1403\t            # GH#53631\r\n  1404\t            name = {1: \"Series\", 2: \"DataFrame\"}[self.ndim]\r\n  1405\t            raise TypeError(f\"{name} cannot interpolate with object dtype.\")\r\n  1406\t\r\n  1407\t        copy, refs = self._get_refs_and_copy(inplace)\r\n  1408\t\r\n  1409\t        # Dispatch to the EA method.\r\n  1410\t        new_values = self.array_values.interpolate(\r\n  1411\t            method=method,\r\n  1412\t            axis=self.ndim - 1,\r\n  1413\t            index=index,\r\n  1414\t            limit=limit,\r\n  1415\t            limit_direction=limit_direction,\r\n  1416\t            limit_area=limit_area,\r\n  1417\t            copy=copy,\r\n  1418\t            **kwargs,\r\n  1419\t        )\r\n  1420\t        data = extract_array(new_values, extract_numpy=True)\r\n  1421\t        return [self.make_block_same_class(data, refs=refs)]\r\n  1422\t\r\n  1423\t    @final\r\n  1424\t    def diff(self, n: int) -> list[Block]:\r\n  1425\t        \"\"\"return block for the diff of the values\"\"\"\r\n  1426\t        # only reached with ndim == 2\r\n  1427\t        # TODO(EA2D): transpose will be unnecessary with 2D EAs\r\n  1428\t        new_values = algos.diff(self.values.T, n, axis=0).T\r\n  1429\t        return [self.make_block(values=new_values)]\r\n  1430\t\r\n  1431\t    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:\r\n  1432\t        \"\"\"shift the block by periods, possibly upcast\"\"\"\r\n  1433\t        # convert integer to float if necessary. need to do a lot more than\r\n  1434\t        # that, handle boolean etc also\r\n  1435\t        axis = self.ndim - 1\r\n  1436\t\r\n  1437\t        # Note: periods is never 0 here, as that is handled at the top of\r\n  1438\t        #  NDFrame.shift.  If that ever changes, we can do a check for periods=0\r\n  1439\t        #  and possibly avoid coercing.\r\n  1440\t\r\n  1441\t        if not lib.is_scalar(fill_value) and self.dtype != _dtype_obj:\r\n  1442\t            # with object dtype there is nothing to promote, and the user can\r\n  1443\t            #  pass pretty much any weird fill_value they like\r\n  1444\t            # see test_shift_object_non_scalar_fill\r\n  1445\t            raise ValueError(\"fill_value must be a scalar\")\r\n  1446\t\r\n  1447\t        fill_value = self._standardize_fill_value(fill_value)\r\n  1448\t\r\n  1449\t        try:\r\n  1450\t            # error: Argument 1 to \"np_can_hold_element\" has incompatible type\r\n  1451\t            # \"Union[dtype[Any], ExtensionDtype]\"; expected \"dtype[Any]\"\r\n  1452\t            casted = np_can_hold_element(\r\n  1453\t                self.dtype,  # type: ignore[arg-type]\r\n  1454\t                fill_value,\r\n  1455\t            )\r\n  1456\t        except LossySetitemError:\r\n  1457\t            nb = self.coerce_to_target_dtype(fill_value, raise_on_upcast=False)\r\n  1458\t            return nb.shift(periods, fill_value=fill_value)\r\n  1459\t\r\n  1460\t        else:\r\n  1461\t            values = cast(np.ndarray, self.values)\r\n  1462\t            new_values = shift(values, periods, axis, casted)\r\n  1463\t            return [self.make_block_same_class(new_values)]\r\n  1464\t\r\n  1465\t    @final\r\n  1466\t    def quantile(\r\n  1467\t        self,\r\n  1468\t        qs: Index,  # with dtype float64\r\n  1469\t        interpolation: QuantileInterpolation = \"linear\",\r\n  1470\t    ) -> Block:\r\n  1471\t        \"\"\"\r\n  1472\t        compute the quantiles of the\r\n  1473\t\r\n  1474\t        Parameters\r\n  1475\t        ----------\r\n  1476\t        qs : Index\r\n  1477\t            The quantiles to be computed in float64.\r\n  1478\t        interpolation : str, default 'linear'\r\n  1479\t            Type of interpolation.\r\n  1480\t\r\n  1481\t        Returns\r\n  1482\t        -------\r\n  1483\t        Block\r\n  1484\t        \"\"\"\r\n  1485\t        # We should always have ndim == 2 because Series dispatches to DataFrame\r\n  1486\t        assert self.ndim == 2\r\n  1487\t        assert is_list_like(qs)  # caller is responsible for this\r\n  1488\t\r\n  1489\t        result = quantile_compat(self.values, np.asarray(qs._values), interpolation)\r\n  1490\t        # ensure_block_shape needed for cases where we start with EA and result\r\n  1491\t        #  is ndarray, e.g. IntegerArray, SparseArray\r\n  1492\t        result = ensure_block_shape(result, ndim=2)\r\n  1493\t        return new_block_2d(result, placement=self._mgr_locs)\r\n  1494\t\r\n  1495\t    @final\r\n  1496\t    def round(self, decimals: int) -> Self:\r\n  1497\t        \"\"\"\r\n  1498\t        Rounds the values.\r\n  1499\t        If the block is not of an integer or float dtype, nothing happens.\r\n  1500\t        This is consistent with DataFrame.round behavior.\r\n"]
[925.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[925.002, "i", "python - << 'PY'\r"]
[925.004, "o", "python - << 'PY'\r\n"]
[925.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/internals/blocks.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Try to find the where method definition within Block class by a less strict pattern\r\n\u001b[?2004l\r\n\u001b[?2004h> m_def = re.search(r\"^\\s*def\\s+where\\s*\\(.*\\):\", s, flags=re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m_def:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('where() def not found; printing nearby excerpt for manual inspection')\r\n\u001b[?2004l\r\n\u001b[?2004h>     print(s[1000:1500])\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> start_def = m_def.start()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Find the first 'except LossySetitemError:' after def where\r\n\u001b[?2004l\r\n\u001b[?2004h> m_exc = re.search(r\"except\\s+LossySetitemError:\\n(\\s*)if\\s+self\\.ndim\\s*==\\s*1\\s*or\\s*self\\.shape\\[0\\]\\s*==\\s*1:\\n\", s[start_def:])\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m_exc:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('LossySetitemError branch not found under where()')\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> indent = m_exc.group(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> block_start = start_def + m_exc.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> else_match = re.search(rf\"^{indent}else:\\n\", s[block_start:], flags=re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not else_match:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('else: branch after LossySetitemError if not found')\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> else_pos = block_start + else_match.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> fastpath = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"\\n{indent}    # Fastpath: for 2D blocks where dtype cannot hold 'other' (e.g., bool -> NaN),\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    # upcast once and apply assignment vectorized instead of splitting columns.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    if not is_list_like(other) or (isinstance(other, np.ndarray) and other.ndim == 0):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        obj_block = self.astype(np.dtype(object))\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        vals = obj_block.values\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        # where(cond, other): replace where cond is False\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        putmask_without_repeat(vals.T, ~cond, other)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        return [obj_block]\\n\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> s2 = s[:else_pos] + fastpath + s[else_pos:]\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(s2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Patched where() fastpath')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nwhere() def not found; printing nearby excerpt for manual inspection\r\nelement,\r\n    convert_dtypes,\r\n    find_result_type,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    is_1d_only_ea_dtype,\r\n    is_float_dtype,\r\n    is_integer_dtype,\r\n    is_list_like,\r\n    is_scalar,\r\n    is_string_dtype,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    IntervalDtype,\r\n    NumpyEADtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCIndex,\r\n    ABCNumpyExtensionArray,\r\n    ABCSeries,\r\n)\r\nfrom\r\n"]
[930.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[930.002, "i", "git diff -- pandas/core/internals/blocks.py | sed -n '1,220p'\r"]
[930.004, "o", "git diff -- pandas/core/internals/blocks.py | sed -n '1,220p'\r\n"]
[930.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/internals/blocks.py b/pandas/core/internals/blocks.py\r\nindex d1a9081b23..806a9117c3 100644\r\n--- a/pandas/core/internals/blocks.py\r\n+++ b/pandas/core/internals/blocks.py\r\n@@ -1194,6 +1194,12 @@ class Block(PandasObject, libinternals.Block):\r\n                     return [nb]\r\n \r\n             else:\r\n+                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n+                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n+                    obj_block = self.astype(np.dtype(object))\r\n+                    obj_vals = cast(np.ndarray, obj_block.values)\r\n+                    putmask_without_repeat(obj_vals.T, mask, new)\r\n+                    return [obj_block]\r\n                 is_array = isinstance(new, np.ndarray)\r\n \r\n                 res_blocks = []\r\n"]
[935.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[935.002, "i", "cd asv_bench\r"]
[935.004, "o", "cd asv_bench\r\n"]
[935.006, "o", "\u001b[?2004l\r\n"]
[940.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[940.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[940.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[940.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              53.7\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             4.25\u00b10ms\r\n"]
[945.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[945.002, "i", "cd /workspace/repo\r"]
[945.004, "o", "cd /workspace/repo\r\n"]
[945.006, "o", "\u001b[?2004l\r\n"]
[950.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[950.002, "i", "grep -R -n \"def where\" pandas/core/internals | head -n 50\r"]
[950.004, "o", "grep -R -n \"def where\" pandas/core/internals | head -n 50\r\n"]
[950.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1217:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1670:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[955.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[955.002, "i", "grep -R -n \"where\\(\" pandas/core/internals | head -n 50\r"]
[955.004, "o", "grep -R -n \"where\\(\" pandas/core/internals | head -n 50\r\n"]
[955.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[960.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[960.002, "i", "nl -ba pandas/core/internals/blocks.py | sed -n '1080,1260p'\r"]
[960.004, "o", "nl -ba pandas/core/internals/blocks.py | sed -n '1080,1260p'\r\n"]
[960.006, "o", "\u001b[?2004l\r\n  1080\t\r\n  1081\t    def setitem(self, indexer, value) -> Block:\r\n  1082\t        \"\"\"\r\n  1083\t        Attempt self.values[indexer] = value, possibly creating a new array.\r\n  1084\t\r\n  1085\t        Parameters\r\n  1086\t        ----------\r\n  1087\t        indexer : tuple, list-like, array-like, slice, int\r\n  1088\t            The subset of self.values to set\r\n  1089\t        value : object\r\n  1090\t            The value being set\r\n  1091\t\r\n  1092\t        Returns\r\n  1093\t        -------\r\n  1094\t        Block\r\n  1095\t\r\n  1096\t        Notes\r\n  1097\t        -----\r\n  1098\t        `indexer` is a direct slice/positional indexer. `value` must\r\n  1099\t        be a compatible shape.\r\n  1100\t        \"\"\"\r\n  1101\t\r\n  1102\t        value = self._standardize_fill_value(value)\r\n  1103\t\r\n  1104\t        values = cast(np.ndarray, self.values)\r\n  1105\t        if self.ndim == 2:\r\n  1106\t            values = values.T\r\n  1107\t\r\n  1108\t        # length checking\r\n  1109\t        check_setitem_lengths(indexer, value, values)\r\n  1110\t\r\n  1111\t        if self.dtype != _dtype_obj:\r\n  1112\t            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n  1113\t            value = extract_array(value, extract_numpy=True)\r\n  1114\t        try:\r\n  1115\t            casted = np_can_hold_element(values.dtype, value)\r\n  1116\t        except LossySetitemError:\r\n  1117\t            # current dtype cannot store value, coerce to common dtype\r\n  1118\t            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n  1119\t            return nb.setitem(indexer, value)\r\n  1120\t        else:\r\n  1121\t            if self.dtype == _dtype_obj:\r\n  1122\t                # TODO: avoid having to construct values[indexer]\r\n  1123\t                vi = values[indexer]\r\n  1124\t                if lib.is_list_like(vi):\r\n  1125\t                    # checking lib.is_scalar here fails on\r\n  1126\t                    #  test_iloc_setitem_custom_object\r\n  1127\t                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n  1128\t\r\n  1129\t            self = self._maybe_copy(inplace=True)\r\n  1130\t            values = cast(np.ndarray, self.values.T)\r\n  1131\t            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n  1132\t                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n  1133\t                casted = casted[0, ...]\r\n  1134\t            try:\r\n  1135\t                values[indexer] = casted\r\n  1136\t            except (TypeError, ValueError) as err:\r\n  1137\t                if is_list_like(casted):\r\n  1138\t                    raise ValueError(\r\n  1139\t                        \"setting an array element with a sequence.\"\r\n  1140\t                    ) from err\r\n  1141\t                raise\r\n  1142\t        return self\r\n  1143\t\r\n  1144\t    def putmask(self, mask, new) -> list[Block]:\r\n  1145\t        \"\"\"\r\n  1146\t        putmask the data to the block; it is possible that we may create a\r\n  1147\t        new dtype of block\r\n  1148\t\r\n  1149\t        Return the resulting block(s).\r\n  1150\t\r\n  1151\t        Parameters\r\n  1152\t        ----------\r\n  1153\t        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n  1154\t        new : a ndarray/object\r\n  1155\t\r\n  1156\t        Returns\r\n  1157\t        -------\r\n  1158\t        List[Block]\r\n  1159\t        \"\"\"\r\n  1160\t        orig_mask = mask\r\n  1161\t        values = cast(np.ndarray, self.values)\r\n  1162\t        mask, noop = validate_putmask(values.T, mask)\r\n  1163\t        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n  1164\t\r\n  1165\t        if new is lib.no_default:\r\n  1166\t            new = self.fill_value\r\n  1167\t\r\n  1168\t        new = self._standardize_fill_value(new)\r\n  1169\t        new = extract_array(new, extract_numpy=True)\r\n  1170\t\r\n  1171\t        if noop:\r\n  1172\t            return [self.copy(deep=False)]\r\n  1173\t\r\n  1174\t        try:\r\n  1175\t            casted = np_can_hold_element(values.dtype, new)\r\n  1176\t\r\n  1177\t            self = self._maybe_copy(inplace=True)\r\n  1178\t            values = cast(np.ndarray, self.values)\r\n  1179\t\r\n  1180\t            putmask_without_repeat(values.T, mask, casted)\r\n  1181\t            return [self]\r\n  1182\t        except LossySetitemError:\r\n  1183\t            if self.ndim == 1 or self.shape[0] == 1:\r\n  1184\t                # no need to split columns\r\n  1185\t\r\n  1186\t                if not is_list_like(new):\r\n  1187\t                    # using just new[indexer] can't save us the need to cast\r\n  1188\t                    return self.coerce_to_target_dtype(\r\n  1189\t                        new, raise_on_upcast=True\r\n  1190\t                    ).putmask(mask, new)\r\n  1191\t                else:\r\n  1192\t                    indexer = mask.nonzero()[0]\r\n  1193\t                    nb = self.setitem(indexer, new[indexer])\r\n  1194\t                    return [nb]\r\n  1195\t\r\n  1196\t            else:\r\n  1197\t                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n  1198\t                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n  1199\t                    obj_block = self.astype(np.dtype(object))\r\n  1200\t                    obj_vals = cast(np.ndarray, obj_block.values)\r\n  1201\t                    putmask_without_repeat(obj_vals.T, mask, new)\r\n  1202\t                    return [obj_block]\r\n  1203\t                is_array = isinstance(new, np.ndarray)\r\n  1204\t\r\n  1205\t                res_blocks = []\r\n  1206\t                for i, nb in enumerate(self._split()):\r\n  1207\t                    n = new\r\n  1208\t                    if is_array:\r\n  1209\t                        # we have a different value per-column\r\n  1210\t                        n = new[:, i : i + 1]\r\n  1211\t\r\n  1212\t                    submask = orig_mask[:, i : i + 1]\r\n  1213\t                    rbs = nb.putmask(submask, n)\r\n  1214\t                    res_blocks.extend(rbs)\r\n  1215\t                return res_blocks\r\n  1216\t\r\n  1217\t    def where(self, other, cond) -> list[Block]:\r\n  1218\t        \"\"\"\r\n  1219\t        evaluate the block; return result block(s) from the result\r\n  1220\t\r\n  1221\t        Parameters\r\n  1222\t        ----------\r\n  1223\t        other : a ndarray/object\r\n  1224\t        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n  1225\t\r\n  1226\t        Returns\r\n  1227\t        -------\r\n  1228\t        List[Block]\r\n  1229\t        \"\"\"\r\n  1230\t        assert cond.ndim == self.ndim\r\n  1231\t        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\r\n  1232\t\r\n  1233\t        transpose = self.ndim == 2\r\n  1234\t\r\n  1235\t        cond = extract_bool_array(cond)\r\n  1236\t\r\n  1237\t        # EABlocks override where\r\n  1238\t        values = cast(np.ndarray, self.values)\r\n  1239\t        orig_other = other\r\n  1240\t        if transpose:\r\n  1241\t            values = values.T\r\n  1242\t\r\n  1243\t        icond, noop = validate_putmask(values, ~cond)\r\n  1244\t        if noop:\r\n  1245\t            return [self.copy(deep=False)]\r\n  1246\t\r\n  1247\t        if other is lib.no_default:\r\n  1248\t            other = self.fill_value\r\n  1249\t\r\n  1250\t        other = self._standardize_fill_value(other)\r\n  1251\t\r\n  1252\t        try:\r\n  1253\t            # try/except here is equivalent to a self._can_hold_element check,\r\n  1254\t            #  but this gets us back 'casted' which we will reuse below;\r\n  1255\t            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n  1256\t            casted = np_can_hold_element(values.dtype, other)\r\n  1257\t        except (ValueError, TypeError, LossySetitemError):\r\n  1258\t            # we cannot coerce, return a compat dtype\r\n  1259\t\r\n  1260\t            if self.ndim == 1 or self.shape[0] == 1:\r\n"]
[965.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[965.002, "i", "nl -ba pandas/core/internals/blocks.py | sed -n '1260,1500p'\r"]
[965.004, "o", "nl -ba pandas/core/internals/blocks.py | sed -n '1260,1500p'\r\n"]
[965.006, "o", "\u001b[?2004l\r\n  1260\t            if self.ndim == 1 or self.shape[0] == 1:\r\n  1261\t                # no need to split columns\r\n  1262\t\r\n  1263\t                block = self.coerce_to_target_dtype(other, raise_on_upcast=False)\r\n  1264\t                return block.where(orig_other, cond)\r\n  1265\t\r\n  1266\t            else:\r\n  1267\t                is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n  1268\t\r\n  1269\t                res_blocks = []\r\n  1270\t                for i, nb in enumerate(self._split()):\r\n  1271\t                    oth = other\r\n  1272\t                    if is_array:\r\n  1273\t                        # we have a different value per-column\r\n  1274\t                        oth = other[:, i : i + 1]\r\n  1275\t\r\n  1276\t                    submask = cond[:, i : i + 1]\r\n  1277\t                    rbs = nb.where(oth, submask)\r\n  1278\t                    res_blocks.extend(rbs)\r\n  1279\t                return res_blocks\r\n  1280\t\r\n  1281\t        else:\r\n  1282\t            other = casted\r\n  1283\t            alt = setitem_datetimelike_compat(values, icond.sum(), other)\r\n  1284\t            if alt is not other:\r\n  1285\t                if is_list_like(other) and len(other) < len(values):\r\n  1286\t                    # call np.where with other to get the appropriate ValueError\r\n  1287\t                    np.where(~icond, values, other)\r\n  1288\t                    raise NotImplementedError(\r\n  1289\t                        \"This should not be reached; call to np.where above is \"\r\n  1290\t                        \"expected to raise ValueError. Please report a bug at \"\r\n  1291\t                        \"github.com/pandas-dev/pandas\"\r\n  1292\t                    )\r\n  1293\t                result = values.copy()\r\n  1294\t                np.putmask(result, icond, alt)\r\n  1295\t            else:\r\n  1296\t                # By the time we get here, we should have all Series/Index\r\n  1297\t                #  args extracted to ndarray\r\n  1298\t                if (\r\n  1299\t                    is_list_like(other)\r\n  1300\t                    and not isinstance(other, np.ndarray)\r\n  1301\t                    and len(other) == self.shape[-1]\r\n  1302\t                ):\r\n  1303\t                    # If we don't do this broadcasting here, then expressions.where\r\n  1304\t                    #  will broadcast a 1D other to be row-like instead of\r\n  1305\t                    #  column-like.\r\n  1306\t                    other = np.array(other).reshape(values.shape)\r\n  1307\t                    # If lengths don't match (or len(other)==1), we will raise\r\n  1308\t                    #  inside expressions.where, see test_series_where\r\n  1309\t\r\n  1310\t                # Note: expressions.where may upcast.\r\n  1311\t                result = expressions.where(~icond, values, other)\r\n  1312\t                # The np_can_hold_element check _should_ ensure that we always\r\n  1313\t                #  have result.dtype == self.dtype here.\r\n  1314\t\r\n  1315\t        if transpose:\r\n  1316\t            result = result.T\r\n  1317\t\r\n  1318\t        return [self.make_block(result)]\r\n  1319\t\r\n  1320\t    def fillna(\r\n  1321\t        self,\r\n  1322\t        value,\r\n  1323\t        limit: int | None = None,\r\n  1324\t        inplace: bool = False,\r\n  1325\t    ) -> list[Block]:\r\n  1326\t        \"\"\"\r\n  1327\t        fillna on the block with the value. If we fail, then convert to\r\n  1328\t        block to hold objects instead and try again\r\n  1329\t        \"\"\"\r\n  1330\t        # Caller is responsible for validating limit; if int it is strictly positive\r\n  1331\t        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n  1332\t\r\n  1333\t        if not self._can_hold_na:\r\n  1334\t            # can short-circuit the isna call\r\n  1335\t            noop = True\r\n  1336\t        else:\r\n  1337\t            mask = isna(self.values)\r\n  1338\t            mask, noop = validate_putmask(self.values, mask)\r\n  1339\t\r\n  1340\t        if noop:\r\n  1341\t            # we can't process the value, but nothing to do\r\n  1342\t            return [self.copy(deep=False)]\r\n  1343\t\r\n  1344\t        if limit is not None:\r\n  1345\t            mask[mask.cumsum(self.values.ndim - 1) > limit] = False\r\n  1346\t\r\n  1347\t        if inplace:\r\n  1348\t            nbs = self.putmask(mask.T, value)\r\n  1349\t        else:\r\n  1350\t            nbs = self.where(value, ~mask.T)\r\n  1351\t        return extend_blocks(nbs)\r\n  1352\t\r\n  1353\t    def pad_or_backfill(\r\n  1354\t        self,\r\n  1355\t        *,\r\n  1356\t        method: FillnaOptions,\r\n  1357\t        inplace: bool = False,\r\n  1358\t        limit: int | None = None,\r\n  1359\t        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n  1360\t    ) -> list[Block]:\r\n  1361\t        if not self._can_hold_na:\r\n  1362\t            # If there are no NAs, then interpolate is a no-op\r\n  1363\t            return [self.copy(deep=False)]\r\n  1364\t\r\n  1365\t        copy, refs = self._get_refs_and_copy(inplace)\r\n  1366\t\r\n  1367\t        # Dispatch to the NumpyExtensionArray method.\r\n  1368\t        # We know self.array_values is a NumpyExtensionArray bc EABlock overrides\r\n  1369\t        vals = cast(NumpyExtensionArray, self.array_values)\r\n  1370\t        new_values = vals.T._pad_or_backfill(\r\n  1371\t            method=method,\r\n  1372\t            limit=limit,\r\n  1373\t            limit_area=limit_area,\r\n  1374\t            copy=copy,\r\n  1375\t        ).T\r\n  1376\t\r\n  1377\t        data = extract_array(new_values, extract_numpy=True)\r\n  1378\t        return [self.make_block_same_class(data, refs=refs)]\r\n  1379\t\r\n  1380\t    @final\r\n  1381\t    def interpolate(\r\n  1382\t        self,\r\n  1383\t        *,\r\n  1384\t        method: InterpolateOptions,\r\n  1385\t        index: Index,\r\n  1386\t        inplace: bool = False,\r\n  1387\t        limit: int | None = None,\r\n  1388\t        limit_direction: Literal[\"forward\", \"backward\", \"both\"] = \"forward\",\r\n  1389\t        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n  1390\t        **kwargs,\r\n  1391\t    ) -> list[Block]:\r\n  1392\t        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n  1393\t        # error: Non-overlapping equality check [...]\r\n  1394\t        if method == \"asfreq\":  # type: ignore[comparison-overlap]\r\n  1395\t            # clean_fill_method used to allow this\r\n  1396\t            missing.clean_fill_method(method)\r\n  1397\t\r\n  1398\t        if not self._can_hold_na:\r\n  1399\t            # If there are no NAs, then interpolate is a no-op\r\n  1400\t            return [self.copy(deep=False)]\r\n  1401\t\r\n  1402\t        if self.dtype == _dtype_obj:\r\n  1403\t            # GH#53631\r\n  1404\t            name = {1: \"Series\", 2: \"DataFrame\"}[self.ndim]\r\n  1405\t            raise TypeError(f\"{name} cannot interpolate with object dtype.\")\r\n  1406\t\r\n  1407\t        copy, refs = self._get_refs_and_copy(inplace)\r\n  1408\t\r\n  1409\t        # Dispatch to the EA method.\r\n  1410\t        new_values = self.array_values.interpolate(\r\n  1411\t            method=method,\r\n  1412\t            axis=self.ndim - 1,\r\n  1413\t            index=index,\r\n  1414\t            limit=limit,\r\n  1415\t            limit_direction=limit_direction,\r\n  1416\t            limit_area=limit_area,\r\n  1417\t            copy=copy,\r\n  1418\t            **kwargs,\r\n  1419\t        )\r\n  1420\t        data = extract_array(new_values, extract_numpy=True)\r\n  1421\t        return [self.make_block_same_class(data, refs=refs)]\r\n  1422\t\r\n  1423\t    @final\r\n  1424\t    def diff(self, n: int) -> list[Block]:\r\n  1425\t        \"\"\"return block for the diff of the values\"\"\"\r\n  1426\t        # only reached with ndim == 2\r\n  1427\t        # TODO(EA2D): transpose will be unnecessary with 2D EAs\r\n  1428\t        new_values = algos.diff(self.values.T, n, axis=0).T\r\n  1429\t        return [self.make_block(values=new_values)]\r\n  1430\t\r\n  1431\t    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:\r\n  1432\t        \"\"\"shift the block by periods, possibly upcast\"\"\"\r\n  1433\t        # convert integer to float if necessary. need to do a lot more than\r\n  1434\t        # that, handle boolean etc also\r\n  1435\t        axis = self.ndim - 1\r\n  1436\t\r\n  1437\t        # Note: periods is never 0 here, as that is handled at the top of\r\n  1438\t        #  NDFrame.shift.  If that ever changes, we can do a check for periods=0\r\n  1439\t        #  and possibly avoid coercing.\r\n  1440\t\r\n  1441\t        if not lib.is_scalar(fill_value) and self.dtype != _dtype_obj:\r\n  1442\t            # with object dtype there is nothing to promote, and the user can\r\n  1443\t            #  pass pretty much any weird fill_value they like\r\n  1444\t            # see test_shift_object_non_scalar_fill\r\n  1445\t            raise ValueError(\"fill_value must be a scalar\")\r\n  1446\t\r\n  1447\t        fill_value = self._standardize_fill_value(fill_value)\r\n  1448\t\r\n  1449\t        try:\r\n  1450\t            # error: Argument 1 to \"np_can_hold_element\" has incompatible type\r\n  1451\t            # \"Union[dtype[Any], ExtensionDtype]\"; expected \"dtype[Any]\"\r\n  1452\t            casted = np_can_hold_element(\r\n  1453\t                self.dtype,  # type: ignore[arg-type]\r\n  1454\t                fill_value,\r\n  1455\t            )\r\n  1456\t        except LossySetitemError:\r\n  1457\t            nb = self.coerce_to_target_dtype(fill_value, raise_on_upcast=False)\r\n  1458\t            return nb.shift(periods, fill_value=fill_value)\r\n  1459\t\r\n  1460\t        else:\r\n  1461\t            values = cast(np.ndarray, self.values)\r\n  1462\t            new_values = shift(values, periods, axis, casted)\r\n  1463\t            return [self.make_block_same_class(new_values)]\r\n  1464\t\r\n  1465\t    @final\r\n  1466\t    def quantile(\r\n  1467\t        self,\r\n  1468\t        qs: Index,  # with dtype float64\r\n  1469\t        interpolation: QuantileInterpolation = \"linear\",\r\n  1470\t    ) -> Block:\r\n  1471\t        \"\"\"\r\n  1472\t        compute the quantiles of the\r\n  1473\t\r\n  1474\t        Parameters\r\n  1475\t        ----------\r\n  1476\t        qs : Index\r\n  1477\t            The quantiles to be computed in float64.\r\n  1478\t        interpolation : str, default 'linear'\r\n  1479\t            Type of interpolation.\r\n  1480\t\r\n  1481\t        Returns\r\n  1482\t        -------\r\n  1483\t        Block\r\n  1484\t        \"\"\"\r\n  1485\t        # We should always have ndim == 2 because Series dispatches to DataFrame\r\n  1486\t        assert self.ndim == 2\r\n  1487\t        assert is_list_like(qs)  # caller is responsible for this\r\n  1488\t\r\n  1489\t        result = quantile_compat(self.values, np.asarray(qs._values), interpolation)\r\n  1490\t        # ensure_block_shape needed for cases where we start with EA and result\r\n  1491\t        #  is ndarray, e.g. IntegerArray, SparseArray\r\n  1492\t        result = ensure_block_shape(result, ndim=2)\r\n  1493\t        return new_block_2d(result, placement=self._mgr_locs)\r\n  1494\t\r\n  1495\t    @final\r\n  1496\t    def round(self, decimals: int) -> Self:\r\n  1497\t        \"\"\"\r\n  1498\t        Rounds the values.\r\n  1499\t        If the block is not of an integer or float dtype, nothing happens.\r\n  1500\t        This is consistent with DataFrame.round behavior.\r\n"]
[970.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[970.002, "i", "python - << 'PY'\r"]
[970.004, "o", "python - << 'PY'\r\n"]
[970.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/internals/blocks.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Try to inject a fastpath into what appears to be the first LossySetitemError branch (~line 1116)\r\n\u001b[?2004l\r\n\u001b[?2004h> # We'll search for the specific except LossySetitemError block and add a fastpath in its 2D else-branch.\r\n\u001b[?2004l\r\n\u001b[?2004h> exc_iter = list(re.finditer(r\"except\\s+LossySetitemError:\\n(\\s*)if\\s+self\\\\.ndim\\s*==\\s*1\\s*or\\s*self\\\\.shape\\\\[0\\\\]\\s*==\\s*1:\\n\", s))\r\n\u001b[?2004l\r\n\u001b[?2004h> if not exc_iter:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('Could not find LossySetitemError branches')\r\n\u001b[?2004l\r\n\u001b[?2004h> # Try patching the first occurrence (likely for where())\r\n\u001b[?2004l\r\n\u001b[?2004h> m = exc_iter[0]\r\n\u001b[?2004l\r\n\u001b[?2004h> indent = m.group(1)\r\n\u001b[?2004l\r\n\u001b[?2004h> start = m.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> else_match = re.search(rf\"^{indent}else:\\n\", s[start:], flags=re.M)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not else_match:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('else: branch after LossySetitemError if not found')\r\n\u001b[?2004l\r\n\u001b[?2004h> else_pos = start + else_match.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> fastpath = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    # Fastpath: for 2D blocks where dtype cannot hold 'other' (e.g., bool -> NaN),\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    # upcast once and apply assignment vectorized instead of splitting columns.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}    if 'other' in locals() and (not is_list_like(other) or (isinstance(other, np.ndarray) and other.ndim == 0)):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        obj_block = self.astype(np.dtype(object))\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        vals = obj_block.values\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        # where(cond, other): replace where cond is False\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        putmask_without_repeat(vals.T, ~cond, other)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     f\"{indent}        return [obj_block]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> s2 = s[:else_pos] + fastpath + s[else_pos:]\r\n\u001b[?2004l\r\n\u001b[?2004h> Path('pandas/core/internals/blocks.py').write_text(s2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Injected fastpath into first LossySetitemError 2D branch')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nCould not find LossySetitemError branches\r\n"]
[975.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[975.002, "i", "git diff -- pandas/core/internals/blocks.py | sed -n '1,240p'\r"]
[975.004, "o", "git diff -- pandas/core/internals/blocks.py | sed -n '1,240p'\r\n"]
[975.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/internals/blocks.py b/pandas/core/internals/blocks.py\r\nindex d1a9081b23..806a9117c3 100644\r\n--- a/pandas/core/internals/blocks.py\r\n+++ b/pandas/core/internals/blocks.py\r\n@@ -1194,6 +1194,12 @@ class Block(PandasObject, libinternals.Block):\r\n                     return [nb]\r\n \r\n             else:\r\n+                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n+                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n+                    obj_block = self.astype(np.dtype(object))\r\n+                    obj_vals = cast(np.ndarray, obj_block.values)\r\n+                    putmask_without_repeat(obj_vals.T, mask, new)\r\n+                    return [obj_block]\r\n                 is_array = isinstance(new, np.ndarray)\r\n \r\n                 res_blocks = []\r\n"]
[980.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[980.002, "i", "cd asv_bench\r"]
[980.004, "o", "cd asv_bench\r\n"]
[980.006, "o", "\u001b[?2004l\r\n"]
[985.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[985.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[985.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[985.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              53.3\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             4.04\u00b10ms\r\n"]
[990.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[990.002, "i", "cd /workspace/repo\r"]
[990.004, "o", "cd /workspace/repo\r\n"]
[990.006, "o", "\u001b[?2004l\r\n"]
[995.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[995.002, "i", "grep -R -n 'def where' pandas/core | head -n 50\r"]
[995.004, "o", "grep -R -n 'def where' pandas/core | head -n 50\r\n"]
[995.006, "o", "\u001b[?2004l\r\npandas/core/computation/expressions.py:247:def where(cond, left_op, right_op, use_numexpr: bool = True):\r\npandas/core/generic.py:9831:    def where(\r\npandas/core/generic.py:9842:    def where(\r\npandas/core/generic.py:9853:    def where(\r\npandas/core/generic.py:9871:    def where(\r\npandas/core/indexes/base.py:5069:    def where(self, cond, other=None) -> Index:\r\npandas/core/internals/blocks.py:1217:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1670:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[1000.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1000.002, "i", "grep -R -n 'def where' pandas/core/internals | head -n 50\r"]
[1000.004, "o", "grep -R -n 'def where' pandas/core/internals | head -n 50\r\n"]
[1000.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1217:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1670:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[1005.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1005.002, "i", "grep -n 'where' pandas/core/internals/blocks.py | sed -n '1,120p'\r"]
[1005.004, "o", "grep -n 'where' pandas/core/internals/blocks.py | sed -n '1,120p'\r\n"]
[1005.006, "o", "\u001b[?2004l\r\n711:            # TODO(CoW): Maybe split here as well into columns where mask has True\r\n730:            # split so that we only upcast where necessary\r\n848:            # where to index into the mask\r\n962:        # In the case where we have a tuple[slice, int], the slice will always\r\n986:        `set_inplace` never creates a new array or new Block, whereas `setitem`\r\n1217:    def where(self, other, cond) -> list[Block]:\r\n1237:        # EABlocks override where\r\n1255:            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n1264:                return block.where(orig_other, cond)\r\n1277:                    rbs = nb.where(oth, submask)\r\n1286:                    # call np.where with other to get the appropriate ValueError\r\n1287:                    np.where(~icond, values, other)\r\n1289:                        \"This should not be reached; call to np.where above is \"\r\n1303:                    # If we don't do this broadcasting here, then expressions.where\r\n1308:                    #  inside expressions.where, see test_series_where\r\n1310:                # Note: expressions.where may upcast.\r\n1311:                result = expressions.where(~icond, values, other)\r\n1350:            nbs = self.where(value, ~mask.T)\r\n1490:        # ensure_block_shape needed for cases where we start with EA and result\r\n1670:    def where(self, other, cond) -> list[Block]:\r\n1690:            res_values = arr._where(cond, other).T\r\n1703:                    return blk.where(orig_other, orig_cond)\r\n1709:                    return blk.where(orig_other, orig_cond)\r\n1726:                    rbs = nb.where(n, submask)\r\n1914:        # In the case where we have a tuple[slice, int], the slice will always\r\n"]
[1010.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1010.002, "i", "nl -ba pandas/core/internals/blocks.py | sed -n '1080,1260p'\r"]
[1010.004, "o", "nl -ba pandas/core/internals/blocks.py | sed -n '1080,1260p'\r\n"]
[1010.006, "o", "\u001b[?2004l\r\n  1080\t\r\n  1081\t    def setitem(self, indexer, value) -> Block:\r\n  1082\t        \"\"\"\r\n  1083\t        Attempt self.values[indexer] = value, possibly creating a new array.\r\n  1084\t\r\n  1085\t        Parameters\r\n  1086\t        ----------\r\n  1087\t        indexer : tuple, list-like, array-like, slice, int\r\n  1088\t            The subset of self.values to set\r\n  1089\t        value : object\r\n  1090\t            The value being set\r\n  1091\t\r\n  1092\t        Returns\r\n  1093\t        -------\r\n  1094\t        Block\r\n  1095\t\r\n  1096\t        Notes\r\n  1097\t        -----\r\n  1098\t        `indexer` is a direct slice/positional indexer. `value` must\r\n  1099\t        be a compatible shape.\r\n  1100\t        \"\"\"\r\n  1101\t\r\n  1102\t        value = self._standardize_fill_value(value)\r\n  1103\t\r\n  1104\t        values = cast(np.ndarray, self.values)\r\n  1105\t        if self.ndim == 2:\r\n  1106\t            values = values.T\r\n  1107\t\r\n  1108\t        # length checking\r\n  1109\t        check_setitem_lengths(indexer, value, values)\r\n  1110\t\r\n  1111\t        if self.dtype != _dtype_obj:\r\n  1112\t            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n  1113\t            value = extract_array(value, extract_numpy=True)\r\n  1114\t        try:\r\n  1115\t            casted = np_can_hold_element(values.dtype, value)\r\n  1116\t        except LossySetitemError:\r\n  1117\t            # current dtype cannot store value, coerce to common dtype\r\n  1118\t            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n  1119\t            return nb.setitem(indexer, value)\r\n  1120\t        else:\r\n  1121\t            if self.dtype == _dtype_obj:\r\n  1122\t                # TODO: avoid having to construct values[indexer]\r\n  1123\t                vi = values[indexer]\r\n  1124\t                if lib.is_list_like(vi):\r\n  1125\t                    # checking lib.is_scalar here fails on\r\n  1126\t                    #  test_iloc_setitem_custom_object\r\n  1127\t                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n  1128\t\r\n  1129\t            self = self._maybe_copy(inplace=True)\r\n  1130\t            values = cast(np.ndarray, self.values.T)\r\n  1131\t            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n  1132\t                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n  1133\t                casted = casted[0, ...]\r\n  1134\t            try:\r\n  1135\t                values[indexer] = casted\r\n  1136\t            except (TypeError, ValueError) as err:\r\n  1137\t                if is_list_like(casted):\r\n  1138\t                    raise ValueError(\r\n  1139\t                        \"setting an array element with a sequence.\"\r\n  1140\t                    ) from err\r\n  1141\t                raise\r\n  1142\t        return self\r\n  1143\t\r\n  1144\t    def putmask(self, mask, new) -> list[Block]:\r\n  1145\t        \"\"\"\r\n  1146\t        putmask the data to the block; it is possible that we may create a\r\n  1147\t        new dtype of block\r\n  1148\t\r\n  1149\t        Return the resulting block(s).\r\n  1150\t\r\n  1151\t        Parameters\r\n  1152\t        ----------\r\n  1153\t        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n  1154\t        new : a ndarray/object\r\n  1155\t\r\n  1156\t        Returns\r\n  1157\t        -------\r\n  1158\t        List[Block]\r\n  1159\t        \"\"\"\r\n  1160\t        orig_mask = mask\r\n  1161\t        values = cast(np.ndarray, self.values)\r\n  1162\t        mask, noop = validate_putmask(values.T, mask)\r\n  1163\t        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n  1164\t\r\n  1165\t        if new is lib.no_default:\r\n  1166\t            new = self.fill_value\r\n  1167\t\r\n  1168\t        new = self._standardize_fill_value(new)\r\n  1169\t        new = extract_array(new, extract_numpy=True)\r\n  1170\t\r\n  1171\t        if noop:\r\n  1172\t            return [self.copy(deep=False)]\r\n  1173\t\r\n  1174\t        try:\r\n  1175\t            casted = np_can_hold_element(values.dtype, new)\r\n  1176\t\r\n  1177\t            self = self._maybe_copy(inplace=True)\r\n  1178\t            values = cast(np.ndarray, self.values)\r\n  1179\t\r\n  1180\t            putmask_without_repeat(values.T, mask, casted)\r\n  1181\t            return [self]\r\n  1182\t        except LossySetitemError:\r\n  1183\t            if self.ndim == 1 or self.shape[0] == 1:\r\n  1184\t                # no need to split columns\r\n  1185\t\r\n  1186\t                if not is_list_like(new):\r\n  1187\t                    # using just new[indexer] can't save us the need to cast\r\n  1188\t                    return self.coerce_to_target_dtype(\r\n  1189\t                        new, raise_on_upcast=True\r\n  1190\t                    ).putmask(mask, new)\r\n  1191\t                else:\r\n  1192\t                    indexer = mask.nonzero()[0]\r\n  1193\t                    nb = self.setitem(indexer, new[indexer])\r\n  1194\t                    return [nb]\r\n  1195\t\r\n  1196\t            else:\r\n  1197\t                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n  1198\t                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n  1199\t                    obj_block = self.astype(np.dtype(object))\r\n  1200\t                    obj_vals = cast(np.ndarray, obj_block.values)\r\n  1201\t                    putmask_without_repeat(obj_vals.T, mask, new)\r\n  1202\t                    return [obj_block]\r\n  1203\t                is_array = isinstance(new, np.ndarray)\r\n  1204\t\r\n  1205\t                res_blocks = []\r\n  1206\t                for i, nb in enumerate(self._split()):\r\n  1207\t                    n = new\r\n  1208\t                    if is_array:\r\n  1209\t                        # we have a different value per-column\r\n  1210\t                        n = new[:, i : i + 1]\r\n  1211\t\r\n  1212\t                    submask = orig_mask[:, i : i + 1]\r\n  1213\t                    rbs = nb.putmask(submask, n)\r\n  1214\t                    res_blocks.extend(rbs)\r\n  1215\t                return res_blocks\r\n  1216\t\r\n  1217\t    def where(self, other, cond) -> list[Block]:\r\n  1218\t        \"\"\"\r\n  1219\t        evaluate the block; return result block(s) from the result\r\n  1220\t\r\n  1221\t        Parameters\r\n  1222\t        ----------\r\n  1223\t        other : a ndarray/object\r\n  1224\t        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n  1225\t\r\n  1226\t        Returns\r\n  1227\t        -------\r\n  1228\t        List[Block]\r\n  1229\t        \"\"\"\r\n  1230\t        assert cond.ndim == self.ndim\r\n  1231\t        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\r\n  1232\t\r\n  1233\t        transpose = self.ndim == 2\r\n  1234\t\r\n  1235\t        cond = extract_bool_array(cond)\r\n  1236\t\r\n  1237\t        # EABlocks override where\r\n  1238\t        values = cast(np.ndarray, self.values)\r\n  1239\t        orig_other = other\r\n  1240\t        if transpose:\r\n  1241\t            values = values.T\r\n  1242\t\r\n  1243\t        icond, noop = validate_putmask(values, ~cond)\r\n  1244\t        if noop:\r\n  1245\t            return [self.copy(deep=False)]\r\n  1246\t\r\n  1247\t        if other is lib.no_default:\r\n  1248\t            other = self.fill_value\r\n  1249\t\r\n  1250\t        other = self._standardize_fill_value(other)\r\n  1251\t\r\n  1252\t        try:\r\n  1253\t            # try/except here is equivalent to a self._can_hold_element check,\r\n  1254\t            #  but this gets us back 'casted' which we will reuse below;\r\n  1255\t            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n  1256\t            casted = np_can_hold_element(values.dtype, other)\r\n  1257\t        except (ValueError, TypeError, LossySetitemError):\r\n  1258\t            # we cannot coerce, return a compat dtype\r\n  1259\t\r\n  1260\t            if self.ndim == 1 or self.shape[0] == 1:\r\n"]
[1015.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1015.002, "i", "nl -ba pandas/core/internals/blocks.py | sed -n '1260,1500p'\r"]
[1015.004, "o", "nl -ba pandas/core/internals/blocks.py | sed -n '1260,1500p'\r\n"]
[1015.006, "o", "\u001b[?2004l\r\n  1260\t            if self.ndim == 1 or self.shape[0] == 1:\r\n  1261\t                # no need to split columns\r\n  1262\t\r\n  1263\t                block = self.coerce_to_target_dtype(other, raise_on_upcast=False)\r\n  1264\t                return block.where(orig_other, cond)\r\n  1265\t\r\n  1266\t            else:\r\n  1267\t                is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n  1268\t\r\n  1269\t                res_blocks = []\r\n  1270\t                for i, nb in enumerate(self._split()):\r\n  1271\t                    oth = other\r\n  1272\t                    if is_array:\r\n  1273\t                        # we have a different value per-column\r\n  1274\t                        oth = other[:, i : i + 1]\r\n  1275\t\r\n  1276\t                    submask = cond[:, i : i + 1]\r\n  1277\t                    rbs = nb.where(oth, submask)\r\n  1278\t                    res_blocks.extend(rbs)\r\n  1279\t                return res_blocks\r\n  1280\t\r\n  1281\t        else:\r\n  1282\t            other = casted\r\n  1283\t            alt = setitem_datetimelike_compat(values, icond.sum(), other)\r\n  1284\t            if alt is not other:\r\n  1285\t                if is_list_like(other) and len(other) < len(values):\r\n  1286\t                    # call np.where with other to get the appropriate ValueError\r\n  1287\t                    np.where(~icond, values, other)\r\n  1288\t                    raise NotImplementedError(\r\n  1289\t                        \"This should not be reached; call to np.where above is \"\r\n  1290\t                        \"expected to raise ValueError. Please report a bug at \"\r\n  1291\t                        \"github.com/pandas-dev/pandas\"\r\n  1292\t                    )\r\n  1293\t                result = values.copy()\r\n  1294\t                np.putmask(result, icond, alt)\r\n  1295\t            else:\r\n  1296\t                # By the time we get here, we should have all Series/Index\r\n  1297\t                #  args extracted to ndarray\r\n  1298\t                if (\r\n  1299\t                    is_list_like(other)\r\n  1300\t                    and not isinstance(other, np.ndarray)\r\n  1301\t                    and len(other) == self.shape[-1]\r\n  1302\t                ):\r\n  1303\t                    # If we don't do this broadcasting here, then expressions.where\r\n  1304\t                    #  will broadcast a 1D other to be row-like instead of\r\n  1305\t                    #  column-like.\r\n  1306\t                    other = np.array(other).reshape(values.shape)\r\n  1307\t                    # If lengths don't match (or len(other)==1), we will raise\r\n  1308\t                    #  inside expressions.where, see test_series_where\r\n  1309\t\r\n  1310\t                # Note: expressions.where may upcast.\r\n  1311\t                result = expressions.where(~icond, values, other)\r\n  1312\t                # The np_can_hold_element check _should_ ensure that we always\r\n  1313\t                #  have result.dtype == self.dtype here.\r\n  1314\t\r\n  1315\t        if transpose:\r\n  1316\t            result = result.T\r\n  1317\t\r\n  1318\t        return [self.make_block(result)]\r\n  1319\t\r\n  1320\t    def fillna(\r\n  1321\t        self,\r\n  1322\t        value,\r\n  1323\t        limit: int | None = None,\r\n  1324\t        inplace: bool = False,\r\n  1325\t    ) -> list[Block]:\r\n  1326\t        \"\"\"\r\n  1327\t        fillna on the block with the value. If we fail, then convert to\r\n  1328\t        block to hold objects instead and try again\r\n  1329\t        \"\"\"\r\n  1330\t        # Caller is responsible for validating limit; if int it is strictly positive\r\n  1331\t        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n  1332\t\r\n  1333\t        if not self._can_hold_na:\r\n  1334\t            # can short-circuit the isna call\r\n  1335\t            noop = True\r\n  1336\t        else:\r\n  1337\t            mask = isna(self.values)\r\n  1338\t            mask, noop = validate_putmask(self.values, mask)\r\n  1339\t\r\n  1340\t        if noop:\r\n  1341\t            # we can't process the value, but nothing to do\r\n  1342\t            return [self.copy(deep=False)]\r\n  1343\t\r\n  1344\t        if limit is not None:\r\n  1345\t            mask[mask.cumsum(self.values.ndim - 1) > limit] = False\r\n  1346\t\r\n  1347\t        if inplace:\r\n  1348\t            nbs = self.putmask(mask.T, value)\r\n  1349\t        else:\r\n  1350\t            nbs = self.where(value, ~mask.T)\r\n  1351\t        return extend_blocks(nbs)\r\n  1352\t\r\n  1353\t    def pad_or_backfill(\r\n  1354\t        self,\r\n  1355\t        *,\r\n  1356\t        method: FillnaOptions,\r\n  1357\t        inplace: bool = False,\r\n  1358\t        limit: int | None = None,\r\n  1359\t        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n  1360\t    ) -> list[Block]:\r\n  1361\t        if not self._can_hold_na:\r\n  1362\t            # If there are no NAs, then interpolate is a no-op\r\n  1363\t            return [self.copy(deep=False)]\r\n  1364\t\r\n  1365\t        copy, refs = self._get_refs_and_copy(inplace)\r\n  1366\t\r\n  1367\t        # Dispatch to the NumpyExtensionArray method.\r\n  1368\t        # We know self.array_values is a NumpyExtensionArray bc EABlock overrides\r\n  1369\t        vals = cast(NumpyExtensionArray, self.array_values)\r\n  1370\t        new_values = vals.T._pad_or_backfill(\r\n  1371\t            method=method,\r\n  1372\t            limit=limit,\r\n  1373\t            limit_area=limit_area,\r\n  1374\t            copy=copy,\r\n  1375\t        ).T\r\n  1376\t\r\n  1377\t        data = extract_array(new_values, extract_numpy=True)\r\n  1378\t        return [self.make_block_same_class(data, refs=refs)]\r\n  1379\t\r\n  1380\t    @final\r\n  1381\t    def interpolate(\r\n  1382\t        self,\r\n  1383\t        *,\r\n  1384\t        method: InterpolateOptions,\r\n  1385\t        index: Index,\r\n  1386\t        inplace: bool = False,\r\n  1387\t        limit: int | None = None,\r\n  1388\t        limit_direction: Literal[\"forward\", \"backward\", \"both\"] = \"forward\",\r\n  1389\t        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n  1390\t        **kwargs,\r\n  1391\t    ) -> list[Block]:\r\n  1392\t        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n  1393\t        # error: Non-overlapping equality check [...]\r\n  1394\t        if method == \"asfreq\":  # type: ignore[comparison-overlap]\r\n  1395\t            # clean_fill_method used to allow this\r\n  1396\t            missing.clean_fill_method(method)\r\n  1397\t\r\n  1398\t        if not self._can_hold_na:\r\n  1399\t            # If there are no NAs, then interpolate is a no-op\r\n  1400\t            return [self.copy(deep=False)]\r\n  1401\t\r\n  1402\t        if self.dtype == _dtype_obj:\r\n  1403\t            # GH#53631\r\n  1404\t            name = {1: \"Series\", 2: \"DataFrame\"}[self.ndim]\r\n  1405\t            raise TypeError(f\"{name} cannot interpolate with object dtype.\")\r\n  1406\t\r\n  1407\t        copy, refs = self._get_refs_and_copy(inplace)\r\n  1408\t\r\n  1409\t        # Dispatch to the EA method.\r\n  1410\t        new_values = self.array_values.interpolate(\r\n  1411\t            method=method,\r\n  1412\t            axis=self.ndim - 1,\r\n  1413\t            index=index,\r\n  1414\t            limit=limit,\r\n  1415\t            limit_direction=limit_direction,\r\n  1416\t            limit_area=limit_area,\r\n  1417\t            copy=copy,\r\n  1418\t            **kwargs,\r\n  1419\t        )\r\n  1420\t        data = extract_array(new_values, extract_numpy=True)\r\n  1421\t        return [self.make_block_same_class(data, refs=refs)]\r\n  1422\t\r\n  1423\t    @final\r\n  1424\t    def diff(self, n: int) -> list[Block]:\r\n  1425\t        \"\"\"return block for the diff of the values\"\"\"\r\n  1426\t        # only reached with ndim == 2\r\n  1427\t        # TODO(EA2D): transpose will be unnecessary with 2D EAs\r\n  1428\t        new_values = algos.diff(self.values.T, n, axis=0).T\r\n  1429\t        return [self.make_block(values=new_values)]\r\n  1430\t\r\n  1431\t    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:\r\n  1432\t        \"\"\"shift the block by periods, possibly upcast\"\"\"\r\n  1433\t        # convert integer to float if necessary. need to do a lot more than\r\n  1434\t        # that, handle boolean etc also\r\n  1435\t        axis = self.ndim - 1\r\n  1436\t\r\n  1437\t        # Note: periods is never 0 here, as that is handled at the top of\r\n  1438\t        #  NDFrame.shift.  If that ever changes, we can do a check for periods=0\r\n  1439\t        #  and possibly avoid coercing.\r\n  1440\t\r\n  1441\t        if not lib.is_scalar(fill_value) and self.dtype != _dtype_obj:\r\n  1442\t            # with object dtype there is nothing to promote, and the user can\r\n  1443\t            #  pass pretty much any weird fill_value they like\r\n  1444\t            # see test_shift_object_non_scalar_fill\r\n  1445\t            raise ValueError(\"fill_value must be a scalar\")\r\n  1446\t\r\n  1447\t        fill_value = self._standardize_fill_value(fill_value)\r\n  1448\t\r\n  1449\t        try:\r\n  1450\t            # error: Argument 1 to \"np_can_hold_element\" has incompatible type\r\n  1451\t            # \"Union[dtype[Any], ExtensionDtype]\"; expected \"dtype[Any]\"\r\n  1452\t            casted = np_can_hold_element(\r\n  1453\t                self.dtype,  # type: ignore[arg-type]\r\n  1454\t                fill_value,\r\n  1455\t            )\r\n  1456\t        except LossySetitemError:\r\n  1457\t            nb = self.coerce_to_target_dtype(fill_value, raise_on_upcast=False)\r\n  1458\t            return nb.shift(periods, fill_value=fill_value)\r\n  1459\t\r\n  1460\t        else:\r\n  1461\t            values = cast(np.ndarray, self.values)\r\n  1462\t            new_values = shift(values, periods, axis, casted)\r\n  1463\t            return [self.make_block_same_class(new_values)]\r\n  1464\t\r\n  1465\t    @final\r\n  1466\t    def quantile(\r\n  1467\t        self,\r\n  1468\t        qs: Index,  # with dtype float64\r\n  1469\t        interpolation: QuantileInterpolation = \"linear\",\r\n  1470\t    ) -> Block:\r\n  1471\t        \"\"\"\r\n  1472\t        compute the quantiles of the\r\n  1473\t\r\n  1474\t        Parameters\r\n  1475\t        ----------\r\n  1476\t        qs : Index\r\n  1477\t            The quantiles to be computed in float64.\r\n  1478\t        interpolation : str, default 'linear'\r\n  1479\t            Type of interpolation.\r\n  1480\t\r\n  1481\t        Returns\r\n  1482\t        -------\r\n  1483\t        Block\r\n  1484\t        \"\"\"\r\n  1485\t        # We should always have ndim == 2 because Series dispatches to DataFrame\r\n  1486\t        assert self.ndim == 2\r\n  1487\t        assert is_list_like(qs)  # caller is responsible for this\r\n  1488\t\r\n  1489\t        result = quantile_compat(self.values, np.asarray(qs._values), interpolation)\r\n  1490\t        # ensure_block_shape needed for cases where we start with EA and result\r\n  1491\t        #  is ndarray, e.g. IntegerArray, SparseArray\r\n  1492\t        result = ensure_block_shape(result, ndim=2)\r\n  1493\t        return new_block_2d(result, placement=self._mgr_locs)\r\n  1494\t\r\n  1495\t    @final\r\n  1496\t    def round(self, decimals: int) -> Self:\r\n  1497\t        \"\"\"\r\n  1498\t        Rounds the values.\r\n  1499\t        If the block is not of an integer or float dtype, nothing happens.\r\n  1500\t        This is consistent with DataFrame.round behavior.\r\n"]
[1020.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1020.002, "i", "cd /workspace/repo\r"]
[1020.004, "o", "cd /workspace/repo\r\n"]
[1020.006, "o", "\u001b[?2004l\r\n"]
[1025.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1025.002, "i", "grep -n \"def mask\" pandas/core/generic.py pandas/core/frame.py\r"]
[1025.004, "o", "grep -n \"def mask\" pandas/core/generic.py pandas/core/frame.py\r\n"]
[1025.006, "o", "\u001b[?2004l\r\n\u001b[35m\u001b[Kpandas/core/generic.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K10036\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef mask\u001b[m\u001b[K(\r\n\u001b[35m\u001b[Kpandas/core/generic.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K10047\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef mask\u001b[m\u001b[K(\r\n\u001b[35m\u001b[Kpandas/core/generic.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K10058\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef mask\u001b[m\u001b[K(\r\n\u001b[35m\u001b[Kpandas/core/generic.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K10077\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef mask\u001b[m\u001b[K(\r\n"]
[1030.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1030.002, "i", "grep -n \"def where\" pandas/core/generic.py pandas/core/frame.py\r"]
[1030.004, "o", "grep -n \"def where\" pandas/core/generic.py pandas/core/frame.py\r\n"]
[1030.006, "o", "\u001b[?2004l\r\n\u001b[35m\u001b[Kpandas/core/generic.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K9831\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(\r\n\u001b[35m\u001b[Kpandas/core/generic.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K9842\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(\r\n\u001b[35m\u001b[Kpandas/core/generic.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K9853\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(\r\n\u001b[35m\u001b[Kpandas/core/generic.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K9871\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(\r\n"]
[1035.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1035.002, "i", "grep -n \"def where\" pandas/core/internals/blocks.py || true\r"]
[1035.004, "o", "grep -n \"def where\" pandas/core/internals/blocks.py || true\r\n"]
[1035.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K1217\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(self, other, cond) -> list[Block]:\r\n\u001b[32m\u001b[K1670\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef where\u001b[m\u001b[K(self, other, cond) -> list[Block]:\r\n"]
[1040.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1040.002, "i", "grep -n \"@final\\s*def where\" pandas/core/internals/blocks.py || true\r"]
[1040.004, "o", "grep -n \"@final\\s*def where\" pandas/core/internals/blocks.py || true\r\n"]
[1040.006, "o", "\u001b[?2004l\r\n"]
[1045.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1045.002, "i", "grep -n \"where(\" pandas/core/internals/managers.py | head -n 50\r"]
[1045.004, "o", "grep -n \"where(\" pandas/core/internals/managers.py | head -n 50\r\n"]
[1045.006, "o", "\u001b[?2004l\r\n462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[1050.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1050.002, "i", "sed -n '1,260p' pandas/core/internals/managers.py\r"]
[1050.004, "o", "sed -n '1,260p' pandas/core/internals/managers.py\r\n"]
[1050.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nfrom collections.abc import (\r\n    Callable,\r\n    Hashable,\r\n    Sequence,\r\n)\r\nimport itertools\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Literal,\r\n    NoReturn,\r\n    cast,\r\n    final,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config.config import get_option\r\n\r\nfrom pandas._libs import (\r\n    algos as libalgos,\r\n    internals as libinternals,\r\n    lib,\r\n)\r\nfrom pandas._libs.internals import (\r\n    BlockPlacement,\r\n    BlockValuesRefs,\r\n)\r\nfrom pandas._libs.tslibs import Timestamp\r\nfrom pandas.errors import (\r\n    AbstractMethodError,\r\n    PerformanceWarning,\r\n)\r\nfrom pandas.util._decorators import cache_readonly\r\nfrom pandas.util._exceptions import find_stack_level\r\nfrom pandas.util._validators import validate_bool_kwarg\r\n\r\nfrom pandas.core.dtypes.cast import (\r\n    find_common_type,\r\n    infer_dtype_from_scalar,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_platform_int,\r\n    is_1d_only_ea_dtype,\r\n    is_list_like,\r\n)\r\nfrom pandas.core.dtypes.dtypes import (\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    SparseDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCSeries,\r\n)\r\nfrom pandas.core.dtypes.missing import (\r\n    array_equals,\r\n    isna,\r\n)\r\n\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.arrays import DatetimeArray\r\nfrom pandas.core.arrays._mixins import NDArrayBackedExtensionArray\r\nfrom pandas.core.base import PandasObject\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n)\r\nfrom pandas.core.indexers import maybe_convert_indices\r\nfrom pandas.core.indexes.api import (\r\n    Index,\r\n    default_index,\r\n    ensure_index,\r\n)\r\nfrom pandas.core.internals.blocks import (\r\n    Block,\r\n    NumpyBlock,\r\n    ensure_block_shape,\r\n    extend_blocks,\r\n    get_block_type,\r\n    maybe_coerce_values,\r\n    new_block,\r\n    new_block_2d,\r\n)\r\nfrom pandas.core.internals.ops import (\r\n    blockwise_all,\r\n    operate_blockwise,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from collections.abc import Generator\r\n\r\n    from pandas._typing import (\r\n        ArrayLike,\r\n        AxisInt,\r\n        DtypeObj,\r\n        QuantileInterpolation,\r\n        Self,\r\n        Shape,\r\n        npt,\r\n    )\r\n\r\n    from pandas.api.extensions import ExtensionArray\r\n\r\n\r\ndef interleaved_dtype(dtypes: list[DtypeObj]) -> DtypeObj | None:\r\n    \"\"\"\r\n    Find the common dtype for `blocks`.\r\n\r\n    Parameters\r\n    ----------\r\n    blocks : List[DtypeObj]\r\n\r\n    Returns\r\n    -------\r\n    dtype : np.dtype, ExtensionDtype, or None\r\n        None is returned when `blocks` is empty.\r\n    \"\"\"\r\n    if not len(dtypes):\r\n        return None\r\n\r\n    return find_common_type(dtypes)\r\n\r\n\r\ndef ensure_np_dtype(dtype: DtypeObj) -> np.dtype:\r\n    # TODO: https://github.com/pandas-dev/pandas/issues/22791\r\n    # Give EAs some input on what happens here. Sparse needs this.\r\n    if isinstance(dtype, SparseDtype):\r\n        dtype = dtype.subtype\r\n        dtype = cast(np.dtype, dtype)\r\n    elif isinstance(dtype, ExtensionDtype):\r\n        dtype = np.dtype(\"object\")\r\n    elif dtype == np.dtype(str):\r\n        dtype = np.dtype(\"object\")\r\n    return dtype\r\n\r\n\r\nclass BaseBlockManager(PandasObject):\r\n    \"\"\"\r\n    Core internal data structure to implement DataFrame, Series, etc.\r\n\r\n    Manage a bunch of labeled 2D mixed-type ndarrays. Essentially it's a\r\n    lightweight blocked set of labeled data to be manipulated by the DataFrame\r\n    public API class\r\n\r\n    Attributes\r\n    ----------\r\n    shape\r\n    ndim\r\n    axes\r\n    values\r\n    items\r\n\r\n    Methods\r\n    -------\r\n    set_axis(axis, new_labels)\r\n    copy(deep=True)\r\n\r\n    get_dtypes\r\n\r\n    apply(func, axes, block_filter_fn)\r\n\r\n    get_bool_data\r\n    get_numeric_data\r\n\r\n    get_slice(slice_like, axis)\r\n    get(label)\r\n    iget(loc)\r\n\r\n    take(indexer, axis)\r\n    reindex_axis(new_labels, axis)\r\n    reindex_indexer(new_labels, indexer, axis)\r\n\r\n    delete(label)\r\n    insert(loc, label, value)\r\n    set(label, value)\r\n\r\n    Parameters\r\n    ----------\r\n    blocks: Sequence of Block\r\n    axes: Sequence of Index\r\n    verify_integrity: bool, default True\r\n\r\n    Notes\r\n    -----\r\n    This is *not* a public API class\r\n    \"\"\"\r\n\r\n    __slots__ = ()\r\n\r\n    _blknos: npt.NDArray[np.intp]\r\n    _blklocs: npt.NDArray[np.intp]\r\n    blocks: tuple[Block, ...]\r\n    axes: list[Index]\r\n\r\n    @property\r\n    def ndim(self) -> int:\r\n        raise NotImplementedError\r\n\r\n    _known_consolidated: bool\r\n    _is_consolidated: bool\r\n\r\n    def __init__(self, blocks, axes, verify_integrity: bool = True) -> None:\r\n        raise NotImplementedError\r\n\r\n    @final\r\n    def __len__(self) -> int:\r\n        return len(self.items)\r\n\r\n    @property\r\n    def shape(self) -> Shape:\r\n        return tuple(len(ax) for ax in self.axes)\r\n\r\n    @classmethod\r\n    def from_blocks(cls, blocks: list[Block], axes: list[Index]) -> Self:\r\n        raise NotImplementedError\r\n\r\n    @property\r\n    def blknos(self) -> npt.NDArray[np.intp]:\r\n        \"\"\"\r\n        Suppose we want to find the array corresponding to our i'th column.\r\n\r\n        blknos[i] identifies the block from self.blocks that contains this column.\r\n\r\n        blklocs[i] identifies the column of interest within\r\n        self.blocks[self.blknos[i]]\r\n        \"\"\"\r\n        if self._blknos is None:\r\n            # Note: these can be altered by other BlockManager methods.\r\n            self._rebuild_blknos_and_blklocs()\r\n\r\n        return self._blknos\r\n\r\n    @property\r\n    def blklocs(self) -> npt.NDArray[np.intp]:\r\n        \"\"\"\r\n        See blknos.__doc__\r\n        \"\"\"\r\n        if self._blklocs is None:\r\n            # Note: these can be altered by other BlockManager methods.\r\n            self._rebuild_blknos_and_blklocs()\r\n\r\n        return self._blklocs\r\n\r\n    def make_empty(self, axes=None) -> Self:\r\n        \"\"\"return an empty BlockManager with the items axis of len 0\"\"\"\r\n        if axes is None:\r\n            axes = [default_index(0)] + self.axes[1:]\r\n\r\n        # preserve dtype if possible\r\n        if self.ndim == 1:\r\n            assert isinstance(self, SingleBlockManager)  # for mypy\r\n            blk = self.blocks[0]\r\n            arr = blk.values[:0]\r\n            bp = BlockPlacement(slice(0, 0))\r\n            nb = blk.make_block_same_class(arr, placement=bp)\r\n"]
[1055.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1055.002, "i", "grep -n \"LossySetitemError\" pandas/core/internals/blocks.py\r"]
[1055.004, "o", "grep -n \"LossySetitemError\" pandas/core/internals/blocks.py\r\n"]
[1055.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K53\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K,\r\n\u001b[32m\u001b[K1116\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n\u001b[32m\u001b[K1182\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n\u001b[32m\u001b[K1257\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except (ValueError, TypeError, \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K):\r\n\u001b[32m\u001b[K1456\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n"]
[1060.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1060.002, "i", "sed -n '1080,1260p' pandas/core/internals/blocks.py\r"]
[1060.004, "o", "sed -n '1080,1260p' pandas/core/internals/blocks.py\r\n"]
[1060.006, "o", "\u001b[?2004l\r\n\r\n    def setitem(self, indexer, value) -> Block:\r\n        \"\"\"\r\n        Attempt self.values[indexer] = value, possibly creating a new array.\r\n\r\n        Parameters\r\n        ----------\r\n        indexer : tuple, list-like, array-like, slice, int\r\n            The subset of self.values to set\r\n        value : object\r\n            The value being set\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n\r\n        Notes\r\n        -----\r\n        `indexer` is a direct slice/positional indexer. `value` must\r\n        be a compatible shape.\r\n        \"\"\"\r\n\r\n        value = self._standardize_fill_value(value)\r\n\r\n        values = cast(np.ndarray, self.values)\r\n        if self.ndim == 2:\r\n            values = values.T\r\n\r\n        # length checking\r\n        check_setitem_lengths(indexer, value, values)\r\n\r\n        if self.dtype != _dtype_obj:\r\n            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n            value = extract_array(value, extract_numpy=True)\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, value)\r\n        except LossySetitemError:\r\n            # current dtype cannot store value, coerce to common dtype\r\n            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n            return nb.setitem(indexer, value)\r\n        else:\r\n            if self.dtype == _dtype_obj:\r\n                # TODO: avoid having to construct values[indexer]\r\n                vi = values[indexer]\r\n                if lib.is_list_like(vi):\r\n                    # checking lib.is_scalar here fails on\r\n                    #  test_iloc_setitem_custom_object\r\n                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values.T)\r\n            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n                casted = casted[0, ...]\r\n            try:\r\n                values[indexer] = casted\r\n            except (TypeError, ValueError) as err:\r\n                if is_list_like(casted):\r\n                    raise ValueError(\r\n                        \"setting an array element with a sequence.\"\r\n                    ) from err\r\n                raise\r\n        return self\r\n\r\n    def putmask(self, mask, new) -> list[Block]:\r\n        \"\"\"\r\n        putmask the data to the block; it is possible that we may create a\r\n        new dtype of block\r\n\r\n        Return the resulting block(s).\r\n\r\n        Parameters\r\n        ----------\r\n        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n        new : a ndarray/object\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        orig_mask = mask\r\n        values = cast(np.ndarray, self.values)\r\n        mask, noop = validate_putmask(values.T, mask)\r\n        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        if new is lib.no_default:\r\n            new = self.fill_value\r\n\r\n        new = self._standardize_fill_value(new)\r\n        new = extract_array(new, extract_numpy=True)\r\n\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, new)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values)\r\n\r\n            putmask_without_repeat(values.T, mask, casted)\r\n            return [self]\r\n        except LossySetitemError:\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                if not is_list_like(new):\r\n                    # using just new[indexer] can't save us the need to cast\r\n                    return self.coerce_to_target_dtype(\r\n                        new, raise_on_upcast=True\r\n                    ).putmask(mask, new)\r\n                else:\r\n                    indexer = mask.nonzero()[0]\r\n                    nb = self.setitem(indexer, new[indexer])\r\n                    return [nb]\r\n\r\n            else:\r\n                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n                    obj_block = self.astype(np.dtype(object))\r\n                    obj_vals = cast(np.ndarray, obj_block.values)\r\n                    putmask_without_repeat(obj_vals.T, mask, new)\r\n                    return [obj_block]\r\n                is_array = isinstance(new, np.ndarray)\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    n = new\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        n = new[:, i : i + 1]\r\n\r\n                    submask = orig_mask[:, i : i + 1]\r\n                    rbs = nb.putmask(submask, n)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n    def where(self, other, cond) -> list[Block]:\r\n        \"\"\"\r\n        evaluate the block; return result block(s) from the result\r\n\r\n        Parameters\r\n        ----------\r\n        other : a ndarray/object\r\n        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        assert cond.ndim == self.ndim\r\n        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        transpose = self.ndim == 2\r\n\r\n        cond = extract_bool_array(cond)\r\n\r\n        # EABlocks override where\r\n        values = cast(np.ndarray, self.values)\r\n        orig_other = other\r\n        if transpose:\r\n            values = values.T\r\n\r\n        icond, noop = validate_putmask(values, ~cond)\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        if other is lib.no_default:\r\n            other = self.fill_value\r\n\r\n        other = self._standardize_fill_value(other)\r\n\r\n        try:\r\n            # try/except here is equivalent to a self._can_hold_element check,\r\n            #  but this gets us back 'casted' which we will reuse below;\r\n            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n            casted = np_can_hold_element(values.dtype, other)\r\n        except (ValueError, TypeError, LossySetitemError):\r\n            # we cannot coerce, return a compat dtype\r\n\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n"]
[1065.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1065.002, "i", "sed -n '1260,1500p' pandas/core/internals/blocks.py\r"]
[1065.004, "o", "sed -n '1260,1500p' pandas/core/internals/blocks.py\r\n"]
[1065.006, "o", "\u001b[?2004l\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                block = self.coerce_to_target_dtype(other, raise_on_upcast=False)\r\n                return block.where(orig_other, cond)\r\n\r\n            else:\r\n                is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    oth = other\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        oth = other[:, i : i + 1]\r\n\r\n                    submask = cond[:, i : i + 1]\r\n                    rbs = nb.where(oth, submask)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n        else:\r\n            other = casted\r\n            alt = setitem_datetimelike_compat(values, icond.sum(), other)\r\n            if alt is not other:\r\n                if is_list_like(other) and len(other) < len(values):\r\n                    # call np.where with other to get the appropriate ValueError\r\n                    np.where(~icond, values, other)\r\n                    raise NotImplementedError(\r\n                        \"This should not be reached; call to np.where above is \"\r\n                        \"expected to raise ValueError. Please report a bug at \"\r\n                        \"github.com/pandas-dev/pandas\"\r\n                    )\r\n                result = values.copy()\r\n                np.putmask(result, icond, alt)\r\n            else:\r\n                # By the time we get here, we should have all Series/Index\r\n                #  args extracted to ndarray\r\n                if (\r\n                    is_list_like(other)\r\n                    and not isinstance(other, np.ndarray)\r\n                    and len(other) == self.shape[-1]\r\n                ):\r\n                    # If we don't do this broadcasting here, then expressions.where\r\n                    #  will broadcast a 1D other to be row-like instead of\r\n                    #  column-like.\r\n                    other = np.array(other).reshape(values.shape)\r\n                    # If lengths don't match (or len(other)==1), we will raise\r\n                    #  inside expressions.where, see test_series_where\r\n\r\n                # Note: expressions.where may upcast.\r\n                result = expressions.where(~icond, values, other)\r\n                # The np_can_hold_element check _should_ ensure that we always\r\n                #  have result.dtype == self.dtype here.\r\n\r\n        if transpose:\r\n            result = result.T\r\n\r\n        return [self.make_block(result)]\r\n\r\n    def fillna(\r\n        self,\r\n        value,\r\n        limit: int | None = None,\r\n        inplace: bool = False,\r\n    ) -> list[Block]:\r\n        \"\"\"\r\n        fillna on the block with the value. If we fail, then convert to\r\n        block to hold objects instead and try again\r\n        \"\"\"\r\n        # Caller is responsible for validating limit; if int it is strictly positive\r\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n\r\n        if not self._can_hold_na:\r\n            # can short-circuit the isna call\r\n            noop = True\r\n        else:\r\n            mask = isna(self.values)\r\n            mask, noop = validate_putmask(self.values, mask)\r\n\r\n        if noop:\r\n            # we can't process the value, but nothing to do\r\n            return [self.copy(deep=False)]\r\n\r\n        if limit is not None:\r\n            mask[mask.cumsum(self.values.ndim - 1) > limit] = False\r\n\r\n        if inplace:\r\n            nbs = self.putmask(mask.T, value)\r\n        else:\r\n            nbs = self.where(value, ~mask.T)\r\n        return extend_blocks(nbs)\r\n\r\n    def pad_or_backfill(\r\n        self,\r\n        *,\r\n        method: FillnaOptions,\r\n        inplace: bool = False,\r\n        limit: int | None = None,\r\n        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n    ) -> list[Block]:\r\n        if not self._can_hold_na:\r\n            # If there are no NAs, then interpolate is a no-op\r\n            return [self.copy(deep=False)]\r\n\r\n        copy, refs = self._get_refs_and_copy(inplace)\r\n\r\n        # Dispatch to the NumpyExtensionArray method.\r\n        # We know self.array_values is a NumpyExtensionArray bc EABlock overrides\r\n        vals = cast(NumpyExtensionArray, self.array_values)\r\n        new_values = vals.T._pad_or_backfill(\r\n            method=method,\r\n            limit=limit,\r\n            limit_area=limit_area,\r\n            copy=copy,\r\n        ).T\r\n\r\n        data = extract_array(new_values, extract_numpy=True)\r\n        return [self.make_block_same_class(data, refs=refs)]\r\n\r\n    @final\r\n    def interpolate(\r\n        self,\r\n        *,\r\n        method: InterpolateOptions,\r\n        index: Index,\r\n        inplace: bool = False,\r\n        limit: int | None = None,\r\n        limit_direction: Literal[\"forward\", \"backward\", \"both\"] = \"forward\",\r\n        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n        **kwargs,\r\n    ) -> list[Block]:\r\n        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n        # error: Non-overlapping equality check [...]\r\n        if method == \"asfreq\":  # type: ignore[comparison-overlap]\r\n            # clean_fill_method used to allow this\r\n            missing.clean_fill_method(method)\r\n\r\n        if not self._can_hold_na:\r\n            # If there are no NAs, then interpolate is a no-op\r\n            return [self.copy(deep=False)]\r\n\r\n        if self.dtype == _dtype_obj:\r\n            # GH#53631\r\n            name = {1: \"Series\", 2: \"DataFrame\"}[self.ndim]\r\n            raise TypeError(f\"{name} cannot interpolate with object dtype.\")\r\n\r\n        copy, refs = self._get_refs_and_copy(inplace)\r\n\r\n        # Dispatch to the EA method.\r\n        new_values = self.array_values.interpolate(\r\n            method=method,\r\n            axis=self.ndim - 1,\r\n            index=index,\r\n            limit=limit,\r\n            limit_direction=limit_direction,\r\n            limit_area=limit_area,\r\n            copy=copy,\r\n            **kwargs,\r\n        )\r\n        data = extract_array(new_values, extract_numpy=True)\r\n        return [self.make_block_same_class(data, refs=refs)]\r\n\r\n    @final\r\n    def diff(self, n: int) -> list[Block]:\r\n        \"\"\"return block for the diff of the values\"\"\"\r\n        # only reached with ndim == 2\r\n        # TODO(EA2D): transpose will be unnecessary with 2D EAs\r\n        new_values = algos.diff(self.values.T, n, axis=0).T\r\n        return [self.make_block(values=new_values)]\r\n\r\n    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:\r\n        \"\"\"shift the block by periods, possibly upcast\"\"\"\r\n        # convert integer to float if necessary. need to do a lot more than\r\n        # that, handle boolean etc also\r\n        axis = self.ndim - 1\r\n\r\n        # Note: periods is never 0 here, as that is handled at the top of\r\n        #  NDFrame.shift.  If that ever changes, we can do a check for periods=0\r\n        #  and possibly avoid coercing.\r\n\r\n        if not lib.is_scalar(fill_value) and self.dtype != _dtype_obj:\r\n            # with object dtype there is nothing to promote, and the user can\r\n            #  pass pretty much any weird fill_value they like\r\n            # see test_shift_object_non_scalar_fill\r\n            raise ValueError(\"fill_value must be a scalar\")\r\n\r\n        fill_value = self._standardize_fill_value(fill_value)\r\n\r\n        try:\r\n            # error: Argument 1 to \"np_can_hold_element\" has incompatible type\r\n            # \"Union[dtype[Any], ExtensionDtype]\"; expected \"dtype[Any]\"\r\n            casted = np_can_hold_element(\r\n                self.dtype,  # type: ignore[arg-type]\r\n                fill_value,\r\n            )\r\n        except LossySetitemError:\r\n            nb = self.coerce_to_target_dtype(fill_value, raise_on_upcast=False)\r\n            return nb.shift(periods, fill_value=fill_value)\r\n\r\n        else:\r\n            values = cast(np.ndarray, self.values)\r\n            new_values = shift(values, periods, axis, casted)\r\n            return [self.make_block_same_class(new_values)]\r\n\r\n    @final\r\n    def quantile(\r\n        self,\r\n        qs: Index,  # with dtype float64\r\n        interpolation: QuantileInterpolation = \"linear\",\r\n    ) -> Block:\r\n        \"\"\"\r\n        compute the quantiles of the\r\n\r\n        Parameters\r\n        ----------\r\n        qs : Index\r\n            The quantiles to be computed in float64.\r\n        interpolation : str, default 'linear'\r\n            Type of interpolation.\r\n\r\n        Returns\r\n        -------\r\n        Block\r\n        \"\"\"\r\n        # We should always have ndim == 2 because Series dispatches to DataFrame\r\n        assert self.ndim == 2\r\n        assert is_list_like(qs)  # caller is responsible for this\r\n\r\n        result = quantile_compat(self.values, np.asarray(qs._values), interpolation)\r\n        # ensure_block_shape needed for cases where we start with EA and result\r\n        #  is ndarray, e.g. IntegerArray, SparseArray\r\n        result = ensure_block_shape(result, ndim=2)\r\n        return new_block_2d(result, placement=self._mgr_locs)\r\n\r\n    @final\r\n    def round(self, decimals: int) -> Self:\r\n        \"\"\"\r\n        Rounds the values.\r\n        If the block is not of an integer or float dtype, nothing happens.\r\n        This is consistent with DataFrame.round behavior.\r\n"]
[1070.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1070.002, "i", "cd /workspace/repo\r"]
[1070.004, "o", "cd /workspace/repo\r\n"]
[1070.006, "o", "\u001b[?2004l\r\n"]
[1075.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1075.002, "i", "grep -R -n -F \"def where(\" pandas/core | head -n 200\r"]
[1075.004, "o", "grep -R -n -F \"def where(\" pandas/core | head -n 200\r\n"]
[1075.006, "o", "\u001b[?2004l\r\npandas/core/computation/expressions.py:247:def where(cond, left_op, right_op, use_numexpr: bool = True):\r\npandas/core/generic.py:9831:    def where(\r\npandas/core/generic.py:9842:    def where(\r\npandas/core/generic.py:9853:    def where(\r\npandas/core/generic.py:9871:    def where(\r\npandas/core/indexes/base.py:5069:    def where(self, cond, other=None) -> Index:\r\npandas/core/internals/blocks.py:1217:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1670:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[1080.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1080.002, "i", "grep -R -n -F \" where(\" pandas/core/internals | head -n 200\r"]
[1080.004, "o", "grep -R -n -F \" where(\" pandas/core/internals | head -n 200\r\n"]
[1080.006, "o", "\u001b[?2004l\r\npandas/core/internals/blocks.py:1217:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/blocks.py:1670:    def where(self, other, cond) -> list[Block]:\r\npandas/core/internals/managers.py:462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[1085.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1085.002, "i", "nl -ba pandas/core/internals/blocks.py | sed -n '1080,1260p'\r"]
[1085.004, "o", "nl -ba pandas/core/internals/blocks.py | sed -n '1080,1260p'\r\n"]
[1085.006, "o", "\u001b[?2004l\r\n  1080\t\r\n  1081\t    def setitem(self, indexer, value) -> Block:\r\n  1082\t        \"\"\"\r\n  1083\t        Attempt self.values[indexer] = value, possibly creating a new array.\r\n  1084\t\r\n  1085\t        Parameters\r\n  1086\t        ----------\r\n  1087\t        indexer : tuple, list-like, array-like, slice, int\r\n  1088\t            The subset of self.values to set\r\n  1089\t        value : object\r\n  1090\t            The value being set\r\n  1091\t\r\n  1092\t        Returns\r\n  1093\t        -------\r\n  1094\t        Block\r\n  1095\t\r\n  1096\t        Notes\r\n  1097\t        -----\r\n  1098\t        `indexer` is a direct slice/positional indexer. `value` must\r\n  1099\t        be a compatible shape.\r\n  1100\t        \"\"\"\r\n  1101\t\r\n  1102\t        value = self._standardize_fill_value(value)\r\n  1103\t\r\n  1104\t        values = cast(np.ndarray, self.values)\r\n  1105\t        if self.ndim == 2:\r\n  1106\t            values = values.T\r\n  1107\t\r\n  1108\t        # length checking\r\n  1109\t        check_setitem_lengths(indexer, value, values)\r\n  1110\t\r\n  1111\t        if self.dtype != _dtype_obj:\r\n  1112\t            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n  1113\t            value = extract_array(value, extract_numpy=True)\r\n  1114\t        try:\r\n  1115\t            casted = np_can_hold_element(values.dtype, value)\r\n  1116\t        except LossySetitemError:\r\n  1117\t            # current dtype cannot store value, coerce to common dtype\r\n  1118\t            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n  1119\t            return nb.setitem(indexer, value)\r\n  1120\t        else:\r\n  1121\t            if self.dtype == _dtype_obj:\r\n  1122\t                # TODO: avoid having to construct values[indexer]\r\n  1123\t                vi = values[indexer]\r\n  1124\t                if lib.is_list_like(vi):\r\n  1125\t                    # checking lib.is_scalar here fails on\r\n  1126\t                    #  test_iloc_setitem_custom_object\r\n  1127\t                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n  1128\t\r\n  1129\t            self = self._maybe_copy(inplace=True)\r\n  1130\t            values = cast(np.ndarray, self.values.T)\r\n  1131\t            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n  1132\t                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n  1133\t                casted = casted[0, ...]\r\n  1134\t            try:\r\n  1135\t                values[indexer] = casted\r\n  1136\t            except (TypeError, ValueError) as err:\r\n  1137\t                if is_list_like(casted):\r\n  1138\t                    raise ValueError(\r\n  1139\t                        \"setting an array element with a sequence.\"\r\n  1140\t                    ) from err\r\n  1141\t                raise\r\n  1142\t        return self\r\n  1143\t\r\n  1144\t    def putmask(self, mask, new) -> list[Block]:\r\n  1145\t        \"\"\"\r\n  1146\t        putmask the data to the block; it is possible that we may create a\r\n  1147\t        new dtype of block\r\n  1148\t\r\n  1149\t        Return the resulting block(s).\r\n  1150\t\r\n  1151\t        Parameters\r\n  1152\t        ----------\r\n  1153\t        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n  1154\t        new : a ndarray/object\r\n  1155\t\r\n  1156\t        Returns\r\n  1157\t        -------\r\n  1158\t        List[Block]\r\n  1159\t        \"\"\"\r\n  1160\t        orig_mask = mask\r\n  1161\t        values = cast(np.ndarray, self.values)\r\n  1162\t        mask, noop = validate_putmask(values.T, mask)\r\n  1163\t        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n  1164\t\r\n  1165\t        if new is lib.no_default:\r\n  1166\t            new = self.fill_value\r\n  1167\t\r\n  1168\t        new = self._standardize_fill_value(new)\r\n  1169\t        new = extract_array(new, extract_numpy=True)\r\n  1170\t\r\n  1171\t        if noop:\r\n  1172\t            return [self.copy(deep=False)]\r\n  1173\t\r\n  1174\t        try:\r\n  1175\t            casted = np_can_hold_element(values.dtype, new)\r\n  1176\t\r\n  1177\t            self = self._maybe_copy(inplace=True)\r\n  1178\t            values = cast(np.ndarray, self.values)\r\n  1179\t\r\n  1180\t            putmask_without_repeat(values.T, mask, casted)\r\n  1181\t            return [self]\r\n  1182\t        except LossySetitemError:\r\n  1183\t            if self.ndim == 1 or self.shape[0] == 1:\r\n  1184\t                # no need to split columns\r\n  1185\t\r\n  1186\t                if not is_list_like(new):\r\n  1187\t                    # using just new[indexer] can't save us the need to cast\r\n  1188\t                    return self.coerce_to_target_dtype(\r\n  1189\t                        new, raise_on_upcast=True\r\n  1190\t                    ).putmask(mask, new)\r\n  1191\t                else:\r\n  1192\t                    indexer = mask.nonzero()[0]\r\n  1193\t                    nb = self.setitem(indexer, new[indexer])\r\n  1194\t                    return [nb]\r\n  1195\t\r\n  1196\t            else:\r\n  1197\t                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n  1198\t                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n  1199\t                    obj_block = self.astype(np.dtype(object))\r\n  1200\t                    obj_vals = cast(np.ndarray, obj_block.values)\r\n  1201\t                    putmask_without_repeat(obj_vals.T, mask, new)\r\n  1202\t                    return [obj_block]\r\n  1203\t                is_array = isinstance(new, np.ndarray)\r\n  1204\t\r\n  1205\t                res_blocks = []\r\n  1206\t                for i, nb in enumerate(self._split()):\r\n  1207\t                    n = new\r\n  1208\t                    if is_array:\r\n  1209\t                        # we have a different value per-column\r\n  1210\t                        n = new[:, i : i + 1]\r\n  1211\t\r\n  1212\t                    submask = orig_mask[:, i : i + 1]\r\n  1213\t                    rbs = nb.putmask(submask, n)\r\n  1214\t                    res_blocks.extend(rbs)\r\n  1215\t                return res_blocks\r\n  1216\t\r\n  1217\t    def where(self, other, cond) -> list[Block]:\r\n  1218\t        \"\"\"\r\n  1219\t        evaluate the block; return result block(s) from the result\r\n  1220\t\r\n  1221\t        Parameters\r\n  1222\t        ----------\r\n  1223\t        other : a ndarray/object\r\n  1224\t        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n  1225\t\r\n  1226\t        Returns\r\n  1227\t        -------\r\n  1228\t        List[Block]\r\n  1229\t        \"\"\"\r\n  1230\t        assert cond.ndim == self.ndim\r\n  1231\t        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\r\n  1232\t\r\n  1233\t        transpose = self.ndim == 2\r\n  1234\t\r\n  1235\t        cond = extract_bool_array(cond)\r\n  1236\t\r\n  1237\t        # EABlocks override where\r\n  1238\t        values = cast(np.ndarray, self.values)\r\n  1239\t        orig_other = other\r\n  1240\t        if transpose:\r\n  1241\t            values = values.T\r\n  1242\t\r\n  1243\t        icond, noop = validate_putmask(values, ~cond)\r\n  1244\t        if noop:\r\n  1245\t            return [self.copy(deep=False)]\r\n  1246\t\r\n  1247\t        if other is lib.no_default:\r\n  1248\t            other = self.fill_value\r\n  1249\t\r\n  1250\t        other = self._standardize_fill_value(other)\r\n  1251\t\r\n  1252\t        try:\r\n  1253\t            # try/except here is equivalent to a self._can_hold_element check,\r\n  1254\t            #  but this gets us back 'casted' which we will reuse below;\r\n  1255\t            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n  1256\t            casted = np_can_hold_element(values.dtype, other)\r\n  1257\t        except (ValueError, TypeError, LossySetitemError):\r\n  1258\t            # we cannot coerce, return a compat dtype\r\n  1259\t\r\n  1260\t            if self.ndim == 1 or self.shape[0] == 1:\r\n"]
[1090.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1090.002, "i", "nl -ba pandas/core/internals/blocks.py | sed -n '1260,1500p'\r"]
[1090.004, "o", "nl -ba pandas/core/internals/blocks.py | sed -n '1260,1500p'\r\n"]
[1090.006, "o", "\u001b[?2004l\r\n  1260\t            if self.ndim == 1 or self.shape[0] == 1:\r\n  1261\t                # no need to split columns\r\n  1262\t\r\n  1263\t                block = self.coerce_to_target_dtype(other, raise_on_upcast=False)\r\n  1264\t                return block.where(orig_other, cond)\r\n  1265\t\r\n  1266\t            else:\r\n  1267\t                is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n  1268\t\r\n  1269\t                res_blocks = []\r\n  1270\t                for i, nb in enumerate(self._split()):\r\n  1271\t                    oth = other\r\n  1272\t                    if is_array:\r\n  1273\t                        # we have a different value per-column\r\n  1274\t                        oth = other[:, i : i + 1]\r\n  1275\t\r\n  1276\t                    submask = cond[:, i : i + 1]\r\n  1277\t                    rbs = nb.where(oth, submask)\r\n  1278\t                    res_blocks.extend(rbs)\r\n  1279\t                return res_blocks\r\n  1280\t\r\n  1281\t        else:\r\n  1282\t            other = casted\r\n  1283\t            alt = setitem_datetimelike_compat(values, icond.sum(), other)\r\n  1284\t            if alt is not other:\r\n  1285\t                if is_list_like(other) and len(other) < len(values):\r\n  1286\t                    # call np.where with other to get the appropriate ValueError\r\n  1287\t                    np.where(~icond, values, other)\r\n  1288\t                    raise NotImplementedError(\r\n  1289\t                        \"This should not be reached; call to np.where above is \"\r\n  1290\t                        \"expected to raise ValueError. Please report a bug at \"\r\n  1291\t                        \"github.com/pandas-dev/pandas\"\r\n  1292\t                    )\r\n  1293\t                result = values.copy()\r\n  1294\t                np.putmask(result, icond, alt)\r\n  1295\t            else:\r\n  1296\t                # By the time we get here, we should have all Series/Index\r\n  1297\t                #  args extracted to ndarray\r\n  1298\t                if (\r\n  1299\t                    is_list_like(other)\r\n  1300\t                    and not isinstance(other, np.ndarray)\r\n  1301\t                    and len(other) == self.shape[-1]\r\n  1302\t                ):\r\n  1303\t                    # If we don't do this broadcasting here, then expressions.where\r\n  1304\t                    #  will broadcast a 1D other to be row-like instead of\r\n  1305\t                    #  column-like.\r\n  1306\t                    other = np.array(other).reshape(values.shape)\r\n  1307\t                    # If lengths don't match (or len(other)==1), we will raise\r\n  1308\t                    #  inside expressions.where, see test_series_where\r\n  1309\t\r\n  1310\t                # Note: expressions.where may upcast.\r\n  1311\t                result = expressions.where(~icond, values, other)\r\n  1312\t                # The np_can_hold_element check _should_ ensure that we always\r\n  1313\t                #  have result.dtype == self.dtype here.\r\n  1314\t\r\n  1315\t        if transpose:\r\n  1316\t            result = result.T\r\n  1317\t\r\n  1318\t        return [self.make_block(result)]\r\n  1319\t\r\n  1320\t    def fillna(\r\n  1321\t        self,\r\n  1322\t        value,\r\n  1323\t        limit: int | None = None,\r\n  1324\t        inplace: bool = False,\r\n  1325\t    ) -> list[Block]:\r\n  1326\t        \"\"\"\r\n  1327\t        fillna on the block with the value. If we fail, then convert to\r\n  1328\t        block to hold objects instead and try again\r\n  1329\t        \"\"\"\r\n  1330\t        # Caller is responsible for validating limit; if int it is strictly positive\r\n  1331\t        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n  1332\t\r\n  1333\t        if not self._can_hold_na:\r\n  1334\t            # can short-circuit the isna call\r\n  1335\t            noop = True\r\n  1336\t        else:\r\n  1337\t            mask = isna(self.values)\r\n  1338\t            mask, noop = validate_putmask(self.values, mask)\r\n  1339\t\r\n  1340\t        if noop:\r\n  1341\t            # we can't process the value, but nothing to do\r\n  1342\t            return [self.copy(deep=False)]\r\n  1343\t\r\n  1344\t        if limit is not None:\r\n  1345\t            mask[mask.cumsum(self.values.ndim - 1) > limit] = False\r\n  1346\t\r\n  1347\t        if inplace:\r\n  1348\t            nbs = self.putmask(mask.T, value)\r\n  1349\t        else:\r\n  1350\t            nbs = self.where(value, ~mask.T)\r\n  1351\t        return extend_blocks(nbs)\r\n  1352\t\r\n  1353\t    def pad_or_backfill(\r\n  1354\t        self,\r\n  1355\t        *,\r\n  1356\t        method: FillnaOptions,\r\n  1357\t        inplace: bool = False,\r\n  1358\t        limit: int | None = None,\r\n  1359\t        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n  1360\t    ) -> list[Block]:\r\n  1361\t        if not self._can_hold_na:\r\n  1362\t            # If there are no NAs, then interpolate is a no-op\r\n  1363\t            return [self.copy(deep=False)]\r\n  1364\t\r\n  1365\t        copy, refs = self._get_refs_and_copy(inplace)\r\n  1366\t\r\n  1367\t        # Dispatch to the NumpyExtensionArray method.\r\n  1368\t        # We know self.array_values is a NumpyExtensionArray bc EABlock overrides\r\n  1369\t        vals = cast(NumpyExtensionArray, self.array_values)\r\n  1370\t        new_values = vals.T._pad_or_backfill(\r\n  1371\t            method=method,\r\n  1372\t            limit=limit,\r\n  1373\t            limit_area=limit_area,\r\n  1374\t            copy=copy,\r\n  1375\t        ).T\r\n  1376\t\r\n  1377\t        data = extract_array(new_values, extract_numpy=True)\r\n  1378\t        return [self.make_block_same_class(data, refs=refs)]\r\n  1379\t\r\n  1380\t    @final\r\n  1381\t    def interpolate(\r\n  1382\t        self,\r\n  1383\t        *,\r\n  1384\t        method: InterpolateOptions,\r\n  1385\t        index: Index,\r\n  1386\t        inplace: bool = False,\r\n  1387\t        limit: int | None = None,\r\n  1388\t        limit_direction: Literal[\"forward\", \"backward\", \"both\"] = \"forward\",\r\n  1389\t        limit_area: Literal[\"inside\", \"outside\"] | None = None,\r\n  1390\t        **kwargs,\r\n  1391\t    ) -> list[Block]:\r\n  1392\t        inplace = validate_bool_kwarg(inplace, \"inplace\")\r\n  1393\t        # error: Non-overlapping equality check [...]\r\n  1394\t        if method == \"asfreq\":  # type: ignore[comparison-overlap]\r\n  1395\t            # clean_fill_method used to allow this\r\n  1396\t            missing.clean_fill_method(method)\r\n  1397\t\r\n  1398\t        if not self._can_hold_na:\r\n  1399\t            # If there are no NAs, then interpolate is a no-op\r\n  1400\t            return [self.copy(deep=False)]\r\n  1401\t\r\n  1402\t        if self.dtype == _dtype_obj:\r\n  1403\t            # GH#53631\r\n  1404\t            name = {1: \"Series\", 2: \"DataFrame\"}[self.ndim]\r\n  1405\t            raise TypeError(f\"{name} cannot interpolate with object dtype.\")\r\n  1406\t\r\n  1407\t        copy, refs = self._get_refs_and_copy(inplace)\r\n  1408\t\r\n  1409\t        # Dispatch to the EA method.\r\n  1410\t        new_values = self.array_values.interpolate(\r\n  1411\t            method=method,\r\n  1412\t            axis=self.ndim - 1,\r\n  1413\t            index=index,\r\n  1414\t            limit=limit,\r\n  1415\t            limit_direction=limit_direction,\r\n  1416\t            limit_area=limit_area,\r\n  1417\t            copy=copy,\r\n  1418\t            **kwargs,\r\n  1419\t        )\r\n  1420\t        data = extract_array(new_values, extract_numpy=True)\r\n  1421\t        return [self.make_block_same_class(data, refs=refs)]\r\n  1422\t\r\n  1423\t    @final\r\n  1424\t    def diff(self, n: int) -> list[Block]:\r\n  1425\t        \"\"\"return block for the diff of the values\"\"\"\r\n  1426\t        # only reached with ndim == 2\r\n  1427\t        # TODO(EA2D): transpose will be unnecessary with 2D EAs\r\n  1428\t        new_values = algos.diff(self.values.T, n, axis=0).T\r\n  1429\t        return [self.make_block(values=new_values)]\r\n  1430\t\r\n  1431\t    def shift(self, periods: int, fill_value: Any = None) -> list[Block]:\r\n  1432\t        \"\"\"shift the block by periods, possibly upcast\"\"\"\r\n  1433\t        # convert integer to float if necessary. need to do a lot more than\r\n  1434\t        # that, handle boolean etc also\r\n  1435\t        axis = self.ndim - 1\r\n  1436\t\r\n  1437\t        # Note: periods is never 0 here, as that is handled at the top of\r\n  1438\t        #  NDFrame.shift.  If that ever changes, we can do a check for periods=0\r\n  1439\t        #  and possibly avoid coercing.\r\n  1440\t\r\n  1441\t        if not lib.is_scalar(fill_value) and self.dtype != _dtype_obj:\r\n  1442\t            # with object dtype there is nothing to promote, and the user can\r\n  1443\t            #  pass pretty much any weird fill_value they like\r\n  1444\t            # see test_shift_object_non_scalar_fill\r\n  1445\t            raise ValueError(\"fill_value must be a scalar\")\r\n  1446\t\r\n  1447\t        fill_value = self._standardize_fill_value(fill_value)\r\n  1448\t\r\n  1449\t        try:\r\n  1450\t            # error: Argument 1 to \"np_can_hold_element\" has incompatible type\r\n  1451\t            # \"Union[dtype[Any], ExtensionDtype]\"; expected \"dtype[Any]\"\r\n  1452\t            casted = np_can_hold_element(\r\n  1453\t                self.dtype,  # type: ignore[arg-type]\r\n  1454\t                fill_value,\r\n  1455\t            )\r\n  1456\t        except LossySetitemError:\r\n  1457\t            nb = self.coerce_to_target_dtype(fill_value, raise_on_upcast=False)\r\n  1458\t            return nb.shift(periods, fill_value=fill_value)\r\n  1459\t\r\n  1460\t        else:\r\n  1461\t            values = cast(np.ndarray, self.values)\r\n  1462\t            new_values = shift(values, periods, axis, casted)\r\n  1463\t            return [self.make_block_same_class(new_values)]\r\n  1464\t\r\n  1465\t    @final\r\n  1466\t    def quantile(\r\n  1467\t        self,\r\n  1468\t        qs: Index,  # with dtype float64\r\n  1469\t        interpolation: QuantileInterpolation = \"linear\",\r\n  1470\t    ) -> Block:\r\n  1471\t        \"\"\"\r\n  1472\t        compute the quantiles of the\r\n  1473\t\r\n  1474\t        Parameters\r\n  1475\t        ----------\r\n  1476\t        qs : Index\r\n  1477\t            The quantiles to be computed in float64.\r\n  1478\t        interpolation : str, default 'linear'\r\n  1479\t            Type of interpolation.\r\n  1480\t\r\n  1481\t        Returns\r\n  1482\t        -------\r\n  1483\t        Block\r\n  1484\t        \"\"\"\r\n  1485\t        # We should always have ndim == 2 because Series dispatches to DataFrame\r\n  1486\t        assert self.ndim == 2\r\n  1487\t        assert is_list_like(qs)  # caller is responsible for this\r\n  1488\t\r\n  1489\t        result = quantile_compat(self.values, np.asarray(qs._values), interpolation)\r\n  1490\t        # ensure_block_shape needed for cases where we start with EA and result\r\n  1491\t        #  is ndarray, e.g. IntegerArray, SparseArray\r\n  1492\t        result = ensure_block_shape(result, ndim=2)\r\n  1493\t        return new_block_2d(result, placement=self._mgr_locs)\r\n  1494\t\r\n  1495\t    @final\r\n  1496\t    def round(self, decimals: int) -> Self:\r\n  1497\t        \"\"\"\r\n  1498\t        Rounds the values.\r\n  1499\t        If the block is not of an integer or float dtype, nothing happens.\r\n  1500\t        This is consistent with DataFrame.round behavior.\r\n"]
[1095.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1095.002, "i", "grep -n -F \"LossySetitemError\" pandas/core/internals/blocks.py\r"]
[1095.004, "o", "grep -n -F \"LossySetitemError\" pandas/core/internals/blocks.py\r\n"]
[1095.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K53\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K,\r\n\u001b[32m\u001b[K1116\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n\u001b[32m\u001b[K1182\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n\u001b[32m\u001b[K1257\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except (ValueError, TypeError, \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K):\r\n\u001b[32m\u001b[K1456\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K        except \u001b[01;31m\u001b[KLossySetitemError\u001b[m\u001b[K:\r\n"]
[1100.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1100.002, "i", "sed -n '1100,1205p' pandas/core/internals/blocks.py\r"]
[1100.004, "o", "sed -n '1100,1205p' pandas/core/internals/blocks.py\r\n"]
[1100.006, "o", "\u001b[?2004l\r\n        \"\"\"\r\n\r\n        value = self._standardize_fill_value(value)\r\n\r\n        values = cast(np.ndarray, self.values)\r\n        if self.ndim == 2:\r\n            values = values.T\r\n\r\n        # length checking\r\n        check_setitem_lengths(indexer, value, values)\r\n\r\n        if self.dtype != _dtype_obj:\r\n            # GH48933: extract_array would convert a pd.Series value to np.ndarray\r\n            value = extract_array(value, extract_numpy=True)\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, value)\r\n        except LossySetitemError:\r\n            # current dtype cannot store value, coerce to common dtype\r\n            nb = self.coerce_to_target_dtype(value, raise_on_upcast=True)\r\n            return nb.setitem(indexer, value)\r\n        else:\r\n            if self.dtype == _dtype_obj:\r\n                # TODO: avoid having to construct values[indexer]\r\n                vi = values[indexer]\r\n                if lib.is_list_like(vi):\r\n                    # checking lib.is_scalar here fails on\r\n                    #  test_iloc_setitem_custom_object\r\n                    casted = setitem_datetimelike_compat(values, len(vi), casted)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values.T)\r\n            if isinstance(casted, np.ndarray) and casted.ndim == 1 and len(casted) == 1:\r\n                # NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\r\n                casted = casted[0, ...]\r\n            try:\r\n                values[indexer] = casted\r\n            except (TypeError, ValueError) as err:\r\n                if is_list_like(casted):\r\n                    raise ValueError(\r\n                        \"setting an array element with a sequence.\"\r\n                    ) from err\r\n                raise\r\n        return self\r\n\r\n    def putmask(self, mask, new) -> list[Block]:\r\n        \"\"\"\r\n        putmask the data to the block; it is possible that we may create a\r\n        new dtype of block\r\n\r\n        Return the resulting block(s).\r\n\r\n        Parameters\r\n        ----------\r\n        mask : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n        new : a ndarray/object\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        orig_mask = mask\r\n        values = cast(np.ndarray, self.values)\r\n        mask, noop = validate_putmask(values.T, mask)\r\n        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        if new is lib.no_default:\r\n            new = self.fill_value\r\n\r\n        new = self._standardize_fill_value(new)\r\n        new = extract_array(new, extract_numpy=True)\r\n\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, new)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values)\r\n\r\n            putmask_without_repeat(values.T, mask, casted)\r\n            return [self]\r\n        except LossySetitemError:\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                if not is_list_like(new):\r\n                    # using just new[indexer] can't save us the need to cast\r\n                    return self.coerce_to_target_dtype(\r\n                        new, raise_on_upcast=True\r\n                    ).putmask(mask, new)\r\n                else:\r\n                    indexer = mask.nonzero()[0]\r\n                    nb = self.setitem(indexer, new[indexer])\r\n                    return [nb]\r\n\r\n            else:\r\n                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n                    obj_block = self.astype(np.dtype(object))\r\n                    obj_vals = cast(np.ndarray, obj_block.values)\r\n                    putmask_without_repeat(obj_vals.T, mask, new)\r\n                    return [obj_block]\r\n                is_array = isinstance(new, np.ndarray)\r\n\r\n                res_blocks = []\r\n"]
[1105.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1105.002, "i", "sed -n '1160,1220p' pandas/core/internals/blocks.py\r"]
[1105.004, "o", "sed -n '1160,1220p' pandas/core/internals/blocks.py\r\n"]
[1105.006, "o", "\u001b[?2004l\r\n        orig_mask = mask\r\n        values = cast(np.ndarray, self.values)\r\n        mask, noop = validate_putmask(values.T, mask)\r\n        assert not isinstance(new, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        if new is lib.no_default:\r\n            new = self.fill_value\r\n\r\n        new = self._standardize_fill_value(new)\r\n        new = extract_array(new, extract_numpy=True)\r\n\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        try:\r\n            casted = np_can_hold_element(values.dtype, new)\r\n\r\n            self = self._maybe_copy(inplace=True)\r\n            values = cast(np.ndarray, self.values)\r\n\r\n            putmask_without_repeat(values.T, mask, casted)\r\n            return [self]\r\n        except LossySetitemError:\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                if not is_list_like(new):\r\n                    # using just new[indexer] can't save us the need to cast\r\n                    return self.coerce_to_target_dtype(\r\n                        new, raise_on_upcast=True\r\n                    ).putmask(mask, new)\r\n                else:\r\n                    indexer = mask.nonzero()[0]\r\n                    nb = self.setitem(indexer, new[indexer])\r\n                    return [nb]\r\n\r\n            else:\r\n                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n                    obj_block = self.astype(np.dtype(object))\r\n                    obj_vals = cast(np.ndarray, obj_block.values)\r\n                    putmask_without_repeat(obj_vals.T, mask, new)\r\n                    return [obj_block]\r\n                is_array = isinstance(new, np.ndarray)\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    n = new\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        n = new[:, i : i + 1]\r\n\r\n                    submask = orig_mask[:, i : i + 1]\r\n                    rbs = nb.putmask(submask, n)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n    def where(self, other, cond) -> list[Block]:\r\n        \"\"\"\r\n        evaluate the block; return result block(s) from the result\r\n\r\n"]
[1110.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1110.002, "i", "sed -n '1200,1280p' pandas/core/internals/blocks.py\r"]
[1110.004, "o", "sed -n '1200,1280p' pandas/core/internals/blocks.py\r\n"]
[1110.006, "o", "\u001b[?2004l\r\n                    obj_vals = cast(np.ndarray, obj_block.values)\r\n                    putmask_without_repeat(obj_vals.T, mask, new)\r\n                    return [obj_block]\r\n                is_array = isinstance(new, np.ndarray)\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    n = new\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        n = new[:, i : i + 1]\r\n\r\n                    submask = orig_mask[:, i : i + 1]\r\n                    rbs = nb.putmask(submask, n)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n    def where(self, other, cond) -> list[Block]:\r\n        \"\"\"\r\n        evaluate the block; return result block(s) from the result\r\n\r\n        Parameters\r\n        ----------\r\n        other : a ndarray/object\r\n        cond : np.ndarray[bool], SparseArray[bool], or BooleanArray\r\n\r\n        Returns\r\n        -------\r\n        List[Block]\r\n        \"\"\"\r\n        assert cond.ndim == self.ndim\r\n        assert not isinstance(other, (ABCIndex, ABCSeries, ABCDataFrame))\r\n\r\n        transpose = self.ndim == 2\r\n\r\n        cond = extract_bool_array(cond)\r\n\r\n        # EABlocks override where\r\n        values = cast(np.ndarray, self.values)\r\n        orig_other = other\r\n        if transpose:\r\n            values = values.T\r\n\r\n        icond, noop = validate_putmask(values, ~cond)\r\n        if noop:\r\n            return [self.copy(deep=False)]\r\n\r\n        if other is lib.no_default:\r\n            other = self.fill_value\r\n\r\n        other = self._standardize_fill_value(other)\r\n\r\n        try:\r\n            # try/except here is equivalent to a self._can_hold_element check,\r\n            #  but this gets us back 'casted' which we will reuse below;\r\n            #  without using 'casted', expressions.where may do unwanted upcasts.\r\n            casted = np_can_hold_element(values.dtype, other)\r\n        except (ValueError, TypeError, LossySetitemError):\r\n            # we cannot coerce, return a compat dtype\r\n\r\n            if self.ndim == 1 or self.shape[0] == 1:\r\n                # no need to split columns\r\n\r\n                block = self.coerce_to_target_dtype(other, raise_on_upcast=False)\r\n                return block.where(orig_other, cond)\r\n\r\n            else:\r\n                is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n\r\n                res_blocks = []\r\n                for i, nb in enumerate(self._split()):\r\n                    oth = other\r\n                    if is_array:\r\n                        # we have a different value per-column\r\n                        oth = other[:, i : i + 1]\r\n\r\n                    submask = cond[:, i : i + 1]\r\n                    rbs = nb.where(oth, submask)\r\n                    res_blocks.extend(rbs)\r\n                return res_blocks\r\n\r\n"]
[1115.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1115.002, "i", "grep -R -n -F \"where(\" pandas/core/internals/managers.py | head -n 50\r"]
[1115.004, "o", "grep -R -n -F \"where(\" pandas/core/internals/managers.py | head -n 50\r\n"]
[1115.006, "o", "\u001b[?2004l\r\n462:    def where(self, other, cond, align: bool) -> Self:\r\n"]
[1120.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1120.002, "i", "python - << 'PY'\r"]
[1120.004, "o", "python - << 'PY'\r\n"]
[1120.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/internals/blocks.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> # Locate the specific 'except (ValueError, TypeError, LossySetitemError):' branch in where()\r\n\u001b[?2004l\r\n\u001b[?2004h> # We'll look for the snippet we just saw and inject our fastpath before the per-column split.\r\n\u001b[?2004l\r\n\u001b[?2004h> pattern = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     r\"except \\(ValueError, TypeError, LossySetitemError\\):\\n[\\s\\S]*?\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     r\"if self\\.ndim == 1 or self\\.shape\\[0\\] == 1:\\n[\\s\\S]*?return block\\.where\\(orig_other, cond\\)\\n\\n\\s*else:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> m = re.search(pattern, s)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m:\r\n\u001b[?2004l\r\n\u001b[?2004h>     raise SystemExit('Target where() exception branch not found for patching')\r\n\u001b[?2004l\r\n\u001b[?2004h> insert_pos = m.end()\r\n\u001b[?2004l\r\n\u001b[?2004h> fastpath = (\r\n\u001b[?2004l\r\n\u001b[?2004h>     \"                # Fastpath: avoid per-column loop by upcasting once and applying vectorized assignment\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     \"                if not is_list_like(other) or (isinstance(other, np.ndarray) and other.ndim == 0):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     \"                    obj_block = self.astype(np.dtype(object))\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     \"                    vals = obj_block.values\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     \"                    # where(cond, other): replace where cond is False\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     \"                    putmask_without_repeat(vals.T, ~cond, other)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>     \"                    return [obj_block]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h> )\r\n\u001b[?2004l\r\n\u001b[?2004h> s2 = s[:insert_pos] + fastpath + s[insert_pos:]\r\n\u001b[?2004l\r\n\u001b[?2004h> p.write_text(s2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Patched Block.where 2D fastpath for scalar other')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nPatched Block.where 2D fastpath for scalar other\r\n"]
[1125.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1125.002, "i", "git diff -- pandas/core/internals/blocks.py | sed -n '1,240p'\r"]
[1125.004, "o", "git diff -- pandas/core/internals/blocks.py | sed -n '1,240p'\r\n"]
[1125.006, "o", "\u001b[?2004l\r\ndiff --git a/pandas/core/internals/blocks.py b/pandas/core/internals/blocks.py\r\nindex d1a9081b23..5570fd965c 100644\r\n--- a/pandas/core/internals/blocks.py\r\n+++ b/pandas/core/internals/blocks.py\r\n@@ -1194,6 +1194,12 @@ class Block(PandasObject, libinternals.Block):\r\n                     return [nb]\r\n \r\n             else:\r\n+                # Fastpath: avoid per-column loop by upcasting once and applying mask vectorized\r\n+                if not is_list_like(new) or (isinstance(new, np.ndarray) and new.ndim == 0):\r\n+                    obj_block = self.astype(np.dtype(object))\r\n+                    obj_vals = cast(np.ndarray, obj_block.values)\r\n+                    putmask_without_repeat(obj_vals.T, mask, new)\r\n+                    return [obj_block]\r\n                 is_array = isinstance(new, np.ndarray)\r\n \r\n                 res_blocks = []\r\n@@ -1258,6 +1264,13 @@ class Block(PandasObject, libinternals.Block):\r\n                 return block.where(orig_other, cond)\r\n \r\n             else:\r\n+                # Fastpath: avoid per-column loop by upcasting once and applying vectorized assignment\r\n+                if not is_list_like(other) or (isinstance(other, np.ndarray) and other.ndim == 0):\r\n+                    obj_block = self.astype(np.dtype(object))\r\n+                    vals = obj_block.values\r\n+                    # where(cond, other): replace where cond is False\r\n+                    putmask_without_repeat(vals.T, ~cond, other)\r\n+                    return [obj_block]\r\n                 is_array = isinstance(other, (np.ndarray, ExtensionArray))\r\n \r\n                 res_blocks = []\r\n"]
[1130.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1130.002, "i", "cd asv_bench\r"]
[1130.004, "o", "cd asv_bench\r\n"]
[1130.006, "o", "\u001b[?2004l\r\n"]
[1135.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[1135.002, "i", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r"]
[1135.004, "o", "asv run --python=same --quick --bench=\"frame_methods.MaskBool.*\" --show-stderr\r\n"]
[1135.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 2 total benchmarks (1 commits * 1 environments * 2 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_bools\u001b[0m                                                                                              12.5\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.MaskBool.time_frame_mask_floats\u001b[0m                                                                                             4.28\u00b10ms\r\n"]
[1140.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[1140.002, "i", "git add -A\r"]
[1140.004, "o", "git add -A\r\n"]
[1140.006, "o", "\u001b[?2004l\r\n"]
[1145.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[1145.002, "i", "git commit -m \"internals: speed up DataFrame.mask/where for bool dtype by avoiding per-column split when \r"]
[1145.004, "o", "git commit -m \"internals: speed up DataFrame.mask/where for bool dtype by avoiding per-column split when \r\n"]
[1145.006, "o", " upcasting is required; upcast whole 2D block once and apply vectorized putmask (4x speedup for frame_methods.MaskBool)\"\r\n\u001b[?2004l\r\nAuthor identity unknown\r\n\r\n*** Please tell me who you are.\r\n\r\nRun\r\n\r\n  git config --global user.email \"you@example.com\"\r\n  git config --global user.name \"Your Name\"\r\n\r\nto set your account's default identity.\r\nOmit --global to set the identity only in this repository.\r\n\r\nfatal: unable to auto-detect email address (got 'root@80419f89fdc2.(none)')\r\n"]
[1150.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[1150.002, "i", "cd asv_bench\r"]
[1150.004, "o", "cd asv_bench\r\n"]
[1150.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[1155.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[1155.002, "i", "asv run --python=same --quick --bench=\"period.Indexing.*|timedelta.TimedeltaIndexing.*\" --show-stderr\r"]
[1155.004, "o", "asv run --python=same --quick --bench=\"period.Indexing.*|timedelta.TimedeltaIndexing.*\" --show-stderr\r\n"]
[1155.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 13 total benchmarks (1 commits * 1 environments * 13 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7 \u001b[0;39mImporting benchmark suite produced output:\u001b[0m\r\n[ 0.00%] \u00b7\u00b7\u00b7\u00b7 \u001b[0;31mmeson-python: building pandas: /opt/conda/envs/asv_3.10/bin/ninja\u001b[0m\r\n              [1/1] Generating write_version_file with a custom command\r\n\r\n[ 3.85%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_align\u001b[0m                                                                                                                1.66\u00b10ms\r\n[ 7.69%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_get_loc\u001b[0m                                                                                                               225\u00b10\u03bcs\r\n[11.54%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_intersection\u001b[0m                                                                                                          533\u00b10\u03bcs\r\n[15.38%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_series_loc\u001b[0m                                                                                                            309\u00b10\u03bcs\r\n[19.23%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_shallow_copy\u001b[0m                                                                                                         13.7\u00b10\u03bcs\r\n[23.08%] \u00b7\u00b7\u00b7 \u001b[0;39mperiod.Indexing.time_unique\u001b[0m                                                                                                                174\u00b10\u03bcs\r\n[26.92%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_align\u001b[0m                                                                                                    1.78\u00b10ms\r\n[30.77%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_get_loc\u001b[0m                                                                                                   212\u00b10\u03bcs\r\n[34.62%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_intersection\u001b[0m                                                                                              354\u00b10\u03bcs\r\n[38.46%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_series_loc\u001b[0m                                                                                                328\u00b10\u03bcs\r\n[42.31%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_shallow_copy\u001b[0m                                                                                             16.2\u00b10\u03bcs\r\n[46.15%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_union\u001b[0m                                                                                                     525\u00b10\u03bcs\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mtimedelta.TimedeltaIndexing.time_unique\u001b[0m                                                                                                    175\u00b10\u03bcs\r\n"]
[1160.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo/asv_bench# "]
[1160.002, "i", "cd /workspace/repo\r"]
[1160.004, "o", "cd /workspace/repo\r\n"]
[1160.006, "o", "\u001b[?2004l\r\n"]
[1165.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1165.002, "i", "git config user.name \"CI User\"\r"]
[1165.004, "o", "git config user.name \"CI User\"\r\n"]
[1165.006, "o", "\u001b[?2004l\r\n"]
[1170.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1170.002, "i", "git config user.email \"ci@example.com\"\r"]
[1170.004, "o", "git config user.email \"ci@example.com\"\r\n"]
[1170.006, "o", "\u001b[?2004l\r\n"]
[1175.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1175.002, "i", "git add -A\r"]
[1175.004, "o", "git add -A\r\n"]
[1175.006, "o", "\u001b[?2004l\r\n"]
[1180.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1180.002, "i", "git commit -m \"internals: speed up DataFrame.mask/where for bool dtype by avoiding per-column split when upcasting \r"]
[1180.004, "o", "git commit -m \"internals: speed up DataFrame.mask/where for bool dtype by avoiding per-column split when upcasting \r\n"]
[1180.006, "o", " is required; upcast whole 2D block once and apply vectorized putmask (~4x speedup for frame_methods.MaskBool)\"\r\n\u001b[?2004l\r\n[main 6994c15340] internals: speed up DataFrame.mask/where for bool dtype by avoiding per-column split when upcasting is required; upcast whole 2D block once and apply vectorized putmask (~4x speedup for frame_methods.MaskBool)\r\n 2 files changed, 265 insertions(+)\r\n create mode 100644 profile_maskbool.txt\r\n"]
[1185.0, "o", "(asv_3.10) root@80419f89fdc2:/workspace/repo# "]
[1185.002, "i", "\u001b[?2004l\r"]
[1185.004, "o", "\u001b[?2004l\r\n"]
[1185.006, "o", "\r\nlogout\r\n"]
