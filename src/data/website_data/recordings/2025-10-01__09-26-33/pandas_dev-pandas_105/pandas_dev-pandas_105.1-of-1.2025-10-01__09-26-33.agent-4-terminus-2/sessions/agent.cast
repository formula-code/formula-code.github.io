{"version": 2, "width": 160, "height": 40, "timestamp": 1762994737, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[1.242, "o", "\u001b[?2004l\r\n"]
[2.478, "o", "\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n"]
[3.714, "o", "\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[7.478, "o", "\u001b[?2004l\r\n"]
[10.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.132769, "o", "\u001b[?2004l\r\n"]
[10.259538, "o", "total 220\r\n"]
[10.386308, "o", "drwxr-xr-x 1 root root  4096 Oct  1 17:01 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[10.513077, "o", "drwxr-xr-x 1 root root  4096 Sep 15 17:10 \u001b[01;34m..\u001b[0m\r\n"]
[10.639846, "o", "-rw-r--r-- 1 root root   971 Sep 13 19:32 .devcontainer.json\r\n"]
[10.766615, "o", "drwxr-xr-x 1 root root  4096 Sep 15 17:13 \u001b[01;34m.git\u001b[0m\r\n"]
[10.893385, "o", "-rw-r--r-- 1 root root  1866 Sep 13 19:33 .gitattributes\r\n"]
[11.020154, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:32 \u001b[01;34m.github\u001b[0m\r\n"]
[11.146923, "o", "-rw-r--r-- 1 root root  2004 Sep 13 19:32 .gitignore\r\n"]
[11.273692, "o", "-rw-r--r-- 1 root root  2280 Sep 13 19:32 .gitpod.yml\r\n"]
[11.400462, "o", "-rw-r--r-- 1 root root 11220 Sep 13 19:33 .pre-commit-config.yaml\r\n"]
[11.527231, "o", "-rw-r--r-- 1 root root  2284 Sep 13 19:33 AUTHORS.md\r\n"]
[11.654, "o", "-rw-r--r-- 1 root root  1541 Sep 13 19:32 CITATION.cff\r\n"]
[11.780769, "o", "-rw-r--r-- 1 root root   494 Sep 13 19:33 Dockerfile\r\n"]
[11.907538, "o", "-rw-r--r-- 1 root root  1634 Sep 13 19:32 LICENSE\r\n"]
[12.034308, "o", "drwxr-xr-x 2 root root  4096 Sep 13 19:32 \u001b[01;34mLICENSES\u001b[0m\r\n"]
[12.161077, "o", "-rw-r--r-- 1 root root  1531 Sep 13 19:33 MANIFEST.in\r\n"]
[12.287846, "o", "-rw-r--r-- 1 root root 11661 Sep 13 19:33 README.md\r\n"]
[12.414615, "o", "drwxr-xr-x 2 root root  4096 Sep 15 14:11 \u001b[01;34m__pycache__\u001b[0m\r\n"]
[12.541385, "o", "-rw-r--r-- 1 root root   101 Sep 15 14:11 _version_meson.py\r\n"]
[12.668154, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 \u001b[01;34masv_bench\u001b[0m\r\n"]
[12.794923, "o", "drwxr-xr-x 1 root root  4096 Sep 15 14:11 \u001b[01;34mbuild\u001b[0m\r\n"]
[12.921692, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 \u001b[01;34mci\u001b[0m\r\n"]
[13.048462, "o", "-rw-r--r-- 1 root root   256 Sep 13 19:32 codecov.yml\r\n"]
[13.175231, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 \u001b[01;34mdoc\u001b[0m\r\n"]
[13.302, "o", "-rw-r--r-- 1 root root  2885 Sep 13 19:33 environment.yml\r\n"]
[13.428769, "o", "-rw-r--r-- 1 root root   866 Sep 13 19:32 generate_pxi.py\r\n"]
[13.555538, "o", "-rw-r--r-- 1 root root  1715 Sep 13 19:32 generate_version.py\r\n"]
[13.682308, "o", "drwxr-xr-x 2 root root  4096 Sep 13 19:32 \u001b[01;34mgitpod\u001b[0m\r\n"]
[13.809077, "o", "-rw-r--r-- 1 root root  1774 Sep 13 19:33 meson.build\r\n"]
[13.935846, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 \u001b[01;34mpandas\u001b[0m\r\n"]
[14.062615, "o", "-rw-r--r-- 1 root root 22870 Sep 13 19:33 pyproject.toml\r\n"]
[14.189385, "o", "-rw-r--r-- 1 root root  4307 Sep 13 19:32 pyright_reportGeneralTypeIssues.json\r\n"]
[14.316154, "o", "-rw-r--r-- 1 root root  1451 Sep 13 19:33 requirements-dev.txt\r\n"]
[14.442923, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 \u001b[01;34mscripts\u001b[0m\r\n"]
[14.569692, "o", "-rwxr-xr-x 1 root root 21977 Sep 13 19:32 \u001b[01;32msetup.py\u001b[0m\r\n"]
[14.696462, "o", "drwxr-xr-x 3 root root  4096 Sep 13 19:32 \u001b[01;34mtooling\u001b[0m\r\n"]
[14.823231, "o", "drwxr-xr-x 2 root root  4096 Sep 13 19:32 \u001b[01;34mtypings\u001b[0m\r\n"]
[15.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[15.002, "i", "ls -la asv* .*asv* 2>/dev/null || true\r"]
[15.004, "o", "ls -la asv* .*asv* 2>/dev/null || true\r\n"]
[15.712286, "o", "\u001b[?2004l\r\n"]
[16.418571, "o", "asv_bench:\r\n"]
[17.124857, "o", "total 24\r\n"]
[17.831143, "o", "drwxr-xr-x 1 root root 4096 Sep 13 19:33 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[18.537429, "o", "drwxr-xr-x 1 root root 4096 Oct  1 17:01 \u001b[01;34m..\u001b[0m\r\n"]
[19.243714, "o", "-rw-r--r-- 1 root root 5194 Sep 13 19:33 asv.conf.json\r\n"]
[20.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[20.002, "i", "grep -RIl \"benchmark_dir\" -n . 2>/dev/null | head -n 5\r"]
[20.004, "o", "grep -RIl \"benchmark_dir\" -n . 2>/dev/null | head -n 5\r\n"]
[22.478, "o", "\u001b[?2004l\r\n"]
[25.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[25.002, "i", "test -f asv.conf.json && cat asv.conf.json || true\r"]
[25.004, "o", "test -f asv.conf.json && cat asv.conf.json || true\r\n"]
[25.006, "o", "\u001b[?2004l\r\n"]
[30.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[30.002, "i", "test -f asv.conf-*.json && ls -1 asv.conf-*.json || true\r"]
[30.004, "o", "test -f asv.conf-*.json && ls -1 asv.conf-*.json || true\r\n"]
[30.006, "o", "\u001b[?2004l\r\n"]
[35.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[35.002, "i", "if [ -f asv_benchmarks.txt ]; then sed -n '1,200p' asv_benchmarks.txt; fi\r"]
[35.004, "o", "if [ -f asv_benchmarks.txt ]; then sed -n '1,200p' asv_benchmarks.txt; fi\r\n"]
[35.006, "o", "\u001b[?2004l\r\n"]
[40.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[40.002, "i", "find . -maxdepth 3 -type d -iname \"asv_bench*\" -or -iname \"bench*\" | sed -n '1,80p'\r"]
[40.004, "o", "find . -maxdepth 3 -type d -iname \"asv_bench*\" -or -iname \"bench*\" | sed -n '1,80p'\r\n"]
[41.654, "o", "\u001b[?2004l\r\n"]
[43.302, "o", "./asv_bench\r\n"]
[45.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[45.002, "i", "rg -n \"class .*\\(.*Benchmark.*\\)|def time_\" -g \"asv*|bench*|**/bench*\" 2>/dev/null | sed -n '1,200p'\r"]
[45.004, "o", "rg -n \"class .*\\(.*Benchmark.*\\)|def time_\" -g \"asv*|bench*|**/bench*\" 2>/dev/null | sed -n '1,200p'\r\n"]
[45.006, "o", "\u001b[?2004l\r\n"]
[50.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[50.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*|tslibs.timedelta.*\" --quick\r"]
[50.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*|tslibs.timedelta.*\" --quick\r\n"]
[52.478, "o", "\u001b[?2004l\r\n"]
[55.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[55.002, "i", "sed -n '1,200p' asv_bench/asv.conf.json\r"]
[55.004, "o", "sed -n '1,200p' asv_bench/asv.conf.json\r\n"]
[55.043173, "o", "\u001b[?2004l\r\n"]
[55.080346, "o", "{\r\n"]
[55.117519, "o", "    // The version of the config file format.  Do not change, unless\r\n"]
[55.154692, "o", "    // you know what you are doing.\r\n"]
[55.191865, "o", "    \"version\": 1,\r\n"]
[55.229038, "o", "\r\n"]
[55.266211, "o", "    // The name of the project being benchmarked\r\n"]
[55.303383, "o", "    \"project\": \"pandas\",\r\n"]
[55.340556, "o", "\r\n"]
[55.377729, "o", "    // The project's homepage\r\n"]
[55.414902, "o", "    \"project_url\": \"https://pandas.pydata.org/\",\r\n"]
[55.452075, "o", "\r\n"]
[55.489248, "o", "    // The URL of the source code repository for the project being\r\n"]
[55.526421, "o", "    // benchmarked\r\n"]
[55.563594, "o", "    \"repo\": \"..\",\r\n"]
[55.600767, "o", "\r\n"]
[55.63794, "o", "    // List of branches to benchmark. If not provided, defaults to \"master\"\r\n"]
[55.675113, "o", "    // (for git) or \"default\" (for mercurial).\r\n"]
[55.712286, "o", "    \"branches\": [\"main\"],\r\n"]
[55.749459, "o", "\r\n"]
[55.786632, "o", "    // The tool to use to create environments.  May be \"conda\",\r\n"]
[55.823805, "o", "    // \"virtualenv\" or other value depending on the plugins in use.\r\n"]
[55.860977, "o", "    // If missing or the empty string, the tool will be automatically\r\n"]
[55.89815, "o", "    // determined by looking for tools on the PATH environment\r\n"]
[55.935323, "o", "    // variable.\r\n"]
[55.972496, "o", "    \"environment_type\": \"conda\",\r\n"]
[56.009669, "o", "\r\n"]
[56.046842, "o", "    // the base URL to show a commit for the project.\r\n"]
[56.084015, "o", "    \"show_commit_url\": \"https://github.com/pandas-dev/pandas/commit/\",\r\n"]
[56.121188, "o", "\r\n"]
[56.158361, "o", "    // The Pythons you'd like to test against.  If not provided, defaults\r\n"]
[56.195534, "o", "    // to the current version of Python used to run `asv`.\r\n"]
[56.232707, "o", "    \"pythons\": [\"3.10\"],\r\n"]
[56.26988, "o", "\r\n"]
[56.307053, "o", "    // The matrix of dependencies to test.  Each key is the name of a\r\n"]
[56.344226, "o", "    // package (in PyPI) and the values are version numbers.  An empty\r\n"]
[56.381398, "o", "    // list or empty string indicates to just test against the default\r\n"]
[56.418571, "o", "    // (latest) version. null indicates that the package is to not be\r\n"]
[56.455744, "o", "    // installed. If the package to be tested is only available from\r\n"]
[56.492917, "o", "    // PyPi, and the 'environment_type' is conda, then you can preface\r\n"]
[56.53009, "o", "    // the package name by 'pip+', and the package will be installed via\r\n"]
[56.567263, "o", "    // pip (with all the conda available packages installed first,\r\n"]
[56.604436, "o", "    // followed by the pip installed packages).\r\n"]
[56.641609, "o", "    \"matrix\": {\r\n"]
[56.678782, "o", "        \"pip+build\": [],\r\n"]
[56.715955, "o", "        \"Cython\": [\"3.0\"],\r\n"]
[56.753128, "o", "        \"matplotlib\": [],\r\n"]
[56.790301, "o", "        \"sqlalchemy\": [],\r\n"]
[56.827474, "o", "        \"scipy\": [],\r\n"]
[56.864647, "o", "        \"numba\": [],\r\n"]
[56.90182, "o", "        \"numexpr\": [],\r\n"]
[56.938992, "o", "        \"pytables\": [null, \"\"],  // platform dependent, see excludes below\r\n"]
[56.976165, "o", "        \"pyarrow\": [],\r\n"]
[57.013338, "o", "        \"tables\": [null, \"\"],\r\n"]
[57.050511, "o", "        \"openpyxl\": [],\r\n"]
[57.087684, "o", "        \"xlsxwriter\": [],\r\n"]
[57.124857, "o", "        \"xlrd\": [],\r\n"]
[57.16203, "o", "        \"odfpy\": [],\r\n"]
[57.199203, "o", "        \"jinja2\": [],\r\n"]
[57.236376, "o", "        \"meson\": [],\r\n"]
[57.273549, "o", "        \"meson-python\": [],\r\n"]
[57.310722, "o", "        \"python-build\": [],\r\n"]
[57.347895, "o", "    },\r\n"]
[57.385068, "o", "    \"conda_channels\": [\"conda-forge\"],\r\n"]
[57.422241, "o", "    // Combinations of libraries/python versions can be excluded/included\r\n"]
[57.459414, "o", "    // from the set to test. Each entry is a dictionary containing additional\r\n"]
[57.496586, "o", "    // key-value pairs to include/exclude.\r\n"]
[57.533759, "o", "    //\r\n"]
[57.570932, "o", "    // An exclude entry excludes entries where all values match. The\r\n"]
[57.608105, "o", "    // values are regexps that should match the whole string.\r\n"]
[57.645278, "o", "    //\r\n"]
[57.682451, "o", "    // An include entry adds an environment. Only the packages listed\r\n"]
[57.719624, "o", "    // are installed. The 'python' key is required. The exclude rules\r\n"]
[57.756797, "o", "    // do not apply to includes.\r\n"]
[57.79397, "o", "    //\r\n"]
[57.831143, "o", "    // In addition to package names, the following keys are available:\r\n"]
[57.868316, "o", "    //\r\n"]
[57.905489, "o", "    // - python\r\n"]
[57.942662, "o", "    //     Python version, as in the *pythons* variable above.\r\n"]
[57.979835, "o", "    // - environment_type\r\n"]
[58.017008, "o", "    //     Environment type, as above.\r\n"]
[58.05418, "o", "    // - sys_platform\r\n"]
[58.091353, "o", "    //     Platform, as in sys.platform. Possible values for the common\r\n"]
[58.128526, "o", "    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.\r\n"]
[58.165699, "o", "    \"exclude\": [\r\n"]
[58.202872, "o", "        // On conda install pytables, otherwise tables\r\n"]
[58.240045, "o", "        {\"environment_type\": \"conda\", \"tables\": \"\"},\r\n"]
[58.277218, "o", "        {\"environment_type\": \"conda\", \"pytables\": null},\r\n"]
[58.314391, "o", "        {\"environment_type\": \"(?!conda).*\", \"tables\": null},\r\n"]
[58.351564, "o", "        {\"environment_type\": \"(?!conda).*\", \"pytables\": \"\"},\r\n"]
[58.388737, "o", "    ],\r\n"]
[58.42591, "o", "    \"include\": [],\r\n"]
[58.463083, "o", "\r\n"]
[58.500256, "o", "    // The directory (relative to the current directory) that benchmarks are\r\n"]
[58.537429, "o", "    // stored in.  If not provided, defaults to \"benchmarks\"\r\n"]
[58.574602, "o", "    // \"benchmark_dir\": \"benchmarks\",\r\n"]
[58.611774, "o", "\r\n"]
[58.648947, "o", "    // The directory (relative to the current directory) to cache the Python\r\n"]
[58.68612, "o", "    // environments in.  If not provided, defaults to \"env\"\r\n"]
[58.723293, "o", "    // \"env_dir\": \"env\",\r\n"]
[58.760466, "o", "\r\n"]
[58.797639, "o", "    // The directory (relative to the current directory) that raw benchmark\r\n"]
[58.834812, "o", "    // results are stored in.  If not provided, defaults to \"results\".\r\n"]
[58.871985, "o", "    // \"results_dir\": \"results\",\r\n"]
[58.909158, "o", "\r\n"]
[58.946331, "o", "    // The directory (relative to the current directory) that the html tree\r\n"]
[58.983504, "o", "    // should be written to.  If not provided, defaults to \"html\".\r\n"]
[59.020677, "o", "    // \"html_dir\": \"html\",\r\n"]
[59.05785, "o", "\r\n"]
[59.095023, "o", "    // The number of characters to retain in the commit hashes.\r\n"]
[59.132195, "o", "    // \"hash_length\": 8,\r\n"]
[59.169368, "o", "\r\n"]
[59.206541, "o", "    // `asv` will cache wheels of the recent builds in each\r\n"]
[59.243714, "o", "    // environment, making them faster to install next time.  This is\r\n"]
[59.280887, "o", "    // number of builds to keep, per environment.\r\n"]
[59.31806, "o", "    \"build_cache_size\": 8,\r\n"]
[59.355233, "o", "\r\n"]
[59.392406, "o", "    // The commits after which the regression search in `asv publish`\r\n"]
[59.429579, "o", "    // should start looking for regressions. Dictionary whose keys are\r\n"]
[59.466752, "o", "    // regexps matching to benchmark names, and values corresponding to\r\n"]
[59.503925, "o", "    // the commit (exclusive) after which to start looking for\r\n"]
[59.541098, "o", "    // regressions.  The default is to start from the first commit\r\n"]
[59.578271, "o", "    // with results. If the commit is `null`, regression detection is\r\n"]
[59.615444, "o", "    // skipped for the matching benchmark.\r\n"]
[59.652617, "o", "    //\r\n"]
[59.689789, "o", "    \"regressions_first_commits\": {\r\n"]
[59.726962, "o", "        \".*\": \"0409521665\"\r\n"]
[59.764135, "o", "    },\r\n"]
[59.801308, "o", "    \"regression_thresholds\": {\r\n"]
[59.838481, "o", "    },\r\n"]
[59.875654, "o", "    \"build_command\":\r\n"]
[59.912827, "o", "    [\"python -m build -Cbuilddir=builddir --wheel --outdir {build_cache_dir} {build_dir}\"]\r\n"]
[60.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[60.002, "i", "ls -la asv_bench/benchmarks\r"]
[60.004, "o", "ls -la asv_bench/benchmarks\r\n"]
[60.113478, "o", "\u001b[?2004l\r\n"]
[60.220957, "o", "total 376\r\n"]
[60.328435, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[60.435913, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 \u001b[01;34m..\u001b[0m\r\n"]
[60.543391, "o", "-rw-r--r-- 1 root root    25 Sep 13 19:32 __init__.py\r\n"]
[60.65087, "o", "-rw-r--r-- 1 root root  6160 Sep 13 19:32 algorithms.py\r\n"]
[60.758348, "o", "drwxr-xr-x 2 root root  4096 Sep 13 19:32 \u001b[01;34malgos\u001b[0m\r\n"]
[60.865826, "o", "-rw-r--r-- 1 root root 12498 Sep 13 19:32 arithmetic.py\r\n"]
[60.973304, "o", "-rw-r--r-- 1 root root  4282 Sep 13 19:32 array.py\r\n"]
[61.080783, "o", "-rw-r--r-- 1 root root  1414 Sep 13 19:32 attrs_caching.py\r\n"]
[61.188261, "o", "-rw-r--r-- 1 root root   739 Sep 13 19:32 boolean.py\r\n"]
[61.295739, "o", "-rw-r--r-- 1 root root  9776 Sep 13 19:32 categoricals.py\r\n"]
[61.403217, "o", "-rw-r--r-- 1 root root  3462 Sep 13 19:32 ctors.py\r\n"]
[61.510696, "o", "-rw-r--r-- 1 root root  3559 Sep 13 19:32 dtypes.py\r\n"]
[61.618174, "o", "-rw-r--r-- 1 root root  1988 Sep 13 19:32 eval.py\r\n"]
[61.725652, "o", "-rw-r--r-- 1 root root   379 Sep 13 19:32 finalize.py\r\n"]
[61.83313, "o", "-rw-r--r-- 1 root root  5142 Sep 13 19:32 frame_ctor.py\r\n"]
[61.940609, "o", "-rw-r--r-- 1 root root 24293 Sep 13 19:32 frame_methods.py\r\n"]
[62.048087, "o", "-rw-r--r-- 1 root root  8150 Sep 13 19:33 gil.py\r\n"]
[62.155565, "o", "-rw-r--r-- 1 root root 33292 Sep 13 19:32 groupby.py\r\n"]
[62.263043, "o", "-rw-r--r-- 1 root root  2393 Sep 13 19:32 hash_functions.py\r\n"]
[62.370522, "o", "-rw-r--r-- 1 root root  2274 Sep 13 19:32 index_cached_properties.py\r\n"]
[62.478, "o", "-rw-r--r-- 1 root root  7138 Sep 13 19:32 index_object.py\r\n"]
[62.585478, "o", "-rw-r--r-- 1 root root 16813 Sep 13 19:32 indexing.py\r\n"]
[62.692957, "o", "-rw-r--r-- 1 root root  6372 Sep 13 19:32 indexing_engines.py\r\n"]
[62.800435, "o", "-rw-r--r-- 1 root root  8662 Sep 13 19:32 inference.py\r\n"]
[62.907913, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 \u001b[01;34mio\u001b[0m\r\n"]
[63.015391, "o", "-rw-r--r-- 1 root root 18607 Sep 13 19:32 join_merge.py\r\n"]
[63.12287, "o", "-rw-r--r-- 1 root root  2445 Sep 13 19:32 libs.py\r\n"]
[63.230348, "o", "-rw-r--r-- 1 root root 12356 Sep 13 19:32 multiindex_object.py\r\n"]
[63.337826, "o", "-rw-r--r-- 1 root root   624 Sep 13 19:32 package.py\r\n"]
[63.445304, "o", "-rw-r--r-- 1 root root  1740 Sep 13 19:32 pandas_vb_common.py\r\n"]
[63.552783, "o", "-rw-r--r-- 1 root root  2909 Sep 13 19:32 period.py\r\n"]
[63.660261, "o", "-rw-r--r-- 1 root root  4554 Sep 13 19:32 plotting.py\r\n"]
[63.767739, "o", "-rw-r--r-- 1 root root  4948 Sep 13 19:32 reindex.py\r\n"]
[63.875217, "o", "-rw-r--r-- 1 root root  2103 Sep 13 19:32 replace.py\r\n"]
[63.982696, "o", "-rw-r--r-- 1 root root  9973 Sep 13 19:32 reshape.py\r\n"]
[64.090174, "o", "-rw-r--r-- 1 root root 11628 Sep 13 19:32 rolling.py\r\n"]
[64.197652, "o", "-rw-r--r-- 1 root root 10677 Sep 13 19:32 series_methods.py\r\n"]
[64.30513, "o", "-rw-r--r-- 1 root root  6817 Sep 13 19:32 sparse.py\r\n"]
[64.412609, "o", "-rw-r--r-- 1 root root  4685 Sep 13 19:32 stat_ops.py\r\n"]
[64.520087, "o", "-rw-r--r-- 1 root root  3535 Sep 13 19:32 strftime.py\r\n"]
[64.627565, "o", "-rw-r--r-- 1 root root  7996 Sep 13 19:33 strings.py\r\n"]
[64.735043, "o", "-rw-r--r-- 1 root root  1528 Sep 13 19:32 timedelta.py\r\n"]
[64.842522, "o", "-rw-r--r-- 1 root root  8565 Sep 13 19:32 timeseries.py\r\n"]
[65.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[65.002, "i", "rg -n \"class .*Benchmark|def time_\" asv_bench/benchmarks | sed -n '1,200p'\r"]
[65.004, "o", "rg -n \"class .*Benchmark|def time_\" asv_bench/benchmarks | sed -n '1,200p'\r\n"]
[67.478, "o", "\u001b[?2004l\r\n"]
[70.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[70.002, "i", "asv run --python=same --config asv_bench/asv.conf.json --bench=\"algorithms.Hashing.*|tslibs.timedelta.*\" --quick\r"]
[70.004, "o", "asv run --python=same --config asv_bench/asv.conf.json --bench=\"algorithms.Hashing.*|tslibs.timedelta.*\" --quick\r\n"]
[72.478, "o", "\u001b[?2004l\r\n"]
[75.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[75.002, "i", "sed -n '1,200p' asv_bench/benchmarks/algorithms.py\r"]
[75.004, "o", "sed -n '1,200p' asv_bench/benchmarks/algorithms.py\r\n"]
[75.030597, "o", "\u001b[?2004l\r\n"]
[75.055194, "o", "from importlib import import_module\r\n"]
[75.079791, "o", "\r\n"]
[75.104388, "o", "import numpy as np\r\n"]
[75.128985, "o", "\r\n"]
[75.153582, "o", "import pandas as pd\r\n"]
[75.178179, "o", "\r\n"]
[75.202776, "o", "for imp in [\"pandas.util\", \"pandas.tools.hashing\"]:\r\n"]
[75.227373, "o", "    try:\r\n"]
[75.25197, "o", "        hashing = import_module(imp)\r\n"]
[75.276567, "o", "        break\r\n"]
[75.301164, "o", "    except (ImportError, TypeError, ValueError):\r\n"]
[75.325761, "o", "        pass\r\n"]
[75.350358, "o", "\r\n"]
[75.374955, "o", "\r\n"]
[75.399552, "o", "class Factorize:\r\n"]
[75.424149, "o", "    params = [\r\n"]
[75.448746, "o", "        [True, False],\r\n"]
[75.473343, "o", "        [True, False],\r\n"]
[75.49794, "o", "        [\r\n"]
[75.522537, "o", "            \"int64\",\r\n"]
[75.547134, "o", "            \"uint64\",\r\n"]
[75.571731, "o", "            \"float64\",\r\n"]
[75.596328, "o", "            \"object\",\r\n"]
[75.620925, "o", "            \"object_str\",\r\n"]
[75.645522, "o", "            \"datetime64[ns]\",\r\n"]
[75.670119, "o", "            \"datetime64[ns, tz]\",\r\n"]
[75.694716, "o", "            \"Int64\",\r\n"]
[75.719313, "o", "            \"boolean\",\r\n"]
[75.74391, "o", "            \"string[pyarrow]\",\r\n"]
[75.768507, "o", "        ],\r\n"]
[75.793104, "o", "    ]\r\n"]
[75.817701, "o", "    param_names = [\"unique\", \"sort\", \"dtype\"]\r\n"]
[75.842299, "o", "\r\n"]
[75.866896, "o", "    def setup(self, unique, sort, dtype):\r\n"]
[75.891493, "o", "        N = 10**5\r\n"]
[75.91609, "o", "\r\n"]
[75.940687, "o", "        if dtype in [\"int64\", \"uint64\", \"Int64\", \"object\"]:\r\n"]
[75.965284, "o", "            data = pd.Index(np.arange(N), dtype=dtype)\r\n"]
[75.989881, "o", "        elif dtype == \"float64\":\r\n"]
[76.014478, "o", "            data = pd.Index(np.random.randn(N), dtype=dtype)\r\n"]
[76.039075, "o", "        elif dtype == \"boolean\":\r\n"]
[76.063672, "o", "            data = pd.array(np.random.randint(0, 2, N), dtype=dtype)\r\n"]
[76.088269, "o", "        elif dtype == \"datetime64[ns]\":\r\n"]
[76.112866, "o", "            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\r\n"]
[76.137463, "o", "        elif dtype == \"datetime64[ns, tz]\":\r\n"]
[76.16206, "o", "            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\r\n"]
[76.186657, "o", "        elif dtype == \"object_str\":\r\n"]
[76.211254, "o", "            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\r\n"]
[76.235851, "o", "        elif dtype == \"string[pyarrow]\":\r\n"]
[76.260448, "o", "            data = pd.array(\r\n"]
[76.285045, "o", "                pd.Index([f\"i-{i}\" for i in range(N)], dtype=object),\r\n"]
[76.309642, "o", "                dtype=\"string[pyarrow]\",\r\n"]
[76.334239, "o", "            )\r\n"]
[76.358836, "o", "        else:\r\n"]
[76.383433, "o", "            raise NotImplementedError\r\n"]
[76.40803, "o", "\r\n"]
[76.432627, "o", "        if not unique:\r\n"]
[76.457224, "o", "            data = data.repeat(5)\r\n"]
[76.481821, "o", "        self.data = data\r\n"]
[76.506418, "o", "\r\n"]
[76.531015, "o", "    def time_factorize(self, unique, sort, dtype):\r\n"]
[76.555612, "o", "        pd.factorize(self.data, sort=sort)\r\n"]
[76.580209, "o", "\r\n"]
[76.604806, "o", "    def peakmem_factorize(self, unique, sort, dtype):\r\n"]
[76.629403, "o", "        pd.factorize(self.data, sort=sort)\r\n"]
[76.654, "o", "\r\n"]
[76.678597, "o", "\r\n"]
[76.703194, "o", "class Duplicated:\r\n"]
[76.727791, "o", "    params = [\r\n"]
[76.752388, "o", "        [True, False],\r\n"]
[76.776985, "o", "        [\"first\", \"last\", False],\r\n"]
[76.801582, "o", "        [\r\n"]
[76.826179, "o", "            \"int64\",\r\n"]
[76.850776, "o", "            \"uint64\",\r\n"]
[76.875373, "o", "            \"float64\",\r\n"]
[76.89997, "o", "            \"string\",\r\n"]
[76.924567, "o", "            \"datetime64[ns]\",\r\n"]
[76.949164, "o", "            \"datetime64[ns, tz]\",\r\n"]
[76.973761, "o", "            \"timestamp[ms][pyarrow]\",\r\n"]
[76.998358, "o", "            \"duration[s][pyarrow]\",\r\n"]
[77.022955, "o", "        ],\r\n"]
[77.047552, "o", "    ]\r\n"]
[77.072149, "o", "    param_names = [\"unique\", \"keep\", \"dtype\"]\r\n"]
[77.096746, "o", "\r\n"]
[77.121343, "o", "    def setup(self, unique, keep, dtype):\r\n"]
[77.14594, "o", "        N = 10**5\r\n"]
[77.170537, "o", "        if dtype in [\"int64\", \"uint64\"]:\r\n"]
[77.195134, "o", "            data = pd.Index(np.arange(N), dtype=dtype)\r\n"]
[77.219731, "o", "        elif dtype == \"float64\":\r\n"]
[77.244328, "o", "            data = pd.Index(np.random.randn(N), dtype=\"float64\")\r\n"]
[77.268925, "o", "        elif dtype == \"string\":\r\n"]
[77.293522, "o", "            data = pd.Index([f\"i-{i}\" for i in range(N)], dtype=object)\r\n"]
[77.318119, "o", "        elif dtype == \"datetime64[ns]\":\r\n"]
[77.342716, "o", "            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N)\r\n"]
[77.367313, "o", "        elif dtype == \"datetime64[ns, tz]\":\r\n"]
[77.39191, "o", "            data = pd.date_range(\"2011-01-01\", freq=\"h\", periods=N, tz=\"Asia/Tokyo\")\r\n"]
[77.416507, "o", "        elif dtype in [\"timestamp[ms][pyarrow]\", \"duration[s][pyarrow]\"]:\r\n"]
[77.441104, "o", "            data = pd.Index(np.arange(N), dtype=dtype)\r\n"]
[77.465701, "o", "        else:\r\n"]
[77.490299, "o", "            raise NotImplementedError\r\n"]
[77.514896, "o", "        if not unique:\r\n"]
[77.539493, "o", "            data = data.repeat(5)\r\n"]
[77.56409, "o", "        self.idx = data\r\n"]
[77.588687, "o", "        # cache is_unique\r\n"]
[77.613284, "o", "        self.idx.is_unique\r\n"]
[77.637881, "o", "\r\n"]
[77.662478, "o", "    def time_duplicated(self, unique, keep, dtype):\r\n"]
[77.687075, "o", "        self.idx.duplicated(keep=keep)\r\n"]
[77.711672, "o", "\r\n"]
[77.736269, "o", "\r\n"]
[77.760866, "o", "class DuplicatedMaskedArray:\r\n"]
[77.785463, "o", "    params = [\r\n"]
[77.81006, "o", "        [True, False],\r\n"]
[77.834657, "o", "        [\"first\", \"last\", False],\r\n"]
[77.859254, "o", "        [\"Int64\", \"Float64\"],\r\n"]
[77.883851, "o", "    ]\r\n"]
[77.908448, "o", "    param_names = [\"unique\", \"keep\", \"dtype\"]\r\n"]
[77.933045, "o", "\r\n"]
[77.957642, "o", "    def setup(self, unique, keep, dtype):\r\n"]
[77.982239, "o", "        N = 10**5\r\n"]
[78.006836, "o", "        data = pd.Series(np.arange(N), dtype=dtype)\r\n"]
[78.031433, "o", "        data[list(range(1, N, 100))] = pd.NA\r\n"]
[78.05603, "o", "        if not unique:\r\n"]
[78.080627, "o", "            data = data.repeat(5)\r\n"]
[78.105224, "o", "        self.ser = data\r\n"]
[78.129821, "o", "        # cache is_unique\r\n"]
[78.154418, "o", "        self.ser.is_unique\r\n"]
[78.179015, "o", "\r\n"]
[78.203612, "o", "    def time_duplicated(self, unique, keep, dtype):\r\n"]
[78.228209, "o", "        self.ser.duplicated(keep=keep)\r\n"]
[78.252806, "o", "\r\n"]
[78.277403, "o", "\r\n"]
[78.302, "o", "class Hashing:\r\n"]
[78.326597, "o", "    def setup_cache(self):\r\n"]
[78.351194, "o", "        N = 10**5\r\n"]
[78.375791, "o", "\r\n"]
[78.400388, "o", "        df = pd.DataFrame(\r\n"]
[78.424985, "o", "            {\r\n"]
[78.449582, "o", "                \"strings\": pd.Series(\r\n"]
[78.474179, "o", "                    pd.Index([f\"i-{i}\" for i in range(10000)], dtype=object).take(\r\n"]
[78.498776, "o", "                        np.random.randint(0, 10000, size=N)\r\n"]
[78.523373, "o", "                    )\r\n"]
[78.54797, "o", "                ),\r\n"]
[78.572567, "o", "                \"floats\": np.random.randn(N),\r\n"]
[78.597164, "o", "                \"ints\": np.arange(N),\r\n"]
[78.621761, "o", "                \"dates\": pd.date_range(\"20110101\", freq=\"s\", periods=N),\r\n"]
[78.646358, "o", "                \"timedeltas\": pd.timedelta_range(\"1 day\", freq=\"s\", periods=N),\r\n"]
[78.670955, "o", "            }\r\n"]
[78.695552, "o", "        )\r\n"]
[78.720149, "o", "        df[\"categories\"] = df[\"strings\"].astype(\"category\")\r\n"]
[78.744746, "o", "        df.iloc[10:20] = np.nan\r\n"]
[78.769343, "o", "        return df\r\n"]
[78.79394, "o", "\r\n"]
[78.818537, "o", "    def time_frame(self, df):\r\n"]
[78.843134, "o", "        hashing.hash_pandas_object(df)\r\n"]
[78.867731, "o", "\r\n"]
[78.892328, "o", "    def time_series_int(self, df):\r\n"]
[78.916925, "o", "        hashing.hash_pandas_object(df[\"ints\"])\r\n"]
[78.941522, "o", "\r\n"]
[78.966119, "o", "    def time_series_string(self, df):\r\n"]
[78.990716, "o", "        hashing.hash_pandas_object(df[\"strings\"])\r\n"]
[79.015313, "o", "\r\n"]
[79.03991, "o", "    def time_series_float(self, df):\r\n"]
[79.064507, "o", "        hashing.hash_pandas_object(df[\"floats\"])\r\n"]
[79.089104, "o", "\r\n"]
[79.113701, "o", "    def time_series_categorical(self, df):\r\n"]
[79.138299, "o", "        hashing.hash_pandas_object(df[\"categories\"])\r\n"]
[79.162896, "o", "\r\n"]
[79.187493, "o", "    def time_series_timedeltas(self, df):\r\n"]
[79.21209, "o", "        hashing.hash_pandas_object(df[\"timedeltas\"])\r\n"]
[79.236687, "o", "\r\n"]
[79.261284, "o", "    def time_series_dates(self, df):\r\n"]
[79.285881, "o", "        hashing.hash_pandas_object(df[\"dates\"])\r\n"]
[79.310478, "o", "\r\n"]
[79.335075, "o", "\r\n"]
[79.359672, "o", "class Quantile:\r\n"]
[79.384269, "o", "    params = [\r\n"]
[79.408866, "o", "        [0, 0.5, 1],\r\n"]
[79.433463, "o", "        [\"linear\", \"nearest\", \"lower\", \"higher\", \"midpoint\"],\r\n"]
[79.45806, "o", "        [\"float64\", \"int64\", \"uint64\"],\r\n"]
[79.482657, "o", "    ]\r\n"]
[79.507254, "o", "    param_names = [\"quantile\", \"interpolation\", \"dtype\"]\r\n"]
[79.531851, "o", "\r\n"]
[79.556448, "o", "    def setup(self, quantile, interpolation, dtype):\r\n"]
[79.581045, "o", "        N = 10**5\r\n"]
[79.605642, "o", "        if dtype in [\"int64\", \"uint64\"]:\r\n"]
[79.630239, "o", "            data = np.arange(N, dtype=dtype)\r\n"]
[79.654836, "o", "        elif dtype == \"float64\":\r\n"]
[79.679433, "o", "            data = np.random.randn(N)\r\n"]
[79.70403, "o", "        else:\r\n"]
[79.728627, "o", "            raise NotImplementedError\r\n"]
[79.753224, "o", "        self.ser = pd.Series(data.repeat(5))\r\n"]
[79.777821, "o", "\r\n"]
[79.802418, "o", "    def time_quantile(self, quantile, interpolation, dtype):\r\n"]
[79.827015, "o", "        self.ser.quantile(quantile, interpolation=interpolation)\r\n"]
[79.851612, "o", "\r\n"]
[79.876209, "o", "\r\n"]
[79.900806, "o", "class SortIntegerArray:\r\n"]
[79.925403, "o", "    params = [10**3, 10**5]\r\n"]
[80.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[80.002, "i", "sed -n '1,200p' asv_bench/benchmarks/timedelta.py\r"]
[80.004, "o", "sed -n '1,200p' asv_bench/benchmarks/timedelta.py\r\n"]
[80.085742, "o", "\u001b[?2004l\r\n"]
[80.165484, "o", "\"\"\"\r\n"]
[80.245226, "o", "Timedelta benchmarks with non-tslibs dependencies.  See\r\n"]
[80.324968, "o", "benchmarks.tslibs.timedelta for benchmarks that rely only on tslibs.\r\n"]
[80.40471, "o", "\"\"\"\r\n"]
[80.484452, "o", "\r\n"]
[80.564194, "o", "from pandas import (\r\n"]
[80.643935, "o", "    DataFrame,\r\n"]
[80.723677, "o", "    Series,\r\n"]
[80.803419, "o", "    timedelta_range,\r\n"]
[80.883161, "o", ")\r\n"]
[80.962903, "o", "\r\n"]
[81.042645, "o", "\r\n"]
[81.122387, "o", "class DatetimeAccessor:\r\n"]
[81.202129, "o", "    def setup_cache(self):\r\n"]
[81.281871, "o", "        N = 100000\r\n"]
[81.361613, "o", "        series = Series(timedelta_range(\"1 days\", periods=N, freq=\"h\"))\r\n"]
[81.441355, "o", "        return series\r\n"]
[81.521097, "o", "\r\n"]
[81.600839, "o", "    def time_dt_accessor(self, series):\r\n"]
[81.680581, "o", "        series.dt\r\n"]
[81.760323, "o", "\r\n"]
[81.840065, "o", "    def time_timedelta_days(self, series):\r\n"]
[81.919806, "o", "        series.dt.days\r\n"]
[81.999548, "o", "\r\n"]
[82.07929, "o", "    def time_timedelta_seconds(self, series):\r\n"]
[82.159032, "o", "        series.dt.seconds\r\n"]
[82.238774, "o", "\r\n"]
[82.318516, "o", "    def time_timedelta_microseconds(self, series):\r\n"]
[82.398258, "o", "        series.dt.microseconds\r\n"]
[82.478, "o", "\r\n"]
[82.557742, "o", "    def time_timedelta_nanoseconds(self, series):\r\n"]
[82.637484, "o", "        series.dt.nanoseconds\r\n"]
[82.717226, "o", "\r\n"]
[82.796968, "o", "\r\n"]
[82.87671, "o", "class TimedeltaIndexing:\r\n"]
[82.956452, "o", "    def setup(self):\r\n"]
[83.036194, "o", "        self.index = timedelta_range(start=\"1985\", periods=1000, freq=\"D\")\r\n"]
[83.115935, "o", "        self.index2 = timedelta_range(start=\"1986\", periods=1000, freq=\"D\")\r\n"]
[83.195677, "o", "        self.series = Series(range(1000), index=self.index)\r\n"]
[83.275419, "o", "        self.timedelta = self.index[500]\r\n"]
[83.355161, "o", "\r\n"]
[83.434903, "o", "    def time_get_loc(self):\r\n"]
[83.514645, "o", "        self.index.get_loc(self.timedelta)\r\n"]
[83.594387, "o", "\r\n"]
[83.674129, "o", "    def time_shallow_copy(self):\r\n"]
[83.753871, "o", "        self.index._view()\r\n"]
[83.833613, "o", "\r\n"]
[83.913355, "o", "    def time_series_loc(self):\r\n"]
[83.993097, "o", "        self.series.loc[self.timedelta]\r\n"]
[84.072839, "o", "\r\n"]
[84.152581, "o", "    def time_align(self):\r\n"]
[84.232323, "o", "        DataFrame({\"a\": self.series, \"b\": self.series[:500]})\r\n"]
[84.312065, "o", "\r\n"]
[84.391806, "o", "    def time_intersection(self):\r\n"]
[84.471548, "o", "        self.index.intersection(self.index2)\r\n"]
[84.55129, "o", "\r\n"]
[84.631032, "o", "    def time_union(self):\r\n"]
[84.710774, "o", "        self.index.union(self.index2)\r\n"]
[84.790516, "o", "\r\n"]
[84.870258, "o", "    def time_unique(self):\r\n"]
[85.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[85.002, "i", "ls -la asv_bench/benchmarks/tslibs\r"]
[85.004, "o", "ls -la asv_bench/benchmarks/tslibs\r\n"]
[85.359143, "o", "\u001b[?2004l\r\n"]
[85.712286, "o", "total 48\r\n"]
[86.065429, "o", "drwxr-xr-x 2 root root 4096 Sep 13 19:32 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[86.418571, "o", "drwxr-xr-x 1 root root 4096 Sep 13 19:33 \u001b[01;34m..\u001b[0m\r\n"]
[86.771714, "o", "-rw-r--r-- 1 root root  193 Sep 13 19:32 __init__.py\r\n"]
[87.124857, "o", "-rw-r--r-- 1 root root 2045 Sep 13 19:32 fields.py\r\n"]
[87.478, "o", "-rw-r--r-- 1 root root 1209 Sep 13 19:32 normalize.py\r\n"]
[87.831143, "o", "-rw-r--r-- 1 root root 2132 Sep 13 19:32 offsets.py\r\n"]
[88.184286, "o", "-rw-r--r-- 1 root root 3734 Sep 13 19:32 period.py\r\n"]
[88.537429, "o", "-rw-r--r-- 1 root root 1336 Sep 13 19:32 resolution.py\r\n"]
[88.890571, "o", "-rw-r--r-- 1 root root 1594 Sep 13 19:32 timedelta.py\r\n"]
[89.243714, "o", "-rw-r--r-- 1 root root 3602 Sep 13 19:32 timestamp.py\r\n"]
[89.596857, "o", "-rw-r--r-- 1 root root 1767 Sep 13 19:32 tslib.py\r\n"]
[90.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[90.002, "i", "sed -n '1,200p' asv_bench/benchmarks/tslibs/timedelta.py\r"]
[90.004, "o", "sed -n '1,200p' asv_bench/benchmarks/tslibs/timedelta.py\r\n"]
[90.075634, "o", "\u001b[?2004l\r\n"]
[90.145268, "o", "\"\"\"\r\n"]
[90.214901, "o", "Timedelta benchmarks that rely only on tslibs. See benchmarks.timedeltas for\r\n"]
[90.284535, "o", "Timedelta benchmarks that rely on other parts of pandas.\r\n"]
[90.354169, "o", "\"\"\"\r\n"]
[90.423803, "o", "\r\n"]
[90.493437, "o", "import datetime\r\n"]
[90.56307, "o", "\r\n"]
[90.632704, "o", "import numpy as np\r\n"]
[90.702338, "o", "\r\n"]
[90.771972, "o", "from pandas import Timedelta\r\n"]
[90.841606, "o", "\r\n"]
[90.911239, "o", "\r\n"]
[90.980873, "o", "class TimedeltaConstructor:\r\n"]
[91.050507, "o", "    def setup(self):\r\n"]
[91.120141, "o", "        self.nptimedelta64 = np.timedelta64(3600)\r\n"]
[91.189775, "o", "        self.dttimedelta = datetime.timedelta(seconds=3600)\r\n"]
[91.259408, "o", "        self.td = Timedelta(3600, unit=\"s\")\r\n"]
[91.329042, "o", "\r\n"]
[91.398676, "o", "    def time_from_int(self):\r\n"]
[91.46831, "o", "        Timedelta(123456789)\r\n"]
[91.537944, "o", "\r\n"]
[91.607577, "o", "    def time_from_unit(self):\r\n"]
[91.677211, "o", "        Timedelta(1, unit=\"D\")\r\n"]
[91.746845, "o", "\r\n"]
[91.816479, "o", "    def time_from_components(self):\r\n"]
[91.886113, "o", "        Timedelta(\r\n"]
[91.955746, "o", "            days=1,\r\n"]
[92.02538, "o", "            hours=2,\r\n"]
[92.095014, "o", "            minutes=3,\r\n"]
[92.164648, "o", "            seconds=4,\r\n"]
[92.234282, "o", "            milliseconds=5,\r\n"]
[92.303915, "o", "            microseconds=6,\r\n"]
[92.373549, "o", "            nanoseconds=7,\r\n"]
[92.443183, "o", "        )\r\n"]
[92.512817, "o", "\r\n"]
[92.582451, "o", "    def time_from_datetime_timedelta(self):\r\n"]
[92.652085, "o", "        Timedelta(self.dttimedelta)\r\n"]
[92.721718, "o", "\r\n"]
[92.791352, "o", "    def time_from_np_timedelta(self):\r\n"]
[92.860986, "o", "        Timedelta(self.nptimedelta64)\r\n"]
[92.93062, "o", "\r\n"]
[93.000254, "o", "    def time_from_string(self):\r\n"]
[93.069887, "o", "        Timedelta(\"1 days\")\r\n"]
[93.139521, "o", "\r\n"]
[93.209155, "o", "    def time_from_iso_format(self):\r\n"]
[93.278789, "o", "        Timedelta(\"P4DT12H30M5S\")\r\n"]
[93.348423, "o", "\r\n"]
[93.418056, "o", "    def time_from_missing(self):\r\n"]
[93.48769, "o", "        Timedelta(\"nat\")\r\n"]
[93.557324, "o", "\r\n"]
[93.626958, "o", "    def time_from_pd_timedelta(self):\r\n"]
[93.696592, "o", "        Timedelta(self.td)\r\n"]
[93.766225, "o", "\r\n"]
[93.835859, "o", "\r\n"]
[93.905493, "o", "class TimedeltaProperties:\r\n"]
[93.975127, "o", "    def setup_cache(self):\r\n"]
[94.044761, "o", "        td = Timedelta(days=365, minutes=35, seconds=25, milliseconds=35)\r\n"]
[94.114394, "o", "        return td\r\n"]
[94.184028, "o", "\r\n"]
[94.253662, "o", "    def time_timedelta_days(self, td):\r\n"]
[94.323296, "o", "        td.days\r\n"]
[94.39293, "o", "\r\n"]
[94.462563, "o", "    def time_timedelta_seconds(self, td):\r\n"]
[94.532197, "o", "        td.seconds\r\n"]
[94.601831, "o", "\r\n"]
[94.671465, "o", "    def time_timedelta_microseconds(self, td):\r\n"]
[94.741099, "o", "        td.microseconds\r\n"]
[94.810732, "o", "\r\n"]
[94.880366, "o", "    def time_timedelta_nanoseconds(self, td):\r\n"]
[95.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[95.002, "i", "cd asv_bench\r"]
[95.004, "o", "cd asv_bench\r\n"]
[95.006, "o", "\u001b[?2004l\r\n"]
[100.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[100.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*|tslibs.timedelta.*\" --quick\r"]
[100.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*|tslibs.timedelta.*\" --quick\r\n"]
[100.196154, "o", "\u001b[?2004l\r\n"]
[100.386308, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[100.576462, "o", "\u00b7 \u001b[0;32mRunning 20 total benchmarks (1 commits * 1 environments * 20 benchmarks)\u001b[0m\r\n"]
[100.766615, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[100.956769, "o", "[ 2.50%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n"]
[101.146923, "o", "[ 2.50%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             15.8\u00b10ms\r\n"]
[101.337077, "o", "[ 5.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                4.16\u00b10ms\r\n"]
[101.527231, "o", "[ 7.50%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.31\u00b10ms\r\n"]
[101.717385, "o", "[10.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.31\u00b10ms\r\n"]
[101.907538, "o", "[12.50%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.31\u00b10ms\r\n"]
[102.097692, "o", "[15.00%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.9\u00b10ms\r\n"]
[102.287846, "o", "[17.50%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_timedeltas\u001b[0m                                                                                                 3.26\u00b10ms\r\n"]
[102.478, "o", "[20.00%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaConstructor.time_from_components\u001b[0m                                                                                36.3\u00b10\u03bcs\r\n"]
[102.668154, "o", "[22.50%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaConstructor.time_from_datetime_timedelta\u001b[0m                                                                        53.5\u00b10\u03bcs\r\n"]
[102.858308, "o", "[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaConstructor.time_from_int\u001b[0m                                                                                       15.0\u00b10\u03bcs\r\n"]
[103.048462, "o", "[27.50%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaConstructor.time_from_iso_format\u001b[0m                                                                                70.4\u00b10\u03bcs\r\n"]
[103.238615, "o", "[30.00%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaConstructor.time_from_missing\u001b[0m                                                                                   16.2\u00b10\u03bcs\r\n"]
[103.428769, "o", "[32.50%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaConstructor.time_from_np_timedelta\u001b[0m                                                                              11.8\u00b10\u03bcs\r\n"]
[103.618923, "o", "[35.00%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaConstructor.time_from_pd_timedelta\u001b[0m                                                                              1.82\u00b10\u03bcs\r\n"]
[103.809077, "o", "[37.50%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaConstructor.time_from_string\u001b[0m                                                                                    45.1\u00b10\u03bcs\r\n"]
[103.999231, "o", "[40.00%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaConstructor.time_from_unit\u001b[0m                                                                                      17.3\u00b10\u03bcs\r\n"]
[104.189385, "o", "[42.50%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up tslibs.timedelta:56\u001b[0m                                                                                                                  ok\r\n"]
[104.379538, "o", "[42.50%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaProperties.time_timedelta_days\u001b[0m                                                                                  12.1\u00b10\u03bcs\r\n"]
[104.569692, "o", "[45.00%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaProperties.time_timedelta_microseconds\u001b[0m                                                                          13.3\u00b10\u03bcs\r\n"]
[104.759846, "o", "[47.50%] \u00b7\u00b7\u00b7 \u001b[0;39mtslibs.timedelta.TimedeltaProperties.time_timedelta_nanoseconds\u001b[0m                                                                           14.8\u00b10\u03bcs\r\n"]
[105.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[105.002, "i", "cd ..\r"]
[105.004, "o", "cd ..\r\n"]
[105.006, "o", "\u001b[?2004l\r\n"]
[110.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[110.002, "i", "grep -RIn \"hash_pandas_object\\|hash_array\\|hashing\" pandas | head -n 50\r"]
[110.004, "o", "grep -RIn \"hash_pandas_object\\|hash_array\\|hashing\" pandas | head -n 50\r\n"]
[110.102941, "o", "\u001b[?2004l\r\n"]
[110.199882, "o", "pandas/tests/api/test_api.py:376:            [\"hash_array\", \"hash_pandas_object\"],\r\n"]
[110.296824, "o", "pandas/tests/groupby/test_groupby_dropna.py:455:    # issues with hashing np.nan\r\n"]
[110.393765, "o", "pandas/tests/extension/test_interval.py:107:    def test_hash_pandas_object(self, data):\r\n"]
[110.490706, "o", "pandas/tests/extension/test_interval.py:108:        super().test_hash_pandas_object(data)\r\n"]
[110.587647, "o", "pandas/tests/extension/test_interval.py:113:    def test_hash_pandas_object_works(self, data, as_frame):\r\n"]
[110.684588, "o", "pandas/tests/extension/test_interval.py:114:        super().test_hash_pandas_object_works(data, as_frame)\r\n"]
[110.781529, "o", "pandas/tests/extension/base/methods.py:21:    def test_hash_pandas_object(self, data):\r\n"]
[110.878471, "o", "pandas/tests/extension/base/methods.py:22:        # _hash_pandas_object should return a uint64 ndarray of the same length\r\n"]
[110.975412, "o", "pandas/tests/extension/base/methods.py:24:        from pandas.core.util.hashing import _default_hash_key\r\n"]
[111.072353, "o", "pandas/tests/extension/base/methods.py:26:        res = data._hash_pandas_object(\r\n"]
[111.169294, "o", "pandas/tests/extension/base/methods.py:509:    def test_hash_pandas_object_works(self, data, as_frame):\r\n"]
[111.266235, "o", "pandas/tests/extension/base/methods.py:514:        a = pd.util.hash_pandas_object(data)\r\n"]
[111.363176, "o", "pandas/tests/extension/base/methods.py:515:        b = pd.util.hash_pandas_object(data)\r\n"]
[111.460118, "o", "pandas/tests/util/test_hashing.py:14:from pandas.core.util.hashing import hash_tuples\r\n"]
[111.557059, "o", "pandas/tests/util/test_hashing.py:16:    hash_array,\r\n"]
[111.654, "o", "pandas/tests/util/test_hashing.py:17:    hash_pandas_object,\r\n"]
[111.750941, "o", "pandas/tests/util/test_hashing.py:45:    result = hash_pandas_object(Index([\"foo\", \"bar\", \"baz\"]))\r\n"]
[111.847882, "o", "pandas/tests/util/test_hashing.py:56:def test_hash_array(series):\r\n"]
[111.944824, "o", "pandas/tests/util/test_hashing.py:58:    tm.assert_numpy_array_equal(hash_array(arr), hash_array(arr))\r\n"]
[112.041765, "o", "pandas/tests/util/test_hashing.py:62:def test_hash_array_mixed(dtype):\r\n"]
[112.138706, "o", "pandas/tests/util/test_hashing.py:63:    result1 = hash_array(np.array([\"3\", \"4\", \"All\"]))\r\n"]
[112.235647, "o", "pandas/tests/util/test_hashing.py:64:    result2 = hash_array(np.array([3, 4, \"All\"], dtype=dtype))\r\n"]
[112.332588, "o", "pandas/tests/util/test_hashing.py:70:def test_hash_array_errors(val):\r\n"]
[112.429529, "o", "pandas/tests/util/test_hashing.py:73:        hash_array(val)\r\n"]
[112.526471, "o", "pandas/tests/util/test_hashing.py:76:def test_hash_array_index_exception():\r\n"]
[112.623412, "o", "pandas/tests/util/test_hashing.py:80:    msg = \"Use hash_pandas_object instead\"\r\n"]
[112.720353, "o", "pandas/tests/util/test_hashing.py:82:        hash_array(obj)\r\n"]
[112.817294, "o", "pandas/tests/util/test_hashing.py:89:    expected = hash_pandas_object(MultiIndex.from_tuples(tuples)).values\r\n"]
[112.914235, "o", "pandas/tests/util/test_hashing.py:109:    result = hash_pandas_object(mi)\r\n"]
[113.011176, "o", "pandas/tests/util/test_hashing.py:155:def test_hash_pandas_object(obj, index):\r\n"]
[113.108118, "o", "pandas/tests/util/test_hashing.py:156:    a = hash_pandas_object(obj, index=index)\r\n"]
[113.205059, "o", "pandas/tests/util/test_hashing.py:157:    b = hash_pandas_object(obj, index=index)\r\n"]
[113.302, "o", "pandas/tests/util/test_hashing.py:188:def test_hash_pandas_object_diff_index_non_empty(obj):\r\n"]
[113.398941, "o", "pandas/tests/util/test_hashing.py:189:    a = hash_pandas_object(obj, index=True)\r\n"]
[113.495882, "o", "pandas/tests/util/test_hashing.py:190:    b = hash_pandas_object(obj, index=False)\r\n"]
[113.592824, "o", "pandas/tests/util/test_hashing.py:208:    a = hash_pandas_object(obj, index=index)\r\n"]
[113.689765, "o", "pandas/tests/util/test_hashing.py:209:    b = hash_pandas_object(obj, index=index)\r\n"]
[113.786706, "o", "pandas/tests/util/test_hashing.py:214:    a = hash_pandas_object(series, index=index)\r\n"]
[113.883647, "o", "pandas/tests/util/test_hashing.py:215:    b = hash_pandas_object(series, index=index)\r\n"]
[113.980588, "o", "pandas/tests/util/test_hashing.py:220:    a = hash_pandas_object(series, index=True)\r\n"]
[114.077529, "o", "pandas/tests/util/test_hashing.py:221:    b = hash_pandas_object(series, index=False)\r\n"]
[114.174471, "o", "pandas/tests/util/test_hashing.py:231:    a = hash_pandas_object(obj, index=index)\r\n"]
[114.271412, "o", "pandas/tests/util/test_hashing.py:232:    b = hash_pandas_object(obj, index=index)\r\n"]
[114.368353, "o", "pandas/tests/util/test_hashing.py:255:    h1 = hash_pandas_object(s1, categorize=categorize)\r\n"]
[114.465294, "o", "pandas/tests/util/test_hashing.py:256:    h2 = hash_pandas_object(s2, categorize=categorize)\r\n"]
[114.562235, "o", "pandas/tests/util/test_hashing.py:257:    h3 = hash_pandas_object(s3, categorize=categorize)\r\n"]
[114.659176, "o", "pandas/tests/util/test_hashing.py:266:    expected = hash_array(cat, categorize=False)\r\n"]
[114.756118, "o", "pandas/tests/util/test_hashing.py:270:    result = hash_array(cat2, categorize=False)\r\n"]
[114.853059, "o", "pandas/tests/util/test_hashing.py:277:    msg = \"Unexpected type for hashing\"\r\n"]
[115.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[115.002, "i", "grep -RIn \"def hash_pandas_object\\|class .*Hash\" pandas | head -n 50\r"]
[115.004, "o", "grep -RIn \"def hash_pandas_object\\|class .*Hash\" pandas | head -n 50\r\n"]
[115.118364, "o", "\u001b[?2004l\r\n"]
[115.230727, "o", "pandas/io/parsers/readers.py:98:    class _read_shared(TypedDict, Generic[HashableT], total=False):\r\n"]
[115.343091, "o", "pandas/tests/dtypes/test_inference.py:435:    class HashableClass:\r\n"]
[115.455455, "o", "pandas/tests/test_algos.py:1684:class TestHashTable:\r\n"]
[115.567818, "o", "pandas/tests/libs/test_hashtable.py:54:class TestHashTable:\r\n"]
[115.680182, "o", "pandas/tests/libs/test_hashtable.py:265:class TestHashTableUnsorted:\r\n"]
[115.792545, "o", "pandas/tests/libs/test_hashtable.py:385:class TestPyObjectHashTableWithNans:\r\n"]
[115.904909, "o", "pandas/tests/libs/test_hashtable.py:544:class TestHashTableWithNans:\r\n"]
[116.017273, "o", "pandas/core/util/hashing.py:84:def hash_pandas_object(\r\n"]
[116.129636, "o", "pandas/_libs/hashtable.pxd:39:cdef class HashTable:\r\n"]
[116.242, "o", "pandas/_libs/hashtable.pxd:42:cdef class UInt64HashTable(HashTable):\r\n"]
[116.354364, "o", "pandas/_libs/hashtable.pxd:52:cdef class Int64HashTable(HashTable):\r\n"]
[116.466727, "o", "pandas/_libs/hashtable.pxd:62:cdef class UInt32HashTable(HashTable):\r\n"]
[116.579091, "o", "pandas/_libs/hashtable.pxd:72:cdef class Int32HashTable(HashTable):\r\n"]
[116.691455, "o", "pandas/_libs/hashtable.pxd:82:cdef class UInt16HashTable(HashTable):\r\n"]
[116.803818, "o", "pandas/_libs/hashtable.pxd:92:cdef class Int16HashTable(HashTable):\r\n"]
[116.916182, "o", "pandas/_libs/hashtable.pxd:102:cdef class UInt8HashTable(HashTable):\r\n"]
[117.028545, "o", "pandas/_libs/hashtable.pxd:112:cdef class Int8HashTable(HashTable):\r\n"]
[117.140909, "o", "pandas/_libs/hashtable.pxd:122:cdef class Float64HashTable(HashTable):\r\n"]
[117.253273, "o", "pandas/_libs/hashtable.pxd:132:cdef class Float32HashTable(HashTable):\r\n"]
[117.365636, "o", "pandas/_libs/hashtable.pxd:142:cdef class Complex64HashTable(HashTable):\r\n"]
[117.478, "o", "pandas/_libs/hashtable.pxd:152:cdef class Complex128HashTable(HashTable):\r\n"]
[117.590364, "o", "pandas/_libs/hashtable.pxd:162:cdef class PyObjectHashTable(HashTable):\r\n"]
[117.702727, "o", "pandas/_libs/hashtable.pxd:169:cdef class StringHashTable(HashTable):\r\n"]
[117.815091, "o", "pandas/_libs/hashtable.pyi:154:class HashTable:\r\n"]
[117.927455, "o", "pandas/_libs/hashtable.pyi:226:class Complex128HashTable(HashTable): ...\r\n"]
[118.039818, "o", "pandas/_libs/hashtable.pyi:227:class Complex64HashTable(HashTable): ...\r\n"]
[118.152182, "o", "pandas/_libs/hashtable.pyi:228:class Float64HashTable(HashTable): ...\r\n"]
[118.264545, "o", "pandas/_libs/hashtable.pyi:229:class Float32HashTable(HashTable): ...\r\n"]
[118.376909, "o", "pandas/_libs/hashtable.pyi:231:class Int64HashTable(HashTable):\r\n"]
[118.489273, "o", "pandas/_libs/hashtable.pyi:243:class Int32HashTable(HashTable): ...\r\n"]
[118.601636, "o", "pandas/_libs/hashtable.pyi:244:class Int16HashTable(HashTable): ...\r\n"]
[118.714, "o", "pandas/_libs/hashtable.pyi:245:class Int8HashTable(HashTable): ...\r\n"]
[118.826364, "o", "pandas/_libs/hashtable.pyi:246:class UInt64HashTable(HashTable): ...\r\n"]
[118.938727, "o", "pandas/_libs/hashtable.pyi:247:class UInt32HashTable(HashTable): ...\r\n"]
[119.051091, "o", "pandas/_libs/hashtable.pyi:248:class UInt16HashTable(HashTable): ...\r\n"]
[119.163455, "o", "pandas/_libs/hashtable.pyi:249:class UInt8HashTable(HashTable): ...\r\n"]
[119.275818, "o", "pandas/_libs/hashtable.pyi:250:class StringHashTable(HashTable): ...\r\n"]
[119.388182, "o", "pandas/_libs/hashtable.pyi:251:class PyObjectHashTable(HashTable): ...\r\n"]
[119.500545, "o", "pandas/_libs/hashtable.pyi:252:class IntpHashTable(HashTable): ...\r\n"]
[119.612909, "o", "pandas/_libs/hashtable_class_helper.pxi.in:368:cdef class HashTable:\r\n"]
[119.725273, "o", "pandas/_libs/hashtable_class_helper.pxi.in:393:cdef class {{name}}HashTable(HashTable):\r\n"]
[119.837636, "o", "pandas/_libs/hashtable_class_helper.pxi.in:962:cdef class StringHashTable(HashTable):\r\n"]
[120.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[120.002, "i", "sed -n '1,200p' pandas/util/_hashing.py 2>/dev/null || sed -n '1,200p' pandas/util/hash_pandas_object.py 2>/dev/nul\r"]
[120.004, "o", "sed -n '1,200p' pandas/util/_hashing.py 2>/dev/null || sed -n '1,200p' pandas/util/hash_pandas_object.py 2>/dev/nul\r\n"]
[122.478, "o", "ll || sed -n '1,200p' pandas/tools/hashing.py 2>/dev/null\r\n"]
[125.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[125.002, "i", "cd asv_bench\r"]
[125.004, "o", "cd asv_bench\r\n"]
[125.006, "o", "\u001b[?2004l\r\n"]
[130.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[130.002, "i", "asv profile --python=same algorithms.Hashing.time_series_string\r"]
[130.004, "o", "asv profile --python=same algorithms.Hashing.time_series_string\r\n"]
[130.030844, "o", "\u001b[?2004l\r\n"]
[130.055688, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[130.080533, "o", "\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n"]
[130.105377, "o", "\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[130.130221, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n"]
[130.155065, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n"]
[130.17991, "o", "\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   8.32\u00b10.4ms\r\n"]
[130.204754, "o", "\r\n"]
[130.229598, "o", "Wed Oct  1 17:09:42 2025    /tmp/tmpjto1_y1k\r\n"]
[130.254442, "o", "\r\n"]
[130.279286, "o", "         798 function calls (782 primitive calls) in 0.010 seconds\r\n"]
[130.304131, "o", "\r\n"]
[130.328975, "o", "   Ordered by: cumulative time\r\n"]
[130.353819, "o", "\r\n"]
[130.378663, "o", "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n"]
[130.403508, "o", "        1    0.000    0.000    0.010    0.010 {built-in method builtins.exec}\r\n"]
[130.428352, "o", "        1    0.000    0.000    0.010    0.010 _base.py:689(method_caller)\r\n"]
[130.453196, "o", "        1    0.000    0.000    0.010    0.010 algorithms.py:160(time_series_string)\r\n"]
[130.47804, "o", "      2/1    0.000    0.000    0.010    0.010 hashing.py:84(hash_pandas_object)\r\n"]
[130.502884, "o", "      3/2    0.000    0.000    0.009    0.005 hashing.py:235(hash_array)\r\n"]
[130.527729, "o", "      3/2    0.001    0.000    0.009    0.005 hashing.py:290(_hash_ndarray)\r\n"]
[130.552573, "o", "        1    0.000    0.000    0.006    0.006 algorithms.py:639(factorize)\r\n"]
[130.577417, "o", "        1    0.006    0.006    0.006    0.006 algorithms.py:577(factorize_array)\r\n"]
[130.602261, "o", "        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n"]
[130.627106, "o", "        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n"]
[130.65195, "o", "        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n"]
[130.676794, "o", "        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n"]
[130.701638, "o", "        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n"]
[130.726482, "o", "        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n"]
[130.751327, "o", "        1    0.000    0.000    0.001    0.001 base.py:2406(is_unique)\r\n"]
[130.776171, "o", "        2    0.000    0.000    0.000    0.000 series.py:369(__init__)\r\n"]
[130.801015, "o", "        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n"]
[130.825859, "o", "        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n"]
[130.850704, "o", "        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n"]
[130.875548, "o", "        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n"]
[130.900392, "o", "        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n"]
[130.925236, "o", "        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n"]
[130.95008, "o", "        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n"]
[130.974925, "o", "        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n"]
[130.999769, "o", "        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n"]
[131.024613, "o", "        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n"]
[131.049457, "o", "        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n"]
[131.074302, "o", "        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n"]
[131.099146, "o", "  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n"]
[131.12399, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n"]
[131.148834, "o", "        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n"]
[131.173678, "o", "        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n"]
[131.198523, "o", "        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n"]
[131.223367, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n"]
[131.248211, "o", "        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n"]
[131.273055, "o", "       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n"]
[131.297899, "o", "        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n"]
[131.322744, "o", "        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n"]
[131.347588, "o", "        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n"]
[131.372432, "o", "        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n"]
[131.397276, "o", "        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n"]
[131.422121, "o", "        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n"]
[131.446965, "o", "        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n"]
[131.471809, "o", "        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n"]
[131.496653, "o", "        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n"]
[131.521497, "o", "        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n"]
[131.546342, "o", "        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n"]
[131.571186, "o", "        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n"]
[131.59603, "o", "       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n"]
[131.620874, "o", "        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n"]
[131.645719, "o", "       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n"]
[131.670563, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n"]
[131.695407, "o", "        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n"]
[131.720251, "o", "        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n"]
[131.745095, "o", "        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n"]
[131.76994, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n"]
[131.794784, "o", "        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n"]
[131.819628, "o", "        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n"]
[131.844472, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n"]
[131.869317, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n"]
[131.894161, "o", "        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n"]
[131.919005, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n"]
[131.943849, "o", "        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n"]
[131.968693, "o", "        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n"]
[131.993538, "o", "        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n"]
[132.018382, "o", "        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n"]
[132.043226, "o", "    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n"]
[132.06807, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n"]
[132.092915, "o", "        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n"]
[132.117759, "o", "        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n"]
[132.142603, "o", "        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n"]
[132.167447, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n"]
[132.192291, "o", "        2    0.000    0.000    0.000    0.000 series.py:737(name)\r\n"]
[132.217136, "o", "        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n"]
[132.24198, "o", "        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n"]
[132.266824, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n"]
[132.291668, "o", "        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n"]
[132.316513, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2232(new_block)\r\n"]
[132.341357, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n"]
[132.366201, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n"]
[132.391045, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n"]
[132.415889, "o", "        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n"]
[132.440734, "o", "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n"]
[132.465578, "o", "        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n"]
[132.490422, "o", "       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n"]
[132.515266, "o", "        2    0.000    0.000    0.000    0.000 series.py:686(name)\r\n"]
[132.540111, "o", "        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n"]
[132.564955, "o", "        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n"]
[132.589799, "o", "        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n"]
[132.614643, "o", "        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n"]
[132.639487, "o", "       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n"]
[132.664332, "o", "        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n"]
[132.689176, "o", "        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n"]
[132.71402, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2161(maybe_coerce_values)\r\n"]
[132.738864, "o", "        2    0.000    0.000    0.000    0.000 series.py:783(_values)\r\n"]
[132.763709, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n"]
[132.788553, "o", "        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n"]
[132.813397, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n"]
[132.838241, "o", "        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n"]
[132.863085, "o", "        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n"]
[132.88793, "o", "        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n"]
[132.912774, "o", "        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n"]
[132.937618, "o", "        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n"]
[132.962462, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n"]
[132.987307, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n"]
[133.012151, "o", "        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n"]
[133.036995, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n"]
[133.061839, "o", "        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n"]
[133.086683, "o", "        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n"]
[133.111528, "o", "        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n"]
[133.136372, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2190(get_block_type)\r\n"]
[133.161216, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n"]
[133.18606, "o", "        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n"]
[133.210905, "o", "        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n"]
[133.235749, "o", "        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n"]
[133.260593, "o", "        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n"]
[133.285437, "o", "        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n"]
[133.310281, "o", "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n"]
[133.335126, "o", "        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n"]
[133.35997, "o", "        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n"]
[133.384814, "o", "        1    0.000    0.000    0.000    0.000 indexing.py:2746(check_dict_or_set_indexers)\r\n"]
[133.409658, "o", "        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n"]
[133.434503, "o", "        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n"]
[133.459347, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n"]
[133.484191, "o", "       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n"]
[133.509035, "o", "        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n"]
[133.533879, "o", "        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n"]
[133.558724, "o", "        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n"]
[133.583568, "o", "        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n"]
[133.608412, "o", "        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n"]
[133.633256, "o", "        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n"]
[133.658101, "o", "        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n"]
[133.682945, "o", "        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n"]
[133.707789, "o", "        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n"]
[133.732633, "o", "       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n"]
[133.757477, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n"]
[133.782322, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n"]
[133.807166, "o", "        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n"]
[133.83201, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n"]
[133.856854, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n"]
[133.881698, "o", "        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n"]
[133.906543, "o", "        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n"]
[133.931387, "o", "        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n"]
[133.956231, "o", "        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n"]
[133.981075, "o", "        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n"]
[134.00592, "o", "        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n"]
[134.030764, "o", "        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n"]
[134.055608, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n"]
[134.080452, "o", "        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n"]
[134.105296, "o", "        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n"]
[134.130141, "o", "        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n"]
[134.154985, "o", "        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n"]
[134.179829, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n"]
[134.204673, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n"]
[134.229518, "o", "        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n"]
[134.254362, "o", "        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n"]
[134.279206, "o", "        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n"]
[134.30405, "o", "        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55a26d8ee640}\r\n"]
[134.328894, "o", "        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n"]
[134.353739, "o", "        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n"]
[134.378583, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n"]
[134.403427, "o", "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n"]
[134.428271, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n"]
[134.453116, "o", "        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n"]
[134.47796, "o", "        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n"]
[134.502804, "o", "        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n"]
[134.527648, "o", "        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n"]
[134.552492, "o", "        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n"]
[134.577337, "o", "        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n"]
[134.602181, "o", "        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n"]
[134.627025, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n"]
[134.651869, "o", "        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n"]
[134.676714, "o", "        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n"]
[134.701558, "o", "        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n"]
[134.726402, "o", "        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n"]
[134.751246, "o", "        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n"]
[134.77609, "o", "        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n"]
[134.800935, "o", "        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n"]
[134.825779, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n"]
[134.850623, "o", "        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n"]
[134.875467, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n"]
[134.900312, "o", "        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n"]
[134.925156, "o", "\r\n"]
[135.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[135.002, "i", "ls -la pandas/core/util\r"]
[135.004, "o", "ls -la pandas/core/util\r\n"]
[137.478, "o", "\u001b[?2004l\r\n"]
[140.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[140.002, "i", "sed -n '1,240p' pandas/core/util/hashing.py\r"]
[140.004, "o", "sed -n '1,240p' pandas/core/util/hashing.py\r\n"]
[142.478, "o", "\u001b[?2004l\r\n"]
[145.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[145.002, "i", "sed -n '240,520p' pandas/core/util/hashing.py\r"]
[145.004, "o", "sed -n '240,520p' pandas/core/util/hashing.py\r\n"]
[147.478, "o", "\u001b[?2004l\r\n"]
[150.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[150.002, "i", "git checkout -b opt/hash-string-memo\r"]
[150.004, "o", "git checkout -b opt/hash-string-memo\r\n"]
[152.478, "o", "\u001b[?2004l\r\n"]
[155.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[155.002, "i", "python - << 'PY'\r"]
[155.004, "o", "python - << 'PY'\r\n"]
[155.359143, "o", "\u001b[?2004l\r\n"]
[155.712286, "o", "\u001b[?2004h> import io,sys\r\n"]
[156.065429, "o", "\u001b[?2004l\r\n"]
[156.418571, "o", "\u001b[?2004h> p='pandas/core/util/hashing.py'\r\n"]
[156.771714, "o", "\u001b[?2004l\r\n"]
[157.124857, "o", "\u001b[?2004h> s=open(p, 'r', encoding='utf-8').read()\r\n"]
[157.478, "o", "\u001b[?2004l\r\n"]
[157.831143, "o", "\u001b[?2004h> print(p, 'loaded', len(s))\r\n"]
[158.184286, "o", "\u001b[?2004l\r\n"]
[158.537429, "o", "\u001b[?2004h> PY\r\n"]
[158.890571, "o", "\u001b[?2004l\r\n"]
[159.243714, "o", "Traceback (most recent call last):\r\n"]
[159.596857, "o", "  File \"<stdin>\", line 3, in <module>\r\n"]
[160.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[160.002, "i", "python - << 'PY'\r"]
[160.004, "o", "python - << 'PY'\r\n"]
[160.151412, "o", "\u001b[?2004l\r\n"]
[160.296824, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[160.442235, "o", "\u001b[?2004l\r\n"]
[160.587647, "o", "\u001b[?2004h> p=Path('pandas/core/util/hashing.py')\r\n"]
[160.733059, "o", "\u001b[?2004l\r\n"]
[160.878471, "o", "\u001b[?2004h> s=p.read_text(encoding='utf-8')\r\n"]
[161.023882, "o", "\u001b[?2004l\r\n"]
[161.169294, "o", "\u001b[?2004h> # Attempt a targeted patch: add memoization for object arrays of pure strings in hash_object_array or equivalent function\r\n"]
[161.314706, "o", "\u001b[?2004l\r\n"]
[161.460118, "o", "\u001b[?2004h> new=s\r\n"]
[161.605529, "o", "\u001b[?2004l\r\n"]
[161.750941, "o", "\u001b[?2004h> import re\r\n"]
[161.896353, "o", "\u001b[?2004l\r\n"]
[162.041765, "o", "\u001b[?2004h> # We'll look for a function named hash_object_array or similar to patch\r\n"]
[162.187176, "o", "\u001b[?2004l\r\n"]
[162.332588, "o", "\u001b[?2004h> m=re.search(r\"def\\s+hash_object_array\\s*\\(.*?\\):\", s)\r\n"]
[162.478, "o", "\u001b[?2004l\r\n"]
[162.623412, "o", "\u001b[?2004h> if not m:\r\n"]
[162.768824, "o", "\u001b[?2004l\r\n"]
[162.914235, "o", "\u001b[?2004h>     m=re.search(r\"def\\s+hash_array\\s*\\(.*?\\):\", s)\r\n"]
[163.059647, "o", "\u001b[?2004l\r\n"]
[163.205059, "o", "\u001b[?2004h> print('found func at', m.start() if m else None)\r\n"]
[163.350471, "o", "\u001b[?2004l\r\n"]
[163.495882, "o", "\u001b[?2004h> print(s[:2000])\r\n"]
[163.641294, "o", "\u001b[?2004l\r\n"]
[163.786706, "o", "\u001b[?2004h> PY\r\n"]
[163.932118, "o", "\u001b[?2004l\r\n"]
[164.077529, "o", "Traceback (most recent call last):\r\n"]
[164.222941, "o", "  File \"<stdin>\", line 3, in <module>\r\n"]
[164.368353, "o", "  File \"/opt/conda/envs/asv_3.10/lib/python3.10/pathlib.py\", line 1134, in read_text\r\n"]
[164.513765, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[164.659176, "o", "  File \"/opt/conda/envs/asv_3.10/lib/python3.10/pathlib.py\", line 1119, in open\r\n"]
[164.804588, "o", "    return self._accessor.open(self, mode, buffering, encoding, errors,\r\n"]
[165.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[165.002, "i", "cd ..\r"]
[165.004, "o", "cd ..\r\n"]
[165.006, "o", "\u001b[?2004l\r\n"]
[170.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[170.002, "i", "grep -RIn \"def hash_pandas_object\\(|def hash_array\\(|hash_object_array\" pandas | head -n 50\r"]
[170.004, "o", "grep -RIn \"def hash_pandas_object\\(|def hash_array\\(|hash_object_array\" pandas | head -n 50\r\n"]
[172.478, "o", "\u001b[?2004l\r\n"]
[175.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[175.002, "i", "grep -RIn \"hash_pandas_object\" pandas | head -n 100\r"]
[175.004, "o", "grep -RIn \"hash_pandas_object\" pandas | head -n 100\r\n"]
[175.071053, "o", "\u001b[?2004l\r\n"]
[175.136105, "o", "pandas/tests/api/test_api.py:376:            [\"hash_array\", \"hash_pandas_object\"],\r\n"]
[175.201158, "o", "pandas/tests/extension/test_interval.py:107:    def test_hash_pandas_object(self, data):\r\n"]
[175.266211, "o", "pandas/tests/extension/test_interval.py:108:        super().test_hash_pandas_object(data)\r\n"]
[175.331263, "o", "pandas/tests/extension/test_interval.py:113:    def test_hash_pandas_object_works(self, data, as_frame):\r\n"]
[175.396316, "o", "pandas/tests/extension/test_interval.py:114:        super().test_hash_pandas_object_works(data, as_frame)\r\n"]
[175.461368, "o", "pandas/tests/extension/base/methods.py:21:    def test_hash_pandas_object(self, data):\r\n"]
[175.526421, "o", "pandas/tests/extension/base/methods.py:22:        # _hash_pandas_object should return a uint64 ndarray of the same length\r\n"]
[175.591474, "o", "pandas/tests/extension/base/methods.py:26:        res = data._hash_pandas_object(\r\n"]
[175.656526, "o", "pandas/tests/extension/base/methods.py:509:    def test_hash_pandas_object_works(self, data, as_frame):\r\n"]
[175.721579, "o", "pandas/tests/extension/base/methods.py:514:        a = pd.util.hash_pandas_object(data)\r\n"]
[175.786632, "o", "pandas/tests/extension/base/methods.py:515:        b = pd.util.hash_pandas_object(data)\r\n"]
[175.851684, "o", "pandas/tests/util/test_hashing.py:17:    hash_pandas_object,\r\n"]
[175.916737, "o", "pandas/tests/util/test_hashing.py:45:    result = hash_pandas_object(Index([\"foo\", \"bar\", \"baz\"]))\r\n"]
[175.981789, "o", "pandas/tests/util/test_hashing.py:80:    msg = \"Use hash_pandas_object instead\"\r\n"]
[176.046842, "o", "pandas/tests/util/test_hashing.py:89:    expected = hash_pandas_object(MultiIndex.from_tuples(tuples)).values\r\n"]
[176.111895, "o", "pandas/tests/util/test_hashing.py:109:    result = hash_pandas_object(mi)\r\n"]
[176.176947, "o", "pandas/tests/util/test_hashing.py:155:def test_hash_pandas_object(obj, index):\r\n"]
[176.242, "o", "pandas/tests/util/test_hashing.py:156:    a = hash_pandas_object(obj, index=index)\r\n"]
[176.307053, "o", "pandas/tests/util/test_hashing.py:157:    b = hash_pandas_object(obj, index=index)\r\n"]
[176.372105, "o", "pandas/tests/util/test_hashing.py:188:def test_hash_pandas_object_diff_index_non_empty(obj):\r\n"]
[176.437158, "o", "pandas/tests/util/test_hashing.py:189:    a = hash_pandas_object(obj, index=True)\r\n"]
[176.502211, "o", "pandas/tests/util/test_hashing.py:190:    b = hash_pandas_object(obj, index=False)\r\n"]
[176.567263, "o", "pandas/tests/util/test_hashing.py:208:    a = hash_pandas_object(obj, index=index)\r\n"]
[176.632316, "o", "pandas/tests/util/test_hashing.py:209:    b = hash_pandas_object(obj, index=index)\r\n"]
[176.697368, "o", "pandas/tests/util/test_hashing.py:214:    a = hash_pandas_object(series, index=index)\r\n"]
[176.762421, "o", "pandas/tests/util/test_hashing.py:215:    b = hash_pandas_object(series, index=index)\r\n"]
[176.827474, "o", "pandas/tests/util/test_hashing.py:220:    a = hash_pandas_object(series, index=True)\r\n"]
[176.892526, "o", "pandas/tests/util/test_hashing.py:221:    b = hash_pandas_object(series, index=False)\r\n"]
[176.957579, "o", "pandas/tests/util/test_hashing.py:231:    a = hash_pandas_object(obj, index=index)\r\n"]
[177.022632, "o", "pandas/tests/util/test_hashing.py:232:    b = hash_pandas_object(obj, index=index)\r\n"]
[177.087684, "o", "pandas/tests/util/test_hashing.py:255:    h1 = hash_pandas_object(s1, categorize=categorize)\r\n"]
[177.152737, "o", "pandas/tests/util/test_hashing.py:256:    h2 = hash_pandas_object(s2, categorize=categorize)\r\n"]
[177.217789, "o", "pandas/tests/util/test_hashing.py:257:    h3 = hash_pandas_object(s3, categorize=categorize)\r\n"]
[177.282842, "o", "pandas/tests/util/test_hashing.py:279:        hash_pandas_object(pd.Timestamp(\"20130101\"))\r\n"]
[177.347895, "o", "pandas/tests/util/test_hashing.py:289:    a = hash_pandas_object(obj, hash_key=\"9876543210123456\")\r\n"]
[177.412947, "o", "pandas/tests/util/test_hashing.py:290:    b = hash_pandas_object(obj, hash_key=\"9876543210123465\")\r\n"]
[177.478, "o", "pandas/tests/util/test_hashing.py:300:    a = hash_pandas_object(obj, hash_key=\"9876543210123456\")\r\n"]
[177.543053, "o", "pandas/tests/util/test_hashing.py:301:    b = hash_pandas_object(obj, hash_key=\"9876543210123465\")\r\n"]
[177.608105, "o", "pandas/tests/util/test_hashing.py:312:    a = hash_pandas_object(obj, encoding=\"utf8\")\r\n"]
[177.673158, "o", "pandas/tests/util/test_hashing.py:313:    b = hash_pandas_object(obj, encoding=\"utf7\")\r\n"]
[177.738211, "o", "pandas/tests/util/test_hashing.py:326:        hash_pandas_object(Series(list(\"abc\")), hash_key=\"foo\")\r\n"]
[177.803263, "o", "pandas/tests/util/test_hashing.py:332:    a = hash_pandas_object(obj, index=index)\r\n"]
[177.868316, "o", "pandas/tests/util/test_hashing.py:333:    b = hash_pandas_object(obj, index=index)\r\n"]
[177.933368, "o", "pandas/tests/util/test_hashing.py:339:    a = hash_pandas_object(obj, index=index)\r\n"]
[177.998421, "o", "pandas/tests/util/test_hashing.py:340:    b = hash_pandas_object(obj, index=index)\r\n"]
[178.063474, "o", "pandas/tests/util/test_hashing.py:388:    result = hash_pandas_object(df)\r\n"]
[178.128526, "o", "pandas/tests/util/test_hashing.py:411:        hash_pandas_object(df3)\r\n"]
[178.193579, "o", "pandas/tests/util/test_hashing.py:416:    result = pd.util.hash_pandas_object(Series([\"a\", \"b\"]), hash_key=None)\r\n"]
[178.258632, "o", "pandas/core/util/hashing.py:84:def hash_pandas_object(\r\n"]
[178.323684, "o", "pandas/core/util/hashing.py:114:    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[178.388737, "o", "pandas/core/util/hashing.py:140:                hash_pandas_object(\r\n"]
[178.453789, "o", "pandas/core/util/hashing.py:162:                hash_pandas_object(\r\n"]
[178.518842, "o", "pandas/core/util/hashing.py:227:        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[178.583895, "o", "pandas/core/util/hashing.py:263:    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[178.648947, "o", "pandas/core/util/hashing.py:276:        return vals._hash_pandas_object(\r\n"]
[178.714, "o", "pandas/core/util/hashing.py:284:            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[178.779053, "o", "pandas/core/util/hashing.py:329:            return cat._hash_pandas_object(\r\n"]
[178.844105, "o", "pandas/core/arrays/masked.py:911:    def _hash_pandas_object(\r\n"]
[178.909158, "o", "pandas/core/arrays/base.py:155:    _hash_pandas_object\r\n"]
[178.974211, "o", "pandas/core/arrays/base.py:302:        api.extensions.ExtensionArray._hash_pandas_object : Hook for\r\n"]
[179.039263, "o", "pandas/core/arrays/base.py:303:            hash_pandas_object.\r\n"]
[179.104316, "o", "pandas/core/arrays/base.py:1576:        util.hash_pandas_object : Hash the pandas object.\r\n"]
[179.169368, "o", "pandas/core/arrays/base.py:1581:        :func:`pandas.util.hash_pandas_object`. If needed, this can be\r\n"]
[179.234421, "o", "pandas/core/arrays/base.py:1582:        overridden in the ``self._hash_pandas_object()`` method.\r\n"]
[179.299474, "o", "pandas/core/arrays/base.py:2226:    def _hash_pandas_object(\r\n"]
[179.364526, "o", "pandas/core/arrays/base.py:2230:        Hook for hash_pandas_object.\r\n"]
[179.429579, "o", "pandas/core/arrays/base.py:2257:        >>> pd.array([1, 2])._hash_pandas_object(\r\n"]
[179.494632, "o", "pandas/core/arrays/arrow/array.py:1192:        :func:`pandas.util.hash_pandas_object`.\r\n"]
[179.559684, "o", "pandas/core/arrays/sparse/array.py:879:        # Still override this for hash_pandas_object\r\n"]
[179.624737, "o", "pandas/core/arrays/_mixins.py:192:    def _hash_pandas_object(\r\n"]
[179.689789, "o", "pandas/core/arrays/categorical.py:2133:    def _hash_pandas_object(\r\n"]
[179.754842, "o", "pandas/util/__init__.py:7:    if key == \"hash_pandas_object\":\r\n"]
[179.819895, "o", "pandas/util/__init__.py:8:        from pandas.core.util.hashing import hash_pandas_object\r\n"]
[179.884947, "o", "pandas/util/__init__.py:10:        return hash_pandas_object\r\n"]
[180.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[180.002, "i", "find pandas -maxdepth 3 -type f -iname \"*hash*.py*\" -o -iname \"*hash*.pyx\" -o -iname \"*hash*.pxd\" | sed -n '1,120p'\r"]
[180.004, "o", "find pandas -maxdepth 3 -type f -iname \"*hash*.py*\" -o -iname \"*hash*.pyx\" -o -iname \"*hash*.pxd\" | sed -n '1,120p'\r\n"]
[180.455455, "o", "'\r\n"]
[180.904909, "o", "\u001b[?2004l\r\n"]
[181.354364, "o", "pandas/tests/util/test_hashing.py\r\n"]
[181.803818, "o", "pandas/tests/libs/test_hashtable.py\r\n"]
[182.253273, "o", "pandas/core/util/hashing.py\r\n"]
[182.702727, "o", "pandas/_libs/hashing.pyi\r\n"]
[183.152182, "o", "pandas/_libs/hashtable.pyx\r\n"]
[183.601636, "o", "pandas/_libs/hashtable.pxd\r\n"]
[184.051091, "o", "pandas/_libs/hashing.pyx\r\n"]
[184.500545, "o", "pandas/_libs/hashtable.pyi\r\n"]
[185.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[185.002, "i", "sed -n '1,240p' pandas/core/util/hashing.py 2>/dev/null || sed -n '1,240p' pandas/util/_hashing.py 2>/dev/null || s\r"]
[185.004, "o", "sed -n '1,240p' pandas/core/util/hashing.py 2>/dev/null || sed -n '1,240p' pandas/util/_hashing.py 2>/dev/null || s\r\n"]
[185.02643, "o", "sed -n '1,240p' pandas/core/util/_hashing.py 2>/dev/null\r\n"]
[185.04686, "o", "\u001b[?2004l\r\n"]
[185.067289, "o", "\"\"\"\r\n"]
[185.087719, "o", "data hash pandas / numpy objects\r\n"]
[185.108149, "o", "\"\"\"\r\n"]
[185.128579, "o", "\r\n"]
[185.149008, "o", "from __future__ import annotations\r\n"]
[185.169438, "o", "\r\n"]
[185.189868, "o", "import itertools\r\n"]
[185.210298, "o", "from typing import TYPE_CHECKING\r\n"]
[185.230727, "o", "\r\n"]
[185.251157, "o", "import numpy as np\r\n"]
[185.271587, "o", "\r\n"]
[185.292017, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[185.312446, "o", "\r\n"]
[185.332876, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[185.353306, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[185.373736, "o", "from pandas.core.dtypes.generic import (\r\n"]
[185.394165, "o", "    ABCDataFrame,\r\n"]
[185.414595, "o", "    ABCExtensionArray,\r\n"]
[185.435025, "o", "    ABCIndex,\r\n"]
[185.455455, "o", "    ABCMultiIndex,\r\n"]
[185.475884, "o", "    ABCSeries,\r\n"]
[185.496314, "o", ")\r\n"]
[185.516744, "o", "\r\n"]
[185.537174, "o", "if TYPE_CHECKING:\r\n"]
[185.557603, "o", "    from collections.abc import (\r\n"]
[185.578033, "o", "        Hashable,\r\n"]
[185.598463, "o", "        Iterable,\r\n"]
[185.618893, "o", "        Iterator,\r\n"]
[185.639322, "o", "    )\r\n"]
[185.659752, "o", "\r\n"]
[185.680182, "o", "    from pandas._typing import (\r\n"]
[185.700612, "o", "        ArrayLike,\r\n"]
[185.721041, "o", "        npt,\r\n"]
[185.741471, "o", "    )\r\n"]
[185.761901, "o", "\r\n"]
[185.782331, "o", "    from pandas import (\r\n"]
[185.80276, "o", "        DataFrame,\r\n"]
[185.82319, "o", "        Index,\r\n"]
[185.84362, "o", "        MultiIndex,\r\n"]
[185.86405, "o", "        Series,\r\n"]
[185.884479, "o", "    )\r\n"]
[185.904909, "o", "\r\n"]
[185.925339, "o", "\r\n"]
[185.945769, "o", "# 16 byte long hashing key\r\n"]
[185.966198, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[185.986628, "o", "\r\n"]
[186.007058, "o", "\r\n"]
[186.027488, "o", "def combine_hash_arrays(\r\n"]
[186.047917, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[186.068347, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[186.088777, "o", "    \"\"\"\r\n"]
[186.109207, "o", "    Parameters\r\n"]
[186.129636, "o", "    ----------\r\n"]
[186.150066, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[186.170496, "o", "    num_items : int\r\n"]
[186.190926, "o", "\r\n"]
[186.211355, "o", "    Returns\r\n"]
[186.231785, "o", "    -------\r\n"]
[186.252215, "o", "    np.ndarray[uint64]\r\n"]
[186.272645, "o", "\r\n"]
[186.293074, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[186.313504, "o", "    \"\"\"\r\n"]
[186.333934, "o", "    try:\r\n"]
[186.354364, "o", "        first = next(arrays)\r\n"]
[186.374793, "o", "    except StopIteration:\r\n"]
[186.395223, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[186.415653, "o", "\r\n"]
[186.436083, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[186.456512, "o", "\r\n"]
[186.476942, "o", "    mult = np.uint64(1000003)\r\n"]
[186.497372, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[186.517802, "o", "    last_i = 0\r\n"]
[186.538231, "o", "    for i, a in enumerate(arrays):\r\n"]
[186.558661, "o", "        inverse_i = num_items - i\r\n"]
[186.579091, "o", "        out ^= a\r\n"]
[186.599521, "o", "        out *= mult\r\n"]
[186.61995, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[186.64038, "o", "        last_i = i\r\n"]
[186.66081, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[186.68124, "o", "    out += np.uint64(97531)\r\n"]
[186.701669, "o", "    return out\r\n"]
[186.722099, "o", "\r\n"]
[186.742529, "o", "\r\n"]
[186.762959, "o", "def hash_pandas_object(\r\n"]
[186.783388, "o", "    obj: Index | DataFrame | Series,\r\n"]
[186.803818, "o", "    index: bool = True,\r\n"]
[186.824248, "o", "    encoding: str = \"utf8\",\r\n"]
[186.844678, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[186.865107, "o", "    categorize: bool = True,\r\n"]
[186.885537, "o", ") -> Series:\r\n"]
[186.905967, "o", "    \"\"\"\r\n"]
[186.926397, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[186.946826, "o", "\r\n"]
[186.967256, "o", "    Parameters\r\n"]
[186.987686, "o", "    ----------\r\n"]
[187.008116, "o", "    obj : Index, Series, or DataFrame\r\n"]
[187.028545, "o", "    index : bool, default True\r\n"]
[187.048975, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[187.069405, "o", "    encoding : str, default 'utf8'\r\n"]
[187.089835, "o", "        Encoding for data & key when strings.\r\n"]
[187.110264, "o", "    hash_key : str, default _default_hash_key\r\n"]
[187.130694, "o", "        Hash_key for string key to encode.\r\n"]
[187.151124, "o", "    categorize : bool, default True\r\n"]
[187.171554, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[187.191983, "o", "        efficient when the array contains duplicate values.\r\n"]
[187.212413, "o", "\r\n"]
[187.232843, "o", "    Returns\r\n"]
[187.253273, "o", "    -------\r\n"]
[187.273702, "o", "    Series of uint64\r\n"]
[187.294132, "o", "        Same length as the object.\r\n"]
[187.314562, "o", "\r\n"]
[187.334992, "o", "    Examples\r\n"]
[187.355421, "o", "    --------\r\n"]
[187.375851, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[187.396281, "o", "    0    14639053686158035780\r\n"]
[187.416711, "o", "    1     3869563279212530728\r\n"]
[187.43714, "o", "    2      393322362522515241\r\n"]
[187.45757, "o", "    dtype: uint64\r\n"]
[187.478, "o", "    \"\"\"\r\n"]
[187.49843, "o", "    from pandas import Series\r\n"]
[187.51886, "o", "\r\n"]
[187.539289, "o", "    if hash_key is None:\r\n"]
[187.559719, "o", "        hash_key = _default_hash_key\r\n"]
[187.580149, "o", "\r\n"]
[187.600579, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[187.621008, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[187.641438, "o", "\r\n"]
[187.661868, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[187.682298, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[187.702727, "o", "            \"uint64\", copy=False\r\n"]
[187.723157, "o", "        )\r\n"]
[187.743587, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[187.764017, "o", "\r\n"]
[187.784446, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[187.804876, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[187.825306, "o", "            \"uint64\", copy=False\r\n"]
[187.845736, "o", "        )\r\n"]
[187.866165, "o", "        if index:\r\n"]
[187.886595, "o", "            index_iter = (\r\n"]
[187.907025, "o", "                hash_pandas_object(\r\n"]
[187.927455, "o", "                    obj.index,\r\n"]
[187.947884, "o", "                    index=False,\r\n"]
[187.968314, "o", "                    encoding=encoding,\r\n"]
[187.988744, "o", "                    hash_key=hash_key,\r\n"]
[188.009174, "o", "                    categorize=categorize,\r\n"]
[188.029603, "o", "                )._values\r\n"]
[188.050033, "o", "                for _ in [None]\r\n"]
[188.070463, "o", "            )\r\n"]
[188.090893, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[188.111322, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[188.131752, "o", "\r\n"]
[188.152182, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[188.172612, "o", "\r\n"]
[188.193041, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[188.213471, "o", "        hashes = (\r\n"]
[188.233901, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[188.254331, "o", "            for _, series in obj.items()\r\n"]
[188.27476, "o", "        )\r\n"]
[188.29519, "o", "        num_items = len(obj.columns)\r\n"]
[188.31562, "o", "        if index:\r\n"]
[188.33605, "o", "            index_hash_generator = (\r\n"]
[188.356479, "o", "                hash_pandas_object(\r\n"]
[188.376909, "o", "                    obj.index,\r\n"]
[188.397339, "o", "                    index=False,\r\n"]
[188.417769, "o", "                    encoding=encoding,\r\n"]
[188.438198, "o", "                    hash_key=hash_key,\r\n"]
[188.458628, "o", "                    categorize=categorize,\r\n"]
[188.479058, "o", "                )._values\r\n"]
[188.499488, "o", "                for _ in [None]\r\n"]
[188.519917, "o", "            )\r\n"]
[188.540347, "o", "            num_items += 1\r\n"]
[188.560777, "o", "\r\n"]
[188.581207, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[188.601636, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[188.622066, "o", "            hashes = (x for x in _hashes)\r\n"]
[188.642496, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[188.662926, "o", "\r\n"]
[188.683355, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[188.703785, "o", "    else:\r\n"]
[188.724215, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[188.744645, "o", "\r\n"]
[188.765074, "o", "    return ser\r\n"]
[188.785504, "o", "\r\n"]
[188.805934, "o", "\r\n"]
[188.826364, "o", "def hash_tuples(\r\n"]
[188.846793, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[188.867223, "o", "    encoding: str = \"utf8\",\r\n"]
[188.887653, "o", "    hash_key: str = _default_hash_key,\r\n"]
[188.908083, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[188.928512, "o", "    \"\"\"\r\n"]
[188.948942, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[188.969372, "o", "\r\n"]
[188.989802, "o", "    Parameters\r\n"]
[189.010231, "o", "    ----------\r\n"]
[189.030661, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[189.051091, "o", "    encoding : str, default 'utf8'\r\n"]
[189.071521, "o", "    hash_key : str, default _default_hash_key\r\n"]
[189.09195, "o", "\r\n"]
[189.11238, "o", "    Returns\r\n"]
[189.13281, "o", "    -------\r\n"]
[189.15324, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[189.173669, "o", "    \"\"\"\r\n"]
[189.194099, "o", "    if not is_list_like(vals):\r\n"]
[189.214529, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[189.234959, "o", "\r\n"]
[189.255388, "o", "    from pandas import (\r\n"]
[189.275818, "o", "        Categorical,\r\n"]
[189.296248, "o", "        MultiIndex,\r\n"]
[189.316678, "o", "    )\r\n"]
[189.337107, "o", "\r\n"]
[189.357537, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[189.377967, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[189.398397, "o", "    else:\r\n"]
[189.418826, "o", "        mi = vals\r\n"]
[189.439256, "o", "\r\n"]
[189.459686, "o", "    # create a list-of-Categoricals\r\n"]
[189.480116, "o", "    cat_vals = [\r\n"]
[189.500545, "o", "        Categorical._simple_new(\r\n"]
[189.520975, "o", "            mi.codes[level],\r\n"]
[189.541405, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[189.561835, "o", "        )\r\n"]
[189.582264, "o", "        for level in range(mi.nlevels)\r\n"]
[189.602694, "o", "    ]\r\n"]
[189.623124, "o", "\r\n"]
[189.643554, "o", "    # hash the list-of-ndarrays\r\n"]
[189.663983, "o", "    hashes = (\r\n"]
[189.684413, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[189.704843, "o", "        for cat in cat_vals\r\n"]
[189.725273, "o", "    )\r\n"]
[189.745702, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[189.766132, "o", "\r\n"]
[189.786562, "o", "    return h\r\n"]
[189.806992, "o", "\r\n"]
[189.827421, "o", "\r\n"]
[189.847851, "o", "def hash_array(\r\n"]
[189.868281, "o", "    vals: ArrayLike,\r\n"]
[189.888711, "o", "    encoding: str = \"utf8\",\r\n"]
[189.90914, "o", "    hash_key: str = _default_hash_key,\r\n"]
[189.92957, "o", "    categorize: bool = True,\r\n"]
[190.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[190.002, "i", "sed -n '1,240p' pandas/_libs/hash.pyx 2>/dev/null || true\r"]
[190.004, "o", "sed -n '1,240p' pandas/_libs/hash.pyx 2>/dev/null || true\r\n"]
[190.006, "o", "\u001b[?2004l\r\n"]
[195.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[195.002, "i", "cd asv_bench\r"]
[195.004, "o", "cd asv_bench\r\n"]
[195.006, "o", "\u001b[?2004l\r\n"]
[200.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[200.002, "i", "asv profile --python=same algorithms.Hashing.time_series_string\r"]
[200.004, "o", "asv profile --python=same algorithms.Hashing.time_series_string\r\n"]
[200.030844, "o", "\u001b[?2004l\r\n"]
[200.055688, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[200.080533, "o", "\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n"]
[200.105377, "o", "\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[200.130221, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n"]
[200.155065, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n"]
[200.17991, "o", "\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   8.53\u00b10.1ms\r\n"]
[200.204754, "o", "\r\n"]
[200.229598, "o", "Wed Oct  1 17:13:24 2025    /tmp/tmp1d5c9z2l\r\n"]
[200.254442, "o", "\r\n"]
[200.279286, "o", "         798 function calls (782 primitive calls) in 0.009 seconds\r\n"]
[200.304131, "o", "\r\n"]
[200.328975, "o", "   Ordered by: cumulative time\r\n"]
[200.353819, "o", "\r\n"]
[200.378663, "o", "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n"]
[200.403508, "o", "        1    0.000    0.000    0.009    0.009 {built-in method builtins.exec}\r\n"]
[200.428352, "o", "        1    0.000    0.000    0.009    0.009 _base.py:689(method_caller)\r\n"]
[200.453196, "o", "        1    0.000    0.000    0.009    0.009 algorithms.py:160(time_series_string)\r\n"]
[200.47804, "o", "      2/1    0.000    0.000    0.009    0.009 hashing.py:84(hash_pandas_object)\r\n"]
[200.502884, "o", "      3/2    0.000    0.000    0.008    0.004 hashing.py:235(hash_array)\r\n"]
[200.527729, "o", "      3/2    0.001    0.000    0.008    0.004 hashing.py:290(_hash_ndarray)\r\n"]
[200.552573, "o", "        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n"]
[200.577417, "o", "        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n"]
[200.602261, "o", "        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n"]
[200.627106, "o", "        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n"]
[200.65195, "o", "        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n"]
[200.676794, "o", "        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n"]
[200.701638, "o", "        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n"]
[200.726482, "o", "        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n"]
[200.751327, "o", "        1    0.000    0.000    0.000    0.000 base.py:2406(is_unique)\r\n"]
[200.776171, "o", "        2    0.000    0.000    0.000    0.000 series.py:369(__init__)\r\n"]
[200.801015, "o", "        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n"]
[200.825859, "o", "        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n"]
[200.850704, "o", "        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n"]
[200.875548, "o", "        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n"]
[200.900392, "o", "        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n"]
[200.925236, "o", "        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n"]
[200.95008, "o", "        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n"]
[200.974925, "o", "        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n"]
[200.999769, "o", "        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n"]
[201.024613, "o", "        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n"]
[201.049457, "o", "        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n"]
[201.074302, "o", "        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n"]
[201.099146, "o", "  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n"]
[201.12399, "o", "        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n"]
[201.148834, "o", "        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n"]
[201.173678, "o", "        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n"]
[201.198523, "o", "        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n"]
[201.223367, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n"]
[201.248211, "o", "       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n"]
[201.273055, "o", "        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n"]
[201.297899, "o", "        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n"]
[201.322744, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n"]
[201.347588, "o", "        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n"]
[201.372432, "o", "        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n"]
[201.397276, "o", "        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n"]
[201.422121, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n"]
[201.446965, "o", "        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n"]
[201.471809, "o", "        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n"]
[201.496653, "o", "       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n"]
[201.521497, "o", "        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n"]
[201.546342, "o", "        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n"]
[201.571186, "o", "        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n"]
[201.59603, "o", "        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n"]
[201.620874, "o", "       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n"]
[201.645719, "o", "        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n"]
[201.670563, "o", "        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n"]
[201.695407, "o", "        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n"]
[201.720251, "o", "        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n"]
[201.745095, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n"]
[201.76994, "o", "        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n"]
[201.794784, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n"]
[201.819628, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n"]
[201.844472, "o", "        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n"]
[201.869317, "o", "        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n"]
[201.894161, "o", "        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n"]
[201.919005, "o", "    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n"]
[201.943849, "o", "        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n"]
[201.968693, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n"]
[201.993538, "o", "        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n"]
[202.018382, "o", "        2    0.000    0.000    0.000    0.000 series.py:737(name)\r\n"]
[202.043226, "o", "        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n"]
[202.06807, "o", "        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n"]
[202.092915, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n"]
[202.117759, "o", "        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n"]
[202.142603, "o", "        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n"]
[202.167447, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n"]
[202.192291, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n"]
[202.217136, "o", "        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n"]
[202.24198, "o", "        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n"]
[202.266824, "o", "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n"]
[202.291668, "o", "        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n"]
[202.316513, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2232(new_block)\r\n"]
[202.341357, "o", "        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n"]
[202.366201, "o", "        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n"]
[202.391045, "o", "       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n"]
[202.415889, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n"]
[202.440734, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n"]
[202.465578, "o", "        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n"]
[202.490422, "o", "       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n"]
[202.515266, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n"]
[202.540111, "o", "        2    0.000    0.000    0.000    0.000 series.py:783(_values)\r\n"]
[202.564955, "o", "        2    0.000    0.000    0.000    0.000 series.py:686(name)\r\n"]
[202.589799, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n"]
[202.614643, "o", "        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n"]
[202.639487, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2161(maybe_coerce_values)\r\n"]
[202.664332, "o", "        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n"]
[202.689176, "o", "        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n"]
[202.71402, "o", "        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n"]
[202.738864, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n"]
[202.763709, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n"]
[202.788553, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n"]
[202.813397, "o", "        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n"]
[202.838241, "o", "        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n"]
[202.863085, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n"]
[202.88793, "o", "        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n"]
[202.912774, "o", "        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n"]
[202.937618, "o", "        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n"]
[202.962462, "o", "        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n"]
[202.987307, "o", "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n"]
[203.012151, "o", "        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n"]
[203.036995, "o", "        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n"]
[203.061839, "o", "        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n"]
[203.086683, "o", "        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n"]
[203.111528, "o", "        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n"]
[203.136372, "o", "        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n"]
[203.161216, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2190(get_block_type)\r\n"]
[203.18606, "o", "        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n"]
[203.210905, "o", "        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n"]
[203.235749, "o", "        1    0.000    0.000    0.000    0.000 indexing.py:2746(check_dict_or_set_indexers)\r\n"]
[203.260593, "o", "        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n"]
[203.285437, "o", "        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n"]
[203.310281, "o", "        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n"]
[203.335126, "o", "        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n"]
[203.35997, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n"]
[203.384814, "o", "        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n"]
[203.409658, "o", "        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n"]
[203.434503, "o", "       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n"]
[203.459347, "o", "        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n"]
[203.484191, "o", "        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n"]
[203.509035, "o", "        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n"]
[203.533879, "o", "        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n"]
[203.558724, "o", "        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n"]
[203.583568, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n"]
[203.608412, "o", "        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n"]
[203.633256, "o", "        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n"]
[203.658101, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n"]
[203.682945, "o", "        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n"]
[203.707789, "o", "       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n"]
[203.732633, "o", "        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n"]
[203.757477, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n"]
[203.782322, "o", "        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n"]
[203.807166, "o", "        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n"]
[203.83201, "o", "        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n"]
[203.856854, "o", "        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n"]
[203.881698, "o", "        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n"]
[203.906543, "o", "        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n"]
[203.931387, "o", "        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n"]
[203.956231, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n"]
[203.981075, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n"]
[204.00592, "o", "        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n"]
[204.030764, "o", "        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n"]
[204.055608, "o", "        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n"]
[204.080452, "o", "        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n"]
[204.105296, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n"]
[204.130141, "o", "        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x5616dac95640}\r\n"]
[204.154985, "o", "        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n"]
[204.179829, "o", "        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n"]
[204.204673, "o", "        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n"]
[204.229518, "o", "        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n"]
[204.254362, "o", "        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n"]
[204.279206, "o", "        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n"]
[204.30405, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n"]
[204.328894, "o", "        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n"]
[204.353739, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n"]
[204.378583, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n"]
[204.403427, "o", "        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n"]
[204.428271, "o", "        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n"]
[204.453116, "o", "        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n"]
[204.47796, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n"]
[204.502804, "o", "        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n"]
[204.527648, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n"]
[204.552492, "o", "        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n"]
[204.577337, "o", "        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n"]
[204.602181, "o", "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n"]
[204.627025, "o", "        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n"]
[204.651869, "o", "        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n"]
[204.676714, "o", "        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n"]
[204.701558, "o", "        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n"]
[204.726402, "o", "        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n"]
[204.751246, "o", "        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n"]
[204.77609, "o", "        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n"]
[204.800935, "o", "        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n"]
[204.825779, "o", "        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n"]
[204.850623, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n"]
[204.875467, "o", "        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n"]
[204.900312, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n"]
[204.925156, "o", "\r\n"]
[205.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[205.002, "i", "cd /workspace/repo\r"]
[205.004, "o", "cd /workspace/repo\r\n"]
[205.006, "o", "\u001b[?2004l\r\n"]
[210.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[210.002, "i", "sed -n '1,240p' pandas/core/util/hashing.py\r"]
[210.004, "o", "sed -n '1,240p' pandas/core/util/hashing.py\r\n"]
[210.026515, "o", "\u001b[?2004l\r\n"]
[210.047029, "o", "\"\"\"\r\n"]
[210.067544, "o", "data hash pandas / numpy objects\r\n"]
[210.088058, "o", "\"\"\"\r\n"]
[210.108573, "o", "\r\n"]
[210.129087, "o", "from __future__ import annotations\r\n"]
[210.149602, "o", "\r\n"]
[210.170116, "o", "import itertools\r\n"]
[210.190631, "o", "from typing import TYPE_CHECKING\r\n"]
[210.211145, "o", "\r\n"]
[210.23166, "o", "import numpy as np\r\n"]
[210.252174, "o", "\r\n"]
[210.272689, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[210.293203, "o", "\r\n"]
[210.313718, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[210.334232, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[210.354747, "o", "from pandas.core.dtypes.generic import (\r\n"]
[210.375261, "o", "    ABCDataFrame,\r\n"]
[210.395776, "o", "    ABCExtensionArray,\r\n"]
[210.41629, "o", "    ABCIndex,\r\n"]
[210.436805, "o", "    ABCMultiIndex,\r\n"]
[210.45732, "o", "    ABCSeries,\r\n"]
[210.477834, "o", ")\r\n"]
[210.498349, "o", "\r\n"]
[210.518863, "o", "if TYPE_CHECKING:\r\n"]
[210.539378, "o", "    from collections.abc import (\r\n"]
[210.559892, "o", "        Hashable,\r\n"]
[210.580407, "o", "        Iterable,\r\n"]
[210.600921, "o", "        Iterator,\r\n"]
[210.621436, "o", "    )\r\n"]
[210.64195, "o", "\r\n"]
[210.662465, "o", "    from pandas._typing import (\r\n"]
[210.682979, "o", "        ArrayLike,\r\n"]
[210.703494, "o", "        npt,\r\n"]
[210.724008, "o", "    )\r\n"]
[210.744523, "o", "\r\n"]
[210.765037, "o", "    from pandas import (\r\n"]
[210.785552, "o", "        DataFrame,\r\n"]
[210.806066, "o", "        Index,\r\n"]
[210.826581, "o", "        MultiIndex,\r\n"]
[210.847095, "o", "        Series,\r\n"]
[210.86761, "o", "    )\r\n"]
[210.888124, "o", "\r\n"]
[210.908639, "o", "\r\n"]
[210.929154, "o", "# 16 byte long hashing key\r\n"]
[210.949668, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[210.970183, "o", "\r\n"]
[210.990697, "o", "\r\n"]
[211.011212, "o", "def combine_hash_arrays(\r\n"]
[211.031726, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[211.052241, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[211.072755, "o", "    \"\"\"\r\n"]
[211.09327, "o", "    Parameters\r\n"]
[211.113784, "o", "    ----------\r\n"]
[211.134299, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[211.154813, "o", "    num_items : int\r\n"]
[211.175328, "o", "\r\n"]
[211.195842, "o", "    Returns\r\n"]
[211.216357, "o", "    -------\r\n"]
[211.236871, "o", "    np.ndarray[uint64]\r\n"]
[211.257386, "o", "\r\n"]
[211.2779, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[211.298415, "o", "    \"\"\"\r\n"]
[211.318929, "o", "    try:\r\n"]
[211.339444, "o", "        first = next(arrays)\r\n"]
[211.359959, "o", "    except StopIteration:\r\n"]
[211.380473, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[211.400988, "o", "\r\n"]
[211.421502, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[211.442017, "o", "\r\n"]
[211.462531, "o", "    mult = np.uint64(1000003)\r\n"]
[211.483046, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[211.50356, "o", "    last_i = 0\r\n"]
[211.524075, "o", "    for i, a in enumerate(arrays):\r\n"]
[211.544589, "o", "        inverse_i = num_items - i\r\n"]
[211.565104, "o", "        out ^= a\r\n"]
[211.585618, "o", "        out *= mult\r\n"]
[211.606133, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[211.626647, "o", "        last_i = i\r\n"]
[211.647162, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[211.667676, "o", "    out += np.uint64(97531)\r\n"]
[211.688191, "o", "    return out\r\n"]
[211.708705, "o", "\r\n"]
[211.72922, "o", "\r\n"]
[211.749734, "o", "def hash_pandas_object(\r\n"]
[211.770249, "o", "    obj: Index | DataFrame | Series,\r\n"]
[211.790763, "o", "    index: bool = True,\r\n"]
[211.811278, "o", "    encoding: str = \"utf8\",\r\n"]
[211.831793, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[211.852307, "o", "    categorize: bool = True,\r\n"]
[211.872822, "o", ") -> Series:\r\n"]
[211.893336, "o", "    \"\"\"\r\n"]
[211.913851, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[211.934365, "o", "\r\n"]
[211.95488, "o", "    Parameters\r\n"]
[211.975394, "o", "    ----------\r\n"]
[211.995909, "o", "    obj : Index, Series, or DataFrame\r\n"]
[212.016423, "o", "    index : bool, default True\r\n"]
[212.036938, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[212.057452, "o", "    encoding : str, default 'utf8'\r\n"]
[212.077967, "o", "        Encoding for data & key when strings.\r\n"]
[212.098481, "o", "    hash_key : str, default _default_hash_key\r\n"]
[212.118996, "o", "        Hash_key for string key to encode.\r\n"]
[212.13951, "o", "    categorize : bool, default True\r\n"]
[212.160025, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[212.180539, "o", "        efficient when the array contains duplicate values.\r\n"]
[212.201054, "o", "\r\n"]
[212.221568, "o", "    Returns\r\n"]
[212.242083, "o", "    -------\r\n"]
[212.262598, "o", "    Series of uint64\r\n"]
[212.283112, "o", "        Same length as the object.\r\n"]
[212.303627, "o", "\r\n"]
[212.324141, "o", "    Examples\r\n"]
[212.344656, "o", "    --------\r\n"]
[212.36517, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[212.385685, "o", "    0    14639053686158035780\r\n"]
[212.406199, "o", "    1     3869563279212530728\r\n"]
[212.426714, "o", "    2      393322362522515241\r\n"]
[212.447228, "o", "    dtype: uint64\r\n"]
[212.467743, "o", "    \"\"\"\r\n"]
[212.488257, "o", "    from pandas import Series\r\n"]
[212.508772, "o", "\r\n"]
[212.529286, "o", "    if hash_key is None:\r\n"]
[212.549801, "o", "        hash_key = _default_hash_key\r\n"]
[212.570315, "o", "\r\n"]
[212.59083, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[212.611344, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[212.631859, "o", "\r\n"]
[212.652373, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[212.672888, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[212.693402, "o", "            \"uint64\", copy=False\r\n"]
[212.713917, "o", "        )\r\n"]
[212.734432, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[212.754946, "o", "\r\n"]
[212.775461, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[212.795975, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[212.81649, "o", "            \"uint64\", copy=False\r\n"]
[212.837004, "o", "        )\r\n"]
[212.857519, "o", "        if index:\r\n"]
[212.878033, "o", "            index_iter = (\r\n"]
[212.898548, "o", "                hash_pandas_object(\r\n"]
[212.919062, "o", "                    obj.index,\r\n"]
[212.939577, "o", "                    index=False,\r\n"]
[212.960091, "o", "                    encoding=encoding,\r\n"]
[212.980606, "o", "                    hash_key=hash_key,\r\n"]
[213.00112, "o", "                    categorize=categorize,\r\n"]
[213.021635, "o", "                )._values\r\n"]
[213.042149, "o", "                for _ in [None]\r\n"]
[213.062664, "o", "            )\r\n"]
[213.083178, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[213.103693, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[213.124207, "o", "\r\n"]
[213.144722, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[213.165237, "o", "\r\n"]
[213.185751, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[213.206266, "o", "        hashes = (\r\n"]
[213.22678, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[213.247295, "o", "            for _, series in obj.items()\r\n"]
[213.267809, "o", "        )\r\n"]
[213.288324, "o", "        num_items = len(obj.columns)\r\n"]
[213.308838, "o", "        if index:\r\n"]
[213.329353, "o", "            index_hash_generator = (\r\n"]
[213.349867, "o", "                hash_pandas_object(\r\n"]
[213.370382, "o", "                    obj.index,\r\n"]
[213.390896, "o", "                    index=False,\r\n"]
[213.411411, "o", "                    encoding=encoding,\r\n"]
[213.431925, "o", "                    hash_key=hash_key,\r\n"]
[213.45244, "o", "                    categorize=categorize,\r\n"]
[213.472954, "o", "                )._values\r\n"]
[213.493469, "o", "                for _ in [None]\r\n"]
[213.513983, "o", "            )\r\n"]
[213.534498, "o", "            num_items += 1\r\n"]
[213.555012, "o", "\r\n"]
[213.575527, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[213.596041, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[213.616556, "o", "            hashes = (x for x in _hashes)\r\n"]
[213.637071, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[213.657585, "o", "\r\n"]
[213.6781, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[213.698614, "o", "    else:\r\n"]
[213.719129, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[213.739643, "o", "\r\n"]
[213.760158, "o", "    return ser\r\n"]
[213.780672, "o", "\r\n"]
[213.801187, "o", "\r\n"]
[213.821701, "o", "def hash_tuples(\r\n"]
[213.842216, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[213.86273, "o", "    encoding: str = \"utf8\",\r\n"]
[213.883245, "o", "    hash_key: str = _default_hash_key,\r\n"]
[213.903759, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[213.924274, "o", "    \"\"\"\r\n"]
[213.944788, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[213.965303, "o", "\r\n"]
[213.985817, "o", "    Parameters\r\n"]
[214.006332, "o", "    ----------\r\n"]
[214.026846, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[214.047361, "o", "    encoding : str, default 'utf8'\r\n"]
[214.067876, "o", "    hash_key : str, default _default_hash_key\r\n"]
[214.08839, "o", "\r\n"]
[214.108905, "o", "    Returns\r\n"]
[214.129419, "o", "    -------\r\n"]
[214.149934, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[214.170448, "o", "    \"\"\"\r\n"]
[214.190963, "o", "    if not is_list_like(vals):\r\n"]
[214.211477, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[214.231992, "o", "\r\n"]
[214.252506, "o", "    from pandas import (\r\n"]
[214.273021, "o", "        Categorical,\r\n"]
[214.293535, "o", "        MultiIndex,\r\n"]
[214.31405, "o", "    )\r\n"]
[214.334564, "o", "\r\n"]
[214.355079, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[214.375593, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[214.396108, "o", "    else:\r\n"]
[214.416622, "o", "        mi = vals\r\n"]
[214.437137, "o", "\r\n"]
[214.457651, "o", "    # create a list-of-Categoricals\r\n"]
[214.478166, "o", "    cat_vals = [\r\n"]
[214.49868, "o", "        Categorical._simple_new(\r\n"]
[214.519195, "o", "            mi.codes[level],\r\n"]
[214.53971, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[214.560224, "o", "        )\r\n"]
[214.580739, "o", "        for level in range(mi.nlevels)\r\n"]
[214.601253, "o", "    ]\r\n"]
[214.621768, "o", "\r\n"]
[214.642282, "o", "    # hash the list-of-ndarrays\r\n"]
[214.662797, "o", "    hashes = (\r\n"]
[214.683311, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[214.703826, "o", "        for cat in cat_vals\r\n"]
[214.72434, "o", "    )\r\n"]
[214.744855, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[214.765369, "o", "\r\n"]
[214.785884, "o", "    return h\r\n"]
[214.806398, "o", "\r\n"]
[214.826913, "o", "\r\n"]
[214.847427, "o", "def hash_array(\r\n"]
[214.867942, "o", "    vals: ArrayLike,\r\n"]
[214.888456, "o", "    encoding: str = \"utf8\",\r\n"]
[214.908971, "o", "    hash_key: str = _default_hash_key,\r\n"]
[214.929485, "o", "    categorize: bool = True,\r\n"]
[215.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[215.002, "i", "sed -n '240,520p' pandas/core/util/hashing.py\r"]
[215.004, "o", "sed -n '240,520p' pandas/core/util/hashing.py\r\n"]
[215.051358, "o", "\u001b[?2004l\r\n"]
[215.096716, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[215.142073, "o", "    \"\"\"\r\n"]
[215.187431, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[215.232789, "o", "\r\n"]
[215.278147, "o", "    Parameters\r\n"]
[215.323505, "o", "    ----------\r\n"]
[215.368862, "o", "    vals : ndarray or ExtensionArray\r\n"]
[215.41422, "o", "        The input array to hash.\r\n"]
[215.459578, "o", "    encoding : str, default 'utf8'\r\n"]
[215.504936, "o", "        Encoding for data & key when strings.\r\n"]
[215.550294, "o", "    hash_key : str, default _default_hash_key\r\n"]
[215.595651, "o", "        Hash_key for string key to encode.\r\n"]
[215.641009, "o", "    categorize : bool, default True\r\n"]
[215.686367, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[215.731725, "o", "        efficient when the array contains duplicate values.\r\n"]
[215.777083, "o", "\r\n"]
[215.82244, "o", "    Returns\r\n"]
[215.867798, "o", "    -------\r\n"]
[215.913156, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[215.958514, "o", "        Hashed values, same length as the vals.\r\n"]
[216.003872, "o", "\r\n"]
[216.049229, "o", "    See Also\r\n"]
[216.094587, "o", "    --------\r\n"]
[216.139945, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[216.185303, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[216.230661, "o", "\r\n"]
[216.276018, "o", "    Examples\r\n"]
[216.321376, "o", "    --------\r\n"]
[216.366734, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[216.412092, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[216.45745, "o", "      dtype=uint64)\r\n"]
[216.502807, "o", "    \"\"\"\r\n"]
[216.548165, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[216.593523, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[216.638881, "o", "\r\n"]
[216.684239, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[216.729596, "o", "        return vals._hash_pandas_object(\r\n"]
[216.774954, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[216.820312, "o", "        )\r\n"]
[216.86567, "o", "\r\n"]
[216.911028, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[216.956385, "o", "        # GH#42003\r\n"]
[217.001743, "o", "        raise TypeError(\r\n"]
[217.047101, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[217.092459, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[217.137817, "o", "        )\r\n"]
[217.183174, "o", "\r\n"]
[217.228532, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[217.27389, "o", "\r\n"]
[217.319248, "o", "\r\n"]
[217.364606, "o", "def _hash_ndarray(\r\n"]
[217.409963, "o", "    vals: np.ndarray,\r\n"]
[217.455321, "o", "    encoding: str = \"utf8\",\r\n"]
[217.500679, "o", "    hash_key: str = _default_hash_key,\r\n"]
[217.546037, "o", "    categorize: bool = True,\r\n"]
[217.591394, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[217.636752, "o", "    \"\"\"\r\n"]
[217.68211, "o", "    See hash_array.__doc__.\r\n"]
[217.727468, "o", "    \"\"\"\r\n"]
[217.772826, "o", "    dtype = vals.dtype\r\n"]
[217.818183, "o", "\r\n"]
[217.863541, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[217.908899, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[217.954257, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[217.999615, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[218.044972, "o", "        return hash_real + 23 * hash_imag\r\n"]
[218.09033, "o", "\r\n"]
[218.135688, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[218.181046, "o", "    # manage it.\r\n"]
[218.226404, "o", "    if dtype == bool:\r\n"]
[218.271761, "o", "        vals = vals.astype(\"u8\")\r\n"]
[218.317119, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[218.362477, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[218.407835, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[218.453193, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[218.49855, "o", "    else:\r\n"]
[218.543908, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[218.589266, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[218.634624, "o", "        # when the values are known/likely to be unique.\r\n"]
[218.679982, "o", "        if categorize:\r\n"]
[218.725339, "o", "            from pandas import (\r\n"]
[218.770697, "o", "                Categorical,\r\n"]
[218.816055, "o", "                Index,\r\n"]
[218.861413, "o", "                factorize,\r\n"]
[218.906771, "o", "            )\r\n"]
[218.952128, "o", "\r\n"]
[218.997486, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[219.042844, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[219.088202, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[219.13356, "o", "            return cat._hash_pandas_object(\r\n"]
[219.178917, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[219.224275, "o", "            )\r\n"]
[219.269633, "o", "\r\n"]
[219.314991, "o", "        try:\r\n"]
[219.360349, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[219.405706, "o", "        except TypeError:\r\n"]
[219.451064, "o", "            # we have mixed types\r\n"]
[219.496422, "o", "            vals = hash_object_array(\r\n"]
[219.54178, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[219.587138, "o", "            )\r\n"]
[219.632495, "o", "\r\n"]
[219.677853, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[219.723211, "o", "    vals ^= vals >> 30\r\n"]
[219.768569, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[219.813927, "o", "    vals ^= vals >> 27\r\n"]
[219.859284, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[219.904642, "o", "    vals ^= vals >> 31\r\n"]
[220.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[220.002, "i", "sed -n '1,240p' pandas/_libs/hash.pyx 2>/dev/null || true\r"]
[220.004, "o", "sed -n '1,240p' pandas/_libs/hash.pyx 2>/dev/null || true\r\n"]
[220.006, "o", "\u001b[?2004l\r\n"]
[225.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[225.002, "i", "cd asv_bench\r"]
[225.004, "o", "cd asv_bench\r\n"]
[225.006, "o", "\u001b[?2004l\r\n"]
[230.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[230.002, "i", "asv profile --python=same algorithms.Hashing.time_series_string\r"]
[230.004, "o", "asv profile --python=same algorithms.Hashing.time_series_string\r\n"]
[230.030844, "o", "\u001b[?2004l\r\n"]
[230.055688, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[230.080533, "o", "\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n"]
[230.105377, "o", "\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[230.130221, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n"]
[230.155065, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n"]
[230.17991, "o", "\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                  7.93\u00b10.02ms\r\n"]
[230.204754, "o", "\r\n"]
[230.229598, "o", "Wed Oct  1 17:15:37 2025    /tmp/tmpqrkdq0wv\r\n"]
[230.254442, "o", "\r\n"]
[230.279286, "o", "         798 function calls (782 primitive calls) in 0.008 seconds\r\n"]
[230.304131, "o", "\r\n"]
[230.328975, "o", "   Ordered by: cumulative time\r\n"]
[230.353819, "o", "\r\n"]
[230.378663, "o", "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n"]
[230.403508, "o", "        1    0.000    0.000    0.008    0.008 {built-in method builtins.exec}\r\n"]
[230.428352, "o", "        1    0.000    0.000    0.008    0.008 _base.py:689(method_caller)\r\n"]
[230.453196, "o", "        1    0.000    0.000    0.008    0.008 algorithms.py:160(time_series_string)\r\n"]
[230.47804, "o", "      2/1    0.000    0.000    0.008    0.008 hashing.py:84(hash_pandas_object)\r\n"]
[230.502884, "o", "      3/2    0.000    0.000    0.008    0.004 hashing.py:235(hash_array)\r\n"]
[230.527729, "o", "      3/2    0.001    0.000    0.008    0.004 hashing.py:290(_hash_ndarray)\r\n"]
[230.552573, "o", "        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n"]
[230.577417, "o", "        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n"]
[230.602261, "o", "        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n"]
[230.627106, "o", "        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n"]
[230.65195, "o", "        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n"]
[230.676794, "o", "        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n"]
[230.701638, "o", "        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n"]
[230.726482, "o", "        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n"]
[230.751327, "o", "        1    0.000    0.000    0.000    0.000 base.py:2406(is_unique)\r\n"]
[230.776171, "o", "        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n"]
[230.801015, "o", "        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n"]
[230.825859, "o", "        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n"]
[230.850704, "o", "        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n"]
[230.875548, "o", "        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n"]
[230.900392, "o", "        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n"]
[230.925236, "o", "        2    0.000    0.000    0.000    0.000 series.py:369(__init__)\r\n"]
[230.95008, "o", "        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n"]
[230.974925, "o", "        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n"]
[230.999769, "o", "        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n"]
[231.024613, "o", "        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n"]
[231.049457, "o", "        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n"]
[231.074302, "o", "        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n"]
[231.099146, "o", "  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n"]
[231.12399, "o", "        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n"]
[231.148834, "o", "        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n"]
[231.173678, "o", "        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n"]
[231.198523, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n"]
[231.223367, "o", "        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n"]
[231.248211, "o", "        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n"]
[231.273055, "o", "       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n"]
[231.297899, "o", "        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n"]
[231.322744, "o", "        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n"]
[231.347588, "o", "        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n"]
[231.372432, "o", "        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n"]
[231.397276, "o", "        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n"]
[231.422121, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n"]
[231.446965, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n"]
[231.471809, "o", "        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n"]
[231.496653, "o", "        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n"]
[231.521497, "o", "        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n"]
[231.546342, "o", "        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n"]
[231.571186, "o", "        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n"]
[231.59603, "o", "       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n"]
[231.620874, "o", "        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n"]
[231.645719, "o", "       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n"]
[231.670563, "o", "        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n"]
[231.695407, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n"]
[231.720251, "o", "        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n"]
[231.745095, "o", "        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n"]
[231.76994, "o", "        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n"]
[231.794784, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n"]
[231.819628, "o", "        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n"]
[231.844472, "o", "        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n"]
[231.869317, "o", "        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n"]
[231.894161, "o", "    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n"]
[231.919005, "o", "        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n"]
[231.943849, "o", "        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n"]
[231.968693, "o", "        2    0.000    0.000    0.000    0.000 series.py:737(name)\r\n"]
[231.993538, "o", "        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n"]
[232.018382, "o", "        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n"]
[232.043226, "o", "        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n"]
[232.06807, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n"]
[232.092915, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n"]
[232.117759, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n"]
[232.142603, "o", "        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n"]
[232.167447, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n"]
[232.192291, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n"]
[232.217136, "o", "        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n"]
[232.24198, "o", "        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n"]
[232.266824, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2232(new_block)\r\n"]
[232.291668, "o", "        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n"]
[232.316513, "o", "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n"]
[232.341357, "o", "        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n"]
[232.366201, "o", "       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n"]
[232.391045, "o", "        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n"]
[232.415889, "o", "        2    0.000    0.000    0.000    0.000 series.py:686(name)\r\n"]
[232.440734, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n"]
[232.465578, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n"]
[232.490422, "o", "        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n"]
[232.515266, "o", "        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n"]
[232.540111, "o", "        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n"]
[232.564955, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2161(maybe_coerce_values)\r\n"]
[232.589799, "o", "        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n"]
[232.614643, "o", "        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n"]
[232.639487, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n"]
[232.664332, "o", "       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n"]
[232.689176, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n"]
[232.71402, "o", "        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n"]
[232.738864, "o", "        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n"]
[232.763709, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n"]
[232.788553, "o", "        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n"]
[232.813397, "o", "        2    0.000    0.000    0.000    0.000 series.py:783(_values)\r\n"]
[232.838241, "o", "        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n"]
[232.863085, "o", "        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n"]
[232.88793, "o", "        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n"]
[232.912774, "o", "        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n"]
[232.937618, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n"]
[232.962462, "o", "        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n"]
[232.987307, "o", "        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n"]
[233.012151, "o", "        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n"]
[233.036995, "o", "        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n"]
[233.061839, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n"]
[233.086683, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n"]
[233.111528, "o", "        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n"]
[233.136372, "o", "        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n"]
[233.161216, "o", "        1    0.000    0.000    0.000    0.000 indexing.py:2746(check_dict_or_set_indexers)\r\n"]
[233.18606, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2190(get_block_type)\r\n"]
[233.210905, "o", "        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n"]
[233.235749, "o", "        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n"]
[233.260593, "o", "        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n"]
[233.285437, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n"]
[233.310281, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n"]
[233.335126, "o", "        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n"]
[233.35997, "o", "        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n"]
[233.384814, "o", "        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n"]
[233.409658, "o", "        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n"]
[233.434503, "o", "        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n"]
[233.459347, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n"]
[233.484191, "o", "        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n"]
[233.509035, "o", "        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n"]
[233.533879, "o", "       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n"]
[233.558724, "o", "        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n"]
[233.583568, "o", "       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n"]
[233.608412, "o", "        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n"]
[233.633256, "o", "        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n"]
[233.658101, "o", "        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n"]
[233.682945, "o", "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n"]
[233.707789, "o", "        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n"]
[233.732633, "o", "        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n"]
[233.757477, "o", "        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n"]
[233.782322, "o", "        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n"]
[233.807166, "o", "        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n"]
[233.83201, "o", "        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n"]
[233.856854, "o", "        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n"]
[233.881698, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n"]
[233.906543, "o", "        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n"]
[233.931387, "o", "        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n"]
[233.956231, "o", "        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n"]
[233.981075, "o", "        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n"]
[234.00592, "o", "        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n"]
[234.030764, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n"]
[234.055608, "o", "        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n"]
[234.080452, "o", "        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n"]
[234.105296, "o", "        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n"]
[234.130141, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n"]
[234.154985, "o", "        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n"]
[234.179829, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n"]
[234.204673, "o", "        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55d4e3ea2640}\r\n"]
[234.229518, "o", "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n"]
[234.254362, "o", "        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n"]
[234.279206, "o", "        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n"]
[234.30405, "o", "        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n"]
[234.328894, "o", "        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n"]
[234.353739, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n"]
[234.378583, "o", "        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n"]
[234.403427, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n"]
[234.428271, "o", "        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n"]
[234.453116, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n"]
[234.47796, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n"]
[234.502804, "o", "        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n"]
[234.527648, "o", "        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n"]
[234.552492, "o", "        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n"]
[234.577337, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n"]
[234.602181, "o", "        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n"]
[234.627025, "o", "        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n"]
[234.651869, "o", "        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n"]
[234.676714, "o", "        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n"]
[234.701558, "o", "        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n"]
[234.726402, "o", "        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n"]
[234.751246, "o", "        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n"]
[234.77609, "o", "        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n"]
[234.800935, "o", "        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n"]
[234.825779, "o", "        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n"]
[234.850623, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n"]
[234.875467, "o", "        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n"]
[234.900312, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n"]
[234.925156, "o", "\r\n"]
[235.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[235.002, "i", "cd /workspace/repo\r"]
[235.004, "o", "cd /workspace/repo\r\n"]
[235.006, "o", "\u001b[?2004l\r\n"]
[240.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[240.002, "i", "sed -n '1,240p' pandas/core/util/hashing.py\r"]
[240.004, "o", "sed -n '1,240p' pandas/core/util/hashing.py\r\n"]
[240.026515, "o", "\u001b[?2004l\r\n"]
[240.047029, "o", "\"\"\"\r\n"]
[240.067544, "o", "data hash pandas / numpy objects\r\n"]
[240.088058, "o", "\"\"\"\r\n"]
[240.108573, "o", "\r\n"]
[240.129087, "o", "from __future__ import annotations\r\n"]
[240.149602, "o", "\r\n"]
[240.170116, "o", "import itertools\r\n"]
[240.190631, "o", "from typing import TYPE_CHECKING\r\n"]
[240.211145, "o", "\r\n"]
[240.23166, "o", "import numpy as np\r\n"]
[240.252174, "o", "\r\n"]
[240.272689, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[240.293203, "o", "\r\n"]
[240.313718, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[240.334232, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[240.354747, "o", "from pandas.core.dtypes.generic import (\r\n"]
[240.375261, "o", "    ABCDataFrame,\r\n"]
[240.395776, "o", "    ABCExtensionArray,\r\n"]
[240.41629, "o", "    ABCIndex,\r\n"]
[240.436805, "o", "    ABCMultiIndex,\r\n"]
[240.45732, "o", "    ABCSeries,\r\n"]
[240.477834, "o", ")\r\n"]
[240.498349, "o", "\r\n"]
[240.518863, "o", "if TYPE_CHECKING:\r\n"]
[240.539378, "o", "    from collections.abc import (\r\n"]
[240.559892, "o", "        Hashable,\r\n"]
[240.580407, "o", "        Iterable,\r\n"]
[240.600921, "o", "        Iterator,\r\n"]
[240.621436, "o", "    )\r\n"]
[240.64195, "o", "\r\n"]
[240.662465, "o", "    from pandas._typing import (\r\n"]
[240.682979, "o", "        ArrayLike,\r\n"]
[240.703494, "o", "        npt,\r\n"]
[240.724008, "o", "    )\r\n"]
[240.744523, "o", "\r\n"]
[240.765037, "o", "    from pandas import (\r\n"]
[240.785552, "o", "        DataFrame,\r\n"]
[240.806066, "o", "        Index,\r\n"]
[240.826581, "o", "        MultiIndex,\r\n"]
[240.847095, "o", "        Series,\r\n"]
[240.86761, "o", "    )\r\n"]
[240.888124, "o", "\r\n"]
[240.908639, "o", "\r\n"]
[240.929154, "o", "# 16 byte long hashing key\r\n"]
[240.949668, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[240.970183, "o", "\r\n"]
[240.990697, "o", "\r\n"]
[241.011212, "o", "def combine_hash_arrays(\r\n"]
[241.031726, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[241.052241, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[241.072755, "o", "    \"\"\"\r\n"]
[241.09327, "o", "    Parameters\r\n"]
[241.113784, "o", "    ----------\r\n"]
[241.134299, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[241.154813, "o", "    num_items : int\r\n"]
[241.175328, "o", "\r\n"]
[241.195842, "o", "    Returns\r\n"]
[241.216357, "o", "    -------\r\n"]
[241.236871, "o", "    np.ndarray[uint64]\r\n"]
[241.257386, "o", "\r\n"]
[241.2779, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[241.298415, "o", "    \"\"\"\r\n"]
[241.318929, "o", "    try:\r\n"]
[241.339444, "o", "        first = next(arrays)\r\n"]
[241.359959, "o", "    except StopIteration:\r\n"]
[241.380473, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[241.400988, "o", "\r\n"]
[241.421502, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[241.442017, "o", "\r\n"]
[241.462531, "o", "    mult = np.uint64(1000003)\r\n"]
[241.483046, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[241.50356, "o", "    last_i = 0\r\n"]
[241.524075, "o", "    for i, a in enumerate(arrays):\r\n"]
[241.544589, "o", "        inverse_i = num_items - i\r\n"]
[241.565104, "o", "        out ^= a\r\n"]
[241.585618, "o", "        out *= mult\r\n"]
[241.606133, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[241.626647, "o", "        last_i = i\r\n"]
[241.647162, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[241.667676, "o", "    out += np.uint64(97531)\r\n"]
[241.688191, "o", "    return out\r\n"]
[241.708705, "o", "\r\n"]
[241.72922, "o", "\r\n"]
[241.749734, "o", "def hash_pandas_object(\r\n"]
[241.770249, "o", "    obj: Index | DataFrame | Series,\r\n"]
[241.790763, "o", "    index: bool = True,\r\n"]
[241.811278, "o", "    encoding: str = \"utf8\",\r\n"]
[241.831793, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[241.852307, "o", "    categorize: bool = True,\r\n"]
[241.872822, "o", ") -> Series:\r\n"]
[241.893336, "o", "    \"\"\"\r\n"]
[241.913851, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[241.934365, "o", "\r\n"]
[241.95488, "o", "    Parameters\r\n"]
[241.975394, "o", "    ----------\r\n"]
[241.995909, "o", "    obj : Index, Series, or DataFrame\r\n"]
[242.016423, "o", "    index : bool, default True\r\n"]
[242.036938, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[242.057452, "o", "    encoding : str, default 'utf8'\r\n"]
[242.077967, "o", "        Encoding for data & key when strings.\r\n"]
[242.098481, "o", "    hash_key : str, default _default_hash_key\r\n"]
[242.118996, "o", "        Hash_key for string key to encode.\r\n"]
[242.13951, "o", "    categorize : bool, default True\r\n"]
[242.160025, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[242.180539, "o", "        efficient when the array contains duplicate values.\r\n"]
[242.201054, "o", "\r\n"]
[242.221568, "o", "    Returns\r\n"]
[242.242083, "o", "    -------\r\n"]
[242.262598, "o", "    Series of uint64\r\n"]
[242.283112, "o", "        Same length as the object.\r\n"]
[242.303627, "o", "\r\n"]
[242.324141, "o", "    Examples\r\n"]
[242.344656, "o", "    --------\r\n"]
[242.36517, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[242.385685, "o", "    0    14639053686158035780\r\n"]
[242.406199, "o", "    1     3869563279212530728\r\n"]
[242.426714, "o", "    2      393322362522515241\r\n"]
[242.447228, "o", "    dtype: uint64\r\n"]
[242.467743, "o", "    \"\"\"\r\n"]
[242.488257, "o", "    from pandas import Series\r\n"]
[242.508772, "o", "\r\n"]
[242.529286, "o", "    if hash_key is None:\r\n"]
[242.549801, "o", "        hash_key = _default_hash_key\r\n"]
[242.570315, "o", "\r\n"]
[242.59083, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[242.611344, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[242.631859, "o", "\r\n"]
[242.652373, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[242.672888, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[242.693402, "o", "            \"uint64\", copy=False\r\n"]
[242.713917, "o", "        )\r\n"]
[242.734432, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[242.754946, "o", "\r\n"]
[242.775461, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[242.795975, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[242.81649, "o", "            \"uint64\", copy=False\r\n"]
[242.837004, "o", "        )\r\n"]
[242.857519, "o", "        if index:\r\n"]
[242.878033, "o", "            index_iter = (\r\n"]
[242.898548, "o", "                hash_pandas_object(\r\n"]
[242.919062, "o", "                    obj.index,\r\n"]
[242.939577, "o", "                    index=False,\r\n"]
[242.960091, "o", "                    encoding=encoding,\r\n"]
[242.980606, "o", "                    hash_key=hash_key,\r\n"]
[243.00112, "o", "                    categorize=categorize,\r\n"]
[243.021635, "o", "                )._values\r\n"]
[243.042149, "o", "                for _ in [None]\r\n"]
[243.062664, "o", "            )\r\n"]
[243.083178, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[243.103693, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[243.124207, "o", "\r\n"]
[243.144722, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[243.165237, "o", "\r\n"]
[243.185751, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[243.206266, "o", "        hashes = (\r\n"]
[243.22678, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[243.247295, "o", "            for _, series in obj.items()\r\n"]
[243.267809, "o", "        )\r\n"]
[243.288324, "o", "        num_items = len(obj.columns)\r\n"]
[243.308838, "o", "        if index:\r\n"]
[243.329353, "o", "            index_hash_generator = (\r\n"]
[243.349867, "o", "                hash_pandas_object(\r\n"]
[243.370382, "o", "                    obj.index,\r\n"]
[243.390896, "o", "                    index=False,\r\n"]
[243.411411, "o", "                    encoding=encoding,\r\n"]
[243.431925, "o", "                    hash_key=hash_key,\r\n"]
[243.45244, "o", "                    categorize=categorize,\r\n"]
[243.472954, "o", "                )._values\r\n"]
[243.493469, "o", "                for _ in [None]\r\n"]
[243.513983, "o", "            )\r\n"]
[243.534498, "o", "            num_items += 1\r\n"]
[243.555012, "o", "\r\n"]
[243.575527, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[243.596041, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[243.616556, "o", "            hashes = (x for x in _hashes)\r\n"]
[243.637071, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[243.657585, "o", "\r\n"]
[243.6781, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[243.698614, "o", "    else:\r\n"]
[243.719129, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[243.739643, "o", "\r\n"]
[243.760158, "o", "    return ser\r\n"]
[243.780672, "o", "\r\n"]
[243.801187, "o", "\r\n"]
[243.821701, "o", "def hash_tuples(\r\n"]
[243.842216, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[243.86273, "o", "    encoding: str = \"utf8\",\r\n"]
[243.883245, "o", "    hash_key: str = _default_hash_key,\r\n"]
[243.903759, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[243.924274, "o", "    \"\"\"\r\n"]
[243.944788, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[243.965303, "o", "\r\n"]
[243.985817, "o", "    Parameters\r\n"]
[244.006332, "o", "    ----------\r\n"]
[244.026846, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[244.047361, "o", "    encoding : str, default 'utf8'\r\n"]
[244.067876, "o", "    hash_key : str, default _default_hash_key\r\n"]
[244.08839, "o", "\r\n"]
[244.108905, "o", "    Returns\r\n"]
[244.129419, "o", "    -------\r\n"]
[244.149934, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[244.170448, "o", "    \"\"\"\r\n"]
[244.190963, "o", "    if not is_list_like(vals):\r\n"]
[244.211477, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[244.231992, "o", "\r\n"]
[244.252506, "o", "    from pandas import (\r\n"]
[244.273021, "o", "        Categorical,\r\n"]
[244.293535, "o", "        MultiIndex,\r\n"]
[244.31405, "o", "    )\r\n"]
[244.334564, "o", "\r\n"]
[244.355079, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[244.375593, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[244.396108, "o", "    else:\r\n"]
[244.416622, "o", "        mi = vals\r\n"]
[244.437137, "o", "\r\n"]
[244.457651, "o", "    # create a list-of-Categoricals\r\n"]
[244.478166, "o", "    cat_vals = [\r\n"]
[244.49868, "o", "        Categorical._simple_new(\r\n"]
[244.519195, "o", "            mi.codes[level],\r\n"]
[244.53971, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[244.560224, "o", "        )\r\n"]
[244.580739, "o", "        for level in range(mi.nlevels)\r\n"]
[244.601253, "o", "    ]\r\n"]
[244.621768, "o", "\r\n"]
[244.642282, "o", "    # hash the list-of-ndarrays\r\n"]
[244.662797, "o", "    hashes = (\r\n"]
[244.683311, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[244.703826, "o", "        for cat in cat_vals\r\n"]
[244.72434, "o", "    )\r\n"]
[244.744855, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[244.765369, "o", "\r\n"]
[244.785884, "o", "    return h\r\n"]
[244.806398, "o", "\r\n"]
[244.826913, "o", "\r\n"]
[244.847427, "o", "def hash_array(\r\n"]
[244.867942, "o", "    vals: ArrayLike,\r\n"]
[244.888456, "o", "    encoding: str = \"utf8\",\r\n"]
[244.908971, "o", "    hash_key: str = _default_hash_key,\r\n"]
[244.929485, "o", "    categorize: bool = True,\r\n"]
[245.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[245.002, "i", "sed -n '240,520p' pandas/core/util/hashing.py\r"]
[245.004, "o", "sed -n '240,520p' pandas/core/util/hashing.py\r\n"]
[245.051358, "o", "\u001b[?2004l\r\n"]
[245.096716, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[245.142073, "o", "    \"\"\"\r\n"]
[245.187431, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[245.232789, "o", "\r\n"]
[245.278147, "o", "    Parameters\r\n"]
[245.323505, "o", "    ----------\r\n"]
[245.368862, "o", "    vals : ndarray or ExtensionArray\r\n"]
[245.41422, "o", "        The input array to hash.\r\n"]
[245.459578, "o", "    encoding : str, default 'utf8'\r\n"]
[245.504936, "o", "        Encoding for data & key when strings.\r\n"]
[245.550294, "o", "    hash_key : str, default _default_hash_key\r\n"]
[245.595651, "o", "        Hash_key for string key to encode.\r\n"]
[245.641009, "o", "    categorize : bool, default True\r\n"]
[245.686367, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[245.731725, "o", "        efficient when the array contains duplicate values.\r\n"]
[245.777083, "o", "\r\n"]
[245.82244, "o", "    Returns\r\n"]
[245.867798, "o", "    -------\r\n"]
[245.913156, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[245.958514, "o", "        Hashed values, same length as the vals.\r\n"]
[246.003872, "o", "\r\n"]
[246.049229, "o", "    See Also\r\n"]
[246.094587, "o", "    --------\r\n"]
[246.139945, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[246.185303, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[246.230661, "o", "\r\n"]
[246.276018, "o", "    Examples\r\n"]
[246.321376, "o", "    --------\r\n"]
[246.366734, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[246.412092, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[246.45745, "o", "      dtype=uint64)\r\n"]
[246.502807, "o", "    \"\"\"\r\n"]
[246.548165, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[246.593523, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[246.638881, "o", "\r\n"]
[246.684239, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[246.729596, "o", "        return vals._hash_pandas_object(\r\n"]
[246.774954, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[246.820312, "o", "        )\r\n"]
[246.86567, "o", "\r\n"]
[246.911028, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[246.956385, "o", "        # GH#42003\r\n"]
[247.001743, "o", "        raise TypeError(\r\n"]
[247.047101, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[247.092459, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[247.137817, "o", "        )\r\n"]
[247.183174, "o", "\r\n"]
[247.228532, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[247.27389, "o", "\r\n"]
[247.319248, "o", "\r\n"]
[247.364606, "o", "def _hash_ndarray(\r\n"]
[247.409963, "o", "    vals: np.ndarray,\r\n"]
[247.455321, "o", "    encoding: str = \"utf8\",\r\n"]
[247.500679, "o", "    hash_key: str = _default_hash_key,\r\n"]
[247.546037, "o", "    categorize: bool = True,\r\n"]
[247.591394, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[247.636752, "o", "    \"\"\"\r\n"]
[247.68211, "o", "    See hash_array.__doc__.\r\n"]
[247.727468, "o", "    \"\"\"\r\n"]
[247.772826, "o", "    dtype = vals.dtype\r\n"]
[247.818183, "o", "\r\n"]
[247.863541, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[247.908899, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[247.954257, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[247.999615, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[248.044972, "o", "        return hash_real + 23 * hash_imag\r\n"]
[248.09033, "o", "\r\n"]
[248.135688, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[248.181046, "o", "    # manage it.\r\n"]
[248.226404, "o", "    if dtype == bool:\r\n"]
[248.271761, "o", "        vals = vals.astype(\"u8\")\r\n"]
[248.317119, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[248.362477, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[248.407835, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[248.453193, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[248.49855, "o", "    else:\r\n"]
[248.543908, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[248.589266, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[248.634624, "o", "        # when the values are known/likely to be unique.\r\n"]
[248.679982, "o", "        if categorize:\r\n"]
[248.725339, "o", "            from pandas import (\r\n"]
[248.770697, "o", "                Categorical,\r\n"]
[248.816055, "o", "                Index,\r\n"]
[248.861413, "o", "                factorize,\r\n"]
[248.906771, "o", "            )\r\n"]
[248.952128, "o", "\r\n"]
[248.997486, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[249.042844, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[249.088202, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[249.13356, "o", "            return cat._hash_pandas_object(\r\n"]
[249.178917, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[249.224275, "o", "            )\r\n"]
[249.269633, "o", "\r\n"]
[249.314991, "o", "        try:\r\n"]
[249.360349, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[249.405706, "o", "        except TypeError:\r\n"]
[249.451064, "o", "            # we have mixed types\r\n"]
[249.496422, "o", "            vals = hash_object_array(\r\n"]
[249.54178, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[249.587138, "o", "            )\r\n"]
[249.632495, "o", "\r\n"]
[249.677853, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[249.723211, "o", "    vals ^= vals >> 30\r\n"]
[249.768569, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[249.813927, "o", "    vals ^= vals >> 27\r\n"]
[249.859284, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[249.904642, "o", "    vals ^= vals >> 31\r\n"]
[250.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[250.002, "i", "sed -n '1,240p' pandas/_libs/hash.pyx 2>/dev/null || true\r"]
[250.004, "o", "sed -n '1,240p' pandas/_libs/hash.pyx 2>/dev/null || true\r\n"]
[250.006, "o", "\u001b[?2004l\r\n"]
[255.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[255.002, "i", "cd asv_bench\r"]
[255.004, "o", "cd asv_bench\r\n"]
[255.006, "o", "\u001b[?2004l\r\n"]
[260.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[260.002, "i", "asv profile --python=same algorithms.Hashing.time_series_string\r"]
[260.004, "o", "asv profile --python=same algorithms.Hashing.time_series_string\r\n"]
[260.030844, "o", "\u001b[?2004l\r\n"]
[260.055688, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[260.080533, "o", "\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n"]
[260.105377, "o", "\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[260.130221, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n"]
[260.155065, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mRunning (algorithms.Hashing.time_series_string--)\u001b[0m.\r\n"]
[260.17991, "o", "\u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                   7.99\u00b10.1ms\r\n"]
[260.204754, "o", "\r\n"]
[260.229598, "o", "Wed Oct  1 17:17:46 2025    /tmp/tmp7q_86psg\r\n"]
[260.254442, "o", "\r\n"]
[260.279286, "o", "         798 function calls (782 primitive calls) in 0.009 seconds\r\n"]
[260.304131, "o", "\r\n"]
[260.328975, "o", "   Ordered by: cumulative time\r\n"]
[260.353819, "o", "\r\n"]
[260.378663, "o", "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n"]
[260.403508, "o", "        1    0.000    0.000    0.009    0.009 {built-in method builtins.exec}\r\n"]
[260.428352, "o", "        1    0.000    0.000    0.009    0.009 _base.py:689(method_caller)\r\n"]
[260.453196, "o", "        1    0.000    0.000    0.009    0.009 algorithms.py:160(time_series_string)\r\n"]
[260.47804, "o", "      2/1    0.000    0.000    0.009    0.009 hashing.py:84(hash_pandas_object)\r\n"]
[260.502884, "o", "      3/2    0.000    0.000    0.008    0.004 hashing.py:235(hash_array)\r\n"]
[260.527729, "o", "      3/2    0.001    0.000    0.008    0.004 hashing.py:290(_hash_ndarray)\r\n"]
[260.552573, "o", "        1    0.000    0.000    0.005    0.005 algorithms.py:639(factorize)\r\n"]
[260.577417, "o", "        1    0.005    0.005    0.005    0.005 algorithms.py:577(factorize_array)\r\n"]
[260.602261, "o", "        1    0.000    0.000    0.001    0.001 categorical.py:2133(_hash_pandas_object)\r\n"]
[260.627106, "o", "        1    0.000    0.000    0.001    0.001 hashing.py:48(combine_hash_arrays)\r\n"]
[260.65195, "o", "        2    0.000    0.000    0.001    0.000 dtypes.py:229(__init__)\r\n"]
[260.676794, "o", "        2    0.000    0.000    0.001    0.000 dtypes.py:382(_finalize)\r\n"]
[260.701638, "o", "        1    0.000    0.000    0.001    0.001 dtypes.py:559(validate_categories)\r\n"]
[260.726482, "o", "        2    0.000    0.000    0.001    0.000 hashing.py:139(<genexpr>)\r\n"]
[260.751327, "o", "        1    0.000    0.000    0.000    0.000 base.py:2406(is_unique)\r\n"]
[260.776171, "o", "        2    0.000    0.000    0.000    0.000 series.py:369(__init__)\r\n"]
[260.801015, "o", "        1    0.000    0.000    0.000    0.000 base.py:2555(hasnans)\r\n"]
[260.825859, "o", "        1    0.000    0.000    0.000    0.000 base.py:2542(_isnan)\r\n"]
[260.850704, "o", "        1    0.000    0.000    0.000    0.000 missing.py:97(isna)\r\n"]
[260.875548, "o", "        1    0.000    0.000    0.000    0.000 missing.py:180(_isna)\r\n"]
[260.900392, "o", "        1    0.000    0.000    0.000    0.000 missing.py:223(_isna_array)\r\n"]
[260.925236, "o", "        1    0.000    0.000    0.000    0.000 missing.py:260(_isna_string_dtype)\r\n"]
[260.95008, "o", "        2    0.000    0.000    0.000    0.000 generic.py:473(_validate_dtype)\r\n"]
[260.974925, "o", "        1    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n"]
[260.999769, "o", "        2    0.000    0.000    0.000    0.000 common.py:1782(pandas_dtype)\r\n"]
[261.024613, "o", "        3    0.000    0.000    0.000    0.000 construction.py:530(sanitize_array)\r\n"]
[261.049457, "o", "        1    0.000    0.000    0.000    0.000 base.py:480(__new__)\r\n"]
[261.074302, "o", "        2    0.000    0.000    0.000    0.000 base.py:557(find)\r\n"]
[261.099146, "o", "  219/215    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n"]
[261.12399, "o", "        1    0.000    0.000    0.000    0.000 frame.py:3934(__getitem__)\r\n"]
[261.148834, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:372(_simple_new)\r\n"]
[261.173678, "o", "        1    0.000    0.000    0.000    0.000 frame.py:4471(_get_item)\r\n"]
[261.198523, "o", "        7    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\r\n"]
[261.223367, "o", "        1    0.000    0.000    0.000    0.000 frame.py:3889(_ixs)\r\n"]
[261.248211, "o", "        2    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\r\n"]
[261.273055, "o", "        2    0.000    0.000    0.000    0.000 _methods.py:59(_any)\r\n"]
[261.297899, "o", "        1    0.000    0.000    0.000    0.000 frame.py:4459(_box_col_values)\r\n"]
[261.322744, "o", "        1    0.000    0.000    0.000    0.000 cast.py:972(coerce_indexer_dtype)\r\n"]
[261.347588, "o", "        1    0.000    0.000    0.000    0.000 cast.py:1164(maybe_infer_to_datetimelike)\r\n"]
[261.372432, "o", "       42    0.000    0.000    0.000    0.000 generic.py:43(_instancecheck)\r\n"]
[261.397276, "o", "        1    0.000    0.000    0.000    0.000 base.py:837(_engine)\r\n"]
[261.422121, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:65(zeros_like)\r\n"]
[261.446965, "o", "        2    0.000    0.000    0.000    0.000 construction.py:774(_try_cast)\r\n"]
[261.471809, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:269(_get_hashtable_algo)\r\n"]
[261.496653, "o", "        2    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n"]
[261.521497, "o", "        2    0.000    0.000    0.000    0.000 cast.py:1608(maybe_cast_to_integer_array)\r\n"]
[261.546342, "o", "        2    0.000    0.000    0.000    0.000 managers.py:1977(from_array)\r\n"]
[261.571186, "o", "        4    0.000    0.000    0.000    0.000 generic.py:6120(__setattr__)\r\n"]
[261.59603, "o", "       22    0.000    0.000    0.000    0.000 base.py:242(construct_from_string)\r\n"]
[261.620874, "o", "        1    0.000    0.000    0.000    0.000 frame.py:682(_constructor_sliced_from_mgr)\r\n"]
[261.645719, "o", "       42    0.000    0.000    0.000    0.000 generic.py:38(_check)\r\n"]
[261.670563, "o", "        3    0.000    0.000    0.000    0.000 numerictypes.py:471(issubdtype)\r\n"]
[261.695407, "o", "        1    0.000    0.000    0.000    0.000 generic.py:292(_from_mgr)\r\n"]
[261.720251, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:289(_check_object_for_strings)\r\n"]
[261.745095, "o", "        1    0.000    0.000    0.000    0.000 common.py:234(asarray_tuplesafe)\r\n"]
[261.76994, "o", "        4    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\r\n"]
[261.794784, "o", "        2    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\r\n"]
[261.819628, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:1780(isna)\r\n"]
[261.844472, "o", "        2    0.000    0.000    0.000    0.000 algorithms.py:188(_reconstruct_data)\r\n"]
[261.869317, "o", "    28/19    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n"]
[261.894161, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:303(full)\r\n"]
[261.919005, "o", "        2    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\r\n"]
[261.943849, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\r\n"]
[261.968693, "o", "        1    0.000    0.000    0.000    0.000 managers.py:1151(iget)\r\n"]
[261.993538, "o", "        2    0.000    0.000    0.000    0.000 series.py:737(name)\r\n"]
[262.018382, "o", "        3    0.000    0.000    0.000    0.000 generic.py:256(__init__)\r\n"]
[262.043226, "o", "        2    0.000    0.000    0.000    0.000 generic.py:759(_set_axis)\r\n"]
[262.06807, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:869(construct_from_string)\r\n"]
[262.092915, "o", "        3    0.000    0.000    0.000    0.000 base.py:7646(maybe_extract_name)\r\n"]
[262.117759, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:110(_ensure_data)\r\n"]
[262.142603, "o", "        6    0.000    0.000    0.000    0.000 numerictypes.py:289(issubclass_)\r\n"]
[262.167447, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1376(construct_from_string)\r\n"]
[262.192291, "o", "        1    0.000    0.000    0.000    0.000 dtypes.py:595(update_dtype)\r\n"]
[262.217136, "o", "        1    0.000    0.000    0.000    0.000 base.py:4998(_get_engine_target)\r\n"]
[262.24198, "o", "        1    0.000    0.000    0.000    0.000 generic.py:6054(__finalize__)\r\n"]
[262.266824, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2232(new_block)\r\n"]
[262.291668, "o", "        2    0.000    0.000    0.000    0.000 common.py:140(is_object_dtype)\r\n"]
[262.316513, "o", "        1    0.000    0.000    0.000    0.000 base.py:643(_simple_new)\r\n"]
[262.341357, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:351(construct_from_string)\r\n"]
[262.366201, "o", "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1053(_handle_fromlist)\r\n"]
[262.391045, "o", "        2    0.000    0.000    0.000    0.000 common.py:1757(validate_all_hashable)\r\n"]
[262.415889, "o", "        2    0.000    0.000    0.000    0.000 managers.py:269(set_axis)\r\n"]
[262.440734, "o", "       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n"]
[262.465578, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1115(construct_from_string)\r\n"]
[262.490422, "o", "        2    0.000    0.000    0.000    0.000 series.py:686(name)\r\n"]
[262.515266, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2161(maybe_coerce_values)\r\n"]
[262.540111, "o", "        8    0.000    0.000    0.000    0.000 inference.py:378(is_hashable)\r\n"]
[262.564955, "o", "        2    0.000    0.000    0.000    0.000 series.py:783(_values)\r\n"]
[262.589799, "o", "       26    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n"]
[262.614643, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\r\n"]
[262.639487, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:350(_name_get)\r\n"]
[262.664332, "o", "        2    0.000    0.000    0.000    0.000 common.py:594(require_length_match)\r\n"]
[262.689176, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:2329(construct_from_string)\r\n"]
[262.71402, "o", "        1    0.000    0.000    0.000    0.000 base.py:298(is_dtype)\r\n"]
[262.738864, "o", "        1    0.000    0.000    0.000    0.000 common.py:600(is_string_dtype)\r\n"]
[262.763709, "o", "        5    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\r\n"]
[262.788553, "o", "        3    0.000    0.000    0.000    0.000 construction.py:701(_sanitize_ndim)\r\n"]
[262.813397, "o", "        2    0.000    0.000    0.000    0.000 managers.py:274(_validate_set_axis)\r\n"]
[262.838241, "o", "        3    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)\r\n"]
[262.863085, "o", "        8    0.000    0.000    0.000    0.000 range.py:1164(__len__)\r\n"]
[262.88793, "o", "        4    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\r\n"]
[262.912774, "o", "        2    0.000    0.000    0.000    0.000 common.py:1620(_is_dtype_type)\r\n"]
[262.937618, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2128(internal_values)\r\n"]
[262.962462, "o", "        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n"]
[262.987307, "o", "        1    0.000    0.000    0.000    0.000 algorithms.py:223(_ensure_arraylike)\r\n"]
[263.012151, "o", "        1    0.000    0.000    0.000    0.000 base.py:461(_engine_type)\r\n"]
[263.036995, "o", "        1    0.000    0.000    0.000    0.000 base.py:5205(__getitem__)\r\n"]
[263.061839, "o", "        2    0.000    0.000    0.000    0.000 blocks.py:2190(get_block_type)\r\n"]
[263.086683, "o", "        1    0.000    0.000    0.000    0.000 base.py:5155(__contains__)\r\n"]
[263.111528, "o", "        4    0.000    0.000    0.000    0.000 construction.py:429(extract_array)\r\n"]
[263.136372, "o", "        1    0.000    0.000    0.000    0.000 common.py:1561(_is_dtype)\r\n"]
[263.161216, "o", "        1    0.000    0.000    0.000    0.000 base.py:2313(_can_hold_na)\r\n"]
[263.18606, "o", "        2    0.000    0.000    0.000    0.000 string_.py:235(construct_from_string)\r\n"]
[263.210905, "o", "        5    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n"]
[263.235749, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:1927(construct_from_string)\r\n"]
[263.260593, "o", "        3    0.000    0.000    0.000    0.000 flags.py:60(__init__)\r\n"]
[263.285437, "o", "        1    0.000    0.000    0.000    0.000 indexing.py:2746(check_dict_or_set_indexers)\r\n"]
[263.310281, "o", "        3    0.000    0.000    0.000    0.000 construction.py:740(_sanitize_str_dtypes)\r\n"]
[263.335126, "o", "        2    0.000    0.000    0.000    0.000 common.py:1509(is_ea_or_datetimelike_dtype)\r\n"]
[263.35997, "o", "        4    0.000    0.000    0.000    0.000 common.py:1776(<genexpr>)\r\n"]
[263.384814, "o", "        2    0.000    0.000    0.000    0.000 generic.py:6103(__getattr__)\r\n"]
[263.409658, "o", "        4    0.000    0.000    0.000    0.000 base.py:7562(ensure_index)\r\n"]
[263.434503, "o", "       10    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n"]
[263.459347, "o", "        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\r\n"]
[263.484191, "o", "        1    0.000    0.000    0.000    0.000 base.py:3548(get_loc)\r\n"]
[263.509035, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:764(categories)\r\n"]
[263.533879, "o", "        3    0.000    0.000    0.000    0.000 construction.py:494(ensure_wrapped_if_datetimelike)\r\n"]
[263.558724, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:1(__getattr__)\r\n"]
[263.583568, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n"]
[263.608412, "o", "        6    0.000    0.000    0.000    0.000 base.py:4972(_values)\r\n"]
[263.633256, "o", "        1    0.000    0.000    0.000    0.000 base.py:585(_ensure_array)\r\n"]
[263.658101, "o", "        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\r\n"]
[263.682945, "o", "        2    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\r\n"]
[263.707789, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:33(using_string_dtype)\r\n"]
[263.732633, "o", "        3    0.000    0.000    0.000    0.000 construction.py:763(_maybe_repeat)\r\n"]
[263.757477, "o", "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n"]
[263.782322, "o", "       14    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\r\n"]
[263.807166, "o", "        9    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n"]
[263.83201, "o", "        3    0.000    0.000    0.000    0.000 managers.py:1951(__init__)\r\n"]
[263.856854, "o", "        2    0.000    0.000    0.000    0.000 dtypes.py:540(validate_ordered)\r\n"]
[263.881698, "o", "        1    0.000    0.000    0.000    0.000 flags.py:96(allows_duplicate_labels)\r\n"]
[263.906543, "o", "        2    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\r\n"]
[263.931387, "o", "        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\r\n"]
[263.956231, "o", "        1    0.000    0.000    0.000    0.000 common.py:1171(needs_i8_conversion)\r\n"]
[263.981075, "o", "        1    0.000    0.000    0.000    0.000 blocks.py:958(iget)\r\n"]
[264.00592, "o", "        1    0.000    0.000    0.000    0.000 common.py:377(apply_if_callable)\r\n"]
[264.030764, "o", "        2    0.000    0.000    0.000    0.000 categorical.py:2179(_codes)\r\n"]
[264.055608, "o", "        1    0.000    0.000    0.000    0.000 base.py:825(_reset_identity)\r\n"]
[264.080452, "o", "        2    0.000    0.000    0.000    0.000 common.py:126(<lambda>)\r\n"]
[264.105296, "o", "        1    0.000    0.000    0.000    0.000 base.py:603(_dtype_to_subclass)\r\n"]
[264.130141, "o", "        2    0.000    0.000    0.000    0.000 common.py:124(classes)\r\n"]
[264.154985, "o", "        1    0.000    0.000    0.000    0.000 common.py:641(condition)\r\n"]
[264.179829, "o", "        2    0.000    0.000    0.000    0.000 common.py:593(is_string_or_object_np_dtype)\r\n"]
[264.204673, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\r\n"]
[264.229518, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2054(_block)\r\n"]
[264.254362, "o", "        2    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\r\n"]
[264.279206, "o", "        1    0.000    0.000    0.000    0.000 common.py:1585(_get_dtype)\r\n"]
[264.30405, "o", "        2    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55ebf3736640}\r\n"]
[264.328894, "o", "        1    0.000    0.000    0.000    0.000 base.py:906(__len__)\r\n"]
[264.353739, "o", "        1    0.000    0.000    0.000    0.000 common.py:156(cast_scalar_indexer)\r\n"]
[264.378583, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.next}\r\n"]
[264.403427, "o", "        5    0.000    0.000    0.000    0.000 typing.py:1737(cast)\r\n"]
[264.428271, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n"]
[264.453116, "o", "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n"]
[264.47796, "o", "        1    0.000    0.000    0.000    0.000 _dtype.py:334(_name_includes_bit_suffix)\r\n"]
[264.502804, "o", "        2    0.000    0.000    0.000    0.000 multiarray.py:1101(copyto)\r\n"]
[264.527648, "o", "        3    0.000    0.000    0.000    0.000 generic.py:358(flags)\r\n"]
[264.552492, "o", "        1    0.000    0.000    0.000    0.000 categorical.py:498(dtype)\r\n"]
[264.577337, "o", "        1    0.000    0.000    0.000    0.000 managers.py:222(blknos)\r\n"]
[264.602181, "o", "        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\r\n"]
[264.627025, "o", "        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n"]
[264.651869, "o", "        1    0.000    0.000    0.000    0.000 base.py:978(dtype)\r\n"]
[264.676714, "o", "        2    0.000    0.000    0.000    0.000 base.py:367(ndim)\r\n"]
[264.701558, "o", "        3    0.000    0.000    0.000    0.000 dtypes.py:634(categories)\r\n"]
[264.726402, "o", "        1    0.000    0.000    0.000    0.000 managers.py:238(blklocs)\r\n"]
[264.751246, "o", "        2    0.000    0.000    0.000    0.000 flags.py:64(allows_duplicate_labels)\r\n"]
[264.77609, "o", "        1    0.000    0.000    0.000    0.000 base.py:6572(_maybe_cast_indexer)\r\n"]
[264.800935, "o", "        1    0.000    0.000    0.000    0.000 numeric.py:59(_zeros_like_dispatcher)\r\n"]
[264.825779, "o", "        1    0.000    0.000    0.000    0.000 multiarray.py:82(empty_like)\r\n"]
[264.850623, "o", "        1    0.000    0.000    0.000    0.000 generic.py:316(attrs)\r\n"]
[264.875467, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\r\n"]
[264.900312, "o", "        1    0.000    0.000    0.000    0.000 dtypes.py:651(ordered)\r\n"]
[264.925156, "o", "\r\n"]
[265.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[265.002, "i", "cd /workspace/repo\r"]
[265.004, "o", "cd /workspace/repo\r\n"]
[265.006, "o", "\u001b[?2004l\r\n"]
[270.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[270.002, "i", "sed -n '1,260p' pandas/core/util/hashing.py\r"]
[270.004, "o", "sed -n '1,260p' pandas/core/util/hashing.py\r\n"]
[270.024943, "o", "\u001b[?2004l\r\n"]
[270.043885, "o", "\"\"\"\r\n"]
[270.062828, "o", "data hash pandas / numpy objects\r\n"]
[270.08177, "o", "\"\"\"\r\n"]
[270.100713, "o", "\r\n"]
[270.119655, "o", "from __future__ import annotations\r\n"]
[270.138598, "o", "\r\n"]
[270.15754, "o", "import itertools\r\n"]
[270.176483, "o", "from typing import TYPE_CHECKING\r\n"]
[270.195425, "o", "\r\n"]
[270.214368, "o", "import numpy as np\r\n"]
[270.23331, "o", "\r\n"]
[270.252253, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[270.271195, "o", "\r\n"]
[270.290138, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[270.30908, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[270.328023, "o", "from pandas.core.dtypes.generic import (\r\n"]
[270.346966, "o", "    ABCDataFrame,\r\n"]
[270.365908, "o", "    ABCExtensionArray,\r\n"]
[270.384851, "o", "    ABCIndex,\r\n"]
[270.403793, "o", "    ABCMultiIndex,\r\n"]
[270.422736, "o", "    ABCSeries,\r\n"]
[270.441678, "o", ")\r\n"]
[270.460621, "o", "\r\n"]
[270.479563, "o", "if TYPE_CHECKING:\r\n"]
[270.498506, "o", "    from collections.abc import (\r\n"]
[270.517448, "o", "        Hashable,\r\n"]
[270.536391, "o", "        Iterable,\r\n"]
[270.555333, "o", "        Iterator,\r\n"]
[270.574276, "o", "    )\r\n"]
[270.593218, "o", "\r\n"]
[270.612161, "o", "    from pandas._typing import (\r\n"]
[270.631103, "o", "        ArrayLike,\r\n"]
[270.650046, "o", "        npt,\r\n"]
[270.668989, "o", "    )\r\n"]
[270.687931, "o", "\r\n"]
[270.706874, "o", "    from pandas import (\r\n"]
[270.725816, "o", "        DataFrame,\r\n"]
[270.744759, "o", "        Index,\r\n"]
[270.763701, "o", "        MultiIndex,\r\n"]
[270.782644, "o", "        Series,\r\n"]
[270.801586, "o", "    )\r\n"]
[270.820529, "o", "\r\n"]
[270.839471, "o", "\r\n"]
[270.858414, "o", "# 16 byte long hashing key\r\n"]
[270.877356, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[270.896299, "o", "\r\n"]
[270.915241, "o", "\r\n"]
[270.934184, "o", "def combine_hash_arrays(\r\n"]
[270.953126, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[270.972069, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[270.991011, "o", "    \"\"\"\r\n"]
[271.009954, "o", "    Parameters\r\n"]
[271.028897, "o", "    ----------\r\n"]
[271.047839, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[271.066782, "o", "    num_items : int\r\n"]
[271.085724, "o", "\r\n"]
[271.104667, "o", "    Returns\r\n"]
[271.123609, "o", "    -------\r\n"]
[271.142552, "o", "    np.ndarray[uint64]\r\n"]
[271.161494, "o", "\r\n"]
[271.180437, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[271.199379, "o", "    \"\"\"\r\n"]
[271.218322, "o", "    try:\r\n"]
[271.237264, "o", "        first = next(arrays)\r\n"]
[271.256207, "o", "    except StopIteration:\r\n"]
[271.275149, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[271.294092, "o", "\r\n"]
[271.313034, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[271.331977, "o", "\r\n"]
[271.35092, "o", "    mult = np.uint64(1000003)\r\n"]
[271.369862, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[271.388805, "o", "    last_i = 0\r\n"]
[271.407747, "o", "    for i, a in enumerate(arrays):\r\n"]
[271.42669, "o", "        inverse_i = num_items - i\r\n"]
[271.445632, "o", "        out ^= a\r\n"]
[271.464575, "o", "        out *= mult\r\n"]
[271.483517, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[271.50246, "o", "        last_i = i\r\n"]
[271.521402, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[271.540345, "o", "    out += np.uint64(97531)\r\n"]
[271.559287, "o", "    return out\r\n"]
[271.57823, "o", "\r\n"]
[271.597172, "o", "\r\n"]
[271.616115, "o", "def hash_pandas_object(\r\n"]
[271.635057, "o", "    obj: Index | DataFrame | Series,\r\n"]
[271.654, "o", "    index: bool = True,\r\n"]
[271.672943, "o", "    encoding: str = \"utf8\",\r\n"]
[271.691885, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[271.710828, "o", "    categorize: bool = True,\r\n"]
[271.72977, "o", ") -> Series:\r\n"]
[271.748713, "o", "    \"\"\"\r\n"]
[271.767655, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[271.786598, "o", "\r\n"]
[271.80554, "o", "    Parameters\r\n"]
[271.824483, "o", "    ----------\r\n"]
[271.843425, "o", "    obj : Index, Series, or DataFrame\r\n"]
[271.862368, "o", "    index : bool, default True\r\n"]
[271.88131, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[271.900253, "o", "    encoding : str, default 'utf8'\r\n"]
[271.919195, "o", "        Encoding for data & key when strings.\r\n"]
[271.938138, "o", "    hash_key : str, default _default_hash_key\r\n"]
[271.95708, "o", "        Hash_key for string key to encode.\r\n"]
[271.976023, "o", "    categorize : bool, default True\r\n"]
[271.994966, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[272.013908, "o", "        efficient when the array contains duplicate values.\r\n"]
[272.032851, "o", "\r\n"]
[272.051793, "o", "    Returns\r\n"]
[272.070736, "o", "    -------\r\n"]
[272.089678, "o", "    Series of uint64\r\n"]
[272.108621, "o", "        Same length as the object.\r\n"]
[272.127563, "o", "\r\n"]
[272.146506, "o", "    Examples\r\n"]
[272.165448, "o", "    --------\r\n"]
[272.184391, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[272.203333, "o", "    0    14639053686158035780\r\n"]
[272.222276, "o", "    1     3869563279212530728\r\n"]
[272.241218, "o", "    2      393322362522515241\r\n"]
[272.260161, "o", "    dtype: uint64\r\n"]
[272.279103, "o", "    \"\"\"\r\n"]
[272.298046, "o", "    from pandas import Series\r\n"]
[272.316989, "o", "\r\n"]
[272.335931, "o", "    if hash_key is None:\r\n"]
[272.354874, "o", "        hash_key = _default_hash_key\r\n"]
[272.373816, "o", "\r\n"]
[272.392759, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[272.411701, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[272.430644, "o", "\r\n"]
[272.449586, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[272.468529, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[272.487471, "o", "            \"uint64\", copy=False\r\n"]
[272.506414, "o", "        )\r\n"]
[272.525356, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[272.544299, "o", "\r\n"]
[272.563241, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[272.582184, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[272.601126, "o", "            \"uint64\", copy=False\r\n"]
[272.620069, "o", "        )\r\n"]
[272.639011, "o", "        if index:\r\n"]
[272.657954, "o", "            index_iter = (\r\n"]
[272.676897, "o", "                hash_pandas_object(\r\n"]
[272.695839, "o", "                    obj.index,\r\n"]
[272.714782, "o", "                    index=False,\r\n"]
[272.733724, "o", "                    encoding=encoding,\r\n"]
[272.752667, "o", "                    hash_key=hash_key,\r\n"]
[272.771609, "o", "                    categorize=categorize,\r\n"]
[272.790552, "o", "                )._values\r\n"]
[272.809494, "o", "                for _ in [None]\r\n"]
[272.828437, "o", "            )\r\n"]
[272.847379, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[272.866322, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[272.885264, "o", "\r\n"]
[272.904207, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[272.923149, "o", "\r\n"]
[272.942092, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[272.961034, "o", "        hashes = (\r\n"]
[272.979977, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[272.99892, "o", "            for _, series in obj.items()\r\n"]
[273.017862, "o", "        )\r\n"]
[273.036805, "o", "        num_items = len(obj.columns)\r\n"]
[273.055747, "o", "        if index:\r\n"]
[273.07469, "o", "            index_hash_generator = (\r\n"]
[273.093632, "o", "                hash_pandas_object(\r\n"]
[273.112575, "o", "                    obj.index,\r\n"]
[273.131517, "o", "                    index=False,\r\n"]
[273.15046, "o", "                    encoding=encoding,\r\n"]
[273.169402, "o", "                    hash_key=hash_key,\r\n"]
[273.188345, "o", "                    categorize=categorize,\r\n"]
[273.207287, "o", "                )._values\r\n"]
[273.22623, "o", "                for _ in [None]\r\n"]
[273.245172, "o", "            )\r\n"]
[273.264115, "o", "            num_items += 1\r\n"]
[273.283057, "o", "\r\n"]
[273.302, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[273.320943, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[273.339885, "o", "            hashes = (x for x in _hashes)\r\n"]
[273.358828, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[273.37777, "o", "\r\n"]
[273.396713, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[273.415655, "o", "    else:\r\n"]
[273.434598, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[273.45354, "o", "\r\n"]
[273.472483, "o", "    return ser\r\n"]
[273.491425, "o", "\r\n"]
[273.510368, "o", "\r\n"]
[273.52931, "o", "def hash_tuples(\r\n"]
[273.548253, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[273.567195, "o", "    encoding: str = \"utf8\",\r\n"]
[273.586138, "o", "    hash_key: str = _default_hash_key,\r\n"]
[273.60508, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[273.624023, "o", "    \"\"\"\r\n"]
[273.642966, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[273.661908, "o", "\r\n"]
[273.680851, "o", "    Parameters\r\n"]
[273.699793, "o", "    ----------\r\n"]
[273.718736, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[273.737678, "o", "    encoding : str, default 'utf8'\r\n"]
[273.756621, "o", "    hash_key : str, default _default_hash_key\r\n"]
[273.775563, "o", "\r\n"]
[273.794506, "o", "    Returns\r\n"]
[273.813448, "o", "    -------\r\n"]
[273.832391, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[273.851333, "o", "    \"\"\"\r\n"]
[273.870276, "o", "    if not is_list_like(vals):\r\n"]
[273.889218, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[273.908161, "o", "\r\n"]
[273.927103, "o", "    from pandas import (\r\n"]
[273.946046, "o", "        Categorical,\r\n"]
[273.964989, "o", "        MultiIndex,\r\n"]
[273.983931, "o", "    )\r\n"]
[274.002874, "o", "\r\n"]
[274.021816, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[274.040759, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[274.059701, "o", "    else:\r\n"]
[274.078644, "o", "        mi = vals\r\n"]
[274.097586, "o", "\r\n"]
[274.116529, "o", "    # create a list-of-Categoricals\r\n"]
[274.135471, "o", "    cat_vals = [\r\n"]
[274.154414, "o", "        Categorical._simple_new(\r\n"]
[274.173356, "o", "            mi.codes[level],\r\n"]
[274.192299, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[274.211241, "o", "        )\r\n"]
[274.230184, "o", "        for level in range(mi.nlevels)\r\n"]
[274.249126, "o", "    ]\r\n"]
[274.268069, "o", "\r\n"]
[274.287011, "o", "    # hash the list-of-ndarrays\r\n"]
[274.305954, "o", "    hashes = (\r\n"]
[274.324897, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[274.343839, "o", "        for cat in cat_vals\r\n"]
[274.362782, "o", "    )\r\n"]
[274.381724, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[274.400667, "o", "\r\n"]
[274.419609, "o", "    return h\r\n"]
[274.438552, "o", "\r\n"]
[274.457494, "o", "\r\n"]
[274.476437, "o", "def hash_array(\r\n"]
[274.495379, "o", "    vals: ArrayLike,\r\n"]
[274.514322, "o", "    encoding: str = \"utf8\",\r\n"]
[274.533264, "o", "    hash_key: str = _default_hash_key,\r\n"]
[274.552207, "o", "    categorize: bool = True,\r\n"]
[274.571149, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[274.590092, "o", "    \"\"\"\r\n"]
[274.609034, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[274.627977, "o", "\r\n"]
[274.64692, "o", "    Parameters\r\n"]
[274.665862, "o", "    ----------\r\n"]
[274.684805, "o", "    vals : ndarray or ExtensionArray\r\n"]
[274.703747, "o", "        The input array to hash.\r\n"]
[274.72269, "o", "    encoding : str, default 'utf8'\r\n"]
[274.741632, "o", "        Encoding for data & key when strings.\r\n"]
[274.760575, "o", "    hash_key : str, default _default_hash_key\r\n"]
[274.779517, "o", "        Hash_key for string key to encode.\r\n"]
[274.79846, "o", "    categorize : bool, default True\r\n"]
[274.817402, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[274.836345, "o", "        efficient when the array contains duplicate values.\r\n"]
[274.855287, "o", "\r\n"]
[274.87423, "o", "    Returns\r\n"]
[274.893172, "o", "    -------\r\n"]
[274.912115, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[274.931057, "o", "        Hashed values, same length as the vals.\r\n"]
[275.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[275.002, "i", "sed -n '260,620p' pandas/core/util/hashing.py\r"]
[275.004, "o", "sed -n '260,620p' pandas/core/util/hashing.py\r\n"]
[275.061551, "o", "\u001b[?2004l\r\n"]
[275.117101, "o", "\r\n"]
[275.172652, "o", "    See Also\r\n"]
[275.228202, "o", "    --------\r\n"]
[275.283753, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[275.339303, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[275.394854, "o", "\r\n"]
[275.450404, "o", "    Examples\r\n"]
[275.505955, "o", "    --------\r\n"]
[275.561506, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[275.617056, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[275.672607, "o", "      dtype=uint64)\r\n"]
[275.728157, "o", "    \"\"\"\r\n"]
[275.783708, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[275.839258, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[275.894809, "o", "\r\n"]
[275.95036, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[276.00591, "o", "        return vals._hash_pandas_object(\r\n"]
[276.061461, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[276.117011, "o", "        )\r\n"]
[276.172562, "o", "\r\n"]
[276.228112, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[276.283663, "o", "        # GH#42003\r\n"]
[276.339213, "o", "        raise TypeError(\r\n"]
[276.394764, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[276.450315, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[276.505865, "o", "        )\r\n"]
[276.561416, "o", "\r\n"]
[276.616966, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[276.672517, "o", "\r\n"]
[276.728067, "o", "\r\n"]
[276.783618, "o", "def _hash_ndarray(\r\n"]
[276.839169, "o", "    vals: np.ndarray,\r\n"]
[276.894719, "o", "    encoding: str = \"utf8\",\r\n"]
[276.95027, "o", "    hash_key: str = _default_hash_key,\r\n"]
[277.00582, "o", "    categorize: bool = True,\r\n"]
[277.061371, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[277.116921, "o", "    \"\"\"\r\n"]
[277.172472, "o", "    See hash_array.__doc__.\r\n"]
[277.228022, "o", "    \"\"\"\r\n"]
[277.283573, "o", "    dtype = vals.dtype\r\n"]
[277.339124, "o", "\r\n"]
[277.394674, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[277.450225, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[277.505775, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[277.561326, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[277.616876, "o", "        return hash_real + 23 * hash_imag\r\n"]
[277.672427, "o", "\r\n"]
[277.727978, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[277.783528, "o", "    # manage it.\r\n"]
[277.839079, "o", "    if dtype == bool:\r\n"]
[277.894629, "o", "        vals = vals.astype(\"u8\")\r\n"]
[277.95018, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[278.00573, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[278.061281, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[278.116831, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[278.172382, "o", "    else:\r\n"]
[278.227933, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[278.283483, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[278.339034, "o", "        # when the values are known/likely to be unique.\r\n"]
[278.394584, "o", "        if categorize:\r\n"]
[278.450135, "o", "            from pandas import (\r\n"]
[278.505685, "o", "                Categorical,\r\n"]
[278.561236, "o", "                Index,\r\n"]
[278.616787, "o", "                factorize,\r\n"]
[278.672337, "o", "            )\r\n"]
[278.727888, "o", "\r\n"]
[278.783438, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[278.838989, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[278.894539, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[278.95009, "o", "            return cat._hash_pandas_object(\r\n"]
[279.00564, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[279.061191, "o", "            )\r\n"]
[279.116742, "o", "\r\n"]
[279.172292, "o", "        try:\r\n"]
[279.227843, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[279.283393, "o", "        except TypeError:\r\n"]
[279.338944, "o", "            # we have mixed types\r\n"]
[279.394494, "o", "            vals = hash_object_array(\r\n"]
[279.450045, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[279.505596, "o", "            )\r\n"]
[279.561146, "o", "\r\n"]
[279.616697, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[279.672247, "o", "    vals ^= vals >> 30\r\n"]
[279.727798, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[279.783348, "o", "    vals ^= vals >> 27\r\n"]
[279.838899, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[279.894449, "o", "    vals ^= vals >> 31\r\n"]
[280.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[280.002, "i", "ls -la pandas/_libs | sed -n '1,200p'\r"]
[280.004, "o", "ls -la pandas/_libs | sed -n '1,200p'\r\n"]
[280.072811, "o", "\u001b[?2004l\r\n"]
[280.139622, "o", "total 880\r\n"]
[280.206432, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 .\r\n"]
[280.273243, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 ..\r\n"]
[280.340054, "o", "-rw-r--r-- 1 root root   673 Sep 13 19:32 __init__.py\r\n"]
[280.406865, "o", "-rw-r--r-- 1 root root   449 Sep 13 19:32 algos.pxd\r\n"]
[280.473676, "o", "-rw-r--r-- 1 root root 16379 Sep 13 19:32 algos.pyi\r\n"]
[280.540486, "o", "-rw-r--r-- 1 root root 45563 Sep 13 19:33 algos.pyx\r\n"]
[280.607297, "o", "-rw-r--r-- 1 root root  2249 Sep 13 19:32 algos_common_helper.pxi.in\r\n"]
[280.674108, "o", "-rw-r--r-- 1 root root  6913 Sep 13 19:32 algos_take_helper.pxi.in\r\n"]
[280.740919, "o", "-rw-r--r-- 1 root root   233 Sep 13 19:32 arrays.pxd\r\n"]
[280.80773, "o", "-rw-r--r-- 1 root root  1185 Sep 13 19:33 arrays.pyi\r\n"]
[280.874541, "o", "-rw-r--r-- 1 root root  6321 Sep 13 19:32 arrays.pyx\r\n"]
[280.941351, "o", "-rw-r--r-- 1 root root   423 Sep 13 19:32 byteswap.pyi\r\n"]
[281.008162, "o", "-rw-r--r-- 1 root root  2411 Sep 13 19:32 byteswap.pyx\r\n"]
[281.074973, "o", "-rw-r--r-- 1 root root   510 Sep 13 19:32 dtypes.pxd\r\n"]
[281.141784, "o", "-rw-r--r-- 1 root root   132 Sep 13 19:32 free_threading_config.pxi.in\r\n"]
[281.208595, "o", "-rw-r--r-- 1 root root  7757 Sep 13 19:33 groupby.pyi\r\n"]
[281.275405, "o", "-rw-r--r-- 1 root root 71099 Sep 13 19:33 groupby.pyx\r\n"]
[281.342216, "o", "-rw-r--r-- 1 root root   181 Sep 13 19:32 hashing.pyi\r\n"]
[281.409027, "o", "-rw-r--r-- 1 root root  4835 Sep 13 19:32 hashing.pyx\r\n"]
[281.475838, "o", "-rw-r--r-- 1 root root  4661 Sep 13 19:32 hashtable.pxd\r\n"]
[281.542649, "o", "-rw-r--r-- 1 root root  8174 Sep 13 19:33 hashtable.pyi\r\n"]
[281.609459, "o", "-rw-r--r-- 1 root root  3107 Sep 13 19:32 hashtable.pyx\r\n"]
[281.67627, "o", "-rw-r--r-- 1 root root 55054 Sep 13 19:32 hashtable_class_helper.pxi.in\r\n"]
[281.743081, "o", "-rw-r--r-- 1 root root 14621 Sep 13 19:32 hashtable_func_helper.pxi.in\r\n"]
[281.809892, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:32 include\r\n"]
[281.876703, "o", "-rw-r--r-- 1 root root  3842 Sep 13 19:32 index.pyi\r\n"]
[281.943514, "o", "-rw-r--r-- 1 root root 42080 Sep 13 19:33 index.pyx\r\n"]
[282.010324, "o", "-rw-r--r-- 1 root root  2326 Sep 13 19:32 index_class_helper.pxi.in\r\n"]
[282.077135, "o", "-rw-r--r-- 1 root root   427 Sep 13 19:32 indexing.pyi\r\n"]
[282.143946, "o", "-rw-r--r-- 1 root root   778 Sep 13 19:32 indexing.pyx\r\n"]
[282.210757, "o", "-rw-r--r-- 1 root root  2761 Sep 13 19:33 internals.pyi\r\n"]
[282.277568, "o", "-rw-r--r-- 1 root root 30466 Sep 13 19:33 internals.pyx\r\n"]
[282.344378, "o", "-rw-r--r-- 1 root root  5378 Sep 13 19:32 interval.pyi\r\n"]
[282.411189, "o", "-rw-r--r-- 1 root root 20754 Sep 13 19:32 interval.pyx\r\n"]
[282.478, "o", "-rw-r--r-- 1 root root 15271 Sep 13 19:32 intervaltree.pxi.in\r\n"]
[282.544811, "o", "-rw-r--r-- 1 root root  2780 Sep 13 19:32 join.pyi\r\n"]
[282.611622, "o", "-rw-r--r-- 1 root root 27790 Sep 13 19:32 join.pyx\r\n"]
[282.678432, "o", "-rw-r--r-- 1 root root   496 Sep 13 19:33 json.pyi\r\n"]
[282.745243, "o", "-rw-r--r-- 1 root root  3821 Sep 13 19:32 khash.pxd\r\n"]
[282.812054, "o", "-rw-r--r-- 1 root root  1442 Sep 13 19:32 khash_for_primitive_helper.pxi.in\r\n"]
[282.878865, "o", "-rw-r--r-- 1 root root   139 Sep 13 19:32 lib.pxd\r\n"]
[282.945676, "o", "-rw-r--r-- 1 root root  7372 Sep 13 19:33 lib.pyi\r\n"]
[283.012486, "o", "-rw-r--r-- 1 root root 95396 Sep 13 19:33 lib.pyx\r\n"]
[283.079297, "o", "-rw-r--r-- 1 root root  5859 Sep 13 19:33 meson.build\r\n"]
[283.146108, "o", "-rw-r--r-- 1 root root   435 Sep 13 19:32 missing.pxd\r\n"]
[283.212919, "o", "-rw-r--r-- 1 root root   478 Sep 13 19:32 missing.pyi\r\n"]
[283.27973, "o", "-rw-r--r-- 1 root root 14452 Sep 13 19:33 missing.pyx\r\n"]
[283.346541, "o", "-rw-r--r-- 1 root root  1318 Sep 13 19:33 ops.pyi\r\n"]
[283.413351, "o", "-rw-r--r-- 1 root root  7776 Sep 13 19:32 ops.pyx\r\n"]
[283.480162, "o", "-rw-r--r-- 1 root root   124 Sep 13 19:32 ops_dispatch.pyi\r\n"]
[283.546973, "o", "-rw-r--r-- 1 root root  2570 Sep 13 19:32 ops_dispatch.pyx\r\n"]
[283.613784, "o", "-rw-r--r-- 1 root root  2378 Sep 13 19:33 parsers.pyi\r\n"]
[283.680595, "o", "-rw-r--r-- 1 root root 71983 Sep 13 19:33 parsers.pyx\r\n"]
[283.747405, "o", "-rw-r--r-- 1 root root   717 Sep 13 19:33 properties.pyi\r\n"]
[283.814216, "o", "-rw-r--r-- 1 root root  1633 Sep 13 19:32 properties.pyx\r\n"]
[283.881027, "o", "-rw-r--r-- 1 root root   419 Sep 13 19:32 reshape.pyi\r\n"]
[283.947838, "o", "-rw-r--r-- 1 root root  2819 Sep 13 19:32 reshape.pyx\r\n"]
[284.014649, "o", "-rw-r--r-- 1 root root   224 Sep 13 19:32 sas.pyi\r\n"]
[284.081459, "o", "-rw-r--r-- 1 root root 19192 Sep 13 19:32 sas.pyx\r\n"]
[284.14827, "o", "-rw-r--r-- 1 root root  1485 Sep 13 19:33 sparse.pyi\r\n"]
[284.215081, "o", "-rw-r--r-- 1 root root 20846 Sep 13 19:32 sparse.pyx\r\n"]
[284.281892, "o", "-rw-r--r-- 1 root root  9547 Sep 13 19:32 sparse_op_helper.pxi.in\r\n"]
[284.348703, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:32 src\r\n"]
[284.415514, "o", "-rw-r--r-- 1 root root   305 Sep 13 19:33 testing.pyi\r\n"]
[284.482324, "o", "-rw-r--r-- 1 root root  6077 Sep 13 19:32 testing.pyx\r\n"]
[284.549135, "o", "-rw-r--r-- 1 root root   859 Sep 13 19:32 tslib.pyi\r\n"]
[284.615946, "o", "-rw-r--r-- 1 root root 18282 Sep 13 19:32 tslib.pyx\r\n"]
[284.682757, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 tslibs\r\n"]
[284.749568, "o", "-rw-r--r-- 1 root root   272 Sep 13 19:32 util.pxd\r\n"]
[284.816378, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:33 window\r\n"]
[284.883189, "o", "-rw-r--r-- 1 root root   516 Sep 13 19:32 writers.pyi\r\n"]
[285.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[285.002, "i", "grep -RIn \"def hash_\\|cdef .*hash_\\|hash_object_array\\|hash_array\" pandas/core/util pandas/_libs | sed -n '1,120p' \r"]
[285.004, "o", "grep -RIn \"def hash_\\|cdef .*hash_\\|hash_object_array\\|hash_array\" pandas/core/util pandas/_libs | sed -n '1,120p' \r\n"]
[290.0, "o", "\u001bM(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[290.002, "i", "grep -RIn \"def hash_\\|cdef .*hash_\\|hash_object_array\\|hash_array\" pandas/core/util pandas/_libs | sed -n '1,120p\u001b[K'\r"]
[290.004, "o", "grep -RIn \"def hash_\\|cdef .*hash_\\|hash_object_array\\|hash_array\" pandas/core/util pandas/_libs | sed -n '1,120p\u001b[K'\r\n"]
[290.1708, "o", "\u001b[?2004l\r\n"]
[290.3356, "o", "pandas/core/util/hashing.py:12:from pandas._libs.hashing import hash_object_array\r\n"]
[290.5004, "o", "pandas/core/util/hashing.py:48:def combine_hash_arrays(\r\n"]
[290.6652, "o", "pandas/core/util/hashing.py:84:def hash_pandas_object(\r\n"]
[290.83, "o", "pandas/core/util/hashing.py:129:        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[290.9948, "o", "pandas/core/util/hashing.py:135:        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[291.1596, "o", "pandas/core/util/hashing.py:150:            h = combine_hash_arrays(arrays, 2)\r\n"]
[291.3244, "o", "pandas/core/util/hashing.py:156:            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[291.4892, "o", "pandas/core/util/hashing.py:176:        h = combine_hash_arrays(hashes, num_items)\r\n"]
[291.654, "o", "pandas/core/util/hashing.py:185:def hash_tuples(\r\n"]
[291.8188, "o", "pandas/core/util/hashing.py:230:    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[291.9836, "o", "pandas/core/util/hashing.py:235:def hash_array(\r\n"]
[292.1484, "o", "pandas/core/util/hashing.py:268:    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[292.3132, "o", "pandas/core/util/hashing.py:283:            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[292.478, "o", "pandas/core/util/hashing.py:297:    See hash_array.__doc__.\r\n"]
[292.6428, "o", "pandas/core/util/hashing.py:334:            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[292.8076, "o", "pandas/core/util/hashing.py:337:            vals = hash_object_array(\r\n"]
[292.9724, "o", "pandas/_libs/hashing.pyi:5:def hash_object_array(\r\n"]
[293.1372, "o", "pandas/_libs/khash_for_primitive_helper.pxi.in:27:cdef extern from \"pandas/vendored/klib/khash_python.h\":\r\n"]
[293.302, "o", "pandas/_libs/hashtable.pyx:85:    def hash_inner_join(self, values, mask=None):\r\n"]
[293.4668, "o", "pandas/_libs/index.pyx:328:    cdef _make_hash_table(self, Py_ssize_t n):\r\n"]
[293.6316, "o", "pandas/_libs/index.pyx:537:    cdef _make_hash_table(self, Py_ssize_t n):\r\n"]
[293.7964, "o", "pandas/_libs/index.pyx:552:    cdef _make_hash_table(self, Py_ssize_t n):\r\n"]
[293.9612, "o", "pandas/_libs/hashing.pyx:25:def hash_object_array(\r\n"]
[294.126, "o", "pandas/_libs/hashtable.pyi:28:    def hash_inner_join(\r\n"]
[294.2908, "o", "pandas/_libs/hashtable.pyi:222:    def hash_inner_join(\r\n"]
[294.4556, "o", "pandas/_libs/khash.pxd:18:cdef extern from \"pandas/vendored/klib/khash_python.h\":\r\n"]
[294.6204, "o", "pandas/_libs/hashtable_class_helper.pxi.in:561:    def hash_inner_join(self, const {{dtype}}_t[:] values, const uint8_t[:] mask = None) -> tuple[ndarray, ndarray]:\r\n"]
[294.7852, "o", "pandas/_libs/hashtable_class_helper.pxi.in:956:    def hash_inner_join(self, const {{c_type}}[:] values, const uint8_t[:] mask = None) -> tuple[np.ndarray, np.ndarray]:\r\n"]
[295.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[295.002, "i", "sed -n '1,240p' pandas/_libs/hash.pyx 2>/dev/null || true\r"]
[295.004, "o", "sed -n '1,240p' pandas/_libs/hash.pyx 2>/dev/null || true\r\n"]
[295.006, "o", "\u001b[?2004l\r\n"]
[300.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[300.002, "i", "sed -n '1,260p' pandas/core/util/hashing.py\r"]
[300.004, "o", "sed -n '1,260p' pandas/core/util/hashing.py\r\n"]
[300.024943, "o", "\u001b[?2004l\r\n"]
[300.043885, "o", "\"\"\"\r\n"]
[300.062828, "o", "data hash pandas / numpy objects\r\n"]
[300.08177, "o", "\"\"\"\r\n"]
[300.100713, "o", "\r\n"]
[300.119655, "o", "from __future__ import annotations\r\n"]
[300.138598, "o", "\r\n"]
[300.15754, "o", "import itertools\r\n"]
[300.176483, "o", "from typing import TYPE_CHECKING\r\n"]
[300.195425, "o", "\r\n"]
[300.214368, "o", "import numpy as np\r\n"]
[300.23331, "o", "\r\n"]
[300.252253, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[300.271195, "o", "\r\n"]
[300.290138, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[300.30908, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[300.328023, "o", "from pandas.core.dtypes.generic import (\r\n"]
[300.346966, "o", "    ABCDataFrame,\r\n"]
[300.365908, "o", "    ABCExtensionArray,\r\n"]
[300.384851, "o", "    ABCIndex,\r\n"]
[300.403793, "o", "    ABCMultiIndex,\r\n"]
[300.422736, "o", "    ABCSeries,\r\n"]
[300.441678, "o", ")\r\n"]
[300.460621, "o", "\r\n"]
[300.479563, "o", "if TYPE_CHECKING:\r\n"]
[300.498506, "o", "    from collections.abc import (\r\n"]
[300.517448, "o", "        Hashable,\r\n"]
[300.536391, "o", "        Iterable,\r\n"]
[300.555333, "o", "        Iterator,\r\n"]
[300.574276, "o", "    )\r\n"]
[300.593218, "o", "\r\n"]
[300.612161, "o", "    from pandas._typing import (\r\n"]
[300.631103, "o", "        ArrayLike,\r\n"]
[300.650046, "o", "        npt,\r\n"]
[300.668989, "o", "    )\r\n"]
[300.687931, "o", "\r\n"]
[300.706874, "o", "    from pandas import (\r\n"]
[300.725816, "o", "        DataFrame,\r\n"]
[300.744759, "o", "        Index,\r\n"]
[300.763701, "o", "        MultiIndex,\r\n"]
[300.782644, "o", "        Series,\r\n"]
[300.801586, "o", "    )\r\n"]
[300.820529, "o", "\r\n"]
[300.839471, "o", "\r\n"]
[300.858414, "o", "# 16 byte long hashing key\r\n"]
[300.877356, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[300.896299, "o", "\r\n"]
[300.915241, "o", "\r\n"]
[300.934184, "o", "def combine_hash_arrays(\r\n"]
[300.953126, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[300.972069, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[300.991011, "o", "    \"\"\"\r\n"]
[301.009954, "o", "    Parameters\r\n"]
[301.028897, "o", "    ----------\r\n"]
[301.047839, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[301.066782, "o", "    num_items : int\r\n"]
[301.085724, "o", "\r\n"]
[301.104667, "o", "    Returns\r\n"]
[301.123609, "o", "    -------\r\n"]
[301.142552, "o", "    np.ndarray[uint64]\r\n"]
[301.161494, "o", "\r\n"]
[301.180437, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[301.199379, "o", "    \"\"\"\r\n"]
[301.218322, "o", "    try:\r\n"]
[301.237264, "o", "        first = next(arrays)\r\n"]
[301.256207, "o", "    except StopIteration:\r\n"]
[301.275149, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[301.294092, "o", "\r\n"]
[301.313034, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[301.331977, "o", "\r\n"]
[301.35092, "o", "    mult = np.uint64(1000003)\r\n"]
[301.369862, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[301.388805, "o", "    last_i = 0\r\n"]
[301.407747, "o", "    for i, a in enumerate(arrays):\r\n"]
[301.42669, "o", "        inverse_i = num_items - i\r\n"]
[301.445632, "o", "        out ^= a\r\n"]
[301.464575, "o", "        out *= mult\r\n"]
[301.483517, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[301.50246, "o", "        last_i = i\r\n"]
[301.521402, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[301.540345, "o", "    out += np.uint64(97531)\r\n"]
[301.559287, "o", "    return out\r\n"]
[301.57823, "o", "\r\n"]
[301.597172, "o", "\r\n"]
[301.616115, "o", "def hash_pandas_object(\r\n"]
[301.635057, "o", "    obj: Index | DataFrame | Series,\r\n"]
[301.654, "o", "    index: bool = True,\r\n"]
[301.672943, "o", "    encoding: str = \"utf8\",\r\n"]
[301.691885, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[301.710828, "o", "    categorize: bool = True,\r\n"]
[301.72977, "o", ") -> Series:\r\n"]
[301.748713, "o", "    \"\"\"\r\n"]
[301.767655, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[301.786598, "o", "\r\n"]
[301.80554, "o", "    Parameters\r\n"]
[301.824483, "o", "    ----------\r\n"]
[301.843425, "o", "    obj : Index, Series, or DataFrame\r\n"]
[301.862368, "o", "    index : bool, default True\r\n"]
[301.88131, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[301.900253, "o", "    encoding : str, default 'utf8'\r\n"]
[301.919195, "o", "        Encoding for data & key when strings.\r\n"]
[301.938138, "o", "    hash_key : str, default _default_hash_key\r\n"]
[301.95708, "o", "        Hash_key for string key to encode.\r\n"]
[301.976023, "o", "    categorize : bool, default True\r\n"]
[301.994966, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[302.013908, "o", "        efficient when the array contains duplicate values.\r\n"]
[302.032851, "o", "\r\n"]
[302.051793, "o", "    Returns\r\n"]
[302.070736, "o", "    -------\r\n"]
[302.089678, "o", "    Series of uint64\r\n"]
[302.108621, "o", "        Same length as the object.\r\n"]
[302.127563, "o", "\r\n"]
[302.146506, "o", "    Examples\r\n"]
[302.165448, "o", "    --------\r\n"]
[302.184391, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[302.203333, "o", "    0    14639053686158035780\r\n"]
[302.222276, "o", "    1     3869563279212530728\r\n"]
[302.241218, "o", "    2      393322362522515241\r\n"]
[302.260161, "o", "    dtype: uint64\r\n"]
[302.279103, "o", "    \"\"\"\r\n"]
[302.298046, "o", "    from pandas import Series\r\n"]
[302.316989, "o", "\r\n"]
[302.335931, "o", "    if hash_key is None:\r\n"]
[302.354874, "o", "        hash_key = _default_hash_key\r\n"]
[302.373816, "o", "\r\n"]
[302.392759, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[302.411701, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[302.430644, "o", "\r\n"]
[302.449586, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[302.468529, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[302.487471, "o", "            \"uint64\", copy=False\r\n"]
[302.506414, "o", "        )\r\n"]
[302.525356, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[302.544299, "o", "\r\n"]
[302.563241, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[302.582184, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[302.601126, "o", "            \"uint64\", copy=False\r\n"]
[302.620069, "o", "        )\r\n"]
[302.639011, "o", "        if index:\r\n"]
[302.657954, "o", "            index_iter = (\r\n"]
[302.676897, "o", "                hash_pandas_object(\r\n"]
[302.695839, "o", "                    obj.index,\r\n"]
[302.714782, "o", "                    index=False,\r\n"]
[302.733724, "o", "                    encoding=encoding,\r\n"]
[302.752667, "o", "                    hash_key=hash_key,\r\n"]
[302.771609, "o", "                    categorize=categorize,\r\n"]
[302.790552, "o", "                )._values\r\n"]
[302.809494, "o", "                for _ in [None]\r\n"]
[302.828437, "o", "            )\r\n"]
[302.847379, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[302.866322, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[302.885264, "o", "\r\n"]
[302.904207, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[302.923149, "o", "\r\n"]
[302.942092, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[302.961034, "o", "        hashes = (\r\n"]
[302.979977, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[302.99892, "o", "            for _, series in obj.items()\r\n"]
[303.017862, "o", "        )\r\n"]
[303.036805, "o", "        num_items = len(obj.columns)\r\n"]
[303.055747, "o", "        if index:\r\n"]
[303.07469, "o", "            index_hash_generator = (\r\n"]
[303.093632, "o", "                hash_pandas_object(\r\n"]
[303.112575, "o", "                    obj.index,\r\n"]
[303.131517, "o", "                    index=False,\r\n"]
[303.15046, "o", "                    encoding=encoding,\r\n"]
[303.169402, "o", "                    hash_key=hash_key,\r\n"]
[303.188345, "o", "                    categorize=categorize,\r\n"]
[303.207287, "o", "                )._values\r\n"]
[303.22623, "o", "                for _ in [None]\r\n"]
[303.245172, "o", "            )\r\n"]
[303.264115, "o", "            num_items += 1\r\n"]
[303.283057, "o", "\r\n"]
[303.302, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[303.320943, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[303.339885, "o", "            hashes = (x for x in _hashes)\r\n"]
[303.358828, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[303.37777, "o", "\r\n"]
[303.396713, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[303.415655, "o", "    else:\r\n"]
[303.434598, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[303.45354, "o", "\r\n"]
[303.472483, "o", "    return ser\r\n"]
[303.491425, "o", "\r\n"]
[303.510368, "o", "\r\n"]
[303.52931, "o", "def hash_tuples(\r\n"]
[303.548253, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[303.567195, "o", "    encoding: str = \"utf8\",\r\n"]
[303.586138, "o", "    hash_key: str = _default_hash_key,\r\n"]
[303.60508, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[303.624023, "o", "    \"\"\"\r\n"]
[303.642966, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[303.661908, "o", "\r\n"]
[303.680851, "o", "    Parameters\r\n"]
[303.699793, "o", "    ----------\r\n"]
[303.718736, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[303.737678, "o", "    encoding : str, default 'utf8'\r\n"]
[303.756621, "o", "    hash_key : str, default _default_hash_key\r\n"]
[303.775563, "o", "\r\n"]
[303.794506, "o", "    Returns\r\n"]
[303.813448, "o", "    -------\r\n"]
[303.832391, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[303.851333, "o", "    \"\"\"\r\n"]
[303.870276, "o", "    if not is_list_like(vals):\r\n"]
[303.889218, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[303.908161, "o", "\r\n"]
[303.927103, "o", "    from pandas import (\r\n"]
[303.946046, "o", "        Categorical,\r\n"]
[303.964989, "o", "        MultiIndex,\r\n"]
[303.983931, "o", "    )\r\n"]
[304.002874, "o", "\r\n"]
[304.021816, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[304.040759, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[304.059701, "o", "    else:\r\n"]
[304.078644, "o", "        mi = vals\r\n"]
[304.097586, "o", "\r\n"]
[304.116529, "o", "    # create a list-of-Categoricals\r\n"]
[304.135471, "o", "    cat_vals = [\r\n"]
[304.154414, "o", "        Categorical._simple_new(\r\n"]
[304.173356, "o", "            mi.codes[level],\r\n"]
[304.192299, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[304.211241, "o", "        )\r\n"]
[304.230184, "o", "        for level in range(mi.nlevels)\r\n"]
[304.249126, "o", "    ]\r\n"]
[304.268069, "o", "\r\n"]
[304.287011, "o", "    # hash the list-of-ndarrays\r\n"]
[304.305954, "o", "    hashes = (\r\n"]
[304.324897, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[304.343839, "o", "        for cat in cat_vals\r\n"]
[304.362782, "o", "    )\r\n"]
[304.381724, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[304.400667, "o", "\r\n"]
[304.419609, "o", "    return h\r\n"]
[304.438552, "o", "\r\n"]
[304.457494, "o", "\r\n"]
[304.476437, "o", "def hash_array(\r\n"]
[304.495379, "o", "    vals: ArrayLike,\r\n"]
[304.514322, "o", "    encoding: str = \"utf8\",\r\n"]
[304.533264, "o", "    hash_key: str = _default_hash_key,\r\n"]
[304.552207, "o", "    categorize: bool = True,\r\n"]
[304.571149, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[304.590092, "o", "    \"\"\"\r\n"]
[304.609034, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[304.627977, "o", "\r\n"]
[304.64692, "o", "    Parameters\r\n"]
[304.665862, "o", "    ----------\r\n"]
[304.684805, "o", "    vals : ndarray or ExtensionArray\r\n"]
[304.703747, "o", "        The input array to hash.\r\n"]
[304.72269, "o", "    encoding : str, default 'utf8'\r\n"]
[304.741632, "o", "        Encoding for data & key when strings.\r\n"]
[304.760575, "o", "    hash_key : str, default _default_hash_key\r\n"]
[304.779517, "o", "        Hash_key for string key to encode.\r\n"]
[304.79846, "o", "    categorize : bool, default True\r\n"]
[304.817402, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[304.836345, "o", "        efficient when the array contains duplicate values.\r\n"]
[304.855287, "o", "\r\n"]
[304.87423, "o", "    Returns\r\n"]
[304.893172, "o", "    -------\r\n"]
[304.912115, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[304.931057, "o", "        Hashed values, same length as the vals.\r\n"]
[305.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[305.002, "i", "sed -n '260,620p' pandas/core/util/hashing.py\r"]
[305.004, "o", "sed -n '260,620p' pandas/core/util/hashing.py\r\n"]
[305.061551, "o", "\u001b[?2004l\r\n"]
[305.117101, "o", "\r\n"]
[305.172652, "o", "    See Also\r\n"]
[305.228202, "o", "    --------\r\n"]
[305.283753, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[305.339303, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[305.394854, "o", "\r\n"]
[305.450404, "o", "    Examples\r\n"]
[305.505955, "o", "    --------\r\n"]
[305.561506, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[305.617056, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[305.672607, "o", "      dtype=uint64)\r\n"]
[305.728157, "o", "    \"\"\"\r\n"]
[305.783708, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[305.839258, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[305.894809, "o", "\r\n"]
[305.95036, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[306.00591, "o", "        return vals._hash_pandas_object(\r\n"]
[306.061461, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[306.117011, "o", "        )\r\n"]
[306.172562, "o", "\r\n"]
[306.228112, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[306.283663, "o", "        # GH#42003\r\n"]
[306.339213, "o", "        raise TypeError(\r\n"]
[306.394764, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[306.450315, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[306.505865, "o", "        )\r\n"]
[306.561416, "o", "\r\n"]
[306.616966, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[306.672517, "o", "\r\n"]
[306.728067, "o", "\r\n"]
[306.783618, "o", "def _hash_ndarray(\r\n"]
[306.839169, "o", "    vals: np.ndarray,\r\n"]
[306.894719, "o", "    encoding: str = \"utf8\",\r\n"]
[306.95027, "o", "    hash_key: str = _default_hash_key,\r\n"]
[307.00582, "o", "    categorize: bool = True,\r\n"]
[307.061371, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[307.116921, "o", "    \"\"\"\r\n"]
[307.172472, "o", "    See hash_array.__doc__.\r\n"]
[307.228022, "o", "    \"\"\"\r\n"]
[307.283573, "o", "    dtype = vals.dtype\r\n"]
[307.339124, "o", "\r\n"]
[307.394674, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[307.450225, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[307.505775, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[307.561326, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[307.616876, "o", "        return hash_real + 23 * hash_imag\r\n"]
[307.672427, "o", "\r\n"]
[307.727978, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[307.783528, "o", "    # manage it.\r\n"]
[307.839079, "o", "    if dtype == bool:\r\n"]
[307.894629, "o", "        vals = vals.astype(\"u8\")\r\n"]
[307.95018, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[308.00573, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[308.061281, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[308.116831, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[308.172382, "o", "    else:\r\n"]
[308.227933, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[308.283483, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[308.339034, "o", "        # when the values are known/likely to be unique.\r\n"]
[308.394584, "o", "        if categorize:\r\n"]
[308.450135, "o", "            from pandas import (\r\n"]
[308.505685, "o", "                Categorical,\r\n"]
[308.561236, "o", "                Index,\r\n"]
[308.616787, "o", "                factorize,\r\n"]
[308.672337, "o", "            )\r\n"]
[308.727888, "o", "\r\n"]
[308.783438, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[308.838989, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[308.894539, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[308.95009, "o", "            return cat._hash_pandas_object(\r\n"]
[309.00564, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[309.061191, "o", "            )\r\n"]
[309.116742, "o", "\r\n"]
[309.172292, "o", "        try:\r\n"]
[309.227843, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[309.283393, "o", "        except TypeError:\r\n"]
[309.338944, "o", "            # we have mixed types\r\n"]
[309.394494, "o", "            vals = hash_object_array(\r\n"]
[309.450045, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[309.505596, "o", "            )\r\n"]
[309.561146, "o", "\r\n"]
[309.616697, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[309.672247, "o", "    vals ^= vals >> 30\r\n"]
[309.727798, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[309.783348, "o", "    vals ^= vals >> 27\r\n"]
[309.838899, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[309.894449, "o", "    vals ^= vals >> 31\r\n"]
[310.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[310.002, "i", "sed -n '1,260p' pandas/_libs/hashing.pyx\r"]
[310.004, "o", "sed -n '1,260p' pandas/_libs/hashing.pyx\r\n"]
[310.030844, "o", "\u001b[?2004l\r\n"]
[310.055688, "o", "# Translated from the reference implementation\r\n"]
[310.080533, "o", "# at https://github.com/veorq/SipHash\r\n"]
[310.105377, "o", "\r\n"]
[310.130221, "o", "cimport cython\r\n"]
[310.155065, "o", "from libc.stdlib cimport (\r\n"]
[310.17991, "o", "    free,\r\n"]
[310.204754, "o", "    malloc,\r\n"]
[310.229598, "o", ")\r\n"]
[310.254442, "o", "\r\n"]
[310.279286, "o", "import numpy as np\r\n"]
[310.304131, "o", "\r\n"]
[310.328975, "o", "from numpy cimport (\r\n"]
[310.353819, "o", "    import_array,\r\n"]
[310.378663, "o", "    ndarray,\r\n"]
[310.403508, "o", "    uint8_t,\r\n"]
[310.428352, "o", "    uint64_t,\r\n"]
[310.453196, "o", ")\r\n"]
[310.47804, "o", "\r\n"]
[310.502884, "o", "import_array()\r\n"]
[310.527729, "o", "\r\n"]
[310.552573, "o", "from pandas._libs.util cimport is_nan\r\n"]
[310.577417, "o", "\r\n"]
[310.602261, "o", "\r\n"]
[310.627106, "o", "@cython.boundscheck(False)\r\n"]
[310.65195, "o", "def hash_object_array(\r\n"]
[310.676794, "o", "    ndarray[object, ndim=1] arr, str key, str encoding=\"utf8\"\r\n"]
[310.701638, "o", ") -> np.ndarray[np.uint64]:\r\n"]
[310.726482, "o", "    \"\"\"\r\n"]
[310.751327, "o", "    Parameters\r\n"]
[310.776171, "o", "    ----------\r\n"]
[310.801015, "o", "    arr : 1-d object ndarray of objects\r\n"]
[310.825859, "o", "    key : hash key, must be 16 byte len encoded\r\n"]
[310.850704, "o", "    encoding : encoding for key & arr, default to 'utf8'\r\n"]
[310.875548, "o", "\r\n"]
[310.900392, "o", "    Returns\r\n"]
[310.925236, "o", "    -------\r\n"]
[310.95008, "o", "    1-d uint64 ndarray of hashes.\r\n"]
[310.974925, "o", "\r\n"]
[310.999769, "o", "    Raises\r\n"]
[311.024613, "o", "    ------\r\n"]
[311.049457, "o", "    TypeError\r\n"]
[311.074302, "o", "        If the array contains mixed types.\r\n"]
[311.099146, "o", "\r\n"]
[311.12399, "o", "    Notes\r\n"]
[311.148834, "o", "    -----\r\n"]
[311.173678, "o", "    Allowed values must be strings, or nulls\r\n"]
[311.198523, "o", "    mixed array types will raise TypeError.\r\n"]
[311.223367, "o", "    \"\"\"\r\n"]
[311.248211, "o", "    cdef:\r\n"]
[311.273055, "o", "        Py_ssize_t i, n\r\n"]
[311.297899, "o", "        uint64_t[::1] result\r\n"]
[311.322744, "o", "        bytes data, k\r\n"]
[311.347588, "o", "        uint8_t *kb\r\n"]
[311.372432, "o", "        uint64_t *lens\r\n"]
[311.397276, "o", "        char **vecs\r\n"]
[311.422121, "o", "        char *cdata\r\n"]
[311.446965, "o", "        object val\r\n"]
[311.471809, "o", "        list data_list = []\r\n"]
[311.496653, "o", "\r\n"]
[311.521497, "o", "    k = <bytes>key.encode(encoding)\r\n"]
[311.546342, "o", "    kb = <uint8_t *>k\r\n"]
[311.571186, "o", "    if len(k) != 16:\r\n"]
[311.59603, "o", "        raise ValueError(\r\n"]
[311.620874, "o", "            f\"key should be a 16-byte string encoded, got {k} (len {len(k)})\"\r\n"]
[311.645719, "o", "        )\r\n"]
[311.670563, "o", "\r\n"]
[311.695407, "o", "    n = len(arr)\r\n"]
[311.720251, "o", "\r\n"]
[311.745095, "o", "    # create an array of bytes\r\n"]
[311.76994, "o", "    vecs = <char **>malloc(n * sizeof(char *))\r\n"]
[311.794784, "o", "    if vecs is NULL:\r\n"]
[311.819628, "o", "        raise MemoryError()\r\n"]
[311.844472, "o", "    lens = <uint64_t*>malloc(n * sizeof(uint64_t))\r\n"]
[311.869317, "o", "    if lens is NULL:\r\n"]
[311.894161, "o", "        raise MemoryError()\r\n"]
[311.919005, "o", "\r\n"]
[311.943849, "o", "    for i in range(n):\r\n"]
[311.968693, "o", "        val = arr[i]\r\n"]
[311.993538, "o", "        if isinstance(val, bytes):\r\n"]
[312.018382, "o", "            data = <bytes>val\r\n"]
[312.043226, "o", "        elif isinstance(val, str):\r\n"]
[312.06807, "o", "            data = <bytes>val.encode(encoding)\r\n"]
[312.092915, "o", "        elif val is None or is_nan(val):\r\n"]
[312.117759, "o", "            # null, stringify and encode\r\n"]
[312.142603, "o", "            data = <bytes>str(val).encode(encoding)\r\n"]
[312.167447, "o", "\r\n"]
[312.192291, "o", "        elif isinstance(val, tuple):\r\n"]
[312.217136, "o", "            # GH#28969 we could have a tuple, but need to ensure that\r\n"]
[312.24198, "o", "            #  the tuple entries are themselves hashable before converting\r\n"]
[312.266824, "o", "            #  to str\r\n"]
[312.291668, "o", "            hash(val)\r\n"]
[312.316513, "o", "            data = <bytes>str(val).encode(encoding)\r\n"]
[312.341357, "o", "        else:\r\n"]
[312.366201, "o", "            raise TypeError(\r\n"]
[312.391045, "o", "                f\"{val} of type {type(val)} is not a valid type for hashing, \"\r\n"]
[312.415889, "o", "                \"must be string or null\"\r\n"]
[312.440734, "o", "            )\r\n"]
[312.465578, "o", "\r\n"]
[312.490422, "o", "        lens[i] = len(data)\r\n"]
[312.515266, "o", "        cdata = data\r\n"]
[312.540111, "o", "\r\n"]
[312.564955, "o", "        # keep the references alive through the end of the\r\n"]
[312.589799, "o", "        # function\r\n"]
[312.614643, "o", "        data_list.append(data)\r\n"]
[312.639487, "o", "        vecs[i] = cdata\r\n"]
[312.664332, "o", "\r\n"]
[312.689176, "o", "    result = np.empty(n, dtype=np.uint64)\r\n"]
[312.71402, "o", "    with nogil:\r\n"]
[312.738864, "o", "        for i in range(n):\r\n"]
[312.763709, "o", "            result[i] = low_level_siphash(<uint8_t *>vecs[i], lens[i], kb)\r\n"]
[312.788553, "o", "\r\n"]
[312.813397, "o", "    free(vecs)\r\n"]
[312.838241, "o", "    free(lens)\r\n"]
[312.863085, "o", "    return result.base  # .base to retrieve underlying np.ndarray\r\n"]
[312.88793, "o", "\r\n"]
[312.912774, "o", "\r\n"]
[312.937618, "o", "cdef uint64_t _rotl(uint64_t x, uint64_t b) noexcept nogil:\r\n"]
[312.962462, "o", "    return (x << b) | (x >> (64 - b))\r\n"]
[312.987307, "o", "\r\n"]
[313.012151, "o", "\r\n"]
[313.036995, "o", "cdef uint64_t u8to64_le(uint8_t* p) noexcept nogil:\r\n"]
[313.061839, "o", "    return (<uint64_t>p[0] |\r\n"]
[313.086683, "o", "            <uint64_t>p[1] << 8 |\r\n"]
[313.111528, "o", "            <uint64_t>p[2] << 16 |\r\n"]
[313.136372, "o", "            <uint64_t>p[3] << 24 |\r\n"]
[313.161216, "o", "            <uint64_t>p[4] << 32 |\r\n"]
[313.18606, "o", "            <uint64_t>p[5] << 40 |\r\n"]
[313.210905, "o", "            <uint64_t>p[6] << 48 |\r\n"]
[313.235749, "o", "            <uint64_t>p[7] << 56)\r\n"]
[313.260593, "o", "\r\n"]
[313.285437, "o", "\r\n"]
[313.310281, "o", "cdef void _sipround(uint64_t* v0, uint64_t* v1,\r\n"]
[313.335126, "o", "                    uint64_t* v2, uint64_t* v3) noexcept nogil:\r\n"]
[313.35997, "o", "    v0[0] += v1[0]\r\n"]
[313.384814, "o", "    v1[0] = _rotl(v1[0], 13)\r\n"]
[313.409658, "o", "    v1[0] ^= v0[0]\r\n"]
[313.434503, "o", "    v0[0] = _rotl(v0[0], 32)\r\n"]
[313.459347, "o", "    v2[0] += v3[0]\r\n"]
[313.484191, "o", "    v3[0] = _rotl(v3[0], 16)\r\n"]
[313.509035, "o", "    v3[0] ^= v2[0]\r\n"]
[313.533879, "o", "    v0[0] += v3[0]\r\n"]
[313.558724, "o", "    v3[0] = _rotl(v3[0], 21)\r\n"]
[313.583568, "o", "    v3[0] ^= v0[0]\r\n"]
[313.608412, "o", "    v2[0] += v1[0]\r\n"]
[313.633256, "o", "    v1[0] = _rotl(v1[0], 17)\r\n"]
[313.658101, "o", "    v1[0] ^= v2[0]\r\n"]
[313.682945, "o", "    v2[0] = _rotl(v2[0], 32)\r\n"]
[313.707789, "o", "\r\n"]
[313.732633, "o", "\r\n"]
[313.757477, "o", "@cython.cdivision(True)\r\n"]
[313.782322, "o", "cdef uint64_t low_level_siphash(uint8_t* data, size_t datalen,\r\n"]
[313.807166, "o", "                                uint8_t* key) noexcept nogil:\r\n"]
[313.83201, "o", "    cdef uint64_t v0 = 0x736f6d6570736575ULL\r\n"]
[313.856854, "o", "    cdef uint64_t v1 = 0x646f72616e646f6dULL\r\n"]
[313.881698, "o", "    cdef uint64_t v2 = 0x6c7967656e657261ULL\r\n"]
[313.906543, "o", "    cdef uint64_t v3 = 0x7465646279746573ULL\r\n"]
[313.931387, "o", "    cdef uint64_t b\r\n"]
[313.956231, "o", "    cdef uint64_t k0 = u8to64_le(key)\r\n"]
[313.981075, "o", "    cdef uint64_t k1 = u8to64_le(key + 8)\r\n"]
[314.00592, "o", "    cdef uint64_t m\r\n"]
[314.030764, "o", "    cdef int i\r\n"]
[314.055608, "o", "    cdef uint8_t* end = data + datalen - (datalen % sizeof(uint64_t))\r\n"]
[314.080452, "o", "    cdef int left = datalen & 7\r\n"]
[314.105296, "o", "    cdef int cROUNDS = 2\r\n"]
[314.130141, "o", "    cdef int dROUNDS = 4\r\n"]
[314.154985, "o", "\r\n"]
[314.179829, "o", "    b = (<uint64_t>datalen) << 56\r\n"]
[314.204673, "o", "    v3 ^= k1\r\n"]
[314.229518, "o", "    v2 ^= k0\r\n"]
[314.254362, "o", "    v1 ^= k1\r\n"]
[314.279206, "o", "    v0 ^= k0\r\n"]
[314.30405, "o", "\r\n"]
[314.328894, "o", "    while (data != end):\r\n"]
[314.353739, "o", "        m = u8to64_le(data)\r\n"]
[314.378583, "o", "        v3 ^= m\r\n"]
[314.403427, "o", "        for i in range(cROUNDS):\r\n"]
[314.428271, "o", "            _sipround(&v0, &v1, &v2, &v3)\r\n"]
[314.453116, "o", "        v0 ^= m\r\n"]
[314.47796, "o", "\r\n"]
[314.502804, "o", "        data += sizeof(uint64_t)\r\n"]
[314.527648, "o", "\r\n"]
[314.552492, "o", "    for i in range(left-1, -1, -1):\r\n"]
[314.577337, "o", "        b |= (<uint64_t>data[i]) << (i * 8)\r\n"]
[314.602181, "o", "\r\n"]
[314.627025, "o", "    v3 ^= b\r\n"]
[314.651869, "o", "\r\n"]
[314.676714, "o", "    for i in range(cROUNDS):\r\n"]
[314.701558, "o", "        _sipround(&v0, &v1, &v2, &v3)\r\n"]
[314.726402, "o", "\r\n"]
[314.751246, "o", "    v0 ^= b\r\n"]
[314.77609, "o", "    v2 ^= 0xff\r\n"]
[314.800935, "o", "\r\n"]
[314.825779, "o", "    for i in range(dROUNDS):\r\n"]
[314.850623, "o", "        _sipround(&v0, &v1, &v2, &v3)\r\n"]
[314.875467, "o", "\r\n"]
[314.900312, "o", "    b = v0 ^ v1 ^ v2 ^ v3\r\n"]
[314.925156, "o", "\r\n"]
[315.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[315.002, "i", "sed -n '260,620p' pandas/_libs/hashing.pyx\r"]
[315.004, "o", "sed -n '260,620p' pandas/_libs/hashing.pyx\r\n"]
[315.006, "o", "\u001b[?2004l\r\n"]
[320.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[320.002, "i", "sed -n '1,260p' pandas/core/util/hashing.py\r"]
[320.004, "o", "sed -n '1,260p' pandas/core/util/hashing.py\r\n"]
[320.024943, "o", "\u001b[?2004l\r\n"]
[320.043885, "o", "\"\"\"\r\n"]
[320.062828, "o", "data hash pandas / numpy objects\r\n"]
[320.08177, "o", "\"\"\"\r\n"]
[320.100713, "o", "\r\n"]
[320.119655, "o", "from __future__ import annotations\r\n"]
[320.138598, "o", "\r\n"]
[320.15754, "o", "import itertools\r\n"]
[320.176483, "o", "from typing import TYPE_CHECKING\r\n"]
[320.195425, "o", "\r\n"]
[320.214368, "o", "import numpy as np\r\n"]
[320.23331, "o", "\r\n"]
[320.252253, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[320.271195, "o", "\r\n"]
[320.290138, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[320.30908, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[320.328023, "o", "from pandas.core.dtypes.generic import (\r\n"]
[320.346966, "o", "    ABCDataFrame,\r\n"]
[320.365908, "o", "    ABCExtensionArray,\r\n"]
[320.384851, "o", "    ABCIndex,\r\n"]
[320.403793, "o", "    ABCMultiIndex,\r\n"]
[320.422736, "o", "    ABCSeries,\r\n"]
[320.441678, "o", ")\r\n"]
[320.460621, "o", "\r\n"]
[320.479563, "o", "if TYPE_CHECKING:\r\n"]
[320.498506, "o", "    from collections.abc import (\r\n"]
[320.517448, "o", "        Hashable,\r\n"]
[320.536391, "o", "        Iterable,\r\n"]
[320.555333, "o", "        Iterator,\r\n"]
[320.574276, "o", "    )\r\n"]
[320.593218, "o", "\r\n"]
[320.612161, "o", "    from pandas._typing import (\r\n"]
[320.631103, "o", "        ArrayLike,\r\n"]
[320.650046, "o", "        npt,\r\n"]
[320.668989, "o", "    )\r\n"]
[320.687931, "o", "\r\n"]
[320.706874, "o", "    from pandas import (\r\n"]
[320.725816, "o", "        DataFrame,\r\n"]
[320.744759, "o", "        Index,\r\n"]
[320.763701, "o", "        MultiIndex,\r\n"]
[320.782644, "o", "        Series,\r\n"]
[320.801586, "o", "    )\r\n"]
[320.820529, "o", "\r\n"]
[320.839471, "o", "\r\n"]
[320.858414, "o", "# 16 byte long hashing key\r\n"]
[320.877356, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[320.896299, "o", "\r\n"]
[320.915241, "o", "\r\n"]
[320.934184, "o", "def combine_hash_arrays(\r\n"]
[320.953126, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[320.972069, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[320.991011, "o", "    \"\"\"\r\n"]
[321.009954, "o", "    Parameters\r\n"]
[321.028897, "o", "    ----------\r\n"]
[321.047839, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[321.066782, "o", "    num_items : int\r\n"]
[321.085724, "o", "\r\n"]
[321.104667, "o", "    Returns\r\n"]
[321.123609, "o", "    -------\r\n"]
[321.142552, "o", "    np.ndarray[uint64]\r\n"]
[321.161494, "o", "\r\n"]
[321.180437, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[321.199379, "o", "    \"\"\"\r\n"]
[321.218322, "o", "    try:\r\n"]
[321.237264, "o", "        first = next(arrays)\r\n"]
[321.256207, "o", "    except StopIteration:\r\n"]
[321.275149, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[321.294092, "o", "\r\n"]
[321.313034, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[321.331977, "o", "\r\n"]
[321.35092, "o", "    mult = np.uint64(1000003)\r\n"]
[321.369862, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[321.388805, "o", "    last_i = 0\r\n"]
[321.407747, "o", "    for i, a in enumerate(arrays):\r\n"]
[321.42669, "o", "        inverse_i = num_items - i\r\n"]
[321.445632, "o", "        out ^= a\r\n"]
[321.464575, "o", "        out *= mult\r\n"]
[321.483517, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[321.50246, "o", "        last_i = i\r\n"]
[321.521402, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[321.540345, "o", "    out += np.uint64(97531)\r\n"]
[321.559287, "o", "    return out\r\n"]
[321.57823, "o", "\r\n"]
[321.597172, "o", "\r\n"]
[321.616115, "o", "def hash_pandas_object(\r\n"]
[321.635057, "o", "    obj: Index | DataFrame | Series,\r\n"]
[321.654, "o", "    index: bool = True,\r\n"]
[321.672943, "o", "    encoding: str = \"utf8\",\r\n"]
[321.691885, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[321.710828, "o", "    categorize: bool = True,\r\n"]
[321.72977, "o", ") -> Series:\r\n"]
[321.748713, "o", "    \"\"\"\r\n"]
[321.767655, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[321.786598, "o", "\r\n"]
[321.80554, "o", "    Parameters\r\n"]
[321.824483, "o", "    ----------\r\n"]
[321.843425, "o", "    obj : Index, Series, or DataFrame\r\n"]
[321.862368, "o", "    index : bool, default True\r\n"]
[321.88131, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[321.900253, "o", "    encoding : str, default 'utf8'\r\n"]
[321.919195, "o", "        Encoding for data & key when strings.\r\n"]
[321.938138, "o", "    hash_key : str, default _default_hash_key\r\n"]
[321.95708, "o", "        Hash_key for string key to encode.\r\n"]
[321.976023, "o", "    categorize : bool, default True\r\n"]
[321.994966, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[322.013908, "o", "        efficient when the array contains duplicate values.\r\n"]
[322.032851, "o", "\r\n"]
[322.051793, "o", "    Returns\r\n"]
[322.070736, "o", "    -------\r\n"]
[322.089678, "o", "    Series of uint64\r\n"]
[322.108621, "o", "        Same length as the object.\r\n"]
[322.127563, "o", "\r\n"]
[322.146506, "o", "    Examples\r\n"]
[322.165448, "o", "    --------\r\n"]
[322.184391, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[322.203333, "o", "    0    14639053686158035780\r\n"]
[322.222276, "o", "    1     3869563279212530728\r\n"]
[322.241218, "o", "    2      393322362522515241\r\n"]
[322.260161, "o", "    dtype: uint64\r\n"]
[322.279103, "o", "    \"\"\"\r\n"]
[322.298046, "o", "    from pandas import Series\r\n"]
[322.316989, "o", "\r\n"]
[322.335931, "o", "    if hash_key is None:\r\n"]
[322.354874, "o", "        hash_key = _default_hash_key\r\n"]
[322.373816, "o", "\r\n"]
[322.392759, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[322.411701, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[322.430644, "o", "\r\n"]
[322.449586, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[322.468529, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[322.487471, "o", "            \"uint64\", copy=False\r\n"]
[322.506414, "o", "        )\r\n"]
[322.525356, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[322.544299, "o", "\r\n"]
[322.563241, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[322.582184, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[322.601126, "o", "            \"uint64\", copy=False\r\n"]
[322.620069, "o", "        )\r\n"]
[322.639011, "o", "        if index:\r\n"]
[322.657954, "o", "            index_iter = (\r\n"]
[322.676897, "o", "                hash_pandas_object(\r\n"]
[322.695839, "o", "                    obj.index,\r\n"]
[322.714782, "o", "                    index=False,\r\n"]
[322.733724, "o", "                    encoding=encoding,\r\n"]
[322.752667, "o", "                    hash_key=hash_key,\r\n"]
[322.771609, "o", "                    categorize=categorize,\r\n"]
[322.790552, "o", "                )._values\r\n"]
[322.809494, "o", "                for _ in [None]\r\n"]
[322.828437, "o", "            )\r\n"]
[322.847379, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[322.866322, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[322.885264, "o", "\r\n"]
[322.904207, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[322.923149, "o", "\r\n"]
[322.942092, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[322.961034, "o", "        hashes = (\r\n"]
[322.979977, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[322.99892, "o", "            for _, series in obj.items()\r\n"]
[323.017862, "o", "        )\r\n"]
[323.036805, "o", "        num_items = len(obj.columns)\r\n"]
[323.055747, "o", "        if index:\r\n"]
[323.07469, "o", "            index_hash_generator = (\r\n"]
[323.093632, "o", "                hash_pandas_object(\r\n"]
[323.112575, "o", "                    obj.index,\r\n"]
[323.131517, "o", "                    index=False,\r\n"]
[323.15046, "o", "                    encoding=encoding,\r\n"]
[323.169402, "o", "                    hash_key=hash_key,\r\n"]
[323.188345, "o", "                    categorize=categorize,\r\n"]
[323.207287, "o", "                )._values\r\n"]
[323.22623, "o", "                for _ in [None]\r\n"]
[323.245172, "o", "            )\r\n"]
[323.264115, "o", "            num_items += 1\r\n"]
[323.283057, "o", "\r\n"]
[323.302, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[323.320943, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[323.339885, "o", "            hashes = (x for x in _hashes)\r\n"]
[323.358828, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[323.37777, "o", "\r\n"]
[323.396713, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[323.415655, "o", "    else:\r\n"]
[323.434598, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[323.45354, "o", "\r\n"]
[323.472483, "o", "    return ser\r\n"]
[323.491425, "o", "\r\n"]
[323.510368, "o", "\r\n"]
[323.52931, "o", "def hash_tuples(\r\n"]
[323.548253, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[323.567195, "o", "    encoding: str = \"utf8\",\r\n"]
[323.586138, "o", "    hash_key: str = _default_hash_key,\r\n"]
[323.60508, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[323.624023, "o", "    \"\"\"\r\n"]
[323.642966, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[323.661908, "o", "\r\n"]
[323.680851, "o", "    Parameters\r\n"]
[323.699793, "o", "    ----------\r\n"]
[323.718736, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[323.737678, "o", "    encoding : str, default 'utf8'\r\n"]
[323.756621, "o", "    hash_key : str, default _default_hash_key\r\n"]
[323.775563, "o", "\r\n"]
[323.794506, "o", "    Returns\r\n"]
[323.813448, "o", "    -------\r\n"]
[323.832391, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[323.851333, "o", "    \"\"\"\r\n"]
[323.870276, "o", "    if not is_list_like(vals):\r\n"]
[323.889218, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[323.908161, "o", "\r\n"]
[323.927103, "o", "    from pandas import (\r\n"]
[323.946046, "o", "        Categorical,\r\n"]
[323.964989, "o", "        MultiIndex,\r\n"]
[323.983931, "o", "    )\r\n"]
[324.002874, "o", "\r\n"]
[324.021816, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[324.040759, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[324.059701, "o", "    else:\r\n"]
[324.078644, "o", "        mi = vals\r\n"]
[324.097586, "o", "\r\n"]
[324.116529, "o", "    # create a list-of-Categoricals\r\n"]
[324.135471, "o", "    cat_vals = [\r\n"]
[324.154414, "o", "        Categorical._simple_new(\r\n"]
[324.173356, "o", "            mi.codes[level],\r\n"]
[324.192299, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[324.211241, "o", "        )\r\n"]
[324.230184, "o", "        for level in range(mi.nlevels)\r\n"]
[324.249126, "o", "    ]\r\n"]
[324.268069, "o", "\r\n"]
[324.287011, "o", "    # hash the list-of-ndarrays\r\n"]
[324.305954, "o", "    hashes = (\r\n"]
[324.324897, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[324.343839, "o", "        for cat in cat_vals\r\n"]
[324.362782, "o", "    )\r\n"]
[324.381724, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[324.400667, "o", "\r\n"]
[324.419609, "o", "    return h\r\n"]
[324.438552, "o", "\r\n"]
[324.457494, "o", "\r\n"]
[324.476437, "o", "def hash_array(\r\n"]
[324.495379, "o", "    vals: ArrayLike,\r\n"]
[324.514322, "o", "    encoding: str = \"utf8\",\r\n"]
[324.533264, "o", "    hash_key: str = _default_hash_key,\r\n"]
[324.552207, "o", "    categorize: bool = True,\r\n"]
[324.571149, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[324.590092, "o", "    \"\"\"\r\n"]
[324.609034, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[324.627977, "o", "\r\n"]
[324.64692, "o", "    Parameters\r\n"]
[324.665862, "o", "    ----------\r\n"]
[324.684805, "o", "    vals : ndarray or ExtensionArray\r\n"]
[324.703747, "o", "        The input array to hash.\r\n"]
[324.72269, "o", "    encoding : str, default 'utf8'\r\n"]
[324.741632, "o", "        Encoding for data & key when strings.\r\n"]
[324.760575, "o", "    hash_key : str, default _default_hash_key\r\n"]
[324.779517, "o", "        Hash_key for string key to encode.\r\n"]
[324.79846, "o", "    categorize : bool, default True\r\n"]
[324.817402, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[324.836345, "o", "        efficient when the array contains duplicate values.\r\n"]
[324.855287, "o", "\r\n"]
[324.87423, "o", "    Returns\r\n"]
[324.893172, "o", "    -------\r\n"]
[324.912115, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[324.931057, "o", "        Hashed values, same length as the vals.\r\n"]
[325.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[325.002, "i", "sed -n '260,620p' pandas/core/util/hashing.py\r"]
[325.004, "o", "sed -n '260,620p' pandas/core/util/hashing.py\r\n"]
[325.061551, "o", "\u001b[?2004l\r\n"]
[325.117101, "o", "\r\n"]
[325.172652, "o", "    See Also\r\n"]
[325.228202, "o", "    --------\r\n"]
[325.283753, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[325.339303, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[325.394854, "o", "\r\n"]
[325.450404, "o", "    Examples\r\n"]
[325.505955, "o", "    --------\r\n"]
[325.561506, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[325.617056, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[325.672607, "o", "      dtype=uint64)\r\n"]
[325.728157, "o", "    \"\"\"\r\n"]
[325.783708, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[325.839258, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[325.894809, "o", "\r\n"]
[325.95036, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[326.00591, "o", "        return vals._hash_pandas_object(\r\n"]
[326.061461, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[326.117011, "o", "        )\r\n"]
[326.172562, "o", "\r\n"]
[326.228112, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[326.283663, "o", "        # GH#42003\r\n"]
[326.339213, "o", "        raise TypeError(\r\n"]
[326.394764, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[326.450315, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[326.505865, "o", "        )\r\n"]
[326.561416, "o", "\r\n"]
[326.616966, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[326.672517, "o", "\r\n"]
[326.728067, "o", "\r\n"]
[326.783618, "o", "def _hash_ndarray(\r\n"]
[326.839169, "o", "    vals: np.ndarray,\r\n"]
[326.894719, "o", "    encoding: str = \"utf8\",\r\n"]
[326.95027, "o", "    hash_key: str = _default_hash_key,\r\n"]
[327.00582, "o", "    categorize: bool = True,\r\n"]
[327.061371, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[327.116921, "o", "    \"\"\"\r\n"]
[327.172472, "o", "    See hash_array.__doc__.\r\n"]
[327.228022, "o", "    \"\"\"\r\n"]
[327.283573, "o", "    dtype = vals.dtype\r\n"]
[327.339124, "o", "\r\n"]
[327.394674, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[327.450225, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[327.505775, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[327.561326, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[327.616876, "o", "        return hash_real + 23 * hash_imag\r\n"]
[327.672427, "o", "\r\n"]
[327.727978, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[327.783528, "o", "    # manage it.\r\n"]
[327.839079, "o", "    if dtype == bool:\r\n"]
[327.894629, "o", "        vals = vals.astype(\"u8\")\r\n"]
[327.95018, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[328.00573, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[328.061281, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[328.116831, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[328.172382, "o", "    else:\r\n"]
[328.227933, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[328.283483, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[328.339034, "o", "        # when the values are known/likely to be unique.\r\n"]
[328.394584, "o", "        if categorize:\r\n"]
[328.450135, "o", "            from pandas import (\r\n"]
[328.505685, "o", "                Categorical,\r\n"]
[328.561236, "o", "                Index,\r\n"]
[328.616787, "o", "                factorize,\r\n"]
[328.672337, "o", "            )\r\n"]
[328.727888, "o", "\r\n"]
[328.783438, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[328.838989, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[328.894539, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[328.95009, "o", "            return cat._hash_pandas_object(\r\n"]
[329.00564, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[329.061191, "o", "            )\r\n"]
[329.116742, "o", "\r\n"]
[329.172292, "o", "        try:\r\n"]
[329.227843, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[329.283393, "o", "        except TypeError:\r\n"]
[329.338944, "o", "            # we have mixed types\r\n"]
[329.394494, "o", "            vals = hash_object_array(\r\n"]
[329.450045, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[329.505596, "o", "            )\r\n"]
[329.561146, "o", "\r\n"]
[329.616697, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[329.672247, "o", "    vals ^= vals >> 30\r\n"]
[329.727798, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[329.783348, "o", "    vals ^= vals >> 27\r\n"]
[329.838899, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[329.894449, "o", "    vals ^= vals >> 31\r\n"]
[330.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[330.002, "i", "sed -n '1,260p' pandas/_libs/hashing.pyx\r"]
[330.004, "o", "sed -n '1,260p' pandas/_libs/hashing.pyx\r\n"]
[330.030844, "o", "\u001b[?2004l\r\n"]
[330.055688, "o", "# Translated from the reference implementation\r\n"]
[330.080533, "o", "# at https://github.com/veorq/SipHash\r\n"]
[330.105377, "o", "\r\n"]
[330.130221, "o", "cimport cython\r\n"]
[330.155065, "o", "from libc.stdlib cimport (\r\n"]
[330.17991, "o", "    free,\r\n"]
[330.204754, "o", "    malloc,\r\n"]
[330.229598, "o", ")\r\n"]
[330.254442, "o", "\r\n"]
[330.279286, "o", "import numpy as np\r\n"]
[330.304131, "o", "\r\n"]
[330.328975, "o", "from numpy cimport (\r\n"]
[330.353819, "o", "    import_array,\r\n"]
[330.378663, "o", "    ndarray,\r\n"]
[330.403508, "o", "    uint8_t,\r\n"]
[330.428352, "o", "    uint64_t,\r\n"]
[330.453196, "o", ")\r\n"]
[330.47804, "o", "\r\n"]
[330.502884, "o", "import_array()\r\n"]
[330.527729, "o", "\r\n"]
[330.552573, "o", "from pandas._libs.util cimport is_nan\r\n"]
[330.577417, "o", "\r\n"]
[330.602261, "o", "\r\n"]
[330.627106, "o", "@cython.boundscheck(False)\r\n"]
[330.65195, "o", "def hash_object_array(\r\n"]
[330.676794, "o", "    ndarray[object, ndim=1] arr, str key, str encoding=\"utf8\"\r\n"]
[330.701638, "o", ") -> np.ndarray[np.uint64]:\r\n"]
[330.726482, "o", "    \"\"\"\r\n"]
[330.751327, "o", "    Parameters\r\n"]
[330.776171, "o", "    ----------\r\n"]
[330.801015, "o", "    arr : 1-d object ndarray of objects\r\n"]
[330.825859, "o", "    key : hash key, must be 16 byte len encoded\r\n"]
[330.850704, "o", "    encoding : encoding for key & arr, default to 'utf8'\r\n"]
[330.875548, "o", "\r\n"]
[330.900392, "o", "    Returns\r\n"]
[330.925236, "o", "    -------\r\n"]
[330.95008, "o", "    1-d uint64 ndarray of hashes.\r\n"]
[330.974925, "o", "\r\n"]
[330.999769, "o", "    Raises\r\n"]
[331.024613, "o", "    ------\r\n"]
[331.049457, "o", "    TypeError\r\n"]
[331.074302, "o", "        If the array contains mixed types.\r\n"]
[331.099146, "o", "\r\n"]
[331.12399, "o", "    Notes\r\n"]
[331.148834, "o", "    -----\r\n"]
[331.173678, "o", "    Allowed values must be strings, or nulls\r\n"]
[331.198523, "o", "    mixed array types will raise TypeError.\r\n"]
[331.223367, "o", "    \"\"\"\r\n"]
[331.248211, "o", "    cdef:\r\n"]
[331.273055, "o", "        Py_ssize_t i, n\r\n"]
[331.297899, "o", "        uint64_t[::1] result\r\n"]
[331.322744, "o", "        bytes data, k\r\n"]
[331.347588, "o", "        uint8_t *kb\r\n"]
[331.372432, "o", "        uint64_t *lens\r\n"]
[331.397276, "o", "        char **vecs\r\n"]
[331.422121, "o", "        char *cdata\r\n"]
[331.446965, "o", "        object val\r\n"]
[331.471809, "o", "        list data_list = []\r\n"]
[331.496653, "o", "\r\n"]
[331.521497, "o", "    k = <bytes>key.encode(encoding)\r\n"]
[331.546342, "o", "    kb = <uint8_t *>k\r\n"]
[331.571186, "o", "    if len(k) != 16:\r\n"]
[331.59603, "o", "        raise ValueError(\r\n"]
[331.620874, "o", "            f\"key should be a 16-byte string encoded, got {k} (len {len(k)})\"\r\n"]
[331.645719, "o", "        )\r\n"]
[331.670563, "o", "\r\n"]
[331.695407, "o", "    n = len(arr)\r\n"]
[331.720251, "o", "\r\n"]
[331.745095, "o", "    # create an array of bytes\r\n"]
[331.76994, "o", "    vecs = <char **>malloc(n * sizeof(char *))\r\n"]
[331.794784, "o", "    if vecs is NULL:\r\n"]
[331.819628, "o", "        raise MemoryError()\r\n"]
[331.844472, "o", "    lens = <uint64_t*>malloc(n * sizeof(uint64_t))\r\n"]
[331.869317, "o", "    if lens is NULL:\r\n"]
[331.894161, "o", "        raise MemoryError()\r\n"]
[331.919005, "o", "\r\n"]
[331.943849, "o", "    for i in range(n):\r\n"]
[331.968693, "o", "        val = arr[i]\r\n"]
[331.993538, "o", "        if isinstance(val, bytes):\r\n"]
[332.018382, "o", "            data = <bytes>val\r\n"]
[332.043226, "o", "        elif isinstance(val, str):\r\n"]
[332.06807, "o", "            data = <bytes>val.encode(encoding)\r\n"]
[332.092915, "o", "        elif val is None or is_nan(val):\r\n"]
[332.117759, "o", "            # null, stringify and encode\r\n"]
[332.142603, "o", "            data = <bytes>str(val).encode(encoding)\r\n"]
[332.167447, "o", "\r\n"]
[332.192291, "o", "        elif isinstance(val, tuple):\r\n"]
[332.217136, "o", "            # GH#28969 we could have a tuple, but need to ensure that\r\n"]
[332.24198, "o", "            #  the tuple entries are themselves hashable before converting\r\n"]
[332.266824, "o", "            #  to str\r\n"]
[332.291668, "o", "            hash(val)\r\n"]
[332.316513, "o", "            data = <bytes>str(val).encode(encoding)\r\n"]
[332.341357, "o", "        else:\r\n"]
[332.366201, "o", "            raise TypeError(\r\n"]
[332.391045, "o", "                f\"{val} of type {type(val)} is not a valid type for hashing, \"\r\n"]
[332.415889, "o", "                \"must be string or null\"\r\n"]
[332.440734, "o", "            )\r\n"]
[332.465578, "o", "\r\n"]
[332.490422, "o", "        lens[i] = len(data)\r\n"]
[332.515266, "o", "        cdata = data\r\n"]
[332.540111, "o", "\r\n"]
[332.564955, "o", "        # keep the references alive through the end of the\r\n"]
[332.589799, "o", "        # function\r\n"]
[332.614643, "o", "        data_list.append(data)\r\n"]
[332.639487, "o", "        vecs[i] = cdata\r\n"]
[332.664332, "o", "\r\n"]
[332.689176, "o", "    result = np.empty(n, dtype=np.uint64)\r\n"]
[332.71402, "o", "    with nogil:\r\n"]
[332.738864, "o", "        for i in range(n):\r\n"]
[332.763709, "o", "            result[i] = low_level_siphash(<uint8_t *>vecs[i], lens[i], kb)\r\n"]
[332.788553, "o", "\r\n"]
[332.813397, "o", "    free(vecs)\r\n"]
[332.838241, "o", "    free(lens)\r\n"]
[332.863085, "o", "    return result.base  # .base to retrieve underlying np.ndarray\r\n"]
[332.88793, "o", "\r\n"]
[332.912774, "o", "\r\n"]
[332.937618, "o", "cdef uint64_t _rotl(uint64_t x, uint64_t b) noexcept nogil:\r\n"]
[332.962462, "o", "    return (x << b) | (x >> (64 - b))\r\n"]
[332.987307, "o", "\r\n"]
[333.012151, "o", "\r\n"]
[333.036995, "o", "cdef uint64_t u8to64_le(uint8_t* p) noexcept nogil:\r\n"]
[333.061839, "o", "    return (<uint64_t>p[0] |\r\n"]
[333.086683, "o", "            <uint64_t>p[1] << 8 |\r\n"]
[333.111528, "o", "            <uint64_t>p[2] << 16 |\r\n"]
[333.136372, "o", "            <uint64_t>p[3] << 24 |\r\n"]
[333.161216, "o", "            <uint64_t>p[4] << 32 |\r\n"]
[333.18606, "o", "            <uint64_t>p[5] << 40 |\r\n"]
[333.210905, "o", "            <uint64_t>p[6] << 48 |\r\n"]
[333.235749, "o", "            <uint64_t>p[7] << 56)\r\n"]
[333.260593, "o", "\r\n"]
[333.285437, "o", "\r\n"]
[333.310281, "o", "cdef void _sipround(uint64_t* v0, uint64_t* v1,\r\n"]
[333.335126, "o", "                    uint64_t* v2, uint64_t* v3) noexcept nogil:\r\n"]
[333.35997, "o", "    v0[0] += v1[0]\r\n"]
[333.384814, "o", "    v1[0] = _rotl(v1[0], 13)\r\n"]
[333.409658, "o", "    v1[0] ^= v0[0]\r\n"]
[333.434503, "o", "    v0[0] = _rotl(v0[0], 32)\r\n"]
[333.459347, "o", "    v2[0] += v3[0]\r\n"]
[333.484191, "o", "    v3[0] = _rotl(v3[0], 16)\r\n"]
[333.509035, "o", "    v3[0] ^= v2[0]\r\n"]
[333.533879, "o", "    v0[0] += v3[0]\r\n"]
[333.558724, "o", "    v3[0] = _rotl(v3[0], 21)\r\n"]
[333.583568, "o", "    v3[0] ^= v0[0]\r\n"]
[333.608412, "o", "    v2[0] += v1[0]\r\n"]
[333.633256, "o", "    v1[0] = _rotl(v1[0], 17)\r\n"]
[333.658101, "o", "    v1[0] ^= v2[0]\r\n"]
[333.682945, "o", "    v2[0] = _rotl(v2[0], 32)\r\n"]
[333.707789, "o", "\r\n"]
[333.732633, "o", "\r\n"]
[333.757477, "o", "@cython.cdivision(True)\r\n"]
[333.782322, "o", "cdef uint64_t low_level_siphash(uint8_t* data, size_t datalen,\r\n"]
[333.807166, "o", "                                uint8_t* key) noexcept nogil:\r\n"]
[333.83201, "o", "    cdef uint64_t v0 = 0x736f6d6570736575ULL\r\n"]
[333.856854, "o", "    cdef uint64_t v1 = 0x646f72616e646f6dULL\r\n"]
[333.881698, "o", "    cdef uint64_t v2 = 0x6c7967656e657261ULL\r\n"]
[333.906543, "o", "    cdef uint64_t v3 = 0x7465646279746573ULL\r\n"]
[333.931387, "o", "    cdef uint64_t b\r\n"]
[333.956231, "o", "    cdef uint64_t k0 = u8to64_le(key)\r\n"]
[333.981075, "o", "    cdef uint64_t k1 = u8to64_le(key + 8)\r\n"]
[334.00592, "o", "    cdef uint64_t m\r\n"]
[334.030764, "o", "    cdef int i\r\n"]
[334.055608, "o", "    cdef uint8_t* end = data + datalen - (datalen % sizeof(uint64_t))\r\n"]
[334.080452, "o", "    cdef int left = datalen & 7\r\n"]
[334.105296, "o", "    cdef int cROUNDS = 2\r\n"]
[334.130141, "o", "    cdef int dROUNDS = 4\r\n"]
[334.154985, "o", "\r\n"]
[334.179829, "o", "    b = (<uint64_t>datalen) << 56\r\n"]
[334.204673, "o", "    v3 ^= k1\r\n"]
[334.229518, "o", "    v2 ^= k0\r\n"]
[334.254362, "o", "    v1 ^= k1\r\n"]
[334.279206, "o", "    v0 ^= k0\r\n"]
[334.30405, "o", "\r\n"]
[334.328894, "o", "    while (data != end):\r\n"]
[334.353739, "o", "        m = u8to64_le(data)\r\n"]
[334.378583, "o", "        v3 ^= m\r\n"]
[334.403427, "o", "        for i in range(cROUNDS):\r\n"]
[334.428271, "o", "            _sipround(&v0, &v1, &v2, &v3)\r\n"]
[334.453116, "o", "        v0 ^= m\r\n"]
[334.47796, "o", "\r\n"]
[334.502804, "o", "        data += sizeof(uint64_t)\r\n"]
[334.527648, "o", "\r\n"]
[334.552492, "o", "    for i in range(left-1, -1, -1):\r\n"]
[334.577337, "o", "        b |= (<uint64_t>data[i]) << (i * 8)\r\n"]
[334.602181, "o", "\r\n"]
[334.627025, "o", "    v3 ^= b\r\n"]
[334.651869, "o", "\r\n"]
[334.676714, "o", "    for i in range(cROUNDS):\r\n"]
[334.701558, "o", "        _sipround(&v0, &v1, &v2, &v3)\r\n"]
[334.726402, "o", "\r\n"]
[334.751246, "o", "    v0 ^= b\r\n"]
[334.77609, "o", "    v2 ^= 0xff\r\n"]
[334.800935, "o", "\r\n"]
[334.825779, "o", "    for i in range(dROUNDS):\r\n"]
[334.850623, "o", "        _sipround(&v0, &v1, &v2, &v3)\r\n"]
[334.875467, "o", "\r\n"]
[334.900312, "o", "    b = v0 ^ v1 ^ v2 ^ v3\r\n"]
[334.925156, "o", "\r\n"]
[335.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[335.002, "i", "sed -n '260,520p' pandas/_libs/hashing.pyx\r"]
[335.004, "o", "sed -n '260,520p' pandas/_libs/hashing.pyx\r\n"]
[335.006, "o", "\u001b[?2004l\r\n"]
[340.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[340.002, "i", "sed -n '1,260p' pandas/core/util/hashing.py\r"]
[340.004, "o", "sed -n '1,260p' pandas/core/util/hashing.py\r\n"]
[340.024943, "o", "\u001b[?2004l\r\n"]
[340.043885, "o", "\"\"\"\r\n"]
[340.062828, "o", "data hash pandas / numpy objects\r\n"]
[340.08177, "o", "\"\"\"\r\n"]
[340.100713, "o", "\r\n"]
[340.119655, "o", "from __future__ import annotations\r\n"]
[340.138598, "o", "\r\n"]
[340.15754, "o", "import itertools\r\n"]
[340.176483, "o", "from typing import TYPE_CHECKING\r\n"]
[340.195425, "o", "\r\n"]
[340.214368, "o", "import numpy as np\r\n"]
[340.23331, "o", "\r\n"]
[340.252253, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[340.271195, "o", "\r\n"]
[340.290138, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[340.30908, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[340.328023, "o", "from pandas.core.dtypes.generic import (\r\n"]
[340.346966, "o", "    ABCDataFrame,\r\n"]
[340.365908, "o", "    ABCExtensionArray,\r\n"]
[340.384851, "o", "    ABCIndex,\r\n"]
[340.403793, "o", "    ABCMultiIndex,\r\n"]
[340.422736, "o", "    ABCSeries,\r\n"]
[340.441678, "o", ")\r\n"]
[340.460621, "o", "\r\n"]
[340.479563, "o", "if TYPE_CHECKING:\r\n"]
[340.498506, "o", "    from collections.abc import (\r\n"]
[340.517448, "o", "        Hashable,\r\n"]
[340.536391, "o", "        Iterable,\r\n"]
[340.555333, "o", "        Iterator,\r\n"]
[340.574276, "o", "    )\r\n"]
[340.593218, "o", "\r\n"]
[340.612161, "o", "    from pandas._typing import (\r\n"]
[340.631103, "o", "        ArrayLike,\r\n"]
[340.650046, "o", "        npt,\r\n"]
[340.668989, "o", "    )\r\n"]
[340.687931, "o", "\r\n"]
[340.706874, "o", "    from pandas import (\r\n"]
[340.725816, "o", "        DataFrame,\r\n"]
[340.744759, "o", "        Index,\r\n"]
[340.763701, "o", "        MultiIndex,\r\n"]
[340.782644, "o", "        Series,\r\n"]
[340.801586, "o", "    )\r\n"]
[340.820529, "o", "\r\n"]
[340.839471, "o", "\r\n"]
[340.858414, "o", "# 16 byte long hashing key\r\n"]
[340.877356, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[340.896299, "o", "\r\n"]
[340.915241, "o", "\r\n"]
[340.934184, "o", "def combine_hash_arrays(\r\n"]
[340.953126, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[340.972069, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[340.991011, "o", "    \"\"\"\r\n"]
[341.009954, "o", "    Parameters\r\n"]
[341.028897, "o", "    ----------\r\n"]
[341.047839, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[341.066782, "o", "    num_items : int\r\n"]
[341.085724, "o", "\r\n"]
[341.104667, "o", "    Returns\r\n"]
[341.123609, "o", "    -------\r\n"]
[341.142552, "o", "    np.ndarray[uint64]\r\n"]
[341.161494, "o", "\r\n"]
[341.180437, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[341.199379, "o", "    \"\"\"\r\n"]
[341.218322, "o", "    try:\r\n"]
[341.237264, "o", "        first = next(arrays)\r\n"]
[341.256207, "o", "    except StopIteration:\r\n"]
[341.275149, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[341.294092, "o", "\r\n"]
[341.313034, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[341.331977, "o", "\r\n"]
[341.35092, "o", "    mult = np.uint64(1000003)\r\n"]
[341.369862, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[341.388805, "o", "    last_i = 0\r\n"]
[341.407747, "o", "    for i, a in enumerate(arrays):\r\n"]
[341.42669, "o", "        inverse_i = num_items - i\r\n"]
[341.445632, "o", "        out ^= a\r\n"]
[341.464575, "o", "        out *= mult\r\n"]
[341.483517, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[341.50246, "o", "        last_i = i\r\n"]
[341.521402, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[341.540345, "o", "    out += np.uint64(97531)\r\n"]
[341.559287, "o", "    return out\r\n"]
[341.57823, "o", "\r\n"]
[341.597172, "o", "\r\n"]
[341.616115, "o", "def hash_pandas_object(\r\n"]
[341.635057, "o", "    obj: Index | DataFrame | Series,\r\n"]
[341.654, "o", "    index: bool = True,\r\n"]
[341.672943, "o", "    encoding: str = \"utf8\",\r\n"]
[341.691885, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[341.710828, "o", "    categorize: bool = True,\r\n"]
[341.72977, "o", ") -> Series:\r\n"]
[341.748713, "o", "    \"\"\"\r\n"]
[341.767655, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[341.786598, "o", "\r\n"]
[341.80554, "o", "    Parameters\r\n"]
[341.824483, "o", "    ----------\r\n"]
[341.843425, "o", "    obj : Index, Series, or DataFrame\r\n"]
[341.862368, "o", "    index : bool, default True\r\n"]
[341.88131, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[341.900253, "o", "    encoding : str, default 'utf8'\r\n"]
[341.919195, "o", "        Encoding for data & key when strings.\r\n"]
[341.938138, "o", "    hash_key : str, default _default_hash_key\r\n"]
[341.95708, "o", "        Hash_key for string key to encode.\r\n"]
[341.976023, "o", "    categorize : bool, default True\r\n"]
[341.994966, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[342.013908, "o", "        efficient when the array contains duplicate values.\r\n"]
[342.032851, "o", "\r\n"]
[342.051793, "o", "    Returns\r\n"]
[342.070736, "o", "    -------\r\n"]
[342.089678, "o", "    Series of uint64\r\n"]
[342.108621, "o", "        Same length as the object.\r\n"]
[342.127563, "o", "\r\n"]
[342.146506, "o", "    Examples\r\n"]
[342.165448, "o", "    --------\r\n"]
[342.184391, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[342.203333, "o", "    0    14639053686158035780\r\n"]
[342.222276, "o", "    1     3869563279212530728\r\n"]
[342.241218, "o", "    2      393322362522515241\r\n"]
[342.260161, "o", "    dtype: uint64\r\n"]
[342.279103, "o", "    \"\"\"\r\n"]
[342.298046, "o", "    from pandas import Series\r\n"]
[342.316989, "o", "\r\n"]
[342.335931, "o", "    if hash_key is None:\r\n"]
[342.354874, "o", "        hash_key = _default_hash_key\r\n"]
[342.373816, "o", "\r\n"]
[342.392759, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[342.411701, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[342.430644, "o", "\r\n"]
[342.449586, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[342.468529, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[342.487471, "o", "            \"uint64\", copy=False\r\n"]
[342.506414, "o", "        )\r\n"]
[342.525356, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[342.544299, "o", "\r\n"]
[342.563241, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[342.582184, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[342.601126, "o", "            \"uint64\", copy=False\r\n"]
[342.620069, "o", "        )\r\n"]
[342.639011, "o", "        if index:\r\n"]
[342.657954, "o", "            index_iter = (\r\n"]
[342.676897, "o", "                hash_pandas_object(\r\n"]
[342.695839, "o", "                    obj.index,\r\n"]
[342.714782, "o", "                    index=False,\r\n"]
[342.733724, "o", "                    encoding=encoding,\r\n"]
[342.752667, "o", "                    hash_key=hash_key,\r\n"]
[342.771609, "o", "                    categorize=categorize,\r\n"]
[342.790552, "o", "                )._values\r\n"]
[342.809494, "o", "                for _ in [None]\r\n"]
[342.828437, "o", "            )\r\n"]
[342.847379, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[342.866322, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[342.885264, "o", "\r\n"]
[342.904207, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[342.923149, "o", "\r\n"]
[342.942092, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[342.961034, "o", "        hashes = (\r\n"]
[342.979977, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[342.99892, "o", "            for _, series in obj.items()\r\n"]
[343.017862, "o", "        )\r\n"]
[343.036805, "o", "        num_items = len(obj.columns)\r\n"]
[343.055747, "o", "        if index:\r\n"]
[343.07469, "o", "            index_hash_generator = (\r\n"]
[343.093632, "o", "                hash_pandas_object(\r\n"]
[343.112575, "o", "                    obj.index,\r\n"]
[343.131517, "o", "                    index=False,\r\n"]
[343.15046, "o", "                    encoding=encoding,\r\n"]
[343.169402, "o", "                    hash_key=hash_key,\r\n"]
[343.188345, "o", "                    categorize=categorize,\r\n"]
[343.207287, "o", "                )._values\r\n"]
[343.22623, "o", "                for _ in [None]\r\n"]
[343.245172, "o", "            )\r\n"]
[343.264115, "o", "            num_items += 1\r\n"]
[343.283057, "o", "\r\n"]
[343.302, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[343.320943, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[343.339885, "o", "            hashes = (x for x in _hashes)\r\n"]
[343.358828, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[343.37777, "o", "\r\n"]
[343.396713, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[343.415655, "o", "    else:\r\n"]
[343.434598, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[343.45354, "o", "\r\n"]
[343.472483, "o", "    return ser\r\n"]
[343.491425, "o", "\r\n"]
[343.510368, "o", "\r\n"]
[343.52931, "o", "def hash_tuples(\r\n"]
[343.548253, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[343.567195, "o", "    encoding: str = \"utf8\",\r\n"]
[343.586138, "o", "    hash_key: str = _default_hash_key,\r\n"]
[343.60508, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[343.624023, "o", "    \"\"\"\r\n"]
[343.642966, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[343.661908, "o", "\r\n"]
[343.680851, "o", "    Parameters\r\n"]
[343.699793, "o", "    ----------\r\n"]
[343.718736, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[343.737678, "o", "    encoding : str, default 'utf8'\r\n"]
[343.756621, "o", "    hash_key : str, default _default_hash_key\r\n"]
[343.775563, "o", "\r\n"]
[343.794506, "o", "    Returns\r\n"]
[343.813448, "o", "    -------\r\n"]
[343.832391, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[343.851333, "o", "    \"\"\"\r\n"]
[343.870276, "o", "    if not is_list_like(vals):\r\n"]
[343.889218, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[343.908161, "o", "\r\n"]
[343.927103, "o", "    from pandas import (\r\n"]
[343.946046, "o", "        Categorical,\r\n"]
[343.964989, "o", "        MultiIndex,\r\n"]
[343.983931, "o", "    )\r\n"]
[344.002874, "o", "\r\n"]
[344.021816, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[344.040759, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[344.059701, "o", "    else:\r\n"]
[344.078644, "o", "        mi = vals\r\n"]
[344.097586, "o", "\r\n"]
[344.116529, "o", "    # create a list-of-Categoricals\r\n"]
[344.135471, "o", "    cat_vals = [\r\n"]
[344.154414, "o", "        Categorical._simple_new(\r\n"]
[344.173356, "o", "            mi.codes[level],\r\n"]
[344.192299, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[344.211241, "o", "        )\r\n"]
[344.230184, "o", "        for level in range(mi.nlevels)\r\n"]
[344.249126, "o", "    ]\r\n"]
[344.268069, "o", "\r\n"]
[344.287011, "o", "    # hash the list-of-ndarrays\r\n"]
[344.305954, "o", "    hashes = (\r\n"]
[344.324897, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[344.343839, "o", "        for cat in cat_vals\r\n"]
[344.362782, "o", "    )\r\n"]
[344.381724, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[344.400667, "o", "\r\n"]
[344.419609, "o", "    return h\r\n"]
[344.438552, "o", "\r\n"]
[344.457494, "o", "\r\n"]
[344.476437, "o", "def hash_array(\r\n"]
[344.495379, "o", "    vals: ArrayLike,\r\n"]
[344.514322, "o", "    encoding: str = \"utf8\",\r\n"]
[344.533264, "o", "    hash_key: str = _default_hash_key,\r\n"]
[344.552207, "o", "    categorize: bool = True,\r\n"]
[344.571149, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[344.590092, "o", "    \"\"\"\r\n"]
[344.609034, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[344.627977, "o", "\r\n"]
[344.64692, "o", "    Parameters\r\n"]
[344.665862, "o", "    ----------\r\n"]
[344.684805, "o", "    vals : ndarray or ExtensionArray\r\n"]
[344.703747, "o", "        The input array to hash.\r\n"]
[344.72269, "o", "    encoding : str, default 'utf8'\r\n"]
[344.741632, "o", "        Encoding for data & key when strings.\r\n"]
[344.760575, "o", "    hash_key : str, default _default_hash_key\r\n"]
[344.779517, "o", "        Hash_key for string key to encode.\r\n"]
[344.79846, "o", "    categorize : bool, default True\r\n"]
[344.817402, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[344.836345, "o", "        efficient when the array contains duplicate values.\r\n"]
[344.855287, "o", "\r\n"]
[344.87423, "o", "    Returns\r\n"]
[344.893172, "o", "    -------\r\n"]
[344.912115, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[344.931057, "o", "        Hashed values, same length as the vals.\r\n"]
[345.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[345.002, "i", "sed -n '260,620p' pandas/core/util/hashing.py\r"]
[345.004, "o", "sed -n '260,620p' pandas/core/util/hashing.py\r\n"]
[345.061551, "o", "\u001b[?2004l\r\n"]
[345.117101, "o", "\r\n"]
[345.172652, "o", "    See Also\r\n"]
[345.228202, "o", "    --------\r\n"]
[345.283753, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[345.339303, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[345.394854, "o", "\r\n"]
[345.450404, "o", "    Examples\r\n"]
[345.505955, "o", "    --------\r\n"]
[345.561506, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[345.617056, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[345.672607, "o", "      dtype=uint64)\r\n"]
[345.728157, "o", "    \"\"\"\r\n"]
[345.783708, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[345.839258, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[345.894809, "o", "\r\n"]
[345.95036, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[346.00591, "o", "        return vals._hash_pandas_object(\r\n"]
[346.061461, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[346.117011, "o", "        )\r\n"]
[346.172562, "o", "\r\n"]
[346.228112, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[346.283663, "o", "        # GH#42003\r\n"]
[346.339213, "o", "        raise TypeError(\r\n"]
[346.394764, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[346.450315, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[346.505865, "o", "        )\r\n"]
[346.561416, "o", "\r\n"]
[346.616966, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[346.672517, "o", "\r\n"]
[346.728067, "o", "\r\n"]
[346.783618, "o", "def _hash_ndarray(\r\n"]
[346.839169, "o", "    vals: np.ndarray,\r\n"]
[346.894719, "o", "    encoding: str = \"utf8\",\r\n"]
[346.95027, "o", "    hash_key: str = _default_hash_key,\r\n"]
[347.00582, "o", "    categorize: bool = True,\r\n"]
[347.061371, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[347.116921, "o", "    \"\"\"\r\n"]
[347.172472, "o", "    See hash_array.__doc__.\r\n"]
[347.228022, "o", "    \"\"\"\r\n"]
[347.283573, "o", "    dtype = vals.dtype\r\n"]
[347.339124, "o", "\r\n"]
[347.394674, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[347.450225, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[347.505775, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[347.561326, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[347.616876, "o", "        return hash_real + 23 * hash_imag\r\n"]
[347.672427, "o", "\r\n"]
[347.727978, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[347.783528, "o", "    # manage it.\r\n"]
[347.839079, "o", "    if dtype == bool:\r\n"]
[347.894629, "o", "        vals = vals.astype(\"u8\")\r\n"]
[347.95018, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[348.00573, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[348.061281, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[348.116831, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[348.172382, "o", "    else:\r\n"]
[348.227933, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[348.283483, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[348.339034, "o", "        # when the values are known/likely to be unique.\r\n"]
[348.394584, "o", "        if categorize:\r\n"]
[348.450135, "o", "            from pandas import (\r\n"]
[348.505685, "o", "                Categorical,\r\n"]
[348.561236, "o", "                Index,\r\n"]
[348.616787, "o", "                factorize,\r\n"]
[348.672337, "o", "            )\r\n"]
[348.727888, "o", "\r\n"]
[348.783438, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[348.838989, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[348.894539, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[348.95009, "o", "            return cat._hash_pandas_object(\r\n"]
[349.00564, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[349.061191, "o", "            )\r\n"]
[349.116742, "o", "\r\n"]
[349.172292, "o", "        try:\r\n"]
[349.227843, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[349.283393, "o", "        except TypeError:\r\n"]
[349.338944, "o", "            # we have mixed types\r\n"]
[349.394494, "o", "            vals = hash_object_array(\r\n"]
[349.450045, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[349.505596, "o", "            )\r\n"]
[349.561146, "o", "\r\n"]
[349.616697, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[349.672247, "o", "    vals ^= vals >> 30\r\n"]
[349.727798, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[349.783348, "o", "    vals ^= vals >> 27\r\n"]
[349.838899, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[349.894449, "o", "    vals ^= vals >> 31\r\n"]
[350.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[350.002, "i", "sed -n '1,200p' pandas/_libs/hashing.pyx\r"]
[350.004, "o", "sed -n '1,200p' pandas/_libs/hashing.pyx\r\n"]
[350.030844, "o", "\u001b[?2004l\r\n"]
[350.055688, "o", "# Translated from the reference implementation\r\n"]
[350.080533, "o", "# at https://github.com/veorq/SipHash\r\n"]
[350.105377, "o", "\r\n"]
[350.130221, "o", "cimport cython\r\n"]
[350.155065, "o", "from libc.stdlib cimport (\r\n"]
[350.17991, "o", "    free,\r\n"]
[350.204754, "o", "    malloc,\r\n"]
[350.229598, "o", ")\r\n"]
[350.254442, "o", "\r\n"]
[350.279286, "o", "import numpy as np\r\n"]
[350.304131, "o", "\r\n"]
[350.328975, "o", "from numpy cimport (\r\n"]
[350.353819, "o", "    import_array,\r\n"]
[350.378663, "o", "    ndarray,\r\n"]
[350.403508, "o", "    uint8_t,\r\n"]
[350.428352, "o", "    uint64_t,\r\n"]
[350.453196, "o", ")\r\n"]
[350.47804, "o", "\r\n"]
[350.502884, "o", "import_array()\r\n"]
[350.527729, "o", "\r\n"]
[350.552573, "o", "from pandas._libs.util cimport is_nan\r\n"]
[350.577417, "o", "\r\n"]
[350.602261, "o", "\r\n"]
[350.627106, "o", "@cython.boundscheck(False)\r\n"]
[350.65195, "o", "def hash_object_array(\r\n"]
[350.676794, "o", "    ndarray[object, ndim=1] arr, str key, str encoding=\"utf8\"\r\n"]
[350.701638, "o", ") -> np.ndarray[np.uint64]:\r\n"]
[350.726482, "o", "    \"\"\"\r\n"]
[350.751327, "o", "    Parameters\r\n"]
[350.776171, "o", "    ----------\r\n"]
[350.801015, "o", "    arr : 1-d object ndarray of objects\r\n"]
[350.825859, "o", "    key : hash key, must be 16 byte len encoded\r\n"]
[350.850704, "o", "    encoding : encoding for key & arr, default to 'utf8'\r\n"]
[350.875548, "o", "\r\n"]
[350.900392, "o", "    Returns\r\n"]
[350.925236, "o", "    -------\r\n"]
[350.95008, "o", "    1-d uint64 ndarray of hashes.\r\n"]
[350.974925, "o", "\r\n"]
[350.999769, "o", "    Raises\r\n"]
[351.024613, "o", "    ------\r\n"]
[351.049457, "o", "    TypeError\r\n"]
[351.074302, "o", "        If the array contains mixed types.\r\n"]
[351.099146, "o", "\r\n"]
[351.12399, "o", "    Notes\r\n"]
[351.148834, "o", "    -----\r\n"]
[351.173678, "o", "    Allowed values must be strings, or nulls\r\n"]
[351.198523, "o", "    mixed array types will raise TypeError.\r\n"]
[351.223367, "o", "    \"\"\"\r\n"]
[351.248211, "o", "    cdef:\r\n"]
[351.273055, "o", "        Py_ssize_t i, n\r\n"]
[351.297899, "o", "        uint64_t[::1] result\r\n"]
[351.322744, "o", "        bytes data, k\r\n"]
[351.347588, "o", "        uint8_t *kb\r\n"]
[351.372432, "o", "        uint64_t *lens\r\n"]
[351.397276, "o", "        char **vecs\r\n"]
[351.422121, "o", "        char *cdata\r\n"]
[351.446965, "o", "        object val\r\n"]
[351.471809, "o", "        list data_list = []\r\n"]
[351.496653, "o", "\r\n"]
[351.521497, "o", "    k = <bytes>key.encode(encoding)\r\n"]
[351.546342, "o", "    kb = <uint8_t *>k\r\n"]
[351.571186, "o", "    if len(k) != 16:\r\n"]
[351.59603, "o", "        raise ValueError(\r\n"]
[351.620874, "o", "            f\"key should be a 16-byte string encoded, got {k} (len {len(k)})\"\r\n"]
[351.645719, "o", "        )\r\n"]
[351.670563, "o", "\r\n"]
[351.695407, "o", "    n = len(arr)\r\n"]
[351.720251, "o", "\r\n"]
[351.745095, "o", "    # create an array of bytes\r\n"]
[351.76994, "o", "    vecs = <char **>malloc(n * sizeof(char *))\r\n"]
[351.794784, "o", "    if vecs is NULL:\r\n"]
[351.819628, "o", "        raise MemoryError()\r\n"]
[351.844472, "o", "    lens = <uint64_t*>malloc(n * sizeof(uint64_t))\r\n"]
[351.869317, "o", "    if lens is NULL:\r\n"]
[351.894161, "o", "        raise MemoryError()\r\n"]
[351.919005, "o", "\r\n"]
[351.943849, "o", "    for i in range(n):\r\n"]
[351.968693, "o", "        val = arr[i]\r\n"]
[351.993538, "o", "        if isinstance(val, bytes):\r\n"]
[352.018382, "o", "            data = <bytes>val\r\n"]
[352.043226, "o", "        elif isinstance(val, str):\r\n"]
[352.06807, "o", "            data = <bytes>val.encode(encoding)\r\n"]
[352.092915, "o", "        elif val is None or is_nan(val):\r\n"]
[352.117759, "o", "            # null, stringify and encode\r\n"]
[352.142603, "o", "            data = <bytes>str(val).encode(encoding)\r\n"]
[352.167447, "o", "\r\n"]
[352.192291, "o", "        elif isinstance(val, tuple):\r\n"]
[352.217136, "o", "            # GH#28969 we could have a tuple, but need to ensure that\r\n"]
[352.24198, "o", "            #  the tuple entries are themselves hashable before converting\r\n"]
[352.266824, "o", "            #  to str\r\n"]
[352.291668, "o", "            hash(val)\r\n"]
[352.316513, "o", "            data = <bytes>str(val).encode(encoding)\r\n"]
[352.341357, "o", "        else:\r\n"]
[352.366201, "o", "            raise TypeError(\r\n"]
[352.391045, "o", "                f\"{val} of type {type(val)} is not a valid type for hashing, \"\r\n"]
[352.415889, "o", "                \"must be string or null\"\r\n"]
[352.440734, "o", "            )\r\n"]
[352.465578, "o", "\r\n"]
[352.490422, "o", "        lens[i] = len(data)\r\n"]
[352.515266, "o", "        cdata = data\r\n"]
[352.540111, "o", "\r\n"]
[352.564955, "o", "        # keep the references alive through the end of the\r\n"]
[352.589799, "o", "        # function\r\n"]
[352.614643, "o", "        data_list.append(data)\r\n"]
[352.639487, "o", "        vecs[i] = cdata\r\n"]
[352.664332, "o", "\r\n"]
[352.689176, "o", "    result = np.empty(n, dtype=np.uint64)\r\n"]
[352.71402, "o", "    with nogil:\r\n"]
[352.738864, "o", "        for i in range(n):\r\n"]
[352.763709, "o", "            result[i] = low_level_siphash(<uint8_t *>vecs[i], lens[i], kb)\r\n"]
[352.788553, "o", "\r\n"]
[352.813397, "o", "    free(vecs)\r\n"]
[352.838241, "o", "    free(lens)\r\n"]
[352.863085, "o", "    return result.base  # .base to retrieve underlying np.ndarray\r\n"]
[352.88793, "o", "\r\n"]
[352.912774, "o", "\r\n"]
[352.937618, "o", "cdef uint64_t _rotl(uint64_t x, uint64_t b) noexcept nogil:\r\n"]
[352.962462, "o", "    return (x << b) | (x >> (64 - b))\r\n"]
[352.987307, "o", "\r\n"]
[353.012151, "o", "\r\n"]
[353.036995, "o", "cdef uint64_t u8to64_le(uint8_t* p) noexcept nogil:\r\n"]
[353.061839, "o", "    return (<uint64_t>p[0] |\r\n"]
[353.086683, "o", "            <uint64_t>p[1] << 8 |\r\n"]
[353.111528, "o", "            <uint64_t>p[2] << 16 |\r\n"]
[353.136372, "o", "            <uint64_t>p[3] << 24 |\r\n"]
[353.161216, "o", "            <uint64_t>p[4] << 32 |\r\n"]
[353.18606, "o", "            <uint64_t>p[5] << 40 |\r\n"]
[353.210905, "o", "            <uint64_t>p[6] << 48 |\r\n"]
[353.235749, "o", "            <uint64_t>p[7] << 56)\r\n"]
[353.260593, "o", "\r\n"]
[353.285437, "o", "\r\n"]
[353.310281, "o", "cdef void _sipround(uint64_t* v0, uint64_t* v1,\r\n"]
[353.335126, "o", "                    uint64_t* v2, uint64_t* v3) noexcept nogil:\r\n"]
[353.35997, "o", "    v0[0] += v1[0]\r\n"]
[353.384814, "o", "    v1[0] = _rotl(v1[0], 13)\r\n"]
[353.409658, "o", "    v1[0] ^= v0[0]\r\n"]
[353.434503, "o", "    v0[0] = _rotl(v0[0], 32)\r\n"]
[353.459347, "o", "    v2[0] += v3[0]\r\n"]
[353.484191, "o", "    v3[0] = _rotl(v3[0], 16)\r\n"]
[353.509035, "o", "    v3[0] ^= v2[0]\r\n"]
[353.533879, "o", "    v0[0] += v3[0]\r\n"]
[353.558724, "o", "    v3[0] = _rotl(v3[0], 21)\r\n"]
[353.583568, "o", "    v3[0] ^= v0[0]\r\n"]
[353.608412, "o", "    v2[0] += v1[0]\r\n"]
[353.633256, "o", "    v1[0] = _rotl(v1[0], 17)\r\n"]
[353.658101, "o", "    v1[0] ^= v2[0]\r\n"]
[353.682945, "o", "    v2[0] = _rotl(v2[0], 32)\r\n"]
[353.707789, "o", "\r\n"]
[353.732633, "o", "\r\n"]
[353.757477, "o", "@cython.cdivision(True)\r\n"]
[353.782322, "o", "cdef uint64_t low_level_siphash(uint8_t* data, size_t datalen,\r\n"]
[353.807166, "o", "                                uint8_t* key) noexcept nogil:\r\n"]
[353.83201, "o", "    cdef uint64_t v0 = 0x736f6d6570736575ULL\r\n"]
[353.856854, "o", "    cdef uint64_t v1 = 0x646f72616e646f6dULL\r\n"]
[353.881698, "o", "    cdef uint64_t v2 = 0x6c7967656e657261ULL\r\n"]
[353.906543, "o", "    cdef uint64_t v3 = 0x7465646279746573ULL\r\n"]
[353.931387, "o", "    cdef uint64_t b\r\n"]
[353.956231, "o", "    cdef uint64_t k0 = u8to64_le(key)\r\n"]
[353.981075, "o", "    cdef uint64_t k1 = u8to64_le(key + 8)\r\n"]
[354.00592, "o", "    cdef uint64_t m\r\n"]
[354.030764, "o", "    cdef int i\r\n"]
[354.055608, "o", "    cdef uint8_t* end = data + datalen - (datalen % sizeof(uint64_t))\r\n"]
[354.080452, "o", "    cdef int left = datalen & 7\r\n"]
[354.105296, "o", "    cdef int cROUNDS = 2\r\n"]
[354.130141, "o", "    cdef int dROUNDS = 4\r\n"]
[354.154985, "o", "\r\n"]
[354.179829, "o", "    b = (<uint64_t>datalen) << 56\r\n"]
[354.204673, "o", "    v3 ^= k1\r\n"]
[354.229518, "o", "    v2 ^= k0\r\n"]
[354.254362, "o", "    v1 ^= k1\r\n"]
[354.279206, "o", "    v0 ^= k0\r\n"]
[354.30405, "o", "\r\n"]
[354.328894, "o", "    while (data != end):\r\n"]
[354.353739, "o", "        m = u8to64_le(data)\r\n"]
[354.378583, "o", "        v3 ^= m\r\n"]
[354.403427, "o", "        for i in range(cROUNDS):\r\n"]
[354.428271, "o", "            _sipround(&v0, &v1, &v2, &v3)\r\n"]
[354.453116, "o", "        v0 ^= m\r\n"]
[354.47796, "o", "\r\n"]
[354.502804, "o", "        data += sizeof(uint64_t)\r\n"]
[354.527648, "o", "\r\n"]
[354.552492, "o", "    for i in range(left-1, -1, -1):\r\n"]
[354.577337, "o", "        b |= (<uint64_t>data[i]) << (i * 8)\r\n"]
[354.602181, "o", "\r\n"]
[354.627025, "o", "    v3 ^= b\r\n"]
[354.651869, "o", "\r\n"]
[354.676714, "o", "    for i in range(cROUNDS):\r\n"]
[354.701558, "o", "        _sipround(&v0, &v1, &v2, &v3)\r\n"]
[354.726402, "o", "\r\n"]
[354.751246, "o", "    v0 ^= b\r\n"]
[354.77609, "o", "    v2 ^= 0xff\r\n"]
[354.800935, "o", "\r\n"]
[354.825779, "o", "    for i in range(dROUNDS):\r\n"]
[354.850623, "o", "        _sipround(&v0, &v1, &v2, &v3)\r\n"]
[354.875467, "o", "\r\n"]
[354.900312, "o", "    b = v0 ^ v1 ^ v2 ^ v3\r\n"]
[354.925156, "o", "\r\n"]
[355.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[355.002, "i", "sed -n '200,520p' pandas/_libs/hashing.pyx\r"]
[355.004, "o", "sed -n '200,520p' pandas/_libs/hashing.pyx\r\n"]
[355.006, "o", "\u001b[?2004l\r\n"]
[360.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[360.002, "i", "sed -n '1,260p' pandas/core/util/hashing.py\r"]
[360.004, "o", "sed -n '1,260p' pandas/core/util/hashing.py\r\n"]
[360.024943, "o", "\u001b[?2004l\r\n"]
[360.043885, "o", "\"\"\"\r\n"]
[360.062828, "o", "data hash pandas / numpy objects\r\n"]
[360.08177, "o", "\"\"\"\r\n"]
[360.100713, "o", "\r\n"]
[360.119655, "o", "from __future__ import annotations\r\n"]
[360.138598, "o", "\r\n"]
[360.15754, "o", "import itertools\r\n"]
[360.176483, "o", "from typing import TYPE_CHECKING\r\n"]
[360.195425, "o", "\r\n"]
[360.214368, "o", "import numpy as np\r\n"]
[360.23331, "o", "\r\n"]
[360.252253, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[360.271195, "o", "\r\n"]
[360.290138, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[360.30908, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[360.328023, "o", "from pandas.core.dtypes.generic import (\r\n"]
[360.346966, "o", "    ABCDataFrame,\r\n"]
[360.365908, "o", "    ABCExtensionArray,\r\n"]
[360.384851, "o", "    ABCIndex,\r\n"]
[360.403793, "o", "    ABCMultiIndex,\r\n"]
[360.422736, "o", "    ABCSeries,\r\n"]
[360.441678, "o", ")\r\n"]
[360.460621, "o", "\r\n"]
[360.479563, "o", "if TYPE_CHECKING:\r\n"]
[360.498506, "o", "    from collections.abc import (\r\n"]
[360.517448, "o", "        Hashable,\r\n"]
[360.536391, "o", "        Iterable,\r\n"]
[360.555333, "o", "        Iterator,\r\n"]
[360.574276, "o", "    )\r\n"]
[360.593218, "o", "\r\n"]
[360.612161, "o", "    from pandas._typing import (\r\n"]
[360.631103, "o", "        ArrayLike,\r\n"]
[360.650046, "o", "        npt,\r\n"]
[360.668989, "o", "    )\r\n"]
[360.687931, "o", "\r\n"]
[360.706874, "o", "    from pandas import (\r\n"]
[360.725816, "o", "        DataFrame,\r\n"]
[360.744759, "o", "        Index,\r\n"]
[360.763701, "o", "        MultiIndex,\r\n"]
[360.782644, "o", "        Series,\r\n"]
[360.801586, "o", "    )\r\n"]
[360.820529, "o", "\r\n"]
[360.839471, "o", "\r\n"]
[360.858414, "o", "# 16 byte long hashing key\r\n"]
[360.877356, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[360.896299, "o", "\r\n"]
[360.915241, "o", "\r\n"]
[360.934184, "o", "def combine_hash_arrays(\r\n"]
[360.953126, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[360.972069, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[360.991011, "o", "    \"\"\"\r\n"]
[361.009954, "o", "    Parameters\r\n"]
[361.028897, "o", "    ----------\r\n"]
[361.047839, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[361.066782, "o", "    num_items : int\r\n"]
[361.085724, "o", "\r\n"]
[361.104667, "o", "    Returns\r\n"]
[361.123609, "o", "    -------\r\n"]
[361.142552, "o", "    np.ndarray[uint64]\r\n"]
[361.161494, "o", "\r\n"]
[361.180437, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[361.199379, "o", "    \"\"\"\r\n"]
[361.218322, "o", "    try:\r\n"]
[361.237264, "o", "        first = next(arrays)\r\n"]
[361.256207, "o", "    except StopIteration:\r\n"]
[361.275149, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[361.294092, "o", "\r\n"]
[361.313034, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[361.331977, "o", "\r\n"]
[361.35092, "o", "    mult = np.uint64(1000003)\r\n"]
[361.369862, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[361.388805, "o", "    last_i = 0\r\n"]
[361.407747, "o", "    for i, a in enumerate(arrays):\r\n"]
[361.42669, "o", "        inverse_i = num_items - i\r\n"]
[361.445632, "o", "        out ^= a\r\n"]
[361.464575, "o", "        out *= mult\r\n"]
[361.483517, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[361.50246, "o", "        last_i = i\r\n"]
[361.521402, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[361.540345, "o", "    out += np.uint64(97531)\r\n"]
[361.559287, "o", "    return out\r\n"]
[361.57823, "o", "\r\n"]
[361.597172, "o", "\r\n"]
[361.616115, "o", "def hash_pandas_object(\r\n"]
[361.635057, "o", "    obj: Index | DataFrame | Series,\r\n"]
[361.654, "o", "    index: bool = True,\r\n"]
[361.672943, "o", "    encoding: str = \"utf8\",\r\n"]
[361.691885, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[361.710828, "o", "    categorize: bool = True,\r\n"]
[361.72977, "o", ") -> Series:\r\n"]
[361.748713, "o", "    \"\"\"\r\n"]
[361.767655, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[361.786598, "o", "\r\n"]
[361.80554, "o", "    Parameters\r\n"]
[361.824483, "o", "    ----------\r\n"]
[361.843425, "o", "    obj : Index, Series, or DataFrame\r\n"]
[361.862368, "o", "    index : bool, default True\r\n"]
[361.88131, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[361.900253, "o", "    encoding : str, default 'utf8'\r\n"]
[361.919195, "o", "        Encoding for data & key when strings.\r\n"]
[361.938138, "o", "    hash_key : str, default _default_hash_key\r\n"]
[361.95708, "o", "        Hash_key for string key to encode.\r\n"]
[361.976023, "o", "    categorize : bool, default True\r\n"]
[361.994966, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[362.013908, "o", "        efficient when the array contains duplicate values.\r\n"]
[362.032851, "o", "\r\n"]
[362.051793, "o", "    Returns\r\n"]
[362.070736, "o", "    -------\r\n"]
[362.089678, "o", "    Series of uint64\r\n"]
[362.108621, "o", "        Same length as the object.\r\n"]
[362.127563, "o", "\r\n"]
[362.146506, "o", "    Examples\r\n"]
[362.165448, "o", "    --------\r\n"]
[362.184391, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[362.203333, "o", "    0    14639053686158035780\r\n"]
[362.222276, "o", "    1     3869563279212530728\r\n"]
[362.241218, "o", "    2      393322362522515241\r\n"]
[362.260161, "o", "    dtype: uint64\r\n"]
[362.279103, "o", "    \"\"\"\r\n"]
[362.298046, "o", "    from pandas import Series\r\n"]
[362.316989, "o", "\r\n"]
[362.335931, "o", "    if hash_key is None:\r\n"]
[362.354874, "o", "        hash_key = _default_hash_key\r\n"]
[362.373816, "o", "\r\n"]
[362.392759, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[362.411701, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[362.430644, "o", "\r\n"]
[362.449586, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[362.468529, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[362.487471, "o", "            \"uint64\", copy=False\r\n"]
[362.506414, "o", "        )\r\n"]
[362.525356, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[362.544299, "o", "\r\n"]
[362.563241, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[362.582184, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[362.601126, "o", "            \"uint64\", copy=False\r\n"]
[362.620069, "o", "        )\r\n"]
[362.639011, "o", "        if index:\r\n"]
[362.657954, "o", "            index_iter = (\r\n"]
[362.676897, "o", "                hash_pandas_object(\r\n"]
[362.695839, "o", "                    obj.index,\r\n"]
[362.714782, "o", "                    index=False,\r\n"]
[362.733724, "o", "                    encoding=encoding,\r\n"]
[362.752667, "o", "                    hash_key=hash_key,\r\n"]
[362.771609, "o", "                    categorize=categorize,\r\n"]
[362.790552, "o", "                )._values\r\n"]
[362.809494, "o", "                for _ in [None]\r\n"]
[362.828437, "o", "            )\r\n"]
[362.847379, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[362.866322, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[362.885264, "o", "\r\n"]
[362.904207, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[362.923149, "o", "\r\n"]
[362.942092, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[362.961034, "o", "        hashes = (\r\n"]
[362.979977, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[362.99892, "o", "            for _, series in obj.items()\r\n"]
[363.017862, "o", "        )\r\n"]
[363.036805, "o", "        num_items = len(obj.columns)\r\n"]
[363.055747, "o", "        if index:\r\n"]
[363.07469, "o", "            index_hash_generator = (\r\n"]
[363.093632, "o", "                hash_pandas_object(\r\n"]
[363.112575, "o", "                    obj.index,\r\n"]
[363.131517, "o", "                    index=False,\r\n"]
[363.15046, "o", "                    encoding=encoding,\r\n"]
[363.169402, "o", "                    hash_key=hash_key,\r\n"]
[363.188345, "o", "                    categorize=categorize,\r\n"]
[363.207287, "o", "                )._values\r\n"]
[363.22623, "o", "                for _ in [None]\r\n"]
[363.245172, "o", "            )\r\n"]
[363.264115, "o", "            num_items += 1\r\n"]
[363.283057, "o", "\r\n"]
[363.302, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[363.320943, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[363.339885, "o", "            hashes = (x for x in _hashes)\r\n"]
[363.358828, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[363.37777, "o", "\r\n"]
[363.396713, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[363.415655, "o", "    else:\r\n"]
[363.434598, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[363.45354, "o", "\r\n"]
[363.472483, "o", "    return ser\r\n"]
[363.491425, "o", "\r\n"]
[363.510368, "o", "\r\n"]
[363.52931, "o", "def hash_tuples(\r\n"]
[363.548253, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[363.567195, "o", "    encoding: str = \"utf8\",\r\n"]
[363.586138, "o", "    hash_key: str = _default_hash_key,\r\n"]
[363.60508, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[363.624023, "o", "    \"\"\"\r\n"]
[363.642966, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[363.661908, "o", "\r\n"]
[363.680851, "o", "    Parameters\r\n"]
[363.699793, "o", "    ----------\r\n"]
[363.718736, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[363.737678, "o", "    encoding : str, default 'utf8'\r\n"]
[363.756621, "o", "    hash_key : str, default _default_hash_key\r\n"]
[363.775563, "o", "\r\n"]
[363.794506, "o", "    Returns\r\n"]
[363.813448, "o", "    -------\r\n"]
[363.832391, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[363.851333, "o", "    \"\"\"\r\n"]
[363.870276, "o", "    if not is_list_like(vals):\r\n"]
[363.889218, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[363.908161, "o", "\r\n"]
[363.927103, "o", "    from pandas import (\r\n"]
[363.946046, "o", "        Categorical,\r\n"]
[363.964989, "o", "        MultiIndex,\r\n"]
[363.983931, "o", "    )\r\n"]
[364.002874, "o", "\r\n"]
[364.021816, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[364.040759, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[364.059701, "o", "    else:\r\n"]
[364.078644, "o", "        mi = vals\r\n"]
[364.097586, "o", "\r\n"]
[364.116529, "o", "    # create a list-of-Categoricals\r\n"]
[364.135471, "o", "    cat_vals = [\r\n"]
[364.154414, "o", "        Categorical._simple_new(\r\n"]
[364.173356, "o", "            mi.codes[level],\r\n"]
[364.192299, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[364.211241, "o", "        )\r\n"]
[364.230184, "o", "        for level in range(mi.nlevels)\r\n"]
[364.249126, "o", "    ]\r\n"]
[364.268069, "o", "\r\n"]
[364.287011, "o", "    # hash the list-of-ndarrays\r\n"]
[364.305954, "o", "    hashes = (\r\n"]
[364.324897, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[364.343839, "o", "        for cat in cat_vals\r\n"]
[364.362782, "o", "    )\r\n"]
[364.381724, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[364.400667, "o", "\r\n"]
[364.419609, "o", "    return h\r\n"]
[364.438552, "o", "\r\n"]
[364.457494, "o", "\r\n"]
[364.476437, "o", "def hash_array(\r\n"]
[364.495379, "o", "    vals: ArrayLike,\r\n"]
[364.514322, "o", "    encoding: str = \"utf8\",\r\n"]
[364.533264, "o", "    hash_key: str = _default_hash_key,\r\n"]
[364.552207, "o", "    categorize: bool = True,\r\n"]
[364.571149, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[364.590092, "o", "    \"\"\"\r\n"]
[364.609034, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[364.627977, "o", "\r\n"]
[364.64692, "o", "    Parameters\r\n"]
[364.665862, "o", "    ----------\r\n"]
[364.684805, "o", "    vals : ndarray or ExtensionArray\r\n"]
[364.703747, "o", "        The input array to hash.\r\n"]
[364.72269, "o", "    encoding : str, default 'utf8'\r\n"]
[364.741632, "o", "        Encoding for data & key when strings.\r\n"]
[364.760575, "o", "    hash_key : str, default _default_hash_key\r\n"]
[364.779517, "o", "        Hash_key for string key to encode.\r\n"]
[364.79846, "o", "    categorize : bool, default True\r\n"]
[364.817402, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[364.836345, "o", "        efficient when the array contains duplicate values.\r\n"]
[364.855287, "o", "\r\n"]
[364.87423, "o", "    Returns\r\n"]
[364.893172, "o", "    -------\r\n"]
[364.912115, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[364.931057, "o", "        Hashed values, same length as the vals.\r\n"]
[365.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[365.002, "i", "sed -n '260,620p' pandas/core/util/hashing.py\r"]
[365.004, "o", "sed -n '260,620p' pandas/core/util/hashing.py\r\n"]
[365.061551, "o", "\u001b[?2004l\r\n"]
[365.117101, "o", "\r\n"]
[365.172652, "o", "    See Also\r\n"]
[365.228202, "o", "    --------\r\n"]
[365.283753, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[365.339303, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[365.394854, "o", "\r\n"]
[365.450404, "o", "    Examples\r\n"]
[365.505955, "o", "    --------\r\n"]
[365.561506, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[365.617056, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[365.672607, "o", "      dtype=uint64)\r\n"]
[365.728157, "o", "    \"\"\"\r\n"]
[365.783708, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[365.839258, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[365.894809, "o", "\r\n"]
[365.95036, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[366.00591, "o", "        return vals._hash_pandas_object(\r\n"]
[366.061461, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[366.117011, "o", "        )\r\n"]
[366.172562, "o", "\r\n"]
[366.228112, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[366.283663, "o", "        # GH#42003\r\n"]
[366.339213, "o", "        raise TypeError(\r\n"]
[366.394764, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[366.450315, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[366.505865, "o", "        )\r\n"]
[366.561416, "o", "\r\n"]
[366.616966, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[366.672517, "o", "\r\n"]
[366.728067, "o", "\r\n"]
[366.783618, "o", "def _hash_ndarray(\r\n"]
[366.839169, "o", "    vals: np.ndarray,\r\n"]
[366.894719, "o", "    encoding: str = \"utf8\",\r\n"]
[366.95027, "o", "    hash_key: str = _default_hash_key,\r\n"]
[367.00582, "o", "    categorize: bool = True,\r\n"]
[367.061371, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[367.116921, "o", "    \"\"\"\r\n"]
[367.172472, "o", "    See hash_array.__doc__.\r\n"]
[367.228022, "o", "    \"\"\"\r\n"]
[367.283573, "o", "    dtype = vals.dtype\r\n"]
[367.339124, "o", "\r\n"]
[367.394674, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[367.450225, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[367.505775, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[367.561326, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[367.616876, "o", "        return hash_real + 23 * hash_imag\r\n"]
[367.672427, "o", "\r\n"]
[367.727978, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[367.783528, "o", "    # manage it.\r\n"]
[367.839079, "o", "    if dtype == bool:\r\n"]
[367.894629, "o", "        vals = vals.astype(\"u8\")\r\n"]
[367.95018, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[368.00573, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[368.061281, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[368.116831, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[368.172382, "o", "    else:\r\n"]
[368.227933, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[368.283483, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[368.339034, "o", "        # when the values are known/likely to be unique.\r\n"]
[368.394584, "o", "        if categorize:\r\n"]
[368.450135, "o", "            from pandas import (\r\n"]
[368.505685, "o", "                Categorical,\r\n"]
[368.561236, "o", "                Index,\r\n"]
[368.616787, "o", "                factorize,\r\n"]
[368.672337, "o", "            )\r\n"]
[368.727888, "o", "\r\n"]
[368.783438, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[368.838989, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[368.894539, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[368.95009, "o", "            return cat._hash_pandas_object(\r\n"]
[369.00564, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[369.061191, "o", "            )\r\n"]
[369.116742, "o", "\r\n"]
[369.172292, "o", "        try:\r\n"]
[369.227843, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[369.283393, "o", "        except TypeError:\r\n"]
[369.338944, "o", "            # we have mixed types\r\n"]
[369.394494, "o", "            vals = hash_object_array(\r\n"]
[369.450045, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[369.505596, "o", "            )\r\n"]
[369.561146, "o", "\r\n"]
[369.616697, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[369.672247, "o", "    vals ^= vals >> 30\r\n"]
[369.727798, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[369.783348, "o", "    vals ^= vals >> 27\r\n"]
[369.838899, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[369.894449, "o", "    vals ^= vals >> 31\r\n"]
[370.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[370.002, "i", "sed -n '1,220p' pandas/_libs/hashing.pyx\r"]
[370.004, "o", "sed -n '1,220p' pandas/_libs/hashing.pyx\r\n"]
[370.030844, "o", "\u001b[?2004l\r\n"]
[370.055688, "o", "# Translated from the reference implementation\r\n"]
[370.080533, "o", "# at https://github.com/veorq/SipHash\r\n"]
[370.105377, "o", "\r\n"]
[370.130221, "o", "cimport cython\r\n"]
[370.155065, "o", "from libc.stdlib cimport (\r\n"]
[370.17991, "o", "    free,\r\n"]
[370.204754, "o", "    malloc,\r\n"]
[370.229598, "o", ")\r\n"]
[370.254442, "o", "\r\n"]
[370.279286, "o", "import numpy as np\r\n"]
[370.304131, "o", "\r\n"]
[370.328975, "o", "from numpy cimport (\r\n"]
[370.353819, "o", "    import_array,\r\n"]
[370.378663, "o", "    ndarray,\r\n"]
[370.403508, "o", "    uint8_t,\r\n"]
[370.428352, "o", "    uint64_t,\r\n"]
[370.453196, "o", ")\r\n"]
[370.47804, "o", "\r\n"]
[370.502884, "o", "import_array()\r\n"]
[370.527729, "o", "\r\n"]
[370.552573, "o", "from pandas._libs.util cimport is_nan\r\n"]
[370.577417, "o", "\r\n"]
[370.602261, "o", "\r\n"]
[370.627106, "o", "@cython.boundscheck(False)\r\n"]
[370.65195, "o", "def hash_object_array(\r\n"]
[370.676794, "o", "    ndarray[object, ndim=1] arr, str key, str encoding=\"utf8\"\r\n"]
[370.701638, "o", ") -> np.ndarray[np.uint64]:\r\n"]
[370.726482, "o", "    \"\"\"\r\n"]
[370.751327, "o", "    Parameters\r\n"]
[370.776171, "o", "    ----------\r\n"]
[370.801015, "o", "    arr : 1-d object ndarray of objects\r\n"]
[370.825859, "o", "    key : hash key, must be 16 byte len encoded\r\n"]
[370.850704, "o", "    encoding : encoding for key & arr, default to 'utf8'\r\n"]
[370.875548, "o", "\r\n"]
[370.900392, "o", "    Returns\r\n"]
[370.925236, "o", "    -------\r\n"]
[370.95008, "o", "    1-d uint64 ndarray of hashes.\r\n"]
[370.974925, "o", "\r\n"]
[370.999769, "o", "    Raises\r\n"]
[371.024613, "o", "    ------\r\n"]
[371.049457, "o", "    TypeError\r\n"]
[371.074302, "o", "        If the array contains mixed types.\r\n"]
[371.099146, "o", "\r\n"]
[371.12399, "o", "    Notes\r\n"]
[371.148834, "o", "    -----\r\n"]
[371.173678, "o", "    Allowed values must be strings, or nulls\r\n"]
[371.198523, "o", "    mixed array types will raise TypeError.\r\n"]
[371.223367, "o", "    \"\"\"\r\n"]
[371.248211, "o", "    cdef:\r\n"]
[371.273055, "o", "        Py_ssize_t i, n\r\n"]
[371.297899, "o", "        uint64_t[::1] result\r\n"]
[371.322744, "o", "        bytes data, k\r\n"]
[371.347588, "o", "        uint8_t *kb\r\n"]
[371.372432, "o", "        uint64_t *lens\r\n"]
[371.397276, "o", "        char **vecs\r\n"]
[371.422121, "o", "        char *cdata\r\n"]
[371.446965, "o", "        object val\r\n"]
[371.471809, "o", "        list data_list = []\r\n"]
[371.496653, "o", "\r\n"]
[371.521497, "o", "    k = <bytes>key.encode(encoding)\r\n"]
[371.546342, "o", "    kb = <uint8_t *>k\r\n"]
[371.571186, "o", "    if len(k) != 16:\r\n"]
[371.59603, "o", "        raise ValueError(\r\n"]
[371.620874, "o", "            f\"key should be a 16-byte string encoded, got {k} (len {len(k)})\"\r\n"]
[371.645719, "o", "        )\r\n"]
[371.670563, "o", "\r\n"]
[371.695407, "o", "    n = len(arr)\r\n"]
[371.720251, "o", "\r\n"]
[371.745095, "o", "    # create an array of bytes\r\n"]
[371.76994, "o", "    vecs = <char **>malloc(n * sizeof(char *))\r\n"]
[371.794784, "o", "    if vecs is NULL:\r\n"]
[371.819628, "o", "        raise MemoryError()\r\n"]
[371.844472, "o", "    lens = <uint64_t*>malloc(n * sizeof(uint64_t))\r\n"]
[371.869317, "o", "    if lens is NULL:\r\n"]
[371.894161, "o", "        raise MemoryError()\r\n"]
[371.919005, "o", "\r\n"]
[371.943849, "o", "    for i in range(n):\r\n"]
[371.968693, "o", "        val = arr[i]\r\n"]
[371.993538, "o", "        if isinstance(val, bytes):\r\n"]
[372.018382, "o", "            data = <bytes>val\r\n"]
[372.043226, "o", "        elif isinstance(val, str):\r\n"]
[372.06807, "o", "            data = <bytes>val.encode(encoding)\r\n"]
[372.092915, "o", "        elif val is None or is_nan(val):\r\n"]
[372.117759, "o", "            # null, stringify and encode\r\n"]
[372.142603, "o", "            data = <bytes>str(val).encode(encoding)\r\n"]
[372.167447, "o", "\r\n"]
[372.192291, "o", "        elif isinstance(val, tuple):\r\n"]
[372.217136, "o", "            # GH#28969 we could have a tuple, but need to ensure that\r\n"]
[372.24198, "o", "            #  the tuple entries are themselves hashable before converting\r\n"]
[372.266824, "o", "            #  to str\r\n"]
[372.291668, "o", "            hash(val)\r\n"]
[372.316513, "o", "            data = <bytes>str(val).encode(encoding)\r\n"]
[372.341357, "o", "        else:\r\n"]
[372.366201, "o", "            raise TypeError(\r\n"]
[372.391045, "o", "                f\"{val} of type {type(val)} is not a valid type for hashing, \"\r\n"]
[372.415889, "o", "                \"must be string or null\"\r\n"]
[372.440734, "o", "            )\r\n"]
[372.465578, "o", "\r\n"]
[372.490422, "o", "        lens[i] = len(data)\r\n"]
[372.515266, "o", "        cdata = data\r\n"]
[372.540111, "o", "\r\n"]
[372.564955, "o", "        # keep the references alive through the end of the\r\n"]
[372.589799, "o", "        # function\r\n"]
[372.614643, "o", "        data_list.append(data)\r\n"]
[372.639487, "o", "        vecs[i] = cdata\r\n"]
[372.664332, "o", "\r\n"]
[372.689176, "o", "    result = np.empty(n, dtype=np.uint64)\r\n"]
[372.71402, "o", "    with nogil:\r\n"]
[372.738864, "o", "        for i in range(n):\r\n"]
[372.763709, "o", "            result[i] = low_level_siphash(<uint8_t *>vecs[i], lens[i], kb)\r\n"]
[372.788553, "o", "\r\n"]
[372.813397, "o", "    free(vecs)\r\n"]
[372.838241, "o", "    free(lens)\r\n"]
[372.863085, "o", "    return result.base  # .base to retrieve underlying np.ndarray\r\n"]
[372.88793, "o", "\r\n"]
[372.912774, "o", "\r\n"]
[372.937618, "o", "cdef uint64_t _rotl(uint64_t x, uint64_t b) noexcept nogil:\r\n"]
[372.962462, "o", "    return (x << b) | (x >> (64 - b))\r\n"]
[372.987307, "o", "\r\n"]
[373.012151, "o", "\r\n"]
[373.036995, "o", "cdef uint64_t u8to64_le(uint8_t* p) noexcept nogil:\r\n"]
[373.061839, "o", "    return (<uint64_t>p[0] |\r\n"]
[373.086683, "o", "            <uint64_t>p[1] << 8 |\r\n"]
[373.111528, "o", "            <uint64_t>p[2] << 16 |\r\n"]
[373.136372, "o", "            <uint64_t>p[3] << 24 |\r\n"]
[373.161216, "o", "            <uint64_t>p[4] << 32 |\r\n"]
[373.18606, "o", "            <uint64_t>p[5] << 40 |\r\n"]
[373.210905, "o", "            <uint64_t>p[6] << 48 |\r\n"]
[373.235749, "o", "            <uint64_t>p[7] << 56)\r\n"]
[373.260593, "o", "\r\n"]
[373.285437, "o", "\r\n"]
[373.310281, "o", "cdef void _sipround(uint64_t* v0, uint64_t* v1,\r\n"]
[373.335126, "o", "                    uint64_t* v2, uint64_t* v3) noexcept nogil:\r\n"]
[373.35997, "o", "    v0[0] += v1[0]\r\n"]
[373.384814, "o", "    v1[0] = _rotl(v1[0], 13)\r\n"]
[373.409658, "o", "    v1[0] ^= v0[0]\r\n"]
[373.434503, "o", "    v0[0] = _rotl(v0[0], 32)\r\n"]
[373.459347, "o", "    v2[0] += v3[0]\r\n"]
[373.484191, "o", "    v3[0] = _rotl(v3[0], 16)\r\n"]
[373.509035, "o", "    v3[0] ^= v2[0]\r\n"]
[373.533879, "o", "    v0[0] += v3[0]\r\n"]
[373.558724, "o", "    v3[0] = _rotl(v3[0], 21)\r\n"]
[373.583568, "o", "    v3[0] ^= v0[0]\r\n"]
[373.608412, "o", "    v2[0] += v1[0]\r\n"]
[373.633256, "o", "    v1[0] = _rotl(v1[0], 17)\r\n"]
[373.658101, "o", "    v1[0] ^= v2[0]\r\n"]
[373.682945, "o", "    v2[0] = _rotl(v2[0], 32)\r\n"]
[373.707789, "o", "\r\n"]
[373.732633, "o", "\r\n"]
[373.757477, "o", "@cython.cdivision(True)\r\n"]
[373.782322, "o", "cdef uint64_t low_level_siphash(uint8_t* data, size_t datalen,\r\n"]
[373.807166, "o", "                                uint8_t* key) noexcept nogil:\r\n"]
[373.83201, "o", "    cdef uint64_t v0 = 0x736f6d6570736575ULL\r\n"]
[373.856854, "o", "    cdef uint64_t v1 = 0x646f72616e646f6dULL\r\n"]
[373.881698, "o", "    cdef uint64_t v2 = 0x6c7967656e657261ULL\r\n"]
[373.906543, "o", "    cdef uint64_t v3 = 0x7465646279746573ULL\r\n"]
[373.931387, "o", "    cdef uint64_t b\r\n"]
[373.956231, "o", "    cdef uint64_t k0 = u8to64_le(key)\r\n"]
[373.981075, "o", "    cdef uint64_t k1 = u8to64_le(key + 8)\r\n"]
[374.00592, "o", "    cdef uint64_t m\r\n"]
[374.030764, "o", "    cdef int i\r\n"]
[374.055608, "o", "    cdef uint8_t* end = data + datalen - (datalen % sizeof(uint64_t))\r\n"]
[374.080452, "o", "    cdef int left = datalen & 7\r\n"]
[374.105296, "o", "    cdef int cROUNDS = 2\r\n"]
[374.130141, "o", "    cdef int dROUNDS = 4\r\n"]
[374.154985, "o", "\r\n"]
[374.179829, "o", "    b = (<uint64_t>datalen) << 56\r\n"]
[374.204673, "o", "    v3 ^= k1\r\n"]
[374.229518, "o", "    v2 ^= k0\r\n"]
[374.254362, "o", "    v1 ^= k1\r\n"]
[374.279206, "o", "    v0 ^= k0\r\n"]
[374.30405, "o", "\r\n"]
[374.328894, "o", "    while (data != end):\r\n"]
[374.353739, "o", "        m = u8to64_le(data)\r\n"]
[374.378583, "o", "        v3 ^= m\r\n"]
[374.403427, "o", "        for i in range(cROUNDS):\r\n"]
[374.428271, "o", "            _sipround(&v0, &v1, &v2, &v3)\r\n"]
[374.453116, "o", "        v0 ^= m\r\n"]
[374.47796, "o", "\r\n"]
[374.502804, "o", "        data += sizeof(uint64_t)\r\n"]
[374.527648, "o", "\r\n"]
[374.552492, "o", "    for i in range(left-1, -1, -1):\r\n"]
[374.577337, "o", "        b |= (<uint64_t>data[i]) << (i * 8)\r\n"]
[374.602181, "o", "\r\n"]
[374.627025, "o", "    v3 ^= b\r\n"]
[374.651869, "o", "\r\n"]
[374.676714, "o", "    for i in range(cROUNDS):\r\n"]
[374.701558, "o", "        _sipround(&v0, &v1, &v2, &v3)\r\n"]
[374.726402, "o", "\r\n"]
[374.751246, "o", "    v0 ^= b\r\n"]
[374.77609, "o", "    v2 ^= 0xff\r\n"]
[374.800935, "o", "\r\n"]
[374.825779, "o", "    for i in range(dROUNDS):\r\n"]
[374.850623, "o", "        _sipround(&v0, &v1, &v2, &v3)\r\n"]
[374.875467, "o", "\r\n"]
[374.900312, "o", "    b = v0 ^ v1 ^ v2 ^ v3\r\n"]
[374.925156, "o", "\r\n"]
[375.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[375.002, "i", "sed -n '1,260p' pandas/core/util/hashing.py\r"]
[375.004, "o", "sed -n '1,260p' pandas/core/util/hashing.py\r\n"]
[375.024943, "o", "\u001b[?2004l\r\n"]
[375.043885, "o", "\"\"\"\r\n"]
[375.062828, "o", "data hash pandas / numpy objects\r\n"]
[375.08177, "o", "\"\"\"\r\n"]
[375.100713, "o", "\r\n"]
[375.119655, "o", "from __future__ import annotations\r\n"]
[375.138598, "o", "\r\n"]
[375.15754, "o", "import itertools\r\n"]
[375.176483, "o", "from typing import TYPE_CHECKING\r\n"]
[375.195425, "o", "\r\n"]
[375.214368, "o", "import numpy as np\r\n"]
[375.23331, "o", "\r\n"]
[375.252253, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[375.271195, "o", "\r\n"]
[375.290138, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[375.30908, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[375.328023, "o", "from pandas.core.dtypes.generic import (\r\n"]
[375.346966, "o", "    ABCDataFrame,\r\n"]
[375.365908, "o", "    ABCExtensionArray,\r\n"]
[375.384851, "o", "    ABCIndex,\r\n"]
[375.403793, "o", "    ABCMultiIndex,\r\n"]
[375.422736, "o", "    ABCSeries,\r\n"]
[375.441678, "o", ")\r\n"]
[375.460621, "o", "\r\n"]
[375.479563, "o", "if TYPE_CHECKING:\r\n"]
[375.498506, "o", "    from collections.abc import (\r\n"]
[375.517448, "o", "        Hashable,\r\n"]
[375.536391, "o", "        Iterable,\r\n"]
[375.555333, "o", "        Iterator,\r\n"]
[375.574276, "o", "    )\r\n"]
[375.593218, "o", "\r\n"]
[375.612161, "o", "    from pandas._typing import (\r\n"]
[375.631103, "o", "        ArrayLike,\r\n"]
[375.650046, "o", "        npt,\r\n"]
[375.668989, "o", "    )\r\n"]
[375.687931, "o", "\r\n"]
[375.706874, "o", "    from pandas import (\r\n"]
[375.725816, "o", "        DataFrame,\r\n"]
[375.744759, "o", "        Index,\r\n"]
[375.763701, "o", "        MultiIndex,\r\n"]
[375.782644, "o", "        Series,\r\n"]
[375.801586, "o", "    )\r\n"]
[375.820529, "o", "\r\n"]
[375.839471, "o", "\r\n"]
[375.858414, "o", "# 16 byte long hashing key\r\n"]
[375.877356, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[375.896299, "o", "\r\n"]
[375.915241, "o", "\r\n"]
[375.934184, "o", "def combine_hash_arrays(\r\n"]
[375.953126, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[375.972069, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[375.991011, "o", "    \"\"\"\r\n"]
[376.009954, "o", "    Parameters\r\n"]
[376.028897, "o", "    ----------\r\n"]
[376.047839, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[376.066782, "o", "    num_items : int\r\n"]
[376.085724, "o", "\r\n"]
[376.104667, "o", "    Returns\r\n"]
[376.123609, "o", "    -------\r\n"]
[376.142552, "o", "    np.ndarray[uint64]\r\n"]
[376.161494, "o", "\r\n"]
[376.180437, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[376.199379, "o", "    \"\"\"\r\n"]
[376.218322, "o", "    try:\r\n"]
[376.237264, "o", "        first = next(arrays)\r\n"]
[376.256207, "o", "    except StopIteration:\r\n"]
[376.275149, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[376.294092, "o", "\r\n"]
[376.313034, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[376.331977, "o", "\r\n"]
[376.35092, "o", "    mult = np.uint64(1000003)\r\n"]
[376.369862, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[376.388805, "o", "    last_i = 0\r\n"]
[376.407747, "o", "    for i, a in enumerate(arrays):\r\n"]
[376.42669, "o", "        inverse_i = num_items - i\r\n"]
[376.445632, "o", "        out ^= a\r\n"]
[376.464575, "o", "        out *= mult\r\n"]
[376.483517, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[376.50246, "o", "        last_i = i\r\n"]
[376.521402, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[376.540345, "o", "    out += np.uint64(97531)\r\n"]
[376.559287, "o", "    return out\r\n"]
[376.57823, "o", "\r\n"]
[376.597172, "o", "\r\n"]
[376.616115, "o", "def hash_pandas_object(\r\n"]
[376.635057, "o", "    obj: Index | DataFrame | Series,\r\n"]
[376.654, "o", "    index: bool = True,\r\n"]
[376.672943, "o", "    encoding: str = \"utf8\",\r\n"]
[376.691885, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[376.710828, "o", "    categorize: bool = True,\r\n"]
[376.72977, "o", ") -> Series:\r\n"]
[376.748713, "o", "    \"\"\"\r\n"]
[376.767655, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[376.786598, "o", "\r\n"]
[376.80554, "o", "    Parameters\r\n"]
[376.824483, "o", "    ----------\r\n"]
[376.843425, "o", "    obj : Index, Series, or DataFrame\r\n"]
[376.862368, "o", "    index : bool, default True\r\n"]
[376.88131, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[376.900253, "o", "    encoding : str, default 'utf8'\r\n"]
[376.919195, "o", "        Encoding for data & key when strings.\r\n"]
[376.938138, "o", "    hash_key : str, default _default_hash_key\r\n"]
[376.95708, "o", "        Hash_key for string key to encode.\r\n"]
[376.976023, "o", "    categorize : bool, default True\r\n"]
[376.994966, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[377.013908, "o", "        efficient when the array contains duplicate values.\r\n"]
[377.032851, "o", "\r\n"]
[377.051793, "o", "    Returns\r\n"]
[377.070736, "o", "    -------\r\n"]
[377.089678, "o", "    Series of uint64\r\n"]
[377.108621, "o", "        Same length as the object.\r\n"]
[377.127563, "o", "\r\n"]
[377.146506, "o", "    Examples\r\n"]
[377.165448, "o", "    --------\r\n"]
[377.184391, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[377.203333, "o", "    0    14639053686158035780\r\n"]
[377.222276, "o", "    1     3869563279212530728\r\n"]
[377.241218, "o", "    2      393322362522515241\r\n"]
[377.260161, "o", "    dtype: uint64\r\n"]
[377.279103, "o", "    \"\"\"\r\n"]
[377.298046, "o", "    from pandas import Series\r\n"]
[377.316989, "o", "\r\n"]
[377.335931, "o", "    if hash_key is None:\r\n"]
[377.354874, "o", "        hash_key = _default_hash_key\r\n"]
[377.373816, "o", "\r\n"]
[377.392759, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[377.411701, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[377.430644, "o", "\r\n"]
[377.449586, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[377.468529, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[377.487471, "o", "            \"uint64\", copy=False\r\n"]
[377.506414, "o", "        )\r\n"]
[377.525356, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[377.544299, "o", "\r\n"]
[377.563241, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[377.582184, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[377.601126, "o", "            \"uint64\", copy=False\r\n"]
[377.620069, "o", "        )\r\n"]
[377.639011, "o", "        if index:\r\n"]
[377.657954, "o", "            index_iter = (\r\n"]
[377.676897, "o", "                hash_pandas_object(\r\n"]
[377.695839, "o", "                    obj.index,\r\n"]
[377.714782, "o", "                    index=False,\r\n"]
[377.733724, "o", "                    encoding=encoding,\r\n"]
[377.752667, "o", "                    hash_key=hash_key,\r\n"]
[377.771609, "o", "                    categorize=categorize,\r\n"]
[377.790552, "o", "                )._values\r\n"]
[377.809494, "o", "                for _ in [None]\r\n"]
[377.828437, "o", "            )\r\n"]
[377.847379, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[377.866322, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[377.885264, "o", "\r\n"]
[377.904207, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[377.923149, "o", "\r\n"]
[377.942092, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[377.961034, "o", "        hashes = (\r\n"]
[377.979977, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[377.99892, "o", "            for _, series in obj.items()\r\n"]
[378.017862, "o", "        )\r\n"]
[378.036805, "o", "        num_items = len(obj.columns)\r\n"]
[378.055747, "o", "        if index:\r\n"]
[378.07469, "o", "            index_hash_generator = (\r\n"]
[378.093632, "o", "                hash_pandas_object(\r\n"]
[378.112575, "o", "                    obj.index,\r\n"]
[378.131517, "o", "                    index=False,\r\n"]
[378.15046, "o", "                    encoding=encoding,\r\n"]
[378.169402, "o", "                    hash_key=hash_key,\r\n"]
[378.188345, "o", "                    categorize=categorize,\r\n"]
[378.207287, "o", "                )._values\r\n"]
[378.22623, "o", "                for _ in [None]\r\n"]
[378.245172, "o", "            )\r\n"]
[378.264115, "o", "            num_items += 1\r\n"]
[378.283057, "o", "\r\n"]
[378.302, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[378.320943, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[378.339885, "o", "            hashes = (x for x in _hashes)\r\n"]
[378.358828, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[378.37777, "o", "\r\n"]
[378.396713, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[378.415655, "o", "    else:\r\n"]
[378.434598, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[378.45354, "o", "\r\n"]
[378.472483, "o", "    return ser\r\n"]
[378.491425, "o", "\r\n"]
[378.510368, "o", "\r\n"]
[378.52931, "o", "def hash_tuples(\r\n"]
[378.548253, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[378.567195, "o", "    encoding: str = \"utf8\",\r\n"]
[378.586138, "o", "    hash_key: str = _default_hash_key,\r\n"]
[378.60508, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[378.624023, "o", "    \"\"\"\r\n"]
[378.642966, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[378.661908, "o", "\r\n"]
[378.680851, "o", "    Parameters\r\n"]
[378.699793, "o", "    ----------\r\n"]
[378.718736, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[378.737678, "o", "    encoding : str, default 'utf8'\r\n"]
[378.756621, "o", "    hash_key : str, default _default_hash_key\r\n"]
[378.775563, "o", "\r\n"]
[378.794506, "o", "    Returns\r\n"]
[378.813448, "o", "    -------\r\n"]
[378.832391, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[378.851333, "o", "    \"\"\"\r\n"]
[378.870276, "o", "    if not is_list_like(vals):\r\n"]
[378.889218, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[378.908161, "o", "\r\n"]
[378.927103, "o", "    from pandas import (\r\n"]
[378.946046, "o", "        Categorical,\r\n"]
[378.964989, "o", "        MultiIndex,\r\n"]
[378.983931, "o", "    )\r\n"]
[379.002874, "o", "\r\n"]
[379.021816, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[379.040759, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[379.059701, "o", "    else:\r\n"]
[379.078644, "o", "        mi = vals\r\n"]
[379.097586, "o", "\r\n"]
[379.116529, "o", "    # create a list-of-Categoricals\r\n"]
[379.135471, "o", "    cat_vals = [\r\n"]
[379.154414, "o", "        Categorical._simple_new(\r\n"]
[379.173356, "o", "            mi.codes[level],\r\n"]
[379.192299, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[379.211241, "o", "        )\r\n"]
[379.230184, "o", "        for level in range(mi.nlevels)\r\n"]
[379.249126, "o", "    ]\r\n"]
[379.268069, "o", "\r\n"]
[379.287011, "o", "    # hash the list-of-ndarrays\r\n"]
[379.305954, "o", "    hashes = (\r\n"]
[379.324897, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[379.343839, "o", "        for cat in cat_vals\r\n"]
[379.362782, "o", "    )\r\n"]
[379.381724, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[379.400667, "o", "\r\n"]
[379.419609, "o", "    return h\r\n"]
[379.438552, "o", "\r\n"]
[379.457494, "o", "\r\n"]
[379.476437, "o", "def hash_array(\r\n"]
[379.495379, "o", "    vals: ArrayLike,\r\n"]
[379.514322, "o", "    encoding: str = \"utf8\",\r\n"]
[379.533264, "o", "    hash_key: str = _default_hash_key,\r\n"]
[379.552207, "o", "    categorize: bool = True,\r\n"]
[379.571149, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[379.590092, "o", "    \"\"\"\r\n"]
[379.609034, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[379.627977, "o", "\r\n"]
[379.64692, "o", "    Parameters\r\n"]
[379.665862, "o", "    ----------\r\n"]
[379.684805, "o", "    vals : ndarray or ExtensionArray\r\n"]
[379.703747, "o", "        The input array to hash.\r\n"]
[379.72269, "o", "    encoding : str, default 'utf8'\r\n"]
[379.741632, "o", "        Encoding for data & key when strings.\r\n"]
[379.760575, "o", "    hash_key : str, default _default_hash_key\r\n"]
[379.779517, "o", "        Hash_key for string key to encode.\r\n"]
[379.79846, "o", "    categorize : bool, default True\r\n"]
[379.817402, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[379.836345, "o", "        efficient when the array contains duplicate values.\r\n"]
[379.855287, "o", "\r\n"]
[379.87423, "o", "    Returns\r\n"]
[379.893172, "o", "    -------\r\n"]
[379.912115, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[379.931057, "o", "        Hashed values, same length as the vals.\r\n"]
[380.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[380.002, "i", "sed -n '260,640p' pandas/core/util/hashing.py\r"]
[380.004, "o", "sed -n '260,640p' pandas/core/util/hashing.py\r\n"]
[380.061551, "o", "\u001b[?2004l\r\n"]
[380.117101, "o", "\r\n"]
[380.172652, "o", "    See Also\r\n"]
[380.228202, "o", "    --------\r\n"]
[380.283753, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[380.339303, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[380.394854, "o", "\r\n"]
[380.450404, "o", "    Examples\r\n"]
[380.505955, "o", "    --------\r\n"]
[380.561506, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[380.617056, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[380.672607, "o", "      dtype=uint64)\r\n"]
[380.728157, "o", "    \"\"\"\r\n"]
[380.783708, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[380.839258, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[380.894809, "o", "\r\n"]
[380.95036, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[381.00591, "o", "        return vals._hash_pandas_object(\r\n"]
[381.061461, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[381.117011, "o", "        )\r\n"]
[381.172562, "o", "\r\n"]
[381.228112, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[381.283663, "o", "        # GH#42003\r\n"]
[381.339213, "o", "        raise TypeError(\r\n"]
[381.394764, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[381.450315, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[381.505865, "o", "        )\r\n"]
[381.561416, "o", "\r\n"]
[381.616966, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[381.672517, "o", "\r\n"]
[381.728067, "o", "\r\n"]
[381.783618, "o", "def _hash_ndarray(\r\n"]
[381.839169, "o", "    vals: np.ndarray,\r\n"]
[381.894719, "o", "    encoding: str = \"utf8\",\r\n"]
[381.95027, "o", "    hash_key: str = _default_hash_key,\r\n"]
[382.00582, "o", "    categorize: bool = True,\r\n"]
[382.061371, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[382.116921, "o", "    \"\"\"\r\n"]
[382.172472, "o", "    See hash_array.__doc__.\r\n"]
[382.228022, "o", "    \"\"\"\r\n"]
[382.283573, "o", "    dtype = vals.dtype\r\n"]
[382.339124, "o", "\r\n"]
[382.394674, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[382.450225, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[382.505775, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[382.561326, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[382.616876, "o", "        return hash_real + 23 * hash_imag\r\n"]
[382.672427, "o", "\r\n"]
[382.727978, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[382.783528, "o", "    # manage it.\r\n"]
[382.839079, "o", "    if dtype == bool:\r\n"]
[382.894629, "o", "        vals = vals.astype(\"u8\")\r\n"]
[382.95018, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[383.00573, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[383.061281, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[383.116831, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[383.172382, "o", "    else:\r\n"]
[383.227933, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[383.283483, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[383.339034, "o", "        # when the values are known/likely to be unique.\r\n"]
[383.394584, "o", "        if categorize:\r\n"]
[383.450135, "o", "            from pandas import (\r\n"]
[383.505685, "o", "                Categorical,\r\n"]
[383.561236, "o", "                Index,\r\n"]
[383.616787, "o", "                factorize,\r\n"]
[383.672337, "o", "            )\r\n"]
[383.727888, "o", "\r\n"]
[383.783438, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[383.838989, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[383.894539, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[383.95009, "o", "            return cat._hash_pandas_object(\r\n"]
[384.00564, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[384.061191, "o", "            )\r\n"]
[384.116742, "o", "\r\n"]
[384.172292, "o", "        try:\r\n"]
[384.227843, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[384.283393, "o", "        except TypeError:\r\n"]
[384.338944, "o", "            # we have mixed types\r\n"]
[384.394494, "o", "            vals = hash_object_array(\r\n"]
[384.450045, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[384.505596, "o", "            )\r\n"]
[384.561146, "o", "\r\n"]
[384.616697, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[384.672247, "o", "    vals ^= vals >> 30\r\n"]
[384.727798, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[384.783348, "o", "    vals ^= vals >> 27\r\n"]
[384.838899, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[384.894449, "o", "    vals ^= vals >> 31\r\n"]
[385.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[385.002, "i", "python - << 'PY'\r"]
[385.004, "o", "python - << 'PY'\r\n"]
[385.418, "o", "\u001b[?2004l\r\n"]
[385.83, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[386.242, "o", "\u001b[?2004l\r\n"]
[386.654, "o", "\u001b[?2004h> p=Path('pandas/core/util/hashing.py')\r\n"]
[387.066, "o", "\u001b[?2004l\r\n"]
[387.478, "o", "\u001b[?2004h> s=p.read_text(encoding='utf-8')\r\n"]
[387.89, "o", "\u001b[?2004l\r\n"]
[388.302, "o", "\u001b[?2004h> print('Original length:', len(s))\r\n"]
[388.714, "o", "\u001b[?2004l\r\n"]
[389.126, "o", "\u001b[?2004h> PY\r\n"]
[389.538, "o", "\u001b[?2004l\r\n"]
[390.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[390.002, "i", "python - << 'PY'\r"]
[390.004, "o", "python - << 'PY'\r\n"]
[390.054471, "o", "\u001b[?2004l\r\n"]
[390.102941, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[390.151412, "o", "\u001b[?2004l\r\n"]
[390.199882, "o", "\u001b[?2004h> import re\r\n"]
[390.248353, "o", "\u001b[?2004l\r\n"]
[390.296824, "o", "\u001b[?2004h> p=Path('pandas/core/util/hashing.py')\r\n"]
[390.345294, "o", "\u001b[?2004l\r\n"]
[390.393765, "o", "\u001b[?2004h> s=p.read_text(encoding='utf-8')\r\n"]
[390.442235, "o", "\u001b[?2004l\r\n"]
[390.490706, "o", "\u001b[?2004h> # Insert fast-path in hash_array for object arrays of strings when categorize=False\r\n"]
[390.539176, "o", "\u001b[?2004l\r\n"]
[390.587647, "o", "\u001b[?2004h> # We'll find the start of def hash_array and patch within the object-dtype branch before calling hash_object_array\r\n"]
[390.636118, "o", "\u001b[?2004l\r\n"]
[390.684588, "o", "\u001b[?2004h> start = s.find('def hash_array(')\r\n"]
[390.733059, "o", "\u001b[?2004l\r\n"]
[390.781529, "o", "\u001b[?2004h> end = s.find('\\ndef ', start+1)\r\n"]
[390.83, "o", "\u001b[?2004l\r\n"]
[390.878471, "o", "\u001b[?2004h> block = s[start:end if end!=-1 else None]\r\n"]
[390.926941, "o", "\u001b[?2004l\r\n"]
[390.975412, "o", "\u001b[?2004h> if 'infer_dtype' not in s:\r\n"]
[391.023882, "o", "\u001b[?2004l\r\n"]
[391.072353, "o", "\u001b[?2004h>     # add import near top\r\n"]
[391.120824, "o", "\u001b[?2004l\r\n"]
[391.169294, "o", "\u001b[?2004h>     s = s.replace('\\nfrom __future__ import annotations\\n', '\\nfrom __future__ import annotations\\n')\r\n"]
[391.217765, "o", "\u001b[?2004l\r\n"]
[391.266235, "o", "\u001b[?2004h>     # find a good place after existing imports\r\n"]
[391.314706, "o", "\u001b[?2004l\r\n"]
[391.363176, "o", "\u001b[?2004h>     s = s.replace('from pandas._libs.hashing import hash_object_array', 'from pandas._libs.hashing import hash_object_array\\nfrom pandas.api.types import infer\r\n"]
[391.411647, "o", "r_dtype')\r\n"]
[391.460118, "o", "\u001b[?2004l\r\n"]
[391.508588, "o", "\u001b[?2004h> # Patch inside the function by adding a fast-path just after determining vals for object dtype\r\n"]
[391.557059, "o", "\u001b[?2004l\r\n"]
[391.605529, "o", "\u001b[?2004h> pattern = r\"(def\\s+hash_array\\(.*?\\):[\\s\\S]*?)\\n\\s*#\\s*object dtype handling marker\"\r\n"]
[391.654, "o", "\u001b[?2004l\r\n"]
[391.702471, "o", "\u001b[?2004h> # If there's no marker, we'll inject based on the line that calls hash_object_array for object dtype\r\n"]
[391.750941, "o", "\u001b[?2004l\r\n"]
[391.799412, "o", "\u001b[?2004h> if 'hash_object_array(vals, hash_key, encoding)' in block:\r\n"]
[391.847882, "o", "\u001b[?2004l\r\n"]
[391.896353, "o", "\u001b[?2004h>     patched = s.replace(\r\n"]
[391.944824, "o", "\u001b[?2004l\r\n"]
[391.993294, "o", "\u001b[?2004h>         'vals = hash_object_array(vals, hash_key, encoding)',\r\n"]
[392.041765, "o", "\u001b[?2004l\r\n"]
[392.090235, "o", "\u001b[?2004h>         (\r\n"]
[392.138706, "o", "\u001b[?2004l\r\n"]
[392.187176, "o", "\u001b[?2004h>             'from pandas.core.dtypes.common import is_object_dtype\\n'\r\n"]
[392.235647, "o", "\u001b[?2004l\r\n"]
[392.284118, "o", "\u001b[?2004h>             '        if is_object_dtype(values) and not categorize:\\n'\r\n"]
[392.332588, "o", "\u001b[?2004l\r\n"]
[392.381059, "o", "\u001b[?2004h>             '            # Fast path: factorize pure-string object arrays to hash uniques once\\n'\r\n"]
[392.429529, "o", "\u001b[?2004l\r\n"]
[392.478, "o", "\u001b[?2004h>             '            idt = infer_dtype(values, skipna=True)\\n'\r\n"]
[392.526471, "o", "\u001b[?2004l\r\n"]
[392.574941, "o", "\u001b[?2004h>             '            if idt == \"string\":\\n'\r\n"]
[392.623412, "o", "\u001b[?2004l\r\n"]
[392.671882, "o", "\u001b[?2004h>             '                import numpy as np\\n'\r\n"]
[392.720353, "o", "\u001b[?2004l\r\n"]
[392.768824, "o", "\u001b[?2004h>             '                import pandas as pd\\n'\r\n"]
[392.817294, "o", "\u001b[?2004l\r\n"]
[392.865765, "o", "\u001b[?2004h>             '                codes, uniques = pd.factorize(values, sort=False)\\n'\r\n"]
[392.914235, "o", "\u001b[?2004l\r\n"]
[392.962706, "o", "\u001b[?2004h>             '                # Hash uniques once\\n'\r\n"]
[393.011176, "o", "\u001b[?2004l\r\n"]
[393.059647, "o", "\u001b[?2004h>             '                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\\n'\r\n"]
[393.108118, "o", "\u001b[?2004l\r\n"]
[393.156588, "o", "\u001b[?2004h>             '                res = np.empty(codes.shape[0], dtype=\\'u8\\')\\n'\r\n"]
[393.205059, "o", "\u001b[?2004l\r\n"]
[393.253529, "o", "\u001b[?2004h>             '                mask = codes == -1\\n'\r\n"]
[393.302, "o", "\u001b[?2004l\r\n"]
[393.350471, "o", "\u001b[?2004h>             '                if mask.any():\\n'\r\n"]
[393.398941, "o", "\u001b[?2004l\r\n"]
[393.447412, "o", "\u001b[?2004h>             '                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\\n'\r\n"]
[393.495882, "o", "\u001b[?2004l\r\n"]
[393.544353, "o", "\u001b[?2004h>             '                    res[mask] = na_hash\\n'\r\n"]
[393.592824, "o", "\u001b[?2004l\r\n"]
[393.641294, "o", "\u001b[?2004h>             '                if (~mask).any():\\n'\r\n"]
[393.689765, "o", "\u001b[?2004l\r\n"]
[393.738235, "o", "\u001b[?2004h>             '                    res[~mask] = uhash[codes[~mask]]\\n'\r\n"]
[393.786706, "o", "\u001b[?2004l\r\n"]
[393.835176, "o", "\u001b[?2004h>             '                return res\\n'\r\n"]
[393.883647, "o", "\u001b[?2004l\r\n"]
[393.932118, "o", "\u001b[?2004h>             '        vals = hash_object_array(vals, hash_key, encoding)'\r\n"]
[393.980588, "o", "\u001b[?2004l\r\n"]
[394.029059, "o", "\u001b[?2004h>         )\r\n"]
[394.077529, "o", "\u001b[?2004l\r\n"]
[394.126, "o", "\u001b[?2004h>     )\r\n"]
[394.174471, "o", "\u001b[?2004l\r\n"]
[394.222941, "o", "\u001b[?2004h>     s = patched\r\n"]
[394.271412, "o", "\u001b[?2004l\r\n"]
[394.319882, "o", "\u001b[?2004h> else:\r\n"]
[394.368353, "o", "\u001b[?2004l\r\n"]
[394.416824, "o", "\u001b[?2004h>     print('Did not find target call site; no changes made')\r\n"]
[394.465294, "o", "\u001b[?2004l\r\n"]
[394.513765, "o", "\u001b[?2004h> \r\n"]
[394.562235, "o", "\u001b[?2004l\r\n"]
[394.610706, "o", "\u001b[?2004h> p.write_text(s, encoding='utf-8')\r\n"]
[394.659176, "o", "\u001b[?2004l\r\n"]
[394.707647, "o", "\u001b[?2004h> print('Patched hashing.py')\r\n"]
[394.756118, "o", "\u001b[?2004l\r\n"]
[394.804588, "o", "\u001b[?2004h> PY\r\n"]
[394.853059, "o", "\u001b[?2004l\r\n"]
[394.901529, "o", "Did not find target call site; no changes made\r\n"]
[395.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[395.002, "i", "git add -A && git commit -m \"perf(hash): fast-path for pure-string object arrays in hash_array by factorizing uniqu\r"]
[395.004, "o", "git add -A && git commit -m \"perf(hash): fast-path for pure-string object arrays in hash_array by factorizing uniqu\r\n"]
[395.3356, "o", "ues and remapping to reduce repeated hashing\"\r\n"]
[395.6652, "o", "\u001b[?2004l\r\n"]
[395.9948, "o", "Author identity unknown\r\n"]
[396.3244, "o", "\r\n"]
[396.654, "o", "*** Please tell me who you are.\r\n"]
[396.9836, "o", "\r\n"]
[397.3132, "o", "Run\r\n"]
[397.6428, "o", "\r\n"]
[397.9724, "o", "  git config --global user.email \"you@example.com\"\r\n"]
[398.302, "o", "  git config --global user.name \"Your Name\"\r\n"]
[398.6316, "o", "\r\n"]
[398.9612, "o", "to set your account's default identity.\r\n"]
[399.2908, "o", "Omit --global to set the identity only in this repository.\r\n"]
[399.6204, "o", "\r\n"]
[400.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[400.002, "i", "cd asv_bench\r"]
[400.004, "o", "cd asv_bench\r\n"]
[400.006, "o", "\u001b[?2004l\r\n"]
[405.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[405.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[405.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[405.099283, "o", "\u001b[?2004l\r\n"]
[405.192566, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[405.285849, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpu_stz9_f/result.json (exit status 1)\u001b[0m\r\n"]
[405.379132, "o", "   STDOUT -------->\r\n"]
[405.472415, "o", "   \r\n"]
[405.565698, "o", "   STDERR -------->\r\n"]
[405.658981, "o", "   Traceback (most recent call last):\r\n"]
[405.752264, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[405.845547, "o", "       main()\r\n"]
[405.93883, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[406.032113, "o", "       commands[mode](args)\r\n"]
[406.125396, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[406.218679, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[406.311962, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[406.405245, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[406.498528, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[406.591811, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[406.685094, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[406.778377, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[406.87166, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[406.964943, "o", "       module = importlib.import_module(module_name)\r\n"]
[407.058226, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[407.151509, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[407.244792, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[407.338075, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[407.431358, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[407.524642, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[407.617925, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[407.711208, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[407.804491, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[407.897774, "o", "       import pandas as pd\r\n"]
[407.991057, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[408.08434, "o", "       from pandas.core.api import (\r\n"]
[408.177623, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[408.270906, "o", "       from pandas.core.arrays import Categorical\r\n"]
[408.364189, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[408.457472, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[408.550755, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[408.644038, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[408.737321, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[408.830604, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[408.923887, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[409.01717, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[409.110453, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 13, in <module>\r\n"]
[409.203736, "o", "       from pandas.api.types import infer_dtype\r\n"]
[409.297019, "o", "     File \"/workspace/repo/pandas/api/__init__.py\", line 3, in <module>\r\n"]
[409.390302, "o", "       from pandas.api import (\r\n"]
[409.483585, "o", "     File \"/workspace/repo/pandas/api/extensions/__init__.py\", line 18, in <module>\r\n"]
[409.576868, "o", "       from pandas.core.arrays import (\r\n"]
[409.670151, "o", "   ImportError: cannot import name 'ExtensionArray' from partially initialized module 'pandas.core.arrays' (most likely due to a circular import) (/workspace/repo/pandas/core/arrays/__init__.py)\r\n"]
[409.763434, "o", "\r\n"]
[409.856717, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpu_stz9_f/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[410.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[410.002, "i", "sed -n '1,240p' pandas/core/util/hashing.py\r"]
[410.004, "o", "sed -n '1,240p' pandas/core/util/hashing.py\r\n"]
[412.478, "o", "\u001b[?2004l\r\n"]
[415.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[415.002, "i", "sed -n '240,640p' pandas/core/util/hashing.py\r"]
[415.004, "o", "sed -n '240,640p' pandas/core/util/hashing.py\r\n"]
[417.478, "o", "\u001b[?2004l\r\n"]
[420.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[420.002, "i", "python - << 'PY'\r"]
[420.004, "o", "python - << 'PY'\r\n"]
[420.071053, "o", "\u001b[?2004l\r\n"]
[420.136105, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[420.201158, "o", "\u001b[?2004l\r\n"]
[420.266211, "o", "\u001b[?2004h> import re\r\n"]
[420.331263, "o", "\u001b[?2004l\r\n"]
[420.396316, "o", "\u001b[?2004h> p=Path('pandas/core/util/hashing.py')\r\n"]
[420.461368, "o", "\u001b[?2004l\r\n"]
[420.526421, "o", "\u001b[?2004h> s=p.read_text(encoding='utf-8')\r\n"]
[420.591474, "o", "\u001b[?2004l\r\n"]
[420.656526, "o", "\u001b[?2004h> # Replace the heavy import to avoid circular import; remove pandas.api.types import\r\n"]
[420.721579, "o", "\u001b[?2004l\r\n"]
[420.786632, "o", "\u001b[?2004h> s=s.replace('from pandas.api.types import infer_dtype', '')\r\n"]
[420.851684, "o", "\u001b[?2004l\r\n"]
[420.916737, "o", "\u001b[?2004h> # Improve fast-path: apply to any object-dtype arrays (not just pure strings), avoid needing infer_dtype\r\n"]
[420.981789, "o", "\u001b[?2004l\r\n"]
[421.046842, "o", "\u001b[?2004h> # Also ensure we reference the correct local variable names; look for the call to hash_object_array on vals\r\n"]
[421.111895, "o", "\u001b[?2004l\r\n"]
[421.176947, "o", "\u001b[?2004h> target = 'vals = hash_object_array(vals, hash_key, encoding)'\r\n"]
[421.242, "o", "\u001b[?2004l\r\n"]
[421.307053, "o", "\u001b[?2004h> if target in s:\r\n"]
[421.372105, "o", "\u001b[?2004l\r\n"]
[421.437158, "o", "\u001b[?2004h>     replacement = (\r\n"]
[421.502211, "o", "\u001b[?2004l\r\n"]
[421.567263, "o", "\u001b[?2004h>         'from pandas.core.dtypes.common import is_object_dtype\\n'\r\n"]
[421.632316, "o", "\u001b[?2004l\r\n"]
[421.697368, "o", "\u001b[?2004h>         '        if is_object_dtype(values) and not categorize:\\n'\r\n"]
[421.762421, "o", "\u001b[?2004l\r\n"]
[421.827474, "o", "\u001b[?2004h>         '            import numpy as np\\n'\r\n"]
[421.892526, "o", "\u001b[?2004l\r\n"]
[421.957579, "o", "\u001b[?2004h>         '            import pandas as pd\\n'\r\n"]
[422.022632, "o", "\u001b[?2004l\r\n"]
[422.087684, "o", "\u001b[?2004h>         '            codes, uniques = pd.factorize(values, sort=False)\\n'\r\n"]
[422.152737, "o", "\u001b[?2004l\r\n"]
[422.217789, "o", "\u001b[?2004h>         '            uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\\n'\r\n"]
[422.282842, "o", "\u001b[?2004l\r\n"]
[422.347895, "o", "\u001b[?2004h>         '            res = np.empty(codes.shape[0], dtype=\\'u8\\')\\n'\r\n"]
[422.412947, "o", "\u001b[?2004l\r\n"]
[422.478, "o", "\u001b[?2004h>         '            mask = codes == -1\\n'\r\n"]
[422.543053, "o", "\u001b[?2004l\r\n"]
[422.608105, "o", "\u001b[?2004h>         '            if mask.any():\\n'\r\n"]
[422.673158, "o", "\u001b[?2004l\r\n"]
[422.738211, "o", "\u001b[?2004h>         '                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\\n'\r\n"]
[422.803263, "o", "\u001b[?2004l\r\n"]
[422.868316, "o", "\u001b[?2004h>         '                res[mask] = na_hash\\n'\r\n"]
[422.933368, "o", "\u001b[?2004l\r\n"]
[422.998421, "o", "\u001b[?2004h>         '            if (~mask).any():\\n'\r\n"]
[423.063474, "o", "\u001b[?2004l\r\n"]
[423.128526, "o", "\u001b[?2004h>         '                res[~mask] = uhash[codes[~mask]]\\n'\r\n"]
[423.193579, "o", "\u001b[?2004l\r\n"]
[423.258632, "o", "\u001b[?2004h>         '            return res\\n'\r\n"]
[423.323684, "o", "\u001b[?2004l\r\n"]
[423.388737, "o", "\u001b[?2004h>         '        vals = hash_object_array(vals, hash_key, encoding)'\r\n"]
[423.453789, "o", "\u001b[?2004l\r\n"]
[423.518842, "o", "\u001b[?2004h>     )\r\n"]
[423.583895, "o", "\u001b[?2004l\r\n"]
[423.648947, "o", "\u001b[?2004h>     s = s.replace(target, replacement)\r\n"]
[423.714, "o", "\u001b[?2004l\r\n"]
[423.779053, "o", "\u001b[?2004h> else:\r\n"]
[423.844105, "o", "\u001b[?2004l\r\n"]
[423.909158, "o", "\u001b[?2004h>     print('Warning: expected call site not found; no replacement made')\r\n"]
[423.974211, "o", "\u001b[?2004l\r\n"]
[424.039263, "o", "\u001b[?2004h> \r\n"]
[424.104316, "o", "\u001b[?2004l\r\n"]
[424.169368, "o", "\u001b[?2004h> p.write_text(s, encoding='utf-8')\r\n"]
[424.234421, "o", "\u001b[?2004l\r\n"]
[424.299474, "o", "\u001b[?2004h> print('hashing.py updated to avoid circular import and broaden fast-path')\r\n"]
[424.364526, "o", "\u001b[?2004l\r\n"]
[424.429579, "o", "\u001b[?2004h> PY\r\n"]
[424.494632, "o", "\u001b[?2004l\r\n"]
[424.559684, "o", "Traceback (most recent call last):\r\n"]
[424.624737, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[424.689789, "o", "  File \"/opt/conda/envs/asv_3.10/lib/python3.10/pathlib.py\", line 1134, in read_text\r\n"]
[424.754842, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[424.819895, "o", "  File \"/opt/conda/envs/asv_3.10/lib/python3.10/pathlib.py\", line 1119, in open\r\n"]
[424.884947, "o", "    return self._accessor.open(self, mode, buffering, encoding, errors,\r\n"]
[425.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[425.002, "i", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): avoid circular import and add object-dt\r"]
[425.004, "o", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): avoid circular import and add object-dt\r\n"]
[426.242, "o", "type fast-path (factorize uniques, hash once, remap)\"\r\n"]
[427.478, "o", "\u001b[?2004l\r\n"]
[428.714, "o", "warning: could not open directory 'asv_bench/pandas/core/util/': No such file or directory\r\n"]
[430.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[430.002, "i", "cd asv_bench\r"]
[430.004, "o", "cd asv_bench\r\n"]
[432.478, "o", "\u001b[?2004l\r\n"]
[435.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[435.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[435.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[435.099283, "o", "\u001b[?2004l\r\n"]
[435.192566, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[435.285849, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpwv460bga/result.json (exit status 1)\u001b[0m\r\n"]
[435.379132, "o", "   STDOUT -------->\r\n"]
[435.472415, "o", "   \r\n"]
[435.565698, "o", "   STDERR -------->\r\n"]
[435.658981, "o", "   Traceback (most recent call last):\r\n"]
[435.752264, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[435.845547, "o", "       main()\r\n"]
[435.93883, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[436.032113, "o", "       commands[mode](args)\r\n"]
[436.125396, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[436.218679, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[436.311962, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[436.405245, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[436.498528, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[436.591811, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[436.685094, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[436.778377, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[436.87166, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[436.964943, "o", "       module = importlib.import_module(module_name)\r\n"]
[437.058226, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[437.151509, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[437.244792, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[437.338075, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[437.431358, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[437.524642, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[437.617925, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[437.711208, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[437.804491, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[437.897774, "o", "       import pandas as pd\r\n"]
[437.991057, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[438.08434, "o", "       from pandas.core.api import (\r\n"]
[438.177623, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[438.270906, "o", "       from pandas.core.arrays import Categorical\r\n"]
[438.364189, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[438.457472, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[438.550755, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[438.644038, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[438.737321, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[438.830604, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[438.923887, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[439.01717, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[439.110453, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 13, in <module>\r\n"]
[439.203736, "o", "       from pandas.api.types import infer_dtype\r\n"]
[439.297019, "o", "     File \"/workspace/repo/pandas/api/__init__.py\", line 3, in <module>\r\n"]
[439.390302, "o", "       from pandas.api import (\r\n"]
[439.483585, "o", "     File \"/workspace/repo/pandas/api/extensions/__init__.py\", line 18, in <module>\r\n"]
[439.576868, "o", "       from pandas.core.arrays import (\r\n"]
[439.670151, "o", "   ImportError: cannot import name 'ExtensionArray' from partially initialized module 'pandas.core.arrays' (most likely due to a circular import) (/workspace/repo/pandas/core/arrays/__init__.py)\r\n"]
[439.763434, "o", "\r\n"]
[439.856717, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpwv460bga/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[440.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[440.002, "i", "sed -n '1,80p' /workspace/repo/pandas/core/util/hashing.py\r"]
[440.004, "o", "sed -n '1,80p' /workspace/repo/pandas/core/util/hashing.py\r\n"]
[440.067037, "o", "\u001b[?2004l\r\n"]
[440.128074, "o", "\"\"\"\r\n"]
[440.189111, "o", "data hash pandas / numpy objects\r\n"]
[440.250148, "o", "\"\"\"\r\n"]
[440.311185, "o", "\r\n"]
[440.372222, "o", "from __future__ import annotations\r\n"]
[440.433259, "o", "\r\n"]
[440.494296, "o", "import itertools\r\n"]
[440.555333, "o", "from typing import TYPE_CHECKING\r\n"]
[440.61637, "o", "\r\n"]
[440.677407, "o", "import numpy as np\r\n"]
[440.738444, "o", "\r\n"]
[440.799481, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[440.860519, "o", "from pandas.api.types import infer_dtype\r\n"]
[440.921556, "o", "\r\n"]
[440.982593, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[441.04363, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[441.104667, "o", "from pandas.core.dtypes.generic import (\r\n"]
[441.165704, "o", "    ABCDataFrame,\r\n"]
[441.226741, "o", "    ABCExtensionArray,\r\n"]
[441.287778, "o", "    ABCIndex,\r\n"]
[441.348815, "o", "    ABCMultiIndex,\r\n"]
[441.409852, "o", "    ABCSeries,\r\n"]
[441.470889, "o", ")\r\n"]
[441.531926, "o", "\r\n"]
[441.592963, "o", "if TYPE_CHECKING:\r\n"]
[441.654, "o", "    from collections.abc import (\r\n"]
[441.715037, "o", "        Hashable,\r\n"]
[441.776074, "o", "        Iterable,\r\n"]
[441.837111, "o", "        Iterator,\r\n"]
[441.898148, "o", "    )\r\n"]
[441.959185, "o", "\r\n"]
[442.020222, "o", "    from pandas._typing import (\r\n"]
[442.081259, "o", "        ArrayLike,\r\n"]
[442.142296, "o", "        npt,\r\n"]
[442.203333, "o", "    )\r\n"]
[442.26437, "o", "\r\n"]
[442.325407, "o", "    from pandas import (\r\n"]
[442.386444, "o", "        DataFrame,\r\n"]
[442.447481, "o", "        Index,\r\n"]
[442.508519, "o", "        MultiIndex,\r\n"]
[442.569556, "o", "        Series,\r\n"]
[442.630593, "o", "    )\r\n"]
[442.69163, "o", "\r\n"]
[442.752667, "o", "\r\n"]
[442.813704, "o", "# 16 byte long hashing key\r\n"]
[442.874741, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[442.935778, "o", "\r\n"]
[442.996815, "o", "\r\n"]
[443.057852, "o", "def combine_hash_arrays(\r\n"]
[443.118889, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[443.179926, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[443.240963, "o", "    \"\"\"\r\n"]
[443.302, "o", "    Parameters\r\n"]
[443.363037, "o", "    ----------\r\n"]
[443.424074, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[443.485111, "o", "    num_items : int\r\n"]
[443.546148, "o", "\r\n"]
[443.607185, "o", "    Returns\r\n"]
[443.668222, "o", "    -------\r\n"]
[443.729259, "o", "    np.ndarray[uint64]\r\n"]
[443.790296, "o", "\r\n"]
[443.851333, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[443.91237, "o", "    \"\"\"\r\n"]
[443.973407, "o", "    try:\r\n"]
[444.034444, "o", "        first = next(arrays)\r\n"]
[444.095481, "o", "    except StopIteration:\r\n"]
[444.156519, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[444.217556, "o", "\r\n"]
[444.278593, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[444.33963, "o", "\r\n"]
[444.400667, "o", "    mult = np.uint64(1000003)\r\n"]
[444.461704, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[444.522741, "o", "    last_i = 0\r\n"]
[444.583778, "o", "    for i, a in enumerate(arrays):\r\n"]
[444.644815, "o", "        inverse_i = num_items - i\r\n"]
[444.705852, "o", "        out ^= a\r\n"]
[444.766889, "o", "        out *= mult\r\n"]
[444.827926, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[444.888963, "o", "        last_i = i\r\n"]
[445.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[445.002, "i", "grep -n \"pandas.api.types import infer_dtype\" -n /workspace/repo/pandas/core/util/hashing.py || true\r"]
[445.004, "o", "grep -n \"pandas.api.types import infer_dtype\" -n /workspace/repo/pandas/core/util/hashing.py || true\r\n"]
[447.478, "o", "\u001b[?2004l\r\n"]
[450.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[450.002, "i", "applypatch << 'PATCH'\r"]
[450.004, "o", "applypatch << 'PATCH'\r\n"]
[450.280667, "o", "\u001b[?2004l\r\n"]
[450.555333, "o", "\u001b[?2004h> *** Begin Patch\r\n"]
[450.83, "o", "\u001b[?2004l\r\n"]
[451.104667, "o", "\u001b[?2004h> *** Update File: pandas/core/util/hashing.py\r\n"]
[451.379333, "o", "\u001b[?2004l\r\n"]
[451.654, "o", "\u001b[?2004h> @@\r\n"]
[451.928667, "o", "\u001b[?2004l\r\n"]
[452.203333, "o", "\u001b[?2004h> -from pandas.api.types import infer_dtype\r\n"]
[452.478, "o", "\u001b[?2004l\r\n"]
[452.752667, "o", "\u001b[?2004h> +# NOTE: Avoid importing from pandas.api at module import time to prevent circular imports during\r\n"]
[453.027333, "o", "\u001b[?2004l\r\n"]
[453.302, "o", "\u001b[?2004h> +# initialization. Any optional helpers should be imported locally within functions as needed.\r\n"]
[453.576667, "o", "\u001b[?2004l\r\n"]
[453.851333, "o", "\u001b[?2004h> *** End Patch\r\n"]
[454.126, "o", "\u001b[?2004l\r\n"]
[454.400667, "o", "\u001b[?2004h> PATCH\r\n"]
[454.675333, "o", "\u001b[?2004l\r\n"]
[455.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[455.002, "i", "git add pandas/core/util/hashing.py && git commit -m \"fix(hash): remove pandas.api import to avoid circul\r"]
[455.004, "o", "git add pandas/core/util/hashing.py && git commit -m \"fix(hash): remove pandas.api import to avoid circul\r\n"]
[456.242, "o", "lar import during initialization\"\r\n"]
[457.478, "o", "\u001b[?2004l\r\n"]
[458.714, "o", "warning: could not open directory 'asv_bench/pandas/core/util/': No such file or directory\r\n"]
[460.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[460.002, "i", "sed -n '200,380p' /workspace/repo/pandas/core/util/hashing.py\r"]
[460.004, "o", "sed -n '200,380p' /workspace/repo/pandas/core/util/hashing.py\r\n"]
[460.03896, "o", "\u001b[?2004l\r\n"]
[460.07192, "o", "    Returns\r\n"]
[460.10488, "o", "    -------\r\n"]
[460.13784, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[460.1708, "o", "    \"\"\"\r\n"]
[460.20376, "o", "    if not is_list_like(vals):\r\n"]
[460.23672, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[460.26968, "o", "\r\n"]
[460.30264, "o", "    from pandas import (\r\n"]
[460.3356, "o", "        Categorical,\r\n"]
[460.36856, "o", "        MultiIndex,\r\n"]
[460.40152, "o", "    )\r\n"]
[460.43448, "o", "\r\n"]
[460.46744, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[460.5004, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[460.53336, "o", "    else:\r\n"]
[460.56632, "o", "        mi = vals\r\n"]
[460.59928, "o", "\r\n"]
[460.63224, "o", "    # create a list-of-Categoricals\r\n"]
[460.6652, "o", "    cat_vals = [\r\n"]
[460.69816, "o", "        Categorical._simple_new(\r\n"]
[460.73112, "o", "            mi.codes[level],\r\n"]
[460.76408, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[460.79704, "o", "        )\r\n"]
[460.83, "o", "        for level in range(mi.nlevels)\r\n"]
[460.86296, "o", "    ]\r\n"]
[460.89592, "o", "\r\n"]
[460.92888, "o", "    # hash the list-of-ndarrays\r\n"]
[460.96184, "o", "    hashes = (\r\n"]
[460.9948, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[461.02776, "o", "        for cat in cat_vals\r\n"]
[461.06072, "o", "    )\r\n"]
[461.09368, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[461.12664, "o", "\r\n"]
[461.1596, "o", "    return h\r\n"]
[461.19256, "o", "\r\n"]
[461.22552, "o", "\r\n"]
[461.25848, "o", "def hash_array(\r\n"]
[461.29144, "o", "    vals: ArrayLike,\r\n"]
[461.3244, "o", "    encoding: str = \"utf8\",\r\n"]
[461.35736, "o", "    hash_key: str = _default_hash_key,\r\n"]
[461.39032, "o", "    categorize: bool = True,\r\n"]
[461.42328, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[461.45624, "o", "    \"\"\"\r\n"]
[461.4892, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[461.52216, "o", "\r\n"]
[461.55512, "o", "    Parameters\r\n"]
[461.58808, "o", "    ----------\r\n"]
[461.62104, "o", "    vals : ndarray or ExtensionArray\r\n"]
[461.654, "o", "        The input array to hash.\r\n"]
[461.68696, "o", "    encoding : str, default 'utf8'\r\n"]
[461.71992, "o", "        Encoding for data & key when strings.\r\n"]
[461.75288, "o", "    hash_key : str, default _default_hash_key\r\n"]
[461.78584, "o", "        Hash_key for string key to encode.\r\n"]
[461.8188, "o", "    categorize : bool, default True\r\n"]
[461.85176, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[461.88472, "o", "        efficient when the array contains duplicate values.\r\n"]
[461.91768, "o", "\r\n"]
[461.95064, "o", "    Returns\r\n"]
[461.9836, "o", "    -------\r\n"]
[462.01656, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[462.04952, "o", "        Hashed values, same length as the vals.\r\n"]
[462.08248, "o", "\r\n"]
[462.11544, "o", "    See Also\r\n"]
[462.1484, "o", "    --------\r\n"]
[462.18136, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[462.21432, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[462.24728, "o", "\r\n"]
[462.28024, "o", "    Examples\r\n"]
[462.3132, "o", "    --------\r\n"]
[462.34616, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[462.37912, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[462.41208, "o", "      dtype=uint64)\r\n"]
[462.44504, "o", "    \"\"\"\r\n"]
[462.478, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[462.51096, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[462.54392, "o", "\r\n"]
[462.57688, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[462.60984, "o", "        return vals._hash_pandas_object(\r\n"]
[462.6428, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[462.67576, "o", "        )\r\n"]
[462.70872, "o", "\r\n"]
[462.74168, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[462.77464, "o", "        # GH#42003\r\n"]
[462.8076, "o", "        raise TypeError(\r\n"]
[462.84056, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[462.87352, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[462.90648, "o", "        )\r\n"]
[462.93944, "o", "\r\n"]
[462.9724, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[463.00536, "o", "\r\n"]
[463.03832, "o", "\r\n"]
[463.07128, "o", "def _hash_ndarray(\r\n"]
[463.10424, "o", "    vals: np.ndarray,\r\n"]
[463.1372, "o", "    encoding: str = \"utf8\",\r\n"]
[463.17016, "o", "    hash_key: str = _default_hash_key,\r\n"]
[463.20312, "o", "    categorize: bool = True,\r\n"]
[463.23608, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[463.26904, "o", "    \"\"\"\r\n"]
[463.302, "o", "    See hash_array.__doc__.\r\n"]
[463.33496, "o", "    \"\"\"\r\n"]
[463.36792, "o", "    dtype = vals.dtype\r\n"]
[463.40088, "o", "\r\n"]
[463.43384, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[463.4668, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[463.49976, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[463.53272, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[463.56568, "o", "        return hash_real + 23 * hash_imag\r\n"]
[463.59864, "o", "\r\n"]
[463.6316, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[463.66456, "o", "    # manage it.\r\n"]
[463.69752, "o", "    if dtype == bool:\r\n"]
[463.73048, "o", "        vals = vals.astype(\"u8\")\r\n"]
[463.76344, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[463.7964, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[463.82936, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[463.86232, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[463.89528, "o", "    else:\r\n"]
[463.92824, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[463.9612, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[463.99416, "o", "        # when the values are known/likely to be unique.\r\n"]
[464.02712, "o", "        if categorize:\r\n"]
[464.06008, "o", "            from pandas import (\r\n"]
[464.09304, "o", "                Categorical,\r\n"]
[464.126, "o", "                Index,\r\n"]
[464.15896, "o", "                factorize,\r\n"]
[464.19192, "o", "            )\r\n"]
[464.22488, "o", "\r\n"]
[464.25784, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[464.2908, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[464.32376, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[464.35672, "o", "            return cat._hash_pandas_object(\r\n"]
[464.38968, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[464.42264, "o", "            )\r\n"]
[464.4556, "o", "\r\n"]
[464.48856, "o", "        try:\r\n"]
[464.52152, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[464.55448, "o", "        except TypeError:\r\n"]
[464.58744, "o", "            # we have mixed types\r\n"]
[464.6204, "o", "            vals = hash_object_array(\r\n"]
[464.65336, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[464.68632, "o", "            )\r\n"]
[464.71928, "o", "\r\n"]
[464.75224, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[464.7852, "o", "    vals ^= vals >> 30\r\n"]
[464.81816, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[464.85112, "o", "    vals ^= vals >> 27\r\n"]
[464.88408, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[464.91704, "o", "    vals ^= vals >> 31\r\n"]
[465.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[465.002, "i", "cd /workspace/repo/asv_bench\r"]
[465.004, "o", "cd /workspace/repo/asv_bench\r\n"]
[465.006, "o", "\u001b[?2004l\r\n"]
[470.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[470.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[470.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[470.099283, "o", "\u001b[?2004l\r\n"]
[470.192566, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[470.285849, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp6dqyhs48/result.json (exit status 1)\u001b[0m\r\n"]
[470.379132, "o", "   STDOUT -------->\r\n"]
[470.472415, "o", "   \r\n"]
[470.565698, "o", "   STDERR -------->\r\n"]
[470.658981, "o", "   Traceback (most recent call last):\r\n"]
[470.752264, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[470.845547, "o", "       main()\r\n"]
[470.93883, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[471.032113, "o", "       commands[mode](args)\r\n"]
[471.125396, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[471.218679, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[471.311962, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[471.405245, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[471.498528, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[471.591811, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[471.685094, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[471.778377, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[471.87166, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[471.964943, "o", "       module = importlib.import_module(module_name)\r\n"]
[472.058226, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[472.151509, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[472.244792, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[472.338075, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[472.431358, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[472.524642, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[472.617925, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[472.711208, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[472.804491, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[472.897774, "o", "       import pandas as pd\r\n"]
[472.991057, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[473.08434, "o", "       from pandas.core.api import (\r\n"]
[473.177623, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[473.270906, "o", "       from pandas.core.arrays import Categorical\r\n"]
[473.364189, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[473.457472, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[473.550755, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[473.644038, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[473.737321, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[473.830604, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[473.923887, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[474.01717, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[474.110453, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 13, in <module>\r\n"]
[474.203736, "o", "       from pandas.api.types import infer_dtype\r\n"]
[474.297019, "o", "     File \"/workspace/repo/pandas/api/__init__.py\", line 3, in <module>\r\n"]
[474.390302, "o", "       from pandas.api import (\r\n"]
[474.483585, "o", "     File \"/workspace/repo/pandas/api/extensions/__init__.py\", line 18, in <module>\r\n"]
[474.576868, "o", "       from pandas.core.arrays import (\r\n"]
[474.670151, "o", "   ImportError: cannot import name 'ExtensionArray' from partially initialized module 'pandas.core.arrays' (most likely due to a circular import) (/workspace/repo/pandas/core/arrays/__init__.py)\r\n"]
[474.763434, "o", "\r\n"]
[474.856717, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp6dqyhs48/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[475.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[475.002, "i", "cd /workspace/repo\r"]
[475.004, "o", "cd /workspace/repo\r\n"]
[475.006, "o", "\u001b[?2004l\r\n"]
[480.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[480.002, "i", "sed -n '1,80p' pandas/core/util/hashing.py\r"]
[480.004, "o", "sed -n '1,80p' pandas/core/util/hashing.py\r\n"]
[480.067037, "o", "\u001b[?2004l\r\n"]
[480.128074, "o", "\"\"\"\r\n"]
[480.189111, "o", "data hash pandas / numpy objects\r\n"]
[480.250148, "o", "\"\"\"\r\n"]
[480.311185, "o", "\r\n"]
[480.372222, "o", "from __future__ import annotations\r\n"]
[480.433259, "o", "\r\n"]
[480.494296, "o", "import itertools\r\n"]
[480.555333, "o", "from typing import TYPE_CHECKING\r\n"]
[480.61637, "o", "\r\n"]
[480.677407, "o", "import numpy as np\r\n"]
[480.738444, "o", "\r\n"]
[480.799481, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[480.860519, "o", "from pandas.api.types import infer_dtype\r\n"]
[480.921556, "o", "\r\n"]
[480.982593, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[481.04363, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[481.104667, "o", "from pandas.core.dtypes.generic import (\r\n"]
[481.165704, "o", "    ABCDataFrame,\r\n"]
[481.226741, "o", "    ABCExtensionArray,\r\n"]
[481.287778, "o", "    ABCIndex,\r\n"]
[481.348815, "o", "    ABCMultiIndex,\r\n"]
[481.409852, "o", "    ABCSeries,\r\n"]
[481.470889, "o", ")\r\n"]
[481.531926, "o", "\r\n"]
[481.592963, "o", "if TYPE_CHECKING:\r\n"]
[481.654, "o", "    from collections.abc import (\r\n"]
[481.715037, "o", "        Hashable,\r\n"]
[481.776074, "o", "        Iterable,\r\n"]
[481.837111, "o", "        Iterator,\r\n"]
[481.898148, "o", "    )\r\n"]
[481.959185, "o", "\r\n"]
[482.020222, "o", "    from pandas._typing import (\r\n"]
[482.081259, "o", "        ArrayLike,\r\n"]
[482.142296, "o", "        npt,\r\n"]
[482.203333, "o", "    )\r\n"]
[482.26437, "o", "\r\n"]
[482.325407, "o", "    from pandas import (\r\n"]
[482.386444, "o", "        DataFrame,\r\n"]
[482.447481, "o", "        Index,\r\n"]
[482.508519, "o", "        MultiIndex,\r\n"]
[482.569556, "o", "        Series,\r\n"]
[482.630593, "o", "    )\r\n"]
[482.69163, "o", "\r\n"]
[482.752667, "o", "\r\n"]
[482.813704, "o", "# 16 byte long hashing key\r\n"]
[482.874741, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[482.935778, "o", "\r\n"]
[482.996815, "o", "\r\n"]
[483.057852, "o", "def combine_hash_arrays(\r\n"]
[483.118889, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[483.179926, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[483.240963, "o", "    \"\"\"\r\n"]
[483.302, "o", "    Parameters\r\n"]
[483.363037, "o", "    ----------\r\n"]
[483.424074, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[483.485111, "o", "    num_items : int\r\n"]
[483.546148, "o", "\r\n"]
[483.607185, "o", "    Returns\r\n"]
[483.668222, "o", "    -------\r\n"]
[483.729259, "o", "    np.ndarray[uint64]\r\n"]
[483.790296, "o", "\r\n"]
[483.851333, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[483.91237, "o", "    \"\"\"\r\n"]
[483.973407, "o", "    try:\r\n"]
[484.034444, "o", "        first = next(arrays)\r\n"]
[484.095481, "o", "    except StopIteration:\r\n"]
[484.156519, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[484.217556, "o", "\r\n"]
[484.278593, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[484.33963, "o", "\r\n"]
[484.400667, "o", "    mult = np.uint64(1000003)\r\n"]
[484.461704, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[484.522741, "o", "    last_i = 0\r\n"]
[484.583778, "o", "    for i, a in enumerate(arrays):\r\n"]
[484.644815, "o", "        inverse_i = num_items - i\r\n"]
[484.705852, "o", "        out ^= a\r\n"]
[484.766889, "o", "        out *= mult\r\n"]
[484.827926, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[484.888963, "o", "        last_i = i\r\n"]
[485.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[485.002, "i", "grep -n \"pandas.api.types import infer_dtype\" pandas/core/util/hashing.py || true\r"]
[485.004, "o", "grep -n \"pandas.api.types import infer_dtype\" pandas/core/util/hashing.py || true\r\n"]
[487.478, "o", "\u001b[?2004l\r\n"]
[490.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[490.002, "i", "python - << 'PY'\r"]
[490.004, "o", "python - << 'PY'\r\n"]
[490.230727, "o", "\u001b[?2004l\r\n"]
[490.455455, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[490.680182, "o", "\u001b[?2004l\r\n"]
[490.904909, "o", "\u001b[?2004h> p = Path('pandas/core/util/hashing.py')\r\n"]
[491.129636, "o", "\u001b[?2004l\r\n"]
[491.354364, "o", "\u001b[?2004h> s = p.read_text(encoding='utf-8')\r\n"]
[491.579091, "o", "\u001b[?2004l\r\n"]
[491.803818, "o", "\u001b[?2004h> if 'from pandas.api.types import infer_dtype' in s:\r\n"]
[492.028545, "o", "\u001b[?2004l\r\n"]
[492.253273, "o", "\u001b[?2004h>     s = s.replace('from pandas.api.types import infer_dtype\\n', '')\r\n"]
[492.478, "o", "\u001b[?2004l\r\n"]
[492.702727, "o", "\u001b[?2004h>     p.write_text(s, encoding='utf-8')\r\n"]
[492.927455, "o", "\u001b[?2004l\r\n"]
[493.152182, "o", "\u001b[?2004h>     print('Removed pandas.api.types import')\r\n"]
[493.376909, "o", "\u001b[?2004l\r\n"]
[493.601636, "o", "\u001b[?2004h> else:\r\n"]
[493.826364, "o", "\u001b[?2004l\r\n"]
[494.051091, "o", "\u001b[?2004h>     print('Import not present')\r\n"]
[494.275818, "o", "\u001b[?2004l\r\n"]
[494.500545, "o", "\u001b[?2004h> PY\r\n"]
[494.725273, "o", "\u001b[?2004l\r\n"]
[495.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[495.002, "i", "grep -n \"infer_dtype\" pandas/core/util/hashing.py || true\r"]
[495.004, "o", "grep -n \"infer_dtype\" pandas/core/util/hashing.py || true\r\n"]
[495.006, "o", "\u001b[?2004l\r\n"]
[500.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[500.002, "i", "grep -n \"Fast path\" -n pandas/core/util/hashing.py || sed -n '220,380p' pandas/core/util/hashing.py\r"]
[500.004, "o", "grep -n \"Fast path\" -n pandas/core/util/hashing.py || sed -n '220,380p' pandas/core/util/hashing.py\r\n"]
[500.044326, "o", "\u001b[?2004l\r\n"]
[500.082651, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[500.120977, "o", "        )\r\n"]
[500.159302, "o", "        for level in range(mi.nlevels)\r\n"]
[500.197628, "o", "    ]\r\n"]
[500.235953, "o", "\r\n"]
[500.274279, "o", "    # hash the list-of-ndarrays\r\n"]
[500.312605, "o", "    hashes = (\r\n"]
[500.35093, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[500.389256, "o", "        for cat in cat_vals\r\n"]
[500.427581, "o", "    )\r\n"]
[500.465907, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[500.504233, "o", "\r\n"]
[500.542558, "o", "    return h\r\n"]
[500.580884, "o", "\r\n"]
[500.619209, "o", "\r\n"]
[500.657535, "o", "def hash_array(\r\n"]
[500.69586, "o", "    vals: ArrayLike,\r\n"]
[500.734186, "o", "    encoding: str = \"utf8\",\r\n"]
[500.772512, "o", "    hash_key: str = _default_hash_key,\r\n"]
[500.810837, "o", "    categorize: bool = True,\r\n"]
[500.849163, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[500.887488, "o", "    \"\"\"\r\n"]
[500.925814, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[500.96414, "o", "\r\n"]
[501.002465, "o", "    Parameters\r\n"]
[501.040791, "o", "    ----------\r\n"]
[501.079116, "o", "    vals : ndarray or ExtensionArray\r\n"]
[501.117442, "o", "        The input array to hash.\r\n"]
[501.155767, "o", "    encoding : str, default 'utf8'\r\n"]
[501.194093, "o", "        Encoding for data & key when strings.\r\n"]
[501.232419, "o", "    hash_key : str, default _default_hash_key\r\n"]
[501.270744, "o", "        Hash_key for string key to encode.\r\n"]
[501.30907, "o", "    categorize : bool, default True\r\n"]
[501.347395, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[501.385721, "o", "        efficient when the array contains duplicate values.\r\n"]
[501.424047, "o", "\r\n"]
[501.462372, "o", "    Returns\r\n"]
[501.500698, "o", "    -------\r\n"]
[501.539023, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[501.577349, "o", "        Hashed values, same length as the vals.\r\n"]
[501.615674, "o", "\r\n"]
[501.654, "o", "    See Also\r\n"]
[501.692326, "o", "    --------\r\n"]
[501.730651, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[501.768977, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[501.807302, "o", "\r\n"]
[501.845628, "o", "    Examples\r\n"]
[501.883953, "o", "    --------\r\n"]
[501.922279, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[501.960605, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[501.99893, "o", "      dtype=uint64)\r\n"]
[502.037256, "o", "    \"\"\"\r\n"]
[502.075581, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[502.113907, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[502.152233, "o", "\r\n"]
[502.190558, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[502.228884, "o", "        return vals._hash_pandas_object(\r\n"]
[502.267209, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[502.305535, "o", "        )\r\n"]
[502.34386, "o", "\r\n"]
[502.382186, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[502.420512, "o", "        # GH#42003\r\n"]
[502.458837, "o", "        raise TypeError(\r\n"]
[502.497163, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[502.535488, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[502.573814, "o", "        )\r\n"]
[502.61214, "o", "\r\n"]
[502.650465, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[502.688791, "o", "\r\n"]
[502.727116, "o", "\r\n"]
[502.765442, "o", "def _hash_ndarray(\r\n"]
[502.803767, "o", "    vals: np.ndarray,\r\n"]
[502.842093, "o", "    encoding: str = \"utf8\",\r\n"]
[502.880419, "o", "    hash_key: str = _default_hash_key,\r\n"]
[502.918744, "o", "    categorize: bool = True,\r\n"]
[502.95707, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[502.995395, "o", "    \"\"\"\r\n"]
[503.033721, "o", "    See hash_array.__doc__.\r\n"]
[503.072047, "o", "    \"\"\"\r\n"]
[503.110372, "o", "    dtype = vals.dtype\r\n"]
[503.148698, "o", "\r\n"]
[503.187023, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[503.225349, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[503.263674, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[503.302, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[503.340326, "o", "        return hash_real + 23 * hash_imag\r\n"]
[503.378651, "o", "\r\n"]
[503.416977, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[503.455302, "o", "    # manage it.\r\n"]
[503.493628, "o", "    if dtype == bool:\r\n"]
[503.531953, "o", "        vals = vals.astype(\"u8\")\r\n"]
[503.570279, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[503.608605, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[503.64693, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[503.685256, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[503.723581, "o", "    else:\r\n"]
[503.761907, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[503.800233, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[503.838558, "o", "        # when the values are known/likely to be unique.\r\n"]
[503.876884, "o", "        if categorize:\r\n"]
[503.915209, "o", "            from pandas import (\r\n"]
[503.953535, "o", "                Categorical,\r\n"]
[503.99186, "o", "                Index,\r\n"]
[504.030186, "o", "                factorize,\r\n"]
[504.068512, "o", "            )\r\n"]
[504.106837, "o", "\r\n"]
[504.145163, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[504.183488, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[504.221814, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[504.26014, "o", "            return cat._hash_pandas_object(\r\n"]
[504.298465, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[504.336791, "o", "            )\r\n"]
[504.375116, "o", "\r\n"]
[504.413442, "o", "        try:\r\n"]
[504.451767, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[504.490093, "o", "        except TypeError:\r\n"]
[504.528419, "o", "            # we have mixed types\r\n"]
[504.566744, "o", "            vals = hash_object_array(\r\n"]
[504.60507, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[504.643395, "o", "            )\r\n"]
[504.681721, "o", "\r\n"]
[504.720047, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[504.758372, "o", "    vals ^= vals >> 30\r\n"]
[504.796698, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[504.835023, "o", "    vals ^= vals >> 27\r\n"]
[504.873349, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[504.911674, "o", "    vals ^= vals >> 31\r\n"]
[505.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[505.002, "i", "git add pandas/core/util/hashing.py && git commit -m \"fix(hash): remove pandas.api import to avoid circular import;\r"]
[505.004, "o", "git add pandas/core/util/hashing.py && git commit -m \"fix(hash): remove pandas.api import to avoid circular import;\r\n"]
[505.3356, "o", "; keep fast-path imports local\"\r\n"]
[505.6652, "o", "\u001b[?2004l\r\n"]
[505.9948, "o", "Author identity unknown\r\n"]
[506.3244, "o", "\r\n"]
[506.654, "o", "*** Please tell me who you are.\r\n"]
[506.9836, "o", "\r\n"]
[507.3132, "o", "Run\r\n"]
[507.6428, "o", "\r\n"]
[507.9724, "o", "  git config --global user.email \"you@example.com\"\r\n"]
[508.302, "o", "  git config --global user.name \"Your Name\"\r\n"]
[508.6316, "o", "\r\n"]
[508.9612, "o", "to set your account's default identity.\r\n"]
[509.2908, "o", "Omit --global to set the identity only in this repository.\r\n"]
[509.6204, "o", "\r\n"]
[510.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[510.002, "i", "cd asv_bench\r"]
[510.004, "o", "cd asv_bench\r\n"]
[510.006, "o", "\u001b[?2004l\r\n"]
[515.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[515.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[515.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[515.418, "o", "\u001b[?2004l\r\n"]
[515.83, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[516.242, "o", "\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n"]
[516.654, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[517.066, "o", "[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n"]
[517.478, "o", "[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             14.4\u00b10ms\r\n"]
[517.89, "o", "[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                3.86\u00b10ms\r\n"]
[518.302, "o", "[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.15\u00b10ms\r\n"]
[518.714, "o", "[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.29\u00b10ms\r\n"]
[519.126, "o", "[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.23\u00b10ms\r\n"]
[519.538, "o", "[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.2\u00b10ms\r\n"]
[520.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[520.002, "i", "sed -n '1,260p' pandas/core/util/hashing.py\r"]
[520.004, "o", "sed -n '1,260p' pandas/core/util/hashing.py\r\n"]
[522.478, "o", "\u001b[?2004l\r\n"]
[525.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[525.002, "i", "sed -n '260,520p' pandas/core/util/hashing.py\r"]
[525.004, "o", "sed -n '260,520p' pandas/core/util/hashing.py\r\n"]
[527.478, "o", "\u001b[?2004l\r\n"]
[530.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[530.002, "i", "python - << 'PY'\r"]
[530.004, "o", "python - << 'PY'\r\n"]
[530.087049, "o", "\u001b[?2004l\r\n"]
[530.168098, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[530.249148, "o", "\u001b[?2004l\r\n"]
[530.330197, "o", "\u001b[?2004h> import re\r\n"]
[530.411246, "o", "\u001b[?2004l\r\n"]
[530.492295, "o", "\u001b[?2004h> p=Path('pandas/core/util/hashing.py')\r\n"]
[530.573344, "o", "\u001b[?2004l\r\n"]
[530.654393, "o", "\u001b[?2004h> s=p.read_text(encoding='utf-8')\r\n"]
[530.735443, "o", "\u001b[?2004l\r\n"]
[530.816492, "o", "\u001b[?2004h> # Tweak the fast path to avoid unnecessary astype(object) and minimize allocations\r\n"]
[530.897541, "o", "\u001b[?2004l\r\n"]
[530.97859, "o", "\u001b[?2004h> s = s.replace(\r\n"]
[531.059639, "o", "\u001b[?2004l\r\n"]
[531.140689, "o", "\u001b[?2004h>     'uhash = hash_object_array(uniques.astype(object), hash_key, encoding)',\r\n"]
[531.221738, "o", "\u001b[?2004l\r\n"]
[531.302787, "o", "\u001b[?2004h>     'uhash = hash_object_array(uniques, hash_key, encoding)'\r\n"]
[531.383836, "o", "\u001b[?2004l\r\n"]
[531.464885, "o", "\u001b[?2004h> )\r\n"]
[531.545934, "o", "\u001b[?2004l\r\n"]
[531.626984, "o", "\u001b[?2004h> # Prefer prealloc + direct indexing using codes for all positions to avoid boolean masks twice\r\n"]
[531.708033, "o", "\u001b[?2004l\r\n"]
[531.789082, "o", "\u001b[?2004h> s = s.replace(\r\n"]
[531.870131, "o", "\u001b[?2004l\r\n"]
[531.95118, "o", "\u001b[?2004h>     'res = np.empty(codes.shape[0], dtype=\\'u8\\')\\n            mask = codes == -1\\n            if mask.any():\\n                na_hash = hash_object_array(np.a\r\n"]
[532.03223, "o", "array([np.nan], dtype=object), hash_key, encoding)[0]\\n                res[mask] = na_hash\\n            if (~mask).any():\\n                res[~mask] = uhash[cod\r\n"]
[532.113279, "o", "des[~mask]]',\r\n"]
[532.194328, "o", "\u001b[?2004l\r\n"]
[532.275377, "o", "\u001b[?2004h>     'res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\\n            # codes == -1 maps to last element with mode=\"wrap\"; handle missing explicitly\\\r\n"]
[532.356426, "o", "\\n            mask = codes == -1\\n            if mask.any():\\n                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0\r\n"]
[532.437475, "o", "0]\\n                res = res.copy()\\n                res[mask] = na_hash'\r\n"]
[532.518525, "o", "\u001b[?2004l\r\n"]
[532.599574, "o", "\u001b[?2004h> )\r\n"]
[532.680623, "o", "\u001b[?2004l\r\n"]
[532.761672, "o", "\u001b[?2004h> # Also patch the analogous call site that casts to str before hashing (if present)\r\n"]
[532.842721, "o", "\u001b[?2004l\r\n"]
[532.92377, "o", "\u001b[?2004h> s = s.replace(\r\n"]
[533.00482, "o", "\u001b[?2004l\r\n"]
[533.085869, "o", "\u001b[?2004h>     'vals = hash_object_array(\\n                vals.astype(str).astype(object), hash_key, encoding\\n            )',\r\n"]
[533.166918, "o", "\u001b[?2004l\r\n"]
[533.247967, "o", "\u001b[?2004h>     'from pandas.core.dtypes.common import is_object_dtype\\n            if is_object_dtype(values) and not categorize:\\n                import numpy as np\\n   \r\n"]
[533.329016, "o", "              import pandas as pd\\n                codes, uniques = pd.factorize(values.astype(str), sort=False)\\n                uhash = hash_object_array(uniqu\r\n"]
[533.410066, "o", "ues.astype(object), hash_key, encoding)\\n                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\\n                mask = codes == -1\\n     \r\n"]
[533.491115, "o", "            if mask.any():\\n                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\\n                    res = r\r\n"]
[533.572164, "o", "res.copy()\\n                    res[mask] = na_hash\\n                return res\\n            vals = hash_object_array(\\n                vals.astype(str).astype(o\r\n"]
[533.653213, "o", "object), hash_key, encoding\\n            )'\r\n"]
[533.734262, "o", "\u001b[?2004l\r\n"]
[533.815311, "o", "\u001b[?2004h> )\r\n"]
[533.896361, "o", "\u001b[?2004l\r\n"]
[533.97741, "o", "\u001b[?2004h> p.write_text(s, encoding='utf-8')\r\n"]
[534.058459, "o", "\u001b[?2004l\r\n"]
[534.139508, "o", "\u001b[?2004h> print('Refined fast path in hashing.py')\r\n"]
[534.220557, "o", "\u001b[?2004l\r\n"]
[534.301607, "o", "\u001b[?2004h> PY\r\n"]
[534.382656, "o", "\u001b[?2004l\r\n"]
[534.463705, "o", "Traceback (most recent call last):\r\n"]
[534.544754, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[534.625803, "o", "  File \"/opt/conda/envs/asv_3.10/lib/python3.10/pathlib.py\", line 1134, in read_text\r\n"]
[534.706852, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[534.787902, "o", "  File \"/opt/conda/envs/asv_3.10/lib/python3.10/pathlib.py\", line 1119, in open\r\n"]
[534.868951, "o", "    return self._accessor.open(self, mode, buffering, encoding, errors,\r\n"]
[535.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[535.002, "i", "git config user.email optimization@example.com && git config user.name Optimizer\r"]
[535.004, "o", "git config user.email optimization@example.com && git config user.name Optimizer\r\n"]
[535.006, "o", "\u001b[?2004l\r\n"]
[540.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[540.002, "i", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): factorize-based fast path for object st\r"]
[540.004, "o", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): factorize-based fast path for object st\r\n"]
[541.242, "o", "trings; reduce allocations and avoid extra casts\"\r\n"]
[542.478, "o", "\u001b[?2004l\r\n"]
[543.714, "o", "warning: could not open directory 'asv_bench/pandas/core/util/': No such file or directory\r\n"]
[545.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[545.002, "i", "cd asv_bench\r"]
[545.004, "o", "cd asv_bench\r\n"]
[547.478, "o", "\u001b[?2004l\r\n"]
[550.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[550.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[550.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[550.418, "o", "\u001b[?2004l\r\n"]
[550.83, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[551.242, "o", "\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n"]
[551.654, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[552.066, "o", "[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n"]
[552.478, "o", "[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             14.7\u00b10ms\r\n"]
[552.89, "o", "[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                4.02\u00b10ms\r\n"]
[553.302, "o", "[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.23\u00b10ms\r\n"]
[553.714, "o", "[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.15\u00b10ms\r\n"]
[554.126, "o", "[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.09\u00b10ms\r\n"]
[554.538, "o", "[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.6\u00b10ms\r\n"]
[555.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[555.002, "i", "cd /workspace/repo\r"]
[555.004, "o", "cd /workspace/repo\r\n"]
[555.006, "o", "\u001b[?2004l\r\n"]
[560.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[560.002, "i", "sed -n '1,200p' pandas/core/util/hashing.py\r"]
[560.004, "o", "sed -n '1,200p' pandas/core/util/hashing.py\r\n"]
[560.030597, "o", "\u001b[?2004l\r\n"]
[560.055194, "o", "\"\"\"\r\n"]
[560.079791, "o", "data hash pandas / numpy objects\r\n"]
[560.104388, "o", "\"\"\"\r\n"]
[560.128985, "o", "\r\n"]
[560.153582, "o", "from __future__ import annotations\r\n"]
[560.178179, "o", "\r\n"]
[560.202776, "o", "import itertools\r\n"]
[560.227373, "o", "from typing import TYPE_CHECKING\r\n"]
[560.25197, "o", "\r\n"]
[560.276567, "o", "import numpy as np\r\n"]
[560.301164, "o", "\r\n"]
[560.325761, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[560.350358, "o", "\r\n"]
[560.374955, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[560.399552, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[560.424149, "o", "from pandas.core.dtypes.generic import (\r\n"]
[560.448746, "o", "    ABCDataFrame,\r\n"]
[560.473343, "o", "    ABCExtensionArray,\r\n"]
[560.49794, "o", "    ABCIndex,\r\n"]
[560.522537, "o", "    ABCMultiIndex,\r\n"]
[560.547134, "o", "    ABCSeries,\r\n"]
[560.571731, "o", ")\r\n"]
[560.596328, "o", "\r\n"]
[560.620925, "o", "if TYPE_CHECKING:\r\n"]
[560.645522, "o", "    from collections.abc import (\r\n"]
[560.670119, "o", "        Hashable,\r\n"]
[560.694716, "o", "        Iterable,\r\n"]
[560.719313, "o", "        Iterator,\r\n"]
[560.74391, "o", "    )\r\n"]
[560.768507, "o", "\r\n"]
[560.793104, "o", "    from pandas._typing import (\r\n"]
[560.817701, "o", "        ArrayLike,\r\n"]
[560.842299, "o", "        npt,\r\n"]
[560.866896, "o", "    )\r\n"]
[560.891493, "o", "\r\n"]
[560.91609, "o", "    from pandas import (\r\n"]
[560.940687, "o", "        DataFrame,\r\n"]
[560.965284, "o", "        Index,\r\n"]
[560.989881, "o", "        MultiIndex,\r\n"]
[561.014478, "o", "        Series,\r\n"]
[561.039075, "o", "    )\r\n"]
[561.063672, "o", "\r\n"]
[561.088269, "o", "\r\n"]
[561.112866, "o", "# 16 byte long hashing key\r\n"]
[561.137463, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[561.16206, "o", "\r\n"]
[561.186657, "o", "\r\n"]
[561.211254, "o", "def combine_hash_arrays(\r\n"]
[561.235851, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[561.260448, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[561.285045, "o", "    \"\"\"\r\n"]
[561.309642, "o", "    Parameters\r\n"]
[561.334239, "o", "    ----------\r\n"]
[561.358836, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[561.383433, "o", "    num_items : int\r\n"]
[561.40803, "o", "\r\n"]
[561.432627, "o", "    Returns\r\n"]
[561.457224, "o", "    -------\r\n"]
[561.481821, "o", "    np.ndarray[uint64]\r\n"]
[561.506418, "o", "\r\n"]
[561.531015, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[561.555612, "o", "    \"\"\"\r\n"]
[561.580209, "o", "    try:\r\n"]
[561.604806, "o", "        first = next(arrays)\r\n"]
[561.629403, "o", "    except StopIteration:\r\n"]
[561.654, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[561.678597, "o", "\r\n"]
[561.703194, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[561.727791, "o", "\r\n"]
[561.752388, "o", "    mult = np.uint64(1000003)\r\n"]
[561.776985, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[561.801582, "o", "    last_i = 0\r\n"]
[561.826179, "o", "    for i, a in enumerate(arrays):\r\n"]
[561.850776, "o", "        inverse_i = num_items - i\r\n"]
[561.875373, "o", "        out ^= a\r\n"]
[561.89997, "o", "        out *= mult\r\n"]
[561.924567, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[561.949164, "o", "        last_i = i\r\n"]
[561.973761, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[561.998358, "o", "    out += np.uint64(97531)\r\n"]
[562.022955, "o", "    return out\r\n"]
[562.047552, "o", "\r\n"]
[562.072149, "o", "\r\n"]
[562.096746, "o", "def hash_pandas_object(\r\n"]
[562.121343, "o", "    obj: Index | DataFrame | Series,\r\n"]
[562.14594, "o", "    index: bool = True,\r\n"]
[562.170537, "o", "    encoding: str = \"utf8\",\r\n"]
[562.195134, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[562.219731, "o", "    categorize: bool = True,\r\n"]
[562.244328, "o", ") -> Series:\r\n"]
[562.268925, "o", "    \"\"\"\r\n"]
[562.293522, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[562.318119, "o", "\r\n"]
[562.342716, "o", "    Parameters\r\n"]
[562.367313, "o", "    ----------\r\n"]
[562.39191, "o", "    obj : Index, Series, or DataFrame\r\n"]
[562.416507, "o", "    index : bool, default True\r\n"]
[562.441104, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[562.465701, "o", "    encoding : str, default 'utf8'\r\n"]
[562.490299, "o", "        Encoding for data & key when strings.\r\n"]
[562.514896, "o", "    hash_key : str, default _default_hash_key\r\n"]
[562.539493, "o", "        Hash_key for string key to encode.\r\n"]
[562.56409, "o", "    categorize : bool, default True\r\n"]
[562.588687, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[562.613284, "o", "        efficient when the array contains duplicate values.\r\n"]
[562.637881, "o", "\r\n"]
[562.662478, "o", "    Returns\r\n"]
[562.687075, "o", "    -------\r\n"]
[562.711672, "o", "    Series of uint64\r\n"]
[562.736269, "o", "        Same length as the object.\r\n"]
[562.760866, "o", "\r\n"]
[562.785463, "o", "    Examples\r\n"]
[562.81006, "o", "    --------\r\n"]
[562.834657, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[562.859254, "o", "    0    14639053686158035780\r\n"]
[562.883851, "o", "    1     3869563279212530728\r\n"]
[562.908448, "o", "    2      393322362522515241\r\n"]
[562.933045, "o", "    dtype: uint64\r\n"]
[562.957642, "o", "    \"\"\"\r\n"]
[562.982239, "o", "    from pandas import Series\r\n"]
[563.006836, "o", "\r\n"]
[563.031433, "o", "    if hash_key is None:\r\n"]
[563.05603, "o", "        hash_key = _default_hash_key\r\n"]
[563.080627, "o", "\r\n"]
[563.105224, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[563.129821, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[563.154418, "o", "\r\n"]
[563.179015, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[563.203612, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[563.228209, "o", "            \"uint64\", copy=False\r\n"]
[563.252806, "o", "        )\r\n"]
[563.277403, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[563.302, "o", "\r\n"]
[563.326597, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[563.351194, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[563.375791, "o", "            \"uint64\", copy=False\r\n"]
[563.400388, "o", "        )\r\n"]
[563.424985, "o", "        if index:\r\n"]
[563.449582, "o", "            index_iter = (\r\n"]
[563.474179, "o", "                hash_pandas_object(\r\n"]
[563.498776, "o", "                    obj.index,\r\n"]
[563.523373, "o", "                    index=False,\r\n"]
[563.54797, "o", "                    encoding=encoding,\r\n"]
[563.572567, "o", "                    hash_key=hash_key,\r\n"]
[563.597164, "o", "                    categorize=categorize,\r\n"]
[563.621761, "o", "                )._values\r\n"]
[563.646358, "o", "                for _ in [None]\r\n"]
[563.670955, "o", "            )\r\n"]
[563.695552, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[563.720149, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[563.744746, "o", "\r\n"]
[563.769343, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[563.79394, "o", "\r\n"]
[563.818537, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[563.843134, "o", "        hashes = (\r\n"]
[563.867731, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[563.892328, "o", "            for _, series in obj.items()\r\n"]
[563.916925, "o", "        )\r\n"]
[563.941522, "o", "        num_items = len(obj.columns)\r\n"]
[563.966119, "o", "        if index:\r\n"]
[563.990716, "o", "            index_hash_generator = (\r\n"]
[564.015313, "o", "                hash_pandas_object(\r\n"]
[564.03991, "o", "                    obj.index,\r\n"]
[564.064507, "o", "                    index=False,\r\n"]
[564.089104, "o", "                    encoding=encoding,\r\n"]
[564.113701, "o", "                    hash_key=hash_key,\r\n"]
[564.138299, "o", "                    categorize=categorize,\r\n"]
[564.162896, "o", "                )._values\r\n"]
[564.187493, "o", "                for _ in [None]\r\n"]
[564.21209, "o", "            )\r\n"]
[564.236687, "o", "            num_items += 1\r\n"]
[564.261284, "o", "\r\n"]
[564.285881, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[564.310478, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[564.335075, "o", "            hashes = (x for x in _hashes)\r\n"]
[564.359672, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[564.384269, "o", "\r\n"]
[564.408866, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[564.433463, "o", "    else:\r\n"]
[564.45806, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[564.482657, "o", "\r\n"]
[564.507254, "o", "    return ser\r\n"]
[564.531851, "o", "\r\n"]
[564.556448, "o", "\r\n"]
[564.581045, "o", "def hash_tuples(\r\n"]
[564.605642, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[564.630239, "o", "    encoding: str = \"utf8\",\r\n"]
[564.654836, "o", "    hash_key: str = _default_hash_key,\r\n"]
[564.679433, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[564.70403, "o", "    \"\"\"\r\n"]
[564.728627, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[564.753224, "o", "\r\n"]
[564.777821, "o", "    Parameters\r\n"]
[564.802418, "o", "    ----------\r\n"]
[564.827015, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[564.851612, "o", "    encoding : str, default 'utf8'\r\n"]
[564.876209, "o", "    hash_key : str, default _default_hash_key\r\n"]
[564.900806, "o", "\r\n"]
[564.925403, "o", "    Returns\r\n"]
[565.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[565.002, "i", "sed -n '200,500p' pandas/core/util/hashing.py\r"]
[565.004, "o", "sed -n '200,500p' pandas/core/util/hashing.py\r\n"]
[565.039181, "o", "\u001b[?2004l\r\n"]
[565.072362, "o", "    -------\r\n"]
[565.105544, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[565.138725, "o", "    \"\"\"\r\n"]
[565.171906, "o", "    if not is_list_like(vals):\r\n"]
[565.205087, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[565.238268, "o", "\r\n"]
[565.27145, "o", "    from pandas import (\r\n"]
[565.304631, "o", "        Categorical,\r\n"]
[565.337812, "o", "        MultiIndex,\r\n"]
[565.370993, "o", "    )\r\n"]
[565.404174, "o", "\r\n"]
[565.437356, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[565.470537, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[565.503718, "o", "    else:\r\n"]
[565.536899, "o", "        mi = vals\r\n"]
[565.570081, "o", "\r\n"]
[565.603262, "o", "    # create a list-of-Categoricals\r\n"]
[565.636443, "o", "    cat_vals = [\r\n"]
[565.669624, "o", "        Categorical._simple_new(\r\n"]
[565.702805, "o", "            mi.codes[level],\r\n"]
[565.735987, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[565.769168, "o", "        )\r\n"]
[565.802349, "o", "        for level in range(mi.nlevels)\r\n"]
[565.83553, "o", "    ]\r\n"]
[565.868711, "o", "\r\n"]
[565.901893, "o", "    # hash the list-of-ndarrays\r\n"]
[565.935074, "o", "    hashes = (\r\n"]
[565.968255, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[566.001436, "o", "        for cat in cat_vals\r\n"]
[566.034617, "o", "    )\r\n"]
[566.067799, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[566.10098, "o", "\r\n"]
[566.134161, "o", "    return h\r\n"]
[566.167342, "o", "\r\n"]
[566.200523, "o", "\r\n"]
[566.233705, "o", "def hash_array(\r\n"]
[566.266886, "o", "    vals: ArrayLike,\r\n"]
[566.300067, "o", "    encoding: str = \"utf8\",\r\n"]
[566.333248, "o", "    hash_key: str = _default_hash_key,\r\n"]
[566.36643, "o", "    categorize: bool = True,\r\n"]
[566.399611, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[566.432792, "o", "    \"\"\"\r\n"]
[566.465973, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[566.499154, "o", "\r\n"]
[566.532336, "o", "    Parameters\r\n"]
[566.565517, "o", "    ----------\r\n"]
[566.598698, "o", "    vals : ndarray or ExtensionArray\r\n"]
[566.631879, "o", "        The input array to hash.\r\n"]
[566.66506, "o", "    encoding : str, default 'utf8'\r\n"]
[566.698242, "o", "        Encoding for data & key when strings.\r\n"]
[566.731423, "o", "    hash_key : str, default _default_hash_key\r\n"]
[566.764604, "o", "        Hash_key for string key to encode.\r\n"]
[566.797785, "o", "    categorize : bool, default True\r\n"]
[566.830966, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[566.864148, "o", "        efficient when the array contains duplicate values.\r\n"]
[566.897329, "o", "\r\n"]
[566.93051, "o", "    Returns\r\n"]
[566.963691, "o", "    -------\r\n"]
[566.996872, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[567.030054, "o", "        Hashed values, same length as the vals.\r\n"]
[567.063235, "o", "\r\n"]
[567.096416, "o", "    See Also\r\n"]
[567.129597, "o", "    --------\r\n"]
[567.162779, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[567.19596, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[567.229141, "o", "\r\n"]
[567.262322, "o", "    Examples\r\n"]
[567.295503, "o", "    --------\r\n"]
[567.328685, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[567.361866, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[567.395047, "o", "      dtype=uint64)\r\n"]
[567.428228, "o", "    \"\"\"\r\n"]
[567.461409, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[567.494591, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[567.527772, "o", "\r\n"]
[567.560953, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[567.594134, "o", "        return vals._hash_pandas_object(\r\n"]
[567.627315, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[567.660497, "o", "        )\r\n"]
[567.693678, "o", "\r\n"]
[567.726859, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[567.76004, "o", "        # GH#42003\r\n"]
[567.793221, "o", "        raise TypeError(\r\n"]
[567.826403, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[567.859584, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[567.892765, "o", "        )\r\n"]
[567.925946, "o", "\r\n"]
[567.959128, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[567.992309, "o", "\r\n"]
[568.02549, "o", "\r\n"]
[568.058671, "o", "def _hash_ndarray(\r\n"]
[568.091852, "o", "    vals: np.ndarray,\r\n"]
[568.125034, "o", "    encoding: str = \"utf8\",\r\n"]
[568.158215, "o", "    hash_key: str = _default_hash_key,\r\n"]
[568.191396, "o", "    categorize: bool = True,\r\n"]
[568.224577, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[568.257758, "o", "    \"\"\"\r\n"]
[568.29094, "o", "    See hash_array.__doc__.\r\n"]
[568.324121, "o", "    \"\"\"\r\n"]
[568.357302, "o", "    dtype = vals.dtype\r\n"]
[568.390483, "o", "\r\n"]
[568.423664, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[568.456846, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[568.490027, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[568.523208, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[568.556389, "o", "        return hash_real + 23 * hash_imag\r\n"]
[568.58957, "o", "\r\n"]
[568.622752, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[568.655933, "o", "    # manage it.\r\n"]
[568.689114, "o", "    if dtype == bool:\r\n"]
[568.722295, "o", "        vals = vals.astype(\"u8\")\r\n"]
[568.755477, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[568.788658, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[568.821839, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[568.85502, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[568.888201, "o", "    else:\r\n"]
[568.921383, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[568.954564, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[568.987745, "o", "        # when the values are known/likely to be unique.\r\n"]
[569.020926, "o", "        if categorize:\r\n"]
[569.054107, "o", "            from pandas import (\r\n"]
[569.087289, "o", "                Categorical,\r\n"]
[569.12047, "o", "                Index,\r\n"]
[569.153651, "o", "                factorize,\r\n"]
[569.186832, "o", "            )\r\n"]
[569.220013, "o", "\r\n"]
[569.253195, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[569.286376, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[569.319557, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[569.352738, "o", "            return cat._hash_pandas_object(\r\n"]
[569.385919, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[569.419101, "o", "            )\r\n"]
[569.452282, "o", "\r\n"]
[569.485463, "o", "        try:\r\n"]
[569.518644, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[569.551826, "o", "        except TypeError:\r\n"]
[569.585007, "o", "            # we have mixed types\r\n"]
[569.618188, "o", "            vals = hash_object_array(\r\n"]
[569.651369, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[569.68455, "o", "            )\r\n"]
[569.717732, "o", "\r\n"]
[569.750913, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[569.784094, "o", "    vals ^= vals >> 30\r\n"]
[569.817275, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[569.850456, "o", "    vals ^= vals >> 27\r\n"]
[569.883638, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[569.916819, "o", "    vals ^= vals >> 31\r\n"]
[570.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[570.002, "i", "grep -n \"hash_object_array\\(|astype(str).*hash_key, encoding\" pandas/core/util/hashing.py\r"]
[570.004, "o", "grep -n \"hash_object_array\\(|astype(str).*hash_key, encoding\" pandas/core/util/hashing.py\r\n"]
[572.478, "o", "\u001b[?2004l\r\n"]
[575.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[575.002, "i", "python - << 'PY'\r"]
[575.004, "o", "python - << 'PY'\r\n"]
[575.05544, "o", "\u001b[?2004l\r\n"]
[575.10488, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[575.15432, "o", "\u001b[?2004l\r\n"]
[575.20376, "o", "\u001b[?2004h> p=Path('pandas/core/util/hashing.py')\r\n"]
[575.2532, "o", "\u001b[?2004l\r\n"]
[575.30264, "o", "\u001b[?2004h> s=p.read_text(encoding='utf-8')\r\n"]
[575.35208, "o", "\u001b[?2004l\r\n"]
[575.40152, "o", "\u001b[?2004h> # Ensure no pandas.api import remains\r\n"]
[575.45096, "o", "\u001b[?2004l\r\n"]
[575.5004, "o", "\u001b[?2004h> s=s.replace('from pandas.api.types import infer_dtype\\n','')\r\n"]
[575.54984, "o", "\u001b[?2004l\r\n"]
[575.59928, "o", "\u001b[?2004h> # Insert/replace fast path at the direct object hashing call site\r\n"]
[575.64872, "o", "\u001b[?2004l\r\n"]
[575.69816, "o", "\u001b[?2004h> target='vals = hash_object_array(vals, hash_key, encoding)'\r\n"]
[575.7476, "o", "\u001b[?2004l\r\n"]
[575.79704, "o", "\u001b[?2004h> if target in s:\r\n"]
[575.84648, "o", "\u001b[?2004l\r\n"]
[575.89592, "o", "\u001b[?2004h>     s=s.replace(target,\r\n"]
[575.94536, "o", "\u001b[?2004l\r\n"]
[575.9948, "o", "\u001b[?2004h>         'from pandas.core.dtypes.common import is_object_dtype\\n'\r\n"]
[576.04424, "o", "\u001b[?2004l\r\n"]
[576.09368, "o", "\u001b[?2004h>         '        if is_object_dtype(values) and not categorize:\\n'\r\n"]
[576.14312, "o", "\u001b[?2004l\r\n"]
[576.19256, "o", "\u001b[?2004h>         '            import numpy as np\\n'\r\n"]
[576.242, "o", "\u001b[?2004l\r\n"]
[576.29144, "o", "\u001b[?2004h>         '            import pandas as pd\\n'\r\n"]
[576.34088, "o", "\u001b[?2004l\r\n"]
[576.39032, "o", "\u001b[?2004h>         '            codes, uniques = pd.factorize(values, sort=False)\\n'\r\n"]
[576.43976, "o", "\u001b[?2004l\r\n"]
[576.4892, "o", "\u001b[?2004h>         '            uhash = hash_object_array(uniques, hash_key, encoding)\\n'\r\n"]
[576.53864, "o", "\u001b[?2004l\r\n"]
[576.58808, "o", "\u001b[?2004h>         '            # map codes -> uhash, handling -1 (NA) separately\\n'\r\n"]
[576.63752, "o", "\u001b[?2004l\r\n"]
[576.68696, "o", "\u001b[?2004h>         '            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\\n'\r\n"]
[576.7364, "o", "\u001b[?2004l\r\n"]
[576.78584, "o", "\u001b[?2004h>         '            mask = codes == -1\\n'\r\n"]
[576.83528, "o", "\u001b[?2004l\r\n"]
[576.88472, "o", "\u001b[?2004h>         '            if mask.any():\\n'\r\n"]
[576.93416, "o", "\u001b[?2004l\r\n"]
[576.9836, "o", "\u001b[?2004h>         '                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\\n'\r\n"]
[577.03304, "o", "\u001b[?2004l\r\n"]
[577.08248, "o", "\u001b[?2004h>         '                res = res.copy()\\n'\r\n"]
[577.13192, "o", "\u001b[?2004l\r\n"]
[577.18136, "o", "\u001b[?2004h>         '                res[mask] = na_hash\\n'\r\n"]
[577.2308, "o", "\u001b[?2004l\r\n"]
[577.28024, "o", "\u001b[?2004h>         '            return res\\n'\r\n"]
[577.32968, "o", "\u001b[?2004l\r\n"]
[577.37912, "o", "\u001b[?2004h>         '        vals = hash_object_array(vals, hash_key, encoding)'\r\n"]
[577.42856, "o", "\u001b[?2004l\r\n"]
[577.478, "o", "\u001b[?2004h>     )\r\n"]
[577.52744, "o", "\u001b[?2004l\r\n"]
[577.57688, "o", "\u001b[?2004h> # Also add fast path at the string-coercion branch, if present\r\n"]
[577.62632, "o", "\u001b[?2004l\r\n"]
[577.67576, "o", "\u001b[?2004h> str_branch='vals = hash_object_array(\\n                vals.astype(str).astype(object), hash_key, encoding\\n            )'\r\n"]
[577.7252, "o", "\u001b[?2004l\r\n"]
[577.77464, "o", "\u001b[?2004h> if str_branch in s:\r\n"]
[577.82408, "o", "\u001b[?2004l\r\n"]
[577.87352, "o", "\u001b[?2004h>     s=s.replace(str_branch,\r\n"]
[577.92296, "o", "\u001b[?2004l\r\n"]
[577.9724, "o", "\u001b[?2004h>         'from pandas.core.dtypes.common import is_object_dtype\\n'\r\n"]
[578.02184, "o", "\u001b[?2004l\r\n"]
[578.07128, "o", "\u001b[?2004h>         '            if is_object_dtype(values) and not categorize:\\n'\r\n"]
[578.12072, "o", "\u001b[?2004l\r\n"]
[578.17016, "o", "\u001b[?2004h>         '                import numpy as np\\n'\r\n"]
[578.2196, "o", "\u001b[?2004l\r\n"]
[578.26904, "o", "\u001b[?2004h>         '                import pandas as pd\\n'\r\n"]
[578.31848, "o", "\u001b[?2004l\r\n"]
[578.36792, "o", "\u001b[?2004h>         '                codes, uniques = pd.factorize(values.astype(str), sort=False)\\n'\r\n"]
[578.41736, "o", "\u001b[?2004l\r\n"]
[578.4668, "o", "\u001b[?2004h>         '                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\\n'\r\n"]
[578.51624, "o", "\u001b[?2004l\r\n"]
[578.56568, "o", "\u001b[?2004h>         '                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\\n'\r\n"]
[578.61512, "o", "\u001b[?2004l\r\n"]
[578.66456, "o", "\u001b[?2004h>         '                mask = codes == -1\\n'\r\n"]
[578.714, "o", "\u001b[?2004l\r\n"]
[578.76344, "o", "\u001b[?2004h>         '                if mask.any():\\n'\r\n"]
[578.81288, "o", "\u001b[?2004l\r\n"]
[578.86232, "o", "\u001b[?2004h>         '                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\\n'\r\n"]
[578.91176, "o", "\u001b[?2004l\r\n"]
[578.9612, "o", "\u001b[?2004h>         '                    res = res.copy()\\n'\r\n"]
[579.01064, "o", "\u001b[?2004l\r\n"]
[579.06008, "o", "\u001b[?2004h>         '                    res[mask] = na_hash\\n'\r\n"]
[579.10952, "o", "\u001b[?2004l\r\n"]
[579.15896, "o", "\u001b[?2004h>         '                return res\\n'\r\n"]
[579.2084, "o", "\u001b[?2004l\r\n"]
[579.25784, "o", "\u001b[?2004h>         '            vals = hash_object_array(\\n'\r\n"]
[579.30728, "o", "\u001b[?2004l\r\n"]
[579.35672, "o", "\u001b[?2004h>         '                vals.astype(str).astype(object), hash_key, encoding\\n'\r\n"]
[579.40616, "o", "\u001b[?2004l\r\n"]
[579.4556, "o", "\u001b[?2004h>         '            )'\r\n"]
[579.50504, "o", "\u001b[?2004l\r\n"]
[579.55448, "o", "\u001b[?2004h>     )\r\n"]
[579.60392, "o", "\u001b[?2004l\r\n"]
[579.65336, "o", "\u001b[?2004h> p.write_text(s, encoding='utf-8')\r\n"]
[579.7028, "o", "\u001b[?2004l\r\n"]
[579.75224, "o", "\u001b[?2004h> print('Applied refined fast path in hashing.py')\r\n"]
[579.80168, "o", "\u001b[?2004l\r\n"]
[579.85112, "o", "\u001b[?2004h> PY\r\n"]
[579.90056, "o", "\u001b[?2004l\r\n"]
[580.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[580.002, "i", "git config user.email optimization@example.com && git config user.name Optimizer\r"]
[580.004, "o", "git config user.email optimization@example.com && git config user.name Optimizer\r\n"]
[580.006, "o", "\u001b[?2004l\r\n"]
[585.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[585.002, "i", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): factorize-based fast path for object arrays; hash\r"]
[585.004, "o", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): factorize-based fast path for object arrays; hash\r\n"]
[585.9948, "o", "h uniques once and remap; avoid circular imports\"\r\n"]
[586.9836, "o", "\u001b[?2004l\r\n"]
[587.9724, "o", "[opt/hash-string-memo fdf3bc04f6] perf(hash): factorize-based fast path for object arrays; hash uniques once and remap; avoid circular imports\r\n"]
[588.9612, "o", " 2 files changed, 30 insertions(+), 1 deletion(-)\r\n"]
[590.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[590.002, "i", "cd asv_bench\r"]
[590.004, "o", "cd asv_bench\r\n"]
[590.006, "o", "\u001b[?2004l\r\n"]
[595.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[595.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[595.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[595.10488, "o", "\u001b[?2004l\r\n"]
[595.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[595.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpotytesfr/result.json (exit status 1)\u001b[0m\r\n"]
[595.40152, "o", "   STDOUT -------->\r\n"]
[595.5004, "o", "   \r\n"]
[595.59928, "o", "   STDERR -------->\r\n"]
[595.69816, "o", "   Traceback (most recent call last):\r\n"]
[595.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[595.89592, "o", "       main()\r\n"]
[595.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[596.09368, "o", "       commands[mode](args)\r\n"]
[596.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[596.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[596.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[596.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[596.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[596.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[596.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[596.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[596.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[597.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[597.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[597.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[597.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[597.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[597.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[597.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[597.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[597.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[597.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[598.07128, "o", "       import pandas as pd\r\n"]
[598.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[598.26904, "o", "       from pandas.core.api import (\r\n"]
[598.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[598.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[598.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[598.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[598.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[598.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[598.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[599.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[599.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[599.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[599.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 335\r\n"]
[599.4556, "o", "       if is_object_dtype(values) and not categorize:\r\n"]
[599.55448, "o", "       ^^\r\n"]
[599.65336, "o", "   SyntaxError: expected 'except' or 'finally' block\r\n"]
[599.75224, "o", "\r\n"]
[599.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpotytesfr/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[600.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[600.002, "i", "cd /workspace/repo\r"]
[600.004, "o", "cd /workspace/repo\r\n"]
[600.006, "o", "\u001b[?2004l\r\n"]
[605.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[605.002, "i", "nl -ba pandas/core/util/hashing.py | sed -n '280,400p'\r"]
[605.004, "o", "nl -ba pandas/core/util/hashing.py | sed -n '280,400p'\r\n"]
[605.0575, "o", "\u001b[?2004l\r\n"]
[605.109, "o", "   280\t    if not isinstance(vals, np.ndarray):\r\n"]
[605.1605, "o", "   281\t        # GH#42003\r\n"]
[605.212, "o", "   282\t        raise TypeError(\r\n"]
[605.2635, "o", "   283\t            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[605.315, "o", "   284\t            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[605.3665, "o", "   285\t        )\r\n"]
[605.418, "o", "   286\t\r\n"]
[605.4695, "o", "   287\t    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[605.521, "o", "   288\t\r\n"]
[605.5725, "o", "   289\t\r\n"]
[605.624, "o", "   290\tdef _hash_ndarray(\r\n"]
[605.6755, "o", "   291\t    vals: np.ndarray,\r\n"]
[605.727, "o", "   292\t    encoding: str = \"utf8\",\r\n"]
[605.7785, "o", "   293\t    hash_key: str = _default_hash_key,\r\n"]
[605.83, "o", "   294\t    categorize: bool = True,\r\n"]
[605.8815, "o", "   295\t) -> npt.NDArray[np.uint64]:\r\n"]
[605.933, "o", "   296\t    \"\"\"\r\n"]
[605.9845, "o", "   297\t    See hash_array.__doc__.\r\n"]
[606.036, "o", "   298\t    \"\"\"\r\n"]
[606.0875, "o", "   299\t    dtype = vals.dtype\r\n"]
[606.139, "o", "   300\t\r\n"]
[606.1905, "o", "   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[606.242, "o", "   302\t    if np.issubdtype(dtype, np.complex128):\r\n"]
[606.2935, "o", "   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[606.345, "o", "   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[606.3965, "o", "   305\t        return hash_real + 23 * hash_imag\r\n"]
[606.448, "o", "   306\t\r\n"]
[606.4995, "o", "   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[606.551, "o", "   308\t    # manage it.\r\n"]
[606.6025, "o", "   309\t    if dtype == bool:\r\n"]
[606.654, "o", "   310\t        vals = vals.astype(\"u8\")\r\n"]
[606.7055, "o", "   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[606.757, "o", "   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[606.8085, "o", "   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[606.86, "o", "   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[606.9115, "o", "   315\t    else:\r\n"]
[606.963, "o", "   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[607.0145, "o", "   317\t        # then hash and rename categories. We allow skipping the categorization\r\n"]
[607.066, "o", "   318\t        # when the values are known/likely to be unique.\r\n"]
[607.1175, "o", "   319\t        if categorize:\r\n"]
[607.169, "o", "   320\t            from pandas import (\r\n"]
[607.2205, "o", "   321\t                Categorical,\r\n"]
[607.272, "o", "   322\t                Index,\r\n"]
[607.3235, "o", "   323\t                factorize,\r\n"]
[607.375, "o", "   324\t            )\r\n"]
[607.4265, "o", "   325\t\r\n"]
[607.478, "o", "   326\t            codes, categories = factorize(vals, sort=False)\r\n"]
[607.5295, "o", "   327\t            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[607.581, "o", "   328\t            cat = Categorical._simple_new(codes, dtype)\r\n"]
[607.6325, "o", "   329\t            return cat._hash_pandas_object(\r\n"]
[607.684, "o", "   330\t                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[607.7355, "o", "   331\t            )\r\n"]
[607.787, "o", "   332\t\r\n"]
[607.8385, "o", "   333\t        try:\r\n"]
[607.89, "o", "   334\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[607.9415, "o", "   335\t        if is_object_dtype(values) and not categorize:\r\n"]
[607.993, "o", "   336\t            import numpy as np\r\n"]
[608.0445, "o", "   337\t            import pandas as pd\r\n"]
[608.096, "o", "   338\t            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[608.1475, "o", "   339\t            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[608.199, "o", "   340\t            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[608.2505, "o", "   341\t            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[608.302, "o", "   342\t            mask = codes == -1\r\n"]
[608.3535, "o", "   343\t            if mask.any():\r\n"]
[608.405, "o", "   344\t                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[608.4565, "o", "   345\t                res = res.copy()\r\n"]
[608.508, "o", "   346\t                res[mask] = na_hash\r\n"]
[608.5595, "o", "   347\t            return res\r\n"]
[608.611, "o", "   348\t        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[608.6625, "o", "   349\t        except TypeError:\r\n"]
[608.714, "o", "   350\t            # we have mixed types\r\n"]
[608.7655, "o", "   351\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[608.817, "o", "   352\t            if is_object_dtype(values) and not categorize:\r\n"]
[608.8685, "o", "   353\t                import numpy as np\r\n"]
[608.92, "o", "   354\t                import pandas as pd\r\n"]
[608.9715, "o", "   355\t                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[609.023, "o", "   356\t                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[609.0745, "o", "   357\t                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[609.126, "o", "   358\t                mask = codes == -1\r\n"]
[609.1775, "o", "   359\t                if mask.any():\r\n"]
[609.229, "o", "   360\t                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[609.2805, "o", "   361\t                    res = res.copy()\r\n"]
[609.332, "o", "   362\t                    res[mask] = na_hash\r\n"]
[609.3835, "o", "   363\t                return res\r\n"]
[609.435, "o", "   364\t            vals = hash_object_array(\r\n"]
[609.4865, "o", "   365\t                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[609.538, "o", "   366\t            )\r\n"]
[609.5895, "o", "   367\t\r\n"]
[609.641, "o", "   368\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[609.6925, "o", "   369\t    vals ^= vals >> 30\r\n"]
[609.744, "o", "   370\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[609.7955, "o", "   371\t    vals ^= vals >> 27\r\n"]
[609.847, "o", "   372\t    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[609.8985, "o", "   373\t    vals ^= vals >> 31\r\n"]
[610.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[610.002, "i", "sed -n '200,380p' pandas/core/util/hashing.py\r"]
[610.004, "o", "sed -n '200,380p' pandas/core/util/hashing.py\r\n"]
[610.034091, "o", "\u001b[?2004l\r\n"]
[610.062182, "o", "    -------\r\n"]
[610.090273, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[610.118364, "o", "    \"\"\"\r\n"]
[610.146455, "o", "    if not is_list_like(vals):\r\n"]
[610.174545, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[610.202636, "o", "\r\n"]
[610.230727, "o", "    from pandas import (\r\n"]
[610.258818, "o", "        Categorical,\r\n"]
[610.286909, "o", "        MultiIndex,\r\n"]
[610.315, "o", "    )\r\n"]
[610.343091, "o", "\r\n"]
[610.371182, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[610.399273, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[610.427364, "o", "    else:\r\n"]
[610.455455, "o", "        mi = vals\r\n"]
[610.483545, "o", "\r\n"]
[610.511636, "o", "    # create a list-of-Categoricals\r\n"]
[610.539727, "o", "    cat_vals = [\r\n"]
[610.567818, "o", "        Categorical._simple_new(\r\n"]
[610.595909, "o", "            mi.codes[level],\r\n"]
[610.624, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[610.652091, "o", "        )\r\n"]
[610.680182, "o", "        for level in range(mi.nlevels)\r\n"]
[610.708273, "o", "    ]\r\n"]
[610.736364, "o", "\r\n"]
[610.764455, "o", "    # hash the list-of-ndarrays\r\n"]
[610.792545, "o", "    hashes = (\r\n"]
[610.820636, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[610.848727, "o", "        for cat in cat_vals\r\n"]
[610.876818, "o", "    )\r\n"]
[610.904909, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[610.933, "o", "\r\n"]
[610.961091, "o", "    return h\r\n"]
[610.989182, "o", "\r\n"]
[611.017273, "o", "\r\n"]
[611.045364, "o", "def hash_array(\r\n"]
[611.073455, "o", "    vals: ArrayLike,\r\n"]
[611.101545, "o", "    encoding: str = \"utf8\",\r\n"]
[611.129636, "o", "    hash_key: str = _default_hash_key,\r\n"]
[611.157727, "o", "    categorize: bool = True,\r\n"]
[611.185818, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[611.213909, "o", "    \"\"\"\r\n"]
[611.242, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[611.270091, "o", "\r\n"]
[611.298182, "o", "    Parameters\r\n"]
[611.326273, "o", "    ----------\r\n"]
[611.354364, "o", "    vals : ndarray or ExtensionArray\r\n"]
[611.382455, "o", "        The input array to hash.\r\n"]
[611.410545, "o", "    encoding : str, default 'utf8'\r\n"]
[611.438636, "o", "        Encoding for data & key when strings.\r\n"]
[611.466727, "o", "    hash_key : str, default _default_hash_key\r\n"]
[611.494818, "o", "        Hash_key for string key to encode.\r\n"]
[611.522909, "o", "    categorize : bool, default True\r\n"]
[611.551, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[611.579091, "o", "        efficient when the array contains duplicate values.\r\n"]
[611.607182, "o", "\r\n"]
[611.635273, "o", "    Returns\r\n"]
[611.663364, "o", "    -------\r\n"]
[611.691455, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[611.719545, "o", "        Hashed values, same length as the vals.\r\n"]
[611.747636, "o", "\r\n"]
[611.775727, "o", "    See Also\r\n"]
[611.803818, "o", "    --------\r\n"]
[611.831909, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[611.86, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[611.888091, "o", "\r\n"]
[611.916182, "o", "    Examples\r\n"]
[611.944273, "o", "    --------\r\n"]
[611.972364, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[612.000455, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[612.028545, "o", "      dtype=uint64)\r\n"]
[612.056636, "o", "    \"\"\"\r\n"]
[612.084727, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[612.112818, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[612.140909, "o", "\r\n"]
[612.169, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[612.197091, "o", "        return vals._hash_pandas_object(\r\n"]
[612.225182, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[612.253273, "o", "        )\r\n"]
[612.281364, "o", "\r\n"]
[612.309455, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[612.337545, "o", "        # GH#42003\r\n"]
[612.365636, "o", "        raise TypeError(\r\n"]
[612.393727, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[612.421818, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[612.449909, "o", "        )\r\n"]
[612.478, "o", "\r\n"]
[612.506091, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[612.534182, "o", "\r\n"]
[612.562273, "o", "\r\n"]
[612.590364, "o", "def _hash_ndarray(\r\n"]
[612.618455, "o", "    vals: np.ndarray,\r\n"]
[612.646545, "o", "    encoding: str = \"utf8\",\r\n"]
[612.674636, "o", "    hash_key: str = _default_hash_key,\r\n"]
[612.702727, "o", "    categorize: bool = True,\r\n"]
[612.730818, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[612.758909, "o", "    \"\"\"\r\n"]
[612.787, "o", "    See hash_array.__doc__.\r\n"]
[612.815091, "o", "    \"\"\"\r\n"]
[612.843182, "o", "    dtype = vals.dtype\r\n"]
[612.871273, "o", "\r\n"]
[612.899364, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[612.927455, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[612.955545, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[612.983636, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[613.011727, "o", "        return hash_real + 23 * hash_imag\r\n"]
[613.039818, "o", "\r\n"]
[613.067909, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[613.096, "o", "    # manage it.\r\n"]
[613.124091, "o", "    if dtype == bool:\r\n"]
[613.152182, "o", "        vals = vals.astype(\"u8\")\r\n"]
[613.180273, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[613.208364, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[613.236455, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[613.264545, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[613.292636, "o", "    else:\r\n"]
[613.320727, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[613.348818, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[613.376909, "o", "        # when the values are known/likely to be unique.\r\n"]
[613.405, "o", "        if categorize:\r\n"]
[613.433091, "o", "            from pandas import (\r\n"]
[613.461182, "o", "                Categorical,\r\n"]
[613.489273, "o", "                Index,\r\n"]
[613.517364, "o", "                factorize,\r\n"]
[613.545455, "o", "            )\r\n"]
[613.573545, "o", "\r\n"]
[613.601636, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[613.629727, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[613.657818, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[613.685909, "o", "            return cat._hash_pandas_object(\r\n"]
[613.714, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[613.742091, "o", "            )\r\n"]
[613.770182, "o", "\r\n"]
[613.798273, "o", "        try:\r\n"]
[613.826364, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[613.854455, "o", "        if is_object_dtype(values) and not categorize:\r\n"]
[613.882545, "o", "            import numpy as np\r\n"]
[613.910636, "o", "            import pandas as pd\r\n"]
[613.938727, "o", "            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[613.966818, "o", "            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[613.994909, "o", "            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[614.023, "o", "            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[614.051091, "o", "            mask = codes == -1\r\n"]
[614.079182, "o", "            if mask.any():\r\n"]
[614.107273, "o", "                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[614.135364, "o", "                res = res.copy()\r\n"]
[614.163455, "o", "                res[mask] = na_hash\r\n"]
[614.191545, "o", "            return res\r\n"]
[614.219636, "o", "        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[614.247727, "o", "        except TypeError:\r\n"]
[614.275818, "o", "            # we have mixed types\r\n"]
[614.303909, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[614.332, "o", "            if is_object_dtype(values) and not categorize:\r\n"]
[614.360091, "o", "                import numpy as np\r\n"]
[614.388182, "o", "                import pandas as pd\r\n"]
[614.416273, "o", "                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[614.444364, "o", "                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[614.472455, "o", "                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[614.500545, "o", "                mask = codes == -1\r\n"]
[614.528636, "o", "                if mask.any():\r\n"]
[614.556727, "o", "                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[614.584818, "o", "                    res = res.copy()\r\n"]
[614.612909, "o", "                    res[mask] = na_hash\r\n"]
[614.641, "o", "                return res\r\n"]
[614.669091, "o", "            vals = hash_object_array(\r\n"]
[614.697182, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[614.725273, "o", "            )\r\n"]
[614.753364, "o", "\r\n"]
[614.781455, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[614.809545, "o", "    vals ^= vals >> 30\r\n"]
[614.837636, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[614.865727, "o", "    vals ^= vals >> 27\r\n"]
[614.893818, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[614.921909, "o", "    vals ^= vals >> 31\r\n"]
[615.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[615.002, "i", "python - << 'PY'\r"]
[615.004, "o", "python - << 'PY'\r\n"]
[615.071053, "o", "\u001b[?2004l\r\n"]
[615.136105, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[615.201158, "o", "\u001b[?2004l\r\n"]
[615.266211, "o", "\u001b[?2004h> import re\r\n"]
[615.331263, "o", "\u001b[?2004l\r\n"]
[615.396316, "o", "\u001b[?2004h> p=Path('pandas/core/util/hashing.py')\r\n"]
[615.461368, "o", "\u001b[?2004l\r\n"]
[615.526421, "o", "\u001b[?2004h> s=p.read_text(encoding='utf-8')\r\n"]
[615.591474, "o", "\u001b[?2004l\r\n"]
[615.656526, "o", "\u001b[?2004h> # Locate hash_array function block\r\n"]
[615.721579, "o", "\u001b[?2004l\r\n"]
[615.786632, "o", "\u001b[?2004h> m=re.search(r\"def\\s+hash_array\\(.*?\\):\", s)\r\n"]
[615.851684, "o", "\u001b[?2004l\r\n"]
[615.916737, "o", "\u001b[?2004h> if not m:\r\n"]
[615.981789, "o", "\u001b[?2004l\r\n"]
[616.046842, "o", "\u001b[?2004h>     raise SystemExit('hash_array not found')\r\n"]
[616.111895, "o", "\u001b[?2004l\r\n"]
[616.176947, "o", "\u001b[?2004h> start=m.start()\r\n"]
[616.242, "o", "\u001b[?2004l\r\n"]
[616.307053, "o", "\u001b[?2004h> # Find end of function by next def or EOF\r\n"]
[616.372105, "o", "\u001b[?2004l\r\n"]
[616.437158, "o", "\u001b[?2004h> m2=re.search(r\"\\ndef\\s+\\w+\\(\", s[start+1:])\r\n"]
[616.502211, "o", "\u001b[?2004l\r\n"]
[616.567263, "o", "\u001b[?2004h> end=(start+1+m2.start()) if m2 else len(s)\r\n"]
[616.632316, "o", "\u001b[?2004l\r\n"]
[616.697368, "o", "\u001b[?2004h> func=s[start:end]\r\n"]
[616.762421, "o", "\u001b[?2004l\r\n"]
[616.827474, "o", "\u001b[?2004h> # We'll rebuild object-dtype branch safely.\r\n"]
[616.892526, "o", "\u001b[?2004l\r\n"]
[616.957579, "o", "\u001b[?2004h> # First, revert our previous risky injections by standardizing two known replacements to the simple original calls\r\n"]
[617.022632, "o", "\u001b[?2004l\r\n"]
[617.087684, "o", "\u001b[?2004h> func=func.replace(\"from pandas.core.dtypes.common import is_object_dtype\", \"from pandas.core.dtypes.common import is_object_dtype\")\r\n"]
[617.152737, "o", "\u001b[?2004l\r\n"]
[617.217789, "o", "\u001b[?2004h> func=func.replace(\"return res\\n        vals = hash_object_array(vals, hash_key, encoding)\", \"return res\\n        # Fallback to original path below\\n        val\r\n"]
[617.282842, "o", "ls = hash_object_array(vals, hash_key, encoding)\")\r\n"]
[617.347895, "o", "\u001b[?2004l\r\n"]
[617.412947, "o", "\u001b[?2004h> # Ensure no stray 'if is_object_dtype(values)...' outside a proper block by removing previous misplaced snippet lines if they caused syntax errors\r\n"]
[617.478, "o", "\u001b[?2004l\r\n"]
[617.543053, "o", "\u001b[?2004h> func=re.sub(r\"\\n\\s*if is_object_dtype\\(values\\).*?return res\\n\", \"\\n\", func, flags=re.S)\r\n"]
[617.608105, "o", "\u001b[?2004l\r\n"]
[617.673158, "o", "\u001b[?2004h> # Now insert our fast path just after we set `vals = values` at start of function, but before object-branch try/except.\r\n"]
[617.738211, "o", "\u001b[?2004l\r\n"]
[617.803263, "o", "\u001b[?2004h> # We'll inject after the line that sets `vals = _ensure_data(values)` or similar; search for object-dtype handling section\r\n"]
[617.868316, "o", "\u001b[?2004l\r\n"]
[617.933368, "o", "\u001b[?2004h> insert_point=re.search(r\"#\\s*object dtype handling|if\\s+is_object_dtype\\(values\\)|vals\\s*=\\s*values\", func)\r\n"]
[617.998421, "o", "\u001b[?2004l\r\n"]
[618.063474, "o", "\u001b[?2004h> if not insert_point:\r\n"]
[618.128526, "o", "\u001b[?2004l\r\n"]
[618.193579, "o", "\u001b[?2004h>     insert_point=re.search(r\"vals\\s*=\\s*values\", func)\r\n"]
[618.258632, "o", "\u001b[?2004l\r\n"]
[618.323684, "o", "\u001b[?2004h> ins_at=insert_point.end() if insert_point else 0\r\n"]
[618.388737, "o", "\u001b[?2004l\r\n"]
[618.453789, "o", "\u001b[?2004h> fastpath='\\n        # Fast path: for object-dtype arrays, factorize to hash uniques once and remap\\n        try:\\n            from pandas.core.dtypes.common im\r\n"]
[618.518842, "o", "mport is_object_dtype\\n            import numpy as np\\n            import pandas as pd\\n            if is_object_dtype(values) and not categorize:\\n             \r\n"]
[618.583895, "o", "    codes, uniques = pd.factorize(values, sort=False)\\n                uhash = hash_object_array(uniques, hash_key, encoding)\\n                res = uhash.take(c\r\n"]
[618.648947, "o", "codes, mode=\"wrap\").astype(\"u8\", copy=False)\\n                mask = codes == -1\\n                if mask.any():\\n                    na_hash = hash_object_array\r\n"]
[618.714, "o", "y(np.array([np.nan], dtype=object), hash_key, encoding)[0]\\n                    res = res.copy()\\n                    res[mask] = na_hash\\n                return\r\n"]
[618.779053, "o", "n res\\n        except Exception:\\n            # If anything goes wrong, fall back to the original path below\\n            pass\\n'\r\n"]
[618.844105, "o", "\u001b[?2004l\r\n"]
[618.909158, "o", "\u001b[?2004h> # Insert fastpath only once if not present\r\n"]
[618.974211, "o", "\u001b[?2004l\r\n"]
[619.039263, "o", "\u001b[?2004h> if 'Fast path: for object-dtype arrays' not in func:\r\n"]
[619.104316, "o", "\u001b[?2004l\r\n"]
[619.169368, "o", "\u001b[?2004h>     func=func[:ins_at]+fastpath+func[ins_at:]\r\n"]
[619.234421, "o", "\u001b[?2004l\r\n"]
[619.299474, "o", "\u001b[?2004h> # Reassemble file\r\n"]
[619.364526, "o", "\u001b[?2004l\r\n"]
[619.429579, "o", "\u001b[?2004h> new=s[:start]+func+s[end:]\r\n"]
[619.494632, "o", "\u001b[?2004l\r\n"]
[619.559684, "o", "\u001b[?2004h> Path('pandas/core/util/hashing.py').write_text(new, encoding='utf-8')\r\n"]
[619.624737, "o", "\u001b[?2004l\r\n"]
[619.689789, "o", "\u001b[?2004h> print('Rewrote hash_array with safe fast path insertion')\r\n"]
[619.754842, "o", "\u001b[?2004l\r\n"]
[619.819895, "o", "\u001b[?2004h> PY\r\n"]
[619.884947, "o", "\u001b[?2004l\r\n"]
[620.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[620.002, "i", "python -m pyflakes pandas/core/util/hashing.py 2>/dev/null || true\r"]
[620.004, "o", "python -m pyflakes pandas/core/util/hashing.py 2>/dev/null || true\r\n"]
[620.006, "o", "\u001b[?2004l\r\n"]
[625.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[625.002, "i", "git config user.email optimization@example.com && git config user.name Optimizer\r"]
[625.004, "o", "git config user.email optimization@example.com && git config user.name Optimizer\r\n"]
[625.006, "o", "\u001b[?2004l\r\n"]
[630.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[630.002, "i", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): add safe factorize-based fast path for object arr\r"]
[630.004, "o", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): add safe factorize-based fast path for object arr\r\n"]
[631.242, "o", "rays in hash_array; fix prior syntax issues\"\r\n"]
[632.478, "o", "\u001b[?2004l\r\n"]
[633.714, "o", "On branch opt/hash-string-memo\r\n"]
[635.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[635.002, "i", "cd asv_bench\r"]
[635.004, "o", "cd asv_bench\r\n"]
[635.006, "o", "\u001b[?2004l\r\n"]
[640.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[640.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[640.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[640.10488, "o", "\u001b[?2004l\r\n"]
[640.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[640.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpyhng_3m3/result.json (exit status 1)\u001b[0m\r\n"]
[640.40152, "o", "   STDOUT -------->\r\n"]
[640.5004, "o", "   \r\n"]
[640.59928, "o", "   STDERR -------->\r\n"]
[640.69816, "o", "   Traceback (most recent call last):\r\n"]
[640.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[640.89592, "o", "       main()\r\n"]
[640.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[641.09368, "o", "       commands[mode](args)\r\n"]
[641.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[641.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[641.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[641.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[641.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[641.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[641.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[641.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[641.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[642.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[642.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[642.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[642.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[642.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[642.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[642.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[642.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[642.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[642.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[643.07128, "o", "       import pandas as pd\r\n"]
[643.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[643.26904, "o", "       from pandas.core.api import (\r\n"]
[643.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[643.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[643.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[643.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[643.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[643.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[643.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[644.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[644.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[644.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[644.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 335\r\n"]
[644.4556, "o", "       if is_object_dtype(values) and not categorize:\r\n"]
[644.55448, "o", "       ^^\r\n"]
[644.65336, "o", "   SyntaxError: expected 'except' or 'finally' block\r\n"]
[644.75224, "o", "\r\n"]
[644.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpyhng_3m3/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[645.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[645.002, "i", "cd /workspace/repo\r"]
[645.004, "o", "cd /workspace/repo\r\n"]
[645.006, "o", "\u001b[?2004l\r\n"]
[650.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[650.002, "i", "nl -ba pandas/core/util/hashing.py | sed -n '280,380p'\r"]
[650.004, "o", "nl -ba pandas/core/util/hashing.py | sed -n '280,380p'\r\n"]
[650.0575, "o", "\u001b[?2004l\r\n"]
[650.109, "o", "   280\t    if not isinstance(vals, np.ndarray):\r\n"]
[650.1605, "o", "   281\t        # GH#42003\r\n"]
[650.212, "o", "   282\t        raise TypeError(\r\n"]
[650.2635, "o", "   283\t            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[650.315, "o", "   284\t            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[650.3665, "o", "   285\t        )\r\n"]
[650.418, "o", "   286\t\r\n"]
[650.4695, "o", "   287\t    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[650.521, "o", "   288\t\r\n"]
[650.5725, "o", "   289\t\r\n"]
[650.624, "o", "   290\tdef _hash_ndarray(\r\n"]
[650.6755, "o", "   291\t    vals: np.ndarray,\r\n"]
[650.727, "o", "   292\t    encoding: str = \"utf8\",\r\n"]
[650.7785, "o", "   293\t    hash_key: str = _default_hash_key,\r\n"]
[650.83, "o", "   294\t    categorize: bool = True,\r\n"]
[650.8815, "o", "   295\t) -> npt.NDArray[np.uint64]:\r\n"]
[650.933, "o", "   296\t    \"\"\"\r\n"]
[650.9845, "o", "   297\t    See hash_array.__doc__.\r\n"]
[651.036, "o", "   298\t    \"\"\"\r\n"]
[651.0875, "o", "   299\t    dtype = vals.dtype\r\n"]
[651.139, "o", "   300\t\r\n"]
[651.1905, "o", "   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[651.242, "o", "   302\t    if np.issubdtype(dtype, np.complex128):\r\n"]
[651.2935, "o", "   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[651.345, "o", "   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[651.3965, "o", "   305\t        return hash_real + 23 * hash_imag\r\n"]
[651.448, "o", "   306\t\r\n"]
[651.4995, "o", "   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[651.551, "o", "   308\t    # manage it.\r\n"]
[651.6025, "o", "   309\t    if dtype == bool:\r\n"]
[651.654, "o", "   310\t        vals = vals.astype(\"u8\")\r\n"]
[651.7055, "o", "   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[651.757, "o", "   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[651.8085, "o", "   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[651.86, "o", "   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[651.9115, "o", "   315\t    else:\r\n"]
[651.963, "o", "   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[652.0145, "o", "   317\t        # then hash and rename categories. We allow skipping the categorization\r\n"]
[652.066, "o", "   318\t        # when the values are known/likely to be unique.\r\n"]
[652.1175, "o", "   319\t        if categorize:\r\n"]
[652.169, "o", "   320\t            from pandas import (\r\n"]
[652.2205, "o", "   321\t                Categorical,\r\n"]
[652.272, "o", "   322\t                Index,\r\n"]
[652.3235, "o", "   323\t                factorize,\r\n"]
[652.375, "o", "   324\t            )\r\n"]
[652.4265, "o", "   325\t\r\n"]
[652.478, "o", "   326\t            codes, categories = factorize(vals, sort=False)\r\n"]
[652.5295, "o", "   327\t            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[652.581, "o", "   328\t            cat = Categorical._simple_new(codes, dtype)\r\n"]
[652.6325, "o", "   329\t            return cat._hash_pandas_object(\r\n"]
[652.684, "o", "   330\t                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[652.7355, "o", "   331\t            )\r\n"]
[652.787, "o", "   332\t\r\n"]
[652.8385, "o", "   333\t        try:\r\n"]
[652.89, "o", "   334\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[652.9415, "o", "   335\t        if is_object_dtype(values) and not categorize:\r\n"]
[652.993, "o", "   336\t            import numpy as np\r\n"]
[653.0445, "o", "   337\t            import pandas as pd\r\n"]
[653.096, "o", "   338\t            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[653.1475, "o", "   339\t            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[653.199, "o", "   340\t            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[653.2505, "o", "   341\t            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[653.302, "o", "   342\t            mask = codes == -1\r\n"]
[653.3535, "o", "   343\t            if mask.any():\r\n"]
[653.405, "o", "   344\t                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[653.4565, "o", "   345\t                res = res.copy()\r\n"]
[653.508, "o", "   346\t                res[mask] = na_hash\r\n"]
[653.5595, "o", "   347\t            return res\r\n"]
[653.611, "o", "   348\t        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[653.6625, "o", "   349\t        except TypeError:\r\n"]
[653.714, "o", "   350\t            # we have mixed types\r\n"]
[653.7655, "o", "   351\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[653.817, "o", "   352\t            if is_object_dtype(values) and not categorize:\r\n"]
[653.8685, "o", "   353\t                import numpy as np\r\n"]
[653.92, "o", "   354\t                import pandas as pd\r\n"]
[653.9715, "o", "   355\t                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[654.023, "o", "   356\t                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[654.0745, "o", "   357\t                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[654.126, "o", "   358\t                mask = codes == -1\r\n"]
[654.1775, "o", "   359\t                if mask.any():\r\n"]
[654.229, "o", "   360\t                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[654.2805, "o", "   361\t                    res = res.copy()\r\n"]
[654.332, "o", "   362\t                    res[mask] = na_hash\r\n"]
[654.3835, "o", "   363\t                return res\r\n"]
[654.435, "o", "   364\t            vals = hash_object_array(\r\n"]
[654.4865, "o", "   365\t                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[654.538, "o", "   366\t            )\r\n"]
[654.5895, "o", "   367\t\r\n"]
[654.641, "o", "   368\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[654.6925, "o", "   369\t    vals ^= vals >> 30\r\n"]
[654.744, "o", "   370\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[654.7955, "o", "   371\t    vals ^= vals >> 27\r\n"]
[654.847, "o", "   372\t    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[654.8985, "o", "   373\t    vals ^= vals >> 31\r\n"]
[655.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[655.002, "i", "sed -n '200,360p' pandas/core/util/hashing.py\r"]
[655.004, "o", "sed -n '200,360p' pandas/core/util/hashing.py\r\n"]
[655.036519, "o", "\u001b[?2004l\r\n"]
[655.067037, "o", "    -------\r\n"]
[655.097556, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[655.128074, "o", "    \"\"\"\r\n"]
[655.158593, "o", "    if not is_list_like(vals):\r\n"]
[655.189111, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[655.21963, "o", "\r\n"]
[655.250148, "o", "    from pandas import (\r\n"]
[655.280667, "o", "        Categorical,\r\n"]
[655.311185, "o", "        MultiIndex,\r\n"]
[655.341704, "o", "    )\r\n"]
[655.372222, "o", "\r\n"]
[655.402741, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[655.433259, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[655.463778, "o", "    else:\r\n"]
[655.494296, "o", "        mi = vals\r\n"]
[655.524815, "o", "\r\n"]
[655.555333, "o", "    # create a list-of-Categoricals\r\n"]
[655.585852, "o", "    cat_vals = [\r\n"]
[655.61637, "o", "        Categorical._simple_new(\r\n"]
[655.646889, "o", "            mi.codes[level],\r\n"]
[655.677407, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[655.707926, "o", "        )\r\n"]
[655.738444, "o", "        for level in range(mi.nlevels)\r\n"]
[655.768963, "o", "    ]\r\n"]
[655.799481, "o", "\r\n"]
[655.83, "o", "    # hash the list-of-ndarrays\r\n"]
[655.860519, "o", "    hashes = (\r\n"]
[655.891037, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[655.921556, "o", "        for cat in cat_vals\r\n"]
[655.952074, "o", "    )\r\n"]
[655.982593, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[656.013111, "o", "\r\n"]
[656.04363, "o", "    return h\r\n"]
[656.074148, "o", "\r\n"]
[656.104667, "o", "\r\n"]
[656.135185, "o", "def hash_array(\r\n"]
[656.165704, "o", "    vals: ArrayLike,\r\n"]
[656.196222, "o", "    encoding: str = \"utf8\",\r\n"]
[656.226741, "o", "    hash_key: str = _default_hash_key,\r\n"]
[656.257259, "o", "    categorize: bool = True,\r\n"]
[656.287778, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[656.318296, "o", "    \"\"\"\r\n"]
[656.348815, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[656.379333, "o", "\r\n"]
[656.409852, "o", "    Parameters\r\n"]
[656.44037, "o", "    ----------\r\n"]
[656.470889, "o", "    vals : ndarray or ExtensionArray\r\n"]
[656.501407, "o", "        The input array to hash.\r\n"]
[656.531926, "o", "    encoding : str, default 'utf8'\r\n"]
[656.562444, "o", "        Encoding for data & key when strings.\r\n"]
[656.592963, "o", "    hash_key : str, default _default_hash_key\r\n"]
[656.623481, "o", "        Hash_key for string key to encode.\r\n"]
[656.654, "o", "    categorize : bool, default True\r\n"]
[656.684519, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[656.715037, "o", "        efficient when the array contains duplicate values.\r\n"]
[656.745556, "o", "\r\n"]
[656.776074, "o", "    Returns\r\n"]
[656.806593, "o", "    -------\r\n"]
[656.837111, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[656.86763, "o", "        Hashed values, same length as the vals.\r\n"]
[656.898148, "o", "\r\n"]
[656.928667, "o", "    See Also\r\n"]
[656.959185, "o", "    --------\r\n"]
[656.989704, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[657.020222, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[657.050741, "o", "\r\n"]
[657.081259, "o", "    Examples\r\n"]
[657.111778, "o", "    --------\r\n"]
[657.142296, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[657.172815, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[657.203333, "o", "      dtype=uint64)\r\n"]
[657.233852, "o", "    \"\"\"\r\n"]
[657.26437, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[657.294889, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[657.325407, "o", "\r\n"]
[657.355926, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[657.386444, "o", "        return vals._hash_pandas_object(\r\n"]
[657.416963, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[657.447481, "o", "        )\r\n"]
[657.478, "o", "\r\n"]
[657.508519, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[657.539037, "o", "        # GH#42003\r\n"]
[657.569556, "o", "        raise TypeError(\r\n"]
[657.600074, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[657.630593, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[657.661111, "o", "        )\r\n"]
[657.69163, "o", "\r\n"]
[657.722148, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[657.752667, "o", "\r\n"]
[657.783185, "o", "\r\n"]
[657.813704, "o", "def _hash_ndarray(\r\n"]
[657.844222, "o", "    vals: np.ndarray,\r\n"]
[657.874741, "o", "    encoding: str = \"utf8\",\r\n"]
[657.905259, "o", "    hash_key: str = _default_hash_key,\r\n"]
[657.935778, "o", "    categorize: bool = True,\r\n"]
[657.966296, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[657.996815, "o", "    \"\"\"\r\n"]
[658.027333, "o", "    See hash_array.__doc__.\r\n"]
[658.057852, "o", "    \"\"\"\r\n"]
[658.08837, "o", "    dtype = vals.dtype\r\n"]
[658.118889, "o", "\r\n"]
[658.149407, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[658.179926, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[658.210444, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[658.240963, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[658.271481, "o", "        return hash_real + 23 * hash_imag\r\n"]
[658.302, "o", "\r\n"]
[658.332519, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[658.363037, "o", "    # manage it.\r\n"]
[658.393556, "o", "    if dtype == bool:\r\n"]
[658.424074, "o", "        vals = vals.astype(\"u8\")\r\n"]
[658.454593, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[658.485111, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[658.51563, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[658.546148, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[658.576667, "o", "    else:\r\n"]
[658.607185, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[658.637704, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[658.668222, "o", "        # when the values are known/likely to be unique.\r\n"]
[658.698741, "o", "        if categorize:\r\n"]
[658.729259, "o", "            from pandas import (\r\n"]
[658.759778, "o", "                Categorical,\r\n"]
[658.790296, "o", "                Index,\r\n"]
[658.820815, "o", "                factorize,\r\n"]
[658.851333, "o", "            )\r\n"]
[658.881852, "o", "\r\n"]
[658.91237, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[658.942889, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[658.973407, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[659.003926, "o", "            return cat._hash_pandas_object(\r\n"]
[659.034444, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[659.064963, "o", "            )\r\n"]
[659.095481, "o", "\r\n"]
[659.126, "o", "        try:\r\n"]
[659.156519, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[659.187037, "o", "        if is_object_dtype(values) and not categorize:\r\n"]
[659.217556, "o", "            import numpy as np\r\n"]
[659.248074, "o", "            import pandas as pd\r\n"]
[659.278593, "o", "            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[659.309111, "o", "            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[659.33963, "o", "            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[659.370148, "o", "            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[659.400667, "o", "            mask = codes == -1\r\n"]
[659.431185, "o", "            if mask.any():\r\n"]
[659.461704, "o", "                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[659.492222, "o", "                res = res.copy()\r\n"]
[659.522741, "o", "                res[mask] = na_hash\r\n"]
[659.553259, "o", "            return res\r\n"]
[659.583778, "o", "        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[659.614296, "o", "        except TypeError:\r\n"]
[659.644815, "o", "            # we have mixed types\r\n"]
[659.675333, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[659.705852, "o", "            if is_object_dtype(values) and not categorize:\r\n"]
[659.73637, "o", "                import numpy as np\r\n"]
[659.766889, "o", "                import pandas as pd\r\n"]
[659.797407, "o", "                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[659.827926, "o", "                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[659.858444, "o", "                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[659.888963, "o", "                mask = codes == -1\r\n"]
[659.919481, "o", "                if mask.any():\r\n"]
[660.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[660.002, "i", "python - << 'PY'\r"]
[660.004, "o", "python - << 'PY'\r\n"]
[660.094286, "o", "\u001b[?2004l\r\n"]
[660.182571, "o", "\u001b[?2004h> from pathlib import Path, re\r\n"]
[660.270857, "o", "\u001b[?2004l\r\n"]
[660.359143, "o", "\u001b[?2004h> p=Path('pandas/core/util/hashing.py')\r\n"]
[660.447429, "o", "\u001b[?2004l\r\n"]
[660.535714, "o", "\u001b[?2004h> s=p.read_text(encoding='utf-8')\r\n"]
[660.624, "o", "\u001b[?2004l\r\n"]
[660.712286, "o", "\u001b[?2004h> # Locate hash_array function\r\n"]
[660.800571, "o", "\u001b[?2004l\r\n"]
[660.888857, "o", "\u001b[?2004h> m=re.search(r\"^def\\s+hash_array\\(.*?\\):\", s, flags=re.M)\r\n"]
[660.977143, "o", "\u001b[?2004l\r\n"]
[661.065429, "o", "\u001b[?2004h> if not m:\r\n"]
[661.153714, "o", "\u001b[?2004l\r\n"]
[661.242, "o", "\u001b[?2004h>     raise SystemExit('hash_array not found')\r\n"]
[661.330286, "o", "\u001b[?2004l\r\n"]
[661.418571, "o", "\u001b[?2004h> start=m.start()\r\n"]
[661.506857, "o", "\u001b[?2004l\r\n"]
[661.595143, "o", "\u001b[?2004h> # Find insertion point: after the first docstring or first assignment line inside function\r\n"]
[661.683429, "o", "\u001b[?2004l\r\n"]
[661.771714, "o", "\u001b[?2004h> body_start=s.find('\\n', m.end())+1\r\n"]
[661.86, "o", "\u001b[?2004l\r\n"]
[661.948286, "o", "\u001b[?2004h> # If there's a docstring, skip past it\r\n"]
[662.036571, "o", "\u001b[?2004l\r\n"]
[662.124857, "o", "\u001b[?2004h> if s[body_start:body_start+3] in ('\"\"\"', \"'''\"):\r\n"]
[662.213143, "o", "\u001b[?2004l\r\n"]
[662.301429, "o", "\u001b[?2004h>     q=s[body_start]\r\n"]
[662.389714, "o", "\u001b[?2004l\r\n"]
[662.478, "o", "\u001b[?2004h>     doc_end=s.find(q*3, body_start+3)\r\n"]
[662.566286, "o", "\u001b[?2004l\r\n"]
[662.654571, "o", "\u001b[?2004h>     body_start=doc_end+3\r\n"]
[662.742857, "o", "\u001b[?2004l\r\n"]
[662.831143, "o", "\u001b[?2004h> # Build fast path block with correct indentation (4 spaces)\r\n"]
[662.919429, "o", "\u001b[?2004l\r\n"]
[663.007714, "o", "\u001b[?2004h> fastpath='\\n    try:\\n        from pandas.core.dtypes.common import is_object_dtype\\n        import numpy as np\\n        import pandas as pd\\n        if is_obj\r\n"]
[663.096, "o", "ject_dtype(values) and not categorize:\\n            codes, uniques = pd.factorize(values, sort=False)\\n            uhash = hash_object_array(uniques, hash_key, e\r\n"]
[663.184286, "o", "encoding)\\n            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\\n            mask = codes == -1\\n            if mask.any():\\n               \r\n"]
[663.272571, "o", "  na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\\n                res = res.copy()\\n                res[mask] = na_hash\\n  \r\n"]
[663.360857, "o", "           return res\\n    except Exception:\\n        # Fall back to the original code paths below on any error\\n        pass\\n'\r\n"]
[663.449143, "o", "\u001b[?2004l\r\n"]
[663.537429, "o", "\u001b[?2004h> # Avoid duplicate insertion\r\n"]
[663.625714, "o", "\u001b[?2004l\r\n"]
[663.714, "o", "\u001b[?2004h> if 'Fast path: for object-dtype arrays' in s or 'codes, uniques = pd.factorize(values, sort=False)' in s[body_start:body_start+300]:\r\n"]
[663.802286, "o", "\u001b[?2004l\r\n"]
[663.890571, "o", "\u001b[?2004h>     print('Fast path seems already present; not reinserting')\r\n"]
[663.978857, "o", "\u001b[?2004l\r\n"]
[664.067143, "o", "\u001b[?2004h> else:\r\n"]
[664.155429, "o", "\u001b[?2004l\r\n"]
[664.243714, "o", "\u001b[?2004h>     s=s[:body_start]+fastpath+s[body_start:]\r\n"]
[664.332, "o", "\u001b[?2004l\r\n"]
[664.420286, "o", "\u001b[?2004h>     p.write_text(s, encoding='utf-8')\r\n"]
[664.508571, "o", "\u001b[?2004l\r\n"]
[664.596857, "o", "\u001b[?2004h>     print('Inserted safe fast path into hash_array')\r\n"]
[664.685143, "o", "\u001b[?2004l\r\n"]
[664.773429, "o", "\u001b[?2004h> PY\r\n"]
[664.861714, "o", "\u001b[?2004l\r\n"]
[665.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[665.002, "i", "python -m pyflakes pandas/core/util/hashing.py 2>/dev/null || true\r"]
[665.004, "o", "python -m pyflakes pandas/core/util/hashing.py 2>/dev/null || true\r\n"]
[665.006, "o", "\u001b[?2004l\r\n"]
[670.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[670.002, "i", "git config user.email optimization@example.com && git config user.name Optimizer\r"]
[670.004, "o", "git config user.email optimization@example.com && git config user.name Optimizer\r\n"]
[670.006, "o", "\u001b[?2004l\r\n"]
[675.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[675.002, "i", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): insert safe early fast path in hash_array (factor\r"]
[675.004, "o", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): insert safe early fast path in hash_array (factor\r\n"]
[676.242, "o", "rize object arrays to hash uniques once); fix prior syntax issues\"\r\n"]
[677.478, "o", "\u001b[?2004l\r\n"]
[678.714, "o", "On branch opt/hash-string-memo\r\n"]
[680.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[680.002, "i", "cd asv_bench\r"]
[680.004, "o", "cd asv_bench\r\n"]
[680.006, "o", "\u001b[?2004l\r\n"]
[685.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[685.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[685.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[685.10488, "o", "\u001b[?2004l\r\n"]
[685.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[685.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpcekf76ce/result.json (exit status 1)\u001b[0m\r\n"]
[685.40152, "o", "   STDOUT -------->\r\n"]
[685.5004, "o", "   \r\n"]
[685.59928, "o", "   STDERR -------->\r\n"]
[685.69816, "o", "   Traceback (most recent call last):\r\n"]
[685.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[685.89592, "o", "       main()\r\n"]
[685.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[686.09368, "o", "       commands[mode](args)\r\n"]
[686.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[686.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[686.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[686.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[686.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[686.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[686.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[686.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[686.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[687.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[687.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[687.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[687.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[687.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[687.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[687.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[687.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[687.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[687.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[688.07128, "o", "       import pandas as pd\r\n"]
[688.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[688.26904, "o", "       from pandas.core.api import (\r\n"]
[688.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[688.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[688.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[688.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[688.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[688.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[688.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[689.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[689.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[689.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[689.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 335\r\n"]
[689.4556, "o", "       if is_object_dtype(values) and not categorize:\r\n"]
[689.55448, "o", "       ^^\r\n"]
[689.65336, "o", "   SyntaxError: expected 'except' or 'finally' block\r\n"]
[689.75224, "o", "\r\n"]
[689.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpcekf76ce/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[690.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[690.002, "i", "cd /workspace/repo\r"]
[690.004, "o", "cd /workspace/repo\r\n"]
[690.006, "o", "\u001b[?2004l\r\n"]
[695.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[695.002, "i", "nl -ba pandas/core/util/hashing.py | sed -n '300,360p'\r"]
[695.004, "o", "nl -ba pandas/core/util/hashing.py | sed -n '300,360p'\r\n"]
[695.085742, "o", "\u001b[?2004l\r\n"]
[695.165484, "o", "   300\t\r\n"]
[695.245226, "o", "   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[695.324968, "o", "   302\t    if np.issubdtype(dtype, np.complex128):\r\n"]
[695.40471, "o", "   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[695.484452, "o", "   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[695.564194, "o", "   305\t        return hash_real + 23 * hash_imag\r\n"]
[695.643935, "o", "   306\t\r\n"]
[695.723677, "o", "   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[695.803419, "o", "   308\t    # manage it.\r\n"]
[695.883161, "o", "   309\t    if dtype == bool:\r\n"]
[695.962903, "o", "   310\t        vals = vals.astype(\"u8\")\r\n"]
[696.042645, "o", "   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[696.122387, "o", "   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[696.202129, "o", "   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[696.281871, "o", "   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[696.361613, "o", "   315\t    else:\r\n"]
[696.441355, "o", "   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[696.521097, "o", "   317\t        # then hash and rename categories. We allow skipping the categorization\r\n"]
[696.600839, "o", "   318\t        # when the values are known/likely to be unique.\r\n"]
[696.680581, "o", "   319\t        if categorize:\r\n"]
[696.760323, "o", "   320\t            from pandas import (\r\n"]
[696.840065, "o", "   321\t                Categorical,\r\n"]
[696.919806, "o", "   322\t                Index,\r\n"]
[696.999548, "o", "   323\t                factorize,\r\n"]
[697.07929, "o", "   324\t            )\r\n"]
[697.159032, "o", "   325\t\r\n"]
[697.238774, "o", "   326\t            codes, categories = factorize(vals, sort=False)\r\n"]
[697.318516, "o", "   327\t            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[697.398258, "o", "   328\t            cat = Categorical._simple_new(codes, dtype)\r\n"]
[697.478, "o", "   329\t            return cat._hash_pandas_object(\r\n"]
[697.557742, "o", "   330\t                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[697.637484, "o", "   331\t            )\r\n"]
[697.717226, "o", "   332\t\r\n"]
[697.796968, "o", "   333\t        try:\r\n"]
[697.87671, "o", "   334\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[697.956452, "o", "   335\t        if is_object_dtype(values) and not categorize:\r\n"]
[698.036194, "o", "   336\t            import numpy as np\r\n"]
[698.115935, "o", "   337\t            import pandas as pd\r\n"]
[698.195677, "o", "   338\t            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[698.275419, "o", "   339\t            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[698.355161, "o", "   340\t            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[698.434903, "o", "   341\t            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[698.514645, "o", "   342\t            mask = codes == -1\r\n"]
[698.594387, "o", "   343\t            if mask.any():\r\n"]
[698.674129, "o", "   344\t                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[698.753871, "o", "   345\t                res = res.copy()\r\n"]
[698.833613, "o", "   346\t                res[mask] = na_hash\r\n"]
[698.913355, "o", "   347\t            return res\r\n"]
[698.993097, "o", "   348\t        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[699.072839, "o", "   349\t        except TypeError:\r\n"]
[699.152581, "o", "   350\t            # we have mixed types\r\n"]
[699.232323, "o", "   351\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[699.312065, "o", "   352\t            if is_object_dtype(values) and not categorize:\r\n"]
[699.391806, "o", "   353\t                import numpy as np\r\n"]
[699.471548, "o", "   354\t                import pandas as pd\r\n"]
[699.55129, "o", "   355\t                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[699.631032, "o", "   356\t                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[699.710774, "o", "   357\t                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[699.790516, "o", "   358\t                mask = codes == -1\r\n"]
[699.870258, "o", "   359\t                if mask.any():\r\n"]
[700.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[700.002, "i", "git restore --source=HEAD -- pandas/core/util/hashing.py\r"]
[700.004, "o", "git restore --source=HEAD -- pandas/core/util/hashing.py\r\n"]
[700.006, "o", "\u001b[?2004l\r\n"]
[705.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[705.002, "i", "sed -n '1,200p' pandas/core/util/hashing.py\r"]
[705.004, "o", "sed -n '1,200p' pandas/core/util/hashing.py\r\n"]
[705.030597, "o", "\u001b[?2004l\r\n"]
[705.055194, "o", "\"\"\"\r\n"]
[705.079791, "o", "data hash pandas / numpy objects\r\n"]
[705.104388, "o", "\"\"\"\r\n"]
[705.128985, "o", "\r\n"]
[705.153582, "o", "from __future__ import annotations\r\n"]
[705.178179, "o", "\r\n"]
[705.202776, "o", "import itertools\r\n"]
[705.227373, "o", "from typing import TYPE_CHECKING\r\n"]
[705.25197, "o", "\r\n"]
[705.276567, "o", "import numpy as np\r\n"]
[705.301164, "o", "\r\n"]
[705.325761, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[705.350358, "o", "\r\n"]
[705.374955, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[705.399552, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[705.424149, "o", "from pandas.core.dtypes.generic import (\r\n"]
[705.448746, "o", "    ABCDataFrame,\r\n"]
[705.473343, "o", "    ABCExtensionArray,\r\n"]
[705.49794, "o", "    ABCIndex,\r\n"]
[705.522537, "o", "    ABCMultiIndex,\r\n"]
[705.547134, "o", "    ABCSeries,\r\n"]
[705.571731, "o", ")\r\n"]
[705.596328, "o", "\r\n"]
[705.620925, "o", "if TYPE_CHECKING:\r\n"]
[705.645522, "o", "    from collections.abc import (\r\n"]
[705.670119, "o", "        Hashable,\r\n"]
[705.694716, "o", "        Iterable,\r\n"]
[705.719313, "o", "        Iterator,\r\n"]
[705.74391, "o", "    )\r\n"]
[705.768507, "o", "\r\n"]
[705.793104, "o", "    from pandas._typing import (\r\n"]
[705.817701, "o", "        ArrayLike,\r\n"]
[705.842299, "o", "        npt,\r\n"]
[705.866896, "o", "    )\r\n"]
[705.891493, "o", "\r\n"]
[705.91609, "o", "    from pandas import (\r\n"]
[705.940687, "o", "        DataFrame,\r\n"]
[705.965284, "o", "        Index,\r\n"]
[705.989881, "o", "        MultiIndex,\r\n"]
[706.014478, "o", "        Series,\r\n"]
[706.039075, "o", "    )\r\n"]
[706.063672, "o", "\r\n"]
[706.088269, "o", "\r\n"]
[706.112866, "o", "# 16 byte long hashing key\r\n"]
[706.137463, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[706.16206, "o", "\r\n"]
[706.186657, "o", "\r\n"]
[706.211254, "o", "def combine_hash_arrays(\r\n"]
[706.235851, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[706.260448, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[706.285045, "o", "    \"\"\"\r\n"]
[706.309642, "o", "    Parameters\r\n"]
[706.334239, "o", "    ----------\r\n"]
[706.358836, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[706.383433, "o", "    num_items : int\r\n"]
[706.40803, "o", "\r\n"]
[706.432627, "o", "    Returns\r\n"]
[706.457224, "o", "    -------\r\n"]
[706.481821, "o", "    np.ndarray[uint64]\r\n"]
[706.506418, "o", "\r\n"]
[706.531015, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[706.555612, "o", "    \"\"\"\r\n"]
[706.580209, "o", "    try:\r\n"]
[706.604806, "o", "        first = next(arrays)\r\n"]
[706.629403, "o", "    except StopIteration:\r\n"]
[706.654, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[706.678597, "o", "\r\n"]
[706.703194, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[706.727791, "o", "\r\n"]
[706.752388, "o", "    mult = np.uint64(1000003)\r\n"]
[706.776985, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[706.801582, "o", "    last_i = 0\r\n"]
[706.826179, "o", "    for i, a in enumerate(arrays):\r\n"]
[706.850776, "o", "        inverse_i = num_items - i\r\n"]
[706.875373, "o", "        out ^= a\r\n"]
[706.89997, "o", "        out *= mult\r\n"]
[706.924567, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[706.949164, "o", "        last_i = i\r\n"]
[706.973761, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[706.998358, "o", "    out += np.uint64(97531)\r\n"]
[707.022955, "o", "    return out\r\n"]
[707.047552, "o", "\r\n"]
[707.072149, "o", "\r\n"]
[707.096746, "o", "def hash_pandas_object(\r\n"]
[707.121343, "o", "    obj: Index | DataFrame | Series,\r\n"]
[707.14594, "o", "    index: bool = True,\r\n"]
[707.170537, "o", "    encoding: str = \"utf8\",\r\n"]
[707.195134, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[707.219731, "o", "    categorize: bool = True,\r\n"]
[707.244328, "o", ") -> Series:\r\n"]
[707.268925, "o", "    \"\"\"\r\n"]
[707.293522, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[707.318119, "o", "\r\n"]
[707.342716, "o", "    Parameters\r\n"]
[707.367313, "o", "    ----------\r\n"]
[707.39191, "o", "    obj : Index, Series, or DataFrame\r\n"]
[707.416507, "o", "    index : bool, default True\r\n"]
[707.441104, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[707.465701, "o", "    encoding : str, default 'utf8'\r\n"]
[707.490299, "o", "        Encoding for data & key when strings.\r\n"]
[707.514896, "o", "    hash_key : str, default _default_hash_key\r\n"]
[707.539493, "o", "        Hash_key for string key to encode.\r\n"]
[707.56409, "o", "    categorize : bool, default True\r\n"]
[707.588687, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[707.613284, "o", "        efficient when the array contains duplicate values.\r\n"]
[707.637881, "o", "\r\n"]
[707.662478, "o", "    Returns\r\n"]
[707.687075, "o", "    -------\r\n"]
[707.711672, "o", "    Series of uint64\r\n"]
[707.736269, "o", "        Same length as the object.\r\n"]
[707.760866, "o", "\r\n"]
[707.785463, "o", "    Examples\r\n"]
[707.81006, "o", "    --------\r\n"]
[707.834657, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[707.859254, "o", "    0    14639053686158035780\r\n"]
[707.883851, "o", "    1     3869563279212530728\r\n"]
[707.908448, "o", "    2      393322362522515241\r\n"]
[707.933045, "o", "    dtype: uint64\r\n"]
[707.957642, "o", "    \"\"\"\r\n"]
[707.982239, "o", "    from pandas import Series\r\n"]
[708.006836, "o", "\r\n"]
[708.031433, "o", "    if hash_key is None:\r\n"]
[708.05603, "o", "        hash_key = _default_hash_key\r\n"]
[708.080627, "o", "\r\n"]
[708.105224, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[708.129821, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[708.154418, "o", "\r\n"]
[708.179015, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[708.203612, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[708.228209, "o", "            \"uint64\", copy=False\r\n"]
[708.252806, "o", "        )\r\n"]
[708.277403, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[708.302, "o", "\r\n"]
[708.326597, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[708.351194, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[708.375791, "o", "            \"uint64\", copy=False\r\n"]
[708.400388, "o", "        )\r\n"]
[708.424985, "o", "        if index:\r\n"]
[708.449582, "o", "            index_iter = (\r\n"]
[708.474179, "o", "                hash_pandas_object(\r\n"]
[708.498776, "o", "                    obj.index,\r\n"]
[708.523373, "o", "                    index=False,\r\n"]
[708.54797, "o", "                    encoding=encoding,\r\n"]
[708.572567, "o", "                    hash_key=hash_key,\r\n"]
[708.597164, "o", "                    categorize=categorize,\r\n"]
[708.621761, "o", "                )._values\r\n"]
[708.646358, "o", "                for _ in [None]\r\n"]
[708.670955, "o", "            )\r\n"]
[708.695552, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[708.720149, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[708.744746, "o", "\r\n"]
[708.769343, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[708.79394, "o", "\r\n"]
[708.818537, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[708.843134, "o", "        hashes = (\r\n"]
[708.867731, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[708.892328, "o", "            for _, series in obj.items()\r\n"]
[708.916925, "o", "        )\r\n"]
[708.941522, "o", "        num_items = len(obj.columns)\r\n"]
[708.966119, "o", "        if index:\r\n"]
[708.990716, "o", "            index_hash_generator = (\r\n"]
[709.015313, "o", "                hash_pandas_object(\r\n"]
[709.03991, "o", "                    obj.index,\r\n"]
[709.064507, "o", "                    index=False,\r\n"]
[709.089104, "o", "                    encoding=encoding,\r\n"]
[709.113701, "o", "                    hash_key=hash_key,\r\n"]
[709.138299, "o", "                    categorize=categorize,\r\n"]
[709.162896, "o", "                )._values\r\n"]
[709.187493, "o", "                for _ in [None]\r\n"]
[709.21209, "o", "            )\r\n"]
[709.236687, "o", "            num_items += 1\r\n"]
[709.261284, "o", "\r\n"]
[709.285881, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[709.310478, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[709.335075, "o", "            hashes = (x for x in _hashes)\r\n"]
[709.359672, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[709.384269, "o", "\r\n"]
[709.408866, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[709.433463, "o", "    else:\r\n"]
[709.45806, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[709.482657, "o", "\r\n"]
[709.507254, "o", "    return ser\r\n"]
[709.531851, "o", "\r\n"]
[709.556448, "o", "\r\n"]
[709.581045, "o", "def hash_tuples(\r\n"]
[709.605642, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[709.630239, "o", "    encoding: str = \"utf8\",\r\n"]
[709.654836, "o", "    hash_key: str = _default_hash_key,\r\n"]
[709.679433, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[709.70403, "o", "    \"\"\"\r\n"]
[709.728627, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[709.753224, "o", "\r\n"]
[709.777821, "o", "    Parameters\r\n"]
[709.802418, "o", "    ----------\r\n"]
[709.827015, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[709.851612, "o", "    encoding : str, default 'utf8'\r\n"]
[709.876209, "o", "    hash_key : str, default _default_hash_key\r\n"]
[709.900806, "o", "\r\n"]
[709.925403, "o", "    Returns\r\n"]
[710.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[710.002, "i", "sed -n '200,420p' pandas/core/util/hashing.py\r"]
[710.004, "o", "sed -n '200,420p' pandas/core/util/hashing.py\r\n"]
[710.034091, "o", "\u001b[?2004l\r\n"]
[710.062182, "o", "    -------\r\n"]
[710.090273, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[710.118364, "o", "    \"\"\"\r\n"]
[710.146455, "o", "    if not is_list_like(vals):\r\n"]
[710.174545, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[710.202636, "o", "\r\n"]
[710.230727, "o", "    from pandas import (\r\n"]
[710.258818, "o", "        Categorical,\r\n"]
[710.286909, "o", "        MultiIndex,\r\n"]
[710.315, "o", "    )\r\n"]
[710.343091, "o", "\r\n"]
[710.371182, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[710.399273, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[710.427364, "o", "    else:\r\n"]
[710.455455, "o", "        mi = vals\r\n"]
[710.483545, "o", "\r\n"]
[710.511636, "o", "    # create a list-of-Categoricals\r\n"]
[710.539727, "o", "    cat_vals = [\r\n"]
[710.567818, "o", "        Categorical._simple_new(\r\n"]
[710.595909, "o", "            mi.codes[level],\r\n"]
[710.624, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[710.652091, "o", "        )\r\n"]
[710.680182, "o", "        for level in range(mi.nlevels)\r\n"]
[710.708273, "o", "    ]\r\n"]
[710.736364, "o", "\r\n"]
[710.764455, "o", "    # hash the list-of-ndarrays\r\n"]
[710.792545, "o", "    hashes = (\r\n"]
[710.820636, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[710.848727, "o", "        for cat in cat_vals\r\n"]
[710.876818, "o", "    )\r\n"]
[710.904909, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[710.933, "o", "\r\n"]
[710.961091, "o", "    return h\r\n"]
[710.989182, "o", "\r\n"]
[711.017273, "o", "\r\n"]
[711.045364, "o", "def hash_array(\r\n"]
[711.073455, "o", "    vals: ArrayLike,\r\n"]
[711.101545, "o", "    encoding: str = \"utf8\",\r\n"]
[711.129636, "o", "    hash_key: str = _default_hash_key,\r\n"]
[711.157727, "o", "    categorize: bool = True,\r\n"]
[711.185818, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[711.213909, "o", "    \"\"\"\r\n"]
[711.242, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[711.270091, "o", "\r\n"]
[711.298182, "o", "    Parameters\r\n"]
[711.326273, "o", "    ----------\r\n"]
[711.354364, "o", "    vals : ndarray or ExtensionArray\r\n"]
[711.382455, "o", "        The input array to hash.\r\n"]
[711.410545, "o", "    encoding : str, default 'utf8'\r\n"]
[711.438636, "o", "        Encoding for data & key when strings.\r\n"]
[711.466727, "o", "    hash_key : str, default _default_hash_key\r\n"]
[711.494818, "o", "        Hash_key for string key to encode.\r\n"]
[711.522909, "o", "    categorize : bool, default True\r\n"]
[711.551, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[711.579091, "o", "        efficient when the array contains duplicate values.\r\n"]
[711.607182, "o", "\r\n"]
[711.635273, "o", "    Returns\r\n"]
[711.663364, "o", "    -------\r\n"]
[711.691455, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[711.719545, "o", "        Hashed values, same length as the vals.\r\n"]
[711.747636, "o", "\r\n"]
[711.775727, "o", "    See Also\r\n"]
[711.803818, "o", "    --------\r\n"]
[711.831909, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[711.86, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[711.888091, "o", "\r\n"]
[711.916182, "o", "    Examples\r\n"]
[711.944273, "o", "    --------\r\n"]
[711.972364, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[712.000455, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[712.028545, "o", "      dtype=uint64)\r\n"]
[712.056636, "o", "    \"\"\"\r\n"]
[712.084727, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[712.112818, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[712.140909, "o", "\r\n"]
[712.169, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[712.197091, "o", "        return vals._hash_pandas_object(\r\n"]
[712.225182, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[712.253273, "o", "        )\r\n"]
[712.281364, "o", "\r\n"]
[712.309455, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[712.337545, "o", "        # GH#42003\r\n"]
[712.365636, "o", "        raise TypeError(\r\n"]
[712.393727, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[712.421818, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[712.449909, "o", "        )\r\n"]
[712.478, "o", "\r\n"]
[712.506091, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[712.534182, "o", "\r\n"]
[712.562273, "o", "\r\n"]
[712.590364, "o", "def _hash_ndarray(\r\n"]
[712.618455, "o", "    vals: np.ndarray,\r\n"]
[712.646545, "o", "    encoding: str = \"utf8\",\r\n"]
[712.674636, "o", "    hash_key: str = _default_hash_key,\r\n"]
[712.702727, "o", "    categorize: bool = True,\r\n"]
[712.730818, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[712.758909, "o", "    \"\"\"\r\n"]
[712.787, "o", "    See hash_array.__doc__.\r\n"]
[712.815091, "o", "    \"\"\"\r\n"]
[712.843182, "o", "    dtype = vals.dtype\r\n"]
[712.871273, "o", "\r\n"]
[712.899364, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[712.927455, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[712.955545, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[712.983636, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[713.011727, "o", "        return hash_real + 23 * hash_imag\r\n"]
[713.039818, "o", "\r\n"]
[713.067909, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[713.096, "o", "    # manage it.\r\n"]
[713.124091, "o", "    if dtype == bool:\r\n"]
[713.152182, "o", "        vals = vals.astype(\"u8\")\r\n"]
[713.180273, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[713.208364, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[713.236455, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[713.264545, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[713.292636, "o", "    else:\r\n"]
[713.320727, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[713.348818, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[713.376909, "o", "        # when the values are known/likely to be unique.\r\n"]
[713.405, "o", "        if categorize:\r\n"]
[713.433091, "o", "            from pandas import (\r\n"]
[713.461182, "o", "                Categorical,\r\n"]
[713.489273, "o", "                Index,\r\n"]
[713.517364, "o", "                factorize,\r\n"]
[713.545455, "o", "            )\r\n"]
[713.573545, "o", "\r\n"]
[713.601636, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[713.629727, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[713.657818, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[713.685909, "o", "            return cat._hash_pandas_object(\r\n"]
[713.714, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[713.742091, "o", "            )\r\n"]
[713.770182, "o", "\r\n"]
[713.798273, "o", "        try:\r\n"]
[713.826364, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[713.854455, "o", "        if is_object_dtype(values) and not categorize:\r\n"]
[713.882545, "o", "            import numpy as np\r\n"]
[713.910636, "o", "            import pandas as pd\r\n"]
[713.938727, "o", "            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[713.966818, "o", "            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[713.994909, "o", "            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[714.023, "o", "            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[714.051091, "o", "            mask = codes == -1\r\n"]
[714.079182, "o", "            if mask.any():\r\n"]
[714.107273, "o", "                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[714.135364, "o", "                res = res.copy()\r\n"]
[714.163455, "o", "                res[mask] = na_hash\r\n"]
[714.191545, "o", "            return res\r\n"]
[714.219636, "o", "        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[714.247727, "o", "        except TypeError:\r\n"]
[714.275818, "o", "            # we have mixed types\r\n"]
[714.303909, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[714.332, "o", "            if is_object_dtype(values) and not categorize:\r\n"]
[714.360091, "o", "                import numpy as np\r\n"]
[714.388182, "o", "                import pandas as pd\r\n"]
[714.416273, "o", "                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[714.444364, "o", "                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[714.472455, "o", "                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[714.500545, "o", "                mask = codes == -1\r\n"]
[714.528636, "o", "                if mask.any():\r\n"]
[714.556727, "o", "                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[714.584818, "o", "                    res = res.copy()\r\n"]
[714.612909, "o", "                    res[mask] = na_hash\r\n"]
[714.641, "o", "                return res\r\n"]
[714.669091, "o", "            vals = hash_object_array(\r\n"]
[714.697182, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[714.725273, "o", "            )\r\n"]
[714.753364, "o", "\r\n"]
[714.781455, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[714.809545, "o", "    vals ^= vals >> 30\r\n"]
[714.837636, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[714.865727, "o", "    vals ^= vals >> 27\r\n"]
[714.893818, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[714.921909, "o", "    vals ^= vals >> 31\r\n"]
[715.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[715.002, "i", "cd asv_bench\r"]
[715.004, "o", "cd asv_bench\r\n"]
[715.006, "o", "\u001b[?2004l\r\n"]
[720.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[720.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[720.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[720.10488, "o", "\u001b[?2004l\r\n"]
[720.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[720.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpnwsoubi9/result.json (exit status 1)\u001b[0m\r\n"]
[720.40152, "o", "   STDOUT -------->\r\n"]
[720.5004, "o", "   \r\n"]
[720.59928, "o", "   STDERR -------->\r\n"]
[720.69816, "o", "   Traceback (most recent call last):\r\n"]
[720.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[720.89592, "o", "       main()\r\n"]
[720.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[721.09368, "o", "       commands[mode](args)\r\n"]
[721.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[721.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[721.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[721.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[721.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[721.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[721.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[721.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[721.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[722.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[722.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[722.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[722.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[722.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[722.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[722.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[722.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[722.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[722.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[723.07128, "o", "       import pandas as pd\r\n"]
[723.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[723.26904, "o", "       from pandas.core.api import (\r\n"]
[723.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[723.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[723.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[723.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[723.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[723.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[723.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[724.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[724.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[724.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[724.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 335\r\n"]
[724.4556, "o", "       if is_object_dtype(values) and not categorize:\r\n"]
[724.55448, "o", "       ^^\r\n"]
[724.65336, "o", "   SyntaxError: expected 'except' or 'finally' block\r\n"]
[724.75224, "o", "\r\n"]
[724.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpnwsoubi9/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[725.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[725.002, "i", "cd /workspace/repo\r"]
[725.004, "o", "cd /workspace/repo\r\n"]
[725.006, "o", "\u001b[?2004l\r\n"]
[730.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[730.002, "i", "python - << 'PY'\r"]
[730.004, "o", "python - << 'PY'\r\n"]
[730.095891, "o", "\u001b[?2004l\r\n"]
[730.185782, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[730.275673, "o", "\u001b[?2004l\r\n"]
[730.365564, "o", "\u001b[?2004h> import re\r\n"]
[730.455455, "o", "\u001b[?2004l\r\n"]
[730.545345, "o", "\u001b[?2004h> p=Path('pandas/core/util/hashing.py')\r\n"]
[730.635236, "o", "\u001b[?2004l\r\n"]
[730.725127, "o", "\u001b[?2004h> s=p.read_text(encoding='utf-8')\r\n"]
[730.815018, "o", "\u001b[?2004l\r\n"]
[730.904909, "o", "\u001b[?2004h> # Find hash_array function\r\n"]
[730.9948, "o", "\u001b[?2004l\r\n"]
[731.084691, "o", "\u001b[?2004h> m=re.search(r\"^def\\s+hash_array\\(.*?\\):\", s, flags=re.M)\r\n"]
[731.174582, "o", "\u001b[?2004l\r\n"]
[731.264473, "o", "\u001b[?2004h> if not m:\r\n"]
[731.354364, "o", "\u001b[?2004l\r\n"]
[731.444255, "o", "\u001b[?2004h>     raise SystemExit('hash_array not found')\r\n"]
[731.534145, "o", "\u001b[?2004l\r\n"]
[731.624036, "o", "\u001b[?2004h> start=m.end()\r\n"]
[731.713927, "o", "\u001b[?2004l\r\n"]
[731.803818, "o", "\u001b[?2004h> # Insert a safe fast path right after the function signature/docstring start\r\n"]
[731.893709, "o", "\u001b[?2004l\r\n"]
[731.9836, "o", "\u001b[?2004h> insert_at = s.find('\\n', start)+1\r\n"]
[732.073491, "o", "\u001b[?2004l\r\n"]
[732.163382, "o", "\u001b[?2004h> # If there is a docstring, skip it\r\n"]
[732.253273, "o", "\u001b[?2004l\r\n"]
[732.343164, "o", "\u001b[?2004h> if s[insert_at:insert_at+3] in ('\"\"\"', \"'''\"):\r\n"]
[732.433055, "o", "\u001b[?2004l\r\n"]
[732.522945, "o", "\u001b[?2004h>     q=s[insert_at]\r\n"]
[732.612836, "o", "\u001b[?2004l\r\n"]
[732.702727, "o", "\u001b[?2004h>     enddoc=s.find(q*3, insert_at+3)\r\n"]
[732.792618, "o", "\u001b[?2004l\r\n"]
[732.882509, "o", "\u001b[?2004h>     insert_at=enddoc+3\r\n"]
[732.9724, "o", "\u001b[?2004l\r\n"]
[733.062291, "o", "\u001b[?2004h> fastpath='\\n    # Fast path: factorize object-dtype arrays and hash uniques once, remap to original\\n    try:\\n        from pandas.core.dtypes.common import is\r\n"]
[733.152182, "o", "s_object_dtype\\n        import numpy as np\\n        import pandas as pd\\n        if is_object_dtype(values) and not categorize:\\n            codes, uniques = pd.\r\n"]
[733.242073, "o", ".factorize(values, sort=False)\\n            from pandas._libs.hashing import hash_object_array\\n            uhash = hash_object_array(uniques, hash_key, encoding\r\n"]
[733.331964, "o", "g)\\n            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\\n            mask = codes == -1\\n            if mask.any():\\n                na_has\r\n"]
[733.421855, "o", "sh = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\\n                res = res.copy()\\n                res[mask] = na_hash\\n         \r\n"]
[733.511745, "o", "    return res\\n    except Exception:\\n        # Fall back to original implementation below on any error\\n        pass\\n'\r\n"]
[733.601636, "o", "\u001b[?2004l\r\n"]
[733.691527, "o", "\u001b[?2004h> if 'Fast path: factorize object-dtype arrays' not in s:\r\n"]
[733.781418, "o", "\u001b[?2004l\r\n"]
[733.871309, "o", "\u001b[?2004h>     s = s[:insert_at] + fastpath + s[insert_at:]\r\n"]
[733.9612, "o", "\u001b[?2004l\r\n"]
[734.051091, "o", "\u001b[?2004h>     p.write_text(s, encoding='utf-8')\r\n"]
[734.140982, "o", "\u001b[?2004l\r\n"]
[734.230873, "o", "\u001b[?2004h>     print('Inserted safe fast path into hash_array')\r\n"]
[734.320764, "o", "\u001b[?2004l\r\n"]
[734.410655, "o", "\u001b[?2004h> else:\r\n"]
[734.500545, "o", "\u001b[?2004l\r\n"]
[734.590436, "o", "\u001b[?2004h>     print('Fast path already present; no changes made')\r\n"]
[734.680327, "o", "\u001b[?2004l\r\n"]
[734.770218, "o", "\u001b[?2004h> PY\r\n"]
[734.860109, "o", "\u001b[?2004l\r\n"]
[735.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[735.002, "i", "git config user.email optimization@example.com && git config user.name Optimizer\r"]
[735.004, "o", "git config user.email optimization@example.com && git config user.name Optimizer\r\n"]
[735.006, "o", "\u001b[?2004l\r\n"]
[740.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[740.002, "i", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): add safe early fast path in hash_array to factori\r"]
[740.004, "o", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): add safe early fast path in hash_array to factori\r\n"]
[741.242, "o", "ize object arrays and hash uniques once\"\r\n"]
[742.478, "o", "\u001b[?2004l\r\n"]
[743.714, "o", "On branch opt/hash-string-memo\r\n"]
[745.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[745.002, "i", "cd asv_bench\r"]
[745.004, "o", "cd asv_bench\r\n"]
[745.006, "o", "\u001b[?2004l\r\n"]
[750.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[750.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[750.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[750.10488, "o", "\u001b[?2004l\r\n"]
[750.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[750.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp5drqio9m/result.json (exit status 1)\u001b[0m\r\n"]
[750.40152, "o", "   STDOUT -------->\r\n"]
[750.5004, "o", "   \r\n"]
[750.59928, "o", "   STDERR -------->\r\n"]
[750.69816, "o", "   Traceback (most recent call last):\r\n"]
[750.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[750.89592, "o", "       main()\r\n"]
[750.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[751.09368, "o", "       commands[mode](args)\r\n"]
[751.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[751.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[751.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[751.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[751.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[751.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[751.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[751.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[751.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[752.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[752.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[752.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[752.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[752.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[752.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[752.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[752.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[752.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[752.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[753.07128, "o", "       import pandas as pd\r\n"]
[753.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[753.26904, "o", "       from pandas.core.api import (\r\n"]
[753.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[753.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[753.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[753.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[753.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[753.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[753.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[754.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[754.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[754.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[754.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 335\r\n"]
[754.4556, "o", "       if is_object_dtype(values) and not categorize:\r\n"]
[754.55448, "o", "       ^^\r\n"]
[754.65336, "o", "   SyntaxError: expected 'except' or 'finally' block\r\n"]
[754.75224, "o", "\r\n"]
[754.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp5drqio9m/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[755.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[755.002, "i", "cd /workspace/repo\r"]
[755.004, "o", "cd /workspace/repo\r\n"]
[755.006, "o", "\u001b[?2004l\r\n"]
[760.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[760.002, "i", "nl -ba pandas/core/util/hashing.py | sed -n '300,360p'\r"]
[760.004, "o", "nl -ba pandas/core/util/hashing.py | sed -n '300,360p'\r\n"]
[760.085742, "o", "\u001b[?2004l\r\n"]
[760.165484, "o", "   300\t\r\n"]
[760.245226, "o", "   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[760.324968, "o", "   302\t    if np.issubdtype(dtype, np.complex128):\r\n"]
[760.40471, "o", "   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[760.484452, "o", "   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[760.564194, "o", "   305\t        return hash_real + 23 * hash_imag\r\n"]
[760.643935, "o", "   306\t\r\n"]
[760.723677, "o", "   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[760.803419, "o", "   308\t    # manage it.\r\n"]
[760.883161, "o", "   309\t    if dtype == bool:\r\n"]
[760.962903, "o", "   310\t        vals = vals.astype(\"u8\")\r\n"]
[761.042645, "o", "   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[761.122387, "o", "   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[761.202129, "o", "   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[761.281871, "o", "   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[761.361613, "o", "   315\t    else:\r\n"]
[761.441355, "o", "   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[761.521097, "o", "   317\t        # then hash and rename categories. We allow skipping the categorization\r\n"]
[761.600839, "o", "   318\t        # when the values are known/likely to be unique.\r\n"]
[761.680581, "o", "   319\t        if categorize:\r\n"]
[761.760323, "o", "   320\t            from pandas import (\r\n"]
[761.840065, "o", "   321\t                Categorical,\r\n"]
[761.919806, "o", "   322\t                Index,\r\n"]
[761.999548, "o", "   323\t                factorize,\r\n"]
[762.07929, "o", "   324\t            )\r\n"]
[762.159032, "o", "   325\t\r\n"]
[762.238774, "o", "   326\t            codes, categories = factorize(vals, sort=False)\r\n"]
[762.318516, "o", "   327\t            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[762.398258, "o", "   328\t            cat = Categorical._simple_new(codes, dtype)\r\n"]
[762.478, "o", "   329\t            return cat._hash_pandas_object(\r\n"]
[762.557742, "o", "   330\t                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[762.637484, "o", "   331\t            )\r\n"]
[762.717226, "o", "   332\t\r\n"]
[762.796968, "o", "   333\t        try:\r\n"]
[762.87671, "o", "   334\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[762.956452, "o", "   335\t        if is_object_dtype(values) and not categorize:\r\n"]
[763.036194, "o", "   336\t            import numpy as np\r\n"]
[763.115935, "o", "   337\t            import pandas as pd\r\n"]
[763.195677, "o", "   338\t            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[763.275419, "o", "   339\t            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[763.355161, "o", "   340\t            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[763.434903, "o", "   341\t            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[763.514645, "o", "   342\t            mask = codes == -1\r\n"]
[763.594387, "o", "   343\t            if mask.any():\r\n"]
[763.674129, "o", "   344\t                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[763.753871, "o", "   345\t                res = res.copy()\r\n"]
[763.833613, "o", "   346\t                res[mask] = na_hash\r\n"]
[763.913355, "o", "   347\t            return res\r\n"]
[763.993097, "o", "   348\t        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[764.072839, "o", "   349\t        except TypeError:\r\n"]
[764.152581, "o", "   350\t            # we have mixed types\r\n"]
[764.232323, "o", "   351\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[764.312065, "o", "   352\t            if is_object_dtype(values) and not categorize:\r\n"]
[764.391806, "o", "   353\t                import numpy as np\r\n"]
[764.471548, "o", "   354\t                import pandas as pd\r\n"]
[764.55129, "o", "   355\t                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[764.631032, "o", "   356\t                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[764.710774, "o", "   357\t                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[764.790516, "o", "   358\t                mask = codes == -1\r\n"]
[764.870258, "o", "   359\t                if mask.any():\r\n"]
[765.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[765.002, "i", "git status --porcelain\r"]
[765.004, "o", "git status --porcelain\r\n"]
[765.006, "o", "\u001b[?2004l\r\n"]
[770.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[770.002, "i", "git restore --worktree --staged -- pandas/core/util/hashing.py\r"]
[770.004, "o", "git restore --worktree --staged -- pandas/core/util/hashing.py\r\n"]
[770.006, "o", "\u001b[?2004l\r\n"]
[775.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[775.002, "i", "sed -n '1,220p' pandas/core/util/hashing.py\r"]
[775.004, "o", "sed -n '1,220p' pandas/core/util/hashing.py\r\n"]
[775.028371, "o", "\u001b[?2004l\r\n"]
[775.050742, "o", "\"\"\"\r\n"]
[775.073113, "o", "data hash pandas / numpy objects\r\n"]
[775.095484, "o", "\"\"\"\r\n"]
[775.117855, "o", "\r\n"]
[775.140226, "o", "from __future__ import annotations\r\n"]
[775.162597, "o", "\r\n"]
[775.184968, "o", "import itertools\r\n"]
[775.207339, "o", "from typing import TYPE_CHECKING\r\n"]
[775.22971, "o", "\r\n"]
[775.252081, "o", "import numpy as np\r\n"]
[775.274452, "o", "\r\n"]
[775.296824, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[775.319195, "o", "\r\n"]
[775.341566, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[775.363937, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[775.386308, "o", "from pandas.core.dtypes.generic import (\r\n"]
[775.408679, "o", "    ABCDataFrame,\r\n"]
[775.43105, "o", "    ABCExtensionArray,\r\n"]
[775.453421, "o", "    ABCIndex,\r\n"]
[775.475792, "o", "    ABCMultiIndex,\r\n"]
[775.498163, "o", "    ABCSeries,\r\n"]
[775.520534, "o", ")\r\n"]
[775.542905, "o", "\r\n"]
[775.565276, "o", "if TYPE_CHECKING:\r\n"]
[775.587647, "o", "    from collections.abc import (\r\n"]
[775.610018, "o", "        Hashable,\r\n"]
[775.632389, "o", "        Iterable,\r\n"]
[775.65476, "o", "        Iterator,\r\n"]
[775.677131, "o", "    )\r\n"]
[775.699502, "o", "\r\n"]
[775.721873, "o", "    from pandas._typing import (\r\n"]
[775.744244, "o", "        ArrayLike,\r\n"]
[775.766615, "o", "        npt,\r\n"]
[775.788986, "o", "    )\r\n"]
[775.811357, "o", "\r\n"]
[775.833729, "o", "    from pandas import (\r\n"]
[775.8561, "o", "        DataFrame,\r\n"]
[775.878471, "o", "        Index,\r\n"]
[775.900842, "o", "        MultiIndex,\r\n"]
[775.923213, "o", "        Series,\r\n"]
[775.945584, "o", "    )\r\n"]
[775.967955, "o", "\r\n"]
[775.990326, "o", "\r\n"]
[776.012697, "o", "# 16 byte long hashing key\r\n"]
[776.035068, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[776.057439, "o", "\r\n"]
[776.07981, "o", "\r\n"]
[776.102181, "o", "def combine_hash_arrays(\r\n"]
[776.124552, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[776.146923, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[776.169294, "o", "    \"\"\"\r\n"]
[776.191665, "o", "    Parameters\r\n"]
[776.214036, "o", "    ----------\r\n"]
[776.236407, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[776.258778, "o", "    num_items : int\r\n"]
[776.281149, "o", "\r\n"]
[776.30352, "o", "    Returns\r\n"]
[776.325891, "o", "    -------\r\n"]
[776.348262, "o", "    np.ndarray[uint64]\r\n"]
[776.370633, "o", "\r\n"]
[776.393005, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[776.415376, "o", "    \"\"\"\r\n"]
[776.437747, "o", "    try:\r\n"]
[776.460118, "o", "        first = next(arrays)\r\n"]
[776.482489, "o", "    except StopIteration:\r\n"]
[776.50486, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[776.527231, "o", "\r\n"]
[776.549602, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[776.571973, "o", "\r\n"]
[776.594344, "o", "    mult = np.uint64(1000003)\r\n"]
[776.616715, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[776.639086, "o", "    last_i = 0\r\n"]
[776.661457, "o", "    for i, a in enumerate(arrays):\r\n"]
[776.683828, "o", "        inverse_i = num_items - i\r\n"]
[776.706199, "o", "        out ^= a\r\n"]
[776.72857, "o", "        out *= mult\r\n"]
[776.750941, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[776.773312, "o", "        last_i = i\r\n"]
[776.795683, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[776.818054, "o", "    out += np.uint64(97531)\r\n"]
[776.840425, "o", "    return out\r\n"]
[776.862796, "o", "\r\n"]
[776.885167, "o", "\r\n"]
[776.907538, "o", "def hash_pandas_object(\r\n"]
[776.92991, "o", "    obj: Index | DataFrame | Series,\r\n"]
[776.952281, "o", "    index: bool = True,\r\n"]
[776.974652, "o", "    encoding: str = \"utf8\",\r\n"]
[776.997023, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[777.019394, "o", "    categorize: bool = True,\r\n"]
[777.041765, "o", ") -> Series:\r\n"]
[777.064136, "o", "    \"\"\"\r\n"]
[777.086507, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[777.108878, "o", "\r\n"]
[777.131249, "o", "    Parameters\r\n"]
[777.15362, "o", "    ----------\r\n"]
[777.175991, "o", "    obj : Index, Series, or DataFrame\r\n"]
[777.198362, "o", "    index : bool, default True\r\n"]
[777.220733, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[777.243104, "o", "    encoding : str, default 'utf8'\r\n"]
[777.265475, "o", "        Encoding for data & key when strings.\r\n"]
[777.287846, "o", "    hash_key : str, default _default_hash_key\r\n"]
[777.310217, "o", "        Hash_key for string key to encode.\r\n"]
[777.332588, "o", "    categorize : bool, default True\r\n"]
[777.354959, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[777.37733, "o", "        efficient when the array contains duplicate values.\r\n"]
[777.399701, "o", "\r\n"]
[777.422072, "o", "    Returns\r\n"]
[777.444443, "o", "    -------\r\n"]
[777.466814, "o", "    Series of uint64\r\n"]
[777.489186, "o", "        Same length as the object.\r\n"]
[777.511557, "o", "\r\n"]
[777.533928, "o", "    Examples\r\n"]
[777.556299, "o", "    --------\r\n"]
[777.57867, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[777.601041, "o", "    0    14639053686158035780\r\n"]
[777.623412, "o", "    1     3869563279212530728\r\n"]
[777.645783, "o", "    2      393322362522515241\r\n"]
[777.668154, "o", "    dtype: uint64\r\n"]
[777.690525, "o", "    \"\"\"\r\n"]
[777.712896, "o", "    from pandas import Series\r\n"]
[777.735267, "o", "\r\n"]
[777.757638, "o", "    if hash_key is None:\r\n"]
[777.780009, "o", "        hash_key = _default_hash_key\r\n"]
[777.80238, "o", "\r\n"]
[777.824751, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[777.847122, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[777.869493, "o", "\r\n"]
[777.891864, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[777.914235, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[777.936606, "o", "            \"uint64\", copy=False\r\n"]
[777.958977, "o", "        )\r\n"]
[777.981348, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[778.003719, "o", "\r\n"]
[778.02609, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[778.048462, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[778.070833, "o", "            \"uint64\", copy=False\r\n"]
[778.093204, "o", "        )\r\n"]
[778.115575, "o", "        if index:\r\n"]
[778.137946, "o", "            index_iter = (\r\n"]
[778.160317, "o", "                hash_pandas_object(\r\n"]
[778.182688, "o", "                    obj.index,\r\n"]
[778.205059, "o", "                    index=False,\r\n"]
[778.22743, "o", "                    encoding=encoding,\r\n"]
[778.249801, "o", "                    hash_key=hash_key,\r\n"]
[778.272172, "o", "                    categorize=categorize,\r\n"]
[778.294543, "o", "                )._values\r\n"]
[778.316914, "o", "                for _ in [None]\r\n"]
[778.339285, "o", "            )\r\n"]
[778.361656, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[778.384027, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[778.406398, "o", "\r\n"]
[778.428769, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[778.45114, "o", "\r\n"]
[778.473511, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[778.495882, "o", "        hashes = (\r\n"]
[778.518253, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[778.540624, "o", "            for _, series in obj.items()\r\n"]
[778.562995, "o", "        )\r\n"]
[778.585367, "o", "        num_items = len(obj.columns)\r\n"]
[778.607738, "o", "        if index:\r\n"]
[778.630109, "o", "            index_hash_generator = (\r\n"]
[778.65248, "o", "                hash_pandas_object(\r\n"]
[778.674851, "o", "                    obj.index,\r\n"]
[778.697222, "o", "                    index=False,\r\n"]
[778.719593, "o", "                    encoding=encoding,\r\n"]
[778.741964, "o", "                    hash_key=hash_key,\r\n"]
[778.764335, "o", "                    categorize=categorize,\r\n"]
[778.786706, "o", "                )._values\r\n"]
[778.809077, "o", "                for _ in [None]\r\n"]
[778.831448, "o", "            )\r\n"]
[778.853819, "o", "            num_items += 1\r\n"]
[778.87619, "o", "\r\n"]
[778.898561, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[778.920932, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[778.943303, "o", "            hashes = (x for x in _hashes)\r\n"]
[778.965674, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[778.988045, "o", "\r\n"]
[779.010416, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[779.032787, "o", "    else:\r\n"]
[779.055158, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[779.077529, "o", "\r\n"]
[779.0999, "o", "    return ser\r\n"]
[779.122271, "o", "\r\n"]
[779.144643, "o", "\r\n"]
[779.167014, "o", "def hash_tuples(\r\n"]
[779.189385, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[779.211756, "o", "    encoding: str = \"utf8\",\r\n"]
[779.234127, "o", "    hash_key: str = _default_hash_key,\r\n"]
[779.256498, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[779.278869, "o", "    \"\"\"\r\n"]
[779.30124, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[779.323611, "o", "\r\n"]
[779.345982, "o", "    Parameters\r\n"]
[779.368353, "o", "    ----------\r\n"]
[779.390724, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[779.413095, "o", "    encoding : str, default 'utf8'\r\n"]
[779.435466, "o", "    hash_key : str, default _default_hash_key\r\n"]
[779.457837, "o", "\r\n"]
[779.480208, "o", "    Returns\r\n"]
[779.502579, "o", "    -------\r\n"]
[779.52495, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[779.547321, "o", "    \"\"\"\r\n"]
[779.569692, "o", "    if not is_list_like(vals):\r\n"]
[779.592063, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[779.614434, "o", "\r\n"]
[779.636805, "o", "    from pandas import (\r\n"]
[779.659176, "o", "        Categorical,\r\n"]
[779.681548, "o", "        MultiIndex,\r\n"]
[779.703919, "o", "    )\r\n"]
[779.72629, "o", "\r\n"]
[779.748661, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[779.771032, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[779.793403, "o", "    else:\r\n"]
[779.815774, "o", "        mi = vals\r\n"]
[779.838145, "o", "\r\n"]
[779.860516, "o", "    # create a list-of-Categoricals\r\n"]
[779.882887, "o", "    cat_vals = [\r\n"]
[779.905258, "o", "        Categorical._simple_new(\r\n"]
[779.927629, "o", "            mi.codes[level],\r\n"]
[780.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[780.002, "i", "sed -n '220,440p' pandas/core/util/hashing.py\r"]
[780.004, "o", "sed -n '220,440p' pandas/core/util/hashing.py\r\n"]
[780.037692, "o", "\u001b[?2004l\r\n"]
[780.069385, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[780.101077, "o", "        )\r\n"]
[780.132769, "o", "        for level in range(mi.nlevels)\r\n"]
[780.164462, "o", "    ]\r\n"]
[780.196154, "o", "\r\n"]
[780.227846, "o", "    # hash the list-of-ndarrays\r\n"]
[780.259538, "o", "    hashes = (\r\n"]
[780.291231, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[780.322923, "o", "        for cat in cat_vals\r\n"]
[780.354615, "o", "    )\r\n"]
[780.386308, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[780.418, "o", "\r\n"]
[780.449692, "o", "    return h\r\n"]
[780.481385, "o", "\r\n"]
[780.513077, "o", "\r\n"]
[780.544769, "o", "def hash_array(\r\n"]
[780.576462, "o", "    vals: ArrayLike,\r\n"]
[780.608154, "o", "    encoding: str = \"utf8\",\r\n"]
[780.639846, "o", "    hash_key: str = _default_hash_key,\r\n"]
[780.671538, "o", "    categorize: bool = True,\r\n"]
[780.703231, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[780.734923, "o", "    \"\"\"\r\n"]
[780.766615, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[780.798308, "o", "\r\n"]
[780.83, "o", "    Parameters\r\n"]
[780.861692, "o", "    ----------\r\n"]
[780.893385, "o", "    vals : ndarray or ExtensionArray\r\n"]
[780.925077, "o", "        The input array to hash.\r\n"]
[780.956769, "o", "    encoding : str, default 'utf8'\r\n"]
[780.988462, "o", "        Encoding for data & key when strings.\r\n"]
[781.020154, "o", "    hash_key : str, default _default_hash_key\r\n"]
[781.051846, "o", "        Hash_key for string key to encode.\r\n"]
[781.083538, "o", "    categorize : bool, default True\r\n"]
[781.115231, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[781.146923, "o", "        efficient when the array contains duplicate values.\r\n"]
[781.178615, "o", "\r\n"]
[781.210308, "o", "    Returns\r\n"]
[781.242, "o", "    -------\r\n"]
[781.273692, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[781.305385, "o", "        Hashed values, same length as the vals.\r\n"]
[781.337077, "o", "\r\n"]
[781.368769, "o", "    See Also\r\n"]
[781.400462, "o", "    --------\r\n"]
[781.432154, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[781.463846, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[781.495538, "o", "\r\n"]
[781.527231, "o", "    Examples\r\n"]
[781.558923, "o", "    --------\r\n"]
[781.590615, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[781.622308, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[781.654, "o", "      dtype=uint64)\r\n"]
[781.685692, "o", "    \"\"\"\r\n"]
[781.717385, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[781.749077, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[781.780769, "o", "\r\n"]
[781.812462, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[781.844154, "o", "        return vals._hash_pandas_object(\r\n"]
[781.875846, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[781.907538, "o", "        )\r\n"]
[781.939231, "o", "\r\n"]
[781.970923, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[782.002615, "o", "        # GH#42003\r\n"]
[782.034308, "o", "        raise TypeError(\r\n"]
[782.066, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[782.097692, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[782.129385, "o", "        )\r\n"]
[782.161077, "o", "\r\n"]
[782.192769, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[782.224462, "o", "\r\n"]
[782.256154, "o", "\r\n"]
[782.287846, "o", "def _hash_ndarray(\r\n"]
[782.319538, "o", "    vals: np.ndarray,\r\n"]
[782.351231, "o", "    encoding: str = \"utf8\",\r\n"]
[782.382923, "o", "    hash_key: str = _default_hash_key,\r\n"]
[782.414615, "o", "    categorize: bool = True,\r\n"]
[782.446308, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[782.478, "o", "    \"\"\"\r\n"]
[782.509692, "o", "    See hash_array.__doc__.\r\n"]
[782.541385, "o", "    \"\"\"\r\n"]
[782.573077, "o", "    dtype = vals.dtype\r\n"]
[782.604769, "o", "\r\n"]
[782.636462, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[782.668154, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[782.699846, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[782.731538, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[782.763231, "o", "        return hash_real + 23 * hash_imag\r\n"]
[782.794923, "o", "\r\n"]
[782.826615, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[782.858308, "o", "    # manage it.\r\n"]
[782.89, "o", "    if dtype == bool:\r\n"]
[782.921692, "o", "        vals = vals.astype(\"u8\")\r\n"]
[782.953385, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[782.985077, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[783.016769, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[783.048462, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[783.080154, "o", "    else:\r\n"]
[783.111846, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[783.143538, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[783.175231, "o", "        # when the values are known/likely to be unique.\r\n"]
[783.206923, "o", "        if categorize:\r\n"]
[783.238615, "o", "            from pandas import (\r\n"]
[783.270308, "o", "                Categorical,\r\n"]
[783.302, "o", "                Index,\r\n"]
[783.333692, "o", "                factorize,\r\n"]
[783.365385, "o", "            )\r\n"]
[783.397077, "o", "\r\n"]
[783.428769, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[783.460462, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[783.492154, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[783.523846, "o", "            return cat._hash_pandas_object(\r\n"]
[783.555538, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[783.587231, "o", "            )\r\n"]
[783.618923, "o", "\r\n"]
[783.650615, "o", "        try:\r\n"]
[783.682308, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[783.714, "o", "        if is_object_dtype(values) and not categorize:\r\n"]
[783.745692, "o", "            import numpy as np\r\n"]
[783.777385, "o", "            import pandas as pd\r\n"]
[783.809077, "o", "            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[783.840769, "o", "            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[783.872462, "o", "            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[783.904154, "o", "            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[783.935846, "o", "            mask = codes == -1\r\n"]
[783.967538, "o", "            if mask.any():\r\n"]
[783.999231, "o", "                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[784.030923, "o", "                res = res.copy()\r\n"]
[784.062615, "o", "                res[mask] = na_hash\r\n"]
[784.094308, "o", "            return res\r\n"]
[784.126, "o", "        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[784.157692, "o", "        except TypeError:\r\n"]
[784.189385, "o", "            # we have mixed types\r\n"]
[784.221077, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[784.252769, "o", "            if is_object_dtype(values) and not categorize:\r\n"]
[784.284462, "o", "                import numpy as np\r\n"]
[784.316154, "o", "                import pandas as pd\r\n"]
[784.347846, "o", "                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[784.379538, "o", "                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[784.411231, "o", "                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[784.442923, "o", "                mask = codes == -1\r\n"]
[784.474615, "o", "                if mask.any():\r\n"]
[784.506308, "o", "                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[784.538, "o", "                    res = res.copy()\r\n"]
[784.569692, "o", "                    res[mask] = na_hash\r\n"]
[784.601385, "o", "                return res\r\n"]
[784.633077, "o", "            vals = hash_object_array(\r\n"]
[784.664769, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[784.696462, "o", "            )\r\n"]
[784.728154, "o", "\r\n"]
[784.759846, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[784.791538, "o", "    vals ^= vals >> 30\r\n"]
[784.823231, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[784.854923, "o", "    vals ^= vals >> 27\r\n"]
[784.886615, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[784.918308, "o", "    vals ^= vals >> 31\r\n"]
[785.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[785.002, "i", "cd asv_bench\r"]
[785.004, "o", "cd asv_bench\r\n"]
[785.006, "o", "\u001b[?2004l\r\n"]
[790.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[790.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[790.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[790.10488, "o", "\u001b[?2004l\r\n"]
[790.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[790.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpf4thegbs/result.json (exit status 1)\u001b[0m\r\n"]
[790.40152, "o", "   STDOUT -------->\r\n"]
[790.5004, "o", "   \r\n"]
[790.59928, "o", "   STDERR -------->\r\n"]
[790.69816, "o", "   Traceback (most recent call last):\r\n"]
[790.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[790.89592, "o", "       main()\r\n"]
[790.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[791.09368, "o", "       commands[mode](args)\r\n"]
[791.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[791.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[791.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[791.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[791.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[791.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[791.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[791.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[791.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[792.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[792.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[792.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[792.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[792.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[792.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[792.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[792.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[792.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[792.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[793.07128, "o", "       import pandas as pd\r\n"]
[793.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[793.26904, "o", "       from pandas.core.api import (\r\n"]
[793.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[793.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[793.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[793.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[793.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[793.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[793.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[794.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[794.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[794.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[794.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 335\r\n"]
[794.4556, "o", "       if is_object_dtype(values) and not categorize:\r\n"]
[794.55448, "o", "       ^^\r\n"]
[794.65336, "o", "   SyntaxError: expected 'except' or 'finally' block\r\n"]
[794.75224, "o", "\r\n"]
[794.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpf4thegbs/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[795.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[795.002, "i", "cd /workspace/repo\r"]
[795.004, "o", "cd /workspace/repo\r\n"]
[795.006, "o", "\u001b[?2004l\r\n"]
[800.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[800.002, "i", "python - << 'PY'\r"]
[800.004, "o", "python - << 'PY'\r\n"]
[800.063488, "o", "\u001b[?2004l\r\n"]
[800.120977, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[800.178465, "o", "\u001b[?2004l\r\n"]
[800.235953, "o", "\u001b[?2004h> import re\r\n"]
[800.293442, "o", "\u001b[?2004l\r\n"]
[800.35093, "o", "\u001b[?2004h> p=Path('pandas/core/util/hashing.py')\r\n"]
[800.408419, "o", "\u001b[?2004l\r\n"]
[800.465907, "o", "\u001b[?2004h> s=p.read_text(encoding='utf-8')\r\n"]
[800.523395, "o", "\u001b[?2004l\r\n"]
[800.580884, "o", "\u001b[?2004h> # Find start of hash_array function and insertion point after docstring\r\n"]
[800.638372, "o", "\u001b[?2004l\r\n"]
[800.69586, "o", "\u001b[?2004h> m=re.search(r'^def\\s+hash_array\\s*\\(.*?\\):', s, flags=re.M)\r\n"]
[800.753349, "o", "\u001b[?2004l\r\n"]
[800.810837, "o", "\u001b[?2004h> assert m, 'hash_array not found'\r\n"]
[800.868326, "o", "\u001b[?2004l\r\n"]
[800.925814, "o", "\u001b[?2004h> insert_at = s.find('\\n', m.end()) + 1\r\n"]
[800.983302, "o", "\u001b[?2004l\r\n"]
[801.040791, "o", "\u001b[?2004h> if s[insert_at:insert_at+3] in ('\"\"\"', \"'''\"):\r\n"]
[801.098279, "o", "\u001b[?2004l\r\n"]
[801.155767, "o", "\u001b[?2004h>     q = s[insert_at]\r\n"]
[801.213256, "o", "\u001b[?2004l\r\n"]
[801.270744, "o", "\u001b[?2004h>     enddoc = s.find(q*3, insert_at+3)\r\n"]
[801.328233, "o", "\u001b[?2004l\r\n"]
[801.385721, "o", "\u001b[?2004h>     insert_at = enddoc + 3\r\n"]
[801.443209, "o", "\u001b[?2004l\r\n"]
[801.500698, "o", "\u001b[?2004h> fastpath = (\r\n"]
[801.558186, "o", "\u001b[?2004l\r\n"]
[801.615674, "o", "\u001b[?2004h>     '\\n'\r\n"]
[801.673163, "o", "\u001b[?2004l\r\n"]
[801.730651, "o", "\u001b[?2004h>     '    # Fast path: factorize object-dtype arrays and hash uniques once, remap to original\\n'\r\n"]
[801.78814, "o", "\u001b[?2004l\r\n"]
[801.845628, "o", "\u001b[?2004h>     '    try:\\n'\r\n"]
[801.903116, "o", "\u001b[?2004l\r\n"]
[801.960605, "o", "\u001b[?2004h>     '        from pandas.core.dtypes.common import is_object_dtype\\n'\r\n"]
[802.018093, "o", "\u001b[?2004l\r\n"]
[802.075581, "o", "\u001b[?2004h>     '        import numpy as np\\n'\r\n"]
[802.13307, "o", "\u001b[?2004l\r\n"]
[802.190558, "o", "\u001b[?2004h>     '        import pandas as pd\\n'\r\n"]
[802.248047, "o", "\u001b[?2004l\r\n"]
[802.305535, "o", "\u001b[?2004h>     '        if is_object_dtype(values) and not categorize:\\n'\r\n"]
[802.363023, "o", "\u001b[?2004l\r\n"]
[802.420512, "o", "\u001b[?2004h>     '            from pandas._libs.hashing import hash_object_array\\n'\r\n"]
[802.478, "o", "\u001b[?2004l\r\n"]
[802.535488, "o", "\u001b[?2004h>     '            codes, uniques = pd.factorize(values, sort=False)\\n'\r\n"]
[802.592977, "o", "\u001b[?2004l\r\n"]
[802.650465, "o", "\u001b[?2004h>     '            uhash = hash_object_array(uniques, hash_key, encoding)\\n'\r\n"]
[802.707953, "o", "\u001b[?2004l\r\n"]
[802.765442, "o", "\u001b[?2004h>     '            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\\n'\r\n"]
[802.82293, "o", "\u001b[?2004l\r\n"]
[802.880419, "o", "\u001b[?2004h>     '            mask = codes == -1\\n'\r\n"]
[802.937907, "o", "\u001b[?2004l\r\n"]
[802.995395, "o", "\u001b[?2004h>     '            if mask.any():\\n'\r\n"]
[803.052884, "o", "\u001b[?2004l\r\n"]
[803.110372, "o", "\u001b[?2004h>     '                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\\n'\r\n"]
[803.16786, "o", "\u001b[?2004l\r\n"]
[803.225349, "o", "\u001b[?2004h>     '                res = res.copy()\\n'\r\n"]
[803.282837, "o", "\u001b[?2004l\r\n"]
[803.340326, "o", "\u001b[?2004h>     '                res[mask] = na_hash\\n'\r\n"]
[803.397814, "o", "\u001b[?2004l\r\n"]
[803.455302, "o", "\u001b[?2004h>     '            return res\\n'\r\n"]
[803.512791, "o", "\u001b[?2004l\r\n"]
[803.570279, "o", "\u001b[?2004h>     '    except Exception:\\n'\r\n"]
[803.627767, "o", "\u001b[?2004l\r\n"]
[803.685256, "o", "\u001b[?2004h>     '        # Fall back to original implementation below on any error\\n'\r\n"]
[803.742744, "o", "\u001b[?2004l\r\n"]
[803.800233, "o", "\u001b[?2004h>     '        pass\\n'\r\n"]
[803.857721, "o", "\u001b[?2004l\r\n"]
[803.915209, "o", "\u001b[?2004h> )\r\n"]
[803.972698, "o", "\u001b[?2004l\r\n"]
[804.030186, "o", "\u001b[?2004h> if 'Fast path: factorize object-dtype arrays' not in s:\r\n"]
[804.087674, "o", "\u001b[?2004l\r\n"]
[804.145163, "o", "\u001b[?2004h>     s = s[:insert_at] + fastpath + s[insert_at:]\r\n"]
[804.202651, "o", "\u001b[?2004l\r\n"]
[804.26014, "o", "\u001b[?2004h>     p.write_text(s, encoding='utf-8')\r\n"]
[804.317628, "o", "\u001b[?2004l\r\n"]
[804.375116, "o", "\u001b[?2004h>     print('Inserted safe fast path into hash_array')\r\n"]
[804.432605, "o", "\u001b[?2004l\r\n"]
[804.490093, "o", "\u001b[?2004h> else:\r\n"]
[804.547581, "o", "\u001b[?2004l\r\n"]
[804.60507, "o", "\u001b[?2004h>     print('Fast path already present; no changes made')\r\n"]
[804.662558, "o", "\u001b[?2004l\r\n"]
[804.720047, "o", "\u001b[?2004h> PY\r\n"]
[804.777535, "o", "\u001b[?2004l\r\n"]
[804.835023, "o", "Traceback (most recent call last):\r\n"]
[804.892512, "o", "  File \"<stdin>\", line 7, in <module>\r\n"]
[805.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[805.002, "i", "python -m pyflakes pandas/core/util/hashing.py 2>/dev/null || true\r"]
[805.004, "o", "python -m pyflakes pandas/core/util/hashing.py 2>/dev/null || true\r\n"]
[805.006, "o", "\u001b[?2004l\r\n"]
[810.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[810.002, "i", "git config user.email optimization@example.com && git config user.name Optimizer\r"]
[810.004, "o", "git config user.email optimization@example.com && git config user.name Optimizer\r\n"]
[810.006, "o", "\u001b[?2004l\r\n"]
[815.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[815.002, "i", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): add early factorize-based fast path in hash_array\r"]
[815.004, "o", "git add pandas/core/util/hashing.py && git commit -m \"perf(hash): add early factorize-based fast path in hash_array\r\n"]
[816.242, "o", "y for object dtype; avoid interfering with existing try/except\"\r\n"]
[817.478, "o", "\u001b[?2004l\r\n"]
[818.714, "o", "On branch opt/hash-string-memo\r\n"]
[820.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[820.002, "i", "cd asv_bench\r"]
[820.004, "o", "cd asv_bench\r\n"]
[820.006, "o", "\u001b[?2004l\r\n"]
[825.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[825.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[825.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[825.10488, "o", "\u001b[?2004l\r\n"]
[825.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[825.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp10y0lg56/result.json (exit status 1)\u001b[0m\r\n"]
[825.40152, "o", "   STDOUT -------->\r\n"]
[825.5004, "o", "   \r\n"]
[825.59928, "o", "   STDERR -------->\r\n"]
[825.69816, "o", "   Traceback (most recent call last):\r\n"]
[825.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[825.89592, "o", "       main()\r\n"]
[825.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[826.09368, "o", "       commands[mode](args)\r\n"]
[826.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[826.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[826.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[826.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[826.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[826.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[826.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[826.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[826.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[827.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[827.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[827.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[827.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[827.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[827.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[827.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[827.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[827.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[827.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[828.07128, "o", "       import pandas as pd\r\n"]
[828.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[828.26904, "o", "       from pandas.core.api import (\r\n"]
[828.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[828.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[828.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[828.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[828.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[828.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[828.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[829.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[829.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[829.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[829.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 335\r\n"]
[829.4556, "o", "       if is_object_dtype(values) and not categorize:\r\n"]
[829.55448, "o", "       ^^\r\n"]
[829.65336, "o", "   SyntaxError: expected 'except' or 'finally' block\r\n"]
[829.75224, "o", "\r\n"]
[829.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp10y0lg56/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[830.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[830.002, "i", "cd /workspace/repo\r"]
[830.004, "o", "cd /workspace/repo\r\n"]
[830.006, "o", "\u001b[?2004l\r\n"]
[835.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[835.002, "i", "nl -ba pandas/core/util/hashing.py | sed -n '300,360p'\r"]
[835.004, "o", "nl -ba pandas/core/util/hashing.py | sed -n '300,360p'\r\n"]
[835.085742, "o", "\u001b[?2004l\r\n"]
[835.165484, "o", "   300\t\r\n"]
[835.245226, "o", "   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[835.324968, "o", "   302\t    if np.issubdtype(dtype, np.complex128):\r\n"]
[835.40471, "o", "   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[835.484452, "o", "   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[835.564194, "o", "   305\t        return hash_real + 23 * hash_imag\r\n"]
[835.643935, "o", "   306\t\r\n"]
[835.723677, "o", "   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[835.803419, "o", "   308\t    # manage it.\r\n"]
[835.883161, "o", "   309\t    if dtype == bool:\r\n"]
[835.962903, "o", "   310\t        vals = vals.astype(\"u8\")\r\n"]
[836.042645, "o", "   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[836.122387, "o", "   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[836.202129, "o", "   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[836.281871, "o", "   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[836.361613, "o", "   315\t    else:\r\n"]
[836.441355, "o", "   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[836.521097, "o", "   317\t        # then hash and rename categories. We allow skipping the categorization\r\n"]
[836.600839, "o", "   318\t        # when the values are known/likely to be unique.\r\n"]
[836.680581, "o", "   319\t        if categorize:\r\n"]
[836.760323, "o", "   320\t            from pandas import (\r\n"]
[836.840065, "o", "   321\t                Categorical,\r\n"]
[836.919806, "o", "   322\t                Index,\r\n"]
[836.999548, "o", "   323\t                factorize,\r\n"]
[837.07929, "o", "   324\t            )\r\n"]
[837.159032, "o", "   325\t\r\n"]
[837.238774, "o", "   326\t            codes, categories = factorize(vals, sort=False)\r\n"]
[837.318516, "o", "   327\t            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[837.398258, "o", "   328\t            cat = Categorical._simple_new(codes, dtype)\r\n"]
[837.478, "o", "   329\t            return cat._hash_pandas_object(\r\n"]
[837.557742, "o", "   330\t                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[837.637484, "o", "   331\t            )\r\n"]
[837.717226, "o", "   332\t\r\n"]
[837.796968, "o", "   333\t        try:\r\n"]
[837.87671, "o", "   334\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[837.956452, "o", "   335\t        if is_object_dtype(values) and not categorize:\r\n"]
[838.036194, "o", "   336\t            import numpy as np\r\n"]
[838.115935, "o", "   337\t            import pandas as pd\r\n"]
[838.195677, "o", "   338\t            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[838.275419, "o", "   339\t            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[838.355161, "o", "   340\t            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[838.434903, "o", "   341\t            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[838.514645, "o", "   342\t            mask = codes == -1\r\n"]
[838.594387, "o", "   343\t            if mask.any():\r\n"]
[838.674129, "o", "   344\t                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[838.753871, "o", "   345\t                res = res.copy()\r\n"]
[838.833613, "o", "   346\t                res[mask] = na_hash\r\n"]
[838.913355, "o", "   347\t            return res\r\n"]
[838.993097, "o", "   348\t        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[839.072839, "o", "   349\t        except TypeError:\r\n"]
[839.152581, "o", "   350\t            # we have mixed types\r\n"]
[839.232323, "o", "   351\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[839.312065, "o", "   352\t            if is_object_dtype(values) and not categorize:\r\n"]
[839.391806, "o", "   353\t                import numpy as np\r\n"]
[839.471548, "o", "   354\t                import pandas as pd\r\n"]
[839.55129, "o", "   355\t                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[839.631032, "o", "   356\t                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[839.710774, "o", "   357\t                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[839.790516, "o", "   358\t                mask = codes == -1\r\n"]
[839.870258, "o", "   359\t                if mask.any():\r\n"]
[840.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[840.002, "i", "git status -s\r"]
[840.004, "o", "git status -s\r\n"]
[840.006, "o", "\u001b[?2004l\r\n"]
[845.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[845.002, "i", "git restore -- pandas/core/util/hashing.py\r"]
[845.004, "o", "git restore -- pandas/core/util/hashing.py\r\n"]
[845.006, "o", "\u001b[?2004l\r\n"]
[850.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[850.002, "i", "sed -n '1,220p' pandas/core/util/hashing.py\r"]
[850.004, "o", "sed -n '1,220p' pandas/core/util/hashing.py\r\n"]
[850.028371, "o", "\u001b[?2004l\r\n"]
[850.050742, "o", "\"\"\"\r\n"]
[850.073113, "o", "data hash pandas / numpy objects\r\n"]
[850.095484, "o", "\"\"\"\r\n"]
[850.117855, "o", "\r\n"]
[850.140226, "o", "from __future__ import annotations\r\n"]
[850.162597, "o", "\r\n"]
[850.184968, "o", "import itertools\r\n"]
[850.207339, "o", "from typing import TYPE_CHECKING\r\n"]
[850.22971, "o", "\r\n"]
[850.252081, "o", "import numpy as np\r\n"]
[850.274452, "o", "\r\n"]
[850.296824, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[850.319195, "o", "\r\n"]
[850.341566, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[850.363937, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[850.386308, "o", "from pandas.core.dtypes.generic import (\r\n"]
[850.408679, "o", "    ABCDataFrame,\r\n"]
[850.43105, "o", "    ABCExtensionArray,\r\n"]
[850.453421, "o", "    ABCIndex,\r\n"]
[850.475792, "o", "    ABCMultiIndex,\r\n"]
[850.498163, "o", "    ABCSeries,\r\n"]
[850.520534, "o", ")\r\n"]
[850.542905, "o", "\r\n"]
[850.565276, "o", "if TYPE_CHECKING:\r\n"]
[850.587647, "o", "    from collections.abc import (\r\n"]
[850.610018, "o", "        Hashable,\r\n"]
[850.632389, "o", "        Iterable,\r\n"]
[850.65476, "o", "        Iterator,\r\n"]
[850.677131, "o", "    )\r\n"]
[850.699502, "o", "\r\n"]
[850.721873, "o", "    from pandas._typing import (\r\n"]
[850.744244, "o", "        ArrayLike,\r\n"]
[850.766615, "o", "        npt,\r\n"]
[850.788986, "o", "    )\r\n"]
[850.811357, "o", "\r\n"]
[850.833729, "o", "    from pandas import (\r\n"]
[850.8561, "o", "        DataFrame,\r\n"]
[850.878471, "o", "        Index,\r\n"]
[850.900842, "o", "        MultiIndex,\r\n"]
[850.923213, "o", "        Series,\r\n"]
[850.945584, "o", "    )\r\n"]
[850.967955, "o", "\r\n"]
[850.990326, "o", "\r\n"]
[851.012697, "o", "# 16 byte long hashing key\r\n"]
[851.035068, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[851.057439, "o", "\r\n"]
[851.07981, "o", "\r\n"]
[851.102181, "o", "def combine_hash_arrays(\r\n"]
[851.124552, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[851.146923, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[851.169294, "o", "    \"\"\"\r\n"]
[851.191665, "o", "    Parameters\r\n"]
[851.214036, "o", "    ----------\r\n"]
[851.236407, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[851.258778, "o", "    num_items : int\r\n"]
[851.281149, "o", "\r\n"]
[851.30352, "o", "    Returns\r\n"]
[851.325891, "o", "    -------\r\n"]
[851.348262, "o", "    np.ndarray[uint64]\r\n"]
[851.370633, "o", "\r\n"]
[851.393005, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[851.415376, "o", "    \"\"\"\r\n"]
[851.437747, "o", "    try:\r\n"]
[851.460118, "o", "        first = next(arrays)\r\n"]
[851.482489, "o", "    except StopIteration:\r\n"]
[851.50486, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[851.527231, "o", "\r\n"]
[851.549602, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[851.571973, "o", "\r\n"]
[851.594344, "o", "    mult = np.uint64(1000003)\r\n"]
[851.616715, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[851.639086, "o", "    last_i = 0\r\n"]
[851.661457, "o", "    for i, a in enumerate(arrays):\r\n"]
[851.683828, "o", "        inverse_i = num_items - i\r\n"]
[851.706199, "o", "        out ^= a\r\n"]
[851.72857, "o", "        out *= mult\r\n"]
[851.750941, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[851.773312, "o", "        last_i = i\r\n"]
[851.795683, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[851.818054, "o", "    out += np.uint64(97531)\r\n"]
[851.840425, "o", "    return out\r\n"]
[851.862796, "o", "\r\n"]
[851.885167, "o", "\r\n"]
[851.907538, "o", "def hash_pandas_object(\r\n"]
[851.92991, "o", "    obj: Index | DataFrame | Series,\r\n"]
[851.952281, "o", "    index: bool = True,\r\n"]
[851.974652, "o", "    encoding: str = \"utf8\",\r\n"]
[851.997023, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[852.019394, "o", "    categorize: bool = True,\r\n"]
[852.041765, "o", ") -> Series:\r\n"]
[852.064136, "o", "    \"\"\"\r\n"]
[852.086507, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[852.108878, "o", "\r\n"]
[852.131249, "o", "    Parameters\r\n"]
[852.15362, "o", "    ----------\r\n"]
[852.175991, "o", "    obj : Index, Series, or DataFrame\r\n"]
[852.198362, "o", "    index : bool, default True\r\n"]
[852.220733, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[852.243104, "o", "    encoding : str, default 'utf8'\r\n"]
[852.265475, "o", "        Encoding for data & key when strings.\r\n"]
[852.287846, "o", "    hash_key : str, default _default_hash_key\r\n"]
[852.310217, "o", "        Hash_key for string key to encode.\r\n"]
[852.332588, "o", "    categorize : bool, default True\r\n"]
[852.354959, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[852.37733, "o", "        efficient when the array contains duplicate values.\r\n"]
[852.399701, "o", "\r\n"]
[852.422072, "o", "    Returns\r\n"]
[852.444443, "o", "    -------\r\n"]
[852.466814, "o", "    Series of uint64\r\n"]
[852.489186, "o", "        Same length as the object.\r\n"]
[852.511557, "o", "\r\n"]
[852.533928, "o", "    Examples\r\n"]
[852.556299, "o", "    --------\r\n"]
[852.57867, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[852.601041, "o", "    0    14639053686158035780\r\n"]
[852.623412, "o", "    1     3869563279212530728\r\n"]
[852.645783, "o", "    2      393322362522515241\r\n"]
[852.668154, "o", "    dtype: uint64\r\n"]
[852.690525, "o", "    \"\"\"\r\n"]
[852.712896, "o", "    from pandas import Series\r\n"]
[852.735267, "o", "\r\n"]
[852.757638, "o", "    if hash_key is None:\r\n"]
[852.780009, "o", "        hash_key = _default_hash_key\r\n"]
[852.80238, "o", "\r\n"]
[852.824751, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[852.847122, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[852.869493, "o", "\r\n"]
[852.891864, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[852.914235, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[852.936606, "o", "            \"uint64\", copy=False\r\n"]
[852.958977, "o", "        )\r\n"]
[852.981348, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[853.003719, "o", "\r\n"]
[853.02609, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[853.048462, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[853.070833, "o", "            \"uint64\", copy=False\r\n"]
[853.093204, "o", "        )\r\n"]
[853.115575, "o", "        if index:\r\n"]
[853.137946, "o", "            index_iter = (\r\n"]
[853.160317, "o", "                hash_pandas_object(\r\n"]
[853.182688, "o", "                    obj.index,\r\n"]
[853.205059, "o", "                    index=False,\r\n"]
[853.22743, "o", "                    encoding=encoding,\r\n"]
[853.249801, "o", "                    hash_key=hash_key,\r\n"]
[853.272172, "o", "                    categorize=categorize,\r\n"]
[853.294543, "o", "                )._values\r\n"]
[853.316914, "o", "                for _ in [None]\r\n"]
[853.339285, "o", "            )\r\n"]
[853.361656, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[853.384027, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[853.406398, "o", "\r\n"]
[853.428769, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[853.45114, "o", "\r\n"]
[853.473511, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[853.495882, "o", "        hashes = (\r\n"]
[853.518253, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[853.540624, "o", "            for _, series in obj.items()\r\n"]
[853.562995, "o", "        )\r\n"]
[853.585367, "o", "        num_items = len(obj.columns)\r\n"]
[853.607738, "o", "        if index:\r\n"]
[853.630109, "o", "            index_hash_generator = (\r\n"]
[853.65248, "o", "                hash_pandas_object(\r\n"]
[853.674851, "o", "                    obj.index,\r\n"]
[853.697222, "o", "                    index=False,\r\n"]
[853.719593, "o", "                    encoding=encoding,\r\n"]
[853.741964, "o", "                    hash_key=hash_key,\r\n"]
[853.764335, "o", "                    categorize=categorize,\r\n"]
[853.786706, "o", "                )._values\r\n"]
[853.809077, "o", "                for _ in [None]\r\n"]
[853.831448, "o", "            )\r\n"]
[853.853819, "o", "            num_items += 1\r\n"]
[853.87619, "o", "\r\n"]
[853.898561, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[853.920932, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[853.943303, "o", "            hashes = (x for x in _hashes)\r\n"]
[853.965674, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[853.988045, "o", "\r\n"]
[854.010416, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[854.032787, "o", "    else:\r\n"]
[854.055158, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[854.077529, "o", "\r\n"]
[854.0999, "o", "    return ser\r\n"]
[854.122271, "o", "\r\n"]
[854.144643, "o", "\r\n"]
[854.167014, "o", "def hash_tuples(\r\n"]
[854.189385, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[854.211756, "o", "    encoding: str = \"utf8\",\r\n"]
[854.234127, "o", "    hash_key: str = _default_hash_key,\r\n"]
[854.256498, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[854.278869, "o", "    \"\"\"\r\n"]
[854.30124, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[854.323611, "o", "\r\n"]
[854.345982, "o", "    Parameters\r\n"]
[854.368353, "o", "    ----------\r\n"]
[854.390724, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[854.413095, "o", "    encoding : str, default 'utf8'\r\n"]
[854.435466, "o", "    hash_key : str, default _default_hash_key\r\n"]
[854.457837, "o", "\r\n"]
[854.480208, "o", "    Returns\r\n"]
[854.502579, "o", "    -------\r\n"]
[854.52495, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[854.547321, "o", "    \"\"\"\r\n"]
[854.569692, "o", "    if not is_list_like(vals):\r\n"]
[854.592063, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[854.614434, "o", "\r\n"]
[854.636805, "o", "    from pandas import (\r\n"]
[854.659176, "o", "        Categorical,\r\n"]
[854.681548, "o", "        MultiIndex,\r\n"]
[854.703919, "o", "    )\r\n"]
[854.72629, "o", "\r\n"]
[854.748661, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[854.771032, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[854.793403, "o", "    else:\r\n"]
[854.815774, "o", "        mi = vals\r\n"]
[854.838145, "o", "\r\n"]
[854.860516, "o", "    # create a list-of-Categoricals\r\n"]
[854.882887, "o", "    cat_vals = [\r\n"]
[854.905258, "o", "        Categorical._simple_new(\r\n"]
[854.927629, "o", "            mi.codes[level],\r\n"]
[855.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[855.002, "i", "sed -n '220,440p' pandas/core/util/hashing.py\r"]
[855.004, "o", "sed -n '220,440p' pandas/core/util/hashing.py\r\n"]
[855.037692, "o", "\u001b[?2004l\r\n"]
[855.069385, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[855.101077, "o", "        )\r\n"]
[855.132769, "o", "        for level in range(mi.nlevels)\r\n"]
[855.164462, "o", "    ]\r\n"]
[855.196154, "o", "\r\n"]
[855.227846, "o", "    # hash the list-of-ndarrays\r\n"]
[855.259538, "o", "    hashes = (\r\n"]
[855.291231, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[855.322923, "o", "        for cat in cat_vals\r\n"]
[855.354615, "o", "    )\r\n"]
[855.386308, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[855.418, "o", "\r\n"]
[855.449692, "o", "    return h\r\n"]
[855.481385, "o", "\r\n"]
[855.513077, "o", "\r\n"]
[855.544769, "o", "def hash_array(\r\n"]
[855.576462, "o", "    vals: ArrayLike,\r\n"]
[855.608154, "o", "    encoding: str = \"utf8\",\r\n"]
[855.639846, "o", "    hash_key: str = _default_hash_key,\r\n"]
[855.671538, "o", "    categorize: bool = True,\r\n"]
[855.703231, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[855.734923, "o", "    \"\"\"\r\n"]
[855.766615, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[855.798308, "o", "\r\n"]
[855.83, "o", "    Parameters\r\n"]
[855.861692, "o", "    ----------\r\n"]
[855.893385, "o", "    vals : ndarray or ExtensionArray\r\n"]
[855.925077, "o", "        The input array to hash.\r\n"]
[855.956769, "o", "    encoding : str, default 'utf8'\r\n"]
[855.988462, "o", "        Encoding for data & key when strings.\r\n"]
[856.020154, "o", "    hash_key : str, default _default_hash_key\r\n"]
[856.051846, "o", "        Hash_key for string key to encode.\r\n"]
[856.083538, "o", "    categorize : bool, default True\r\n"]
[856.115231, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[856.146923, "o", "        efficient when the array contains duplicate values.\r\n"]
[856.178615, "o", "\r\n"]
[856.210308, "o", "    Returns\r\n"]
[856.242, "o", "    -------\r\n"]
[856.273692, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[856.305385, "o", "        Hashed values, same length as the vals.\r\n"]
[856.337077, "o", "\r\n"]
[856.368769, "o", "    See Also\r\n"]
[856.400462, "o", "    --------\r\n"]
[856.432154, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[856.463846, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[856.495538, "o", "\r\n"]
[856.527231, "o", "    Examples\r\n"]
[856.558923, "o", "    --------\r\n"]
[856.590615, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[856.622308, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[856.654, "o", "      dtype=uint64)\r\n"]
[856.685692, "o", "    \"\"\"\r\n"]
[856.717385, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[856.749077, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[856.780769, "o", "\r\n"]
[856.812462, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[856.844154, "o", "        return vals._hash_pandas_object(\r\n"]
[856.875846, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[856.907538, "o", "        )\r\n"]
[856.939231, "o", "\r\n"]
[856.970923, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[857.002615, "o", "        # GH#42003\r\n"]
[857.034308, "o", "        raise TypeError(\r\n"]
[857.066, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[857.097692, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[857.129385, "o", "        )\r\n"]
[857.161077, "o", "\r\n"]
[857.192769, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[857.224462, "o", "\r\n"]
[857.256154, "o", "\r\n"]
[857.287846, "o", "def _hash_ndarray(\r\n"]
[857.319538, "o", "    vals: np.ndarray,\r\n"]
[857.351231, "o", "    encoding: str = \"utf8\",\r\n"]
[857.382923, "o", "    hash_key: str = _default_hash_key,\r\n"]
[857.414615, "o", "    categorize: bool = True,\r\n"]
[857.446308, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[857.478, "o", "    \"\"\"\r\n"]
[857.509692, "o", "    See hash_array.__doc__.\r\n"]
[857.541385, "o", "    \"\"\"\r\n"]
[857.573077, "o", "    dtype = vals.dtype\r\n"]
[857.604769, "o", "\r\n"]
[857.636462, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[857.668154, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[857.699846, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[857.731538, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[857.763231, "o", "        return hash_real + 23 * hash_imag\r\n"]
[857.794923, "o", "\r\n"]
[857.826615, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[857.858308, "o", "    # manage it.\r\n"]
[857.89, "o", "    if dtype == bool:\r\n"]
[857.921692, "o", "        vals = vals.astype(\"u8\")\r\n"]
[857.953385, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[857.985077, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[858.016769, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[858.048462, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[858.080154, "o", "    else:\r\n"]
[858.111846, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[858.143538, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[858.175231, "o", "        # when the values are known/likely to be unique.\r\n"]
[858.206923, "o", "        if categorize:\r\n"]
[858.238615, "o", "            from pandas import (\r\n"]
[858.270308, "o", "                Categorical,\r\n"]
[858.302, "o", "                Index,\r\n"]
[858.333692, "o", "                factorize,\r\n"]
[858.365385, "o", "            )\r\n"]
[858.397077, "o", "\r\n"]
[858.428769, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[858.460462, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[858.492154, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[858.523846, "o", "            return cat._hash_pandas_object(\r\n"]
[858.555538, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[858.587231, "o", "            )\r\n"]
[858.618923, "o", "\r\n"]
[858.650615, "o", "        try:\r\n"]
[858.682308, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[858.714, "o", "        if is_object_dtype(values) and not categorize:\r\n"]
[858.745692, "o", "            import numpy as np\r\n"]
[858.777385, "o", "            import pandas as pd\r\n"]
[858.809077, "o", "            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[858.840769, "o", "            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[858.872462, "o", "            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[858.904154, "o", "            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[858.935846, "o", "            mask = codes == -1\r\n"]
[858.967538, "o", "            if mask.any():\r\n"]
[858.999231, "o", "                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[859.030923, "o", "                res = res.copy()\r\n"]
[859.062615, "o", "                res[mask] = na_hash\r\n"]
[859.094308, "o", "            return res\r\n"]
[859.126, "o", "        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[859.157692, "o", "        except TypeError:\r\n"]
[859.189385, "o", "            # we have mixed types\r\n"]
[859.221077, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[859.252769, "o", "            if is_object_dtype(values) and not categorize:\r\n"]
[859.284462, "o", "                import numpy as np\r\n"]
[859.316154, "o", "                import pandas as pd\r\n"]
[859.347846, "o", "                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[859.379538, "o", "                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[859.411231, "o", "                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[859.442923, "o", "                mask = codes == -1\r\n"]
[859.474615, "o", "                if mask.any():\r\n"]
[859.506308, "o", "                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[859.538, "o", "                    res = res.copy()\r\n"]
[859.569692, "o", "                    res[mask] = na_hash\r\n"]
[859.601385, "o", "                return res\r\n"]
[859.633077, "o", "            vals = hash_object_array(\r\n"]
[859.664769, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[859.696462, "o", "            )\r\n"]
[859.728154, "o", "\r\n"]
[859.759846, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[859.791538, "o", "    vals ^= vals >> 30\r\n"]
[859.823231, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[859.854923, "o", "    vals ^= vals >> 27\r\n"]
[859.886615, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[859.918308, "o", "    vals ^= vals >> 31\r\n"]
[860.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[860.002, "i", "cd asv_bench\r"]
[860.004, "o", "cd asv_bench\r\n"]
[860.006, "o", "\u001b[?2004l\r\n"]
[865.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[865.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[865.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[865.10488, "o", "\u001b[?2004l\r\n"]
[865.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[865.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpopq_70zb/result.json (exit status 1)\u001b[0m\r\n"]
[865.40152, "o", "   STDOUT -------->\r\n"]
[865.5004, "o", "   \r\n"]
[865.59928, "o", "   STDERR -------->\r\n"]
[865.69816, "o", "   Traceback (most recent call last):\r\n"]
[865.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[865.89592, "o", "       main()\r\n"]
[865.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[866.09368, "o", "       commands[mode](args)\r\n"]
[866.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[866.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[866.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[866.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[866.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[866.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[866.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[866.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[866.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[867.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[867.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[867.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[867.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[867.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[867.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[867.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[867.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[867.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[867.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[868.07128, "o", "       import pandas as pd\r\n"]
[868.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[868.26904, "o", "       from pandas.core.api import (\r\n"]
[868.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[868.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[868.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[868.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[868.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[868.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[868.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[869.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[869.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[869.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[869.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 335\r\n"]
[869.4556, "o", "       if is_object_dtype(values) and not categorize:\r\n"]
[869.55448, "o", "       ^^\r\n"]
[869.65336, "o", "   SyntaxError: expected 'except' or 'finally' block\r\n"]
[869.75224, "o", "\r\n"]
[869.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpopq_70zb/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[870.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[870.002, "i", "cd /workspace/repo\r"]
[870.004, "o", "cd /workspace/repo\r\n"]
[870.006, "o", "\u001b[?2004l\r\n"]
[875.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[875.002, "i", "nl -ba pandas/core/util/hashing.py | sed -n '300,360p'\r"]
[875.004, "o", "nl -ba pandas/core/util/hashing.py | sed -n '300,360p'\r\n"]
[875.085742, "o", "\u001b[?2004l\r\n"]
[875.165484, "o", "   300\t\r\n"]
[875.245226, "o", "   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[875.324968, "o", "   302\t    if np.issubdtype(dtype, np.complex128):\r\n"]
[875.40471, "o", "   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[875.484452, "o", "   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[875.564194, "o", "   305\t        return hash_real + 23 * hash_imag\r\n"]
[875.643935, "o", "   306\t\r\n"]
[875.723677, "o", "   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[875.803419, "o", "   308\t    # manage it.\r\n"]
[875.883161, "o", "   309\t    if dtype == bool:\r\n"]
[875.962903, "o", "   310\t        vals = vals.astype(\"u8\")\r\n"]
[876.042645, "o", "   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[876.122387, "o", "   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[876.202129, "o", "   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[876.281871, "o", "   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[876.361613, "o", "   315\t    else:\r\n"]
[876.441355, "o", "   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[876.521097, "o", "   317\t        # then hash and rename categories. We allow skipping the categorization\r\n"]
[876.600839, "o", "   318\t        # when the values are known/likely to be unique.\r\n"]
[876.680581, "o", "   319\t        if categorize:\r\n"]
[876.760323, "o", "   320\t            from pandas import (\r\n"]
[876.840065, "o", "   321\t                Categorical,\r\n"]
[876.919806, "o", "   322\t                Index,\r\n"]
[876.999548, "o", "   323\t                factorize,\r\n"]
[877.07929, "o", "   324\t            )\r\n"]
[877.159032, "o", "   325\t\r\n"]
[877.238774, "o", "   326\t            codes, categories = factorize(vals, sort=False)\r\n"]
[877.318516, "o", "   327\t            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[877.398258, "o", "   328\t            cat = Categorical._simple_new(codes, dtype)\r\n"]
[877.478, "o", "   329\t            return cat._hash_pandas_object(\r\n"]
[877.557742, "o", "   330\t                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[877.637484, "o", "   331\t            )\r\n"]
[877.717226, "o", "   332\t\r\n"]
[877.796968, "o", "   333\t        try:\r\n"]
[877.87671, "o", "   334\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[877.956452, "o", "   335\t        if is_object_dtype(values) and not categorize:\r\n"]
[878.036194, "o", "   336\t            import numpy as np\r\n"]
[878.115935, "o", "   337\t            import pandas as pd\r\n"]
[878.195677, "o", "   338\t            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[878.275419, "o", "   339\t            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[878.355161, "o", "   340\t            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[878.434903, "o", "   341\t            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[878.514645, "o", "   342\t            mask = codes == -1\r\n"]
[878.594387, "o", "   343\t            if mask.any():\r\n"]
[878.674129, "o", "   344\t                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[878.753871, "o", "   345\t                res = res.copy()\r\n"]
[878.833613, "o", "   346\t                res[mask] = na_hash\r\n"]
[878.913355, "o", "   347\t            return res\r\n"]
[878.993097, "o", "   348\t        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[879.072839, "o", "   349\t        except TypeError:\r\n"]
[879.152581, "o", "   350\t            # we have mixed types\r\n"]
[879.232323, "o", "   351\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[879.312065, "o", "   352\t            if is_object_dtype(values) and not categorize:\r\n"]
[879.391806, "o", "   353\t                import numpy as np\r\n"]
[879.471548, "o", "   354\t                import pandas as pd\r\n"]
[879.55129, "o", "   355\t                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[879.631032, "o", "   356\t                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[879.710774, "o", "   357\t                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[879.790516, "o", "   358\t                mask = codes == -1\r\n"]
[879.870258, "o", "   359\t                if mask.any():\r\n"]
[880.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[880.002, "i", "grep -n \"from pandas.core.dtypes.common import is_object_dtype\" pandas/core/util/hashing.py || true\r"]
[880.004, "o", "grep -n \"from pandas.core.dtypes.common import is_object_dtype\" pandas/core/util/hashing.py || true\r\n"]
[881.654, "o", "\u001b[?2004l\r\n"]
[883.302, "o", "\u001b[32m\u001b[K334\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K            \u001b[01;31m\u001b[Kfrom pandas.core.dtypes.common import is_object_dtype\u001b[m\u001b[K\r\n"]
[885.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[885.002, "i", "python - << 'PY'\r"]
[885.004, "o", "python - << 'PY'\r\n"]
[885.092737, "o", "\u001b[?2004l\r\n"]
[885.179474, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[885.266211, "o", "\u001b[?2004l\r\n"]
[885.352947, "o", "\u001b[?2004h> import re\r\n"]
[885.439684, "o", "\u001b[?2004l\r\n"]
[885.526421, "o", "\u001b[?2004h> p = Path('pandas/core/util/hashing.py')\r\n"]
[885.613158, "o", "\u001b[?2004l\r\n"]
[885.699895, "o", "\u001b[?2004h> s = p.read_text(encoding='utf-8')\r\n"]
[885.786632, "o", "\u001b[?2004l\r\n"]
[885.873368, "o", "\u001b[?2004h> # Try to remove the malformed injected fast path block that starts with a try: and is_object_dtype import\r\n"]
[885.960105, "o", "\u001b[?2004l\r\n"]
[886.046842, "o", "\u001b[?2004h> pat = re.compile(r\"\\n\\s*try:\\n\\s*from pandas\\.core\\.dtypes\\.common import is_object_dtype[\\s\\S]*?\\n\\s*except\\s+Exception:\\n\\s*# Fall back to.*?\\n\\s*pass\\n\", re\r\n"]
[886.133579, "o", "e.M)\r\n"]
[886.220316, "o", "\u001b[?2004l\r\n"]
[886.307053, "o", "\u001b[?2004h> new, n = pat.subn('\\n', s)\r\n"]
[886.393789, "o", "\u001b[?2004l\r\n"]
[886.480526, "o", "\u001b[?2004h> if n == 0:\r\n"]
[886.567263, "o", "\u001b[?2004l\r\n"]
[886.654, "o", "\u001b[?2004h>     # fallback: remove from 'try:' to the first 'return res' after it if no except present\r\n"]
[886.740737, "o", "\u001b[?2004l\r\n"]
[886.827474, "o", "\u001b[?2004h>     m = re.search(r\"\\n\\s*try:\\n\\s*from pandas\\.core\\.dtypes\\.common import is_object_dtype\", s)\r\n"]
[886.914211, "o", "\u001b[?2004l\r\n"]
[887.000947, "o", "\u001b[?2004h>     if m:\r\n"]
[887.087684, "o", "\u001b[?2004l\r\n"]
[887.174421, "o", "\u001b[?2004h>         start = m.start()\r\n"]
[887.261158, "o", "\u001b[?2004l\r\n"]
[887.347895, "o", "\u001b[?2004h>         m2 = re.search(r\"\\n\\s*return\\s+res\\b\", s[m.end():])\r\n"]
[887.434632, "o", "\u001b[?2004l\r\n"]
[887.521368, "o", "\u001b[?2004h>         if m2:\r\n"]
[887.608105, "o", "\u001b[?2004l\r\n"]
[887.694842, "o", "\u001b[?2004h>             end = m.end() + m2.end()\r\n"]
[887.781579, "o", "\u001b[?2004l\r\n"]
[887.868316, "o", "\u001b[?2004h>             new = s[:start] + '\\n' + s[end:]\r\n"]
[887.955053, "o", "\u001b[?2004l\r\n"]
[888.041789, "o", "\u001b[?2004h>             n = 1\r\n"]
[888.128526, "o", "\u001b[?2004l\r\n"]
[888.215263, "o", "\u001b[?2004h>         else:\r\n"]
[888.302, "o", "\u001b[?2004l\r\n"]
[888.388737, "o", "\u001b[?2004h>             new = s\r\n"]
[888.475474, "o", "\u001b[?2004l\r\n"]
[888.562211, "o", "\u001b[?2004h>     else:\r\n"]
[888.648947, "o", "\u001b[?2004l\r\n"]
[888.735684, "o", "\u001b[?2004h>         new = s\r\n"]
[888.822421, "o", "\u001b[?2004l\r\n"]
[888.909158, "o", "\u001b[?2004h> if new != s:\r\n"]
[888.995895, "o", "\u001b[?2004l\r\n"]
[889.082632, "o", "\u001b[?2004h>     p.write_text(new, encoding='utf-8')\r\n"]
[889.169368, "o", "\u001b[?2004l\r\n"]
[889.256105, "o", "\u001b[?2004h>     print('Removed malformed injected fast path block(s):', n)\r\n"]
[889.342842, "o", "\u001b[?2004l\r\n"]
[889.429579, "o", "\u001b[?2004h> else:\r\n"]
[889.516316, "o", "\u001b[?2004l\r\n"]
[889.603053, "o", "\u001b[?2004h>     print('No matching injected fast path block found; no changes made')\r\n"]
[889.689789, "o", "\u001b[?2004l\r\n"]
[889.776526, "o", "\u001b[?2004h> PY\r\n"]
[889.863263, "o", "\u001b[?2004l\r\n"]
[890.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[890.002, "i", "python -m pyflakes pandas/core/util/hashing.py 2>/dev/null || true\r"]
[890.004, "o", "python -m pyflakes pandas/core/util/hashing.py 2>/dev/null || true\r\n"]
[890.006, "o", "\u001b[?2004l\r\n"]
[895.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[895.002, "i", "cd asv_bench\r"]
[895.004, "o", "cd asv_bench\r\n"]
[895.006, "o", "\u001b[?2004l\r\n"]
[900.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[900.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[900.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[900.10488, "o", "\u001b[?2004l\r\n"]
[900.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[900.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpvou1l7dw/result.json (exit status 1)\u001b[0m\r\n"]
[900.40152, "o", "   STDOUT -------->\r\n"]
[900.5004, "o", "   \r\n"]
[900.59928, "o", "   STDERR -------->\r\n"]
[900.69816, "o", "   Traceback (most recent call last):\r\n"]
[900.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[900.89592, "o", "       main()\r\n"]
[900.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[901.09368, "o", "       commands[mode](args)\r\n"]
[901.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[901.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[901.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[901.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[901.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[901.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[901.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[901.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[901.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[902.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[902.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[902.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[902.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[902.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[902.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[902.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[902.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[902.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[902.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[903.07128, "o", "       import pandas as pd\r\n"]
[903.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[903.26904, "o", "       from pandas.core.api import (\r\n"]
[903.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[903.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[903.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[903.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[903.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[903.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[903.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[904.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[904.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[904.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[904.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 334\r\n"]
[904.4556, "o", "       except TypeError:\r\n"]
[904.55448, "o", "       ^^^^^^\r\n"]
[904.65336, "o", "   SyntaxError: invalid syntax\r\n"]
[904.75224, "o", "\r\n"]
[904.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpvou1l7dw/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[905.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[905.002, "i", "cd /workspace/repo\r"]
[905.004, "o", "cd /workspace/repo\r\n"]
[905.006, "o", "\u001b[?2004l\r\n"]
[910.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[910.002, "i", "nl -ba pandas/core/util/hashing.py | sed -n '300,360p'\r"]
[910.004, "o", "nl -ba pandas/core/util/hashing.py | sed -n '300,360p'\r\n"]
[910.087049, "o", "\u001b[?2004l\r\n"]
[910.168098, "o", "   300\t\r\n"]
[910.249148, "o", "   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[910.330197, "o", "   302\t    if np.issubdtype(dtype, np.complex128):\r\n"]
[910.411246, "o", "   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[910.492295, "o", "   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[910.573344, "o", "   305\t        return hash_real + 23 * hash_imag\r\n"]
[910.654393, "o", "   306\t\r\n"]
[910.735443, "o", "   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[910.816492, "o", "   308\t    # manage it.\r\n"]
[910.897541, "o", "   309\t    if dtype == bool:\r\n"]
[910.97859, "o", "   310\t        vals = vals.astype(\"u8\")\r\n"]
[911.059639, "o", "   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[911.140689, "o", "   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[911.221738, "o", "   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[911.302787, "o", "   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[911.383836, "o", "   315\t    else:\r\n"]
[911.464885, "o", "   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[911.545934, "o", "   317\t        # then hash and rename categories. We allow skipping the categorization\r\n"]
[911.626984, "o", "   318\t        # when the values are known/likely to be unique.\r\n"]
[911.708033, "o", "   319\t        if categorize:\r\n"]
[911.789082, "o", "   320\t            from pandas import (\r\n"]
[911.870131, "o", "   321\t                Categorical,\r\n"]
[911.95118, "o", "   322\t                Index,\r\n"]
[912.03223, "o", "   323\t                factorize,\r\n"]
[912.113279, "o", "   324\t            )\r\n"]
[912.194328, "o", "   325\t\r\n"]
[912.275377, "o", "   326\t            codes, categories = factorize(vals, sort=False)\r\n"]
[912.356426, "o", "   327\t            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[912.437475, "o", "   328\t            cat = Categorical._simple_new(codes, dtype)\r\n"]
[912.518525, "o", "   329\t            return cat._hash_pandas_object(\r\n"]
[912.599574, "o", "   330\t                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[912.680623, "o", "   331\t            )\r\n"]
[912.761672, "o", "   332\t\r\n"]
[912.842721, "o", "   333\t        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[912.92377, "o", "   334\t        except TypeError:\r\n"]
[913.00482, "o", "   335\t            # we have mixed types\r\n"]
[913.085869, "o", "   336\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[913.166918, "o", "   337\t            if is_object_dtype(values) and not categorize:\r\n"]
[913.247967, "o", "   338\t                import numpy as np\r\n"]
[913.329016, "o", "   339\t                import pandas as pd\r\n"]
[913.410066, "o", "   340\t                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[913.491115, "o", "   341\t                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[913.572164, "o", "   342\t                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[913.653213, "o", "   343\t                mask = codes == -1\r\n"]
[913.734262, "o", "   344\t                if mask.any():\r\n"]
[913.815311, "o", "   345\t                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[913.896361, "o", "   346\t                    res = res.copy()\r\n"]
[913.97741, "o", "   347\t                    res[mask] = na_hash\r\n"]
[914.058459, "o", "   348\t                return res\r\n"]
[914.139508, "o", "   349\t            vals = hash_object_array(\r\n"]
[914.220557, "o", "   350\t                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[914.301607, "o", "   351\t            )\r\n"]
[914.382656, "o", "   352\t\r\n"]
[914.463705, "o", "   353\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[914.544754, "o", "   354\t    vals ^= vals >> 30\r\n"]
[914.625803, "o", "   355\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[914.706852, "o", "   356\t    vals ^= vals >> 27\r\n"]
[914.787902, "o", "   357\t    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[914.868951, "o", "   358\t    vals ^= vals >> 31\r\n"]
[915.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[915.002, "i", "git status -s\r"]
[915.004, "o", "git status -s\r\n"]
[917.478, "o", "\u001b[?2004l\r\n"]
[920.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[920.002, "i", "git restore --worktree --staged -- pandas/core/util/hashing.py || git checkout -- pandas/core/util/hashing.py\r"]
[920.004, "o", "git restore --worktree --staged -- pandas/core/util/hashing.py || git checkout -- pandas/core/util/hashing.py\r\n"]
[920.006, "o", "\u001b[?2004l\r\n"]
[925.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[925.002, "i", "sed -n '1,220p' pandas/core/util/hashing.py\r"]
[925.004, "o", "sed -n '1,220p' pandas/core/util/hashing.py\r\n"]
[925.028371, "o", "\u001b[?2004l\r\n"]
[925.050742, "o", "\"\"\"\r\n"]
[925.073113, "o", "data hash pandas / numpy objects\r\n"]
[925.095484, "o", "\"\"\"\r\n"]
[925.117855, "o", "\r\n"]
[925.140226, "o", "from __future__ import annotations\r\n"]
[925.162597, "o", "\r\n"]
[925.184968, "o", "import itertools\r\n"]
[925.207339, "o", "from typing import TYPE_CHECKING\r\n"]
[925.22971, "o", "\r\n"]
[925.252081, "o", "import numpy as np\r\n"]
[925.274452, "o", "\r\n"]
[925.296824, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[925.319195, "o", "\r\n"]
[925.341566, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[925.363937, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[925.386308, "o", "from pandas.core.dtypes.generic import (\r\n"]
[925.408679, "o", "    ABCDataFrame,\r\n"]
[925.43105, "o", "    ABCExtensionArray,\r\n"]
[925.453421, "o", "    ABCIndex,\r\n"]
[925.475792, "o", "    ABCMultiIndex,\r\n"]
[925.498163, "o", "    ABCSeries,\r\n"]
[925.520534, "o", ")\r\n"]
[925.542905, "o", "\r\n"]
[925.565276, "o", "if TYPE_CHECKING:\r\n"]
[925.587647, "o", "    from collections.abc import (\r\n"]
[925.610018, "o", "        Hashable,\r\n"]
[925.632389, "o", "        Iterable,\r\n"]
[925.65476, "o", "        Iterator,\r\n"]
[925.677131, "o", "    )\r\n"]
[925.699502, "o", "\r\n"]
[925.721873, "o", "    from pandas._typing import (\r\n"]
[925.744244, "o", "        ArrayLike,\r\n"]
[925.766615, "o", "        npt,\r\n"]
[925.788986, "o", "    )\r\n"]
[925.811357, "o", "\r\n"]
[925.833729, "o", "    from pandas import (\r\n"]
[925.8561, "o", "        DataFrame,\r\n"]
[925.878471, "o", "        Index,\r\n"]
[925.900842, "o", "        MultiIndex,\r\n"]
[925.923213, "o", "        Series,\r\n"]
[925.945584, "o", "    )\r\n"]
[925.967955, "o", "\r\n"]
[925.990326, "o", "\r\n"]
[926.012697, "o", "# 16 byte long hashing key\r\n"]
[926.035068, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[926.057439, "o", "\r\n"]
[926.07981, "o", "\r\n"]
[926.102181, "o", "def combine_hash_arrays(\r\n"]
[926.124552, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[926.146923, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[926.169294, "o", "    \"\"\"\r\n"]
[926.191665, "o", "    Parameters\r\n"]
[926.214036, "o", "    ----------\r\n"]
[926.236407, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[926.258778, "o", "    num_items : int\r\n"]
[926.281149, "o", "\r\n"]
[926.30352, "o", "    Returns\r\n"]
[926.325891, "o", "    -------\r\n"]
[926.348262, "o", "    np.ndarray[uint64]\r\n"]
[926.370633, "o", "\r\n"]
[926.393005, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[926.415376, "o", "    \"\"\"\r\n"]
[926.437747, "o", "    try:\r\n"]
[926.460118, "o", "        first = next(arrays)\r\n"]
[926.482489, "o", "    except StopIteration:\r\n"]
[926.50486, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[926.527231, "o", "\r\n"]
[926.549602, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[926.571973, "o", "\r\n"]
[926.594344, "o", "    mult = np.uint64(1000003)\r\n"]
[926.616715, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[926.639086, "o", "    last_i = 0\r\n"]
[926.661457, "o", "    for i, a in enumerate(arrays):\r\n"]
[926.683828, "o", "        inverse_i = num_items - i\r\n"]
[926.706199, "o", "        out ^= a\r\n"]
[926.72857, "o", "        out *= mult\r\n"]
[926.750941, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[926.773312, "o", "        last_i = i\r\n"]
[926.795683, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[926.818054, "o", "    out += np.uint64(97531)\r\n"]
[926.840425, "o", "    return out\r\n"]
[926.862796, "o", "\r\n"]
[926.885167, "o", "\r\n"]
[926.907538, "o", "def hash_pandas_object(\r\n"]
[926.92991, "o", "    obj: Index | DataFrame | Series,\r\n"]
[926.952281, "o", "    index: bool = True,\r\n"]
[926.974652, "o", "    encoding: str = \"utf8\",\r\n"]
[926.997023, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[927.019394, "o", "    categorize: bool = True,\r\n"]
[927.041765, "o", ") -> Series:\r\n"]
[927.064136, "o", "    \"\"\"\r\n"]
[927.086507, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[927.108878, "o", "\r\n"]
[927.131249, "o", "    Parameters\r\n"]
[927.15362, "o", "    ----------\r\n"]
[927.175991, "o", "    obj : Index, Series, or DataFrame\r\n"]
[927.198362, "o", "    index : bool, default True\r\n"]
[927.220733, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[927.243104, "o", "    encoding : str, default 'utf8'\r\n"]
[927.265475, "o", "        Encoding for data & key when strings.\r\n"]
[927.287846, "o", "    hash_key : str, default _default_hash_key\r\n"]
[927.310217, "o", "        Hash_key for string key to encode.\r\n"]
[927.332588, "o", "    categorize : bool, default True\r\n"]
[927.354959, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[927.37733, "o", "        efficient when the array contains duplicate values.\r\n"]
[927.399701, "o", "\r\n"]
[927.422072, "o", "    Returns\r\n"]
[927.444443, "o", "    -------\r\n"]
[927.466814, "o", "    Series of uint64\r\n"]
[927.489186, "o", "        Same length as the object.\r\n"]
[927.511557, "o", "\r\n"]
[927.533928, "o", "    Examples\r\n"]
[927.556299, "o", "    --------\r\n"]
[927.57867, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[927.601041, "o", "    0    14639053686158035780\r\n"]
[927.623412, "o", "    1     3869563279212530728\r\n"]
[927.645783, "o", "    2      393322362522515241\r\n"]
[927.668154, "o", "    dtype: uint64\r\n"]
[927.690525, "o", "    \"\"\"\r\n"]
[927.712896, "o", "    from pandas import Series\r\n"]
[927.735267, "o", "\r\n"]
[927.757638, "o", "    if hash_key is None:\r\n"]
[927.780009, "o", "        hash_key = _default_hash_key\r\n"]
[927.80238, "o", "\r\n"]
[927.824751, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[927.847122, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[927.869493, "o", "\r\n"]
[927.891864, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[927.914235, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[927.936606, "o", "            \"uint64\", copy=False\r\n"]
[927.958977, "o", "        )\r\n"]
[927.981348, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[928.003719, "o", "\r\n"]
[928.02609, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[928.048462, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[928.070833, "o", "            \"uint64\", copy=False\r\n"]
[928.093204, "o", "        )\r\n"]
[928.115575, "o", "        if index:\r\n"]
[928.137946, "o", "            index_iter = (\r\n"]
[928.160317, "o", "                hash_pandas_object(\r\n"]
[928.182688, "o", "                    obj.index,\r\n"]
[928.205059, "o", "                    index=False,\r\n"]
[928.22743, "o", "                    encoding=encoding,\r\n"]
[928.249801, "o", "                    hash_key=hash_key,\r\n"]
[928.272172, "o", "                    categorize=categorize,\r\n"]
[928.294543, "o", "                )._values\r\n"]
[928.316914, "o", "                for _ in [None]\r\n"]
[928.339285, "o", "            )\r\n"]
[928.361656, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[928.384027, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[928.406398, "o", "\r\n"]
[928.428769, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[928.45114, "o", "\r\n"]
[928.473511, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[928.495882, "o", "        hashes = (\r\n"]
[928.518253, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[928.540624, "o", "            for _, series in obj.items()\r\n"]
[928.562995, "o", "        )\r\n"]
[928.585367, "o", "        num_items = len(obj.columns)\r\n"]
[928.607738, "o", "        if index:\r\n"]
[928.630109, "o", "            index_hash_generator = (\r\n"]
[928.65248, "o", "                hash_pandas_object(\r\n"]
[928.674851, "o", "                    obj.index,\r\n"]
[928.697222, "o", "                    index=False,\r\n"]
[928.719593, "o", "                    encoding=encoding,\r\n"]
[928.741964, "o", "                    hash_key=hash_key,\r\n"]
[928.764335, "o", "                    categorize=categorize,\r\n"]
[928.786706, "o", "                )._values\r\n"]
[928.809077, "o", "                for _ in [None]\r\n"]
[928.831448, "o", "            )\r\n"]
[928.853819, "o", "            num_items += 1\r\n"]
[928.87619, "o", "\r\n"]
[928.898561, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[928.920932, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[928.943303, "o", "            hashes = (x for x in _hashes)\r\n"]
[928.965674, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[928.988045, "o", "\r\n"]
[929.010416, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[929.032787, "o", "    else:\r\n"]
[929.055158, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[929.077529, "o", "\r\n"]
[929.0999, "o", "    return ser\r\n"]
[929.122271, "o", "\r\n"]
[929.144643, "o", "\r\n"]
[929.167014, "o", "def hash_tuples(\r\n"]
[929.189385, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[929.211756, "o", "    encoding: str = \"utf8\",\r\n"]
[929.234127, "o", "    hash_key: str = _default_hash_key,\r\n"]
[929.256498, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[929.278869, "o", "    \"\"\"\r\n"]
[929.30124, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[929.323611, "o", "\r\n"]
[929.345982, "o", "    Parameters\r\n"]
[929.368353, "o", "    ----------\r\n"]
[929.390724, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[929.413095, "o", "    encoding : str, default 'utf8'\r\n"]
[929.435466, "o", "    hash_key : str, default _default_hash_key\r\n"]
[929.457837, "o", "\r\n"]
[929.480208, "o", "    Returns\r\n"]
[929.502579, "o", "    -------\r\n"]
[929.52495, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[929.547321, "o", "    \"\"\"\r\n"]
[929.569692, "o", "    if not is_list_like(vals):\r\n"]
[929.592063, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[929.614434, "o", "\r\n"]
[929.636805, "o", "    from pandas import (\r\n"]
[929.659176, "o", "        Categorical,\r\n"]
[929.681548, "o", "        MultiIndex,\r\n"]
[929.703919, "o", "    )\r\n"]
[929.72629, "o", "\r\n"]
[929.748661, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[929.771032, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[929.793403, "o", "    else:\r\n"]
[929.815774, "o", "        mi = vals\r\n"]
[929.838145, "o", "\r\n"]
[929.860516, "o", "    # create a list-of-Categoricals\r\n"]
[929.882887, "o", "    cat_vals = [\r\n"]
[929.905258, "o", "        Categorical._simple_new(\r\n"]
[929.927629, "o", "            mi.codes[level],\r\n"]
[930.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[930.002, "i", "sed -n '220,440p' pandas/core/util/hashing.py\r"]
[930.004, "o", "sed -n '220,440p' pandas/core/util/hashing.py\r\n"]
[930.037692, "o", "\u001b[?2004l\r\n"]
[930.069385, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[930.101077, "o", "        )\r\n"]
[930.132769, "o", "        for level in range(mi.nlevels)\r\n"]
[930.164462, "o", "    ]\r\n"]
[930.196154, "o", "\r\n"]
[930.227846, "o", "    # hash the list-of-ndarrays\r\n"]
[930.259538, "o", "    hashes = (\r\n"]
[930.291231, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[930.322923, "o", "        for cat in cat_vals\r\n"]
[930.354615, "o", "    )\r\n"]
[930.386308, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[930.418, "o", "\r\n"]
[930.449692, "o", "    return h\r\n"]
[930.481385, "o", "\r\n"]
[930.513077, "o", "\r\n"]
[930.544769, "o", "def hash_array(\r\n"]
[930.576462, "o", "    vals: ArrayLike,\r\n"]
[930.608154, "o", "    encoding: str = \"utf8\",\r\n"]
[930.639846, "o", "    hash_key: str = _default_hash_key,\r\n"]
[930.671538, "o", "    categorize: bool = True,\r\n"]
[930.703231, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[930.734923, "o", "    \"\"\"\r\n"]
[930.766615, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[930.798308, "o", "\r\n"]
[930.83, "o", "    Parameters\r\n"]
[930.861692, "o", "    ----------\r\n"]
[930.893385, "o", "    vals : ndarray or ExtensionArray\r\n"]
[930.925077, "o", "        The input array to hash.\r\n"]
[930.956769, "o", "    encoding : str, default 'utf8'\r\n"]
[930.988462, "o", "        Encoding for data & key when strings.\r\n"]
[931.020154, "o", "    hash_key : str, default _default_hash_key\r\n"]
[931.051846, "o", "        Hash_key for string key to encode.\r\n"]
[931.083538, "o", "    categorize : bool, default True\r\n"]
[931.115231, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[931.146923, "o", "        efficient when the array contains duplicate values.\r\n"]
[931.178615, "o", "\r\n"]
[931.210308, "o", "    Returns\r\n"]
[931.242, "o", "    -------\r\n"]
[931.273692, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[931.305385, "o", "        Hashed values, same length as the vals.\r\n"]
[931.337077, "o", "\r\n"]
[931.368769, "o", "    See Also\r\n"]
[931.400462, "o", "    --------\r\n"]
[931.432154, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[931.463846, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[931.495538, "o", "\r\n"]
[931.527231, "o", "    Examples\r\n"]
[931.558923, "o", "    --------\r\n"]
[931.590615, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[931.622308, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[931.654, "o", "      dtype=uint64)\r\n"]
[931.685692, "o", "    \"\"\"\r\n"]
[931.717385, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[931.749077, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[931.780769, "o", "\r\n"]
[931.812462, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[931.844154, "o", "        return vals._hash_pandas_object(\r\n"]
[931.875846, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[931.907538, "o", "        )\r\n"]
[931.939231, "o", "\r\n"]
[931.970923, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[932.002615, "o", "        # GH#42003\r\n"]
[932.034308, "o", "        raise TypeError(\r\n"]
[932.066, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[932.097692, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[932.129385, "o", "        )\r\n"]
[932.161077, "o", "\r\n"]
[932.192769, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[932.224462, "o", "\r\n"]
[932.256154, "o", "\r\n"]
[932.287846, "o", "def _hash_ndarray(\r\n"]
[932.319538, "o", "    vals: np.ndarray,\r\n"]
[932.351231, "o", "    encoding: str = \"utf8\",\r\n"]
[932.382923, "o", "    hash_key: str = _default_hash_key,\r\n"]
[932.414615, "o", "    categorize: bool = True,\r\n"]
[932.446308, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[932.478, "o", "    \"\"\"\r\n"]
[932.509692, "o", "    See hash_array.__doc__.\r\n"]
[932.541385, "o", "    \"\"\"\r\n"]
[932.573077, "o", "    dtype = vals.dtype\r\n"]
[932.604769, "o", "\r\n"]
[932.636462, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[932.668154, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[932.699846, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[932.731538, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[932.763231, "o", "        return hash_real + 23 * hash_imag\r\n"]
[932.794923, "o", "\r\n"]
[932.826615, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[932.858308, "o", "    # manage it.\r\n"]
[932.89, "o", "    if dtype == bool:\r\n"]
[932.921692, "o", "        vals = vals.astype(\"u8\")\r\n"]
[932.953385, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[932.985077, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[933.016769, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[933.048462, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[933.080154, "o", "    else:\r\n"]
[933.111846, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[933.143538, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[933.175231, "o", "        # when the values are known/likely to be unique.\r\n"]
[933.206923, "o", "        if categorize:\r\n"]
[933.238615, "o", "            from pandas import (\r\n"]
[933.270308, "o", "                Categorical,\r\n"]
[933.302, "o", "                Index,\r\n"]
[933.333692, "o", "                factorize,\r\n"]
[933.365385, "o", "            )\r\n"]
[933.397077, "o", "\r\n"]
[933.428769, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[933.460462, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[933.492154, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[933.523846, "o", "            return cat._hash_pandas_object(\r\n"]
[933.555538, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[933.587231, "o", "            )\r\n"]
[933.618923, "o", "\r\n"]
[933.650615, "o", "        try:\r\n"]
[933.682308, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[933.714, "o", "        if is_object_dtype(values) and not categorize:\r\n"]
[933.745692, "o", "            import numpy as np\r\n"]
[933.777385, "o", "            import pandas as pd\r\n"]
[933.809077, "o", "            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[933.840769, "o", "            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[933.872462, "o", "            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[933.904154, "o", "            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[933.935846, "o", "            mask = codes == -1\r\n"]
[933.967538, "o", "            if mask.any():\r\n"]
[933.999231, "o", "                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[934.030923, "o", "                res = res.copy()\r\n"]
[934.062615, "o", "                res[mask] = na_hash\r\n"]
[934.094308, "o", "            return res\r\n"]
[934.126, "o", "        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[934.157692, "o", "        except TypeError:\r\n"]
[934.189385, "o", "            # we have mixed types\r\n"]
[934.221077, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[934.252769, "o", "            if is_object_dtype(values) and not categorize:\r\n"]
[934.284462, "o", "                import numpy as np\r\n"]
[934.316154, "o", "                import pandas as pd\r\n"]
[934.347846, "o", "                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[934.379538, "o", "                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[934.411231, "o", "                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[934.442923, "o", "                mask = codes == -1\r\n"]
[934.474615, "o", "                if mask.any():\r\n"]
[934.506308, "o", "                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[934.538, "o", "                    res = res.copy()\r\n"]
[934.569692, "o", "                    res[mask] = na_hash\r\n"]
[934.601385, "o", "                return res\r\n"]
[934.633077, "o", "            vals = hash_object_array(\r\n"]
[934.664769, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[934.696462, "o", "            )\r\n"]
[934.728154, "o", "\r\n"]
[934.759846, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[934.791538, "o", "    vals ^= vals >> 30\r\n"]
[934.823231, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[934.854923, "o", "    vals ^= vals >> 27\r\n"]
[934.886615, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[934.918308, "o", "    vals ^= vals >> 31\r\n"]
[935.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[935.002, "i", "cd asv_bench\r"]
[935.004, "o", "cd asv_bench\r\n"]
[935.006, "o", "\u001b[?2004l\r\n"]
[940.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[940.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[940.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[940.10488, "o", "\u001b[?2004l\r\n"]
[940.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[940.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmputruume2/result.json (exit status 1)\u001b[0m\r\n"]
[940.40152, "o", "   STDOUT -------->\r\n"]
[940.5004, "o", "   \r\n"]
[940.59928, "o", "   STDERR -------->\r\n"]
[940.69816, "o", "   Traceback (most recent call last):\r\n"]
[940.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[940.89592, "o", "       main()\r\n"]
[940.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[941.09368, "o", "       commands[mode](args)\r\n"]
[941.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[941.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[941.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[941.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[941.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[941.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[941.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[941.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[941.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[942.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[942.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[942.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[942.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[942.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[942.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[942.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[942.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[942.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[942.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[943.07128, "o", "       import pandas as pd\r\n"]
[943.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[943.26904, "o", "       from pandas.core.api import (\r\n"]
[943.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[943.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[943.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[943.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[943.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[943.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[943.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[944.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[944.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[944.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[944.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 335\r\n"]
[944.4556, "o", "       if is_object_dtype(values) and not categorize:\r\n"]
[944.55448, "o", "       ^^\r\n"]
[944.65336, "o", "   SyntaxError: expected 'except' or 'finally' block\r\n"]
[944.75224, "o", "\r\n"]
[944.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmputruume2/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[945.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[945.002, "i", "cd /workspace/repo\r"]
[945.004, "o", "cd /workspace/repo\r\n"]
[945.006, "o", "\u001b[?2004l\r\n"]
[950.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[950.002, "i", "nl -ba pandas/core/util/hashing.py | sed -n '300,380p'\r"]
[950.004, "o", "nl -ba pandas/core/util/hashing.py | sed -n '300,380p'\r\n"]
[950.071053, "o", "\u001b[?2004l\r\n"]
[950.136105, "o", "   300\t\r\n"]
[950.201158, "o", "   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[950.266211, "o", "   302\t    if np.issubdtype(dtype, np.complex128):\r\n"]
[950.331263, "o", "   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[950.396316, "o", "   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[950.461368, "o", "   305\t        return hash_real + 23 * hash_imag\r\n"]
[950.526421, "o", "   306\t\r\n"]
[950.591474, "o", "   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[950.656526, "o", "   308\t    # manage it.\r\n"]
[950.721579, "o", "   309\t    if dtype == bool:\r\n"]
[950.786632, "o", "   310\t        vals = vals.astype(\"u8\")\r\n"]
[950.851684, "o", "   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[950.916737, "o", "   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[950.981789, "o", "   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[951.046842, "o", "   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[951.111895, "o", "   315\t    else:\r\n"]
[951.176947, "o", "   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[951.242, "o", "   317\t        # then hash and rename categories. We allow skipping the categorization\r\n"]
[951.307053, "o", "   318\t        # when the values are known/likely to be unique.\r\n"]
[951.372105, "o", "   319\t        if categorize:\r\n"]
[951.437158, "o", "   320\t            from pandas import (\r\n"]
[951.502211, "o", "   321\t                Categorical,\r\n"]
[951.567263, "o", "   322\t                Index,\r\n"]
[951.632316, "o", "   323\t                factorize,\r\n"]
[951.697368, "o", "   324\t            )\r\n"]
[951.762421, "o", "   325\t\r\n"]
[951.827474, "o", "   326\t            codes, categories = factorize(vals, sort=False)\r\n"]
[951.892526, "o", "   327\t            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[951.957579, "o", "   328\t            cat = Categorical._simple_new(codes, dtype)\r\n"]
[952.022632, "o", "   329\t            return cat._hash_pandas_object(\r\n"]
[952.087684, "o", "   330\t                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[952.152737, "o", "   331\t            )\r\n"]
[952.217789, "o", "   332\t\r\n"]
[952.282842, "o", "   333\t        try:\r\n"]
[952.347895, "o", "   334\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[952.412947, "o", "   335\t        if is_object_dtype(values) and not categorize:\r\n"]
[952.478, "o", "   336\t            import numpy as np\r\n"]
[952.543053, "o", "   337\t            import pandas as pd\r\n"]
[952.608105, "o", "   338\t            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[952.673158, "o", "   339\t            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[952.738211, "o", "   340\t            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[952.803263, "o", "   341\t            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[952.868316, "o", "   342\t            mask = codes == -1\r\n"]
[952.933368, "o", "   343\t            if mask.any():\r\n"]
[952.998421, "o", "   344\t                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[953.063474, "o", "   345\t                res = res.copy()\r\n"]
[953.128526, "o", "   346\t                res[mask] = na_hash\r\n"]
[953.193579, "o", "   347\t            return res\r\n"]
[953.258632, "o", "   348\t        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[953.323684, "o", "   349\t        except TypeError:\r\n"]
[953.388737, "o", "   350\t            # we have mixed types\r\n"]
[953.453789, "o", "   351\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[953.518842, "o", "   352\t            if is_object_dtype(values) and not categorize:\r\n"]
[953.583895, "o", "   353\t                import numpy as np\r\n"]
[953.648947, "o", "   354\t                import pandas as pd\r\n"]
[953.714, "o", "   355\t                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[953.779053, "o", "   356\t                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[953.844105, "o", "   357\t                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[953.909158, "o", "   358\t                mask = codes == -1\r\n"]
[953.974211, "o", "   359\t                if mask.any():\r\n"]
[954.039263, "o", "   360\t                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[954.104316, "o", "   361\t                    res = res.copy()\r\n"]
[954.169368, "o", "   362\t                    res[mask] = na_hash\r\n"]
[954.234421, "o", "   363\t                return res\r\n"]
[954.299474, "o", "   364\t            vals = hash_object_array(\r\n"]
[954.364526, "o", "   365\t                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[954.429579, "o", "   366\t            )\r\n"]
[954.494632, "o", "   367\t\r\n"]
[954.559684, "o", "   368\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[954.624737, "o", "   369\t    vals ^= vals >> 30\r\n"]
[954.689789, "o", "   370\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[954.754842, "o", "   371\t    vals ^= vals >> 27\r\n"]
[954.819895, "o", "   372\t    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[954.884947, "o", "   373\t    vals ^= vals >> 31\r\n"]
[955.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[955.002, "i", "git status -s\r"]
[955.004, "o", "git status -s\r\n"]
[955.006, "o", "\u001b[?2004l\r\n"]
[960.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[960.002, "i", "git restore --worktree --staged -- pandas/core/util/hashing.py || git checkout -- pandas/core/util/hashing.py\r"]
[960.004, "o", "git restore --worktree --staged -- pandas/core/util/hashing.py || git checkout -- pandas/core/util/hashing.py\r\n"]
[960.006, "o", "\u001b[?2004l\r\n"]
[965.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[965.002, "i", "sed -n '1,220p' pandas/core/util/hashing.py\r"]
[965.004, "o", "sed -n '1,220p' pandas/core/util/hashing.py\r\n"]
[965.028371, "o", "\u001b[?2004l\r\n"]
[965.050742, "o", "\"\"\"\r\n"]
[965.073113, "o", "data hash pandas / numpy objects\r\n"]
[965.095484, "o", "\"\"\"\r\n"]
[965.117855, "o", "\r\n"]
[965.140226, "o", "from __future__ import annotations\r\n"]
[965.162597, "o", "\r\n"]
[965.184968, "o", "import itertools\r\n"]
[965.207339, "o", "from typing import TYPE_CHECKING\r\n"]
[965.22971, "o", "\r\n"]
[965.252081, "o", "import numpy as np\r\n"]
[965.274452, "o", "\r\n"]
[965.296824, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[965.319195, "o", "\r\n"]
[965.341566, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[965.363937, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[965.386308, "o", "from pandas.core.dtypes.generic import (\r\n"]
[965.408679, "o", "    ABCDataFrame,\r\n"]
[965.43105, "o", "    ABCExtensionArray,\r\n"]
[965.453421, "o", "    ABCIndex,\r\n"]
[965.475792, "o", "    ABCMultiIndex,\r\n"]
[965.498163, "o", "    ABCSeries,\r\n"]
[965.520534, "o", ")\r\n"]
[965.542905, "o", "\r\n"]
[965.565276, "o", "if TYPE_CHECKING:\r\n"]
[965.587647, "o", "    from collections.abc import (\r\n"]
[965.610018, "o", "        Hashable,\r\n"]
[965.632389, "o", "        Iterable,\r\n"]
[965.65476, "o", "        Iterator,\r\n"]
[965.677131, "o", "    )\r\n"]
[965.699502, "o", "\r\n"]
[965.721873, "o", "    from pandas._typing import (\r\n"]
[965.744244, "o", "        ArrayLike,\r\n"]
[965.766615, "o", "        npt,\r\n"]
[965.788986, "o", "    )\r\n"]
[965.811357, "o", "\r\n"]
[965.833729, "o", "    from pandas import (\r\n"]
[965.8561, "o", "        DataFrame,\r\n"]
[965.878471, "o", "        Index,\r\n"]
[965.900842, "o", "        MultiIndex,\r\n"]
[965.923213, "o", "        Series,\r\n"]
[965.945584, "o", "    )\r\n"]
[965.967955, "o", "\r\n"]
[965.990326, "o", "\r\n"]
[966.012697, "o", "# 16 byte long hashing key\r\n"]
[966.035068, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[966.057439, "o", "\r\n"]
[966.07981, "o", "\r\n"]
[966.102181, "o", "def combine_hash_arrays(\r\n"]
[966.124552, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[966.146923, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[966.169294, "o", "    \"\"\"\r\n"]
[966.191665, "o", "    Parameters\r\n"]
[966.214036, "o", "    ----------\r\n"]
[966.236407, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[966.258778, "o", "    num_items : int\r\n"]
[966.281149, "o", "\r\n"]
[966.30352, "o", "    Returns\r\n"]
[966.325891, "o", "    -------\r\n"]
[966.348262, "o", "    np.ndarray[uint64]\r\n"]
[966.370633, "o", "\r\n"]
[966.393005, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[966.415376, "o", "    \"\"\"\r\n"]
[966.437747, "o", "    try:\r\n"]
[966.460118, "o", "        first = next(arrays)\r\n"]
[966.482489, "o", "    except StopIteration:\r\n"]
[966.50486, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[966.527231, "o", "\r\n"]
[966.549602, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[966.571973, "o", "\r\n"]
[966.594344, "o", "    mult = np.uint64(1000003)\r\n"]
[966.616715, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[966.639086, "o", "    last_i = 0\r\n"]
[966.661457, "o", "    for i, a in enumerate(arrays):\r\n"]
[966.683828, "o", "        inverse_i = num_items - i\r\n"]
[966.706199, "o", "        out ^= a\r\n"]
[966.72857, "o", "        out *= mult\r\n"]
[966.750941, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[966.773312, "o", "        last_i = i\r\n"]
[966.795683, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[966.818054, "o", "    out += np.uint64(97531)\r\n"]
[966.840425, "o", "    return out\r\n"]
[966.862796, "o", "\r\n"]
[966.885167, "o", "\r\n"]
[966.907538, "o", "def hash_pandas_object(\r\n"]
[966.92991, "o", "    obj: Index | DataFrame | Series,\r\n"]
[966.952281, "o", "    index: bool = True,\r\n"]
[966.974652, "o", "    encoding: str = \"utf8\",\r\n"]
[966.997023, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[967.019394, "o", "    categorize: bool = True,\r\n"]
[967.041765, "o", ") -> Series:\r\n"]
[967.064136, "o", "    \"\"\"\r\n"]
[967.086507, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[967.108878, "o", "\r\n"]
[967.131249, "o", "    Parameters\r\n"]
[967.15362, "o", "    ----------\r\n"]
[967.175991, "o", "    obj : Index, Series, or DataFrame\r\n"]
[967.198362, "o", "    index : bool, default True\r\n"]
[967.220733, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[967.243104, "o", "    encoding : str, default 'utf8'\r\n"]
[967.265475, "o", "        Encoding for data & key when strings.\r\n"]
[967.287846, "o", "    hash_key : str, default _default_hash_key\r\n"]
[967.310217, "o", "        Hash_key for string key to encode.\r\n"]
[967.332588, "o", "    categorize : bool, default True\r\n"]
[967.354959, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[967.37733, "o", "        efficient when the array contains duplicate values.\r\n"]
[967.399701, "o", "\r\n"]
[967.422072, "o", "    Returns\r\n"]
[967.444443, "o", "    -------\r\n"]
[967.466814, "o", "    Series of uint64\r\n"]
[967.489186, "o", "        Same length as the object.\r\n"]
[967.511557, "o", "\r\n"]
[967.533928, "o", "    Examples\r\n"]
[967.556299, "o", "    --------\r\n"]
[967.57867, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[967.601041, "o", "    0    14639053686158035780\r\n"]
[967.623412, "o", "    1     3869563279212530728\r\n"]
[967.645783, "o", "    2      393322362522515241\r\n"]
[967.668154, "o", "    dtype: uint64\r\n"]
[967.690525, "o", "    \"\"\"\r\n"]
[967.712896, "o", "    from pandas import Series\r\n"]
[967.735267, "o", "\r\n"]
[967.757638, "o", "    if hash_key is None:\r\n"]
[967.780009, "o", "        hash_key = _default_hash_key\r\n"]
[967.80238, "o", "\r\n"]
[967.824751, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[967.847122, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[967.869493, "o", "\r\n"]
[967.891864, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[967.914235, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[967.936606, "o", "            \"uint64\", copy=False\r\n"]
[967.958977, "o", "        )\r\n"]
[967.981348, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[968.003719, "o", "\r\n"]
[968.02609, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[968.048462, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[968.070833, "o", "            \"uint64\", copy=False\r\n"]
[968.093204, "o", "        )\r\n"]
[968.115575, "o", "        if index:\r\n"]
[968.137946, "o", "            index_iter = (\r\n"]
[968.160317, "o", "                hash_pandas_object(\r\n"]
[968.182688, "o", "                    obj.index,\r\n"]
[968.205059, "o", "                    index=False,\r\n"]
[968.22743, "o", "                    encoding=encoding,\r\n"]
[968.249801, "o", "                    hash_key=hash_key,\r\n"]
[968.272172, "o", "                    categorize=categorize,\r\n"]
[968.294543, "o", "                )._values\r\n"]
[968.316914, "o", "                for _ in [None]\r\n"]
[968.339285, "o", "            )\r\n"]
[968.361656, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[968.384027, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[968.406398, "o", "\r\n"]
[968.428769, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[968.45114, "o", "\r\n"]
[968.473511, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[968.495882, "o", "        hashes = (\r\n"]
[968.518253, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[968.540624, "o", "            for _, series in obj.items()\r\n"]
[968.562995, "o", "        )\r\n"]
[968.585367, "o", "        num_items = len(obj.columns)\r\n"]
[968.607738, "o", "        if index:\r\n"]
[968.630109, "o", "            index_hash_generator = (\r\n"]
[968.65248, "o", "                hash_pandas_object(\r\n"]
[968.674851, "o", "                    obj.index,\r\n"]
[968.697222, "o", "                    index=False,\r\n"]
[968.719593, "o", "                    encoding=encoding,\r\n"]
[968.741964, "o", "                    hash_key=hash_key,\r\n"]
[968.764335, "o", "                    categorize=categorize,\r\n"]
[968.786706, "o", "                )._values\r\n"]
[968.809077, "o", "                for _ in [None]\r\n"]
[968.831448, "o", "            )\r\n"]
[968.853819, "o", "            num_items += 1\r\n"]
[968.87619, "o", "\r\n"]
[968.898561, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[968.920932, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[968.943303, "o", "            hashes = (x for x in _hashes)\r\n"]
[968.965674, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[968.988045, "o", "\r\n"]
[969.010416, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[969.032787, "o", "    else:\r\n"]
[969.055158, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[969.077529, "o", "\r\n"]
[969.0999, "o", "    return ser\r\n"]
[969.122271, "o", "\r\n"]
[969.144643, "o", "\r\n"]
[969.167014, "o", "def hash_tuples(\r\n"]
[969.189385, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[969.211756, "o", "    encoding: str = \"utf8\",\r\n"]
[969.234127, "o", "    hash_key: str = _default_hash_key,\r\n"]
[969.256498, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[969.278869, "o", "    \"\"\"\r\n"]
[969.30124, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[969.323611, "o", "\r\n"]
[969.345982, "o", "    Parameters\r\n"]
[969.368353, "o", "    ----------\r\n"]
[969.390724, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[969.413095, "o", "    encoding : str, default 'utf8'\r\n"]
[969.435466, "o", "    hash_key : str, default _default_hash_key\r\n"]
[969.457837, "o", "\r\n"]
[969.480208, "o", "    Returns\r\n"]
[969.502579, "o", "    -------\r\n"]
[969.52495, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[969.547321, "o", "    \"\"\"\r\n"]
[969.569692, "o", "    if not is_list_like(vals):\r\n"]
[969.592063, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[969.614434, "o", "\r\n"]
[969.636805, "o", "    from pandas import (\r\n"]
[969.659176, "o", "        Categorical,\r\n"]
[969.681548, "o", "        MultiIndex,\r\n"]
[969.703919, "o", "    )\r\n"]
[969.72629, "o", "\r\n"]
[969.748661, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[969.771032, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[969.793403, "o", "    else:\r\n"]
[969.815774, "o", "        mi = vals\r\n"]
[969.838145, "o", "\r\n"]
[969.860516, "o", "    # create a list-of-Categoricals\r\n"]
[969.882887, "o", "    cat_vals = [\r\n"]
[969.905258, "o", "        Categorical._simple_new(\r\n"]
[969.927629, "o", "            mi.codes[level],\r\n"]
[970.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[970.002, "i", "sed -n '220,480p' pandas/core/util/hashing.py\r"]
[970.004, "o", "sed -n '220,480p' pandas/core/util/hashing.py\r\n"]
[970.037692, "o", "\u001b[?2004l\r\n"]
[970.069385, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[970.101077, "o", "        )\r\n"]
[970.132769, "o", "        for level in range(mi.nlevels)\r\n"]
[970.164462, "o", "    ]\r\n"]
[970.196154, "o", "\r\n"]
[970.227846, "o", "    # hash the list-of-ndarrays\r\n"]
[970.259538, "o", "    hashes = (\r\n"]
[970.291231, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[970.322923, "o", "        for cat in cat_vals\r\n"]
[970.354615, "o", "    )\r\n"]
[970.386308, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[970.418, "o", "\r\n"]
[970.449692, "o", "    return h\r\n"]
[970.481385, "o", "\r\n"]
[970.513077, "o", "\r\n"]
[970.544769, "o", "def hash_array(\r\n"]
[970.576462, "o", "    vals: ArrayLike,\r\n"]
[970.608154, "o", "    encoding: str = \"utf8\",\r\n"]
[970.639846, "o", "    hash_key: str = _default_hash_key,\r\n"]
[970.671538, "o", "    categorize: bool = True,\r\n"]
[970.703231, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[970.734923, "o", "    \"\"\"\r\n"]
[970.766615, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[970.798308, "o", "\r\n"]
[970.83, "o", "    Parameters\r\n"]
[970.861692, "o", "    ----------\r\n"]
[970.893385, "o", "    vals : ndarray or ExtensionArray\r\n"]
[970.925077, "o", "        The input array to hash.\r\n"]
[970.956769, "o", "    encoding : str, default 'utf8'\r\n"]
[970.988462, "o", "        Encoding for data & key when strings.\r\n"]
[971.020154, "o", "    hash_key : str, default _default_hash_key\r\n"]
[971.051846, "o", "        Hash_key for string key to encode.\r\n"]
[971.083538, "o", "    categorize : bool, default True\r\n"]
[971.115231, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[971.146923, "o", "        efficient when the array contains duplicate values.\r\n"]
[971.178615, "o", "\r\n"]
[971.210308, "o", "    Returns\r\n"]
[971.242, "o", "    -------\r\n"]
[971.273692, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[971.305385, "o", "        Hashed values, same length as the vals.\r\n"]
[971.337077, "o", "\r\n"]
[971.368769, "o", "    See Also\r\n"]
[971.400462, "o", "    --------\r\n"]
[971.432154, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[971.463846, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[971.495538, "o", "\r\n"]
[971.527231, "o", "    Examples\r\n"]
[971.558923, "o", "    --------\r\n"]
[971.590615, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[971.622308, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[971.654, "o", "      dtype=uint64)\r\n"]
[971.685692, "o", "    \"\"\"\r\n"]
[971.717385, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[971.749077, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[971.780769, "o", "\r\n"]
[971.812462, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[971.844154, "o", "        return vals._hash_pandas_object(\r\n"]
[971.875846, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[971.907538, "o", "        )\r\n"]
[971.939231, "o", "\r\n"]
[971.970923, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[972.002615, "o", "        # GH#42003\r\n"]
[972.034308, "o", "        raise TypeError(\r\n"]
[972.066, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[972.097692, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[972.129385, "o", "        )\r\n"]
[972.161077, "o", "\r\n"]
[972.192769, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[972.224462, "o", "\r\n"]
[972.256154, "o", "\r\n"]
[972.287846, "o", "def _hash_ndarray(\r\n"]
[972.319538, "o", "    vals: np.ndarray,\r\n"]
[972.351231, "o", "    encoding: str = \"utf8\",\r\n"]
[972.382923, "o", "    hash_key: str = _default_hash_key,\r\n"]
[972.414615, "o", "    categorize: bool = True,\r\n"]
[972.446308, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[972.478, "o", "    \"\"\"\r\n"]
[972.509692, "o", "    See hash_array.__doc__.\r\n"]
[972.541385, "o", "    \"\"\"\r\n"]
[972.573077, "o", "    dtype = vals.dtype\r\n"]
[972.604769, "o", "\r\n"]
[972.636462, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[972.668154, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[972.699846, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[972.731538, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[972.763231, "o", "        return hash_real + 23 * hash_imag\r\n"]
[972.794923, "o", "\r\n"]
[972.826615, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[972.858308, "o", "    # manage it.\r\n"]
[972.89, "o", "    if dtype == bool:\r\n"]
[972.921692, "o", "        vals = vals.astype(\"u8\")\r\n"]
[972.953385, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[972.985077, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[973.016769, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[973.048462, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[973.080154, "o", "    else:\r\n"]
[973.111846, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[973.143538, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[973.175231, "o", "        # when the values are known/likely to be unique.\r\n"]
[973.206923, "o", "        if categorize:\r\n"]
[973.238615, "o", "            from pandas import (\r\n"]
[973.270308, "o", "                Categorical,\r\n"]
[973.302, "o", "                Index,\r\n"]
[973.333692, "o", "                factorize,\r\n"]
[973.365385, "o", "            )\r\n"]
[973.397077, "o", "\r\n"]
[973.428769, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[973.460462, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[973.492154, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[973.523846, "o", "            return cat._hash_pandas_object(\r\n"]
[973.555538, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[973.587231, "o", "            )\r\n"]
[973.618923, "o", "\r\n"]
[973.650615, "o", "        try:\r\n"]
[973.682308, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[973.714, "o", "        if is_object_dtype(values) and not categorize:\r\n"]
[973.745692, "o", "            import numpy as np\r\n"]
[973.777385, "o", "            import pandas as pd\r\n"]
[973.809077, "o", "            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[973.840769, "o", "            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[973.872462, "o", "            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[973.904154, "o", "            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[973.935846, "o", "            mask = codes == -1\r\n"]
[973.967538, "o", "            if mask.any():\r\n"]
[973.999231, "o", "                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[974.030923, "o", "                res = res.copy()\r\n"]
[974.062615, "o", "                res[mask] = na_hash\r\n"]
[974.094308, "o", "            return res\r\n"]
[974.126, "o", "        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[974.157692, "o", "        except TypeError:\r\n"]
[974.189385, "o", "            # we have mixed types\r\n"]
[974.221077, "o", "            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[974.252769, "o", "            if is_object_dtype(values) and not categorize:\r\n"]
[974.284462, "o", "                import numpy as np\r\n"]
[974.316154, "o", "                import pandas as pd\r\n"]
[974.347846, "o", "                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[974.379538, "o", "                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[974.411231, "o", "                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[974.442923, "o", "                mask = codes == -1\r\n"]
[974.474615, "o", "                if mask.any():\r\n"]
[974.506308, "o", "                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[974.538, "o", "                    res = res.copy()\r\n"]
[974.569692, "o", "                    res[mask] = na_hash\r\n"]
[974.601385, "o", "                return res\r\n"]
[974.633077, "o", "            vals = hash_object_array(\r\n"]
[974.664769, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[974.696462, "o", "            )\r\n"]
[974.728154, "o", "\r\n"]
[974.759846, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[974.791538, "o", "    vals ^= vals >> 30\r\n"]
[974.823231, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[974.854923, "o", "    vals ^= vals >> 27\r\n"]
[974.886615, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[974.918308, "o", "    vals ^= vals >> 31\r\n"]
[975.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[975.002, "i", "cd asv_bench\r"]
[975.004, "o", "cd asv_bench\r\n"]
[975.006, "o", "\u001b[?2004l\r\n"]
[980.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[980.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[980.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[980.10488, "o", "\u001b[?2004l\r\n"]
[980.20376, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[980.30264, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp3wdi35wx/result.json (exit status 1)\u001b[0m\r\n"]
[980.40152, "o", "   STDOUT -------->\r\n"]
[980.5004, "o", "   \r\n"]
[980.59928, "o", "   STDERR -------->\r\n"]
[980.69816, "o", "   Traceback (most recent call last):\r\n"]
[980.79704, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[980.89592, "o", "       main()\r\n"]
[980.9948, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[981.09368, "o", "       commands[mode](args)\r\n"]
[981.19256, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[981.29144, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[981.39032, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[981.4892, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[981.58808, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[981.68696, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[981.78584, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[981.88472, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[981.9836, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[982.08248, "o", "       module = importlib.import_module(module_name)\r\n"]
[982.18136, "o", "     File \"/opt/conda/envs/asv_3.10/lib/python3.10/importlib/__init__.py\", line 126, in import_module\r\n"]
[982.28024, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[982.37912, "o", "     File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n"]
[982.478, "o", "     File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n"]
[982.57688, "o", "     File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n"]
[982.67576, "o", "     File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n"]
[982.77464, "o", "     File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n"]
[982.87352, "o", "     File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n"]
[982.9724, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[983.07128, "o", "       import pandas as pd\r\n"]
[983.17016, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 45, in <module>\r\n"]
[983.26904, "o", "       from pandas.core.api import (\r\n"]
[983.36792, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[983.4668, "o", "       from pandas.core.arrays import Categorical\r\n"]
[983.56568, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 1, in <module>\r\n"]
[983.66456, "o", "       from pandas.core.arrays.arrow import ArrowExtensionArray\r\n"]
[983.76344, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\r\n"]
[983.86232, "o", "       from pandas.core.arrays.arrow.array import ArrowExtensionArray\r\n"]
[983.9612, "o", "     File \"/workspace/repo/pandas/core/arrays/arrow/array.py\", line 64, in <module>\r\n"]
[984.06008, "o", "       from pandas.core.arrays.masked import BaseMaskedArray\r\n"]
[984.15896, "o", "     File \"/workspace/repo/pandas/core/arrays/masked.py\", line 72, in <module>\r\n"]
[984.25784, "o", "       from pandas.core.util.hashing import hash_array\r\n"]
[984.35672, "o", "     File \"/workspace/repo/pandas/core/util/hashing.py\", line 335\r\n"]
[984.4556, "o", "       if is_object_dtype(values) and not categorize:\r\n"]
[984.55448, "o", "       ^^\r\n"]
[984.65336, "o", "   SyntaxError: expected 'except' or 'finally' block\r\n"]
[984.75224, "o", "\r\n"]
[984.85112, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.10/bin/python3.10 /opt/conda/envs/asv_3.10/lib/python3.10/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp3wdi35wx/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[985.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[985.002, "i", "cd /workspace/repo\r"]
[985.004, "o", "cd /workspace/repo\r\n"]
[985.006, "o", "\u001b[?2004l\r\n"]
[990.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[990.002, "i", "nl -ba pandas/core/util/hashing.py | sed -n '300,380p'\r"]
[990.004, "o", "nl -ba pandas/core/util/hashing.py | sed -n '300,380p'\r\n"]
[990.071053, "o", "\u001b[?2004l\r\n"]
[990.136105, "o", "   300\t\r\n"]
[990.201158, "o", "   301\t    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[990.266211, "o", "   302\t    if np.issubdtype(dtype, np.complex128):\r\n"]
[990.331263, "o", "   303\t        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[990.396316, "o", "   304\t        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[990.461368, "o", "   305\t        return hash_real + 23 * hash_imag\r\n"]
[990.526421, "o", "   306\t\r\n"]
[990.591474, "o", "   307\t    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[990.656526, "o", "   308\t    # manage it.\r\n"]
[990.721579, "o", "   309\t    if dtype == bool:\r\n"]
[990.786632, "o", "   310\t        vals = vals.astype(\"u8\")\r\n"]
[990.851684, "o", "   311\t    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[990.916737, "o", "   312\t        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[990.981789, "o", "   313\t    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[991.046842, "o", "   314\t        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[991.111895, "o", "   315\t    else:\r\n"]
[991.176947, "o", "   316\t        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[991.242, "o", "   317\t        # then hash and rename categories. We allow skipping the categorization\r\n"]
[991.307053, "o", "   318\t        # when the values are known/likely to be unique.\r\n"]
[991.372105, "o", "   319\t        if categorize:\r\n"]
[991.437158, "o", "   320\t            from pandas import (\r\n"]
[991.502211, "o", "   321\t                Categorical,\r\n"]
[991.567263, "o", "   322\t                Index,\r\n"]
[991.632316, "o", "   323\t                factorize,\r\n"]
[991.697368, "o", "   324\t            )\r\n"]
[991.762421, "o", "   325\t\r\n"]
[991.827474, "o", "   326\t            codes, categories = factorize(vals, sort=False)\r\n"]
[991.892526, "o", "   327\t            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[991.957579, "o", "   328\t            cat = Categorical._simple_new(codes, dtype)\r\n"]
[992.022632, "o", "   329\t            return cat._hash_pandas_object(\r\n"]
[992.087684, "o", "   330\t                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[992.152737, "o", "   331\t            )\r\n"]
[992.217789, "o", "   332\t\r\n"]
[992.282842, "o", "   333\t        try:\r\n"]
[992.347895, "o", "   334\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[992.412947, "o", "   335\t        if is_object_dtype(values) and not categorize:\r\n"]
[992.478, "o", "   336\t            import numpy as np\r\n"]
[992.543053, "o", "   337\t            import pandas as pd\r\n"]
[992.608105, "o", "   338\t            codes, uniques = pd.factorize(values, sort=False)\r\n"]
[992.673158, "o", "   339\t            uhash = hash_object_array(uniques, hash_key, encoding)\r\n"]
[992.738211, "o", "   340\t            # map codes -> uhash, handling -1 (NA) separately\r\n"]
[992.803263, "o", "   341\t            res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[992.868316, "o", "   342\t            mask = codes == -1\r\n"]
[992.933368, "o", "   343\t            if mask.any():\r\n"]
[992.998421, "o", "   344\t                na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[993.063474, "o", "   345\t                res = res.copy()\r\n"]
[993.128526, "o", "   346\t                res[mask] = na_hash\r\n"]
[993.193579, "o", "   347\t            return res\r\n"]
[993.258632, "o", "   348\t        vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[993.323684, "o", "   349\t        except TypeError:\r\n"]
[993.388737, "o", "   350\t            # we have mixed types\r\n"]
[993.453789, "o", "   351\t            from pandas.core.dtypes.common import is_object_dtype\r\n"]
[993.518842, "o", "   352\t            if is_object_dtype(values) and not categorize:\r\n"]
[993.583895, "o", "   353\t                import numpy as np\r\n"]
[993.648947, "o", "   354\t                import pandas as pd\r\n"]
[993.714, "o", "   355\t                codes, uniques = pd.factorize(values.astype(str), sort=False)\r\n"]
[993.779053, "o", "   356\t                uhash = hash_object_array(uniques.astype(object), hash_key, encoding)\r\n"]
[993.844105, "o", "   357\t                res = uhash.take(codes, mode=\"wrap\").astype(\"u8\", copy=False)\r\n"]
[993.909158, "o", "   358\t                mask = codes == -1\r\n"]
[993.974211, "o", "   359\t                if mask.any():\r\n"]
[994.039263, "o", "   360\t                    na_hash = hash_object_array(np.array([np.nan], dtype=object), hash_key, encoding)[0]\r\n"]
[994.104316, "o", "   361\t                    res = res.copy()\r\n"]
[994.169368, "o", "   362\t                    res[mask] = na_hash\r\n"]
[994.234421, "o", "   363\t                return res\r\n"]
[994.299474, "o", "   364\t            vals = hash_object_array(\r\n"]
[994.364526, "o", "   365\t                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[994.429579, "o", "   366\t            )\r\n"]
[994.494632, "o", "   367\t\r\n"]
[994.559684, "o", "   368\t    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[994.624737, "o", "   369\t    vals ^= vals >> 30\r\n"]
[994.689789, "o", "   370\t    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[994.754842, "o", "   371\t    vals ^= vals >> 27\r\n"]
[994.819895, "o", "   372\t    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[994.884947, "o", "   373\t    vals ^= vals >> 31\r\n"]
[995.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[995.002, "i", "git --no-pager log --oneline -n 15\r"]
[995.004, "o", "git --no-pager log --oneline -n 15\r\n"]
[995.315, "o", "\u001b[?2004l\r\n"]
[995.624, "o", "\u001b[33mfdf3bc04f6\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD\u001b[m\u001b[33m -> \u001b[m\u001b[1;32mopt/hash-string-memo\u001b[m\u001b[33m)\u001b[m perf(hash): factorize-based fast path for object arrays; hash uniques once and remap; avoid circular imports\r\n"]
[995.933, "o", "\u001b[33mc38e1f1aa9\u001b[m\u001b[33m (\u001b[m\u001b[1;32mmain\u001b[m\u001b[33m)\u001b[m DOC: Updated `groupby.ewm` arguments (#61334)\r\n"]
[996.242, "o", "\u001b[33mf8d5a16542\u001b[m TYP: Remove unused mypy ignores (#61330)\r\n"]
[996.551, "o", "\u001b[33me5898b8d33\u001b[m DEPS: Bump optional dependencies (#60655)\r\n"]
[996.86, "o", "\u001b[33m31b073c794\u001b[m [minor edit] fix typo: psudocode -> pseudocode (#61314)\r\n"]
[997.169, "o", "\u001b[33m7a61e1b3c9\u001b[m DOC: Add missing punctuation to merging.rst (#61315)\r\n"]
[997.478, "o", "\u001b[33mfaf97858ac\u001b[m Remove WillAyd from CODEOWNERS (#61329)\r\n"]
[997.787, "o", "\u001b[33ma811388727\u001b[m BUG(string dtype): groupby/resampler.min/max returns float on all NA strings (#60985)\r\n"]
[998.096, "o", "\u001b[33mc27a309854\u001b[m WEB: Update benchmarks page (#61289)\r\n"]
[998.405, "o", "\u001b[33m5f354ca51f\u001b[m BUG: Handle overlapping line and bar on the same plot (#61173)\r\n"]
[998.714, "o", "\u001b[33m5fef9793dd\u001b[m DOC: copyedit _base.py (#61299)\r\n"]
[999.023, "o", "\u001b[33ma393c31931\u001b[m ENH(string dtype): fallback for HDF5 with UTF-8 surrogates (#60993)\r\n"]
[999.332, "o", "\u001b[33md739c92dd4\u001b[m Bug: Save original index and remap after function completes (#61116)\r\n"]
[999.641, "o", "\u001b[33m52e97673a7\u001b[m DOC: Add documentation for `groupby.expanding()` (#61274)\r\n"]
[1000.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[1000.002, "i", "git --no-pager diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r"]
[1000.004, "o", "git --no-pager diff -- pandas/core/util/hashing.py | sed -n '1,200p'\r\n"]
[1000.006, "o", "\u001b[?2004l\r\n"]
[1005.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[1005.002, "i", "git show HEAD^:pandas/core/util/hashing.py | sed -n '1,60p'\r"]
[1005.004, "o", "git show HEAD^:pandas/core/util/hashing.py | sed -n '1,60p'\r\n"]
[1005.087049, "o", "\u001b[?2004l\r\n"]
[1005.168098, "o", "\"\"\"\r\n"]
[1005.249148, "o", "data hash pandas / numpy objects\r\n"]
[1005.330197, "o", "\"\"\"\r\n"]
[1005.411246, "o", "\r\n"]
[1005.492295, "o", "from __future__ import annotations\r\n"]
[1005.573344, "o", "\r\n"]
[1005.654393, "o", "import itertools\r\n"]
[1005.735443, "o", "from typing import TYPE_CHECKING\r\n"]
[1005.816492, "o", "\r\n"]
[1005.897541, "o", "import numpy as np\r\n"]
[1005.97859, "o", "\r\n"]
[1006.059639, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[1006.140689, "o", "\r\n"]
[1006.221738, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[1006.302787, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[1006.383836, "o", "from pandas.core.dtypes.generic import (\r\n"]
[1006.464885, "o", "    ABCDataFrame,\r\n"]
[1006.545934, "o", "    ABCExtensionArray,\r\n"]
[1006.626984, "o", "    ABCIndex,\r\n"]
[1006.708033, "o", "    ABCMultiIndex,\r\n"]
[1006.789082, "o", "    ABCSeries,\r\n"]
[1006.870131, "o", ")\r\n"]
[1006.95118, "o", "\r\n"]
[1007.03223, "o", "if TYPE_CHECKING:\r\n"]
[1007.113279, "o", "    from collections.abc import (\r\n"]
[1007.194328, "o", "        Hashable,\r\n"]
[1007.275377, "o", "        Iterable,\r\n"]
[1007.356426, "o", "        Iterator,\r\n"]
[1007.437475, "o", "    )\r\n"]
[1007.518525, "o", "\r\n"]
[1007.599574, "o", "    from pandas._typing import (\r\n"]
[1007.680623, "o", "        ArrayLike,\r\n"]
[1007.761672, "o", "        npt,\r\n"]
[1007.842721, "o", "    )\r\n"]
[1007.92377, "o", "\r\n"]
[1008.00482, "o", "    from pandas import (\r\n"]
[1008.085869, "o", "        DataFrame,\r\n"]
[1008.166918, "o", "        Index,\r\n"]
[1008.247967, "o", "        MultiIndex,\r\n"]
[1008.329016, "o", "        Series,\r\n"]
[1008.410066, "o", "    )\r\n"]
[1008.491115, "o", "\r\n"]
[1008.572164, "o", "\r\n"]
[1008.653213, "o", "# 16 byte long hashing key\r\n"]
[1008.734262, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[1008.815311, "o", "\r\n"]
[1008.896361, "o", "\r\n"]
[1008.97741, "o", "def combine_hash_arrays(\r\n"]
[1009.058459, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[1009.139508, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[1009.220557, "o", "    \"\"\"\r\n"]
[1009.301607, "o", "    Parameters\r\n"]
[1009.382656, "o", "    ----------\r\n"]
[1009.463705, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[1009.544754, "o", "    num_items : int\r\n"]
[1009.625803, "o", "\r\n"]
[1009.706852, "o", "    Returns\r\n"]
[1009.787902, "o", "    -------\r\n"]
[1009.868951, "o", "    np.ndarray[uint64]\r\n"]
[1010.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[1010.002, "i", "git show HEAD^:pandas/core/util/hashing.py > /tmp/hashing_prev.py && wc -l /tmp/hashing_prev.py\r"]
[1010.004, "o", "git show HEAD^:pandas/core/util/hashing.py > /tmp/hashing_prev.py && wc -l /tmp/hashing_prev.py\r\n"]
[1012.478, "o", "\u001b[?2004l\r\n"]
[1015.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[1015.002, "i", "cp /tmp/hashing_prev.py pandas/core/util/hashing.py\r"]
[1015.004, "o", "cp /tmp/hashing_prev.py pandas/core/util/hashing.py\r\n"]
[1015.006, "o", "\u001b[?2004l\r\n"]
[1020.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[1020.002, "i", "git add pandas/core/util/hashing.py && git commit -m \"revert: restore hashing.py to last known-good version to fix \r"]
[1020.004, "o", "git add pandas/core/util/hashing.py && git commit -m \"revert: restore hashing.py to last known-good version to fix \r\n"]
[1021.242, "o", " SyntaxError\"\r\n"]
[1022.478, "o", "\u001b[?2004l\r\n"]
[1023.714, "o", "[opt/hash-string-memo 36074a37fc] revert: restore hashing.py to last known-good version to fix SyntaxError\r\n"]
[1025.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[1025.002, "i", "cd asv_bench\r"]
[1025.004, "o", "cd asv_bench\r\n"]
[1025.006, "o", "\u001b[?2004l\r\n"]
[1030.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[1030.002, "i", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r"]
[1030.004, "o", "asv run --python=same --bench=\"algorithms.Hashing.*\" --quick\r\n"]
[1030.418, "o", "\u001b[?2004l\r\n"]
[1030.83, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[1031.242, "o", "\u00b7 \u001b[0;32mRunning 7 total benchmarks (1 commits * 1 environments * 7 benchmarks)\u001b[0m\r\n"]
[1031.654, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.10_bin_python3.10\u001b[0m\r\n"]
[1032.066, "o", "[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39mSetting up algorithms:134\u001b[0m                                                                                                                       ok\r\n"]
[1032.478, "o", "[ 7.14%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_frame\u001b[0m                                                                                                             15.6\u00b10ms\r\n"]
[1032.89, "o", "[14.29%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_categorical\u001b[0m                                                                                                4.13\u00b10ms\r\n"]
[1033.302, "o", "[21.43%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_dates\u001b[0m                                                                                                      3.35\u00b10ms\r\n"]
[1033.714, "o", "[28.57%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_float\u001b[0m                                                                                                      3.36\u00b10ms\r\n"]
[1034.126, "o", "[35.71%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_int\u001b[0m                                                                                                        3.33\u00b10ms\r\n"]
[1034.538, "o", "[42.86%] \u00b7\u00b7\u00b7 \u001b[0;39malgorithms.Hashing.time_series_string\u001b[0m                                                                                                     10.5\u00b10ms\r\n"]
[1035.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo/asv_bench# "]
[1035.002, "i", "cd /workspace/repo\r"]
[1035.004, "o", "cd /workspace/repo\r\n"]
[1035.006, "o", "\u001b[?2004l\r\n"]
[1040.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[1040.002, "i", "sed -n '1,200p' pandas/core/util/hashing.py\r"]
[1040.004, "o", "sed -n '1,200p' pandas/core/util/hashing.py\r\n"]
[1040.030597, "o", "\u001b[?2004l\r\n"]
[1040.055194, "o", "\"\"\"\r\n"]
[1040.079791, "o", "data hash pandas / numpy objects\r\n"]
[1040.104388, "o", "\"\"\"\r\n"]
[1040.128985, "o", "\r\n"]
[1040.153582, "o", "from __future__ import annotations\r\n"]
[1040.178179, "o", "\r\n"]
[1040.202776, "o", "import itertools\r\n"]
[1040.227373, "o", "from typing import TYPE_CHECKING\r\n"]
[1040.25197, "o", "\r\n"]
[1040.276567, "o", "import numpy as np\r\n"]
[1040.301164, "o", "\r\n"]
[1040.325761, "o", "from pandas._libs.hashing import hash_object_array\r\n"]
[1040.350358, "o", "\r\n"]
[1040.374955, "o", "from pandas.core.dtypes.common import is_list_like\r\n"]
[1040.399552, "o", "from pandas.core.dtypes.dtypes import CategoricalDtype\r\n"]
[1040.424149, "o", "from pandas.core.dtypes.generic import (\r\n"]
[1040.448746, "o", "    ABCDataFrame,\r\n"]
[1040.473343, "o", "    ABCExtensionArray,\r\n"]
[1040.49794, "o", "    ABCIndex,\r\n"]
[1040.522537, "o", "    ABCMultiIndex,\r\n"]
[1040.547134, "o", "    ABCSeries,\r\n"]
[1040.571731, "o", ")\r\n"]
[1040.596328, "o", "\r\n"]
[1040.620925, "o", "if TYPE_CHECKING:\r\n"]
[1040.645522, "o", "    from collections.abc import (\r\n"]
[1040.670119, "o", "        Hashable,\r\n"]
[1040.694716, "o", "        Iterable,\r\n"]
[1040.719313, "o", "        Iterator,\r\n"]
[1040.74391, "o", "    )\r\n"]
[1040.768507, "o", "\r\n"]
[1040.793104, "o", "    from pandas._typing import (\r\n"]
[1040.817701, "o", "        ArrayLike,\r\n"]
[1040.842299, "o", "        npt,\r\n"]
[1040.866896, "o", "    )\r\n"]
[1040.891493, "o", "\r\n"]
[1040.91609, "o", "    from pandas import (\r\n"]
[1040.940687, "o", "        DataFrame,\r\n"]
[1040.965284, "o", "        Index,\r\n"]
[1040.989881, "o", "        MultiIndex,\r\n"]
[1041.014478, "o", "        Series,\r\n"]
[1041.039075, "o", "    )\r\n"]
[1041.063672, "o", "\r\n"]
[1041.088269, "o", "\r\n"]
[1041.112866, "o", "# 16 byte long hashing key\r\n"]
[1041.137463, "o", "_default_hash_key = \"0123456789123456\"\r\n"]
[1041.16206, "o", "\r\n"]
[1041.186657, "o", "\r\n"]
[1041.211254, "o", "def combine_hash_arrays(\r\n"]
[1041.235851, "o", "    arrays: Iterator[np.ndarray], num_items: int\r\n"]
[1041.260448, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[1041.285045, "o", "    \"\"\"\r\n"]
[1041.309642, "o", "    Parameters\r\n"]
[1041.334239, "o", "    ----------\r\n"]
[1041.358836, "o", "    arrays : Iterator[np.ndarray]\r\n"]
[1041.383433, "o", "    num_items : int\r\n"]
[1041.40803, "o", "\r\n"]
[1041.432627, "o", "    Returns\r\n"]
[1041.457224, "o", "    -------\r\n"]
[1041.481821, "o", "    np.ndarray[uint64]\r\n"]
[1041.506418, "o", "\r\n"]
[1041.531015, "o", "    Should be the same as CPython's tupleobject.c\r\n"]
[1041.555612, "o", "    \"\"\"\r\n"]
[1041.580209, "o", "    try:\r\n"]
[1041.604806, "o", "        first = next(arrays)\r\n"]
[1041.629403, "o", "    except StopIteration:\r\n"]
[1041.654, "o", "        return np.array([], dtype=np.uint64)\r\n"]
[1041.678597, "o", "\r\n"]
[1041.703194, "o", "    arrays = itertools.chain([first], arrays)\r\n"]
[1041.727791, "o", "\r\n"]
[1041.752388, "o", "    mult = np.uint64(1000003)\r\n"]
[1041.776985, "o", "    out = np.zeros_like(first) + np.uint64(0x345678)\r\n"]
[1041.801582, "o", "    last_i = 0\r\n"]
[1041.826179, "o", "    for i, a in enumerate(arrays):\r\n"]
[1041.850776, "o", "        inverse_i = num_items - i\r\n"]
[1041.875373, "o", "        out ^= a\r\n"]
[1041.89997, "o", "        out *= mult\r\n"]
[1041.924567, "o", "        mult += np.uint64(82520 + inverse_i + inverse_i)\r\n"]
[1041.949164, "o", "        last_i = i\r\n"]
[1041.973761, "o", "    assert last_i + 1 == num_items, \"Fed in wrong num_items\"\r\n"]
[1041.998358, "o", "    out += np.uint64(97531)\r\n"]
[1042.022955, "o", "    return out\r\n"]
[1042.047552, "o", "\r\n"]
[1042.072149, "o", "\r\n"]
[1042.096746, "o", "def hash_pandas_object(\r\n"]
[1042.121343, "o", "    obj: Index | DataFrame | Series,\r\n"]
[1042.14594, "o", "    index: bool = True,\r\n"]
[1042.170537, "o", "    encoding: str = \"utf8\",\r\n"]
[1042.195134, "o", "    hash_key: str | None = _default_hash_key,\r\n"]
[1042.219731, "o", "    categorize: bool = True,\r\n"]
[1042.244328, "o", ") -> Series:\r\n"]
[1042.268925, "o", "    \"\"\"\r\n"]
[1042.293522, "o", "    Return a data hash of the Index/Series/DataFrame.\r\n"]
[1042.318119, "o", "\r\n"]
[1042.342716, "o", "    Parameters\r\n"]
[1042.367313, "o", "    ----------\r\n"]
[1042.39191, "o", "    obj : Index, Series, or DataFrame\r\n"]
[1042.416507, "o", "    index : bool, default True\r\n"]
[1042.441104, "o", "        Include the index in the hash (if Series/DataFrame).\r\n"]
[1042.465701, "o", "    encoding : str, default 'utf8'\r\n"]
[1042.490299, "o", "        Encoding for data & key when strings.\r\n"]
[1042.514896, "o", "    hash_key : str, default _default_hash_key\r\n"]
[1042.539493, "o", "        Hash_key for string key to encode.\r\n"]
[1042.56409, "o", "    categorize : bool, default True\r\n"]
[1042.588687, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[1042.613284, "o", "        efficient when the array contains duplicate values.\r\n"]
[1042.637881, "o", "\r\n"]
[1042.662478, "o", "    Returns\r\n"]
[1042.687075, "o", "    -------\r\n"]
[1042.711672, "o", "    Series of uint64\r\n"]
[1042.736269, "o", "        Same length as the object.\r\n"]
[1042.760866, "o", "\r\n"]
[1042.785463, "o", "    Examples\r\n"]
[1042.81006, "o", "    --------\r\n"]
[1042.834657, "o", "    >>> pd.util.hash_pandas_object(pd.Series([1, 2, 3]))\r\n"]
[1042.859254, "o", "    0    14639053686158035780\r\n"]
[1042.883851, "o", "    1     3869563279212530728\r\n"]
[1042.908448, "o", "    2      393322362522515241\r\n"]
[1042.933045, "o", "    dtype: uint64\r\n"]
[1042.957642, "o", "    \"\"\"\r\n"]
[1042.982239, "o", "    from pandas import Series\r\n"]
[1043.006836, "o", "\r\n"]
[1043.031433, "o", "    if hash_key is None:\r\n"]
[1043.05603, "o", "        hash_key = _default_hash_key\r\n"]
[1043.080627, "o", "\r\n"]
[1043.105224, "o", "    if isinstance(obj, ABCMultiIndex):\r\n"]
[1043.129821, "o", "        return Series(hash_tuples(obj, encoding, hash_key), dtype=\"uint64\", copy=False)\r\n"]
[1043.154418, "o", "\r\n"]
[1043.179015, "o", "    elif isinstance(obj, ABCIndex):\r\n"]
[1043.203612, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[1043.228209, "o", "            \"uint64\", copy=False\r\n"]
[1043.252806, "o", "        )\r\n"]
[1043.277403, "o", "        ser = Series(h, index=obj, dtype=\"uint64\", copy=False)\r\n"]
[1043.302, "o", "\r\n"]
[1043.326597, "o", "    elif isinstance(obj, ABCSeries):\r\n"]
[1043.351194, "o", "        h = hash_array(obj._values, encoding, hash_key, categorize).astype(\r\n"]
[1043.375791, "o", "            \"uint64\", copy=False\r\n"]
[1043.400388, "o", "        )\r\n"]
[1043.424985, "o", "        if index:\r\n"]
[1043.449582, "o", "            index_iter = (\r\n"]
[1043.474179, "o", "                hash_pandas_object(\r\n"]
[1043.498776, "o", "                    obj.index,\r\n"]
[1043.523373, "o", "                    index=False,\r\n"]
[1043.54797, "o", "                    encoding=encoding,\r\n"]
[1043.572567, "o", "                    hash_key=hash_key,\r\n"]
[1043.597164, "o", "                    categorize=categorize,\r\n"]
[1043.621761, "o", "                )._values\r\n"]
[1043.646358, "o", "                for _ in [None]\r\n"]
[1043.670955, "o", "            )\r\n"]
[1043.695552, "o", "            arrays = itertools.chain([h], index_iter)\r\n"]
[1043.720149, "o", "            h = combine_hash_arrays(arrays, 2)\r\n"]
[1043.744746, "o", "\r\n"]
[1043.769343, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[1043.79394, "o", "\r\n"]
[1043.818537, "o", "    elif isinstance(obj, ABCDataFrame):\r\n"]
[1043.843134, "o", "        hashes = (\r\n"]
[1043.867731, "o", "            hash_array(series._values, encoding, hash_key, categorize)\r\n"]
[1043.892328, "o", "            for _, series in obj.items()\r\n"]
[1043.916925, "o", "        )\r\n"]
[1043.941522, "o", "        num_items = len(obj.columns)\r\n"]
[1043.966119, "o", "        if index:\r\n"]
[1043.990716, "o", "            index_hash_generator = (\r\n"]
[1044.015313, "o", "                hash_pandas_object(\r\n"]
[1044.03991, "o", "                    obj.index,\r\n"]
[1044.064507, "o", "                    index=False,\r\n"]
[1044.089104, "o", "                    encoding=encoding,\r\n"]
[1044.113701, "o", "                    hash_key=hash_key,\r\n"]
[1044.138299, "o", "                    categorize=categorize,\r\n"]
[1044.162896, "o", "                )._values\r\n"]
[1044.187493, "o", "                for _ in [None]\r\n"]
[1044.21209, "o", "            )\r\n"]
[1044.236687, "o", "            num_items += 1\r\n"]
[1044.261284, "o", "\r\n"]
[1044.285881, "o", "            # keep `hashes` specifically a generator to keep mypy happy\r\n"]
[1044.310478, "o", "            _hashes = itertools.chain(hashes, index_hash_generator)\r\n"]
[1044.335075, "o", "            hashes = (x for x in _hashes)\r\n"]
[1044.359672, "o", "        h = combine_hash_arrays(hashes, num_items)\r\n"]
[1044.384269, "o", "\r\n"]
[1044.408866, "o", "        ser = Series(h, index=obj.index, dtype=\"uint64\", copy=False)\r\n"]
[1044.433463, "o", "    else:\r\n"]
[1044.45806, "o", "        raise TypeError(f\"Unexpected type for hashing {type(obj)}\")\r\n"]
[1044.482657, "o", "\r\n"]
[1044.507254, "o", "    return ser\r\n"]
[1044.531851, "o", "\r\n"]
[1044.556448, "o", "\r\n"]
[1044.581045, "o", "def hash_tuples(\r\n"]
[1044.605642, "o", "    vals: MultiIndex | Iterable[tuple[Hashable, ...]],\r\n"]
[1044.630239, "o", "    encoding: str = \"utf8\",\r\n"]
[1044.654836, "o", "    hash_key: str = _default_hash_key,\r\n"]
[1044.679433, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[1044.70403, "o", "    \"\"\"\r\n"]
[1044.728627, "o", "    Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[1044.753224, "o", "\r\n"]
[1044.777821, "o", "    Parameters\r\n"]
[1044.802418, "o", "    ----------\r\n"]
[1044.827015, "o", "    vals : MultiIndex or listlike-of-tuples\r\n"]
[1044.851612, "o", "    encoding : str, default 'utf8'\r\n"]
[1044.876209, "o", "    hash_key : str, default _default_hash_key\r\n"]
[1044.900806, "o", "\r\n"]
[1044.925403, "o", "    Returns\r\n"]
[1045.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[1045.002, "i", "sed -n '200,420p' pandas/core/util/hashing.py\r"]
[1045.004, "o", "sed -n '200,420p' pandas/core/util/hashing.py\r\n"]
[1045.039181, "o", "\u001b[?2004l\r\n"]
[1045.072362, "o", "    -------\r\n"]
[1045.105544, "o", "    ndarray[np.uint64] of hashed values\r\n"]
[1045.138725, "o", "    \"\"\"\r\n"]
[1045.171906, "o", "    if not is_list_like(vals):\r\n"]
[1045.205087, "o", "        raise TypeError(\"must be convertible to a list-of-tuples\")\r\n"]
[1045.238268, "o", "\r\n"]
[1045.27145, "o", "    from pandas import (\r\n"]
[1045.304631, "o", "        Categorical,\r\n"]
[1045.337812, "o", "        MultiIndex,\r\n"]
[1045.370993, "o", "    )\r\n"]
[1045.404174, "o", "\r\n"]
[1045.437356, "o", "    if not isinstance(vals, ABCMultiIndex):\r\n"]
[1045.470537, "o", "        mi = MultiIndex.from_tuples(vals)\r\n"]
[1045.503718, "o", "    else:\r\n"]
[1045.536899, "o", "        mi = vals\r\n"]
[1045.570081, "o", "\r\n"]
[1045.603262, "o", "    # create a list-of-Categoricals\r\n"]
[1045.636443, "o", "    cat_vals = [\r\n"]
[1045.669624, "o", "        Categorical._simple_new(\r\n"]
[1045.702805, "o", "            mi.codes[level],\r\n"]
[1045.735987, "o", "            CategoricalDtype(categories=mi.levels[level], ordered=False),\r\n"]
[1045.769168, "o", "        )\r\n"]
[1045.802349, "o", "        for level in range(mi.nlevels)\r\n"]
[1045.83553, "o", "    ]\r\n"]
[1045.868711, "o", "\r\n"]
[1045.901893, "o", "    # hash the list-of-ndarrays\r\n"]
[1045.935074, "o", "    hashes = (\r\n"]
[1045.968255, "o", "        cat._hash_pandas_object(encoding=encoding, hash_key=hash_key, categorize=False)\r\n"]
[1046.001436, "o", "        for cat in cat_vals\r\n"]
[1046.034617, "o", "    )\r\n"]
[1046.067799, "o", "    h = combine_hash_arrays(hashes, len(cat_vals))\r\n"]
[1046.10098, "o", "\r\n"]
[1046.134161, "o", "    return h\r\n"]
[1046.167342, "o", "\r\n"]
[1046.200523, "o", "\r\n"]
[1046.233705, "o", "def hash_array(\r\n"]
[1046.266886, "o", "    vals: ArrayLike,\r\n"]
[1046.300067, "o", "    encoding: str = \"utf8\",\r\n"]
[1046.333248, "o", "    hash_key: str = _default_hash_key,\r\n"]
[1046.36643, "o", "    categorize: bool = True,\r\n"]
[1046.399611, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[1046.432792, "o", "    \"\"\"\r\n"]
[1046.465973, "o", "    Given a 1d array, return an array of deterministic integers.\r\n"]
[1046.499154, "o", "\r\n"]
[1046.532336, "o", "    Parameters\r\n"]
[1046.565517, "o", "    ----------\r\n"]
[1046.598698, "o", "    vals : ndarray or ExtensionArray\r\n"]
[1046.631879, "o", "        The input array to hash.\r\n"]
[1046.66506, "o", "    encoding : str, default 'utf8'\r\n"]
[1046.698242, "o", "        Encoding for data & key when strings.\r\n"]
[1046.731423, "o", "    hash_key : str, default _default_hash_key\r\n"]
[1046.764604, "o", "        Hash_key for string key to encode.\r\n"]
[1046.797785, "o", "    categorize : bool, default True\r\n"]
[1046.830966, "o", "        Whether to first categorize object arrays before hashing. This is more\r\n"]
[1046.864148, "o", "        efficient when the array contains duplicate values.\r\n"]
[1046.897329, "o", "\r\n"]
[1046.93051, "o", "    Returns\r\n"]
[1046.963691, "o", "    -------\r\n"]
[1046.996872, "o", "    ndarray[np.uint64, ndim=1]\r\n"]
[1047.030054, "o", "        Hashed values, same length as the vals.\r\n"]
[1047.063235, "o", "\r\n"]
[1047.096416, "o", "    See Also\r\n"]
[1047.129597, "o", "    --------\r\n"]
[1047.162779, "o", "    util.hash_pandas_object : Return a data hash of the Index/Series/DataFrame.\r\n"]
[1047.19596, "o", "    util.hash_tuples : Hash an MultiIndex / listlike-of-tuples efficiently.\r\n"]
[1047.229141, "o", "\r\n"]
[1047.262322, "o", "    Examples\r\n"]
[1047.295503, "o", "    --------\r\n"]
[1047.328685, "o", "    >>> pd.util.hash_array(np.array([1, 2, 3]))\r\n"]
[1047.361866, "o", "    array([ 6238072747940578789, 15839785061582574730,  2185194620014831856],\r\n"]
[1047.395047, "o", "      dtype=uint64)\r\n"]
[1047.428228, "o", "    \"\"\"\r\n"]
[1047.461409, "o", "    if not hasattr(vals, \"dtype\"):\r\n"]
[1047.494591, "o", "        raise TypeError(\"must pass a ndarray-like\")\r\n"]
[1047.527772, "o", "\r\n"]
[1047.560953, "o", "    if isinstance(vals, ABCExtensionArray):\r\n"]
[1047.594134, "o", "        return vals._hash_pandas_object(\r\n"]
[1047.627315, "o", "            encoding=encoding, hash_key=hash_key, categorize=categorize\r\n"]
[1047.660497, "o", "        )\r\n"]
[1047.693678, "o", "\r\n"]
[1047.726859, "o", "    if not isinstance(vals, np.ndarray):\r\n"]
[1047.76004, "o", "        # GH#42003\r\n"]
[1047.793221, "o", "        raise TypeError(\r\n"]
[1047.826403, "o", "            \"hash_array requires np.ndarray or ExtensionArray, not \"\r\n"]
[1047.859584, "o", "            f\"{type(vals).__name__}. Use hash_pandas_object instead.\"\r\n"]
[1047.892765, "o", "        )\r\n"]
[1047.925946, "o", "\r\n"]
[1047.959128, "o", "    return _hash_ndarray(vals, encoding, hash_key, categorize)\r\n"]
[1047.992309, "o", "\r\n"]
[1048.02549, "o", "\r\n"]
[1048.058671, "o", "def _hash_ndarray(\r\n"]
[1048.091852, "o", "    vals: np.ndarray,\r\n"]
[1048.125034, "o", "    encoding: str = \"utf8\",\r\n"]
[1048.158215, "o", "    hash_key: str = _default_hash_key,\r\n"]
[1048.191396, "o", "    categorize: bool = True,\r\n"]
[1048.224577, "o", ") -> npt.NDArray[np.uint64]:\r\n"]
[1048.257758, "o", "    \"\"\"\r\n"]
[1048.29094, "o", "    See hash_array.__doc__.\r\n"]
[1048.324121, "o", "    \"\"\"\r\n"]
[1048.357302, "o", "    dtype = vals.dtype\r\n"]
[1048.390483, "o", "\r\n"]
[1048.423664, "o", "    # _hash_ndarray only takes 64-bit values, so handle 128-bit by parts\r\n"]
[1048.456846, "o", "    if np.issubdtype(dtype, np.complex128):\r\n"]
[1048.490027, "o", "        hash_real = _hash_ndarray(vals.real, encoding, hash_key, categorize)\r\n"]
[1048.523208, "o", "        hash_imag = _hash_ndarray(vals.imag, encoding, hash_key, categorize)\r\n"]
[1048.556389, "o", "        return hash_real + 23 * hash_imag\r\n"]
[1048.58957, "o", "\r\n"]
[1048.622752, "o", "    # First, turn whatever array this is into unsigned 64-bit ints, if we can\r\n"]
[1048.655933, "o", "    # manage it.\r\n"]
[1048.689114, "o", "    if dtype == bool:\r\n"]
[1048.722295, "o", "        vals = vals.astype(\"u8\")\r\n"]
[1048.755477, "o", "    elif issubclass(dtype.type, (np.datetime64, np.timedelta64)):\r\n"]
[1048.788658, "o", "        vals = vals.view(\"i8\").astype(\"u8\", copy=False)\r\n"]
[1048.821839, "o", "    elif issubclass(dtype.type, np.number) and dtype.itemsize <= 8:\r\n"]
[1048.85502, "o", "        vals = vals.view(f\"u{vals.dtype.itemsize}\").astype(\"u8\")\r\n"]
[1048.888201, "o", "    else:\r\n"]
[1048.921383, "o", "        # With repeated values, its MUCH faster to categorize object dtypes,\r\n"]
[1048.954564, "o", "        # then hash and rename categories. We allow skipping the categorization\r\n"]
[1048.987745, "o", "        # when the values are known/likely to be unique.\r\n"]
[1049.020926, "o", "        if categorize:\r\n"]
[1049.054107, "o", "            from pandas import (\r\n"]
[1049.087289, "o", "                Categorical,\r\n"]
[1049.12047, "o", "                Index,\r\n"]
[1049.153651, "o", "                factorize,\r\n"]
[1049.186832, "o", "            )\r\n"]
[1049.220013, "o", "\r\n"]
[1049.253195, "o", "            codes, categories = factorize(vals, sort=False)\r\n"]
[1049.286376, "o", "            dtype = CategoricalDtype(categories=Index(categories), ordered=False)\r\n"]
[1049.319557, "o", "            cat = Categorical._simple_new(codes, dtype)\r\n"]
[1049.352738, "o", "            return cat._hash_pandas_object(\r\n"]
[1049.385919, "o", "                encoding=encoding, hash_key=hash_key, categorize=False\r\n"]
[1049.419101, "o", "            )\r\n"]
[1049.452282, "o", "\r\n"]
[1049.485463, "o", "        try:\r\n"]
[1049.518644, "o", "            vals = hash_object_array(vals, hash_key, encoding)\r\n"]
[1049.551826, "o", "        except TypeError:\r\n"]
[1049.585007, "o", "            # we have mixed types\r\n"]
[1049.618188, "o", "            vals = hash_object_array(\r\n"]
[1049.651369, "o", "                vals.astype(str).astype(object), hash_key, encoding\r\n"]
[1049.68455, "o", "            )\r\n"]
[1049.717732, "o", "\r\n"]
[1049.750913, "o", "    # Then, redistribute these 64-bit ints within the space of 64-bit ints\r\n"]
[1049.784094, "o", "    vals ^= vals >> 30\r\n"]
[1049.817275, "o", "    vals *= np.uint64(0xBF58476D1CE4E5B9)\r\n"]
[1049.850456, "o", "    vals ^= vals >> 27\r\n"]
[1049.883638, "o", "    vals *= np.uint64(0x94D049BB133111EB)\r\n"]
[1049.916819, "o", "    vals ^= vals >> 31\r\n"]
[1050.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[1050.002, "i", "grep -n \"astype(str).*hash_key, encoding\" pandas/core/util/hashing.py || true\r"]
[1050.004, "o", "grep -n \"astype(str).*hash_key, encoding\" pandas/core/util/hashing.py || true\r\n"]
[1052.478, "o", "\u001b[?2004l\r\n"]
[1055.0, "o", "(asv_3.10) root@937d3033b2a8:/workspace/repo# "]
[1055.002, "i", "\u001b[?2004l\r"]
[1055.004, "o", "\u001b[?2004l\r\n"]
[1057.478, "o", "\r\n"]
