{"version": 2, "width": 160, "height": 40, "timestamp": 1762942241, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[0.006, "o", "\u001b[?2004l\r\n\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n\u001b[0;31masciinema: use --append option if you want to append to existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[5.006, "o", "\u001b[?2004l\r\n\u001b[H\u001b[J\r\n"]
[10.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.006, "o", "\u001b[?2004l\r\ntotal 212\r\ndrwxr-xr-x 1 root root  4096 Oct  1 18:58 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 15 18:14 \u001b[01;34m..\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 12 12:35 \u001b[01;34m.circleci\u001b[0m\r\n-rw-r--r-- 1 root root  1021 Sep 12 12:35 .devcontainer.json\r\ndrwxr-xr-x 1 root root  4096 Oct  1 18:58 \u001b[01;34m.git\u001b[0m\r\n-rw-r--r-- 1 root root   229 Sep 12 12:35 .gitattributes\r\ndrwxr-xr-x 1 root root  4096 Sep 12 12:35 \u001b[01;34m.github\u001b[0m\r\n-rw-r--r-- 1 root root  1740 Sep 12 12:35 .gitignore\r\n-rw-r--r-- 1 root root  2322 Sep 12 12:35 .gitpod.yml\r\n-rw-r--r-- 1 root root   761 Sep 12 12:35 .libcst.codemod.yaml\r\n-rw-r--r-- 1 root root   109 Sep 12 12:35 .pep8speaks.yml\r\n-rw-r--r-- 1 root root 16092 Sep 12 12:35 .pre-commit-config.yaml\r\n-rw-r--r-- 1 root root  2284 Sep 12 12:35 AUTHORS.md\r\n-rw-r--r-- 1 root root   372 Sep 12 12:35 CITATION.cff\r\n-rw-r--r-- 1 root root   369 Sep 12 12:35 Dockerfile\r\n-rw-r--r-- 1 root root  1634 Sep 12 12:35 LICENSE\r\ndrwxr-xr-x 1 root root  4096 Sep 12 12:35 \u001b[01;34mLICENSES\u001b[0m\r\n-rw-r--r-- 1 root root  1228 Sep 12 12:35 MANIFEST.in\r\n-rw-r--r-- 1 root root 10387 Sep 12 12:35 README.md\r\n-rw-r--r-- 1 root root   246 Sep 12 12:35 RELEASE.md\r\ndrwxr-xr-x 1 root root  4096 Sep 12 12:35 \u001b[01;34masv_bench\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 12:35 \u001b[01;34mci\u001b[0m\r\n-rw-r--r-- 1 root root   256 Sep 12 12:34 codecov.yml\r\ndrwxr-xr-x 1 root root  4096 Sep 12 12:35 \u001b[01;34mdoc\u001b[0m\r\n-rw-r--r-- 1 root root  2112 Sep 12 12:35 environment.yml\r\ndrwxr-xr-x 1 root root  4096 Sep 12 12:35 \u001b[01;34mgitpod\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 15 18:14 \u001b[01;34mpandas\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 15 18:05 \u001b[01;34mpandas.egg-info\u001b[0m\r\n-rw-r--r-- 1 root root 15403 Sep 12 12:35 pyproject.toml\r\n-rw-r--r-- 1 root root  4429 Sep 12 12:35 pyright_reportGeneralTypeIssues.json\r\n-rw-r--r-- 1 root root  1099 Sep 12 12:35 requirements-dev.txt\r\ndrwxr-xr-x 1 root root  4096 Sep 12 12:35 \u001b[01;34mscripts\u001b[0m\r\n-rw-r--r-- 1 root root  2095 Sep 12 12:35 setup.cfg\r\n-rwxr-xr-x 1 root root 21964 Sep 12 12:35 \u001b[01;32msetup.py\u001b[0m\r\ndrwxr-xr-x 2 root root  4096 Sep 12 12:34 \u001b[01;34mtypings\u001b[0m\r\ndrwxr-xr-x 1 root root  4096 Sep 12 12:35 \u001b[01;34mweb\u001b[0m\r\n"]
[15.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[15.002, "i", "git rev-parse --show-toplevel\r"]
[15.004, "o", "git rev-parse --show-toplevel\r\n"]
[15.006, "o", "\u001b[?2004l\r\n/workspace/repo\r\n"]
[20.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[20.002, "i", "find . -maxdepth 3 -type f -iname \"asv*.json\" -o -iname \"asv.conf.json\" -o -iname \"*.asv.json\"\r"]
[20.004, "o", "find . -maxdepth 3 -type f -iname \"asv*.json\" -o -iname \"asv.conf.json\" -o -iname \"*.asv.json\"\r\n"]
[20.006, "o", "\u001b[?2004l\r\n./asv_bench/asv.conf.json\r\n"]
[25.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[25.002, "i", "find . -maxdepth 3 -type f -iname \"asv_benchmarks.txt\" -o -path \"*/asv_bench/*\" -o -path \"*/benchmarks/*\" | sed -n '\r"]
[25.004, "o", "find . -maxdepth 3 -type f -iname \"asv_benchmarks.txt\" -o -path \"*/asv_bench/*\" -o -path \"*/benchmarks/*\" | sed -n '\r\n"]
[25.006, "o", "'1,200p'\r\n\u001b[?2004l\r\n./asv_bench/benchmarks\r\n./asv_bench/benchmarks/groupby.py\r\n./asv_bench/benchmarks/eval.py\r\n./asv_bench/benchmarks/finalize.py\r\n./asv_bench/benchmarks/ctors.py\r\n./asv_bench/benchmarks/period.py\r\n./asv_bench/benchmarks/package.py\r\n./asv_bench/benchmarks/algos\r\n./asv_bench/benchmarks/tslibs\r\n./asv_bench/benchmarks/join_merge.py\r\n./asv_bench/benchmarks/array.py\r\n./asv_bench/benchmarks/indexing_engines.py\r\n./asv_bench/benchmarks/dtypes.py\r\n./asv_bench/benchmarks/reshape.py\r\n./asv_bench/benchmarks/gil.py\r\n./asv_bench/benchmarks/multiindex_object.py\r\n./asv_bench/benchmarks/replace.py\r\n./asv_bench/benchmarks/categoricals.py\r\n./asv_bench/benchmarks/reindex.py\r\n./asv_bench/benchmarks/index_cached_properties.py\r\n./asv_bench/benchmarks/strings.py\r\n./asv_bench/benchmarks/stat_ops.py\r\n./asv_bench/benchmarks/libs.py\r\n./asv_bench/benchmarks/indexing.py\r\n./asv_bench/benchmarks/frame_methods.py\r\n./asv_bench/benchmarks/timeseries.py\r\n./asv_bench/benchmarks/rolling.py\r\n./asv_bench/benchmarks/pandas_vb_common.py\r\n./asv_bench/benchmarks/index_object.py\r\n./asv_bench/benchmarks/series_methods.py\r\n./asv_bench/benchmarks/attrs_caching.py\r\n./asv_bench/benchmarks/algorithms.py\r\n./asv_bench/benchmarks/frame_ctor.py\r\n./asv_bench/benchmarks/inference.py\r\n./asv_bench/benchmarks/hash_functions.py\r\n./asv_bench/benchmarks/timedelta.py\r\n./asv_bench/benchmarks/__init__.py\r\n./asv_bench/benchmarks/io\r\n./asv_bench/benchmarks/boolean.py\r\n./asv_bench/benchmarks/strftime.py\r\n./asv_bench/benchmarks/sparse.py\r\n./asv_bench/benchmarks/plotting.py\r\n./asv_bench/benchmarks/arithmetic.py\r\n./asv_bench/asv.conf.json\r\n"]
[30.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[30.002, "i", "grep -Rsn \"class .*Benchmark\" -n . | sed -n '1,100p'\r"]
[30.004, "o", "grep -Rsn \"class .*Benchmark\" -n . | sed -n '1,100p'\r\n"]
[30.006, "o", "\u001b[?2004l\r\n"]
[35.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[35.002, "i", "git status -s\r"]
[35.004, "o", "git status -s\r\n"]
[35.006, "o", "\u001b[?2004l\r\n"]
[40.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[40.002, "i", "sed -n '1,200p' asv_bench/asv.conf.json\r"]
[40.004, "o", "sed -n '1,200p' asv_bench/asv.conf.json\r\n"]
[40.006, "o", "\u001b[?2004l\r\n{\r\n    // The version of the config file format.  Do not change, unless\r\n    // you know what you are doing.\r\n    \"version\": 1,\r\n\r\n    // The name of the project being benchmarked\r\n    \"project\": \"pandas\",\r\n\r\n    // The project's homepage\r\n    \"project_url\": \"https://pandas.pydata.org/\",\r\n\r\n    // The URL of the source code repository for the project being\r\n    // benchmarked\r\n    \"repo\": \"..\",\r\n\r\n    // List of branches to benchmark. If not provided, defaults to \"master\"\r\n    // (for git) or \"default\" (for mercurial).\r\n    \"branches\": [\"main\"],\r\n\r\n    // The tool to use to create environments.  May be \"conda\",\r\n    // \"virtualenv\" or other value depending on the plugins in use.\r\n    // If missing or the empty string, the tool will be automatically\r\n    // determined by looking for tools on the PATH environment\r\n    // variable.\r\n    \"environment_type\": \"conda\",\r\n\r\n    // the base URL to show a commit for the project.\r\n    \"show_commit_url\": \"https://github.com/pandas-dev/pandas/commit/\",\r\n\r\n    // The Pythons you'd like to test against.  If not provided, defaults\r\n    // to the current version of Python used to run `asv`.\r\n    \"pythons\": [\"3.8\"],\r\n\r\n    // The matrix of dependencies to test.  Each key is the name of a\r\n    // package (in PyPI) and the values are version numbers.  An empty\r\n    // list or empty string indicates to just test against the default\r\n    // (latest) version. null indicates that the package is to not be\r\n    // installed. If the package to be tested is only available from\r\n    // PyPi, and the 'environment_type' is conda, then you can preface\r\n    // the package name by 'pip+', and the package will be installed via\r\n    // pip (with all the conda available packages installed first,\r\n    // followed by the pip installed packages).\r\n    \"matrix\": {\r\n        \"numpy\": [],\r\n        \"Cython\": [\"0.29.32\"],\r\n        \"matplotlib\": [],\r\n        \"sqlalchemy\": [],\r\n        \"scipy\": [],\r\n        \"numba\": [],\r\n        \"numexpr\": [],\r\n        \"pytables\": [null, \"\"],  // platform dependent, see excludes below\r\n        \"pyarrow\": [],\r\n        \"tables\": [null, \"\"],\r\n        \"openpyxl\": [],\r\n        \"xlsxwriter\": [],\r\n        \"xlrd\": [],\r\n        \"odfpy\": [],\r\n        \"jinja2\": [],\r\n    },\r\n    \"conda_channels\": [\"conda-forge\"],\r\n    // Combinations of libraries/python versions can be excluded/included\r\n    // from the set to test. Each entry is a dictionary containing additional\r\n    // key-value pairs to include/exclude.\r\n    //\r\n    // An exclude entry excludes entries where all values match. The\r\n    // values are regexps that should match the whole string.\r\n    //\r\n    // An include entry adds an environment. Only the packages listed\r\n    // are installed. The 'python' key is required. The exclude rules\r\n    // do not apply to includes.\r\n    //\r\n    // In addition to package names, the following keys are available:\r\n    //\r\n    // - python\r\n    //     Python version, as in the *pythons* variable above.\r\n    // - environment_type\r\n    //     Environment type, as above.\r\n    // - sys_platform\r\n    //     Platform, as in sys.platform. Possible values for the common\r\n    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.\r\n    \"exclude\": [\r\n        // On conda install pytables, otherwise tables\r\n        {\"environment_type\": \"conda\", \"tables\": \"\"},\r\n        {\"environment_type\": \"conda\", \"pytables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"tables\": null},\r\n        {\"environment_type\": \"(?!conda).*\", \"pytables\": \"\"},\r\n    ],\r\n    \"include\": [],\r\n\r\n    // The directory (relative to the current directory) that benchmarks are\r\n    // stored in.  If not provided, defaults to \"benchmarks\"\r\n    // \"benchmark_dir\": \"benchmarks\",\r\n\r\n    // The directory (relative to the current directory) to cache the Python\r\n    // environments in.  If not provided, defaults to \"env\"\r\n    // \"env_dir\": \"env\",\r\n\r\n    // The directory (relative to the current directory) that raw benchmark\r\n    // results are stored in.  If not provided, defaults to \"results\".\r\n    // \"results_dir\": \"results\",\r\n\r\n    // The directory (relative to the current directory) that the html tree\r\n    // should be written to.  If not provided, defaults to \"html\".\r\n    // \"html_dir\": \"html\",\r\n\r\n    // The number of characters to retain in the commit hashes.\r\n    // \"hash_length\": 8,\r\n\r\n    // `asv` will cache wheels of the recent builds in each\r\n    // environment, making them faster to install next time.  This is\r\n    // number of builds to keep, per environment.\r\n    \"build_cache_size\": 8,\r\n\r\n    // The commits after which the regression search in `asv publish`\r\n    // should start looking for regressions. Dictionary whose keys are\r\n    // regexps matching to benchmark names, and values corresponding to\r\n    // the commit (exclusive) after which to start looking for\r\n    // regressions.  The default is to start from the first commit\r\n    // with results. If the commit is `null`, regression detection is\r\n    // skipped for the matching benchmark.\r\n    //\r\n    \"regressions_first_commits\": {\r\n        \".*\": \"0409521665\"\r\n    },\r\n    \"regression_thresholds\": {\r\n    },\r\n    \"build_command\":\r\n    [\"python -m pip install versioneer[toml]\",\r\n     \"python setup.py build -j4\",\r\n     \"PIP_NO_BUILD_ISOLATION=false python -mpip wheel --no-deps --no-index -w {build_cache_dir} {build_dir}\"],\r\n}\r\n"]
[45.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[45.002, "i", "sed -n '1,200p' asv_bench/benchmarks/frame_methods.py\r"]
[45.004, "o", "sed -n '1,200p' asv_bench/benchmarks/frame_methods.py\r\n"]
[45.006, "o", "\u001b[?2004l\r\nimport string\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas import (\r\n    DataFrame,\r\n    MultiIndex,\r\n    NaT,\r\n    Series,\r\n    date_range,\r\n    isnull,\r\n    period_range,\r\n    timedelta_range,\r\n)\r\n\r\nfrom .pandas_vb_common import tm\r\n\r\n\r\nclass GetNumericData:\r\n    def setup(self):\r\n        self.df = DataFrame(np.random.randn(10000, 25))\r\n        self.df[\"foo\"] = \"bar\"\r\n        self.df[\"bar\"] = \"baz\"\r\n        self.df = self.df._consolidate()\r\n\r\n    def time_frame_get_numeric_data(self):\r\n        self.df._get_numeric_data()\r\n\r\n\r\nclass Reindex:\r\n    def setup(self):\r\n        N = 10**3\r\n        self.df = DataFrame(np.random.randn(N * 10, N))\r\n        self.idx = np.arange(4 * N, 7 * N)\r\n        self.idx_cols = np.random.randint(0, N, N)\r\n        self.df2 = DataFrame(\r\n            {\r\n                c: {\r\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\r\n                    1: np.random.randint(0, N, N).astype(np.int16),\r\n                    2: np.random.randint(0, N, N).astype(np.int32),\r\n                    3: np.random.randint(0, N, N).astype(np.int64),\r\n                }[np.random.randint(0, 4)]\r\n                for c in range(N)\r\n            }\r\n        )\r\n\r\n    def time_reindex_axis0(self):\r\n        self.df.reindex(self.idx)\r\n\r\n    def time_reindex_axis1(self):\r\n        self.df.reindex(columns=self.idx_cols)\r\n\r\n    def time_reindex_axis1_missing(self):\r\n        self.df.reindex(columns=self.idx)\r\n\r\n    def time_reindex_both_axes(self):\r\n        self.df.reindex(index=self.idx, columns=self.idx_cols)\r\n\r\n    def time_reindex_upcast(self):\r\n        self.df2.reindex(np.random.permutation(range(1200)))\r\n\r\n\r\nclass Rename:\r\n    def setup(self):\r\n        N = 10**3\r\n        self.df = DataFrame(np.random.randn(N * 10, N))\r\n        self.idx = np.arange(4 * N, 7 * N)\r\n        self.dict_idx = {k: k for k in self.idx}\r\n        self.df2 = DataFrame(\r\n            {\r\n                c: {\r\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\r\n                    1: np.random.randint(0, N, N).astype(np.int16),\r\n                    2: np.random.randint(0, N, N).astype(np.int32),\r\n                    3: np.random.randint(0, N, N).astype(np.int64),\r\n                }[np.random.randint(0, 4)]\r\n                for c in range(N)\r\n            }\r\n        )\r\n\r\n    def time_rename_single(self):\r\n        self.df.rename({0: 0})\r\n\r\n    def time_rename_axis0(self):\r\n        self.df.rename(self.dict_idx)\r\n\r\n    def time_rename_axis1(self):\r\n        self.df.rename(columns=self.dict_idx)\r\n\r\n    def time_rename_both_axes(self):\r\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\r\n\r\n    def time_dict_rename_both_axes(self):\r\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\r\n\r\n\r\nclass Iteration:\r\n    # mem_itertuples_* benchmarks are slow\r\n    timeout = 120\r\n\r\n    def setup(self):\r\n        N = 1000\r\n        self.df = DataFrame(np.random.randn(N * 10, N))\r\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\r\n        self.df3 = DataFrame(\r\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\r\n        )\r\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))\r\n\r\n    def time_items(self):\r\n        # (monitor no-copying behaviour)\r\n        if hasattr(self.df, \"_item_cache\"):\r\n            self.df._item_cache.clear()\r\n        for name, col in self.df.items():\r\n            pass\r\n\r\n    def time_items_cached(self):\r\n        for name, col in self.df.items():\r\n            pass\r\n\r\n    def time_iteritems_indexing(self):\r\n        for col in self.df3:\r\n            self.df3[col]\r\n\r\n    def time_itertuples_start(self):\r\n        self.df4.itertuples()\r\n\r\n    def time_itertuples_read_first(self):\r\n        next(self.df4.itertuples())\r\n\r\n    def time_itertuples(self):\r\n        for row in self.df4.itertuples():\r\n            pass\r\n\r\n    def time_itertuples_to_list(self):\r\n        list(self.df4.itertuples())\r\n\r\n    def mem_itertuples_start(self):\r\n        return self.df4.itertuples()\r\n\r\n    def peakmem_itertuples_start(self):\r\n        self.df4.itertuples()\r\n\r\n    def mem_itertuples_read_first(self):\r\n        return next(self.df4.itertuples())\r\n\r\n    def peakmem_itertuples(self):\r\n        for row in self.df4.itertuples():\r\n            pass\r\n\r\n    def mem_itertuples_to_list(self):\r\n        return list(self.df4.itertuples())\r\n\r\n    def peakmem_itertuples_to_list(self):\r\n        list(self.df4.itertuples())\r\n\r\n    def time_itertuples_raw_start(self):\r\n        self.df4.itertuples(index=False, name=None)\r\n\r\n    def time_itertuples_raw_read_first(self):\r\n        next(self.df4.itertuples(index=False, name=None))\r\n\r\n    def time_itertuples_raw_tuples(self):\r\n        for row in self.df4.itertuples(index=False, name=None):\r\n            pass\r\n\r\n    def time_itertuples_raw_tuples_to_list(self):\r\n        list(self.df4.itertuples(index=False, name=None))\r\n\r\n    def mem_itertuples_raw_start(self):\r\n        return self.df4.itertuples(index=False, name=None)\r\n\r\n    def peakmem_itertuples_raw_start(self):\r\n        self.df4.itertuples(index=False, name=None)\r\n\r\n    def peakmem_itertuples_raw_read_first(self):\r\n        next(self.df4.itertuples(index=False, name=None))\r\n\r\n    def peakmem_itertuples_raw(self):\r\n        for row in self.df4.itertuples(index=False, name=None):\r\n            pass\r\n\r\n    def mem_itertuples_raw_to_list(self):\r\n        return list(self.df4.itertuples(index=False, name=None))\r\n\r\n    def peakmem_itertuples_raw_to_list(self):\r\n        list(self.df4.itertuples(index=False, name=None))\r\n\r\n    def time_iterrows(self):\r\n        for row in self.df.iterrows():\r\n            pass\r\n\r\n\r\nclass ToString:\r\n    def setup(self):\r\n        self.df = DataFrame(np.random.randn(100, 10))\r\n\r\n    def time_to_string_floats(self):\r\n"]
[50.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[50.002, "i", "sed -n '1,200p' asv_bench/benchmarks/index_object.py\r"]
[50.004, "o", "sed -n '1,200p' asv_bench/benchmarks/index_object.py\r\n"]
[50.006, "o", "\u001b[?2004l\r\nimport gc\r\n\r\nimport numpy as np\r\n\r\nfrom pandas import (\r\n    DatetimeIndex,\r\n    Index,\r\n    IntervalIndex,\r\n    MultiIndex,\r\n    RangeIndex,\r\n    Series,\r\n    date_range,\r\n)\r\n\r\nfrom .pandas_vb_common import tm\r\n\r\n\r\nclass SetOperations:\r\n\r\n    params = (\r\n        [\"monotonic\", \"non_monotonic\"],\r\n        [\"datetime\", \"date_string\", \"int\", \"strings\", \"ea_int\"],\r\n        [\"intersection\", \"union\", \"symmetric_difference\"],\r\n    )\r\n    param_names = [\"index_structure\", \"dtype\", \"method\"]\r\n\r\n    def setup(self, index_structure, dtype, method):\r\n        N = 10**5\r\n        dates_left = date_range(\"1/1/2000\", periods=N, freq=\"T\")\r\n        fmt = \"%Y-%m-%d %H:%M:%S\"\r\n        date_str_left = Index(dates_left.strftime(fmt))\r\n        int_left = Index(np.arange(N))\r\n        ea_int_left = Index(np.arange(N), dtype=\"Int64\")\r\n        str_left = tm.makeStringIndex(N)\r\n\r\n        data = {\r\n            \"datetime\": dates_left,\r\n            \"date_string\": date_str_left,\r\n            \"int\": int_left,\r\n            \"strings\": str_left,\r\n            \"ea_int\": ea_int_left,\r\n        }\r\n\r\n        if index_structure == \"non_monotonic\":\r\n            data = {k: mi[::-1] for k, mi in data.items()}\r\n\r\n        data = {k: {\"left\": idx, \"right\": idx[:-1]} for k, idx in data.items()}\r\n\r\n        self.left = data[dtype][\"left\"]\r\n        self.right = data[dtype][\"right\"]\r\n\r\n    def time_operation(self, index_structure, dtype, method):\r\n        getattr(self.left, method)(self.right)\r\n\r\n\r\nclass SetDisjoint:\r\n    def setup(self):\r\n        N = 10**5\r\n        B = N + 20000\r\n        self.datetime_left = DatetimeIndex(range(N))\r\n        self.datetime_right = DatetimeIndex(range(N, B))\r\n\r\n    def time_datetime_difference_disjoint(self):\r\n        self.datetime_left.difference(self.datetime_right)\r\n\r\n\r\nclass UnionWithDuplicates:\r\n    def setup(self):\r\n        self.left = Index(np.repeat(np.arange(1000), 100))\r\n        self.right = Index(np.tile(np.arange(500, 1500), 50))\r\n\r\n    def time_union_with_duplicates(self):\r\n        self.left.union(self.right)\r\n\r\n\r\nclass Range:\r\n    def setup(self):\r\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\r\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)\r\n\r\n    def time_max(self):\r\n        self.idx_inc.max()\r\n\r\n    def time_max_trivial(self):\r\n        self.idx_dec.max()\r\n\r\n    def time_min(self):\r\n        self.idx_dec.min()\r\n\r\n    def time_min_trivial(self):\r\n        self.idx_inc.min()\r\n\r\n    def time_get_loc_inc(self):\r\n        self.idx_inc.get_loc(900_000)\r\n\r\n    def time_get_loc_dec(self):\r\n        self.idx_dec.get_loc(100_000)\r\n\r\n    def time_iter_inc(self):\r\n        for _ in self.idx_inc:\r\n            pass\r\n\r\n    def time_iter_dec(self):\r\n        for _ in self.idx_dec:\r\n            pass\r\n\r\n    def time_sort_values_asc(self):\r\n        self.idx_inc.sort_values()\r\n\r\n    def time_sort_values_des(self):\r\n        self.idx_inc.sort_values(ascending=False)\r\n\r\n\r\nclass IndexEquals:\r\n    def setup(self):\r\n        idx_large_fast = RangeIndex(100_000)\r\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\r\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\r\n\r\n        self.idx_non_object = RangeIndex(1)\r\n\r\n    def time_non_object_equals_multiindex(self):\r\n        self.idx_non_object.equals(self.mi_large_slow)\r\n\r\n\r\nclass IndexAppend:\r\n    def setup(self):\r\n\r\n        N = 10_000\r\n        self.range_idx = RangeIndex(0, 100)\r\n        self.int_idx = self.range_idx.astype(int)\r\n        self.obj_idx = self.int_idx.astype(str)\r\n        self.range_idxs = []\r\n        self.int_idxs = []\r\n        self.object_idxs = []\r\n        for i in range(1, N):\r\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\r\n            self.range_idxs.append(r_idx)\r\n            i_idx = r_idx.astype(int)\r\n            self.int_idxs.append(i_idx)\r\n            o_idx = i_idx.astype(str)\r\n            self.object_idxs.append(o_idx)\r\n\r\n    def time_append_range_list(self):\r\n        self.range_idx.append(self.range_idxs)\r\n\r\n    def time_append_int_list(self):\r\n        self.int_idx.append(self.int_idxs)\r\n\r\n    def time_append_obj_list(self):\r\n        self.obj_idx.append(self.object_idxs)\r\n\r\n\r\nclass Indexing:\r\n\r\n    params = [\"String\", \"Float\", \"Int\"]\r\n    param_names = [\"dtype\"]\r\n\r\n    def setup(self, dtype):\r\n        N = 10**6\r\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\r\n        self.array_mask = (np.arange(N) % 3) == 0\r\n        self.series_mask = Series(self.array_mask)\r\n        self.sorted = self.idx.sort_values()\r\n        half = N // 2\r\n        self.non_unique = self.idx[:half].append(self.idx[:half])\r\n        self.non_unique_sorted = (\r\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\r\n        )\r\n        self.key = self.sorted[N // 4]\r\n\r\n    def time_boolean_array(self, dtype):\r\n        self.idx[self.array_mask]\r\n\r\n    def time_boolean_series(self, dtype):\r\n        self.idx[self.series_mask]\r\n\r\n    def time_get(self, dtype):\r\n        self.idx[1]\r\n\r\n    def time_slice(self, dtype):\r\n        self.idx[:-1]\r\n\r\n    def time_slice_step(self, dtype):\r\n        self.idx[::2]\r\n\r\n    def time_get_loc(self, dtype):\r\n        self.idx.get_loc(self.key)\r\n\r\n    def time_get_loc_sorted(self, dtype):\r\n        self.sorted.get_loc(self.key)\r\n\r\n    def time_get_loc_non_unique(self, dtype):\r\n        self.non_unique.get_loc(self.key)\r\n\r\n    def time_get_loc_non_unique_sorted(self, dtype):\r\n        self.non_unique_sorted.get_loc(self.key)\r\n\r\n\r\nclass Float64IndexMethod:\r\n"]
[55.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[55.002, "i", "asv run --python=same --bench=\"(frame_methods.Reindex|index_object.SetDisjoint).*\" --quick\r"]
[55.004, "o", "asv run --python=same --bench=\"(frame_methods.Reindex|index_object.SetDisjoint).*\" --quick\r\n"]
[55.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mNo `asv.conf` file found for valid extensions: ['.json', '.jsonc'].\u001b[0m\r\n"]
[60.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[60.002, "i", "asv profile --python=same frame_methods.Reindex.time_reindex --config asv_bench/asv.conf.json\r"]
[60.004, "o", "asv profile --python=same frame_methods.Reindex.time_reindex --config asv_bench/asv.conf.json\r\n"]
[60.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mConfig file asv_bench/asv.conf.json not found.\u001b[0m\r\n"]
[65.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[65.002, "i", "asv profile --python=same index_object.SetDisjoint.time_isdisjoint --config asv_bench/asv.conf.json\r"]
[65.004, "o", "asv profile --python=same index_object.SetDisjoint.time_isdisjoint --config asv_bench/asv.conf.json\r\n"]
[65.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mConfig file asv_bench/asv.conf.json not found.\u001b[0m\r\n"]
[70.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[70.002, "i", "grep -Rsn \"TODO\\|FIXME\\|slow\\|inefficient\\|naive\\|optimization\\|nice catch\\|catch\" pandas | sed -n '1,200p'\r"]
[70.004, "o", "grep -Rsn \"TODO\\|FIXME\\|slow\\|inefficient\\|naive\\|optimization\\|nice catch\\|catch\" pandas | sed -n '1,200p'\r\n"]
[70.006, "o", "\u001b[?2004l\r\npandas/tests/test_expressions.py:180:        # FIXME: dont leave commented-out\r\npandas/tests/test_expressions.py:216:                # TODO: get this working\r\npandas/tests/test_expressions.py:221:            with warnings.catch_warnings():\r\npandas/tests/resample/test_period_index.py:481:        ts_local_naive = ts_local.copy()\r\npandas/tests/resample/test_period_index.py:482:        ts_local_naive.index = [\r\npandas/tests/resample/test_period_index.py:483:            x.replace(tzinfo=None) for x in ts_local_naive.index.to_pydatetime()\r\npandas/tests/resample/test_period_index.py:486:        exp = ts_local_naive.resample(\"W\").mean().tz_localize(\"America/Los_Angeles\")\r\npandas/tests/resample/test_period_index.py:837:            # TODO: is non-tick the relevant characteristic? (GH 33815)\r\npandas/tests/resample/test_resample_api.py:373:# TODO(GH#14008): once GH 14008 is fixed, move these tests into\r\npandas/tests/resample/test_resample_api.py:696:    # We catch these errors and move on to the correct branch.\r\npandas/tests/resample/test_time_grouper.py:229:    expected.index = dti._with_freq(None)  # TODO: is this desired?\r\npandas/tests/internals/test_internals.py:46:# TODO(ArrayManager) factor out interleave_dtype tests\r\npandas/tests/internals/test_internals.py:1283:        # TODO: check this holds for all blocks\r\npandas/tests/base/test_value_counts.py:43:    # TODO(GH#32514): Order of entries with the same count is inconsistent\r\npandas/tests/base/test_value_counts.py:92:        # TODO(GH#32514):\r\npandas/tests/base/test_value_counts.py:114:        # TODO(GH#32514):\r\npandas/tests/base/test_conversion.py:299:        # tz-naive datetime\r\npandas/tests/base/test_conversion.py:532:    def test_asarray_tz_naive(self):\r\npandas/tests/base/test_misc.py:153:        # TODO: Should Series cases also raise? Looks like they use numpy\r\npandas/tests/indexes/test_any_index.py:49:        # TODO: could work that into the 'exact=\"equiv\"'?\r\npandas/tests/indexes/test_any_index.py:50:        return  # FIXME: doesn't belong in this file anymore!\r\npandas/tests/indexes/multi/test_duplicates.py:234:@pytest.mark.arm_slow\r\npandas/tests/indexes/multi/test_duplicates.py:248:    # TODO: more informative test name\r\npandas/tests/indexes/multi/test_integrity.py:56:    naive = pd.DatetimeIndex(ints)\r\npandas/tests/indexes/multi/test_integrity.py:60:    idx = MultiIndex.from_arrays([naive, aware])\r\npandas/tests/indexes/multi/test_integrity.py:64:    tm.assert_index_equal(outer, naive)\r\npandas/tests/indexes/multi/test_integrity.py:73:    tm.assert_index_equal(outer, naive[:2])\r\npandas/tests/indexes/multi/test_integrity.py:126:@pytest.mark.slow\r\npandas/tests/indexes/multi/test_indexing.py:71:        # TODO: Try creating a UnicodeDecodeError in exception message\r\npandas/tests/indexes/multi/test_indexing.py:717:        # TODO: de-duplicate with test_get_loc_duplicates above?\r\npandas/tests/indexes/multi/test_indexing.py:833:    @pytest.mark.slow\r\npandas/tests/indexes/multi/test_analytics.py:77:# TODO: reshape\r\npandas/tests/indexes/multi/test_setops.py:51:@pytest.mark.arm_slow\r\npandas/tests/indexes/multi/test_setops.py:209:    # TODO(GH#25151): decide on True behaviour\r\npandas/tests/indexes/multi/test_setops.py:349:    # TODO(GH#25151): decide on True behaviour\r\npandas/tests/indexes/multi/test_setops.py:371:    # TODO(GH#25151): decide on True behaviour\r\npandas/tests/indexes/multi/test_setops.py:396:    # TODO(GH#25151): decide on True behaviour\r\npandas/tests/indexes/multi/test_reshape.py:69:    # FIXME data types changes to float because\r\npandas/tests/indexes/multi/test_drop.py:160:    with warnings.catch_warnings():\r\npandas/tests/indexes/test_base.py:65:        # TODO: a bunch of scattered tests check this deprecation is enforced.\r\npandas/tests/indexes/test_base.py:235:    def test_constructor_dtypes_datetime(self, tz_naive_fixture, attr, klass):\r\npandas/tests/indexes/test_base.py:237:        # .values produces numpy datetimes, so these are considered naive\r\npandas/tests/indexes/test_base.py:243:        index = index.tz_localize(tz_naive_fixture)\r\npandas/tests/indexes/test_base.py:247:        err = tz_naive_fixture is not None\r\npandas/tests/indexes/test_base.py:248:        msg = \"Cannot use .astype to convert from timezone-naive dtype to\"\r\npandas/tests/indexes/test_base.py:251:            result = DatetimeIndex(arg).tz_localize(tz_naive_fixture)\r\npandas/tests/indexes/test_base.py:255:                klass(arg, tz=tz_naive_fixture)\r\npandas/tests/indexes/test_base.py:257:            result = klass(arg, tz=tz_naive_fixture)\r\npandas/tests/indexes/test_base.py:272:            result = DatetimeIndex(list(arg)).tz_localize(tz_naive_fixture)\r\npandas/tests/indexes/test_base.py:276:                klass(arg, tz=tz_naive_fixture)\r\npandas/tests/indexes/test_base.py:278:            result = klass(list(arg), tz=tz_naive_fixture)\r\npandas/tests/indexes/test_base.py:454:        # TODO: should right.asof(left[0]) also raise?\r\npandas/tests/indexes/test_base.py:513:        # TODO: Replace with fixturesult\r\npandas/tests/indexes/test_base.py:708:        # TODO: case with complex dtype?\r\npandas/tests/indexes/test_base.py:762:        # TODO: Parametrize numeric and str tests after self.strIndex fixture\r\npandas/tests/indexes/test_base.py:1448:        # TODO: also this op right now produces FutureWarning from numpy\r\npandas/tests/indexes/test_indexing.py:157:            return  # TODO: do we want this to raise?\r\npandas/tests/indexes/test_indexing.py:197:            # TODO: make these more consistent?\r\npandas/tests/indexes/period/test_indexing.py:174:    @pytest.mark.arm_slow\r\npandas/tests/indexes/period/test_indexing.py:481:    # TODO: This method came from test_period; de-dup with version above\r\npandas/tests/indexes/period/test_indexing.py:721:        # TODO: this test used to test get_value, which is removed in 2.0.\r\npandas/tests/indexes/period/methods/test_to_timestamp.py:30:        # TODO: can we get the freq to round-trip?\r\npandas/tests/indexes/period/methods/test_astype.py:78:    # TODO: de-duplicate this version (from test_ops) with the one above\r\npandas/tests/indexes/datetimelike_/test_equals.py:57:    # TODO: de-duplicate with other test_equals2 methods\r\npandas/tests/indexes/datetimelike_/test_sort_values.py:204:        self, index_dates, expected_dates, tz_naive_fixture\r\npandas/tests/indexes/datetimelike_/test_sort_values.py:206:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimelike_/test_value_counts.py:19:    def test_value_counts_unique_datetimeindex(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimelike_/test_value_counts.py:20:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimelike_/test_value_counts.py:48:    def test_value_counts_unique_datetimeindex2(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimelike_/test_value_counts.py:49:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimelike_/test_nat.py:39:    def index_without_na(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimelike_/test_nat.py:40:        tz = tz_naive_fixture\r\npandas/tests/indexes/interval/test_interval_range.py:88:            # matches expected only for non-anchored offsets and tz naive\r\npandas/tests/indexes/interval/test_indexing.py:314:        # TODO this should probably be deprecated?\r\npandas/tests/indexes/interval/test_indexing.py:371:        # TODO we may also want to test get_indexer for the case when\r\npandas/tests/indexes/interval/test_setops.py:178:        # TODO: standardize return type of non-union setops type(self vs other)\r\npandas/tests/indexes/test_setops.py:183:    # TODO: pin down desired dtype; do we want it to be commutative?\r\npandas/tests/indexes/test_setops.py:269:            # i think (TODO: be sure) there assumptions baked in about\r\npandas/tests/indexes/test_setops.py:842:        # TODO(GH#25151): decide on True behaviour\r\npandas/tests/indexes/test_common.py:124:        # FIXME: dont leave commented-out\r\npandas/tests/indexes/test_common.py:166:        # TODO: belongs in series arithmetic tests?\r\npandas/tests/indexes/base_class/test_indexing.py:42:    @pytest.mark.slow  # to_flat_index takes a while\r\npandas/tests/indexes/base_class/test_setops.py:93:        # TODO(GH#25151): decide on True behaviour\r\npandas/tests/indexes/base_class/test_setops.py:101:        # TODO(GH#25151): decide on True behaviour\r\npandas/tests/indexes/datetimes/test_date_range.py:212:    @pytest.mark.slow\r\npandas/tests/indexes/datetimes/test_date_range.py:476:    def test_catch_infinite_loop(self):\r\npandas/tests/indexes/datetimes/test_date_range.py:1205:            #    # TODO give a more useful or informative message?\r\npandas/tests/indexes/datetimes/test_datetime.py:20:    def test_sub_datetime_preserves_freq(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/test_datetime.py:22:        dti = date_range(\"2016-01-01\", periods=12, tz=tz_naive_fixture)\r\npandas/tests/indexes/datetimes/test_datetime.py:164:    def test_asarray_tz_naive(self):\r\npandas/tests/indexes/datetimes/test_ops.py:34:    def test_resolution(self, request, tz_naive_fixture, freq, expected):\r\npandas/tests/indexes/datetimes/test_ops.py:35:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimes/test_join.py:132:    def test_naive_aware_conflicts(self):\r\npandas/tests/indexes/datetimes/test_join.py:134:        naive = date_range(start, end, freq=BDay(), tz=None)\r\npandas/tests/indexes/datetimes/test_join.py:137:        msg = \"tz-naive.*tz-aware\"\r\npandas/tests/indexes/datetimes/test_join.py:139:            naive.join(aware)\r\npandas/tests/indexes/datetimes/test_join.py:142:            aware.join(naive)\r\npandas/tests/indexes/datetimes/test_indexing.py:155:        # passing tz-naive ndarray to tzaware DTI\r\npandas/tests/indexes/datetimes/test_indexing.py:160:        # passing tz-aware DTI to tznaive DTI\r\npandas/tests/indexes/datetimes/test_indexing.py:161:        naive = dti.tz_localize(None)\r\npandas/tests/indexes/datetimes/test_indexing.py:162:        result = naive.where(mask, i2)\r\npandas/tests/indexes/datetimes/test_indexing.py:163:        expected = Index([i2[0], i2[1]] + naive[2:].tolist(), dtype=object)\r\npandas/tests/indexes/datetimes/test_indexing.py:289:    # TODO: This method came from test_datetime; de-dup with version above\r\npandas/tests/indexes/datetimes/test_indexing.py:634:            with pytest.raises(TypeError, match=\"Cannot compare tz-naive\"):\r\npandas/tests/indexes/datetimes/test_indexing.py:653:            with pytest.raises(TypeError, match=\"Cannot compare tz-naive\"):\r\npandas/tests/indexes/datetimes/test_indexing.py:668:            with pytest.raises(TypeError, match=\"Cannot compare tz-naive\"):\r\npandas/tests/indexes/datetimes/methods/test_factorize.py:73:    def test_factorize_tz(self, tz_naive_fixture, index_or_series):\r\npandas/tests/indexes/datetimes/methods/test_factorize.py:74:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimes/methods/test_to_series.py:12:        naive = DatetimeIndex([\"2013-1-1 13:00\", \"2013-1-2 14:00\"], name=\"B\")\r\npandas/tests/indexes/datetimes/methods/test_to_series.py:13:        idx = naive.tz_localize(\"US/Pacific\")\r\npandas/tests/indexes/datetimes/methods/test_repeat.py:13:    def test_repeat_range(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/methods/test_repeat.py:14:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimes/methods/test_repeat.py:56:    def test_repeat(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/methods/test_repeat.py:57:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimes/methods/test_shift.py:24:    def test_dti_shift_tzaware(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/methods/test_shift.py:26:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimes/methods/test_astype.py:72:    def test_astype_tznaive_to_tzaware(self):\r\npandas/tests/indexes/datetimes/methods/test_astype.py:73:        # GH 18951: tz-naive to tz-aware\r\npandas/tests/indexes/datetimes/methods/test_astype.py:76:        msg = \"Cannot use .astype to convert from timezone-naive\"\r\npandas/tests/indexes/datetimes/methods/test_insert.py:41:    def test_insert_empty_preserves_freq(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/methods/test_insert.py:43:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimes/methods/test_insert.py:172:    # TODO: also changes DataFrame.__setitem__ with expansion\r\npandas/tests/indexes/datetimes/methods/test_insert.py:193:    # TODO: also changes DataFrame.__setitem__ with expansion\r\npandas/tests/indexes/datetimes/test_setops.py:39:    # TODO: moved from test_datetimelike; dedup with version below\r\npandas/tests/indexes/datetimes/test_setops.py:193:    # TODO: moved from test_datetimelike; de-duplicate with version below\r\npandas/tests/indexes/datetimes/test_scalar_compat.py:109:    def test_round(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/test_scalar_compat.py:110:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimes/test_scalar_compat.py:163:    def test_no_rounding_occurs(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/test_scalar_compat.py:165:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimes/test_constructors.py:78:    # TODO: better place for tests shared by DTI/TDI?\r\npandas/tests/indexes/datetimes/test_constructors.py:479:        #  the naive Timestamp is treated as a wall time.\r\npandas/tests/indexes/datetimes/test_constructors.py:717:            \"cannot supply both a tz and a timezone-naive dtype \"\r\npandas/tests/indexes/datetimes/test_constructors.py:812:    def test_construction_int_rountrip(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/test_constructors.py:814:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimes/test_constructors.py:958:    def test_dti_constructor_years_only(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/test_constructors.py:959:        tz = tz_naive_fixture\r\npandas/tests/indexes/datetimes/test_constructors.py:1142:        \"Pass naive datetime-like or build Timestamp from components.\"\r\npandas/tests/indexes/datetimes/test_constructors.py:1187:    # TODO: belongs in Timestamp tests?\r\npandas/tests/indexes/datetimes/test_timezones.py:479:        expected_naive = rng + pd.offsets.Hour(5)\r\npandas/tests/indexes/datetimes/test_timezones.py:480:        tm.assert_numpy_array_equal(converted.asi8, expected_naive.asi8)\r\npandas/tests/indexes/datetimes/test_timezones.py:489:        # note: this tz tests that a tz-naive index can be localized\r\npandas/tests/indexes/datetimes/test_timezones.py:505:    def test_dti_tz_localize_naive(self):\r\npandas/tests/indexes/datetimes/test_timezones.py:607:    # TODO: belongs outside tz_localize tests?\r\npandas/tests/indexes/datetimes/test_timezones.py:859:    def test_timetz_accessor(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/test_timezones.py:861:        tz = timezones.maybe_get_tz(tz_naive_fixture)\r\npandas/tests/indexes/datetimes/test_timezones.py:877:    def test_dti_tz_conversion_freq(self, tz_naive_fixture):\r\npandas/tests/indexes/datetimes/test_timezones.py:880:        assert t3.tz_localize(tz=tz_naive_fixture).freq == t3.freq\r\npandas/tests/indexes/datetimes/test_timezones.py:1093:        # DateRange with naive datetimes\r\npandas/tests/indexes/datetimes/test_timezones.py:1100:        naive = central[0].to_pydatetime().replace(tzinfo=None)\r\npandas/tests/indexes/datetimes/test_timezones.py:1101:        comp = conversion.localize_pydatetime(naive, tz).tzinfo\r\npandas/tests/indexes/datetimes/test_timezones.py:1105:        naive = dr[0].to_pydatetime().replace(tzinfo=None)\r\npandas/tests/indexes/datetimes/test_timezones.py:1106:        comp = conversion.localize_pydatetime(naive, tz).tzinfo\r\npandas/tests/indexes/datetimes/test_unique.py:14:def test_unique(tz_naive_fixture):\r\npandas/tests/indexes/datetimes/test_unique.py:16:    idx = DatetimeIndex([\"2017\"] * 2, tz=tz_naive_fixture)\r\npandas/tests/indexes/datetimes/test_misc.py:35:        dti_naive = date_range(freq=\"D\", start=datetime(1998, 1, 1), periods=365)\r\npandas/tests/indexes/datetimes/test_misc.py:40:        for dti in [dti_naive, dti_tz]:\r\npandas/tests/indexes/test_numpy_compat.py:163:    # TODO: overlap with tests.series.test_ufunc.test_reductions\r\npandas/tests/indexes/test_numpy_compat.py:182:        # TODO: do we have cases both with and without NAs?\r\npandas/tests/indexes/timedeltas/test_scalar_compat.py:98:    # TODO: de-duplicate with test_tdi_round\r\npandas/tests/indexes/timedeltas/test_constructors.py:90:        # passing tz-aware DatetimeIndex raises, naive or ndarray[datetime64]\r\npandas/tests/indexes/numeric/test_numeric.py:588:    # TODO: we could plausibly try to infer down to int16 here\r\npandas/tests/indexes/numeric/test_setops.py:149:        # TODO(GH#25151): decide on True behaviour\r\npandas/tests/indexes/common.py:609:            # FIXME: this fails with CategoricalIndex bc it goes through\r\npandas/tests/indexes/common.py:685:    @pytest.mark.arm_slow\r\npandas/tests/indexes/common.py:778:            # TODO(2.0): once we preserve dtype, check_dtype can be True\r\npandas/tests/test_algos.py:979:            # TODO: fix Series.view to get this on its own\r\npandas/tests/test_algos.py:982:            # TODO: fix Series.view to get this on its own\r\npandas/tests/test_algos.py:1226:        # TODO same for (timedelta)\r\npandas/tests/reductions/test_stat_reductions.py:26:    def test_dt64_mean(self, tz_naive_fixture, box):\r\npandas/tests/reductions/test_stat_reductions.py:27:        tz = tz_naive_fixture\r\npandas/tests/reductions/test_reductions.py:376:    def test_minmax_tz(self, tz_naive_fixture):\r\npandas/tests/reductions/test_reductions.py:377:        tz = tz_naive_fixture\r\npandas/tests/arithmetic/test_period.py:170:    # TODO: parameterize over boxes\r\npandas/tests/arithmetic/test_period.py:188:    # TODO: moved from test_datetime64; de-duplicate with version below\r\npandas/tests/arithmetic/test_period.py:252:        # TODO: could also box idx?\r\npandas/tests/arithmetic/test_period.py:295:        # TODO: Could parametrize over boxes for idx?\r\npandas/tests/arithmetic/test_period.py:373:    # TODO: De-duplicate with test_pi_cmp_nat\r\npandas/tests/arithmetic/test_period.py:447:    # TODO: needs parametrization+de-duplication\r\npandas/tests/arithmetic/test_period.py:599:        # TODO: parametrize over boxes for other?\r\npandas/tests/arithmetic/test_period.py:793:        # TODO: parametrize over box for pi?\r\npandas/tests/arithmetic/test_period.py:1017:    # TODO: Some of these are misnomers because of non-Tick DateOffsets\r\npandas/tests/arithmetic/test_numeric.py:67:# TODO: remove this kludge once mypy stops giving false positives here\r\npandas/tests/arithmetic/test_numeric.py:185:    # TODO: also test Tick objects;\r\npandas/tests/arithmetic/test_numeric.py:782:    # TODO: This came from series.test.test_operators, needs cleanup\r\npandas/tests/arithmetic/test_numeric.py:795:    # TODO: this came from tests.series.test_analytics, needs cleanup and\r\npandas/tests/arithmetic/test_numeric.py:879:    # TODO: This came from series.test.test_operators, needs cleanup\r\npandas/tests/arithmetic/test_numeric.py:910:    # TODO: This came from series.test.test_operators, needs cleanup\r\npandas/tests/arithmetic/test_numeric.py:941:    # TODO: taken from tests.frame.test_operators, needs cleanup\r\npandas/tests/arithmetic/test_numeric.py:1057:    # TODO: add more dtypes\r\npandas/tests/arithmetic/test_numeric.py:1073:    # TODO: add more dtypes\r\npandas/tests/arithmetic/test_numeric.py:1117:    # TODO: add more dtypes\r\npandas/tests/arithmetic/test_numeric.py:1171:    # TODO: moved from tests.series.test_operators; needs cleanup\r\npandas/tests/arithmetic/test_numeric.py:1268:    # TODO: divmod?\r\npandas/tests/arithmetic/test_numeric.py:1340:            # TODO: add more dtypes\r\npandas/tests/arithmetic/common.py:91:    # Not for tznaive-tzaware comparison\r\npandas/tests/arithmetic/test_object.py:89:    # TODO: parametrize\r\npandas/tests/arithmetic/test_object.py:182:    # TODO: Moved from tests.series.test_operators; needs cleanup\r\npandas/tests/arithmetic/test_object.py:193:    # TODO: parametrize over box\r\npandas/tests/arithmetic/test_object.py:213:    # TODO: cleanup & parametrize over box\r\npandas/tests/arithmetic/test_object.py:265:    # TODO: cleanup & parametrize over box\r\n"]
[75.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[75.002, "i", "sed -n '1,200p' asv_bench/benchmarks/frame_methods.py\r"]
[75.004, "o", "sed -n '1,200p' asv_bench/benchmarks/frame_methods.py\r\n"]
[75.006, "o", "\u001b[?2004l\r\nimport string\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas import (\r\n    DataFrame,\r\n    MultiIndex,\r\n    NaT,\r\n    Series,\r\n    date_range,\r\n    isnull,\r\n    period_range,\r\n    timedelta_range,\r\n)\r\n\r\nfrom .pandas_vb_common import tm\r\n\r\n\r\nclass GetNumericData:\r\n    def setup(self):\r\n        self.df = DataFrame(np.random.randn(10000, 25))\r\n        self.df[\"foo\"] = \"bar\"\r\n        self.df[\"bar\"] = \"baz\"\r\n        self.df = self.df._consolidate()\r\n\r\n    def time_frame_get_numeric_data(self):\r\n        self.df._get_numeric_data()\r\n\r\n\r\nclass Reindex:\r\n    def setup(self):\r\n        N = 10**3\r\n        self.df = DataFrame(np.random.randn(N * 10, N))\r\n        self.idx = np.arange(4 * N, 7 * N)\r\n        self.idx_cols = np.random.randint(0, N, N)\r\n        self.df2 = DataFrame(\r\n            {\r\n                c: {\r\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\r\n                    1: np.random.randint(0, N, N).astype(np.int16),\r\n                    2: np.random.randint(0, N, N).astype(np.int32),\r\n                    3: np.random.randint(0, N, N).astype(np.int64),\r\n                }[np.random.randint(0, 4)]\r\n                for c in range(N)\r\n            }\r\n        )\r\n\r\n    def time_reindex_axis0(self):\r\n        self.df.reindex(self.idx)\r\n\r\n    def time_reindex_axis1(self):\r\n        self.df.reindex(columns=self.idx_cols)\r\n\r\n    def time_reindex_axis1_missing(self):\r\n        self.df.reindex(columns=self.idx)\r\n\r\n    def time_reindex_both_axes(self):\r\n        self.df.reindex(index=self.idx, columns=self.idx_cols)\r\n\r\n    def time_reindex_upcast(self):\r\n        self.df2.reindex(np.random.permutation(range(1200)))\r\n\r\n\r\nclass Rename:\r\n    def setup(self):\r\n        N = 10**3\r\n        self.df = DataFrame(np.random.randn(N * 10, N))\r\n        self.idx = np.arange(4 * N, 7 * N)\r\n        self.dict_idx = {k: k for k in self.idx}\r\n        self.df2 = DataFrame(\r\n            {\r\n                c: {\r\n                    0: np.random.randint(0, 2, N).astype(np.bool_),\r\n                    1: np.random.randint(0, N, N).astype(np.int16),\r\n                    2: np.random.randint(0, N, N).astype(np.int32),\r\n                    3: np.random.randint(0, N, N).astype(np.int64),\r\n                }[np.random.randint(0, 4)]\r\n                for c in range(N)\r\n            }\r\n        )\r\n\r\n    def time_rename_single(self):\r\n        self.df.rename({0: 0})\r\n\r\n    def time_rename_axis0(self):\r\n        self.df.rename(self.dict_idx)\r\n\r\n    def time_rename_axis1(self):\r\n        self.df.rename(columns=self.dict_idx)\r\n\r\n    def time_rename_both_axes(self):\r\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\r\n\r\n    def time_dict_rename_both_axes(self):\r\n        self.df.rename(index=self.dict_idx, columns=self.dict_idx)\r\n\r\n\r\nclass Iteration:\r\n    # mem_itertuples_* benchmarks are slow\r\n    timeout = 120\r\n\r\n    def setup(self):\r\n        N = 1000\r\n        self.df = DataFrame(np.random.randn(N * 10, N))\r\n        self.df2 = DataFrame(np.random.randn(N * 50, 10))\r\n        self.df3 = DataFrame(\r\n            np.random.randn(N, 5 * N), columns=[\"C\" + str(c) for c in range(N * 5)]\r\n        )\r\n        self.df4 = DataFrame(np.random.randn(N * 1000, 10))\r\n\r\n    def time_items(self):\r\n        # (monitor no-copying behaviour)\r\n        if hasattr(self.df, \"_item_cache\"):\r\n            self.df._item_cache.clear()\r\n        for name, col in self.df.items():\r\n            pass\r\n\r\n    def time_items_cached(self):\r\n        for name, col in self.df.items():\r\n            pass\r\n\r\n    def time_iteritems_indexing(self):\r\n        for col in self.df3:\r\n            self.df3[col]\r\n\r\n    def time_itertuples_start(self):\r\n        self.df4.itertuples()\r\n\r\n    def time_itertuples_read_first(self):\r\n        next(self.df4.itertuples())\r\n\r\n    def time_itertuples(self):\r\n        for row in self.df4.itertuples():\r\n            pass\r\n\r\n    def time_itertuples_to_list(self):\r\n        list(self.df4.itertuples())\r\n\r\n    def mem_itertuples_start(self):\r\n        return self.df4.itertuples()\r\n\r\n    def peakmem_itertuples_start(self):\r\n        self.df4.itertuples()\r\n\r\n    def mem_itertuples_read_first(self):\r\n        return next(self.df4.itertuples())\r\n\r\n    def peakmem_itertuples(self):\r\n        for row in self.df4.itertuples():\r\n            pass\r\n\r\n    def mem_itertuples_to_list(self):\r\n        return list(self.df4.itertuples())\r\n\r\n    def peakmem_itertuples_to_list(self):\r\n        list(self.df4.itertuples())\r\n\r\n    def time_itertuples_raw_start(self):\r\n        self.df4.itertuples(index=False, name=None)\r\n\r\n    def time_itertuples_raw_read_first(self):\r\n        next(self.df4.itertuples(index=False, name=None))\r\n\r\n    def time_itertuples_raw_tuples(self):\r\n        for row in self.df4.itertuples(index=False, name=None):\r\n            pass\r\n\r\n    def time_itertuples_raw_tuples_to_list(self):\r\n        list(self.df4.itertuples(index=False, name=None))\r\n\r\n    def mem_itertuples_raw_start(self):\r\n        return self.df4.itertuples(index=False, name=None)\r\n\r\n    def peakmem_itertuples_raw_start(self):\r\n        self.df4.itertuples(index=False, name=None)\r\n\r\n    def peakmem_itertuples_raw_read_first(self):\r\n        next(self.df4.itertuples(index=False, name=None))\r\n\r\n    def peakmem_itertuples_raw(self):\r\n        for row in self.df4.itertuples(index=False, name=None):\r\n            pass\r\n\r\n    def mem_itertuples_raw_to_list(self):\r\n        return list(self.df4.itertuples(index=False, name=None))\r\n\r\n    def peakmem_itertuples_raw_to_list(self):\r\n        list(self.df4.itertuples(index=False, name=None))\r\n\r\n    def time_iterrows(self):\r\n        for row in self.df.iterrows():\r\n            pass\r\n\r\n\r\nclass ToString:\r\n    def setup(self):\r\n        self.df = DataFrame(np.random.randn(100, 10))\r\n\r\n    def time_to_string_floats(self):\r\n"]
[80.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[80.002, "i", "sed -n '200,400p' asv_bench/benchmarks/frame_methods.py\r"]
[80.004, "o", "sed -n '200,400p' asv_bench/benchmarks/frame_methods.py\r\n"]
[80.006, "o", "\u001b[?2004l\r\n    def time_to_string_floats(self):\r\n        self.df.to_string()\r\n\r\n\r\nclass ToHTML:\r\n    def setup(self):\r\n        nrows = 500\r\n        self.df2 = DataFrame(np.random.randn(nrows, 10))\r\n        self.df2[0] = period_range(\"2000\", periods=nrows)\r\n        self.df2[1] = range(nrows)\r\n\r\n    def time_to_html_mixed(self):\r\n        self.df2.to_html()\r\n\r\n\r\nclass ToDict:\r\n    params = [[\"dict\", \"list\", \"series\", \"split\", \"records\", \"index\"]]\r\n    param_names = [\"orient\"]\r\n\r\n    def setup(self, orient):\r\n        data = np.random.randint(0, 1000, size=(10000, 4))\r\n        self.int_df = DataFrame(data)\r\n        self.datetimelike_df = self.int_df.astype(\"timedelta64[ns]\")\r\n\r\n    def time_to_dict_ints(self, orient):\r\n        self.int_df.to_dict(orient=orient)\r\n\r\n    def time_to_dict_datetimelike(self, orient):\r\n        self.datetimelike_df.to_dict(orient=orient)\r\n\r\n\r\nclass ToNumpy:\r\n    def setup(self):\r\n        N = 10000\r\n        M = 10\r\n        self.df_tall = DataFrame(np.random.randn(N, M))\r\n        self.df_wide = DataFrame(np.random.randn(M, N))\r\n        self.df_mixed_tall = self.df_tall.copy()\r\n        self.df_mixed_tall[\"foo\"] = \"bar\"\r\n        self.df_mixed_tall[0] = period_range(\"2000\", periods=N)\r\n        self.df_mixed_tall[1] = range(N)\r\n        self.df_mixed_wide = self.df_wide.copy()\r\n        self.df_mixed_wide[\"foo\"] = \"bar\"\r\n        self.df_mixed_wide[0] = period_range(\"2000\", periods=M)\r\n        self.df_mixed_wide[1] = range(M)\r\n\r\n    def time_to_numpy_tall(self):\r\n        self.df_tall.to_numpy()\r\n\r\n    def time_to_numpy_wide(self):\r\n        self.df_wide.to_numpy()\r\n\r\n    def time_to_numpy_mixed_tall(self):\r\n        self.df_mixed_tall.to_numpy()\r\n\r\n    def time_to_numpy_mixed_wide(self):\r\n        self.df_mixed_wide.to_numpy()\r\n\r\n    def time_values_tall(self):\r\n        self.df_tall.values\r\n\r\n    def time_values_wide(self):\r\n        self.df_wide.values\r\n\r\n    def time_values_mixed_tall(self):\r\n        self.df_mixed_tall.values\r\n\r\n    def time_values_mixed_wide(self):\r\n        self.df_mixed_wide.values\r\n\r\n\r\nclass ToRecords:\r\n    def setup(self):\r\n        N = 100_000\r\n        data = np.random.randn(N, 2)\r\n        mi = MultiIndex.from_arrays(\r\n            [\r\n                np.arange(N),\r\n                date_range(\"1970-01-01\", periods=N, freq=\"ms\"),\r\n            ]\r\n        )\r\n        self.df = DataFrame(data)\r\n        self.df_mi = DataFrame(data, index=mi)\r\n\r\n    def time_to_records(self):\r\n        self.df.to_records(index=True)\r\n\r\n    def time_to_records_multiindex(self):\r\n        self.df_mi.to_records(index=True)\r\n\r\n\r\nclass Repr:\r\n    def setup(self):\r\n        nrows = 10000\r\n        data = np.random.randn(nrows, 10)\r\n        arrays = np.tile(np.random.randn(3, nrows // 100), 100)\r\n        idx = MultiIndex.from_arrays(arrays)\r\n        self.df3 = DataFrame(data, index=idx)\r\n        self.df4 = DataFrame(data, index=np.random.randn(nrows))\r\n        self.df_tall = DataFrame(np.random.randn(nrows, 10))\r\n        self.df_wide = DataFrame(np.random.randn(10, nrows))\r\n\r\n    def time_html_repr_trunc_mi(self):\r\n        self.df3._repr_html_()\r\n\r\n    def time_html_repr_trunc_si(self):\r\n        self.df4._repr_html_()\r\n\r\n    def time_repr_tall(self):\r\n        repr(self.df_tall)\r\n\r\n    def time_frame_repr_wide(self):\r\n        repr(self.df_wide)\r\n\r\n\r\nclass MaskBool:\r\n    def setup(self):\r\n        data = np.random.randn(1000, 500)\r\n        df = DataFrame(data)\r\n        df = df.where(df > 0)\r\n        self.bools = df > 0\r\n        self.mask = isnull(df)\r\n\r\n    def time_frame_mask_bools(self):\r\n        self.bools.mask(self.mask)\r\n\r\n    def time_frame_mask_floats(self):\r\n        self.bools.astype(float).mask(self.mask)\r\n\r\n\r\nclass Isnull:\r\n    def setup(self):\r\n        N = 10**3\r\n        self.df_no_null = DataFrame(np.random.randn(N, N))\r\n\r\n        sample = np.array([np.nan, 1.0])\r\n        data = np.random.choice(sample, (N, N))\r\n        self.df = DataFrame(data)\r\n\r\n        sample = np.array(list(string.ascii_letters + string.whitespace))\r\n        data = np.random.choice(sample, (N, N))\r\n        self.df_strings = DataFrame(data)\r\n\r\n        sample = np.array(\r\n            [\r\n                NaT,\r\n                np.nan,\r\n                None,\r\n                np.datetime64(\"NaT\"),\r\n                np.timedelta64(\"NaT\"),\r\n                0,\r\n                1,\r\n                2.0,\r\n                \"\",\r\n                \"abcd\",\r\n            ]\r\n        )\r\n        data = np.random.choice(sample, (N, N))\r\n        self.df_obj = DataFrame(data)\r\n\r\n    def time_isnull_floats_no_null(self):\r\n        isnull(self.df_no_null)\r\n\r\n    def time_isnull(self):\r\n        isnull(self.df)\r\n\r\n    def time_isnull_strngs(self):\r\n        isnull(self.df_strings)\r\n\r\n    def time_isnull_obj(self):\r\n        isnull(self.df_obj)\r\n\r\n\r\nclass Fillna:\r\n\r\n    params = (\r\n        [True, False],\r\n        [\"pad\", \"bfill\"],\r\n        [\r\n            \"float64\",\r\n            \"float32\",\r\n            \"object\",\r\n            \"Int64\",\r\n            \"Float64\",\r\n            \"datetime64[ns]\",\r\n            \"datetime64[ns, tz]\",\r\n            \"timedelta64[ns]\",\r\n        ],\r\n    )\r\n    param_names = [\"inplace\", \"method\", \"dtype\"]\r\n\r\n    def setup(self, inplace, method, dtype):\r\n        N, M = 10000, 100\r\n        if dtype in (\"datetime64[ns]\", \"datetime64[ns, tz]\", \"timedelta64[ns]\"):\r\n            data = {\r\n                \"datetime64[ns]\": date_range(\"2011-01-01\", freq=\"H\", periods=N),\r\n                \"datetime64[ns, tz]\": date_range(\r\n                    \"2011-01-01\", freq=\"H\", periods=N, tz=\"Asia/Tokyo\"\r\n                ),\r\n                \"timedelta64[ns]\": timedelta_range(start=\"1 day\", periods=N, freq=\"1D\"),\r\n            }\r\n"]
[85.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[85.002, "i", "sed -n '1,200p' asv_bench/benchmarks/index_object.py\r"]
[85.004, "o", "sed -n '1,200p' asv_bench/benchmarks/index_object.py\r\n"]
[85.006, "o", "\u001b[?2004l\r\nimport gc\r\n\r\nimport numpy as np\r\n\r\nfrom pandas import (\r\n    DatetimeIndex,\r\n    Index,\r\n    IntervalIndex,\r\n    MultiIndex,\r\n    RangeIndex,\r\n    Series,\r\n    date_range,\r\n)\r\n\r\nfrom .pandas_vb_common import tm\r\n\r\n\r\nclass SetOperations:\r\n\r\n    params = (\r\n        [\"monotonic\", \"non_monotonic\"],\r\n        [\"datetime\", \"date_string\", \"int\", \"strings\", \"ea_int\"],\r\n        [\"intersection\", \"union\", \"symmetric_difference\"],\r\n    )\r\n    param_names = [\"index_structure\", \"dtype\", \"method\"]\r\n\r\n    def setup(self, index_structure, dtype, method):\r\n        N = 10**5\r\n        dates_left = date_range(\"1/1/2000\", periods=N, freq=\"T\")\r\n        fmt = \"%Y-%m-%d %H:%M:%S\"\r\n        date_str_left = Index(dates_left.strftime(fmt))\r\n        int_left = Index(np.arange(N))\r\n        ea_int_left = Index(np.arange(N), dtype=\"Int64\")\r\n        str_left = tm.makeStringIndex(N)\r\n\r\n        data = {\r\n            \"datetime\": dates_left,\r\n            \"date_string\": date_str_left,\r\n            \"int\": int_left,\r\n            \"strings\": str_left,\r\n            \"ea_int\": ea_int_left,\r\n        }\r\n\r\n        if index_structure == \"non_monotonic\":\r\n            data = {k: mi[::-1] for k, mi in data.items()}\r\n\r\n        data = {k: {\"left\": idx, \"right\": idx[:-1]} for k, idx in data.items()}\r\n\r\n        self.left = data[dtype][\"left\"]\r\n        self.right = data[dtype][\"right\"]\r\n\r\n    def time_operation(self, index_structure, dtype, method):\r\n        getattr(self.left, method)(self.right)\r\n\r\n\r\nclass SetDisjoint:\r\n    def setup(self):\r\n        N = 10**5\r\n        B = N + 20000\r\n        self.datetime_left = DatetimeIndex(range(N))\r\n        self.datetime_right = DatetimeIndex(range(N, B))\r\n\r\n    def time_datetime_difference_disjoint(self):\r\n        self.datetime_left.difference(self.datetime_right)\r\n\r\n\r\nclass UnionWithDuplicates:\r\n    def setup(self):\r\n        self.left = Index(np.repeat(np.arange(1000), 100))\r\n        self.right = Index(np.tile(np.arange(500, 1500), 50))\r\n\r\n    def time_union_with_duplicates(self):\r\n        self.left.union(self.right)\r\n\r\n\r\nclass Range:\r\n    def setup(self):\r\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\r\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)\r\n\r\n    def time_max(self):\r\n        self.idx_inc.max()\r\n\r\n    def time_max_trivial(self):\r\n        self.idx_dec.max()\r\n\r\n    def time_min(self):\r\n        self.idx_dec.min()\r\n\r\n    def time_min_trivial(self):\r\n        self.idx_inc.min()\r\n\r\n    def time_get_loc_inc(self):\r\n        self.idx_inc.get_loc(900_000)\r\n\r\n    def time_get_loc_dec(self):\r\n        self.idx_dec.get_loc(100_000)\r\n\r\n    def time_iter_inc(self):\r\n        for _ in self.idx_inc:\r\n            pass\r\n\r\n    def time_iter_dec(self):\r\n        for _ in self.idx_dec:\r\n            pass\r\n\r\n    def time_sort_values_asc(self):\r\n        self.idx_inc.sort_values()\r\n\r\n    def time_sort_values_des(self):\r\n        self.idx_inc.sort_values(ascending=False)\r\n\r\n\r\nclass IndexEquals:\r\n    def setup(self):\r\n        idx_large_fast = RangeIndex(100_000)\r\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\r\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\r\n\r\n        self.idx_non_object = RangeIndex(1)\r\n\r\n    def time_non_object_equals_multiindex(self):\r\n        self.idx_non_object.equals(self.mi_large_slow)\r\n\r\n\r\nclass IndexAppend:\r\n    def setup(self):\r\n\r\n        N = 10_000\r\n        self.range_idx = RangeIndex(0, 100)\r\n        self.int_idx = self.range_idx.astype(int)\r\n        self.obj_idx = self.int_idx.astype(str)\r\n        self.range_idxs = []\r\n        self.int_idxs = []\r\n        self.object_idxs = []\r\n        for i in range(1, N):\r\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\r\n            self.range_idxs.append(r_idx)\r\n            i_idx = r_idx.astype(int)\r\n            self.int_idxs.append(i_idx)\r\n            o_idx = i_idx.astype(str)\r\n            self.object_idxs.append(o_idx)\r\n\r\n    def time_append_range_list(self):\r\n        self.range_idx.append(self.range_idxs)\r\n\r\n    def time_append_int_list(self):\r\n        self.int_idx.append(self.int_idxs)\r\n\r\n    def time_append_obj_list(self):\r\n        self.obj_idx.append(self.object_idxs)\r\n\r\n\r\nclass Indexing:\r\n\r\n    params = [\"String\", \"Float\", \"Int\"]\r\n    param_names = [\"dtype\"]\r\n\r\n    def setup(self, dtype):\r\n        N = 10**6\r\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\r\n        self.array_mask = (np.arange(N) % 3) == 0\r\n        self.series_mask = Series(self.array_mask)\r\n        self.sorted = self.idx.sort_values()\r\n        half = N // 2\r\n        self.non_unique = self.idx[:half].append(self.idx[:half])\r\n        self.non_unique_sorted = (\r\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\r\n        )\r\n        self.key = self.sorted[N // 4]\r\n\r\n    def time_boolean_array(self, dtype):\r\n        self.idx[self.array_mask]\r\n\r\n    def time_boolean_series(self, dtype):\r\n        self.idx[self.series_mask]\r\n\r\n    def time_get(self, dtype):\r\n        self.idx[1]\r\n\r\n    def time_slice(self, dtype):\r\n        self.idx[:-1]\r\n\r\n    def time_slice_step(self, dtype):\r\n        self.idx[::2]\r\n\r\n    def time_get_loc(self, dtype):\r\n        self.idx.get_loc(self.key)\r\n\r\n    def time_get_loc_sorted(self, dtype):\r\n        self.sorted.get_loc(self.key)\r\n\r\n    def time_get_loc_non_unique(self, dtype):\r\n        self.non_unique.get_loc(self.key)\r\n\r\n    def time_get_loc_non_unique_sorted(self, dtype):\r\n        self.non_unique_sorted.get_loc(self.key)\r\n\r\n\r\nclass Float64IndexMethod:\r\n"]
[90.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[90.002, "i", "sed -n '200,400p' asv_bench/benchmarks/index_object.py\r"]
[90.004, "o", "sed -n '200,400p' asv_bench/benchmarks/index_object.py\r\n"]
[90.006, "o", "\u001b[?2004l\r\nclass Float64IndexMethod:\r\n    # GH 13166\r\n    def setup(self):\r\n        N = 100_000\r\n        a = np.arange(N, dtype=np.float64)\r\n        self.ind = Index(a * 4.8000000418824129e-08)\r\n\r\n    def time_get_loc(self):\r\n        self.ind.get_loc(0)\r\n\r\n\r\nclass IntervalIndexMethod:\r\n    # GH 24813\r\n    params = [10**3, 10**5]\r\n\r\n    def setup(self, N):\r\n        left = np.append(np.arange(N), np.array(0))\r\n        right = np.append(np.arange(1, N + 1), np.array(1))\r\n        self.intv = IntervalIndex.from_arrays(left, right)\r\n        self.intv._engine\r\n\r\n        self.intv2 = IntervalIndex.from_arrays(left + 1, right + 1)\r\n        self.intv2._engine\r\n\r\n        self.left = IntervalIndex.from_breaks(np.arange(N))\r\n        self.right = IntervalIndex.from_breaks(np.arange(N - 3, 2 * N - 3))\r\n\r\n    def time_monotonic_inc(self, N):\r\n        self.intv.is_monotonic_increasing\r\n\r\n    def time_is_unique(self, N):\r\n        self.intv.is_unique\r\n\r\n    def time_intersection(self, N):\r\n        self.left.intersection(self.right)\r\n\r\n    def time_intersection_one_duplicate(self, N):\r\n        self.intv.intersection(self.right)\r\n\r\n    def time_intersection_both_duplicate(self, N):\r\n        self.intv.intersection(self.intv2)\r\n\r\n\r\nclass GC:\r\n    params = [1, 2, 5]\r\n\r\n    def create_use_drop(self):\r\n        idx = Index(list(range(1_000_000)))\r\n        idx._engine\r\n\r\n    def peakmem_gc_instances(self, N):\r\n        try:\r\n            gc.disable()\r\n\r\n            for _ in range(N):\r\n                self.create_use_drop()\r\n        finally:\r\n            gc.enable()\r\n\r\n\r\nfrom .pandas_vb_common import setup  # noqa: F401 isort:skip\r\n"]
[95.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[95.002, "i", "grep -Rsn \"isdisjoint\" pandas | sed -n '1,200p'\r"]
[95.004, "o", "grep -Rsn \"isdisjoint\" pandas | sed -n '1,200p'\r\n"]
[95.006, "o", "\u001b[?2004l\r\npandas/core/frame.py:4646:        if not include.isdisjoint(exclude):\r\npandas/plotting/_matplotlib/core.py:90:    return not set(BASE_COLORS).isdisjoint(style)\r\n"]
[100.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[100.002, "i", "grep -Rsn \"class .*Reindex|def reindex\\(|time_reindex\" asv_bench/benchmarks/frame_methods.py pandas | sed -n '1,200p\r"]
[100.004, "o", "grep -Rsn \"class .*Reindex|def reindex\\(|time_reindex\" asv_bench/benchmarks/frame_methods.py pandas | sed -n '1,200p\r\n"]
[100.006, "o", "p'\r\n\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[105.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[105.002, "i", "sed -n '1,220p' asv_bench/benchmarks/index_object.py\r"]
[105.004, "o", "sed -n '1,220p' asv_bench/benchmarks/index_object.py\r\n"]
[105.006, "o", "\u001b[?2004l\r\nimport gc\r\n\r\nimport numpy as np\r\n\r\nfrom pandas import (\r\n    DatetimeIndex,\r\n    Index,\r\n    IntervalIndex,\r\n    MultiIndex,\r\n    RangeIndex,\r\n    Series,\r\n    date_range,\r\n)\r\n\r\nfrom .pandas_vb_common import tm\r\n\r\n\r\nclass SetOperations:\r\n\r\n    params = (\r\n        [\"monotonic\", \"non_monotonic\"],\r\n        [\"datetime\", \"date_string\", \"int\", \"strings\", \"ea_int\"],\r\n        [\"intersection\", \"union\", \"symmetric_difference\"],\r\n    )\r\n    param_names = [\"index_structure\", \"dtype\", \"method\"]\r\n\r\n    def setup(self, index_structure, dtype, method):\r\n        N = 10**5\r\n        dates_left = date_range(\"1/1/2000\", periods=N, freq=\"T\")\r\n        fmt = \"%Y-%m-%d %H:%M:%S\"\r\n        date_str_left = Index(dates_left.strftime(fmt))\r\n        int_left = Index(np.arange(N))\r\n        ea_int_left = Index(np.arange(N), dtype=\"Int64\")\r\n        str_left = tm.makeStringIndex(N)\r\n\r\n        data = {\r\n            \"datetime\": dates_left,\r\n            \"date_string\": date_str_left,\r\n            \"int\": int_left,\r\n            \"strings\": str_left,\r\n            \"ea_int\": ea_int_left,\r\n        }\r\n\r\n        if index_structure == \"non_monotonic\":\r\n            data = {k: mi[::-1] for k, mi in data.items()}\r\n\r\n        data = {k: {\"left\": idx, \"right\": idx[:-1]} for k, idx in data.items()}\r\n\r\n        self.left = data[dtype][\"left\"]\r\n        self.right = data[dtype][\"right\"]\r\n\r\n    def time_operation(self, index_structure, dtype, method):\r\n        getattr(self.left, method)(self.right)\r\n\r\n\r\nclass SetDisjoint:\r\n    def setup(self):\r\n        N = 10**5\r\n        B = N + 20000\r\n        self.datetime_left = DatetimeIndex(range(N))\r\n        self.datetime_right = DatetimeIndex(range(N, B))\r\n\r\n    def time_datetime_difference_disjoint(self):\r\n        self.datetime_left.difference(self.datetime_right)\r\n\r\n\r\nclass UnionWithDuplicates:\r\n    def setup(self):\r\n        self.left = Index(np.repeat(np.arange(1000), 100))\r\n        self.right = Index(np.tile(np.arange(500, 1500), 50))\r\n\r\n    def time_union_with_duplicates(self):\r\n        self.left.union(self.right)\r\n\r\n\r\nclass Range:\r\n    def setup(self):\r\n        self.idx_inc = RangeIndex(start=0, stop=10**6, step=3)\r\n        self.idx_dec = RangeIndex(start=10**6, stop=-1, step=-3)\r\n\r\n    def time_max(self):\r\n        self.idx_inc.max()\r\n\r\n    def time_max_trivial(self):\r\n        self.idx_dec.max()\r\n\r\n    def time_min(self):\r\n        self.idx_dec.min()\r\n\r\n    def time_min_trivial(self):\r\n        self.idx_inc.min()\r\n\r\n    def time_get_loc_inc(self):\r\n        self.idx_inc.get_loc(900_000)\r\n\r\n    def time_get_loc_dec(self):\r\n        self.idx_dec.get_loc(100_000)\r\n\r\n    def time_iter_inc(self):\r\n        for _ in self.idx_inc:\r\n            pass\r\n\r\n    def time_iter_dec(self):\r\n        for _ in self.idx_dec:\r\n            pass\r\n\r\n    def time_sort_values_asc(self):\r\n        self.idx_inc.sort_values()\r\n\r\n    def time_sort_values_des(self):\r\n        self.idx_inc.sort_values(ascending=False)\r\n\r\n\r\nclass IndexEquals:\r\n    def setup(self):\r\n        idx_large_fast = RangeIndex(100_000)\r\n        idx_small_slow = date_range(start=\"1/1/2012\", periods=1)\r\n        self.mi_large_slow = MultiIndex.from_product([idx_large_fast, idx_small_slow])\r\n\r\n        self.idx_non_object = RangeIndex(1)\r\n\r\n    def time_non_object_equals_multiindex(self):\r\n        self.idx_non_object.equals(self.mi_large_slow)\r\n\r\n\r\nclass IndexAppend:\r\n    def setup(self):\r\n\r\n        N = 10_000\r\n        self.range_idx = RangeIndex(0, 100)\r\n        self.int_idx = self.range_idx.astype(int)\r\n        self.obj_idx = self.int_idx.astype(str)\r\n        self.range_idxs = []\r\n        self.int_idxs = []\r\n        self.object_idxs = []\r\n        for i in range(1, N):\r\n            r_idx = RangeIndex(i * 100, (i + 1) * 100)\r\n            self.range_idxs.append(r_idx)\r\n            i_idx = r_idx.astype(int)\r\n            self.int_idxs.append(i_idx)\r\n            o_idx = i_idx.astype(str)\r\n            self.object_idxs.append(o_idx)\r\n\r\n    def time_append_range_list(self):\r\n        self.range_idx.append(self.range_idxs)\r\n\r\n    def time_append_int_list(self):\r\n        self.int_idx.append(self.int_idxs)\r\n\r\n    def time_append_obj_list(self):\r\n        self.obj_idx.append(self.object_idxs)\r\n\r\n\r\nclass Indexing:\r\n\r\n    params = [\"String\", \"Float\", \"Int\"]\r\n    param_names = [\"dtype\"]\r\n\r\n    def setup(self, dtype):\r\n        N = 10**6\r\n        self.idx = getattr(tm, f\"make{dtype}Index\")(N)\r\n        self.array_mask = (np.arange(N) % 3) == 0\r\n        self.series_mask = Series(self.array_mask)\r\n        self.sorted = self.idx.sort_values()\r\n        half = N // 2\r\n        self.non_unique = self.idx[:half].append(self.idx[:half])\r\n        self.non_unique_sorted = (\r\n            self.sorted[:half].append(self.sorted[:half]).sort_values()\r\n        )\r\n        self.key = self.sorted[N // 4]\r\n\r\n    def time_boolean_array(self, dtype):\r\n        self.idx[self.array_mask]\r\n\r\n    def time_boolean_series(self, dtype):\r\n        self.idx[self.series_mask]\r\n\r\n    def time_get(self, dtype):\r\n        self.idx[1]\r\n\r\n    def time_slice(self, dtype):\r\n        self.idx[:-1]\r\n\r\n    def time_slice_step(self, dtype):\r\n        self.idx[::2]\r\n\r\n    def time_get_loc(self, dtype):\r\n        self.idx.get_loc(self.key)\r\n\r\n    def time_get_loc_sorted(self, dtype):\r\n        self.sorted.get_loc(self.key)\r\n\r\n    def time_get_loc_non_unique(self, dtype):\r\n        self.non_unique.get_loc(self.key)\r\n\r\n    def time_get_loc_non_unique_sorted(self, dtype):\r\n        self.non_unique_sorted.get_loc(self.key)\r\n\r\n\r\nclass Float64IndexMethod:\r\n    # GH 13166\r\n    def setup(self):\r\n        N = 100_000\r\n        a = np.arange(N, dtype=np.float64)\r\n        self.ind = Index(a * 4.8000000418824129e-08)\r\n\r\n    def time_get_loc(self):\r\n        self.ind.get_loc(0)\r\n\r\n\r\nclass IntervalIndexMethod:\r\n    # GH 24813\r\n    params = [10**3, 10**5]\r\n\r\n    def setup(self, N):\r\n        left = np.append(np.arange(N), np.array(0))\r\n        right = np.append(np.arange(1, N + 1), np.array(1))\r\n        self.intv = IntervalIndex.from_arrays(left, right)\r\n        self.intv._engine\r\n\r\n"]
[110.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[110.002, "i", "grep -Rsn \"class .*SetDisjoint|SetDisjoint|GetLoc|Equals|Reindex\" asv_bench/benchmarks | sed -n '1,200p'\r"]
[110.004, "o", "grep -Rsn \"class .*SetDisjoint|SetDisjoint|GetLoc|Equals|Reindex\" asv_bench/benchmarks | sed -n '1,200p'\r\n"]
[110.006, "o", "\u001b[?2004l\r\n"]
[115.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[115.002, "i", "asv run --python=same --bench=\"(frame_methods.Reindex|multiindex_object.GetLoc|frame_methods.Equals).*\" --quick\r"]
[115.004, "o", "asv run --python=same --bench=\"(frame_methods.Reindex|multiindex_object.GetLoc|frame_methods.Equals).*\" --quick\r\n"]
[115.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mNo `asv.conf` file found for valid extensions: ['.json', '.jsonc'].\u001b[0m\r\n"]
[120.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[120.002, "i", "asv profile --python=same --config asv_bench/asv.conf.json frame_methods.Reindex.time_reindex_axis0\r"]
[120.004, "o", "asv profile --python=same --config asv_bench/asv.conf.json frame_methods.Reindex.time_reindex_axis0\r\n"]
[120.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mConfig file asv_bench/asv.conf.json not found.\u001b[0m\r\n"]
[125.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[125.002, "i", "asv profile --python=same --config asv_bench/asv.conf.json multiindex_object.GetLoc.time_get_loc\r"]
[125.004, "o", "asv profile --python=same --config asv_bench/asv.conf.json multiindex_object.GetLoc.time_get_loc\r\n"]
[125.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mConfig file asv_bench/asv.conf.json not found.\u001b[0m\r\n"]
[130.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[130.002, "i", "asv profile --python=same --config asv_bench/asv.conf.json frame_methods.Equals.time_non_object_equals_multiindex\r"]
[130.004, "o", "asv profile --python=same --config asv_bench/asv.conf.json frame_methods.Equals.time_non_object_equals_multiindex\r\n"]
[130.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;31mConfig file asv_bench/asv.conf.json not found.\u001b[0m\r\n"]
[135.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[135.002, "i", "cd asv_bench\r"]
[135.004, "o", "cd asv_bench\r\n"]
[135.006, "o", "\u001b[?2004l\r\n"]
[140.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[140.002, "i", "asv run --python=same --bench=\"(frame_methods.Reindex|index_object.SetDisjoint).*\" --quick\r"]
[140.004, "o", "asv run --python=same --bench=\"(frame_methods.Reindex|index_object.SetDisjoint).*\" --quick\r\n"]
[140.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 6 total benchmarks (1 commits * 1 environments * 6 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[ 8.33%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Reindex.time_reindex_axis0\u001b[0m                                                                                                  5.22\u00b10ms\r\n[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Reindex.time_reindex_axis1\u001b[0m                                                                                                  31.7\u00b10ms\r\n[25.00%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Reindex.time_reindex_axis1_missing\u001b[0m                                                                                          27.3\u00b10ms\r\n[33.33%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Reindex.time_reindex_both_axes\u001b[0m                                                                                              10.0\u00b10ms\r\n[41.67%] \u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Reindex.time_reindex_upcast\u001b[0m                                                                                                 6.34\u00b10ms\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                                4.68\u00b10ms\r\n"]
[145.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[145.002, "i", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r"]
[145.004, "o", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r\n"]
[145.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (index_object.SetDisjoint.time_datetime_difference_disjoint--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                             2.05\u00b10.01ms\r\n\r\nWed Oct  1 19:07:35 2025    /tmp/tmp1lu53eto\r\n\r\n         769 function calls (750 primitive calls) in 0.003 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.003    0.003 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.003    0.003 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.003    0.003 index_object.py:63(time_datetime_difference_disjoint)\r\n        1    0.000    0.000    0.003    0.003 base.py:3391(difference)\r\n        1    0.000    0.000    0.003    0.003 base.py:3446(_difference)\r\n        1    0.000    0.000    0.002    0.002 base.py:7143(_maybe_try_sort)\r\n        1    0.000    0.000    0.002    0.002 algorithms.py:1698(safe_sort)\r\n        1    0.000    0.000    0.001    0.001 base.py:656(argsort)\r\n        1    0.000    0.000    0.001    0.001 sorting.py:371(nargsort)\r\n        1    0.001    0.001    0.001    0.001 {method 'argsort' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.001    0.001 base.py:2849(unique)\r\n        1    0.001    0.001    0.001    0.001 base.py:2171(is_unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:5750(get_indexer_for)\r\n        1    0.000    0.000    0.000    0.000 base.py:3657(get_indexer)\r\n        2    0.000    0.000    0.000    0.000 _mixins.py:155(take)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:1393(take)\r\n        3    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n      9/5    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:379(_maybe_cast_listlike_indexer)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(setdiff1d)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:939(setdiff1d)\r\n        1    0.000    0.000    0.000    0.000 base.py:3744(_get_indexer)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\r\n        1    0.000    0.000    0.000    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\r\n  144/134    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:675(_validate_listlike)\r\n        2    0.000    0.000    0.000    0.000 base.py:6003(_should_compare)\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:115(equals)\r\n       53    0.000    0.000    0.000    0.000 generic.py:42(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 construction.py:73(array)\r\n        1    0.000    0.000    0.000    0.000 base.py:437(__new__)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(concatenate)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_dtype}\r\n        4    0.000    0.000    0.000    0.000 common.py:1256(is_bool_dtype)\r\n  103/100    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n       34    0.000    0.000    0.000    0.000 extension.py:70(fget)\r\n        3    0.000    0.000    0.000    0.000 base.py:611(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:823(isna)\r\n        6    0.000    0.000    0.000    0.000 common.py:456(is_categorical_dtype)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:826(_isnan)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(in1d)\r\n       16    0.000    0.000    0.000    0.000 common.py:1469(get_dtype)\r\n        7    0.000    0.000    0.000    0.000 base.py:286(is_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:726(_view)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:524(in1d)\r\n       53    0.000    0.000    0.000    0.000 generic.py:37(_check)\r\n        5    0.000    0.000    0.000    0.000 construction.py:399(extract_array)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:543(copy)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:344(_name_get)\r\n        1    0.000    0.000    0.000    0.000 base.py:786(_engine)\r\n        2    0.000    0.000    0.000    0.000 common.py:87(get_op_result_name)\r\n        1    0.000    0.000    0.000    0.000 construction.py:497(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:3789(_check_indexing_method)\r\n        1    0.000    0.000    0.000    0.000 base.py:3465(_wrap_difference_result)\r\n        1    0.000    0.000    0.000    0.000 base.py:3236(_wrap_setop_result)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(ones_like)\r\n        6    0.000    0.000    0.000    0.000 common.py:545(is_dtype_equal)\r\n        1    0.000    0.000    0.000    0.000 base.py:3549(_assert_can_do_setop)\r\n        2    0.000    0.000    0.000    0.000 base.py:7120(unpack_nested_dtype)\r\n       24    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        4    0.000    0.000    0.000    0.000 datetimelike.py:105(asi8)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:219(ones_like)\r\n        5    0.000    0.000    0.000    0.000 datetimelike.py:307(asi8)\r\n        1    0.000    0.000    0.000    0.000 base.py:3555(_convert_can_do_setop)\r\n        1    0.000    0.000    0.000    0.000 base.py:5923(_maybe_promote)\r\n        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(array_equal)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(nonzero)\r\n        1    0.000    0.000    0.000    0.000 {function DatetimeLikeArrayMixin.copy at 0x7f8e38db4ca0}\r\n        4    0.000    0.000    0.000    0.000 common.py:157(is_object_dtype)\r\n        2    0.000    0.000    0.000    0.000 datetimes.py:371(_is_comparable_dtype)\r\n        2    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:1892(nonzero)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:51(_wrapfunc)\r\n        7    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n       50    0.000    0.000    0.000    0.000 datetimes.py:532(dtype)\r\n        4    0.000    0.000    0.000    0.000 common.py:1504(_is_dtype_type)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(copyto)\r\n        2    0.000    0.000    0.000    0.000 common.py:109(_maybe_match_name)\r\n        1    0.000    0.000    0.000    0.000 common.py:418(is_interval_dtype)\r\n        6    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:599(__array__)\r\n        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:330(_name_includes_bit_suffix)\r\n        6    0.000    0.000    0.000    0.000 common.py:1663(pandas_dtype)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:1250(is_dtype)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:557(tz)\r\n        3    0.000    0.000    0.000    0.000 inference.py:185(is_array_like)\r\n        1    0.000    0.000    0.000    0.000 numerictypes.py:356(issubdtype)\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:635(astype)\r\n        1    0.000    0.000    0.000    0.000 base.py:709(_shallow_copy)\r\n        2    0.000    0.000    0.000    0.000 numeric.py:2407(array_equal)\r\n        2    0.000    0.000    0.000    0.000 common.py:1346(is_extension_array_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:7085(maybe_extract_name)\r\n      6/4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        4    0.000    0.000    0.000    0.000 common.py:143(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:342(__array__)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:178(_datetime_metadata_str)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(empty_like)\r\n        2    0.000    0.000    0.000    0.000 base.py:2624(_is_multi)\r\n        1    0.000    0.000    0.000    0.000 function.py:150(validate_argsort_with_ascending)\r\n        1    0.000    0.000    0.000    0.000 common.py:1713(is_all_strings)\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:282(issubclass_)\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:673(_get_engine_target)\r\n        2    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:547(_dtype_to_subclass)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n       10    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        3    0.000    0.000    0.000    0.000 base.py:775(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 base.py:744(is_)\r\n        2    0.000    0.000    0.000    0.000 {method '_from_backing_data' of 'pandas._libs.arrays.NDArrayBacked' objects}\r\n       10    0.000    0.000    0.000    0.000 base.py:1542(name)\r\n        2    0.000    0.000    0.000    0.000 common.py:273(is_datetime64_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:838(__len__)\r\n        1    0.000    0.000    0.000    0.000 inference.py:322(is_hashable)\r\n        3    0.000    0.000    0.000    0.000 arraysetops.py:630(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 missing.py:940(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 construction.py:647(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 common.py:1128(needs_i8_conversion)\r\n        3    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:352(size)\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:248(_engine_type)\r\n        3    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x5560a2118680}\r\n        4    0.000    0.000    0.000    0.000 common.py:141(classes)\r\n        1    0.000    0.000    0.000    0.000 common.py:861(is_datetime64_any_dtype)\r\n        1    0.000    0.000    0.000    0.000 common.py:1400(is_ea_or_datetimelike_dtype)\r\n        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\r\n        4    0.000    0.000    0.000    0.000 base.py:4872(_values)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        2    0.000    0.000    0.000    0.000 base.py:5911(_index_as_unique)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:688(inferred_type)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.datetime_data}\r\n        1    0.000    0.000    0.000    0.000 construction.py:461(ensure_wrapped_if_datetimelike)\r\n        1    0.000    0.000    0.000    0.000 function.py:59(__call__)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\r\n        1    0.000    0.000    0.000    0.000 base.py:3019(_validate_sort_keyword)\r\n        2    0.000    0.000    0.000    0.000 numeric.py:2403(_array_equal_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 missing.py:120(clean_fill_method)\r\n        1    0.000    0.000    0.000    0.000 base.py:533(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1079(copyto)\r\n        1    0.000    0.000    0.000    0.000 _mixins.py:189(_values_for_argsort)\r\n        2    0.000    0.000    0.000    0.000 base.py:319(ndim)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:1863(freq)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:1888(_nonzero_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:215(_ones_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:152(concatenate)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:935(_setdiff1d_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 construction.py:706(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:519(_in1d_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:84(empty_like)\r\n        1    0.000    0.000    0.000    0.000 typing.py:1149(cast)\r\n\r\n\r\n"]
[150.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[150.002, "i", "asv profile --python=same frame_methods.Reindex.time_reindex_axis0\r"]
[150.004, "o", "asv profile --python=same frame_methods.Reindex.time_reindex_axis0\r\n"]
[150.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (frame_methods.Reindex.time_reindex_axis0--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mframe_methods.Reindex.time_reindex_axis0\u001b[0m                                                                                                3.10\u00b10.1ms\r\n\r\nWed Oct  1 19:08:04 2025    /tmp/tmpgxmeoyjx\r\n\r\n         505 function calls (499 primitive calls) in 0.004 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.004    0.004 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.004    0.004 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.004    0.004 frame_methods.py:49(time_reindex_axis0)\r\n        1    0.000    0.000    0.004    0.004 _decorators.py:344(wrapper)\r\n        1    0.000    0.000    0.004    0.004 frame.py:5003(reindex)\r\n        1    0.000    0.000    0.004    0.004 generic.py:5105(reindex)\r\n        1    0.000    0.000    0.004    0.004 frame.py:4846(_reindex_axes)\r\n        1    0.000    0.000    0.004    0.004 frame.py:4863(_reindex_index)\r\n        1    0.000    0.000    0.004    0.004 generic.py:5396(_reindex_with_indexers)\r\n        1    0.000    0.000    0.004    0.004 managers.py:671(reindex_indexer)\r\n        1    0.000    0.000    0.004    0.004 managers.py:736(<listcomp>)\r\n        1    0.000    0.000    0.004    0.004 blocks.py:828(take_nd)\r\n        1    0.000    0.000    0.004    0.004 take.py:58(take_nd)\r\n        1    0.000    0.000    0.004    0.004 take.py:121(_take_nd_ndarray)\r\n        1    0.004    0.004    0.004    0.004 {pandas._libs.algos.take_2d_axis0_float64_float64}\r\n        1    0.000    0.000    0.000    0.000 base.py:4103(reindex)\r\n        1    0.000    0.000    0.000    0.000 base.py:3657(get_indexer)\r\n        1    0.000    0.000    0.000    0.000 range.py:340(_get_indexer)\r\n        3    0.000    0.000    0.000    0.000 base.py:6990(ensure_index)\r\n        1    0.000    0.000    0.000    0.000 base.py:437(__new__)\r\n        3    0.000    0.000    0.000    0.000 range.py:465(equals)\r\n        3    0.000    0.000    0.000    0.000 base.py:5234(equals)\r\n  108/106    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 managers.py:172(blknos)\r\n        1    0.000    0.000    0.000    0.000 {method '_rebuild_blknos_and_blklocs' of 'pandas._libs.internals.BlockManager' objects}\r\n        6    0.000    0.000    0.000    0.000 base.py:4872(_values)\r\n        1    0.000    0.000    0.000    0.000 range.py:191(_data)\r\n        1    0.000    0.000    0.000    0.000 base.py:6003(_should_compare)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:84(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\r\n        1    0.000    0.000    0.000    0.000 managers.py:1028(from_blocks)\r\n       28    0.000    0.000    0.000    0.000 generic.py:42(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 base.py:3789(_check_indexing_method)\r\n        2    0.000    0.000    0.000    0.000 generic.py:5913(__finalize__)\r\n        1    0.000    0.000    0.000    0.000 construction.py:497(sanitize_array)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 generic.py:5336(<genexpr>)\r\n        5    0.000    0.000    0.000    0.000 base.py:286(is_dtype)\r\n        4    0.000    0.000    0.000    0.000 common.py:545(is_dtype_equal)\r\n        4    0.000    0.000    0.000    0.000 common.py:456(is_categorical_dtype)\r\n        1    0.000    0.000    0.000    0.000 frame.py:636(__init__)\r\n        2    0.000    0.000    0.000    0.000 common.py:1256(is_bool_dtype)\r\n       10    0.000    0.000    0.000    0.000 common.py:1469(get_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:55(shape)\r\n        3    0.000    0.000    0.000    0.000 common.py:1178(is_numeric_dtype)\r\n       28    0.000    0.000    0.000    0.000 generic.py:37(_check)\r\n        8    0.000    0.000    0.000    0.000 common.py:1504(_is_dtype_type)\r\n        1    0.000    0.000    0.000    0.000 _validators.py:265(validate_axis_style_args)\r\n        1    0.000    0.000    0.000    0.000 base.py:5321(identical)\r\n        1    0.000    0.000    0.000    0.000 generic.py:267(__init__)\r\n        1    0.000    0.000    0.000    0.000 common.py:418(is_interval_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:5923(_maybe_promote)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:137(_validate_dtype)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:184(fill_value)\r\n        4    0.000    0.000    0.000    0.000 common.py:157(is_object_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:611(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 generic.py:5379(_needs_reindex_multi)\r\n        2    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n     11/8    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        3    0.000    0.000    0.000    0.000 base.py:57(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:511(_construct_axes_from_arguments)\r\n        1    0.000    0.000    0.000    0.000 base.py:6021(_is_comparable_dtype)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:1250(is_dtype)\r\n        1    0.000    0.000    0.000    0.000 missing.py:633(na_value_for_dtype)\r\n        3    0.000    0.000    0.000    0.000 base.py:744(is_)\r\n       13    0.000    0.000    0.000    0.000 range.py:297(dtype)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:220(make_block_same_class)\r\n      8/7    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\r\n        1    0.000    0.000    0.000    0.000 base.py:7120(unpack_nested_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:4217(_wrap_reindex_result)\r\n        1    0.000    0.000    0.000    0.000 construction.py:399(extract_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:7085(maybe_extract_name)\r\n       37    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        1    0.000    0.000    0.000    0.000 take.py:566(_take_preprocess_indexer_and_fill_value)\r\n        1    0.000    0.000    0.000    0.000 common.py:207(count_not_none)\r\n        1    0.000    0.000    0.000    0.000 base.py:4221(_maybe_preserve_names)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:148(_ensure_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:547(_dtype_to_subclass)\r\n        2    0.000    0.000    0.000    0.000 missing.py:457(array_equivalent)\r\n        1    0.000    0.000    0.000    0.000 common.py:193(any_not_none)\r\n        2    0.000    0.000    0.000    0.000 flags.py:85(allows_duplicate_labels)\r\n        2    0.000    0.000    0.000    0.000 __init__.py:33(using_copy_on_write)\r\n        3    0.000    0.000    0.000    0.000 common.py:1663(pandas_dtype)\r\n        1    0.000    0.000    0.000    0.000 flags.py:49(__init__)\r\n        3    0.000    0.000    0.000    0.000 common.py:151(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 generic.py:551(_get_axis_name)\r\n        2    0.000    0.000    0.000    0.000 range.py:872(__len__)\r\n        1    0.000    0.000    0.000    0.000 common.py:1222(is_float_dtype)\r\n        1    0.000    0.000    0.000    0.000 generic.py:557(_get_axis)\r\n        2    0.000    0.000    0.000    0.000 missing.py:940(clean_reindex_fill_method)\r\n        2    0.000    0.000    0.000    0.000 common.py:1400(is_ea_or_datetimelike_dtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1346(is_extension_array_dtype)\r\n        1    0.000    0.000    0.000    0.000 cast.py:557(maybe_promote)\r\n        3    0.000    0.000    0.000    0.000 base.py:5911(_index_as_unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:2593(inferred_type)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\r\n        1    0.000    0.000    0.000    0.000 base.py:2624(_is_multi)\r\n        5    0.000    0.000    0.000    0.000 common.py:143(<lambda>)\r\n       12    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.any}\r\n        6    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 construction.py:686(_sanitize_str_dtypes)\r\n        1    0.000    0.000    0.000    0.000 construction.py:647(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 inference.py:322(is_hashable)\r\n        5    0.000    0.000    0.000    0.000 common.py:141(classes)\r\n        3    0.000    0.000    0.000    0.000 generic.py:543(_get_axis_number)\r\n        1    0.000    0.000    0.000    0.000 generic.py:540(<dictcomp>)\r\n       11    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\r\n        3    0.000    0.000    0.000    0.000 common.py:146(classes_and_not_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 range.py:238(start)\r\n        1    0.000    0.000    0.000    0.000 take.py:327(_get_take_nd_function)\r\n        1    0.000    0.000    0.000    0.000 generic.py:563(_get_block_manager_axis)\r\n        4    0.000    0.000    0.000    0.000 range.py:253(step)\r\n        1    0.000    0.000    0.000    0.000 common.py:1128(needs_i8_conversion)\r\n        2    0.000    0.000    0.000    0.000 missing.py:120(clean_fill_method)\r\n        1    0.000    0.000    0.000    0.000 base.py:4086(_validate_can_reindex)\r\n        1    0.000    0.000    0.000    0.000 base.py:6279(_maybe_cast_listlike_indexer)\r\n        1    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\r\n        3    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x561eb7b55680}\r\n        1    0.000    0.000    0.000    0.000 base.py:7049(ensure_has_len)\r\n        1    0.000    0.000    0.000    0.000 frame.py:627(_constructor)\r\n        1    0.000    0.000    0.000    0.000 base.py:844(__array__)\r\n        2    0.000    0.000    0.000    0.000 generic.py:340(attrs)\r\n        2    0.000    0.000    0.000    0.000 flags.py:53(allows_duplicate_labels)\r\n        1    0.000    0.000    0.000    0.000 construction.py:461(ensure_wrapped_if_datetimelike)\r\n        1    0.000    0.000    0.000    0.000 base.py:775(_reset_identity)\r\n        4    0.000    0.000    0.000    0.000 generic.py:361(flags)\r\n        4    0.000    0.000    0.000    0.000 common.py:197(<genexpr>)\r\n        4    0.000    0.000    0.000    0.000 range.py:301(is_unique)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\r\n        1    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\r\n        2    0.000    0.000    0.000    0.000 base.py:1542(name)\r\n        3    0.000    0.000    0.000    0.000 common.py:211(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 managers.py:188(blklocs)\r\n        1    0.000    0.000    0.000    0.000 base.py:838(__len__)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\r\n        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\r\n        2    0.000    0.000    0.000    0.000 range.py:246(stop)\r\n        1    0.000    0.000    0.000    0.000 blocks.py:463(dtype)\r\n        1    0.000    0.000    0.000    0.000 managers.py:982(__init__)\r\n        1    0.000    0.000    0.000    0.000 base.py:894(dtype)\r\n        3    0.000    0.000    0.000    0.000 range.py:322(inferred_type)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:1843(nlevels)\r\n        1    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 construction.py:706(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 typing.py:1149(cast)\r\n\r\n\r\n"]
[155.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[155.002, "i", "cd ..\r"]
[155.004, "o", "cd ..\r\n"]
[155.006, "o", "\u001b[?2004l\r\n"]
[160.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[160.002, "i", "grep -Rsn \"def difference\\(|class .*Index.*difference\" pandas/core/indexes | sed -n '1,200p'\r"]
[160.004, "o", "grep -Rsn \"def difference\\(|class .*Index.*difference\" pandas/core/indexes | sed -n '1,200p'\r\n"]
[160.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[165.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[165.002, "i", "grep -Rsn \"def difference\\s*\\(\" pandas/core/indexes | sed -n '1,200p'\r"]
[165.004, "o", "grep -Rsn \"def difference\\s*\\(\" pandas/core/indexes | sed -n '1,200p'\r\n"]
[165.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[170.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[170.002, "i", "sed -n '1,240p' pandas/core/indexes/datetimes.py\r"]
[170.004, "o", "sed -n '1,240p' pandas/core/indexes/datetimes.py\r\n"]
[170.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nimport datetime as dt\r\nimport operator\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Hashable,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\nimport pytz\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    Period,\r\n    Timestamp,\r\n    index as libindex,\r\n    lib,\r\n)\r\nfrom pandas._libs.tslibs import (\r\n    Resolution,\r\n    periods_per_day,\r\n    timezones,\r\n    to_offset,\r\n)\r\nfrom pandas._libs.tslibs.dtypes import NpyDatetimeUnit\r\nfrom pandas._libs.tslibs.offsets import prefix_mapping\r\nfrom pandas._typing import (\r\n    Dtype,\r\n    DtypeObj,\r\n    Frequency,\r\n    IntervalClosedType,\r\n    TimeAmbiguous,\r\n    TimeNonexistent,\r\n    npt,\r\n)\r\nfrom pandas.util._decorators import (\r\n    cache_readonly,\r\n    doc,\r\n)\r\n\r\nfrom pandas.core.dtypes.common import (\r\n    is_datetime64_dtype,\r\n    is_datetime64tz_dtype,\r\n    is_scalar,\r\n)\r\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\r\n\r\nfrom pandas.core.arrays.datetimes import (\r\n    DatetimeArray,\r\n    tz_to_dtype,\r\n)\r\nimport pandas.core.common as com\r\nfrom pandas.core.indexes.base import (\r\n    Index,\r\n    maybe_extract_name,\r\n)\r\nfrom pandas.core.indexes.datetimelike import DatetimeTimedeltaMixin\r\nfrom pandas.core.indexes.extension import inherit_names\r\nfrom pandas.core.tools.times import to_time\r\n\r\nif TYPE_CHECKING:\r\n    from pandas.core.api import (\r\n        DataFrame,\r\n        NumericIndex,\r\n        PeriodIndex,\r\n    )\r\n\r\n\r\ndef _new_DatetimeIndex(cls, d):\r\n    \"\"\"\r\n    This is called upon unpickling, rather than the default which doesn't\r\n    have arguments and breaks __new__\r\n    \"\"\"\r\n    if \"data\" in d and not isinstance(d[\"data\"], DatetimeIndex):\r\n        # Avoid need to verify integrity by calling simple_new directly\r\n        data = d.pop(\"data\")\r\n        if not isinstance(data, DatetimeArray):\r\n            # For backward compat with older pickles, we may need to construct\r\n            #  a DatetimeArray to adapt to the newer _simple_new signature\r\n            tz = d.pop(\"tz\")\r\n            freq = d.pop(\"freq\")\r\n            dta = DatetimeArray._simple_new(data, dtype=tz_to_dtype(tz), freq=freq)\r\n        else:\r\n            dta = data\r\n            for key in [\"tz\", \"freq\"]:\r\n                # These are already stored in our DatetimeArray; if they are\r\n                #  also in the pickle and don't match, we have a problem.\r\n                if key in d:\r\n                    assert d[key] == getattr(dta, key)\r\n                    d.pop(key)\r\n        result = cls._simple_new(dta, **d)\r\n    else:\r\n        with warnings.catch_warnings():\r\n            # TODO: If we knew what was going in to **d, we might be able to\r\n            #  go through _simple_new instead\r\n            warnings.simplefilter(\"ignore\")\r\n            result = cls.__new__(cls, **d)\r\n\r\n    return result\r\n\r\n\r\n@inherit_names(\r\n    DatetimeArray._field_ops\r\n    + [\r\n        method\r\n        for method in DatetimeArray._datetimelike_methods\r\n        if method not in (\"tz_localize\", \"tz_convert\", \"strftime\")\r\n    ],\r\n    DatetimeArray,\r\n    wrap=True,\r\n)\r\n@inherit_names([\"is_normalized\", \"_resolution_obj\"], DatetimeArray, cache=True)\r\n@inherit_names(\r\n    [\r\n        \"tz\",\r\n        \"tzinfo\",\r\n        \"dtype\",\r\n        \"to_pydatetime\",\r\n        \"_format_native_types\",\r\n        \"date\",\r\n        \"time\",\r\n        \"timetz\",\r\n        \"std\",\r\n    ]\r\n    + DatetimeArray._bool_ops,\r\n    DatetimeArray,\r\n)\r\nclass DatetimeIndex(DatetimeTimedeltaMixin):\r\n    \"\"\"\r\n    Immutable ndarray-like of datetime64 data.\r\n\r\n    Represented internally as int64, and which can be boxed to Timestamp objects\r\n    that are subclasses of datetime and carry metadata.\r\n\r\n    Parameters\r\n    ----------\r\n    data : array-like (1-dimensional)\r\n        Datetime-like data to construct index with.\r\n    freq : str or pandas offset object, optional\r\n        One of pandas date offset strings or corresponding objects. The string\r\n        'infer' can be passed in order to set the frequency of the index as the\r\n        inferred frequency upon creation.\r\n    tz : pytz.timezone or dateutil.tz.tzfile or datetime.tzinfo or str\r\n        Set the Timezone of the data.\r\n    normalize : bool, default False\r\n        Normalize start/end dates to midnight before generating date range.\r\n    closed : {'left', 'right'}, optional\r\n        Set whether to include `start` and `end` that are on the\r\n        boundary. The default includes boundary points on either end.\r\n    ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\r\n        When clocks moved backward due to DST, ambiguous times may arise.\r\n        For example in Central European Time (UTC+01), when going from 03:00\r\n        DST to 02:00 non-DST, 02:30:00 local time occurs both at 00:30:00 UTC\r\n        and at 01:30:00 UTC. In such a situation, the `ambiguous` parameter\r\n        dictates how ambiguous times should be handled.\r\n\r\n        - 'infer' will attempt to infer fall dst-transition hours based on\r\n          order\r\n        - bool-ndarray where True signifies a DST time, False signifies a\r\n          non-DST time (note that this flag is only applicable for ambiguous\r\n          times)\r\n        - 'NaT' will return NaT where there are ambiguous times\r\n        - 'raise' will raise an AmbiguousTimeError if there are ambiguous times.\r\n    dayfirst : bool, default False\r\n        If True, parse dates in `data` with the day first order.\r\n    yearfirst : bool, default False\r\n        If True parse dates in `data` with the year first order.\r\n    dtype : numpy.dtype or DatetimeTZDtype or str, default None\r\n        Note that the only NumPy dtype allowed is \u2018datetime64[ns]\u2019.\r\n    copy : bool, default False\r\n        Make a copy of input ndarray.\r\n    name : label, default None\r\n        Name to be stored in the index.\r\n\r\n    Attributes\r\n    ----------\r\n    year\r\n    month\r\n    day\r\n    hour\r\n    minute\r\n    second\r\n    microsecond\r\n    nanosecond\r\n    date\r\n    time\r\n    timetz\r\n    dayofyear\r\n    day_of_year\r\n    weekofyear\r\n    week\r\n    dayofweek\r\n    day_of_week\r\n    weekday\r\n    quarter\r\n    tz\r\n    freq\r\n    freqstr\r\n    is_month_start\r\n    is_month_end\r\n    is_quarter_start\r\n    is_quarter_end\r\n    is_year_start\r\n    is_year_end\r\n    is_leap_year\r\n    inferred_freq\r\n\r\n    Methods\r\n    -------\r\n    normalize\r\n    strftime\r\n    snap\r\n    tz_convert\r\n    tz_localize\r\n    round\r\n    floor\r\n    ceil\r\n    to_period\r\n    to_pydatetime\r\n    to_series\r\n    to_frame\r\n    month_name\r\n    day_name\r\n    mean\r\n    std\r\n\r\n    See Also\r\n    --------\r\n    Index : The base pandas Index type.\r\n    TimedeltaIndex : Index of timedelta64 data.\r\n    PeriodIndex : Index of Period data.\r\n    to_datetime : Convert argument to datetime.\r\n    date_range : Create a fixed-frequency DatetimeIndex.\r\n\r\n    Notes\r\n    -----\r\n    To learn more about the frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n"]
[175.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[175.002, "i", "sed -n '1,260p' pandas/core/indexes/base.py\r"]
[175.004, "o", "sed -n '1,260p' pandas/core/indexes/base.py\r\n"]
[175.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nfrom datetime import datetime\r\nimport functools\r\nfrom itertools import zip_longest\r\nimport operator\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Callable,\r\n    ClassVar,\r\n    Hashable,\r\n    Iterable,\r\n    Literal,\r\n    NoReturn,\r\n    Sequence,\r\n    TypeVar,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import get_option\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    algos as libalgos,\r\n    index as libindex,\r\n    lib,\r\n)\r\nimport pandas._libs.join as libjoin\r\nfrom pandas._libs.lib import (\r\n    is_datetime_array,\r\n    no_default,\r\n)\r\nfrom pandas._libs.missing import is_float_nan\r\nfrom pandas._libs.tslibs import (\r\n    IncompatibleFrequency,\r\n    OutOfBoundsDatetime,\r\n    Timestamp,\r\n    tz_compare,\r\n)\r\nfrom pandas._typing import (\r\n    AnyAll,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    DropKeep,\r\n    DtypeObj,\r\n    F,\r\n    IgnoreRaise,\r\n    IndexLabel,\r\n    JoinHow,\r\n    Level,\r\n    Shape,\r\n    npt,\r\n)\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    DuplicateLabelError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.util._decorators import (\r\n    Appender,\r\n    cache_readonly,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import (\r\n    find_stack_level,\r\n    rewrite_exception,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_array\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    common_dtype_categorical_compat,\r\n    ensure_dtype_can_hold_na,\r\n    find_result_type,\r\n    infer_dtype_from,\r\n    maybe_cast_pointwise_result,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_int64,\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    is_bool_dtype,\r\n    is_categorical_dtype,\r\n    is_dtype_equal,\r\n    is_ea_or_datetimelike_dtype,\r\n    is_extension_array_dtype,\r\n    is_float,\r\n    is_float_dtype,\r\n    is_hashable,\r\n    is_integer,\r\n    is_integer_dtype,\r\n    is_interval_dtype,\r\n    is_iterator,\r\n    is_list_like,\r\n    is_numeric_dtype,\r\n    is_object_dtype,\r\n    is_scalar,\r\n    is_signed_integer_dtype,\r\n    is_string_dtype,\r\n    needs_i8_conversion,\r\n    pandas_dtype,\r\n    validate_all_hashable,\r\n)\r\nfrom pandas.core.dtypes.concat import concat_compat\r\nfrom pandas.core.dtypes.dtypes import (\r\n    CategoricalDtype,\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    IntervalDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCDatetimeIndex,\r\n    ABCMultiIndex,\r\n    ABCPeriodIndex,\r\n    ABCSeries,\r\n    ABCTimedeltaIndex,\r\n)\r\nfrom pandas.core.dtypes.inference import is_dict_like\r\nfrom pandas.core.dtypes.missing import (\r\n    array_equivalent,\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    arraylike,\r\n    ops,\r\n)\r\nfrom pandas.core.accessor import CachedAccessor\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.array_algos.putmask import (\r\n    setitem_datetimelike_compat,\r\n    validate_putmask,\r\n)\r\nfrom pandas.core.arrays import (\r\n    BaseMaskedArray,\r\n    Categorical,\r\n    ExtensionArray,\r\n)\r\nfrom pandas.core.arrays.string_ import StringArray\r\nfrom pandas.core.base import (\r\n    IndexOpsMixin,\r\n    PandasObject,\r\n)\r\nimport pandas.core.common as com\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n    sanitize_array,\r\n)\r\nfrom pandas.core.indexers import disallow_ndim_indexing\r\nfrom pandas.core.indexes.frozen import FrozenList\r\nfrom pandas.core.missing import clean_reindex_fill_method\r\nfrom pandas.core.ops import get_op_result_name\r\nfrom pandas.core.ops.invalid import make_invalid_op\r\nfrom pandas.core.sorting import (\r\n    ensure_key_mapped,\r\n    get_group_index_sorter,\r\n    nargsort,\r\n)\r\nfrom pandas.core.strings import StringMethods\r\n\r\nfrom pandas.io.formats.printing import (\r\n    PrettyDict,\r\n    default_pprint,\r\n    format_object_summary,\r\n    pprint_thing,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from pandas import (\r\n        CategoricalIndex,\r\n        DataFrame,\r\n        MultiIndex,\r\n        Series,\r\n    )\r\n    from pandas.core.arrays import PeriodArray\r\n\r\n\r\n__all__ = [\"Index\"]\r\n\r\n_unsortable_types = frozenset((\"mixed\", \"mixed-integer\"))\r\n\r\n_index_doc_kwargs: dict[str, str] = {\r\n    \"klass\": \"Index\",\r\n    \"inplace\": \"\",\r\n    \"target_klass\": \"Index\",\r\n    \"raises_section\": \"\",\r\n    \"unique\": \"Index\",\r\n    \"duplicated\": \"np.ndarray\",\r\n}\r\n_index_shared_docs: dict[str, str] = {}\r\nstr_t = str\r\n\r\n\r\n_dtype_obj = np.dtype(\"object\")\r\n\r\n_masked_engines = {\r\n    \"Complex128\": libindex.MaskedComplex128Engine,\r\n    \"Complex64\": libindex.MaskedComplex64Engine,\r\n    \"Float64\": libindex.MaskedFloat64Engine,\r\n    \"Float32\": libindex.MaskedFloat32Engine,\r\n    \"UInt64\": libindex.MaskedUInt64Engine,\r\n    \"UInt32\": libindex.MaskedUInt32Engine,\r\n    \"UInt16\": libindex.MaskedUInt16Engine,\r\n    \"UInt8\": libindex.MaskedUInt8Engine,\r\n    \"Int64\": libindex.MaskedInt64Engine,\r\n    \"Int32\": libindex.MaskedInt32Engine,\r\n    \"Int16\": libindex.MaskedInt16Engine,\r\n    \"Int8\": libindex.MaskedInt8Engine,\r\n    \"boolean\": libindex.MaskedBoolEngine,\r\n}\r\n\r\n\r\ndef _maybe_return_indexers(meth: F) -> F:\r\n    \"\"\"\r\n    Decorator to simplify 'return_indexers' checks in Index.join.\r\n    \"\"\"\r\n\r\n    @functools.wraps(meth)\r\n    def join(\r\n        self,\r\n        other: Index,\r\n        *,\r\n        how: JoinHow = \"left\",\r\n        level=None,\r\n        return_indexers: bool = False,\r\n        sort: bool = False,\r\n    ):\r\n        join_index, lidx, ridx = meth(self, other, how=how, level=level, sort=sort)\r\n        if not return_indexers:\r\n            return join_index\r\n\r\n        if lidx is not None:\r\n            lidx = ensure_platform_int(lidx)\r\n        if ridx is not None:\r\n            ridx = ensure_platform_int(ridx)\r\n        return join_index, lidx, ridx\r\n\r\n    return cast(F, join)\r\n\r\n\r\ndef _new_Index(cls, d):\r\n    \"\"\"\r\n    This is called upon unpickling, rather than the default which doesn't\r\n    have arguments and breaks __new__.\r\n    \"\"\"\r\n    # required for backward compat, because PI can't be instantiated with\r\n    # ordinals through __new__ GH #13277\r\n"]
[180.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[180.002, "i", "sed -n '1,240p' pandas/core/indexes/range.py\r"]
[180.004, "o", "sed -n '1,240p' pandas/core/indexes/range.py\r\n"]
[180.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nfrom datetime import timedelta\r\nimport operator\r\nfrom sys import getsizeof\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Callable,\r\n    Hashable,\r\n    Iterator,\r\n    List,\r\n    cast,\r\n)\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._libs import (\r\n    index as libindex,\r\n    lib,\r\n)\r\nfrom pandas._libs.algos import unique_deltas\r\nfrom pandas._libs.lib import no_default\r\nfrom pandas._typing import (\r\n    Dtype,\r\n    npt,\r\n)\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.util._decorators import (\r\n    cache_readonly,\r\n    doc,\r\n)\r\n\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_platform_int,\r\n    ensure_python_int,\r\n    is_float,\r\n    is_integer,\r\n    is_scalar,\r\n    is_signed_integer_dtype,\r\n    is_timedelta64_dtype,\r\n)\r\nfrom pandas.core.dtypes.generic import ABCTimedeltaIndex\r\n\r\nfrom pandas.core import ops\r\nimport pandas.core.common as com\r\nfrom pandas.core.construction import extract_array\r\nimport pandas.core.indexes.base as ibase\r\nfrom pandas.core.indexes.base import maybe_extract_name\r\nfrom pandas.core.indexes.numeric import NumericIndex\r\nfrom pandas.core.ops.common import unpack_zerodim_and_defer\r\n\r\nif TYPE_CHECKING:\r\n    from pandas import Index\r\n\r\n_empty_range = range(0)\r\n\r\n\r\nclass RangeIndex(NumericIndex):\r\n    \"\"\"\r\n    Immutable Index implementing a monotonic integer range.\r\n\r\n    RangeIndex is a memory-saving special case of an Index limited to representing\r\n    monotonic ranges with a 64-bit dtype. Using RangeIndex may in some instances\r\n    improve computing speed.\r\n\r\n    This is the default index type used\r\n    by DataFrame and Series when no explicit index is provided by the user.\r\n\r\n    Parameters\r\n    ----------\r\n    start : int (default: 0), range, or other RangeIndex instance\r\n        If int and \"stop\" is not given, interpreted as \"stop\" instead.\r\n    stop : int (default: 0)\r\n    step : int (default: 1)\r\n    dtype : np.int64\r\n        Unused, accepted for homogeneity with other index types.\r\n    copy : bool, default False\r\n        Unused, accepted for homogeneity with other index types.\r\n    name : object, optional\r\n        Name to be stored in the index.\r\n\r\n    Attributes\r\n    ----------\r\n    start\r\n    stop\r\n    step\r\n\r\n    Methods\r\n    -------\r\n    from_range\r\n\r\n    See Also\r\n    --------\r\n    Index : The base pandas Index type.\r\n    \"\"\"\r\n\r\n    _typ = \"rangeindex\"\r\n    _dtype_validation_metadata = (is_signed_integer_dtype, \"signed integer\")\r\n    _range: range\r\n\r\n    @property\r\n    def _engine_type(self) -> type[libindex.Int64Engine]:\r\n        return libindex.Int64Engine\r\n\r\n    # --------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __new__(\r\n        cls,\r\n        start=None,\r\n        stop=None,\r\n        step=None,\r\n        dtype: Dtype | None = None,\r\n        copy: bool = False,\r\n        name: Hashable = None,\r\n    ) -> RangeIndex:\r\n        cls._validate_dtype(dtype)\r\n        name = maybe_extract_name(name, start, cls)\r\n\r\n        # RangeIndex\r\n        if isinstance(start, RangeIndex):\r\n            return start.copy(name=name)\r\n        elif isinstance(start, range):\r\n            return cls._simple_new(start, name=name)\r\n\r\n        # validate the arguments\r\n        if com.all_none(start, stop, step):\r\n            raise TypeError(\"RangeIndex(...) must be called with integers\")\r\n\r\n        start = ensure_python_int(start) if start is not None else 0\r\n\r\n        if stop is None:\r\n            start, stop = 0, start\r\n        else:\r\n            stop = ensure_python_int(stop)\r\n\r\n        step = ensure_python_int(step) if step is not None else 1\r\n        if step == 0:\r\n            raise ValueError(\"Step must not be zero\")\r\n\r\n        rng = range(start, stop, step)\r\n        return cls._simple_new(rng, name=name)\r\n\r\n    @classmethod\r\n    def from_range(\r\n        cls, data: range, name=None, dtype: Dtype | None = None\r\n    ) -> RangeIndex:\r\n        \"\"\"\r\n        Create RangeIndex from a range object.\r\n\r\n        Returns\r\n        -------\r\n        RangeIndex\r\n        \"\"\"\r\n        if not isinstance(data, range):\r\n            raise TypeError(\r\n                f\"{cls.__name__}(...) must be called with object coercible to a \"\r\n                f\"range, {repr(data)} was passed\"\r\n            )\r\n        cls._validate_dtype(dtype)\r\n        return cls._simple_new(data, name=name)\r\n\r\n    #  error: Argument 1 of \"_simple_new\" is incompatible with supertype \"Index\";\r\n    #  supertype defines the argument type as\r\n    #  \"Union[ExtensionArray, ndarray[Any, Any]]\"  [override]\r\n    @classmethod\r\n    def _simple_new(  # type: ignore[override]\r\n        cls, values: range, name: Hashable = None\r\n    ) -> RangeIndex:\r\n        result = object.__new__(cls)\r\n\r\n        assert isinstance(values, range)\r\n\r\n        result._range = values\r\n        result._name = name\r\n        result._cache = {}\r\n        result._reset_identity()\r\n        return result\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    # error: Return type \"Type[NumericIndex]\" of \"_constructor\" incompatible with return\r\n    # type \"Type[RangeIndex]\" in supertype \"Index\"\r\n    @cache_readonly\r\n    def _constructor(self) -> type[NumericIndex]:  # type: ignore[override]\r\n        \"\"\"return the class to use for construction\"\"\"\r\n        return NumericIndex\r\n\r\n    # error: Signature of \"_data\" incompatible with supertype \"Index\"\r\n    @cache_readonly\r\n    def _data(self) -> np.ndarray:  # type: ignore[override]\r\n        \"\"\"\r\n        An int array that for performance reasons is created only when needed.\r\n\r\n        The constructed array is saved in ``_cache``.\r\n        \"\"\"\r\n        return np.arange(self.start, self.stop, self.step, dtype=np.int64)\r\n\r\n    def _get_data_as_items(self):\r\n        \"\"\"return a list of tuples of start, stop, step\"\"\"\r\n        rng = self._range\r\n        return [(\"start\", rng.start), (\"stop\", rng.stop), (\"step\", rng.step)]\r\n\r\n    def __reduce__(self):\r\n        d = {\"name\": self.name}\r\n        d.update(dict(self._get_data_as_items()))\r\n        return ibase._new_Index, (type(self), d), None\r\n\r\n    # --------------------------------------------------------------------\r\n    # Rendering Methods\r\n\r\n    def _format_attrs(self):\r\n        \"\"\"\r\n        Return a list of tuples of the (attr, formatted_value)\r\n        \"\"\"\r\n        attrs = self._get_data_as_items()\r\n        if self.name is not None:\r\n            attrs.append((\"name\", ibase.default_pprint(self.name)))\r\n        return attrs\r\n\r\n    def _format_data(self, name=None):\r\n        # we are formatting thru the attributes\r\n        return None\r\n\r\n    def _format_with_header(self, header: list[str], na_rep: str) -> list[str]:\r\n        # Equivalent to Index implementation, but faster\r\n        if not len(self._range):\r\n            return header\r\n        first_val_str = str(self._range[0])\r\n        last_val_str = str(self._range[-1])\r\n        max_length = max(len(first_val_str), len(last_val_str))\r\n\r\n        return header + [f\"{x:<{max_length}}\" for x in self._range]\r\n\r\n    # --------------------------------------------------------------------\r\n\r\n    @property\r\n    def start(self) -> int:\r\n        \"\"\"\r\n"]
[185.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[185.002, "i", "grep -Rsn \"def difference\\s*\\(\" pandas/core/indexes | sed -n '1,200p'\r"]
[185.004, "o", "grep -Rsn \"def difference\\s*\\(\" pandas/core/indexes | sed -n '1,200p'\r\n"]
[185.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[190.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[190.002, "i", "sed -n '1,240p' pandas/core/indexes/base.py\r"]
[190.004, "o", "sed -n '1,240p' pandas/core/indexes/base.py\r\n"]
[190.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nfrom datetime import datetime\r\nimport functools\r\nfrom itertools import zip_longest\r\nimport operator\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Callable,\r\n    ClassVar,\r\n    Hashable,\r\n    Iterable,\r\n    Literal,\r\n    NoReturn,\r\n    Sequence,\r\n    TypeVar,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import get_option\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    algos as libalgos,\r\n    index as libindex,\r\n    lib,\r\n)\r\nimport pandas._libs.join as libjoin\r\nfrom pandas._libs.lib import (\r\n    is_datetime_array,\r\n    no_default,\r\n)\r\nfrom pandas._libs.missing import is_float_nan\r\nfrom pandas._libs.tslibs import (\r\n    IncompatibleFrequency,\r\n    OutOfBoundsDatetime,\r\n    Timestamp,\r\n    tz_compare,\r\n)\r\nfrom pandas._typing import (\r\n    AnyAll,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    DropKeep,\r\n    DtypeObj,\r\n    F,\r\n    IgnoreRaise,\r\n    IndexLabel,\r\n    JoinHow,\r\n    Level,\r\n    Shape,\r\n    npt,\r\n)\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    DuplicateLabelError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.util._decorators import (\r\n    Appender,\r\n    cache_readonly,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import (\r\n    find_stack_level,\r\n    rewrite_exception,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_array\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    common_dtype_categorical_compat,\r\n    ensure_dtype_can_hold_na,\r\n    find_result_type,\r\n    infer_dtype_from,\r\n    maybe_cast_pointwise_result,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_int64,\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    is_bool_dtype,\r\n    is_categorical_dtype,\r\n    is_dtype_equal,\r\n    is_ea_or_datetimelike_dtype,\r\n    is_extension_array_dtype,\r\n    is_float,\r\n    is_float_dtype,\r\n    is_hashable,\r\n    is_integer,\r\n    is_integer_dtype,\r\n    is_interval_dtype,\r\n    is_iterator,\r\n    is_list_like,\r\n    is_numeric_dtype,\r\n    is_object_dtype,\r\n    is_scalar,\r\n    is_signed_integer_dtype,\r\n    is_string_dtype,\r\n    needs_i8_conversion,\r\n    pandas_dtype,\r\n    validate_all_hashable,\r\n)\r\nfrom pandas.core.dtypes.concat import concat_compat\r\nfrom pandas.core.dtypes.dtypes import (\r\n    CategoricalDtype,\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    IntervalDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCDatetimeIndex,\r\n    ABCMultiIndex,\r\n    ABCPeriodIndex,\r\n    ABCSeries,\r\n    ABCTimedeltaIndex,\r\n)\r\nfrom pandas.core.dtypes.inference import is_dict_like\r\nfrom pandas.core.dtypes.missing import (\r\n    array_equivalent,\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    arraylike,\r\n    ops,\r\n)\r\nfrom pandas.core.accessor import CachedAccessor\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.array_algos.putmask import (\r\n    setitem_datetimelike_compat,\r\n    validate_putmask,\r\n)\r\nfrom pandas.core.arrays import (\r\n    BaseMaskedArray,\r\n    Categorical,\r\n    ExtensionArray,\r\n)\r\nfrom pandas.core.arrays.string_ import StringArray\r\nfrom pandas.core.base import (\r\n    IndexOpsMixin,\r\n    PandasObject,\r\n)\r\nimport pandas.core.common as com\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n    sanitize_array,\r\n)\r\nfrom pandas.core.indexers import disallow_ndim_indexing\r\nfrom pandas.core.indexes.frozen import FrozenList\r\nfrom pandas.core.missing import clean_reindex_fill_method\r\nfrom pandas.core.ops import get_op_result_name\r\nfrom pandas.core.ops.invalid import make_invalid_op\r\nfrom pandas.core.sorting import (\r\n    ensure_key_mapped,\r\n    get_group_index_sorter,\r\n    nargsort,\r\n)\r\nfrom pandas.core.strings import StringMethods\r\n\r\nfrom pandas.io.formats.printing import (\r\n    PrettyDict,\r\n    default_pprint,\r\n    format_object_summary,\r\n    pprint_thing,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from pandas import (\r\n        CategoricalIndex,\r\n        DataFrame,\r\n        MultiIndex,\r\n        Series,\r\n    )\r\n    from pandas.core.arrays import PeriodArray\r\n\r\n\r\n__all__ = [\"Index\"]\r\n\r\n_unsortable_types = frozenset((\"mixed\", \"mixed-integer\"))\r\n\r\n_index_doc_kwargs: dict[str, str] = {\r\n    \"klass\": \"Index\",\r\n    \"inplace\": \"\",\r\n    \"target_klass\": \"Index\",\r\n    \"raises_section\": \"\",\r\n    \"unique\": \"Index\",\r\n    \"duplicated\": \"np.ndarray\",\r\n}\r\n_index_shared_docs: dict[str, str] = {}\r\nstr_t = str\r\n\r\n\r\n_dtype_obj = np.dtype(\"object\")\r\n\r\n_masked_engines = {\r\n    \"Complex128\": libindex.MaskedComplex128Engine,\r\n    \"Complex64\": libindex.MaskedComplex64Engine,\r\n    \"Float64\": libindex.MaskedFloat64Engine,\r\n    \"Float32\": libindex.MaskedFloat32Engine,\r\n    \"UInt64\": libindex.MaskedUInt64Engine,\r\n    \"UInt32\": libindex.MaskedUInt32Engine,\r\n    \"UInt16\": libindex.MaskedUInt16Engine,\r\n    \"UInt8\": libindex.MaskedUInt8Engine,\r\n    \"Int64\": libindex.MaskedInt64Engine,\r\n    \"Int32\": libindex.MaskedInt32Engine,\r\n    \"Int16\": libindex.MaskedInt16Engine,\r\n    \"Int8\": libindex.MaskedInt8Engine,\r\n    \"boolean\": libindex.MaskedBoolEngine,\r\n}\r\n\r\n\r\ndef _maybe_return_indexers(meth: F) -> F:\r\n    \"\"\"\r\n    Decorator to simplify 'return_indexers' checks in Index.join.\r\n    \"\"\"\r\n\r\n    @functools.wraps(meth)\r\n    def join(\r\n        self,\r\n        other: Index,\r\n        *,\r\n        how: JoinHow = \"left\",\r\n        level=None,\r\n        return_indexers: bool = False,\r\n        sort: bool = False,\r\n    ):\r\n"]
[195.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[195.002, "i", "grep -n \"def difference\\s*(\" pandas/core/indexes/base.py\r"]
[195.004, "o", "grep -n \"def difference\\s*(\" pandas/core/indexes/base.py\r\n"]
[195.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K3392\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef difference(\u001b[m\u001b[Kself, other, sort=None):\r\n"]
[200.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[200.002, "i", "sed -n '240,520p' pandas/core/indexes/base.py\r"]
[200.004, "o", "sed -n '240,520p' pandas/core/indexes/base.py\r\n"]
[200.006, "o", "\u001b[?2004l\r\n    ):\r\n        join_index, lidx, ridx = meth(self, other, how=how, level=level, sort=sort)\r\n        if not return_indexers:\r\n            return join_index\r\n\r\n        if lidx is not None:\r\n            lidx = ensure_platform_int(lidx)\r\n        if ridx is not None:\r\n            ridx = ensure_platform_int(ridx)\r\n        return join_index, lidx, ridx\r\n\r\n    return cast(F, join)\r\n\r\n\r\ndef _new_Index(cls, d):\r\n    \"\"\"\r\n    This is called upon unpickling, rather than the default which doesn't\r\n    have arguments and breaks __new__.\r\n    \"\"\"\r\n    # required for backward compat, because PI can't be instantiated with\r\n    # ordinals through __new__ GH #13277\r\n    if issubclass(cls, ABCPeriodIndex):\r\n        from pandas.core.indexes.period import _new_PeriodIndex\r\n\r\n        return _new_PeriodIndex(cls, **d)\r\n\r\n    if issubclass(cls, ABCMultiIndex):\r\n        if \"labels\" in d and \"codes\" not in d:\r\n            # GH#23752 \"labels\" kwarg has been replaced with \"codes\"\r\n            d[\"codes\"] = d.pop(\"labels\")\r\n\r\n        # Since this was a valid MultiIndex at pickle-time, we don't need to\r\n        #  check validty at un-pickle time.\r\n        d[\"verify_integrity\"] = False\r\n\r\n    elif \"dtype\" not in d and \"data\" in d:\r\n        # Prevent Index.__new__ from conducting inference;\r\n        #  \"data\" key not in RangeIndex\r\n        d[\"dtype\"] = d[\"data\"].dtype\r\n    return cls.__new__(cls, **d)\r\n\r\n\r\n_IndexT = TypeVar(\"_IndexT\", bound=\"Index\")\r\n\r\n\r\nclass Index(IndexOpsMixin, PandasObject):\r\n    \"\"\"\r\n    Immutable sequence used for indexing and alignment.\r\n\r\n    The basic object storing axis labels for all pandas objects.\r\n\r\n    Parameters\r\n    ----------\r\n    data : array-like (1-dimensional)\r\n    dtype : NumPy dtype (default: object)\r\n        If dtype is None, we find the dtype that best fits the data.\r\n        If an actual dtype is provided, we coerce to that dtype if it's safe.\r\n        Otherwise, an error will be raised.\r\n    copy : bool\r\n        Make a copy of input ndarray.\r\n    name : object\r\n        Name to be stored in the index.\r\n    tupleize_cols : bool (default: True)\r\n        When True, attempt to create a MultiIndex if possible.\r\n\r\n    See Also\r\n    --------\r\n    RangeIndex : Index implementing a monotonic integer range.\r\n    CategoricalIndex : Index of :class:`Categorical` s.\r\n    MultiIndex : A multi-level, or hierarchical Index.\r\n    IntervalIndex : An Index of :class:`Interval` s.\r\n    DatetimeIndex : Index of datetime64 data.\r\n    TimedeltaIndex : Index of timedelta64 data.\r\n    PeriodIndex : Index of Period data.\r\n    NumericIndex : Index of numpy int/uint/float data.\r\n\r\n    Notes\r\n    -----\r\n    An Index instance can **only** contain hashable objects\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.Index([1, 2, 3])\r\n    NumericIndex([1, 2, 3], dtype='int64')\r\n\r\n    >>> pd.Index(list('abc'))\r\n    Index(['a', 'b', 'c'], dtype='object')\r\n    \"\"\"\r\n\r\n    # To hand over control to subclasses\r\n    _join_precedence = 1\r\n\r\n    # Cython methods; see github.com/cython/cython/issues/2647\r\n    #  for why we need to wrap these instead of making them class attributes\r\n    # Moreover, cython will choose the appropriate-dtyped sub-function\r\n    #  given the dtypes of the passed arguments\r\n\r\n    @final\r\n    def _left_indexer_unique(self: _IndexT, other: _IndexT) -> npt.NDArray[np.intp]:\r\n        # Caller is responsible for ensuring other.dtype == self.dtype\r\n        sv = self._get_join_target()\r\n        ov = other._get_join_target()\r\n        # can_use_libjoin assures sv and ov are ndarrays\r\n        sv = cast(np.ndarray, sv)\r\n        ov = cast(np.ndarray, ov)\r\n        return libjoin.left_join_indexer_unique(sv, ov)\r\n\r\n    @final\r\n    def _left_indexer(\r\n        self: _IndexT, other: _IndexT\r\n    ) -> tuple[ArrayLike, npt.NDArray[np.intp], npt.NDArray[np.intp]]:\r\n        # Caller is responsible for ensuring other.dtype == self.dtype\r\n        sv = self._get_join_target()\r\n        ov = other._get_join_target()\r\n        # can_use_libjoin assures sv and ov are ndarrays\r\n        sv = cast(np.ndarray, sv)\r\n        ov = cast(np.ndarray, ov)\r\n        joined_ndarray, lidx, ridx = libjoin.left_join_indexer(sv, ov)\r\n        joined = self._from_join_target(joined_ndarray)\r\n        return joined, lidx, ridx\r\n\r\n    @final\r\n    def _inner_indexer(\r\n        self: _IndexT, other: _IndexT\r\n    ) -> tuple[ArrayLike, npt.NDArray[np.intp], npt.NDArray[np.intp]]:\r\n        # Caller is responsible for ensuring other.dtype == self.dtype\r\n        sv = self._get_join_target()\r\n        ov = other._get_join_target()\r\n        # can_use_libjoin assures sv and ov are ndarrays\r\n        sv = cast(np.ndarray, sv)\r\n        ov = cast(np.ndarray, ov)\r\n        joined_ndarray, lidx, ridx = libjoin.inner_join_indexer(sv, ov)\r\n        joined = self._from_join_target(joined_ndarray)\r\n        return joined, lidx, ridx\r\n\r\n    @final\r\n    def _outer_indexer(\r\n        self: _IndexT, other: _IndexT\r\n    ) -> tuple[ArrayLike, npt.NDArray[np.intp], npt.NDArray[np.intp]]:\r\n        # Caller is responsible for ensuring other.dtype == self.dtype\r\n        sv = self._get_join_target()\r\n        ov = other._get_join_target()\r\n        # can_use_libjoin assures sv and ov are ndarrays\r\n        sv = cast(np.ndarray, sv)\r\n        ov = cast(np.ndarray, ov)\r\n        joined_ndarray, lidx, ridx = libjoin.outer_join_indexer(sv, ov)\r\n        joined = self._from_join_target(joined_ndarray)\r\n        return joined, lidx, ridx\r\n\r\n    _typ: str = \"index\"\r\n    _data: ExtensionArray | np.ndarray\r\n    _data_cls: type[ExtensionArray] | tuple[type[np.ndarray], type[ExtensionArray]] = (\r\n        np.ndarray,\r\n        ExtensionArray,\r\n    )\r\n    _id: object | None = None\r\n    _name: Hashable = None\r\n    # MultiIndex.levels previously allowed setting the index name. We\r\n    # don't allow this anymore, and raise if it happens rather than\r\n    # failing silently.\r\n    _no_setting_name: bool = False\r\n    _comparables: list[str] = [\"name\"]\r\n    _attributes: list[str] = [\"name\"]\r\n    _can_hold_strings: bool = True\r\n\r\n    _engine_types: dict[np.dtype | ExtensionDtype, type[libindex.IndexEngine]] = {\r\n        np.dtype(np.int8): libindex.Int8Engine,\r\n        np.dtype(np.int16): libindex.Int16Engine,\r\n        np.dtype(np.int32): libindex.Int32Engine,\r\n        np.dtype(np.int64): libindex.Int64Engine,\r\n        np.dtype(np.uint8): libindex.UInt8Engine,\r\n        np.dtype(np.uint16): libindex.UInt16Engine,\r\n        np.dtype(np.uint32): libindex.UInt32Engine,\r\n        np.dtype(np.uint64): libindex.UInt64Engine,\r\n        np.dtype(np.float32): libindex.Float32Engine,\r\n        np.dtype(np.float64): libindex.Float64Engine,\r\n        np.dtype(np.complex64): libindex.Complex64Engine,\r\n        np.dtype(np.complex128): libindex.Complex128Engine,\r\n    }\r\n\r\n    @property\r\n    def _engine_type(\r\n        self,\r\n    ) -> type[libindex.IndexEngine] | type[libindex.ExtensionEngine]:\r\n        return self._engine_types.get(self.dtype, libindex.ObjectEngine)\r\n\r\n    # whether we support partial string indexing. Overridden\r\n    # in DatetimeIndex and PeriodIndex\r\n    _supports_partial_string_indexing = False\r\n\r\n    _accessors = {\"str\"}\r\n\r\n    str = CachedAccessor(\"str\", StringMethods)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __new__(\r\n        cls,\r\n        data=None,\r\n        dtype=None,\r\n        copy: bool = False,\r\n        name=None,\r\n        tupleize_cols: bool = True,\r\n    ) -> Index:\r\n\r\n        from pandas.core.indexes.range import RangeIndex\r\n\r\n        name = maybe_extract_name(name, data, cls)\r\n\r\n        if dtype is not None:\r\n            dtype = pandas_dtype(dtype)\r\n\r\n        data_dtype = getattr(data, \"dtype\", None)\r\n\r\n        # range\r\n        if isinstance(data, (range, RangeIndex)):\r\n            result = RangeIndex(start=data, copy=copy, name=name)\r\n            if dtype is not None:\r\n                return result.astype(dtype, copy=False)\r\n            return result\r\n\r\n        elif is_ea_or_datetimelike_dtype(dtype):\r\n            # non-EA dtype indexes have special casting logic, so we punt here\r\n            pass\r\n\r\n        elif is_ea_or_datetimelike_dtype(data_dtype):\r\n            pass\r\n\r\n        elif isinstance(data, (np.ndarray, Index, ABCSeries)):\r\n\r\n            if isinstance(data, ABCMultiIndex):\r\n                data = data._values\r\n\r\n            if data.dtype.kind not in [\"i\", \"u\", \"f\", \"b\", \"c\", \"m\", \"M\"]:\r\n                # GH#11836 we need to avoid having numpy coerce\r\n                # things that look like ints/floats to ints unless\r\n                # they are actually ints, e.g. '0' and 0.0\r\n                # should not be coerced\r\n                data = com.asarray_tuplesafe(data, dtype=_dtype_obj)\r\n\r\n        elif is_scalar(data):\r\n            raise cls._raise_scalar_data_error(data)\r\n        elif hasattr(data, \"__array__\"):\r\n            return Index(np.asarray(data), dtype=dtype, copy=copy, name=name)\r\n        elif not is_list_like(data) and not isinstance(data, memoryview):\r\n            # 2022-11-16 the memoryview check is only necessary on some CI\r\n            #  builds, not clear why\r\n            raise cls._raise_scalar_data_error(data)\r\n\r\n        else:\r\n\r\n            if tupleize_cols:\r\n                # GH21470: convert iterable to list before determining if empty\r\n                if is_iterator(data):\r\n                    data = list(data)\r\n\r\n                if data and all(isinstance(e, tuple) for e in data):\r\n                    # we must be all tuples, otherwise don't construct\r\n                    # 10697\r\n                    from pandas.core.indexes.multi import MultiIndex\r\n\r\n                    return MultiIndex.from_tuples(data, names=name)\r\n            # other iterable of some kind\r\n\r\n            if not isinstance(data, (list, tuple)):\r\n                # we allow set/frozenset, which Series/sanitize_array does not, so\r\n                #  cast to list here\r\n                data = list(data)\r\n            if len(data) == 0:\r\n                # unlike Series, we default to object dtype:\r\n                data = np.array(data, dtype=object)\r\n\r\n            if len(data) and isinstance(data[0], tuple):\r\n                # Ensure we get 1-D array of tuples instead of 2D array.\r\n                data = com.asarray_tuplesafe(data, dtype=_dtype_obj)\r\n\r\n        try:\r\n            arr = sanitize_array(data, None, dtype=dtype, copy=copy)\r\n        except ValueError as err:\r\n            if \"index must be specified when data is not list-like\" in str(err):\r\n"]
[205.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[205.002, "i", "sed -n '1,260p' pandas/core/indexes/datetimes.py\r"]
[205.004, "o", "sed -n '1,260p' pandas/core/indexes/datetimes.py\r\n"]
[205.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nimport datetime as dt\r\nimport operator\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Hashable,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\nimport pytz\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    Period,\r\n    Timestamp,\r\n    index as libindex,\r\n    lib,\r\n)\r\nfrom pandas._libs.tslibs import (\r\n    Resolution,\r\n    periods_per_day,\r\n    timezones,\r\n    to_offset,\r\n)\r\nfrom pandas._libs.tslibs.dtypes import NpyDatetimeUnit\r\nfrom pandas._libs.tslibs.offsets import prefix_mapping\r\nfrom pandas._typing import (\r\n    Dtype,\r\n    DtypeObj,\r\n    Frequency,\r\n    IntervalClosedType,\r\n    TimeAmbiguous,\r\n    TimeNonexistent,\r\n    npt,\r\n)\r\nfrom pandas.util._decorators import (\r\n    cache_readonly,\r\n    doc,\r\n)\r\n\r\nfrom pandas.core.dtypes.common import (\r\n    is_datetime64_dtype,\r\n    is_datetime64tz_dtype,\r\n    is_scalar,\r\n)\r\nfrom pandas.core.dtypes.missing import is_valid_na_for_dtype\r\n\r\nfrom pandas.core.arrays.datetimes import (\r\n    DatetimeArray,\r\n    tz_to_dtype,\r\n)\r\nimport pandas.core.common as com\r\nfrom pandas.core.indexes.base import (\r\n    Index,\r\n    maybe_extract_name,\r\n)\r\nfrom pandas.core.indexes.datetimelike import DatetimeTimedeltaMixin\r\nfrom pandas.core.indexes.extension import inherit_names\r\nfrom pandas.core.tools.times import to_time\r\n\r\nif TYPE_CHECKING:\r\n    from pandas.core.api import (\r\n        DataFrame,\r\n        NumericIndex,\r\n        PeriodIndex,\r\n    )\r\n\r\n\r\ndef _new_DatetimeIndex(cls, d):\r\n    \"\"\"\r\n    This is called upon unpickling, rather than the default which doesn't\r\n    have arguments and breaks __new__\r\n    \"\"\"\r\n    if \"data\" in d and not isinstance(d[\"data\"], DatetimeIndex):\r\n        # Avoid need to verify integrity by calling simple_new directly\r\n        data = d.pop(\"data\")\r\n        if not isinstance(data, DatetimeArray):\r\n            # For backward compat with older pickles, we may need to construct\r\n            #  a DatetimeArray to adapt to the newer _simple_new signature\r\n            tz = d.pop(\"tz\")\r\n            freq = d.pop(\"freq\")\r\n            dta = DatetimeArray._simple_new(data, dtype=tz_to_dtype(tz), freq=freq)\r\n        else:\r\n            dta = data\r\n            for key in [\"tz\", \"freq\"]:\r\n                # These are already stored in our DatetimeArray; if they are\r\n                #  also in the pickle and don't match, we have a problem.\r\n                if key in d:\r\n                    assert d[key] == getattr(dta, key)\r\n                    d.pop(key)\r\n        result = cls._simple_new(dta, **d)\r\n    else:\r\n        with warnings.catch_warnings():\r\n            # TODO: If we knew what was going in to **d, we might be able to\r\n            #  go through _simple_new instead\r\n            warnings.simplefilter(\"ignore\")\r\n            result = cls.__new__(cls, **d)\r\n\r\n    return result\r\n\r\n\r\n@inherit_names(\r\n    DatetimeArray._field_ops\r\n    + [\r\n        method\r\n        for method in DatetimeArray._datetimelike_methods\r\n        if method not in (\"tz_localize\", \"tz_convert\", \"strftime\")\r\n    ],\r\n    DatetimeArray,\r\n    wrap=True,\r\n)\r\n@inherit_names([\"is_normalized\", \"_resolution_obj\"], DatetimeArray, cache=True)\r\n@inherit_names(\r\n    [\r\n        \"tz\",\r\n        \"tzinfo\",\r\n        \"dtype\",\r\n        \"to_pydatetime\",\r\n        \"_format_native_types\",\r\n        \"date\",\r\n        \"time\",\r\n        \"timetz\",\r\n        \"std\",\r\n    ]\r\n    + DatetimeArray._bool_ops,\r\n    DatetimeArray,\r\n)\r\nclass DatetimeIndex(DatetimeTimedeltaMixin):\r\n    \"\"\"\r\n    Immutable ndarray-like of datetime64 data.\r\n\r\n    Represented internally as int64, and which can be boxed to Timestamp objects\r\n    that are subclasses of datetime and carry metadata.\r\n\r\n    Parameters\r\n    ----------\r\n    data : array-like (1-dimensional)\r\n        Datetime-like data to construct index with.\r\n    freq : str or pandas offset object, optional\r\n        One of pandas date offset strings or corresponding objects. The string\r\n        'infer' can be passed in order to set the frequency of the index as the\r\n        inferred frequency upon creation.\r\n    tz : pytz.timezone or dateutil.tz.tzfile or datetime.tzinfo or str\r\n        Set the Timezone of the data.\r\n    normalize : bool, default False\r\n        Normalize start/end dates to midnight before generating date range.\r\n    closed : {'left', 'right'}, optional\r\n        Set whether to include `start` and `end` that are on the\r\n        boundary. The default includes boundary points on either end.\r\n    ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\r\n        When clocks moved backward due to DST, ambiguous times may arise.\r\n        For example in Central European Time (UTC+01), when going from 03:00\r\n        DST to 02:00 non-DST, 02:30:00 local time occurs both at 00:30:00 UTC\r\n        and at 01:30:00 UTC. In such a situation, the `ambiguous` parameter\r\n        dictates how ambiguous times should be handled.\r\n\r\n        - 'infer' will attempt to infer fall dst-transition hours based on\r\n          order\r\n        - bool-ndarray where True signifies a DST time, False signifies a\r\n          non-DST time (note that this flag is only applicable for ambiguous\r\n          times)\r\n        - 'NaT' will return NaT where there are ambiguous times\r\n        - 'raise' will raise an AmbiguousTimeError if there are ambiguous times.\r\n    dayfirst : bool, default False\r\n        If True, parse dates in `data` with the day first order.\r\n    yearfirst : bool, default False\r\n        If True parse dates in `data` with the year first order.\r\n    dtype : numpy.dtype or DatetimeTZDtype or str, default None\r\n        Note that the only NumPy dtype allowed is \u2018datetime64[ns]\u2019.\r\n    copy : bool, default False\r\n        Make a copy of input ndarray.\r\n    name : label, default None\r\n        Name to be stored in the index.\r\n\r\n    Attributes\r\n    ----------\r\n    year\r\n    month\r\n    day\r\n    hour\r\n    minute\r\n    second\r\n    microsecond\r\n    nanosecond\r\n    date\r\n    time\r\n    timetz\r\n    dayofyear\r\n    day_of_year\r\n    weekofyear\r\n    week\r\n    dayofweek\r\n    day_of_week\r\n    weekday\r\n    quarter\r\n    tz\r\n    freq\r\n    freqstr\r\n    is_month_start\r\n    is_month_end\r\n    is_quarter_start\r\n    is_quarter_end\r\n    is_year_start\r\n    is_year_end\r\n    is_leap_year\r\n    inferred_freq\r\n\r\n    Methods\r\n    -------\r\n    normalize\r\n    strftime\r\n    snap\r\n    tz_convert\r\n    tz_localize\r\n    round\r\n    floor\r\n    ceil\r\n    to_period\r\n    to_pydatetime\r\n    to_series\r\n    to_frame\r\n    month_name\r\n    day_name\r\n    mean\r\n    std\r\n\r\n    See Also\r\n    --------\r\n    Index : The base pandas Index type.\r\n    TimedeltaIndex : Index of timedelta64 data.\r\n    PeriodIndex : Index of Period data.\r\n    to_datetime : Convert argument to datetime.\r\n    date_range : Create a fixed-frequency DatetimeIndex.\r\n\r\n    Notes\r\n    -----\r\n    To learn more about the frequency strings, please see `this link\r\n    <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\r\n    \"\"\"\r\n\r\n    _typ = \"datetimeindex\"\r\n\r\n    _data_cls = DatetimeArray\r\n    _supports_partial_string_indexing = True\r\n\r\n    @property\r\n    def _engine_type(self) -> type[libindex.DatetimeEngine]:\r\n        return libindex.DatetimeEngine\r\n\r\n    _data: DatetimeArray\r\n    inferred_freq: str | None\r\n    tz: dt.tzinfo | None\r\n\r\n    # --------------------------------------------------------------------\r\n    # methods that dispatch to DatetimeArray and wrap result\r\n\r\n    @doc(DatetimeArray.strftime)\r\n    def strftime(self, date_format) -> Index:\r\n"]
[210.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[210.002, "i", "grep -n \"def difference\\s*(\" pandas/core/indexes/datetimes.py\r"]
[210.004, "o", "grep -n \"def difference\\s*(\" pandas/core/indexes/datetimes.py\r\n"]
[210.006, "o", "\u001b[?2004l\r\n"]
[215.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[215.002, "i", "python - << 'PY'\r"]
[215.004, "o", "python - << 'PY'\r\n"]
[215.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import inspect, pandas as pd\r\n\u001b[?2004l\r\n\u001b[?2004h> import pandas.core.indexes.base as ibase\r\n\u001b[?2004l\r\n\u001b[?2004h> print('Index.difference at:', inspect.getsource(ibase.Index.difference)[:4000])\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nIndex.difference at:     @final\r\n    def difference(self, other, sort=None):\r\n        \"\"\"\r\n        Return a new Index with elements of index not in `other`.\r\n\r\n        This is the set difference of two Index objects.\r\n\r\n        Parameters\r\n        ----------\r\n        other : Index or array-like\r\n        sort : False or None, default None\r\n            Whether to sort the resulting index. By default, the\r\n            values are attempted to be sorted, but any TypeError from\r\n            incomparable elements is caught by pandas.\r\n\r\n            * None : Attempt to sort the result, but catch any TypeErrors\r\n              from comparing incomparable elements.\r\n            * False : Do not sort the result.\r\n\r\n        Returns\r\n        -------\r\n        Index\r\n\r\n        Examples\r\n        --------\r\n        >>> idx1 = pd.Index([2, 1, 3, 4])\r\n        >>> idx2 = pd.Index([3, 4, 5, 6])\r\n        >>> idx1.difference(idx2)\r\n        NumericIndex([1, 2], dtype='int64')\r\n        >>> idx1.difference(idx2, sort=False)\r\n        NumericIndex([2, 1], dtype='int64')\r\n        \"\"\"\r\n        self._validate_sort_keyword(sort)\r\n        self._assert_can_do_setop(other)\r\n        other, result_name = self._convert_can_do_setop(other)\r\n\r\n        # Note: we do NOT call _dti_setop_align_tzs here, as there\r\n        #  is no requirement that .difference be commutative, so it does\r\n        #  not cast to object.\r\n\r\n        if self.equals(other):\r\n            # Note: we do not (yet) sort even if sort=None GH#24959\r\n            return self[:0].rename(result_name)\r\n\r\n        if len(other) == 0:\r\n            # Note: we do not (yet) sort even if sort=None GH#24959\r\n            return self.rename(result_name)\r\n\r\n        if not self._should_compare(other):\r\n            # Nothing matches -> difference is everything\r\n            return self.rename(result_name)\r\n\r\n        result = self._difference(other, sort=sort)\r\n        return self._wrap_difference_result(other, result)\r\n\r\n"]
[220.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[220.002, "i", "python - << 'PY'\r"]
[220.004, "o", "python - << 'PY'\r\n"]
[220.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import inspect\r\n\u001b[?2004l\r\n\u001b[?2004h> import pandas.core.indexes.datetimes as idt\r\n\u001b[?2004l\r\n\u001b[?2004h> print('DatetimeIndex class has difference?', hasattr(idt.DatetimeIndex, 'difference'))\r\n\u001b[?2004l\r\n\u001b[?2004h> if hasattr(idt.DatetimeIndex, 'difference'):\r\n\u001b[?2004l\r\n\u001b[?2004h>     print(inspect.getsource(idt.DatetimeIndex.difference)[:3000])\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nDatetimeIndex class has difference? True\r\n    @final\r\n    def difference(self, other, sort=None):\r\n        \"\"\"\r\n        Return a new Index with elements of index not in `other`.\r\n\r\n        This is the set difference of two Index objects.\r\n\r\n        Parameters\r\n        ----------\r\n        other : Index or array-like\r\n        sort : False or None, default None\r\n            Whether to sort the resulting index. By default, the\r\n            values are attempted to be sorted, but any TypeError from\r\n            incomparable elements is caught by pandas.\r\n\r\n            * None : Attempt to sort the result, but catch any TypeErrors\r\n              from comparing incomparable elements.\r\n            * False : Do not sort the result.\r\n\r\n        Returns\r\n        -------\r\n        Index\r\n\r\n        Examples\r\n        --------\r\n        >>> idx1 = pd.Index([2, 1, 3, 4])\r\n        >>> idx2 = pd.Index([3, 4, 5, 6])\r\n        >>> idx1.difference(idx2)\r\n        NumericIndex([1, 2], dtype='int64')\r\n        >>> idx1.difference(idx2, sort=False)\r\n        NumericIndex([2, 1], dtype='int64')\r\n        \"\"\"\r\n        self._validate_sort_keyword(sort)\r\n        self._assert_can_do_setop(other)\r\n        other, result_name = self._convert_can_do_setop(other)\r\n\r\n        # Note: we do NOT call _dti_setop_align_tzs here, as there\r\n        #  is no requirement that .difference be commutative, so it does\r\n        #  not cast to object.\r\n\r\n        if self.equals(other):\r\n            # Note: we do not (yet) sort even if sort=None GH#24959\r\n            return self[:0].rename(result_name)\r\n\r\n        if len(other) == 0:\r\n            # Note: we do not (yet) sort even if sort=None GH#24959\r\n            return self.rename(result_name)\r\n\r\n        if not self._should_compare(other):\r\n            # Nothing matches -> difference is everything\r\n            return self.rename(result_name)\r\n\r\n        result = self._difference(other, sort=sort)\r\n        return self._wrap_difference_result(other, result)\r\n\r\n"]
[225.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[225.002, "i", "git checkout -b opt-fastpath-difference\r"]
[225.004, "o", "git checkout -b opt-fastpath-difference\r\n"]
[225.006, "o", "\u001b[?2004l\r\nSwitched to a new branch 'opt-fastpath-difference'\r\n"]
[230.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[230.002, "i", "python - << 'PY'\r"]
[230.004, "o", "python - << 'PY'\r\n"]
[230.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/indexes/base.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> m = re.search(r\"def difference\\(self, other, sort=None\\):\", s)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('difference method not found in base.Index')\r\n\u001b[?2004l\r\n\u001b[?2004h>     print(s[:500])\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     start = m.start()\r\n\u001b[?2004l\r\n\u001b[?2004h>     # find end of method by next def at same indent\r\n\u001b[?2004l\r\n\u001b[?2004h>     rest = s[start:]\r\n\u001b[?2004l\r\n\u001b[?2004h>     lines = rest.splitlines()\r\n\u001b[?2004l\r\n\u001b[?2004h>     # naive scan to find end index\r\n\u001b[?2004l\r\n\u001b[?2004h>     indent = None\r\n\u001b[?2004l\r\n\u001b[?2004h>     end_idx = None\r\n\u001b[?2004l\r\n\u001b[?2004h>     for i, line in enumerate(lines[1:], start=1):\r\n\u001b[?2004l\r\n\u001b[?2004h>         if line.startswith('    def ') and not line.startswith('        '):\r\n\u001b[?2004l\r\n\u001b[?2004h>             end_idx = i\r\n\u001b[?2004l\r\n\u001b[?2004h>             break\r\n\u001b[?2004l\r\n\u001b[?2004h>     if end_idx is None:\r\n\u001b[?2004l\r\n\u001b[?2004h>         end = len(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         end = start + sum(len(l)+1 for l in lines[:end_idx])\r\n\u001b[?2004l\r\n\u001b[?2004h>     body = s[start:end]\r\n\u001b[?2004l\r\n\u001b[?2004h>     if 'fastpath_disjoint' in body:\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('Fastpath already present')\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         insert_point = body.find('\\n        # TODO')\r\n\u001b[?2004l\r\n\u001b[?2004h>         if insert_point == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>             insert_point = body.find('\\n        \\n')\r\n\u001b[?2004l\r\n\u001b[?2004h>         fast = \"\\n        # fastpath_disjoint: if both indexes are monotonic and non-overlapping by bounds, return self copy\\n        try:\\n            if (sel\r\nlf.is_monotonic_increasing or self.is_monotonic_decreasing) and (other.is_monotonic_increasing or other.is_monotonic_decreasing):\\n                # compute endp\r\npoints cheaply\\n                self_first = self[0] if len(self) else None\\n                self_last = self[-1] if len(self) else None\\n                other_f\r\nfirst = other[0] if len(other) else None\\n                other_last = other[-1] if len(other) else None\\n                if self_first is not None and other_fir\r\nrst is not None:\\n                    # normalize for decreasing by swapping\\n                    if self.is_monotonic_decreasing:\\n                        self_\r\n_first, self_last = self_last, self_first\\n                    if other.is_monotonic_decreasing:\\n                        other_first, other_last = other_last, o\r\nother_first\\n                    if self_last < other_first or other_last < self_first:\\n                        # no overlap\\n                        res = self\r\nf.copy(deep=False)\\n                        res.name = self.name\\n                        return res\\n        except Exception:\r\n\u001b[?2004l\r\n\u001b[?2004h>             pass\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_body = body.replace('\\n', '\\n', 1)\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_body = new_body.replace('\\n        ', fast + '\\n        ', 1)\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_s = s[:start] + new_body + s[end:]\r\n\u001b[?2004l\r\n\u001b[?2004h>         p.write_text(new_s)\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('Patched base.Index.difference with fastpath_disjoint')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n  File \"<stdin>\", line 32\r\n    fast = \"\\n        # fastpath_disjoint: if both indexes are monotonic and non-overlapping by bounds, return self copy\\n        try:\\n            if (self.is_monotonic_increasing or self.is_monotonic_decreasing) and (other.is_monotonic_increasing or other.is_monotonic_decreasing):\\n                # compute endpoints cheaply\\n                self_first = self[0] if len(self) else None\\n                self_last = self[-1] if len(self) else None\\n                other_first = other[0] if len(other) else None\\n                other_last = other[-1] if len(other) else None\\n                if self_first is not None and other_first is not None:\\n                    # normalize for decreasing by swapping\\n                    if self.is_monotonic_decreasing:\\n                        self_first, self_last = self_last, self_first\\n                    if other.is_monotonic_decreasing:\\n                        other_first, other_last = other_last, other_first\\n                    if self_last < other_first or other_last < self_first:\\n                        # no overlap\\n                        res = self.copy(deep=False)\\n                        res.name = self.name\\n                        return res\\n        except Exception:\r\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ^\r\nSyntaxError: EOL while scanning string literal\r\n"]
[235.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[235.002, "i", "python - << 'PY'\r"]
[235.004, "o", "python - << 'PY'\r\n"]
[235.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> # Import pandas to ensure our change parses/loads\r\n\u001b[?2004l\r\n\u001b[?2004h> import pandas as pd\r\n\u001b[?2004l\r\n\u001b[?2004h> print('pandas version:', pd.__version__)\r\n\u001b[?2004l\r\n\u001b[?2004h> idx1 = pd.date_range('1970-01-01', periods=100000, freq='ns')\r\n\u001b[?2004l\r\n\u001b[?2004h> idx2 = pd.date_range('1970-01-01', periods=120000, freq='ns')[100000:]\r\n\u001b[?2004l\r\n\u001b[?2004h> res = idx1.difference(idx2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('len(res)=', len(res), 'expected', len(idx1))\r\n\u001b[?2004l\r\n\u001b[?2004h> print('is equal object values:', res.equals(idx1))\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\npandas version: 0+untagged.31331.g57c6533\r\nlen(res)= 100000 expected 100000\r\nis equal object values: True\r\n"]
[240.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[240.002, "i", "cd asv_bench\r"]
[240.004, "o", "cd asv_bench\r\n"]
[240.006, "o", "\u001b[?2004l\r\n"]
[245.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[245.002, "i", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r"]
[245.004, "o", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r\n"]
[245.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                                4.44\u00b10ms\r\n"]
[250.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[250.002, "i", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r"]
[250.004, "o", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r\n"]
[250.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (index_object.SetDisjoint.time_datetime_difference_disjoint--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                             2.15\u00b10.03ms\r\n\r\nWed Oct  1 19:12:20 2025    /tmp/tmpivuwq9j2\r\n\r\n         769 function calls (750 primitive calls) in 0.004 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.004    0.004 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.004    0.004 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.004    0.004 index_object.py:63(time_datetime_difference_disjoint)\r\n        1    0.000    0.000    0.004    0.004 base.py:3391(difference)\r\n        1    0.000    0.000    0.003    0.003 base.py:3446(_difference)\r\n        1    0.000    0.000    0.002    0.002 base.py:7143(_maybe_try_sort)\r\n        1    0.000    0.000    0.002    0.002 algorithms.py:1698(safe_sort)\r\n        1    0.000    0.000    0.001    0.001 base.py:656(argsort)\r\n        1    0.000    0.000    0.001    0.001 sorting.py:371(nargsort)\r\n        1    0.000    0.000    0.001    0.001 base.py:2849(unique)\r\n        1    0.001    0.001    0.001    0.001 base.py:2171(is_unique)\r\n        1    0.001    0.001    0.001    0.001 {method 'argsort' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 base.py:5750(get_indexer_for)\r\n        1    0.000    0.000    0.000    0.000 base.py:3657(get_indexer)\r\n        2    0.000    0.000    0.000    0.000 _mixins.py:155(take)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:1393(take)\r\n        3    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n      9/5    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(setdiff1d)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:939(setdiff1d)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:379(_maybe_cast_listlike_indexer)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\r\n        1    0.000    0.000    0.000    0.000 base.py:3744(_get_indexer)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:675(_validate_listlike)\r\n        1    0.000    0.000    0.000    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\r\n  144/134    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        2    0.000    0.000    0.000    0.000 base.py:6003(_should_compare)\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:115(equals)\r\n        1    0.000    0.000    0.000    0.000 construction.py:73(array)\r\n       53    0.000    0.000    0.000    0.000 generic.py:42(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 base.py:437(__new__)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(concatenate)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_dtype}\r\n        4    0.000    0.000    0.000    0.000 common.py:1256(is_bool_dtype)\r\n  103/100    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:823(isna)\r\n       34    0.000    0.000    0.000    0.000 extension.py:70(fget)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(in1d)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:826(_isnan)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:524(in1d)\r\n        6    0.000    0.000    0.000    0.000 common.py:456(is_categorical_dtype)\r\n        3    0.000    0.000    0.000    0.000 base.py:611(_simple_new)\r\n       16    0.000    0.000    0.000    0.000 common.py:1469(get_dtype)\r\n        7    0.000    0.000    0.000    0.000 base.py:286(is_dtype)\r\n       53    0.000    0.000    0.000    0.000 generic.py:37(_check)\r\n        1    0.000    0.000    0.000    0.000 base.py:726(_view)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:543(copy)\r\n        5    0.000    0.000    0.000    0.000 construction.py:399(extract_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:786(_engine)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:344(_name_get)\r\n        1    0.000    0.000    0.000    0.000 base.py:3789(_check_indexing_method)\r\n        1    0.000    0.000    0.000    0.000 construction.py:497(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 common.py:87(get_op_result_name)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(ones_like)\r\n        1    0.000    0.000    0.000    0.000 base.py:3465(_wrap_difference_result)\r\n        1    0.000    0.000    0.000    0.000 base.py:3236(_wrap_setop_result)\r\n        1    0.000    0.000    0.000    0.000 {function DatetimeLikeArrayMixin.copy at 0x7f0d8e1beca0}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:219(ones_like)\r\n        6    0.000    0.000    0.000    0.000 common.py:545(is_dtype_equal)\r\n        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(array_equal)\r\n        1    0.000    0.000    0.000    0.000 base.py:3555(_convert_can_do_setop)\r\n        2    0.000    0.000    0.000    0.000 base.py:7120(unpack_nested_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:5923(_maybe_promote)\r\n        5    0.000    0.000    0.000    0.000 datetimelike.py:307(asi8)\r\n        4    0.000    0.000    0.000    0.000 datetimelike.py:105(asi8)\r\n       24    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        4    0.000    0.000    0.000    0.000 common.py:157(is_object_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:3549(_assert_can_do_setop)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(nonzero)\r\n        2    0.000    0.000    0.000    0.000 datetimes.py:371(_is_comparable_dtype)\r\n        2    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:1892(nonzero)\r\n        7    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n       50    0.000    0.000    0.000    0.000 datetimes.py:532(dtype)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(copyto)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:51(_wrapfunc)\r\n        2    0.000    0.000    0.000    0.000 common.py:109(_maybe_match_name)\r\n        4    0.000    0.000    0.000    0.000 common.py:1504(_is_dtype_type)\r\n        1    0.000    0.000    0.000    0.000 common.py:418(is_interval_dtype)\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:599(__array__)\r\n        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\r\n        6    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\r\n        6    0.000    0.000    0.000    0.000 common.py:1663(pandas_dtype)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:330(_name_includes_bit_suffix)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:1250(is_dtype)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:557(tz)\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:635(astype)\r\n        1    0.000    0.000    0.000    0.000 numerictypes.py:356(issubdtype)\r\n        3    0.000    0.000    0.000    0.000 inference.py:185(is_array_like)\r\n        1    0.000    0.000    0.000    0.000 base.py:709(_shallow_copy)\r\n        2    0.000    0.000    0.000    0.000 numeric.py:2407(array_equal)\r\n        1    0.000    0.000    0.000    0.000 base.py:7085(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(empty_like)\r\n        2    0.000    0.000    0.000    0.000 common.py:1346(is_extension_array_dtype)\r\n        4    0.000    0.000    0.000    0.000 common.py:143(<lambda>)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:342(__array__)\r\n        2    0.000    0.000    0.000    0.000 base.py:2624(_is_multi)\r\n        1    0.000    0.000    0.000    0.000 base.py:547(_dtype_to_subclass)\r\n        1    0.000    0.000    0.000    0.000 function.py:150(validate_argsort_with_ascending)\r\n      6/4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 common.py:1713(is_all_strings)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:178(_datetime_metadata_str)\r\n        2    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:673(_get_engine_target)\r\n       10    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:282(issubclass_)\r\n        3    0.000    0.000    0.000    0.000 base.py:775(_reset_identity)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        2    0.000    0.000    0.000    0.000 {method '_from_backing_data' of 'pandas._libs.arrays.NDArrayBacked' objects}\r\n        2    0.000    0.000    0.000    0.000 base.py:744(is_)\r\n       10    0.000    0.000    0.000    0.000 base.py:1542(name)\r\n        1    0.000    0.000    0.000    0.000 inference.py:322(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 base.py:838(__len__)\r\n        3    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\r\n        2    0.000    0.000    0.000    0.000 common.py:273(is_datetime64_dtype)\r\n        1    0.000    0.000    0.000    0.000 construction.py:647(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 missing.py:940(clean_reindex_fill_method)\r\n        1    0.000    0.000    0.000    0.000 base.py:352(size)\r\n        3    0.000    0.000    0.000    0.000 arraysetops.py:630(<genexpr>)\r\n        1    0.000    0.000    0.000    0.000 common.py:1128(needs_i8_conversion)\r\n        4    0.000    0.000    0.000    0.000 common.py:141(classes)\r\n        4    0.000    0.000    0.000    0.000 base.py:4872(_values)\r\n        1    0.000    0.000    0.000    0.000 common.py:861(is_datetime64_any_dtype)\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:248(_engine_type)\r\n        1    0.000    0.000    0.000    0.000 common.py:1400(is_ea_or_datetimelike_dtype)\r\n        3    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55717800b680}\r\n        2    0.000    0.000    0.000    0.000 base.py:5911(_index_as_unique)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:688(inferred_type)\r\n        1    0.000    0.000    0.000    0.000 missing.py:120(clean_fill_method)\r\n        1    0.000    0.000    0.000    0.000 construction.py:461(ensure_wrapped_if_datetimelike)\r\n        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.datetime_data}\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:1863(freq)\r\n        1    0.000    0.000    0.000    0.000 function.py:59(__call__)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:935(_setdiff1d_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\r\n        2    0.000    0.000    0.000    0.000 numeric.py:2403(_array_equal_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 _mixins.py:189(_values_for_argsort)\r\n        1    0.000    0.000    0.000    0.000 base.py:3019(_validate_sort_keyword)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\r\n        1    0.000    0.000    0.000    0.000 base.py:533(_ensure_array)\r\n        2    0.000    0.000    0.000    0.000 base.py:319(ndim)\r\n        1    0.000    0.000    0.000    0.000 typing.py:1149(cast)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:215(_ones_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 construction.py:706(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:152(concatenate)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:519(_in1d_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:1888(_nonzero_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1079(copyto)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:84(empty_like)\r\n\r\n\r\n"]
[255.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[255.002, "i", "grep -Rsn \"def difference\\s*\\(\" pandas/core/indexes | sed -n '1,200p'\r"]
[255.004, "o", "grep -Rsn \"def difference\\s*\\(\" pandas/core/indexes | sed -n '1,200p'\r\n"]
[255.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[260.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[260.002, "i", "sed -n '1,400p' pandas/core/indexes/base.py\r"]
[260.004, "o", "sed -n '1,400p' pandas/core/indexes/base.py\r\n"]
[260.006, "o", "\u001b[?2004l\r\nsed: can't read pandas/core/indexes/base.py: No such file or directory\r\n"]
[265.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[265.002, "i", "grep -n \"def difference\\s*(\" pandas/core/indexes/base.py\r"]
[265.004, "o", "grep -n \"def difference\\s*(\" pandas/core/indexes/base.py\r\n"]
[265.006, "o", "\u001b[?2004l\r\ngrep: pandas/core/indexes/base.py: No such file or directory\r\n"]
[270.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[270.002, "i", "sed -n '400,900p' pandas/core/indexes/base.py\r"]
[270.004, "o", "sed -n '400,900p' pandas/core/indexes/base.py\r\n"]
[270.006, "o", "\u001b[?2004l\r\nsed: can't read pandas/core/indexes/base.py: No such file or directory\r\n"]
[275.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[275.002, "i", "grep -n \"class DatetimeIndex|def difference\\s*(\" pandas/core/indexes/datetimes.py\r"]
[275.004, "o", "grep -n \"class DatetimeIndex|def difference\\s*(\" pandas/core/indexes/datetimes.py\r\n"]
[275.006, "o", "\u001b[?2004l\r\ngrep: pandas/core/indexes/datetimes.py: No such file or directory\r\n"]
[280.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[280.002, "i", "sed -n '1,260p' pandas/core/indexes/datetimes.py\r"]
[280.004, "o", "sed -n '1,260p' pandas/core/indexes/datetimes.py\r\n"]
[280.006, "o", "\u001b[?2004l\r\nsed: can't read pandas/core/indexes/datetimes.py: No such file or directory\r\n"]
[285.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[285.002, "i", "git checkout -b opt-fastpath-difference\r"]
[285.004, "o", "git checkout -b opt-fastpath-difference\r\n"]
[285.006, "o", "\u001b[?2004l\r\nfatal: a branch named 'opt-fastpath-difference' already exists\r\n"]
[290.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[290.002, "i", "python - << 'PY'\r"]
[290.004, "o", "python - << 'PY'\r\n"]
[290.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/indexes/base.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> m = re.search(r\"def difference\\(self, other, sort=None\\):\", s)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('difference method not found in base.Index; abort patch')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     start = m.start()\r\n\u001b[?2004l\r\n\u001b[?2004h>     # find end of method (next def at column 4)\r\n\u001b[?2004l\r\n\u001b[?2004h>     rest = s[start:]\r\n\u001b[?2004l\r\n\u001b[?2004h>     lines = rest.splitlines(keepends=True)\r\n\u001b[?2004l\r\n\u001b[?2004h>     end_offset = None\r\n\u001b[?2004l\r\n\u001b[?2004h>     for i, line in enumerate(lines[1:], start=1):\r\n\u001b[?2004l\r\n\u001b[?2004h>         if line.startswith('    def ') and not line.startswith('        '):\r\n\u001b[?2004l\r\n\u001b[?2004h>             end_offset = sum(len(l) for l in lines[:i])\r\n\u001b[?2004l\r\n\u001b[?2004h>             break\r\n\u001b[?2004l\r\n\u001b[?2004h>     if end_offset is None:\r\n\u001b[?2004l\r\n\u001b[?2004h>         end = len(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         end = start + end_offset\r\n\u001b[?2004l\r\n\u001b[?2004h>     body = s[start:end]\r\n\u001b[?2004l\r\n\u001b[?2004h>     if 'fastpath_disjoint' in body:\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('Fastpath already present')\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         # Insert fastpath after docstring or at start of method body\r\n\u001b[?2004l\r\n\u001b[?2004h>         insert_at = body.find('\\n        \\n')\r\n\u001b[?2004l\r\n\u001b[?2004h>         if insert_at == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>             insert_at = body.find('\\n')\r\n\u001b[?2004l\r\n\u001b[?2004h>         fast = \"\\n        # fastpath_disjoint: if both indexes are monotonic and non-overlapping by bounds,\\n        # return self unchanged. This avoids expen\r\nnsive set operations in common cases.\\n        try:\\n            oth = other\\n            # Accept Index-like or array-like other\r\n\u001b[?2004l\r\n\u001b[?2004h>             # Quickly bail if lengths are zero\r\n\u001b[?2004l\r\n\u001b[?2004h>             if len(self) == 0:\r\n\u001b[?2004l\r\n\u001b[?2004h>                 return self.copy(deep=False)\\n            if hasattr(oth, 'dtype') and getattr(oth, 'ndim', 1) != 1:\r\n\u001b[?2004l\r\n\u001b[?2004h>                 oth = oth.ravel()\\n            # Ensure other is an Index for monotonic checks; otherwise, skip fastpath\r\n\u001b[?2004l\r\n\u001b[?2004h>             if not hasattr(oth, 'is_monotonic_increasing'):\r\n\u001b[?2004l\r\n\u001b[?2004h>                 pass\r\n\u001b[?2004l\r\n\u001b[?2004h>             else:\\n                if (self.is_monotonic_increasing or self.is_monotonic_decreasing) and \\\r\n\u001b[?2004l\r\n\u001b[?2004h>                    (oth.is_monotonic_increasing or oth.is_monotonic_decreasing) and len(oth) > 0:\r\n\u001b[?2004l\r\n\u001b[?2004h>                     # Determine first/last for each, normalize for decreasing\r\n\u001b[?2004l\r\n\u001b[?2004h>                     s_first, s_last = self[0], self[-1]\r\n\u001b[?2004l\r\n\u001b[?2004h>                     o_first, o_last = oth[0], oth[-1]\r\n\u001b[?2004l\r\n\u001b[?2004h>                     if self.is_monotonic_decreasing:\r\n\u001b[?2004l\r\n\u001b[?2004h>                         s_first, s_last = s_last, s_first\r\n\u001b[?2004l\r\n\u001b[?2004h>                     if oth.is_monotonic_decreasing:\r\n\u001b[?2004l\r\n\u001b[?2004h>                         o_first, o_last = o_last, o_first\r\n\u001b[?2004l\r\n\u001b[?2004h>                     # If ranges do not overlap, difference is self\r\n\u001b[?2004l\r\n\u001b[?2004h>                     if s_last < o_first or o_last < s_first:\r\n\u001b[?2004l\r\n\u001b[?2004h>                         res = self.copy(deep=False)\r\n\u001b[?2004l\r\n\u001b[?2004h>                         res.name = self.name\r\n\u001b[?2004l\r\n\u001b[?2004h>                         return res\\n        except Exception:\r\n\u001b[?2004l\r\n\u001b[?2004h>             # If any issue (e.g., incomparable types), fall back to normal path\r\n\u001b[?2004l\r\n\u001b[?2004h>             pass\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_body = body[:insert_at] + fast + body[insert_at:]\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_s = s[:start] + new_body + s[end:]\r\n\u001b[?2004l\r\n\u001b[?2004h>         p.write_text(new_s)\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('Patched base.Index.difference with fastpath_disjoint')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n  File \"<stdin>\", line 30\r\n    fast = \"\\n        # fastpath_disjoint: if both indexes are monotonic and non-overlapping by bounds,\\n        # return self unchanged. This avoids expensive set operations in common cases.\\n        try:\\n            oth = other\\n            # Accept Index-like or array-like other\r\n                                                                                                                                                                                                                                                                                          ^\r\nSyntaxError: EOL while scanning string literal\r\n"]
[295.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[295.002, "i", "python - << 'PY'\r"]
[295.004, "o", "python - << 'PY'\r\n"]
[295.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import pandas as pd\r\n\u001b[?2004l\r\n\u001b[?2004h> print('pandas imported; version:', pd.__version__)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Quick correctness checks\r\n\u001b[?2004l\r\n\u001b[?2004h> left = pd.DatetimeIndex(range(10))\r\n\u001b[?2004l\r\n\u001b[?2004h> right = pd.DatetimeIndex(range(10, 20))\r\n\u001b[?2004l\r\n\u001b[?2004h> res = left.difference(right)\r\n\u001b[?2004l\r\n\u001b[?2004h> assert res.equals(left), 'disjoint monotonic should return self'\r\n\u001b[?2004l\r\n\u001b[?2004h> # Overlapping case should still work\r\n\u001b[?2004l\r\n\u001b[?2004h> right2 = pd.DatetimeIndex(range(5, 15))\r\n\u001b[?2004l\r\n\u001b[?2004h> res2 = left.difference(right2)\r\n\u001b[?2004l\r\n\u001b[?2004h> assert len(res2) == 5 and res2[0] == left[0], 'overlap case should compute correctly'\r\n\u001b[?2004l\r\n\u001b[?2004h> print('basic checks passed; len(res2)=', len(res2))\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\npandas imported; version: 0+untagged.31331.g57c6533\r\nbasic checks passed; len(res2)= 5\r\n"]
[300.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[300.002, "i", "cd asv_bench\r"]
[300.004, "o", "cd asv_bench\r\n"]
[300.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[305.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[305.002, "i", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r"]
[305.004, "o", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r\n"]
[305.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                                4.57\u00b10ms\r\n"]
[310.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[310.002, "i", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r"]
[310.004, "o", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r\n"]
[310.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (index_object.SetDisjoint.time_datetime_difference_disjoint--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                             2.10\u00b10.01ms\r\n\r\nWed Oct  1 19:15:25 2025    /tmp/tmp78b2ka28\r\n\r\n         769 function calls (750 primitive calls) in 0.003 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.003    0.003 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.003    0.003 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.003    0.003 index_object.py:63(time_datetime_difference_disjoint)\r\n        1    0.000    0.000    0.003    0.003 base.py:3391(difference)\r\n        1    0.000    0.000    0.003    0.003 base.py:3446(_difference)\r\n        1    0.000    0.000    0.002    0.002 base.py:7143(_maybe_try_sort)\r\n        1    0.000    0.000    0.002    0.002 algorithms.py:1698(safe_sort)\r\n        1    0.000    0.000    0.001    0.001 base.py:656(argsort)\r\n        1    0.000    0.000    0.001    0.001 sorting.py:371(nargsort)\r\n        1    0.001    0.001    0.001    0.001 {method 'argsort' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.001    0.001 base.py:2849(unique)\r\n        1    0.001    0.001    0.001    0.001 base.py:2171(is_unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:5750(get_indexer_for)\r\n        1    0.000    0.000    0.000    0.000 base.py:3657(get_indexer)\r\n        2    0.000    0.000    0.000    0.000 _mixins.py:155(take)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:1393(take)\r\n        3    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n      9/5    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(setdiff1d)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:379(_maybe_cast_listlike_indexer)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:939(setdiff1d)\r\n  144/134    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 base.py:3744(_get_indexer)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\r\n        1    0.000    0.000    0.000    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\r\n        2    0.000    0.000    0.000    0.000 base.py:6003(_should_compare)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:675(_validate_listlike)\r\n       53    0.000    0.000    0.000    0.000 generic.py:42(_instancecheck)\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:115(equals)\r\n        6    0.000    0.000    0.000    0.000 common.py:456(is_categorical_dtype)\r\n        7    0.000    0.000    0.000    0.000 base.py:286(is_dtype)\r\n        1    0.000    0.000    0.000    0.000 construction.py:73(array)\r\n        4    0.000    0.000    0.000    0.000 common.py:1256(is_bool_dtype)\r\n       53    0.000    0.000    0.000    0.000 generic.py:37(_check)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(concatenate)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_dtype}\r\n        1    0.000    0.000    0.000    0.000 base.py:437(__new__)\r\n        1    0.000    0.000    0.000    0.000 base.py:3789(_check_indexing_method)\r\n  103/100    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n       16    0.000    0.000    0.000    0.000 common.py:1469(get_dtype)\r\n       34    0.000    0.000    0.000    0.000 extension.py:70(fget)\r\n        3    0.000    0.000    0.000    0.000 base.py:611(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:823(isna)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:826(_isnan)\r\n        1    0.000    0.000    0.000    0.000 base.py:726(_view)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(in1d)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:524(in1d)\r\n        5    0.000    0.000    0.000    0.000 construction.py:399(extract_array)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:543(copy)\r\n        2    0.000    0.000    0.000    0.000 common.py:87(get_op_result_name)\r\n        1    0.000    0.000    0.000    0.000 base.py:786(_engine)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:344(_name_get)\r\n        1    0.000    0.000    0.000    0.000 construction.py:497(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 base.py:7120(unpack_nested_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:3465(_wrap_difference_result)\r\n        6    0.000    0.000    0.000    0.000 common.py:545(is_dtype_equal)\r\n       24    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(ones_like)\r\n        1    0.000    0.000    0.000    0.000 base.py:3236(_wrap_setop_result)\r\n        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(array_equal)\r\n        4    0.000    0.000    0.000    0.000 datetimelike.py:105(asi8)\r\n        5    0.000    0.000    0.000    0.000 datetimelike.py:307(asi8)\r\n        4    0.000    0.000    0.000    0.000 common.py:157(is_object_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:3555(_convert_can_do_setop)\r\n        1    0.000    0.000    0.000    0.000 base.py:5923(_maybe_promote)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:219(ones_like)\r\n        1    0.000    0.000    0.000    0.000 base.py:3549(_assert_can_do_setop)\r\n        1    0.000    0.000    0.000    0.000 {function DatetimeLikeArrayMixin.copy at 0x7f74a4f53ca0}\r\n        2    0.000    0.000    0.000    0.000 datetimes.py:371(_is_comparable_dtype)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(nonzero)\r\n        7    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n       50    0.000    0.000    0.000    0.000 datetimes.py:532(dtype)\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:599(__array__)\r\n        2    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:1892(nonzero)\r\n        4    0.000    0.000    0.000    0.000 common.py:1504(_is_dtype_type)\r\n        1    0.000    0.000    0.000    0.000 common.py:418(is_interval_dtype)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:51(_wrapfunc)\r\n        6    0.000    0.000    0.000    0.000 common.py:1663(pandas_dtype)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(copyto)\r\n        2    0.000    0.000    0.000    0.000 common.py:109(_maybe_match_name)\r\n        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:1250(is_dtype)\r\n        6    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:330(_name_includes_bit_suffix)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:557(tz)\r\n        3    0.000    0.000    0.000    0.000 inference.py:185(is_array_like)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:342(__array__)\r\n      6/4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        1    0.000    0.000    0.000    0.000 numerictypes.py:356(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 common.py:1346(is_extension_array_dtype)\r\n        2    0.000    0.000    0.000    0.000 numeric.py:2407(array_equal)\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:635(astype)\r\n        1    0.000    0.000    0.000    0.000 base.py:709(_shallow_copy)\r\n        1    0.000    0.000    0.000    0.000 base.py:7085(maybe_extract_name)\r\n        4    0.000    0.000    0.000    0.000 common.py:143(<lambda>)\r\n        2    0.000    0.000    0.000    0.000 base.py:2624(_is_multi)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:178(_datetime_metadata_str)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(empty_like)\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:673(_get_engine_target)\r\n        1    0.000    0.000    0.000    0.000 function.py:150(validate_argsort_with_ascending)\r\n        1    0.000    0.000    0.000    0.000 base.py:547(_dtype_to_subclass)\r\n        1    0.000    0.000    0.000    0.000 common.py:1713(is_all_strings)\r\n       10    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:282(issubclass_)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 {method '_from_backing_data' of 'pandas._libs.arrays.NDArrayBacked' objects}\r\n        2    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\r\n        2    0.000    0.000    0.000    0.000 base.py:838(__len__)\r\n        3    0.000    0.000    0.000    0.000 base.py:775(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 common.py:273(is_datetime64_dtype)\r\n       10    0.000    0.000    0.000    0.000 base.py:1542(name)\r\n        2    0.000    0.000    0.000    0.000 base.py:744(is_)\r\n        1    0.000    0.000    0.000    0.000 common.py:1128(needs_i8_conversion)\r\n        1    0.000    0.000    0.000    0.000 inference.py:322(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 construction.py:647(_sanitize_ndim)\r\n        1    0.000    0.000    0.000    0.000 base.py:352(size)\r\n        3    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 missing.py:940(clean_reindex_fill_method)\r\n        3    0.000    0.000    0.000    0.000 arraysetops.py:630(<genexpr>)\r\n        4    0.000    0.000    0.000    0.000 common.py:141(classes)\r\n        4    0.000    0.000    0.000    0.000 base.py:4872(_values)\r\n        3    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x5636c3564680}\r\n        1    0.000    0.000    0.000    0.000 common.py:1400(is_ea_or_datetimelike_dtype)\r\n        1    0.000    0.000    0.000    0.000 common.py:861(is_datetime64_any_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:5911(_index_as_unique)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:688(inferred_type)\r\n        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.datetime_data}\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:248(_engine_type)\r\n        1    0.000    0.000    0.000    0.000 construction.py:461(ensure_wrapped_if_datetimelike)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\r\n        1    0.000    0.000    0.000    0.000 missing.py:120(clean_fill_method)\r\n        1    0.000    0.000    0.000    0.000 function.py:59(__call__)\r\n        2    0.000    0.000    0.000    0.000 numeric.py:2403(_array_equal_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 base.py:533(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:3019(_validate_sort_keyword)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:1863(freq)\r\n        2    0.000    0.000    0.000    0.000 base.py:319(ndim)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\r\n        1    0.000    0.000    0.000    0.000 _mixins.py:189(_values_for_argsort)\r\n        1    0.000    0.000    0.000    0.000 typing.py:1149(cast)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:215(_ones_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:1888(_nonzero_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:935(_setdiff1d_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 construction.py:706(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:152(concatenate)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1079(copyto)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:84(empty_like)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:519(_in1d_dispatcher)\r\n\r\n\r\n"]
[315.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[315.002, "i", "cd ..\r"]
[315.004, "o", "cd ..\r\n"]
[315.006, "o", "\u001b[?2004l\r\n"]
[320.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[320.002, "i", "git status -s\r"]
[320.004, "o", "git status -s\r\n"]
[320.006, "o", "\u001b[?2004l\r\n"]
[325.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[325.002, "i", "grep -Rsn \"def difference\\s*\\(\" pandas/core/indexes | sed -n '1,200p'\r"]
[325.004, "o", "grep -Rsn \"def difference\\s*\\(\" pandas/core/indexes | sed -n '1,200p'\r\n"]
[325.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[330.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[330.002, "i", "grep -n \"def difference\\s*(\" pandas/core/indexes/base.py || true\r"]
[330.004, "o", "grep -n \"def difference\\s*(\" pandas/core/indexes/base.py || true\r\n"]
[330.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K3392\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef difference(\u001b[m\u001b[Kself, other, sort=None):\r\n"]
[335.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[335.002, "i", "sed -n '1,240p' pandas/core/indexes/base.py | sed -n '1,240p'\r"]
[335.004, "o", "sed -n '1,240p' pandas/core/indexes/base.py | sed -n '1,240p'\r\n"]
[335.006, "o", "\u001b[?2004l\r\nfrom __future__ import annotations\r\n\r\nfrom datetime import datetime\r\nimport functools\r\nfrom itertools import zip_longest\r\nimport operator\r\nfrom typing import (\r\n    TYPE_CHECKING,\r\n    Any,\r\n    Callable,\r\n    ClassVar,\r\n    Hashable,\r\n    Iterable,\r\n    Literal,\r\n    NoReturn,\r\n    Sequence,\r\n    TypeVar,\r\n    cast,\r\n    final,\r\n    overload,\r\n)\r\nimport warnings\r\n\r\nimport numpy as np\r\n\r\nfrom pandas._config import get_option\r\n\r\nfrom pandas._libs import (\r\n    NaT,\r\n    algos as libalgos,\r\n    index as libindex,\r\n    lib,\r\n)\r\nimport pandas._libs.join as libjoin\r\nfrom pandas._libs.lib import (\r\n    is_datetime_array,\r\n    no_default,\r\n)\r\nfrom pandas._libs.missing import is_float_nan\r\nfrom pandas._libs.tslibs import (\r\n    IncompatibleFrequency,\r\n    OutOfBoundsDatetime,\r\n    Timestamp,\r\n    tz_compare,\r\n)\r\nfrom pandas._typing import (\r\n    AnyAll,\r\n    ArrayLike,\r\n    Axes,\r\n    Axis,\r\n    DropKeep,\r\n    DtypeObj,\r\n    F,\r\n    IgnoreRaise,\r\n    IndexLabel,\r\n    JoinHow,\r\n    Level,\r\n    Shape,\r\n    npt,\r\n)\r\nfrom pandas.compat.numpy import function as nv\r\nfrom pandas.errors import (\r\n    DuplicateLabelError,\r\n    InvalidIndexError,\r\n)\r\nfrom pandas.util._decorators import (\r\n    Appender,\r\n    cache_readonly,\r\n    doc,\r\n)\r\nfrom pandas.util._exceptions import (\r\n    find_stack_level,\r\n    rewrite_exception,\r\n)\r\n\r\nfrom pandas.core.dtypes.astype import astype_array\r\nfrom pandas.core.dtypes.cast import (\r\n    LossySetitemError,\r\n    can_hold_element,\r\n    common_dtype_categorical_compat,\r\n    ensure_dtype_can_hold_na,\r\n    find_result_type,\r\n    infer_dtype_from,\r\n    maybe_cast_pointwise_result,\r\n    np_can_hold_element,\r\n)\r\nfrom pandas.core.dtypes.common import (\r\n    ensure_int64,\r\n    ensure_object,\r\n    ensure_platform_int,\r\n    is_bool_dtype,\r\n    is_categorical_dtype,\r\n    is_dtype_equal,\r\n    is_ea_or_datetimelike_dtype,\r\n    is_extension_array_dtype,\r\n    is_float,\r\n    is_float_dtype,\r\n    is_hashable,\r\n    is_integer,\r\n    is_integer_dtype,\r\n    is_interval_dtype,\r\n    is_iterator,\r\n    is_list_like,\r\n    is_numeric_dtype,\r\n    is_object_dtype,\r\n    is_scalar,\r\n    is_signed_integer_dtype,\r\n    is_string_dtype,\r\n    needs_i8_conversion,\r\n    pandas_dtype,\r\n    validate_all_hashable,\r\n)\r\nfrom pandas.core.dtypes.concat import concat_compat\r\nfrom pandas.core.dtypes.dtypes import (\r\n    CategoricalDtype,\r\n    DatetimeTZDtype,\r\n    ExtensionDtype,\r\n    IntervalDtype,\r\n    PeriodDtype,\r\n)\r\nfrom pandas.core.dtypes.generic import (\r\n    ABCDataFrame,\r\n    ABCDatetimeIndex,\r\n    ABCMultiIndex,\r\n    ABCPeriodIndex,\r\n    ABCSeries,\r\n    ABCTimedeltaIndex,\r\n)\r\nfrom pandas.core.dtypes.inference import is_dict_like\r\nfrom pandas.core.dtypes.missing import (\r\n    array_equivalent,\r\n    is_valid_na_for_dtype,\r\n    isna,\r\n)\r\n\r\nfrom pandas.core import (\r\n    arraylike,\r\n    ops,\r\n)\r\nfrom pandas.core.accessor import CachedAccessor\r\nimport pandas.core.algorithms as algos\r\nfrom pandas.core.array_algos.putmask import (\r\n    setitem_datetimelike_compat,\r\n    validate_putmask,\r\n)\r\nfrom pandas.core.arrays import (\r\n    BaseMaskedArray,\r\n    Categorical,\r\n    ExtensionArray,\r\n)\r\nfrom pandas.core.arrays.string_ import StringArray\r\nfrom pandas.core.base import (\r\n    IndexOpsMixin,\r\n    PandasObject,\r\n)\r\nimport pandas.core.common as com\r\nfrom pandas.core.construction import (\r\n    ensure_wrapped_if_datetimelike,\r\n    extract_array,\r\n    sanitize_array,\r\n)\r\nfrom pandas.core.indexers import disallow_ndim_indexing\r\nfrom pandas.core.indexes.frozen import FrozenList\r\nfrom pandas.core.missing import clean_reindex_fill_method\r\nfrom pandas.core.ops import get_op_result_name\r\nfrom pandas.core.ops.invalid import make_invalid_op\r\nfrom pandas.core.sorting import (\r\n    ensure_key_mapped,\r\n    get_group_index_sorter,\r\n    nargsort,\r\n)\r\nfrom pandas.core.strings import StringMethods\r\n\r\nfrom pandas.io.formats.printing import (\r\n    PrettyDict,\r\n    default_pprint,\r\n    format_object_summary,\r\n    pprint_thing,\r\n)\r\n\r\nif TYPE_CHECKING:\r\n    from pandas import (\r\n        CategoricalIndex,\r\n        DataFrame,\r\n        MultiIndex,\r\n        Series,\r\n    )\r\n    from pandas.core.arrays import PeriodArray\r\n\r\n\r\n__all__ = [\"Index\"]\r\n\r\n_unsortable_types = frozenset((\"mixed\", \"mixed-integer\"))\r\n\r\n_index_doc_kwargs: dict[str, str] = {\r\n    \"klass\": \"Index\",\r\n    \"inplace\": \"\",\r\n    \"target_klass\": \"Index\",\r\n    \"raises_section\": \"\",\r\n    \"unique\": \"Index\",\r\n    \"duplicated\": \"np.ndarray\",\r\n}\r\n_index_shared_docs: dict[str, str] = {}\r\nstr_t = str\r\n\r\n\r\n_dtype_obj = np.dtype(\"object\")\r\n\r\n_masked_engines = {\r\n    \"Complex128\": libindex.MaskedComplex128Engine,\r\n    \"Complex64\": libindex.MaskedComplex64Engine,\r\n    \"Float64\": libindex.MaskedFloat64Engine,\r\n    \"Float32\": libindex.MaskedFloat32Engine,\r\n    \"UInt64\": libindex.MaskedUInt64Engine,\r\n    \"UInt32\": libindex.MaskedUInt32Engine,\r\n    \"UInt16\": libindex.MaskedUInt16Engine,\r\n    \"UInt8\": libindex.MaskedUInt8Engine,\r\n    \"Int64\": libindex.MaskedInt64Engine,\r\n    \"Int32\": libindex.MaskedInt32Engine,\r\n    \"Int16\": libindex.MaskedInt16Engine,\r\n    \"Int8\": libindex.MaskedInt8Engine,\r\n    \"boolean\": libindex.MaskedBoolEngine,\r\n}\r\n\r\n\r\ndef _maybe_return_indexers(meth: F) -> F:\r\n    \"\"\"\r\n    Decorator to simplify 'return_indexers' checks in Index.join.\r\n    \"\"\"\r\n\r\n    @functools.wraps(meth)\r\n    def join(\r\n        self,\r\n        other: Index,\r\n        *,\r\n        how: JoinHow = \"left\",\r\n        level=None,\r\n        return_indexers: bool = False,\r\n        sort: bool = False,\r\n    ):\r\n"]
[340.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[340.002, "i", "sed -n '240,520p' pandas/core/indexes/base.py\r"]
[340.004, "o", "sed -n '240,520p' pandas/core/indexes/base.py\r\n"]
[340.006, "o", "\u001b[?2004l\r\n    ):\r\n        join_index, lidx, ridx = meth(self, other, how=how, level=level, sort=sort)\r\n        if not return_indexers:\r\n            return join_index\r\n\r\n        if lidx is not None:\r\n            lidx = ensure_platform_int(lidx)\r\n        if ridx is not None:\r\n            ridx = ensure_platform_int(ridx)\r\n        return join_index, lidx, ridx\r\n\r\n    return cast(F, join)\r\n\r\n\r\ndef _new_Index(cls, d):\r\n    \"\"\"\r\n    This is called upon unpickling, rather than the default which doesn't\r\n    have arguments and breaks __new__.\r\n    \"\"\"\r\n    # required for backward compat, because PI can't be instantiated with\r\n    # ordinals through __new__ GH #13277\r\n    if issubclass(cls, ABCPeriodIndex):\r\n        from pandas.core.indexes.period import _new_PeriodIndex\r\n\r\n        return _new_PeriodIndex(cls, **d)\r\n\r\n    if issubclass(cls, ABCMultiIndex):\r\n        if \"labels\" in d and \"codes\" not in d:\r\n            # GH#23752 \"labels\" kwarg has been replaced with \"codes\"\r\n            d[\"codes\"] = d.pop(\"labels\")\r\n\r\n        # Since this was a valid MultiIndex at pickle-time, we don't need to\r\n        #  check validty at un-pickle time.\r\n        d[\"verify_integrity\"] = False\r\n\r\n    elif \"dtype\" not in d and \"data\" in d:\r\n        # Prevent Index.__new__ from conducting inference;\r\n        #  \"data\" key not in RangeIndex\r\n        d[\"dtype\"] = d[\"data\"].dtype\r\n    return cls.__new__(cls, **d)\r\n\r\n\r\n_IndexT = TypeVar(\"_IndexT\", bound=\"Index\")\r\n\r\n\r\nclass Index(IndexOpsMixin, PandasObject):\r\n    \"\"\"\r\n    Immutable sequence used for indexing and alignment.\r\n\r\n    The basic object storing axis labels for all pandas objects.\r\n\r\n    Parameters\r\n    ----------\r\n    data : array-like (1-dimensional)\r\n    dtype : NumPy dtype (default: object)\r\n        If dtype is None, we find the dtype that best fits the data.\r\n        If an actual dtype is provided, we coerce to that dtype if it's safe.\r\n        Otherwise, an error will be raised.\r\n    copy : bool\r\n        Make a copy of input ndarray.\r\n    name : object\r\n        Name to be stored in the index.\r\n    tupleize_cols : bool (default: True)\r\n        When True, attempt to create a MultiIndex if possible.\r\n\r\n    See Also\r\n    --------\r\n    RangeIndex : Index implementing a monotonic integer range.\r\n    CategoricalIndex : Index of :class:`Categorical` s.\r\n    MultiIndex : A multi-level, or hierarchical Index.\r\n    IntervalIndex : An Index of :class:`Interval` s.\r\n    DatetimeIndex : Index of datetime64 data.\r\n    TimedeltaIndex : Index of timedelta64 data.\r\n    PeriodIndex : Index of Period data.\r\n    NumericIndex : Index of numpy int/uint/float data.\r\n\r\n    Notes\r\n    -----\r\n    An Index instance can **only** contain hashable objects\r\n\r\n    Examples\r\n    --------\r\n    >>> pd.Index([1, 2, 3])\r\n    NumericIndex([1, 2, 3], dtype='int64')\r\n\r\n    >>> pd.Index(list('abc'))\r\n    Index(['a', 'b', 'c'], dtype='object')\r\n    \"\"\"\r\n\r\n    # To hand over control to subclasses\r\n    _join_precedence = 1\r\n\r\n    # Cython methods; see github.com/cython/cython/issues/2647\r\n    #  for why we need to wrap these instead of making them class attributes\r\n    # Moreover, cython will choose the appropriate-dtyped sub-function\r\n    #  given the dtypes of the passed arguments\r\n\r\n    @final\r\n    def _left_indexer_unique(self: _IndexT, other: _IndexT) -> npt.NDArray[np.intp]:\r\n        # Caller is responsible for ensuring other.dtype == self.dtype\r\n        sv = self._get_join_target()\r\n        ov = other._get_join_target()\r\n        # can_use_libjoin assures sv and ov are ndarrays\r\n        sv = cast(np.ndarray, sv)\r\n        ov = cast(np.ndarray, ov)\r\n        return libjoin.left_join_indexer_unique(sv, ov)\r\n\r\n    @final\r\n    def _left_indexer(\r\n        self: _IndexT, other: _IndexT\r\n    ) -> tuple[ArrayLike, npt.NDArray[np.intp], npt.NDArray[np.intp]]:\r\n        # Caller is responsible for ensuring other.dtype == self.dtype\r\n        sv = self._get_join_target()\r\n        ov = other._get_join_target()\r\n        # can_use_libjoin assures sv and ov are ndarrays\r\n        sv = cast(np.ndarray, sv)\r\n        ov = cast(np.ndarray, ov)\r\n        joined_ndarray, lidx, ridx = libjoin.left_join_indexer(sv, ov)\r\n        joined = self._from_join_target(joined_ndarray)\r\n        return joined, lidx, ridx\r\n\r\n    @final\r\n    def _inner_indexer(\r\n        self: _IndexT, other: _IndexT\r\n    ) -> tuple[ArrayLike, npt.NDArray[np.intp], npt.NDArray[np.intp]]:\r\n        # Caller is responsible for ensuring other.dtype == self.dtype\r\n        sv = self._get_join_target()\r\n        ov = other._get_join_target()\r\n        # can_use_libjoin assures sv and ov are ndarrays\r\n        sv = cast(np.ndarray, sv)\r\n        ov = cast(np.ndarray, ov)\r\n        joined_ndarray, lidx, ridx = libjoin.inner_join_indexer(sv, ov)\r\n        joined = self._from_join_target(joined_ndarray)\r\n        return joined, lidx, ridx\r\n\r\n    @final\r\n    def _outer_indexer(\r\n        self: _IndexT, other: _IndexT\r\n    ) -> tuple[ArrayLike, npt.NDArray[np.intp], npt.NDArray[np.intp]]:\r\n        # Caller is responsible for ensuring other.dtype == self.dtype\r\n        sv = self._get_join_target()\r\n        ov = other._get_join_target()\r\n        # can_use_libjoin assures sv and ov are ndarrays\r\n        sv = cast(np.ndarray, sv)\r\n        ov = cast(np.ndarray, ov)\r\n        joined_ndarray, lidx, ridx = libjoin.outer_join_indexer(sv, ov)\r\n        joined = self._from_join_target(joined_ndarray)\r\n        return joined, lidx, ridx\r\n\r\n    _typ: str = \"index\"\r\n    _data: ExtensionArray | np.ndarray\r\n    _data_cls: type[ExtensionArray] | tuple[type[np.ndarray], type[ExtensionArray]] = (\r\n        np.ndarray,\r\n        ExtensionArray,\r\n    )\r\n    _id: object | None = None\r\n    _name: Hashable = None\r\n    # MultiIndex.levels previously allowed setting the index name. We\r\n    # don't allow this anymore, and raise if it happens rather than\r\n    # failing silently.\r\n    _no_setting_name: bool = False\r\n    _comparables: list[str] = [\"name\"]\r\n    _attributes: list[str] = [\"name\"]\r\n    _can_hold_strings: bool = True\r\n\r\n    _engine_types: dict[np.dtype | ExtensionDtype, type[libindex.IndexEngine]] = {\r\n        np.dtype(np.int8): libindex.Int8Engine,\r\n        np.dtype(np.int16): libindex.Int16Engine,\r\n        np.dtype(np.int32): libindex.Int32Engine,\r\n        np.dtype(np.int64): libindex.Int64Engine,\r\n        np.dtype(np.uint8): libindex.UInt8Engine,\r\n        np.dtype(np.uint16): libindex.UInt16Engine,\r\n        np.dtype(np.uint32): libindex.UInt32Engine,\r\n        np.dtype(np.uint64): libindex.UInt64Engine,\r\n        np.dtype(np.float32): libindex.Float32Engine,\r\n        np.dtype(np.float64): libindex.Float64Engine,\r\n        np.dtype(np.complex64): libindex.Complex64Engine,\r\n        np.dtype(np.complex128): libindex.Complex128Engine,\r\n    }\r\n\r\n    @property\r\n    def _engine_type(\r\n        self,\r\n    ) -> type[libindex.IndexEngine] | type[libindex.ExtensionEngine]:\r\n        return self._engine_types.get(self.dtype, libindex.ObjectEngine)\r\n\r\n    # whether we support partial string indexing. Overridden\r\n    # in DatetimeIndex and PeriodIndex\r\n    _supports_partial_string_indexing = False\r\n\r\n    _accessors = {\"str\"}\r\n\r\n    str = CachedAccessor(\"str\", StringMethods)\r\n\r\n    # --------------------------------------------------------------------\r\n    # Constructors\r\n\r\n    def __new__(\r\n        cls,\r\n        data=None,\r\n        dtype=None,\r\n        copy: bool = False,\r\n        name=None,\r\n        tupleize_cols: bool = True,\r\n    ) -> Index:\r\n\r\n        from pandas.core.indexes.range import RangeIndex\r\n\r\n        name = maybe_extract_name(name, data, cls)\r\n\r\n        if dtype is not None:\r\n            dtype = pandas_dtype(dtype)\r\n\r\n        data_dtype = getattr(data, \"dtype\", None)\r\n\r\n        # range\r\n        if isinstance(data, (range, RangeIndex)):\r\n            result = RangeIndex(start=data, copy=copy, name=name)\r\n            if dtype is not None:\r\n                return result.astype(dtype, copy=False)\r\n            return result\r\n\r\n        elif is_ea_or_datetimelike_dtype(dtype):\r\n            # non-EA dtype indexes have special casting logic, so we punt here\r\n            pass\r\n\r\n        elif is_ea_or_datetimelike_dtype(data_dtype):\r\n            pass\r\n\r\n        elif isinstance(data, (np.ndarray, Index, ABCSeries)):\r\n\r\n            if isinstance(data, ABCMultiIndex):\r\n                data = data._values\r\n\r\n            if data.dtype.kind not in [\"i\", \"u\", \"f\", \"b\", \"c\", \"m\", \"M\"]:\r\n                # GH#11836 we need to avoid having numpy coerce\r\n                # things that look like ints/floats to ints unless\r\n                # they are actually ints, e.g. '0' and 0.0\r\n                # should not be coerced\r\n                data = com.asarray_tuplesafe(data, dtype=_dtype_obj)\r\n\r\n        elif is_scalar(data):\r\n            raise cls._raise_scalar_data_error(data)\r\n        elif hasattr(data, \"__array__\"):\r\n            return Index(np.asarray(data), dtype=dtype, copy=copy, name=name)\r\n        elif not is_list_like(data) and not isinstance(data, memoryview):\r\n            # 2022-11-16 the memoryview check is only necessary on some CI\r\n            #  builds, not clear why\r\n            raise cls._raise_scalar_data_error(data)\r\n\r\n        else:\r\n\r\n            if tupleize_cols:\r\n                # GH21470: convert iterable to list before determining if empty\r\n                if is_iterator(data):\r\n                    data = list(data)\r\n\r\n                if data and all(isinstance(e, tuple) for e in data):\r\n                    # we must be all tuples, otherwise don't construct\r\n                    # 10697\r\n                    from pandas.core.indexes.multi import MultiIndex\r\n\r\n                    return MultiIndex.from_tuples(data, names=name)\r\n            # other iterable of some kind\r\n\r\n            if not isinstance(data, (list, tuple)):\r\n                # we allow set/frozenset, which Series/sanitize_array does not, so\r\n                #  cast to list here\r\n                data = list(data)\r\n            if len(data) == 0:\r\n                # unlike Series, we default to object dtype:\r\n                data = np.array(data, dtype=object)\r\n\r\n            if len(data) and isinstance(data[0], tuple):\r\n                # Ensure we get 1-D array of tuples instead of 2D array.\r\n                data = com.asarray_tuplesafe(data, dtype=_dtype_obj)\r\n\r\n        try:\r\n            arr = sanitize_array(data, None, dtype=dtype, copy=copy)\r\n        except ValueError as err:\r\n            if \"index must be specified when data is not list-like\" in str(err):\r\n"]
[345.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[345.002, "i", "sed -n '520,900p' pandas/core/indexes/base.py\r"]
[345.004, "o", "sed -n '520,900p' pandas/core/indexes/base.py\r\n"]
[345.006, "o", "\u001b[?2004l\r\n            if \"index must be specified when data is not list-like\" in str(err):\r\n                raise cls._raise_scalar_data_error(data) from err\r\n            if \"Data must be 1-dimensional\" in str(err):\r\n                raise ValueError(\"Index data must be 1-dimensional\") from err\r\n            raise\r\n        arr = ensure_wrapped_if_datetimelike(arr)\r\n\r\n        klass = cls._dtype_to_subclass(arr.dtype)\r\n\r\n        # _ensure_array _may_ be unnecessary once NumericIndex etc are gone\r\n        arr = klass._ensure_array(arr, arr.dtype, copy=False)\r\n        return klass._simple_new(arr, name)\r\n\r\n    @classmethod\r\n    def _ensure_array(cls, data, dtype, copy: bool):\r\n        \"\"\"\r\n        Ensure we have a valid array to pass to _simple_new.\r\n        \"\"\"\r\n        if data.ndim > 1:\r\n            # GH#13601, GH#20285, GH#27125\r\n            raise ValueError(\"Index data must be 1-dimensional\")\r\n        if copy:\r\n            # asarray_tuplesafe does not always copy underlying data,\r\n            #  so need to make sure that this happens\r\n            data = data.copy()\r\n        return data\r\n\r\n    @final\r\n    @classmethod\r\n    def _dtype_to_subclass(cls, dtype: DtypeObj):\r\n        # Delay import for perf. https://github.com/pandas-dev/pandas/pull/31423\r\n\r\n        if isinstance(dtype, ExtensionDtype):\r\n            if isinstance(dtype, DatetimeTZDtype):\r\n                from pandas import DatetimeIndex\r\n\r\n                return DatetimeIndex\r\n            elif isinstance(dtype, CategoricalDtype):\r\n                from pandas import CategoricalIndex\r\n\r\n                return CategoricalIndex\r\n            elif isinstance(dtype, IntervalDtype):\r\n                from pandas import IntervalIndex\r\n\r\n                return IntervalIndex\r\n            elif isinstance(dtype, PeriodDtype):\r\n                from pandas import PeriodIndex\r\n\r\n                return PeriodIndex\r\n\r\n            return Index\r\n\r\n        if dtype.kind == \"M\":\r\n            from pandas import DatetimeIndex\r\n\r\n            return DatetimeIndex\r\n\r\n        elif dtype.kind == \"m\":\r\n            from pandas import TimedeltaIndex\r\n\r\n            return TimedeltaIndex\r\n\r\n        elif dtype.kind in [\"i\", \"f\", \"u\"]:\r\n            from pandas.core.api import NumericIndex\r\n\r\n            return NumericIndex\r\n\r\n        elif dtype.kind == \"O\":\r\n            # NB: assuming away MultiIndex\r\n            return Index\r\n\r\n        elif issubclass(\r\n            dtype.type, (str, bool, np.bool_, complex, np.complex64, np.complex128)\r\n        ):\r\n            return Index\r\n\r\n        raise NotImplementedError(dtype)\r\n\r\n    # NOTE for new Index creation:\r\n\r\n    # - _simple_new: It returns new Index with the same type as the caller.\r\n    #   All metadata (such as name) must be provided by caller's responsibility.\r\n    #   Using _shallow_copy is recommended because it fills these metadata\r\n    #   otherwise specified.\r\n\r\n    # - _shallow_copy: It returns new Index with the same type (using\r\n    #   _simple_new), but fills caller's metadata otherwise specified. Passed\r\n    #   kwargs will overwrite corresponding metadata.\r\n\r\n    # See each method's docstring.\r\n\r\n    @classmethod\r\n    def _simple_new(\r\n        cls: type[_IndexT], values: ArrayLike, name: Hashable = None\r\n    ) -> _IndexT:\r\n        \"\"\"\r\n        We require that we have a dtype compat for the values. If we are passed\r\n        a non-dtype compat, then coerce using the constructor.\r\n\r\n        Must be careful not to recurse.\r\n        \"\"\"\r\n        assert isinstance(values, cls._data_cls), type(values)\r\n\r\n        result = object.__new__(cls)\r\n        result._data = values\r\n        result._name = name\r\n        result._cache = {}\r\n        result._reset_identity()\r\n\r\n        return result\r\n\r\n    @classmethod\r\n    def _with_infer(cls, *args, **kwargs):\r\n        \"\"\"\r\n        Constructor that uses the 1.0.x behavior inferring numeric dtypes\r\n        for ndarray[object] inputs.\r\n        \"\"\"\r\n        result = cls(*args, **kwargs)\r\n\r\n        if result.dtype == _dtype_obj and not result._is_multi:\r\n            # error: Argument 1 to \"maybe_convert_objects\" has incompatible type\r\n            # \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected\r\n            # \"ndarray[Any, Any]\"\r\n            values = lib.maybe_convert_objects(result._values)  # type: ignore[arg-type]\r\n            if values.dtype.kind in [\"i\", \"u\", \"f\", \"b\"]:\r\n                return Index(values, name=result.name)\r\n\r\n        return result\r\n\r\n    @cache_readonly\r\n    def _constructor(self: _IndexT) -> type[_IndexT]:\r\n        return type(self)\r\n\r\n    @final\r\n    def _maybe_check_unique(self) -> None:\r\n        \"\"\"\r\n        Check that an Index has no duplicates.\r\n\r\n        This is typically only called via\r\n        `NDFrame.flags.allows_duplicate_labels.setter` when it's set to\r\n        True (duplicates aren't allowed).\r\n\r\n        Raises\r\n        ------\r\n        DuplicateLabelError\r\n            When the index is not unique.\r\n        \"\"\"\r\n        if not self.is_unique:\r\n            msg = \"\"\"Index has duplicates.\"\"\"\r\n            duplicates = self._format_duplicate_message()\r\n            msg += f\"\\n{duplicates}\"\r\n\r\n            raise DuplicateLabelError(msg)\r\n\r\n    @final\r\n    def _format_duplicate_message(self) -> DataFrame:\r\n        \"\"\"\r\n        Construct the DataFrame for a DuplicateLabelError.\r\n\r\n        This returns a DataFrame indicating the labels and positions\r\n        of duplicates in an index. This should only be called when it's\r\n        already known that duplicates are present.\r\n\r\n        Examples\r\n        --------\r\n        >>> idx = pd.Index(['a', 'b', 'a'])\r\n        >>> idx._format_duplicate_message()\r\n            positions\r\n        label\r\n        a        [0, 2]\r\n        \"\"\"\r\n        from pandas import Series\r\n\r\n        duplicates = self[self.duplicated(keep=\"first\")].unique()\r\n        assert len(duplicates)\r\n\r\n        out = Series(np.arange(len(self))).groupby(self).agg(list)[duplicates]\r\n        if self._is_multi:\r\n            # test_format_duplicate_labels_message_multi\r\n            # error: \"Type[Index]\" has no attribute \"from_tuples\"  [attr-defined]\r\n            out.index = type(self).from_tuples(out.index)  # type: ignore[attr-defined]\r\n\r\n        if self.nlevels == 1:\r\n            out = out.rename_axis(\"label\")\r\n        return out.to_frame(name=\"positions\")\r\n\r\n    # --------------------------------------------------------------------\r\n    # Index Internals Methods\r\n\r\n    def _shallow_copy(self: _IndexT, values, name: Hashable = no_default) -> _IndexT:\r\n        \"\"\"\r\n        Create a new Index with the same class as the caller, don't copy the\r\n        data, use the same object attributes with passed in attributes taking\r\n        precedence.\r\n\r\n        *this is an internal non-public method*\r\n\r\n        Parameters\r\n        ----------\r\n        values : the values to create the new Index, optional\r\n        name : Label, defaults to self.name\r\n        \"\"\"\r\n        name = self._name if name is no_default else name\r\n\r\n        return self._simple_new(values, name=name)\r\n\r\n    def _view(self: _IndexT) -> _IndexT:\r\n        \"\"\"\r\n        fastpath to make a shallow copy, i.e. new object with same data.\r\n        \"\"\"\r\n        result = self._simple_new(self._values, name=self._name)\r\n\r\n        result._cache = self._cache\r\n        return result\r\n\r\n    @final\r\n    def _rename(self: _IndexT, name: Hashable) -> _IndexT:\r\n        \"\"\"\r\n        fastpath for rename if new name is already validated.\r\n        \"\"\"\r\n        result = self._view()\r\n        result._name = name\r\n        return result\r\n\r\n    @final\r\n    def is_(self, other) -> bool:\r\n        \"\"\"\r\n        More flexible, faster check like ``is`` but that works through views.\r\n\r\n        Note: this is *not* the same as ``Index.identical()``, which checks\r\n        that metadata is also the same.\r\n\r\n        Parameters\r\n        ----------\r\n        other : object\r\n            Other object to compare against.\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n            True if both have same underlying data, False otherwise.\r\n\r\n        See Also\r\n        --------\r\n        Index.identical : Works like ``Index.is_`` but also checks metadata.\r\n        \"\"\"\r\n        if self is other:\r\n            return True\r\n        elif not hasattr(other, \"_id\"):\r\n            return False\r\n        elif self._id is None or other._id is None:\r\n            return False\r\n        else:\r\n            return self._id is other._id\r\n\r\n    @final\r\n    def _reset_identity(self) -> None:\r\n        \"\"\"\r\n        Initializes or resets ``_id`` attribute with new object.\r\n        \"\"\"\r\n        self._id = object()\r\n\r\n    @final\r\n    def _cleanup(self) -> None:\r\n        self._engine.clear_mapping()\r\n\r\n    @cache_readonly\r\n    def _engine(\r\n        self,\r\n    ) -> libindex.IndexEngine | libindex.ExtensionEngine | libindex.MaskedIndexEngine:\r\n        # For base class (object dtype) we get ObjectEngine\r\n        target_values = self._get_engine_target()\r\n        if isinstance(target_values, ExtensionArray):\r\n\r\n            if isinstance(target_values, BaseMaskedArray):\r\n                return _masked_engines[target_values.dtype.name](target_values)\r\n            elif self._engine_type is libindex.ObjectEngine:\r\n                return libindex.ExtensionEngine(target_values)\r\n\r\n        target_values = cast(np.ndarray, target_values)\r\n        # to avoid a reference cycle, bind `target_values` to a local variable, so\r\n        # `self` is not passed into the lambda.\r\n        if target_values.dtype == bool:\r\n            return libindex.BoolEngine(target_values)\r\n        elif target_values.dtype == np.complex64:\r\n            return libindex.Complex64Engine(target_values)\r\n        elif target_values.dtype == np.complex128:\r\n            return libindex.Complex128Engine(target_values)\r\n        elif needs_i8_conversion(self.dtype):\r\n            # We need to keep M8/m8 dtype when initializing the Engine,\r\n            #  but don't want to change _get_engine_target bc it is used\r\n            #  elsewhere\r\n            # error: Item \"ExtensionArray\" of \"Union[ExtensionArray,\r\n            # ndarray[Any, Any]]\" has no attribute \"_ndarray\"  [union-attr]\r\n            target_values = self._data._ndarray  # type: ignore[union-attr]\r\n\r\n        # error: Argument 1 to \"ExtensionEngine\" has incompatible type\r\n        # \"ndarray[Any, Any]\"; expected \"ExtensionArray\"\r\n        return self._engine_type(target_values)  # type: ignore[arg-type]\r\n\r\n    @final\r\n    @cache_readonly\r\n    def _dir_additions_for_owner(self) -> set[str_t]:\r\n        \"\"\"\r\n        Add the string-like labels to the owner dataframe/series dir output.\r\n\r\n        If this is a MultiIndex, it's first level values are used.\r\n        \"\"\"\r\n        return {\r\n            c\r\n            for c in self.unique(level=0)[: get_option(\"display.max_dir_items\")]\r\n            if isinstance(c, str) and c.isidentifier()\r\n        }\r\n\r\n    # --------------------------------------------------------------------\r\n    # Array-Like Methods\r\n\r\n    # ndarray compat\r\n    def __len__(self) -> int:\r\n        \"\"\"\r\n        Return the length of the Index.\r\n        \"\"\"\r\n        return len(self._data)\r\n\r\n    def __array__(self, dtype=None) -> np.ndarray:\r\n        \"\"\"\r\n        The array interface, return my values.\r\n        \"\"\"\r\n        return np.asarray(self._data, dtype=dtype)\r\n\r\n    def __array_ufunc__(self, ufunc: np.ufunc, method: str_t, *inputs, **kwargs):\r\n        if any(isinstance(other, (ABCSeries, ABCDataFrame)) for other in inputs):\r\n            return NotImplemented\r\n\r\n        result = arraylike.maybe_dispatch_ufunc_to_dunder_op(\r\n            self, ufunc, method, *inputs, **kwargs\r\n        )\r\n        if result is not NotImplemented:\r\n            return result\r\n\r\n        if \"out\" in kwargs:\r\n            # e.g. test_dti_isub_tdi\r\n            return arraylike.dispatch_ufunc_with_out(\r\n                self, ufunc, method, *inputs, **kwargs\r\n            )\r\n\r\n        if method == \"reduce\":\r\n            result = arraylike.dispatch_reduction_ufunc(\r\n                self, ufunc, method, *inputs, **kwargs\r\n            )\r\n            if result is not NotImplemented:\r\n                return result\r\n\r\n        new_inputs = [x if x is not self else x._values for x in inputs]\r\n        result = getattr(ufunc, method)(*new_inputs, **kwargs)\r\n        if ufunc.nout == 2:\r\n            # i.e. np.divmod, np.modf, np.frexp\r\n            return tuple(self.__array_wrap__(x) for x in result)\r\n\r\n        if result.dtype == np.float16:\r\n            result = result.astype(np.float32)\r\n\r\n        return self.__array_wrap__(result)\r\n\r\n    def __array_wrap__(self, result, context=None):\r\n        \"\"\"\r\n        Gets called after a ufunc and other functions e.g. np.split.\r\n        \"\"\"\r\n        result = lib.item_from_zerodim(result)\r\n        if is_bool_dtype(result) or lib.is_scalar(result) or np.ndim(result) > 1:\r\n            return result\r\n\r\n        return Index(result, name=self.name)\r\n\r\n    @cache_readonly\r\n    def dtype(self) -> DtypeObj:\r\n        \"\"\"\r\n        Return the dtype object of the underlying data.\r\n        \"\"\"\r\n        return self._data.dtype\r\n\r\n"]
[350.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[350.002, "i", "python - << 'PY'\r"]
[350.004, "o", "python - << 'PY'\r\n"]
[350.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import inspect\r\n\u001b[?2004l\r\n\u001b[?2004h> import pandas.core.indexes.base as ibase\r\n\u001b[?2004l\r\n\u001b[?2004h> try:\r\n\u001b[?2004l\r\n\u001b[?2004h>     src = inspect.getsource(ibase.Index.difference)\r\n\u001b[?2004l\r\n\u001b[?2004h>     print(src[:2000])\r\n\u001b[?2004l\r\n\u001b[?2004h> except Exception as e:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('Error getting source:', e)\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n    @final\r\n    def difference(self, other, sort=None):\r\n        \"\"\"\r\n        Return a new Index with elements of index not in `other`.\r\n\r\n        This is the set difference of two Index objects.\r\n\r\n        Parameters\r\n        ----------\r\n        other : Index or array-like\r\n        sort : False or None, default None\r\n            Whether to sort the resulting index. By default, the\r\n            values are attempted to be sorted, but any TypeError from\r\n            incomparable elements is caught by pandas.\r\n\r\n            * None : Attempt to sort the result, but catch any TypeErrors\r\n              from comparing incomparable elements.\r\n            * False : Do not sort the result.\r\n\r\n        Returns\r\n        -------\r\n        Index\r\n\r\n        Examples\r\n        --------\r\n        >>> idx1 = pd.Index([2, 1, 3, 4])\r\n        >>> idx2 = pd.Index([3, 4, 5, 6])\r\n        >>> idx1.difference(idx2)\r\n        NumericIndex([1, 2], dtype='int64')\r\n        >>> idx1.difference(idx2, sort=False)\r\n        NumericIndex([2, 1], dtype='int64')\r\n        \"\"\"\r\n        self._validate_sort_keyword(sort)\r\n        self._assert_can_do_setop(other)\r\n        other, result_name = self._convert_can_do_setop(other)\r\n\r\n        # Note: we do NOT call _dti_setop_align_tzs here, as there\r\n        #  is no requirement that .difference be commutative, so it does\r\n        #  not cast to object.\r\n\r\n        if self.equals(other):\r\n            # Note: we do not (yet) sort even if sort=None GH#24959\r\n            return self[:0].rename(result_name)\r\n\r\n        if len(other) == 0:\r\n            # Note: we do not (yet) sort even if sort=None GH#24959\r\n            return self.rename(result_name)\r\n\r\n        if not self._should_compare(other):\r\n            # Nothing matches -> difference is everything\r\n            return self.rename(result_name)\r\n\r\n        result = self._difference(other, sort=sort)\r\n        return self._wrap_difference_result(other, result)\r\n\r\n"]
[355.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[355.002, "i", "git checkout -b opt-fastpath-difference || git checkout opt-fastpath-difference\r"]
[355.004, "o", "git checkout -b opt-fastpath-difference || git checkout opt-fastpath-difference\r\n"]
[355.006, "o", "\u001b[?2004l\r\nfatal: a branch named 'opt-fastpath-difference' already exists\r\nAlready on 'opt-fastpath-difference'\r\n"]
[360.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[360.002, "i", "python - << 'PY'\r"]
[360.004, "o", "python - << 'PY'\r\n"]
[360.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/indexes/base.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> m = re.search(r\"def difference\\(self, other, sort=None\\):\", s)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('difference method not found in base.Index; abort patch')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     start = m.start()\r\n\u001b[?2004l\r\n\u001b[?2004h>     rest = s[start:]\r\n\u001b[?2004l\r\n\u001b[?2004h>     lines = rest.splitlines(keepends=True)\r\n\u001b[?2004l\r\n\u001b[?2004h>     end_offset = None\r\n\u001b[?2004l\r\n\u001b[?2004h>     for i, line in enumerate(lines[1:], start=1):\r\n\u001b[?2004l\r\n\u001b[?2004h>         if line.startswith('    def ') and not line.startswith('        '):\r\n\u001b[?2004l\r\n\u001b[?2004h>             end_offset = sum(len(l) for l in lines[:i])\r\n\u001b[?2004l\r\n\u001b[?2004h>             break\r\n\u001b[?2004l\r\n\u001b[?2004h>     end = start + (end_offset if end_offset is not None else len(rest))\r\n\u001b[?2004l\r\n\u001b[?2004h>     body = s[start:end]\r\n\u001b[?2004l\r\n\u001b[?2004h>     if 'fastpath_disjoint' in body:\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('Fastpath already present')\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         insert_at = body.find('\\n        \\n')\r\n\u001b[?2004l\r\n\u001b[?2004h>         if insert_at == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>             # After signature line\r\n\u001b[?2004l\r\n\u001b[?2004h>             insert_at = body.find('\\n')\r\n\u001b[?2004l\r\n\u001b[?2004h>         fast = \"\\n        # fastpath_disjoint: if both indexes are monotonic and non-overlapping by bounds,\\n        # return self unchanged to avoid expensive\r\ne set operations.\\n        try:\\n            oth = other\\n            if len(self) == 0:\\n                return self.copy(deep=False)\\n            # If 'other' \r\n isn't an Index-like, skip fastpath\r\n\u001b[?2004l\r\n\u001b[?2004h>             if not hasattr(oth, 'is_monotonic_increasing') or len(oth) == 0:\r\n\u001b[?2004l\r\n\u001b[?2004h>                 pass\r\n\u001b[?2004l\r\n\u001b[?2004h>             else:\\n                if (self.is_monotonic_increasing or self.is_monotonic_decreasing) and \\\r\n\u001b[?2004l\r\n\u001b[?2004h>                    (oth.is_monotonic_increasing or oth.is_monotonic_decreasing):\\n                    s_first, s_last = self[0], self[-1]\r\n\u001b[?2004l\r\n\u001b[?2004h>                     o_first, o_last = oth[0], oth[-1]\r\n\u001b[?2004l\r\n\u001b[?2004h>                     if self.is_monotonic_decreasing:\r\n\u001b[?2004l\r\n\u001b[?2004h>                         s_first, s_last = s_last, s_first\r\n\u001b[?2004l\r\n\u001b[?2004h>                     if oth.is_monotonic_decreasing:\r\n\u001b[?2004l\r\n\u001b[?2004h>                         o_first, o_last = o_last, o_first\r\n\u001b[?2004l\r\n\u001b[?2004h>                     if s_last < o_first or o_last < s_first:\r\n\u001b[?2004l\r\n\u001b[?2004h>                         res = self.copy(deep=False)\r\n\u001b[?2004l\r\n\u001b[?2004h>                         res.name = self.name\r\n\u001b[?2004l\r\n\u001b[?2004h>                         return res\\n        except Exception:\r\n\u001b[?2004l\r\n\u001b[?2004h>             # Fall back to full implementation on any issue\r\n\u001b[?2004l\r\n\u001b[?2004h>             pass\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_body = body[:insert_at] + fast + body[insert_at:]\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_s = s[:start] + new_body + s[end:]\r\n\u001b[?2004l\r\n\u001b[?2004h>         p.write_text(new_s)\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('Patched base.Index.difference with fastpath_disjoint')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n  File \"<stdin>\", line 26\r\n    fast = \"\\n        # fastpath_disjoint: if both indexes are monotonic and non-overlapping by bounds,\\n        # return self unchanged to avoid expensive set operations.\\n        try:\\n            oth = other\\n            if len(self) == 0:\\n                return self.copy(deep=False)\\n            # If 'other' isn't an Index-like, skip fastpath\r\n                                                                                                                                                                                                                                                                                                                                                            ^\r\nSyntaxError: EOL while scanning string literal\r\n"]
[365.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[365.002, "i", "python - << 'PY'\r"]
[365.004, "o", "python - << 'PY'\r\n"]
[365.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import pandas as pd\r\n\u001b[?2004l\r\n\u001b[?2004h> print('pandas imported; version:', pd.__version__)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Disjoint monotonic\r\n\u001b[?2004l\r\n\u001b[?2004h> left = pd.DatetimeIndex(range(10**5))\r\n\u001b[?2004l\r\n\u001b[?2004h> right = pd.DatetimeIndex(range(10**5, 120000))\r\n\u001b[?2004l\r\n\u001b[?2004h> res = left.difference(right)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('len(res)=', len(res))\r\n\u001b[?2004l\r\n\u001b[?2004h> assert res.equals(left)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Overlapping to ensure correctness\r\n\u001b[?2004l\r\n\u001b[?2004h> left2 = pd.DatetimeIndex(range(10))\r\n\u001b[?2004l\r\n\u001b[?2004h> right2 = pd.DatetimeIndex(range(5, 15))\r\n\u001b[?2004l\r\n\u001b[?2004h> res2 = left2.difference(right2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('len(res2)=', len(res2), 'first=', res2[0])\r\n\u001b[?2004l\r\n\u001b[?2004h> assert len(res2) == 5 and res2[0] == left2[0]\r\n\u001b[?2004l\r\n\u001b[?2004h> print('basic checks passed')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\npandas imported; version: 0+untagged.31331.g57c6533\r\nlen(res)= 100000\r\nlen(res2)= 5 first= 1970-01-01 00:00:00\r\nbasic checks passed\r\n"]
[370.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[370.002, "i", "git add -A && git commit -m \"Optimize Index.difference: add fastpath for disjoint monotonic indexes (DatetimeIndex e\r"]
[370.004, "o", "git add -A && git commit -m \"Optimize Index.difference: add fastpath for disjoint monotonic indexes (DatetimeIndex e\r\n"]
[370.006, "o", "etc.)\"\r\n\u001b[?2004l\r\nAuthor identity unknown\r\n\r\n*** Please tell me who you are.\r\n\r\nRun\r\n\r\n  git config --global user.email \"you@example.com\"\r\n  git config --global user.name \"Your Name\"\r\n\r\nto set your account's default identity.\r\nOmit --global to set the identity only in this repository.\r\n\r\nfatal: unable to auto-detect email address (got 'root@c510d3ab122e.(none)')\r\n"]
[375.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[375.002, "i", "cd asv_bench\r"]
[375.004, "o", "cd asv_bench\r\n"]
[375.006, "o", "\u001b[?2004l\r\n"]
[380.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[380.002, "i", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r"]
[380.004, "o", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r\n"]
[380.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                                4.53\u00b10ms\r\n"]
[385.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[385.002, "i", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r"]
[385.004, "o", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r\n"]
[385.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (index_object.SetDisjoint.time_datetime_difference_disjoint--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                             2.06\u00b10.01ms\r\n\r\nWed Oct  1 19:18:56 2025    /tmp/tmpn4n3h8qz\r\n\r\n         769 function calls (750 primitive calls) in 0.003 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.003    0.003 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.003    0.003 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.003    0.003 index_object.py:63(time_datetime_difference_disjoint)\r\n        1    0.000    0.000    0.003    0.003 base.py:3391(difference)\r\n        1    0.000    0.000    0.003    0.003 base.py:3446(_difference)\r\n        1    0.000    0.000    0.002    0.002 base.py:7143(_maybe_try_sort)\r\n        1    0.000    0.000    0.002    0.002 algorithms.py:1698(safe_sort)\r\n        1    0.000    0.000    0.001    0.001 base.py:656(argsort)\r\n        1    0.000    0.000    0.001    0.001 sorting.py:371(nargsort)\r\n        1    0.001    0.001    0.001    0.001 {method 'argsort' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.001    0.001 base.py:2849(unique)\r\n        1    0.001    0.001    0.001    0.001 base.py:2171(is_unique)\r\n        1    0.000    0.000    0.000    0.000 base.py:5750(get_indexer_for)\r\n        1    0.000    0.000    0.000    0.000 base.py:3657(get_indexer)\r\n        2    0.000    0.000    0.000    0.000 _mixins.py:155(take)\r\n        2    0.000    0.000    0.000    0.000 algorithms.py:1393(take)\r\n        3    0.000    0.000    0.000    0.000 {method 'take' of 'numpy.ndarray' objects}\r\n      9/5    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:379(_maybe_cast_listlike_indexer)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(setdiff1d)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:939(setdiff1d)\r\n        1    0.000    0.000    0.000    0.000 base.py:3744(_get_indexer)\r\n        2    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\r\n        1    0.000    0.000    0.000    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\r\n  144/134    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:675(_validate_listlike)\r\n        2    0.000    0.000    0.000    0.000 base.py:6003(_should_compare)\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:115(equals)\r\n       53    0.000    0.000    0.000    0.000 generic.py:42(_instancecheck)\r\n        1    0.000    0.000    0.000    0.000 construction.py:73(array)\r\n        1    0.000    0.000    0.000    0.000 base.py:437(__new__)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(concatenate)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_dtype}\r\n        4    0.000    0.000    0.000    0.000 common.py:1256(is_bool_dtype)\r\n  103/100    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n       34    0.000    0.000    0.000    0.000 extension.py:70(fget)\r\n        3    0.000    0.000    0.000    0.000 base.py:611(_simple_new)\r\n        6    0.000    0.000    0.000    0.000 common.py:456(is_categorical_dtype)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:823(isna)\r\n       16    0.000    0.000    0.000    0.000 common.py:1469(get_dtype)\r\n        7    0.000    0.000    0.000    0.000 base.py:286(is_dtype)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:826(_isnan)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(in1d)\r\n        1    0.000    0.000    0.000    0.000 base.py:726(_view)\r\n       53    0.000    0.000    0.000    0.000 generic.py:37(_check)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:524(in1d)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:543(copy)\r\n        5    0.000    0.000    0.000    0.000 construction.py:399(extract_array)\r\n        1    0.000    0.000    0.000    0.000 base.py:3789(_check_indexing_method)\r\n        1    0.000    0.000    0.000    0.000 construction.py:497(sanitize_array)\r\n        2    0.000    0.000    0.000    0.000 common.py:87(get_op_result_name)\r\n        1    0.000    0.000    0.000    0.000 base.py:786(_engine)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:344(_name_get)\r\n        1    0.000    0.000    0.000    0.000 base.py:3465(_wrap_difference_result)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(ones_like)\r\n        6    0.000    0.000    0.000    0.000 common.py:545(is_dtype_equal)\r\n        1    0.000    0.000    0.000    0.000 base.py:3236(_wrap_setop_result)\r\n        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(array_equal)\r\n        1    0.000    0.000    0.000    0.000 base.py:3555(_convert_can_do_setop)\r\n        2    0.000    0.000    0.000    0.000 base.py:7120(unpack_nested_dtype)\r\n        1    0.000    0.000    0.000    0.000 {function DatetimeLikeArrayMixin.copy at 0x7efd22dabca0}\r\n       24    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 numeric.py:219(ones_like)\r\n        4    0.000    0.000    0.000    0.000 common.py:157(is_object_dtype)\r\n        1    0.000    0.000    0.000    0.000 base.py:5923(_maybe_promote)\r\n        1    0.000    0.000    0.000    0.000 base.py:3549(_assert_can_do_setop)\r\n        4    0.000    0.000    0.000    0.000 datetimelike.py:105(asi8)\r\n        5    0.000    0.000    0.000    0.000 datetimelike.py:307(asi8)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(nonzero)\r\n        2    0.000    0.000    0.000    0.000 datetimes.py:371(_is_comparable_dtype)\r\n        2    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:1892(nonzero)\r\n       50    0.000    0.000    0.000    0.000 datetimes.py:532(dtype)\r\n        7    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:51(_wrapfunc)\r\n        2    0.000    0.000    0.000    0.000 common.py:109(_maybe_match_name)\r\n        4    0.000    0.000    0.000    0.000 common.py:1504(_is_dtype_type)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(copyto)\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:599(__array__)\r\n        1    0.000    0.000    0.000    0.000 common.py:418(is_interval_dtype)\r\n        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\r\n        6    0.000    0.000    0.000    0.000 common.py:1663(pandas_dtype)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:330(_name_includes_bit_suffix)\r\n        6    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\r\n        1    0.000    0.000    0.000    0.000 dtypes.py:1250(is_dtype)\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:635(astype)\r\n        3    0.000    0.000    0.000    0.000 inference.py:185(is_array_like)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:557(tz)\r\n        1    0.000    0.000    0.000    0.000 base.py:7085(maybe_extract_name)\r\n        1    0.000    0.000    0.000    0.000 numerictypes.py:356(issubdtype)\r\n        2    0.000    0.000    0.000    0.000 numeric.py:2407(array_equal)\r\n        1    0.000    0.000    0.000    0.000 base.py:709(_shallow_copy)\r\n        2    0.000    0.000    0.000    0.000 base.py:2624(_is_multi)\r\n        4    0.000    0.000    0.000    0.000 common.py:143(<lambda>)\r\n      6/4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 common.py:1346(is_extension_array_dtype)\r\n        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(empty_like)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:178(_datetime_metadata_str)\r\n        1    0.000    0.000    0.000    0.000 function.py:150(validate_argsort_with_ascending)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:342(__array__)\r\n        1    0.000    0.000    0.000    0.000 base.py:547(_dtype_to_subclass)\r\n       10    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n        1    0.000    0.000    0.000    0.000 common.py:1713(is_all_strings)\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:673(_get_engine_target)\r\n        2    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 numerictypes.py:282(issubclass_)\r\n        8    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\r\n        2    0.000    0.000    0.000    0.000 {method '_from_backing_data' of 'pandas._libs.arrays.NDArrayBacked' objects}\r\n        2    0.000    0.000    0.000    0.000 base.py:744(is_)\r\n        3    0.000    0.000    0.000    0.000 base.py:775(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 inference.py:322(is_hashable)\r\n        1    0.000    0.000    0.000    0.000 missing.py:940(clean_reindex_fill_method)\r\n       10    0.000    0.000    0.000    0.000 base.py:1542(name)\r\n        1    0.000    0.000    0.000    0.000 construction.py:647(_sanitize_ndim)\r\n        2    0.000    0.000    0.000    0.000 common.py:273(is_datetime64_dtype)\r\n        2    0.000    0.000    0.000    0.000 base.py:838(__len__)\r\n        1    0.000    0.000    0.000    0.000 base.py:352(size)\r\n        3    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\r\n        3    0.000    0.000    0.000    0.000 arraysetops.py:630(<genexpr>)\r\n        4    0.000    0.000    0.000    0.000 common.py:141(classes)\r\n        3    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55b40cb5c680}\r\n        4    0.000    0.000    0.000    0.000 base.py:4872(_values)\r\n        1    0.000    0.000    0.000    0.000 common.py:1400(is_ea_or_datetimelike_dtype)\r\n        1    0.000    0.000    0.000    0.000 common.py:861(is_datetime64_any_dtype)\r\n        1    0.000    0.000    0.000    0.000 common.py:1128(needs_i8_conversion)\r\n        2    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\r\n        2    0.000    0.000    0.000    0.000 base.py:5911(_index_as_unique)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:688(inferred_type)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\r\n        1    0.000    0.000    0.000    0.000 construction.py:461(ensure_wrapped_if_datetimelike)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.datetime_data}\r\n        1    0.000    0.000    0.000    0.000 datetimes.py:248(_engine_type)\r\n        1    0.000    0.000    0.000    0.000 missing.py:120(clean_fill_method)\r\n        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 function.py:59(__call__)\r\n        2    0.000    0.000    0.000    0.000 numeric.py:2403(_array_equal_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 base.py:3019(_validate_sort_keyword)\r\n        1    0.000    0.000    0.000    0.000 base.py:533(_ensure_array)\r\n        1    0.000    0.000    0.000    0.000 datetimelike.py:1863(freq)\r\n        2    0.000    0.000    0.000    0.000 base.py:319(ndim)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 typing.py:1149(cast)\r\n        1    0.000    0.000    0.000    0.000 _mixins.py:189(_values_for_argsort)\r\n        1    0.000    0.000    0.000    0.000 fromnumeric.py:1888(_nonzero_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 numeric.py:215(_ones_like_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:935(_setdiff1d_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:152(concatenate)\r\n        1    0.000    0.000    0.000    0.000 construction.py:706(_maybe_repeat)\r\n        1    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:1079(copyto)\r\n        1    0.000    0.000    0.000    0.000 arraysetops.py:519(_in1d_dispatcher)\r\n        1    0.000    0.000    0.000    0.000 multiarray.py:84(empty_like)\r\n\r\n\r\n"]
[390.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[390.002, "i", "cd ..\r"]
[390.004, "o", "cd ..\r\n"]
[390.006, "o", "\u001b[?2004l\r\n"]
[395.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[395.002, "i", "pwd\r"]
[395.004, "o", "pwd\r\n"]
[395.006, "o", "\u001b[?2004l\r\n/workspace/repo\r\n"]
[400.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[400.002, "i", "grep -Rsn 'def difference\\s*\\(' pandas/core/indexes | sed -n '1,200p'\r"]
[400.004, "o", "grep -Rsn 'def difference\\s*\\(' pandas/core/indexes | sed -n '1,200p'\r\n"]
[400.006, "o", "\u001b[?2004l\r\ngrep: Unmatched ( or \\(\r\n"]
[405.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[405.002, "i", "grep -n 'def difference\\s*(' pandas/core/indexes/base.py || true\r"]
[405.004, "o", "grep -n 'def difference\\s*(' pandas/core/indexes/base.py || true\r\n"]
[405.006, "o", "\u001b[?2004l\r\n\u001b[32m\u001b[K3392\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K    \u001b[01;31m\u001b[Kdef difference(\u001b[m\u001b[Kself, other, sort=None):\r\n"]
[410.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[410.002, "i", "python - << 'PY'\r"]
[410.004, "o", "python - << 'PY'\r\n"]
[410.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import inspect\r\n\u001b[?2004l\r\n\u001b[?2004h> import pandas.core.indexes.base as ibase\r\n\u001b[?2004l\r\n\u001b[?2004h> print(inspect.getsource(ibase.Index.difference)[:3000])\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\n    @final\r\n    def difference(self, other, sort=None):\r\n        \"\"\"\r\n        Return a new Index with elements of index not in `other`.\r\n\r\n        This is the set difference of two Index objects.\r\n\r\n        Parameters\r\n        ----------\r\n        other : Index or array-like\r\n        sort : False or None, default None\r\n            Whether to sort the resulting index. By default, the\r\n            values are attempted to be sorted, but any TypeError from\r\n            incomparable elements is caught by pandas.\r\n\r\n            * None : Attempt to sort the result, but catch any TypeErrors\r\n              from comparing incomparable elements.\r\n            * False : Do not sort the result.\r\n\r\n        Returns\r\n        -------\r\n        Index\r\n\r\n        Examples\r\n        --------\r\n        >>> idx1 = pd.Index([2, 1, 3, 4])\r\n        >>> idx2 = pd.Index([3, 4, 5, 6])\r\n        >>> idx1.difference(idx2)\r\n        NumericIndex([1, 2], dtype='int64')\r\n        >>> idx1.difference(idx2, sort=False)\r\n        NumericIndex([2, 1], dtype='int64')\r\n        \"\"\"\r\n        self._validate_sort_keyword(sort)\r\n        self._assert_can_do_setop(other)\r\n        other, result_name = self._convert_can_do_setop(other)\r\n\r\n        # Note: we do NOT call _dti_setop_align_tzs here, as there\r\n        #  is no requirement that .difference be commutative, so it does\r\n        #  not cast to object.\r\n\r\n        if self.equals(other):\r\n            # Note: we do not (yet) sort even if sort=None GH#24959\r\n            return self[:0].rename(result_name)\r\n\r\n        if len(other) == 0:\r\n            # Note: we do not (yet) sort even if sort=None GH#24959\r\n            return self.rename(result_name)\r\n\r\n        if not self._should_compare(other):\r\n            # Nothing matches -> difference is everything\r\n            return self.rename(result_name)\r\n\r\n        result = self._difference(other, sort=sort)\r\n        return self._wrap_difference_result(other, result)\r\n\r\n"]
[415.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[415.002, "i", "git checkout -b opt-fastpath-difference || git checkout opt-fastpath-difference\r"]
[415.004, "o", "git checkout -b opt-fastpath-difference || git checkout opt-fastpath-difference\r\n"]
[415.006, "o", "\u001b[?2004l\r\nfatal: a branch named 'opt-fastpath-difference' already exists\r\nAlready on 'opt-fastpath-difference'\r\n"]
[420.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[420.002, "i", "python - << 'PY'\r"]
[420.004, "o", "python - << 'PY'\r\n"]
[420.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> import re\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/indexes/base.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> m = re.search(r\"def difference\\(self, other, sort=None\\):\", s)\r\n\u001b[?2004l\r\n\u001b[?2004h> if not m:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('difference method not found in base.Index; abort patch')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     start = m.start()\r\n\u001b[?2004l\r\n\u001b[?2004h>     rest = s[start:]\r\n\u001b[?2004l\r\n\u001b[?2004h>     lines = rest.splitlines(keepends=True)\r\n\u001b[?2004l\r\n\u001b[?2004h>     end_offset = None\r\n\u001b[?2004l\r\n\u001b[?2004h>     for i, line in enumerate(lines[1:], start=1):\r\n\u001b[?2004l\r\n\u001b[?2004h>         if line.startswith('    def ') and not line.startswith('        '):\r\n\u001b[?2004l\r\n\u001b[?2004h>             end_offset = sum(len(l) for l in lines[:i])\r\n\u001b[?2004l\r\n\u001b[?2004h>             break\r\n\u001b[?2004l\r\n\u001b[?2004h>     end = start + (end_offset if end_offset is not None else len(rest))\r\n\u001b[?2004l\r\n\u001b[?2004h>     body = s[start:end]\r\n\u001b[?2004l\r\n\u001b[?2004h>     if 'fastpath_disjoint' in body:\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('Fastpath already present')\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         # Insert fastpath near the start of the method body\r\n\u001b[?2004l\r\n\u001b[?2004h>         insert_at = body.find('\\n        \\n')\r\n\u001b[?2004l\r\n\u001b[?2004h>         if insert_at == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>             insert_at = body.find('\\n')\r\n\u001b[?2004l\r\n\u001b[?2004h>         fast = (\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"\\n        # fastpath_disjoint: if both indexes are monotonic and non-overlapping by bounds,\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        # return self unchanged to avoid expensive set operations.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        try:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            oth = other\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            if len(self) == 0:\\n                return self.copy(deep=False)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            if hasattr(oth, 'is_monotonic_increasing') and len(oth) > 0 and \\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"               (self.is_monotonic_increasing or self.is_monotonic_decreasing) and \\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"               (oth.is_monotonic_increasing or oth.is_monotonic_decreasing):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                s_first, s_last = self[0], self[-1]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                o_first, o_last = oth[0], oth[-1]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                if self.is_monotonic_decreasing:\\n                    s_first, s_last = s_last, s_first\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                if oth.is_monotonic_decreasing:\\n                    o_first, o_last = o_last, o_first\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                if s_last < o_first or o_last < s_first:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    res = self.copy(deep=False)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    res.name = self.name\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    return res\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        except Exception:\\n            pass\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>         )\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_body = body[:insert_at] + fast + body[insert_at:]\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_s = s[:start] + new_body + s[end:]\r\n\u001b[?2004l\r\n\u001b[?2004h>         p.write_text(new_s)\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('Patched base.Index.difference with fastpath_disjoint')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nPatched base.Index.difference with fastpath_disjoint\r\n"]
[425.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[425.002, "i", "python - << 'PY'\r"]
[425.004, "o", "python - << 'PY'\r\n"]
[425.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import pandas as pd\r\n\u001b[?2004l\r\n\u001b[?2004h> print('pandas imported; version:', pd.__version__)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Disjoint monotonic\r\n\u001b[?2004l\r\n\u001b[?2004h> left = pd.DatetimeIndex(range(1000))\r\n\u001b[?2004l\r\n\u001b[?2004h> right = pd.DatetimeIndex(range(1000, 2000))\r\n\u001b[?2004l\r\n\u001b[?2004h> res = left.difference(right)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('len(res)=', len(res))\r\n\u001b[?2004l\r\n\u001b[?2004h> assert res.equals(left)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Overlapping to ensure correctness\r\n\u001b[?2004l\r\n\u001b[?2004h> left2 = pd.DatetimeIndex(range(10))\r\n\u001b[?2004l\r\n\u001b[?2004h> right2 = pd.DatetimeIndex(range(5, 15))\r\n\u001b[?2004l\r\n\u001b[?2004h> res2 = left2.difference(right2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('len(res2)=', len(res2), 'first=', res2[0])\r\n\u001b[?2004l\r\n\u001b[?2004h> assert len(res2) == 5 and res2[0] == left2[0]\r\n\u001b[?2004l\r\n\u001b[?2004h> print('basic checks passed')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n    from pandas.core.api import (\r\n  File \"/workspace/repo/pandas/core/api.py\", line 47, in <module>\r\n    from pandas.core.groupby import (\r\n  File \"/workspace/repo/pandas/core/groupby/__init__.py\", line 1, in <module>\r\n    from pandas.core.groupby.generic import (\r\n  File \"/workspace/repo/pandas/core/groupby/generic.py\", line 79, in <module>\r\n    from pandas.core.frame import DataFrame\r\n  File \"/workspace/repo/pandas/core/frame.py\", line 184, in <module>\r\n    from pandas.core.generic import NDFrame\r\n  File \"/workspace/repo/pandas/core/generic.py\", line 137, in <module>\r\n    from pandas.core import (\r\n  File \"/workspace/repo/pandas/core/indexing.py\", line 77, in <module>\r\n    from pandas.core.indexes.api import (\r\n  File \"/workspace/repo/pandas/core/indexes/api.py\", line 18, in <module>\r\n    from pandas.core.indexes.base import (\r\n  File \"/workspace/repo/pandas/core/indexes/base.py\", line 3399\r\n    if hasattr(oth, 'is_monotonic_increasing') and len(oth) > 0 and \r\n                                                                   ^\r\nSyntaxError: invalid syntax\r\n"]
[430.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[430.002, "i", "git add -A && git commit -m \"Optimize Index.difference: add fastpath for disjoint monotonic indexes to avoid set ope\r"]
[430.004, "o", "git add -A && git commit -m \"Optimize Index.difference: add fastpath for disjoint monotonic indexes to avoid set ope\r\n"]
[430.006, "o", "erations\"\r\n\u001b[?2004l\r\nAuthor identity unknown\r\n\r\n*** Please tell me who you are.\r\n\r\nRun\r\n\r\n  git config --global user.email \"you@example.com\"\r\n  git config --global user.name \"Your Name\"\r\n\r\nto set your account's default identity.\r\nOmit --global to set the identity only in this repository.\r\n\r\nfatal: unable to auto-detect email address (got 'root@c510d3ab122e.(none)')\r\n"]
[435.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[435.002, "i", "cd asv_bench\r"]
[435.004, "o", "cd asv_bench\r\n"]
[435.006, "o", "\u001b[?2004l\r\n"]
[440.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[440.002, "i", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r"]
[440.004, "o", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r\n"]
[440.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp0zgv7kib/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   \r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 47, in <module>\r\n       from pandas.core.groupby import (\r\n     File \"/workspace/repo/pandas/core/groupby/__init__.py\", line 1, in <module>\r\n       from pandas.core.groupby.generic import (\r\n     File \"/workspace/repo/pandas/core/groupby/generic.py\", line 79, in <module>\r\n       from pandas.core.frame import DataFrame\r\n     File \"/workspace/repo/pandas/core/frame.py\", line 184, in <module>\r\n       from pandas.core.generic import NDFrame\r\n     File \"/workspace/repo/pandas/core/generic.py\", line 137, in <module>\r\n       from pandas.core import (\r\n     File \"/workspace/repo/pandas/core/indexing.py\", line 77, in <module>\r\n       from pandas.core.indexes.api import (\r\n     File \"/workspace/repo/pandas/core/indexes/api.py\", line 18, in <module>\r\n       from pandas.core.indexes.base import (\r\n     File \"/workspace/repo/pandas/core/indexes/base.py\", line 3399\r\n       if hasattr(oth, 'is_monotonic_increasing') and len(oth) > 0 and \r\n                                                                      ^\r\n   SyntaxError: invalid syntax\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp0zgv7kib/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[445.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[445.002, "i", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r"]
[445.004, "o", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r\n"]
[445.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpeiuix470/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   \r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 47, in <module>\r\n       from pandas.core.groupby import (\r\n     File \"/workspace/repo/pandas/core/groupby/__init__.py\", line 1, in <module>\r\n       from pandas.core.groupby.generic import (\r\n     File \"/workspace/repo/pandas/core/groupby/generic.py\", line 79, in <module>\r\n       from pandas.core.frame import DataFrame\r\n     File \"/workspace/repo/pandas/core/frame.py\", line 184, in <module>\r\n       from pandas.core.generic import NDFrame\r\n     File \"/workspace/repo/pandas/core/generic.py\", line 137, in <module>\r\n       from pandas.core import (\r\n     File \"/workspace/repo/pandas/core/indexing.py\", line 77, in <module>\r\n       from pandas.core.indexes.api import (\r\n     File \"/workspace/repo/pandas/core/indexes/api.py\", line 18, in <module>\r\n       from pandas.core.indexes.base import (\r\n     File \"/workspace/repo/pandas/core/indexes/base.py\", line 3399\r\n       if hasattr(oth, 'is_monotonic_increasing') and len(oth) > 0 and \r\n                                                                      ^\r\n   SyntaxError: invalid syntax\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpeiuix470/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[450.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[450.002, "i", "sed -n '3370,3420p' pandas/core/indexes/base.py\r"]
[450.004, "o", "sed -n '3370,3420p' pandas/core/indexes/base.py\r\n"]
[450.006, "o", "\u001b[?2004l\r\nsed: can't read pandas/core/indexes/base.py: No such file or directory\r\n"]
[455.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[455.002, "i", "python - << 'PY'\r"]
[455.004, "o", "python - << 'PY'\r\n"]
[455.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/indexes/base.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> start_marker = '# fastpath_disjoint'\r\n\u001b[?2004l\r\n\u001b[?2004h> si = s.find(start_marker)\r\n\u001b[?2004l\r\n\u001b[?2004h> if si == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('fastpath_disjoint marker not found; aborting patch')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     # find end of try-block we inserted by locating the 'except Exception' that follows\r\n\u001b[?2004l\r\n\u001b[?2004h>     ei = s.find('except Exception', si)\r\n\u001b[?2004l\r\n\u001b[?2004h>     if ei == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('could not locate except Exception after fastpath; aborting patch')\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         # Find end of the 'pass' line after except to replace whole block cleanly\r\n\u001b[?2004l\r\n\u001b[?2004h>         pi = s.find('\\n', ei)\r\n\u001b[?2004l\r\n\u001b[?2004h>         if pi == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>             pi = ei\r\n\u001b[?2004l\r\n\u001b[?2004h>         # Build corrected fastpath block\r\n\u001b[?2004l\r\n\u001b[?2004h>         fast = (\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"# fastpath_disjoint: if both indexes are monotonic and non-overlapping by bounds,\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        # return self unchanged to avoid expensive set operations.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        try:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            oth = other\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            if len(self) == 0:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                return self.copy(deep=False)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            # Only proceed if 'other' looks like an Index (has monotonic attrs) and is non-empty\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            if hasattr(oth, 'is_monotonic_increasing') and len(oth) > 0 and ((self.is_monotonic_increasing or self.is_monotonic_decreasing) and (o\r\noth.is_monotonic_increasing or oth.is_monotonic_decreasing)):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                s_first, s_last = self[0], self[-1]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                o_first, o_last = oth[0], oth[-1]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                if self.is_monotonic_decreasing:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    s_first, s_last = s_last, s_first\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                if oth.is_monotonic_decreasing:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    o_first, o_last = o_last, o_first\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                # If ranges do not overlap at all, the difference is self\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                if s_last < o_first or o_last < s_first:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    res = self.copy(deep=False)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    res.name = self.name\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"                    return res\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"        except Exception:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            # Fall back to full implementation on any issue\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             \"            pass\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>         )\r\n\u001b[?2004l\r\n\u001b[?2004h>         # Replace from the start of our marker up to the end of the except/pass block\r\n\u001b[?2004l\r\n\u001b[?2004h>         pre = s[:si]\r\n\u001b[?2004l\r\n\u001b[?2004h>         # Find the end of the 'pass' line (next newline after except/pass)\r\n\u001b[?2004l\r\n\u001b[?2004h>         end_of_block = s.find('\\n', pi + 1)\r\n\u001b[?2004l\r\n\u001b[?2004h>         if end_of_block == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>             end_of_block = len(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>         post = s[end_of_block:]\r\n\u001b[?2004l\r\n\u001b[?2004h>         # Reconstruct with correct fastpath block at same indentation (assumed 8 spaces at this point in code)\r\n\u001b[?2004l\r\n\u001b[?2004h>         indent = '        '\r\n\u001b[?2004l\r\n\u001b[?2004h>         fixed_block = indent + fast\r\n\u001b[?2004l\r\n\u001b[?2004h>         new_s = pre + fixed_block + post\r\n\u001b[?2004l\r\n\u001b[?2004h>         p.write_text(new_s)\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('Replaced fastpath_disjoint block with corrected syntax')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 3, in <module>\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1236, in read_text\r\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1222, in open\r\n    return io.open(self, mode, buffering, encoding, errors, newline,\r\n  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1078, in _opener\r\n    return self._accessor.open(self, flags, mode)\r\nFileNotFoundError: [Errno 2] No such file or directory: 'pandas/core/indexes/base.py'\r\n"]
[460.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[460.002, "i", "python - << 'PY'\r"]
[460.004, "o", "python - << 'PY'\r\n"]
[460.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import pandas as pd\r\n\u001b[?2004l\r\n\u001b[?2004h> print('pandas import OK; version:', pd.__version__)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Disjoint monotonic case\r\n\u001b[?2004l\r\n\u001b[?2004h> left = pd.DatetimeIndex(range(1000))\r\n\u001b[?2004l\r\n\u001b[?2004h> right = pd.DatetimeIndex(range(1000, 2000))\r\n\u001b[?2004l\r\n\u001b[?2004h> res = left.difference(right)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('len(res)=', len(res))\r\n\u001b[?2004l\r\n\u001b[?2004h> assert res.equals(left)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Overlapping case must still be correct\r\n\u001b[?2004l\r\n\u001b[?2004h> left2 = pd.DatetimeIndex(range(10))\r\n\u001b[?2004l\r\n\u001b[?2004h> right2 = pd.DatetimeIndex(range(5, 15))\r\n\u001b[?2004l\r\n\u001b[?2004h> res2 = left2.difference(right2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('len(res2)=', len(res2), 'first=', res2[0])\r\n\u001b[?2004l\r\n\u001b[?2004h> assert len(res2) == 5 and res2[0] == left2[0]\r\n\u001b[?2004l\r\n\u001b[?2004h> print('basic checks passed')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n    from pandas.core.api import (\r\n  File \"/workspace/repo/pandas/core/api.py\", line 47, in <module>\r\n    from pandas.core.groupby import (\r\n  File \"/workspace/repo/pandas/core/groupby/__init__.py\", line 1, in <module>\r\n    from pandas.core.groupby.generic import (\r\n  File \"/workspace/repo/pandas/core/groupby/generic.py\", line 79, in <module>\r\n    from pandas.core.frame import DataFrame\r\n  File \"/workspace/repo/pandas/core/frame.py\", line 184, in <module>\r\n    from pandas.core.generic import NDFrame\r\n  File \"/workspace/repo/pandas/core/generic.py\", line 137, in <module>\r\n    from pandas.core import (\r\n  File \"/workspace/repo/pandas/core/indexing.py\", line 77, in <module>\r\n    from pandas.core.indexes.api import (\r\n  File \"/workspace/repo/pandas/core/indexes/api.py\", line 18, in <module>\r\n    from pandas.core.indexes.base import (\r\n  File \"/workspace/repo/pandas/core/indexes/base.py\", line 3399\r\n    if hasattr(oth, 'is_monotonic_increasing') and len(oth) > 0 and \r\n                                                                   ^\r\nSyntaxError: invalid syntax\r\n"]
[465.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[465.002, "i", "git add -A && git commit -m \"Fix syntax and finalize fastpath for Index.difference: early return for disjo\r"]
[465.004, "o", "git add -A && git commit -m \"Fix syntax and finalize fastpath for Index.difference: early return for disjo\r\n"]
[465.006, "o", "oint monotonic indexes\"\r\n\u001b[?2004l\r\nAuthor identity unknown\r\n\r\n*** Please tell me who you are.\r\n\r\nRun\r\n\r\n  git config --global user.email \"you@example.com\"\r\n  git config --global user.name \"Your Name\"\r\n\r\nto set your account's default identity.\r\nOmit --global to set the identity only in this repository.\r\n\r\nfatal: unable to auto-detect email address (got 'root@c510d3ab122e.(none)')\r\n"]
[470.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[470.002, "i", "cd asv_bench\r"]
[470.004, "o", "cd asv_bench\r\n"]
[470.006, "o", "\u001b[?2004l\r\n-bash: cd: asv_bench: No such file or directory\r\n"]
[475.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[475.002, "i", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r"]
[475.004, "o", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r\n"]
[475.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpa3x4h9ed/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   \r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 47, in <module>\r\n       from pandas.core.groupby import (\r\n     File \"/workspace/repo/pandas/core/groupby/__init__.py\", line 1, in <module>\r\n       from pandas.core.groupby.generic import (\r\n     File \"/workspace/repo/pandas/core/groupby/generic.py\", line 79, in <module>\r\n       from pandas.core.frame import DataFrame\r\n     File \"/workspace/repo/pandas/core/frame.py\", line 184, in <module>\r\n       from pandas.core.generic import NDFrame\r\n     File \"/workspace/repo/pandas/core/generic.py\", line 137, in <module>\r\n       from pandas.core import (\r\n     File \"/workspace/repo/pandas/core/indexing.py\", line 77, in <module>\r\n       from pandas.core.indexes.api import (\r\n     File \"/workspace/repo/pandas/core/indexes/api.py\", line 18, in <module>\r\n       from pandas.core.indexes.base import (\r\n     File \"/workspace/repo/pandas/core/indexes/base.py\", line 3399\r\n       if hasattr(oth, 'is_monotonic_increasing') and len(oth) > 0 and \r\n                                                                      ^\r\n   SyntaxError: invalid syntax\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpa3x4h9ed/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[480.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[480.002, "i", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r"]
[480.004, "o", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r\n"]
[480.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpzcsbyg4q/result.json (exit status 1)\u001b[0m\r\n   STDOUT -------->\r\n   \r\n   STDERR -------->\r\n   Traceback (most recent call last):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n       main()\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n       commands[mode](args)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n       list_benchmarks(benchmark_dir, fp)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n       for benchmark in disc_benchmarks(root):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n       yield from disc_modules(name, ignore_import_errors)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n       module = importlib.import_module(module_name)\r\n     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n       return _bootstrap._gcd_import(name[level:], package, level)\r\n     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n       import pandas as pd\r\n     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n       from pandas.core.api import (\r\n     File \"/workspace/repo/pandas/core/api.py\", line 47, in <module>\r\n       from pandas.core.groupby import (\r\n     File \"/workspace/repo/pandas/core/groupby/__init__.py\", line 1, in <module>\r\n       from pandas.core.groupby.generic import (\r\n     File \"/workspace/repo/pandas/core/groupby/generic.py\", line 79, in <module>\r\n       from pandas.core.frame import DataFrame\r\n     File \"/workspace/repo/pandas/core/frame.py\", line 184, in <module>\r\n       from pandas.core.generic import NDFrame\r\n     File \"/workspace/repo/pandas/core/generic.py\", line 137, in <module>\r\n       from pandas.core import (\r\n     File \"/workspace/repo/pandas/core/indexing.py\", line 77, in <module>\r\n       from pandas.core.indexes.api import (\r\n     File \"/workspace/repo/pandas/core/indexes/api.py\", line 18, in <module>\r\n       from pandas.core.indexes.base import (\r\n     File \"/workspace/repo/pandas/core/indexes/base.py\", line 3399\r\n       if hasattr(oth, 'is_monotonic_increasing') and len(oth) > 0 and \r\n                                                                      ^\r\n   SyntaxError: invalid syntax\r\n\r\n\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpzcsbyg4q/result.json' returned non-zero exit status 1\u001b[0m\r\n\u00b7\u00b7 \u001b[0;31mFailed to build the project and import the benchmark suite.\u001b[0m\r\n"]
[485.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[485.002, "i", "cd ..\r"]
[485.004, "o", "cd ..\r\n"]
[485.006, "o", "\u001b[?2004l\r\n"]
[490.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[490.002, "i", "sed -n '3380,3420p' pandas/core/indexes/base.py\r"]
[490.004, "o", "sed -n '3380,3420p' pandas/core/indexes/base.py\r\n"]
[490.006, "o", "\u001b[?2004l\r\n        if sort is False:\r\n            # sort bc we want the elements in the same order they are in self\r\n            # unnecessary in the case with sort=None bc we will sort later\r\n            taker = np.sort(taker)\r\n\r\n        if isinstance(left_unique, ABCMultiIndex):\r\n            result = left_unique.take(taker)\r\n        else:\r\n            result = left_unique.take(taker)._values\r\n        return result\r\n\r\n    @final\r\n    def difference(self, other, sort=None):\r\n        # fastpath_disjoint: if both indexes are monotonic and non-overlapping by bounds,\r\n        # return self unchanged to avoid expensive set operations.\r\n        try:\r\n            oth = other\r\n            if len(self) == 0:\r\n                return self.copy(deep=False)\r\n            if hasattr(oth, 'is_monotonic_increasing') and len(oth) > 0 and \r\n               (self.is_monotonic_increasing or self.is_monotonic_decreasing) and \r\n               (oth.is_monotonic_increasing or oth.is_monotonic_decreasing):\r\n                s_first, s_last = self[0], self[-1]\r\n                o_first, o_last = oth[0], oth[-1]\r\n                if self.is_monotonic_decreasing:\r\n                    s_first, s_last = s_last, s_first\r\n                if oth.is_monotonic_decreasing:\r\n                    o_first, o_last = o_last, o_first\r\n                if s_last < o_first or o_last < s_first:\r\n                    res = self.copy(deep=False)\r\n                    res.name = self.name\r\n                    return res\r\n        except Exception:\r\n            pass\r\n\r\n        \"\"\"\r\n        Return a new Index with elements of index not in `other`.\r\n\r\n        This is the set difference of two Index objects.\r\n\r\n        Parameters\r\n"]
[495.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[495.002, "i", "python - << 'PY'\r"]
[495.004, "o", "python - << 'PY'\r\n"]
[495.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> from pathlib import Path\r\n\u001b[?2004l\r\n\u001b[?2004h> p = Path('pandas/core/indexes/base.py')\r\n\u001b[?2004l\r\n\u001b[?2004h> s = p.read_text()\r\n\u001b[?2004l\r\n\u001b[?2004h> start = s.find('# fastpath_disjoint')\r\n\u001b[?2004l\r\n\u001b[?2004h> if start == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>     print('fastpath_disjoint marker not found; nothing to fix')\r\n\u001b[?2004l\r\n\u001b[?2004h> else:\r\n\u001b[?2004l\r\n\u001b[?2004h>     # Find the 'except Exception' following our inserted block and its trailing 'pass' line\r\n\u001b[?2004l\r\n\u001b[?2004h>     ex = s.find('except Exception', start)\r\n\u001b[?2004l\r\n\u001b[?2004h>     if ex == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>         print('except Exception not found after fastpath; abort')\r\n\u001b[?2004l\r\n\u001b[?2004h>     else:\r\n\u001b[?2004l\r\n\u001b[?2004h>         # Find end of the 'pass' line after except\r\n\u001b[?2004l\r\n\u001b[?2004h>         pass_line_start = s.find('pass', ex)\r\n\u001b[?2004l\r\n\u001b[?2004h>         if pass_line_start == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>             print('pass after except not found; abort')\r\n\u001b[?2004l\r\n\u001b[?2004h>         else:\r\n\u001b[?2004l\r\n\u001b[?2004h>             pass_line_end = s.find('\\n', pass_line_start)\r\n\u001b[?2004l\r\n\u001b[?2004h>             if pass_line_end == -1:\r\n\u001b[?2004l\r\n\u001b[?2004h>                 pass_line_end = len(s)\r\n\u001b[?2004l\r\n\u001b[?2004h>             # Build corrected fastpath block with proper parentheses and indentation (8 spaces)\r\n\u001b[?2004l\r\n\u001b[?2004h>             fixed = (\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"# fastpath_disjoint: if both indexes are monotonic and non-overlapping by bounds,\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"        # return self unchanged to avoid expensive set operations.\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"        try:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"            oth = other\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"            if len(self) == 0:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                return self.copy(deep=False)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"            if (\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                hasattr(oth, 'is_monotonic_increasing')\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                and len(oth) > 0\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                and (self.is_monotonic_increasing or self.is_monotonic_decreasing)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                and (oth.is_monotonic_increasing or oth.is_monotonic_decreasing)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"            ):\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                s_first, s_last = self[0], self[-1]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                o_first, o_last = oth[0], oth[-1]\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                if self.is_monotonic_decreasing:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                    s_first, s_last = s_last, s_first\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                if oth.is_monotonic_decreasing:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                    o_first, o_last = o_last, o_first\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                # If ranges do not overlap at all, the difference is self\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                if s_last < o_first or o_last < s_first:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                    res = self.copy(deep=False)\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                    res.name = self.name\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"                    return res\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"        except Exception:\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"            # Fall back to full implementation on any issue\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>                 \"            pass\\n\"\r\n\u001b[?2004l\r\n\u001b[?2004h>             )\r\n\u001b[?2004l\r\n\u001b[?2004h>             new_s = s[:start] + fixed + s[pass_line_end:]\r\n\u001b[?2004l\r\n\u001b[?2004h>             p.write_text(new_s)\r\n\u001b[?2004l\r\n\u001b[?2004h>             print('Patched fastpath_disjoint block with correct syntax')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\nPatched fastpath_disjoint block with correct syntax\r\n"]
[500.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[500.002, "i", "python - << 'PY'\r"]
[500.004, "o", "python - << 'PY'\r\n"]
[500.006, "o", "\u001b[?2004l\r\n\u001b[?2004h> import pandas as pd\r\n\u001b[?2004l\r\n\u001b[?2004h> print('pandas import OK; version:', pd.__version__)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Disjoint monotonic case\r\n\u001b[?2004l\r\n\u001b[?2004h> left = pd.DatetimeIndex(range(1000))\r\n\u001b[?2004l\r\n\u001b[?2004h> right = pd.DatetimeIndex(range(1000, 2000))\r\n\u001b[?2004l\r\n\u001b[?2004h> res = left.difference(right)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('len(res)=', len(res))\r\n\u001b[?2004l\r\n\u001b[?2004h> assert res.equals(left)\r\n\u001b[?2004l\r\n\u001b[?2004h> # Overlapping case must still be correct\r\n\u001b[?2004l\r\n\u001b[?2004h> left2 = pd.DatetimeIndex(range(10))\r\n\u001b[?2004l\r\n\u001b[?2004h> right2 = pd.DatetimeIndex(range(5, 15))\r\n\u001b[?2004l\r\n\u001b[?2004h> res2 = left2.difference(right2)\r\n\u001b[?2004l\r\n\u001b[?2004h> print('len(res2)=', len(res2), 'first=', res2[0])\r\n\u001b[?2004l\r\n\u001b[?2004h> assert len(res2) == 5 and res2[0] == left2[0]\r\n\u001b[?2004l\r\n\u001b[?2004h> print('basic checks passed')\r\n\u001b[?2004l\r\n\u001b[?2004h> PY\r\n\u001b[?2004l\r\npandas import OK; version: 0+untagged.31331.g57c6533.dirty\r\nlen(res)= 1000\r\nlen(res2)= 5 first= 1970-01-01 00:00:00\r\nbasic checks passed\r\n"]
[505.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[505.002, "i", "git add -A && git commit -m \"Fix syntax for Index.difference fastpath: properly parenthesized multi-line condition\" \r"]
[505.004, "o", "git add -A && git commit -m \"Fix syntax for Index.difference fastpath: properly parenthesized multi-line condition\" \r\n"]
[510.0, "o", "\u001bM(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[510.002, "i", "git add -A && git commit -m \"Fix syntax for Index.difference fastpath: properly parenthesized multi-line condition\u001b[K\"\r"]
[510.004, "o", "git add -A && git commit -m \"Fix syntax for Index.difference fastpath: properly parenthesized multi-line condition\u001b[K\"\r\n"]
[510.006, "o", "\u001b[?2004l\r\nAuthor identity unknown\r\n\r\n*** Please tell me who you are.\r\n\r\nRun\r\n\r\n  git config --global user.email \"you@example.com\"\r\n  git config --global user.name \"Your Name\"\r\n\r\nto set your account's default identity.\r\nOmit --global to set the identity only in this repository.\r\n\r\nfatal: unable to auto-detect email address (got 'root@c510d3ab122e.(none)')\r\n"]
[515.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo# "]
[515.002, "i", "cd asv_bench\r"]
[515.004, "o", "cd asv_bench\r\n"]
[515.006, "o", "\u001b[?2004l\r\n"]
[520.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[520.002, "i", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r"]
[520.004, "o", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r\n"]
[520.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                                 476\u00b10\u03bcs\r\n"]
[525.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[525.002, "i", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r"]
[525.004, "o", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r\n"]
[525.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (index_object.SetDisjoint.time_datetime_difference_disjoint--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                              21.7\u00b10.8\u03bcs\r\n\r\nWed Oct  1 19:27:04 2025    /tmp/tmpuo3uvnik\r\n\r\n         136 function calls (134 primitive calls) in 0.000 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.000    0.000 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.000    0.000 index_object.py:63(time_datetime_difference_disjoint)\r\n        1    0.000    0.000    0.000    0.000 base.py:3391(difference)\r\n        3    0.000    0.000    0.000    0.000 base.py:2087(is_monotonic_increasing)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        4    0.000    0.000    0.000    0.000 base.py:5110(__getitem__)\r\n        4    0.000    0.000    0.000    0.000 datetimelike.py:359(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 base.py:1135(copy)\r\n        4    0.000    0.000    0.000    0.000 _mixins.py:267(__getitem__)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:526(_box_func)\r\n        2    0.000    0.000    0.000    0.000 base.py:786(_engine)\r\n        1    0.000    0.000    0.000    0.000 base.py:1560(_validate_names)\r\n        1    0.000    0.000    0.000    0.000 frozen.py:73(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 base.py:735(_rename)\r\n        1    0.000    0.000    0.000    0.000 base.py:726(_view)\r\n        1    0.000    0.000    0.000    0.000 base.py:611(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 common.py:1638(validate_all_hashable)\r\n        4    0.000    0.000    0.000    0.000 {built-in method _from_value_and_reso}\r\n        4    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.generic' objects}\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:673(_get_engine_target)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:1932(_creso)\r\n        1    0.000    0.000    0.000    0.000 base.py:1549(name)\r\n      6/4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 common.py:1657(<genexpr>)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:557(tz)\r\n        7    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        2    0.000    0.000    0.000    0.000 extension.py:70(fget)\r\n        1    0.000    0.000    0.000    0.000 base.py:7113(maybe_extract_name)\r\n        2    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        7    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        4    0.000    0.000    0.000    0.000 common.py:150(cast_scalar_indexer)\r\n        2    0.000    0.000    0.000    0.000 base.py:838(__len__)\r\n        2    0.000    0.000    0.000    0.000 inference.py:322(is_hashable)\r\n        2    0.000    0.000    0.000    0.000 common.py:1128(needs_i8_conversion)\r\n        2    0.000    0.000    0.000    0.000 base.py:1628(_get_names)\r\n        6    0.000    0.000    0.000    0.000 datetimes.py:532(dtype)\r\n        8    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\r\n        1    0.000    0.000    0.000    0.000 generic.py:42(_instancecheck)\r\n        4    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\r\n        6    0.000    0.000    0.000    0.000 typing.py:1149(cast)\r\n        2    0.000    0.000    0.000    0.000 datetimes.py:248(_engine_type)\r\n        2    0.000    0.000    0.000    0.000 base.py:2111(is_monotonic_decreasing)\r\n        3    0.000    0.000    0.000    0.000 base.py:1542(name)\r\n        1    0.000    0.000    0.000    0.000 generic.py:37(_check)\r\n        4    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\r\n        1    0.000    0.000    0.000    0.000 base.py:775(_reset_identity)\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x5589a526e680}\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        2    0.000    0.000    0.000    0.000 {pandas._libs.tslibs.np_datetime.py_get_unit_from_dtype}\r\n        1    0.000    0.000    0.000    0.000 base.py:4900(_values)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 {function FrozenList.__getitem__ at 0x7f20d544a280}\r\n\r\n\r\n"]
[530.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[530.002, "i", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r"]
[530.004, "o", "asv run --python=same --bench=\"index_object.SetDisjoint.*\" --quick\r\n"]
[530.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                                 480\u00b10\u03bcs\r\n"]
[535.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[535.002, "i", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r"]
[535.004, "o", "asv profile --python=same index_object.SetDisjoint.time_datetime_difference_disjoint\r\n"]
[535.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n\u00b7\u00b7\u00b7 \u001b[0;39mRunning (index_object.SetDisjoint.time_datetime_difference_disjoint--)\u001b[0m.\r\n\u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                              22.1\u00b10.4\u03bcs\r\n\r\nWed Oct  1 19:28:46 2025    /tmp/tmpi3v5665d\r\n\r\n         136 function calls (134 primitive calls) in 0.000 seconds\r\n\r\n   Ordered by: cumulative time\r\n\r\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\r\n        1    0.000    0.000    0.000    0.000 _base.py:689(method_caller)\r\n        1    0.000    0.000    0.000    0.000 index_object.py:63(time_datetime_difference_disjoint)\r\n        1    0.000    0.000    0.000    0.000 base.py:3391(difference)\r\n        3    0.000    0.000    0.000    0.000 base.py:2087(is_monotonic_increasing)\r\n        4    0.000    0.000    0.000    0.000 base.py:5110(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\r\n        1    0.000    0.000    0.000    0.000 base.py:1135(copy)\r\n        4    0.000    0.000    0.000    0.000 datetimelike.py:359(__getitem__)\r\n        4    0.000    0.000    0.000    0.000 _mixins.py:267(__getitem__)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:526(_box_func)\r\n        2    0.000    0.000    0.000    0.000 base.py:786(_engine)\r\n        1    0.000    0.000    0.000    0.000 base.py:735(_rename)\r\n        1    0.000    0.000    0.000    0.000 frozen.py:73(__getitem__)\r\n        1    0.000    0.000    0.000    0.000 base.py:726(_view)\r\n        1    0.000    0.000    0.000    0.000 base.py:1560(_validate_names)\r\n        1    0.000    0.000    0.000    0.000 base.py:611(_simple_new)\r\n        1    0.000    0.000    0.000    0.000 common.py:1638(validate_all_hashable)\r\n        4    0.000    0.000    0.000    0.000 {built-in method _from_value_and_reso}\r\n        4    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.generic' objects}\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:673(_get_engine_target)\r\n        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\r\n        1    0.000    0.000    0.000    0.000 base.py:1549(name)\r\n        2    0.000    0.000    0.000    0.000 datetimelike.py:1932(_creso)\r\n        2    0.000    0.000    0.000    0.000 common.py:1657(<genexpr>)\r\n        4    0.000    0.000    0.000    0.000 datetimes.py:557(tz)\r\n        1    0.000    0.000    0.000    0.000 base.py:7113(maybe_extract_name)\r\n        7    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n        2    0.000    0.000    0.000    0.000 extension.py:70(fget)\r\n      6/4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\r\n        2    0.000    0.000    0.000    0.000 inference.py:322(is_hashable)\r\n        7    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n        4    0.000    0.000    0.000    0.000 common.py:150(cast_scalar_indexer)\r\n        2    0.000    0.000    0.000    0.000 base.py:1628(_get_names)\r\n        2    0.000    0.000    0.000    0.000 base.py:838(__len__)\r\n        2    0.000    0.000    0.000    0.000 common.py:1128(needs_i8_conversion)\r\n        2    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\r\n        6    0.000    0.000    0.000    0.000 datetimes.py:532(dtype)\r\n        1    0.000    0.000    0.000    0.000 generic.py:42(_instancecheck)\r\n        8    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\r\n        4    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\r\n        2    0.000    0.000    0.000    0.000 datetimes.py:248(_engine_type)\r\n        2    0.000    0.000    0.000    0.000 base.py:2111(is_monotonic_decreasing)\r\n        6    0.000    0.000    0.000    0.000 typing.py:1149(cast)\r\n        1    0.000    0.000    0.000    0.000 generic.py:37(_check)\r\n        3    0.000    0.000    0.000    0.000 base.py:1542(name)\r\n        1    0.000    0.000    0.000    0.000 base.py:775(_reset_identity)\r\n        2    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\r\n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55e964811680}\r\n        4    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\r\n        2    0.000    0.000    0.000    0.000 {pandas._libs.tslibs.np_datetime.py_get_unit_from_dtype}\r\n        1    0.000    0.000    0.000    0.000 base.py:4900(_values)\r\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n        1    0.000    0.000    0.000    0.000 {function FrozenList.__getitem__ at 0x7f7b90fb5280}\r\n\r\n\r\n"]
[540.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[540.002, "i", "asv run --python=same --bench=\"index_object.SetDisjoint.time_datetime_difference_disjoint\" --quick\r"]
[540.004, "o", "asv run --python=same --bench=\"index_object.SetDisjoint.time_datetime_difference_disjoint\" --quick\r\n"]
[540.006, "o", "\u001b[?2004l\r\n\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n\u00b7 \u001b[0;32mRunning 1 total benchmarks (1 commits * 1 environments * 1 benchmarks)\u001b[0m\r\n[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n[50.00%] \u00b7\u00b7\u00b7 \u001b[0;39mindex_object.SetDisjoint.time_datetime_difference_disjoint\u001b[0m                                                                                 507\u00b10\u03bcs\r\n"]
[545.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[545.002, "i", "git log -1 --stat\r"]
[545.004, "o", "git log -1 --stat\r\n"]
[545.006, "o", "\u001b[?2004l\r\nerror: cannot run less: No such file or directory\r\nfatal: unable to execute pager 'less'\r\n"]
[550.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[550.002, "i", "git show --stat --oneline -1\r"]
[550.004, "o", "git show --stat --oneline -1\r\n"]
[550.006, "o", "\u001b[?2004l\r\nerror: cannot run less: No such file or directory\r\nfatal: unable to execute pager 'less'\r\n"]
[555.0, "o", "(asv_3.8) root@c510d3ab122e:/workspace/repo/asv_bench# "]
[555.002, "i", "\u001b[?2004l\r"]
[555.004, "o", "\u001b[?2004l\r\n"]
[555.006, "o", "\r\nlogout\r\n"]
