{"version": 2, "width": 160, "height": 40, "timestamp": 1762994833, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[1.242, "o", "\u001b[?2004l\r\n"]
[2.478, "o", "\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n"]
[3.714, "o", "\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[7.478, "o", "\u001b[?2004l\r\n"]
[10.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.136105, "o", "\u001b[?2004l\r\n"]
[10.266211, "o", "total 212\r\n"]
[10.396316, "o", "drwxr-xr-x 1 root root  4096 Oct  1 17:33 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[10.526421, "o", "drwxr-xr-x 1 root root  4096 Sep 15 17:16 \u001b[01;34m..\u001b[0m\r\n"]
[10.656526, "o", "drwxr-xr-x 2 root root  4096 Sep 13 19:22 \u001b[01;34m.circleci\u001b[0m\r\n"]
[10.786632, "o", "-rw-r--r-- 1 root root  1021 Sep 13 19:22 .devcontainer.json\r\n"]
[10.916737, "o", "drwxr-xr-x 1 root root  4096 Oct  1 17:33 \u001b[01;34m.git\u001b[0m\r\n"]
[11.046842, "o", "-rw-r--r-- 1 root root   229 Sep 13 19:22 .gitattributes\r\n"]
[11.176947, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:22 \u001b[01;34m.github\u001b[0m\r\n"]
[11.307053, "o", "-rw-r--r-- 1 root root  1740 Sep 13 19:22 .gitignore\r\n"]
[11.437158, "o", "-rw-r--r-- 1 root root  2322 Sep 13 19:22 .gitpod.yml\r\n"]
[11.567263, "o", "-rw-r--r-- 1 root root   761 Sep 13 19:22 .libcst.codemod.yaml\r\n"]
[11.697368, "o", "-rw-r--r-- 1 root root   109 Sep 13 19:22 .pep8speaks.yml\r\n"]
[11.827474, "o", "-rw-r--r-- 1 root root 16092 Sep 13 19:22 .pre-commit-config.yaml\r\n"]
[11.957579, "o", "-rw-r--r-- 1 root root  2284 Sep 13 19:22 AUTHORS.md\r\n"]
[12.087684, "o", "-rw-r--r-- 1 root root   372 Sep 13 19:22 CITATION.cff\r\n"]
[12.217789, "o", "-rw-r--r-- 1 root root   369 Sep 13 19:22 Dockerfile\r\n"]
[12.347895, "o", "-rw-r--r-- 1 root root  1634 Sep 13 19:22 LICENSE\r\n"]
[12.478, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:22 \u001b[01;34mLICENSES\u001b[0m\r\n"]
[12.608105, "o", "-rw-r--r-- 1 root root  1228 Sep 13 19:22 MANIFEST.in\r\n"]
[12.738211, "o", "-rw-r--r-- 1 root root 10387 Sep 13 19:22 README.md\r\n"]
[12.868316, "o", "-rw-r--r-- 1 root root   246 Sep 13 19:22 RELEASE.md\r\n"]
[12.998421, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:22 \u001b[01;34masv_bench\u001b[0m\r\n"]
[13.128526, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:22 \u001b[01;34mci\u001b[0m\r\n"]
[13.258632, "o", "-rw-r--r-- 1 root root   256 Sep 13 19:20 codecov.yml\r\n"]
[13.388737, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:22 \u001b[01;34mdoc\u001b[0m\r\n"]
[13.518842, "o", "-rw-r--r-- 1 root root  2112 Sep 13 19:22 environment.yml\r\n"]
[13.648947, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:22 \u001b[01;34mgitpod\u001b[0m\r\n"]
[13.779053, "o", "drwxr-xr-x 1 root root  4096 Sep 13 22:00 \u001b[01;34mpandas\u001b[0m\r\n"]
[13.909158, "o", "drwxr-xr-x 2 root root  4096 Sep 13 21:46 \u001b[01;34mpandas.egg-info\u001b[0m\r\n"]
[14.039263, "o", "-rw-r--r-- 1 root root 15351 Sep 13 19:22 pyproject.toml\r\n"]
[14.169368, "o", "-rw-r--r-- 1 root root  4429 Sep 13 19:22 pyright_reportGeneralTypeIssues.json\r\n"]
[14.299474, "o", "-rw-r--r-- 1 root root  1099 Sep 13 19:22 requirements-dev.txt\r\n"]
[14.429579, "o", "drwxr-xr-x 1 root root  4096 Sep 13 19:22 \u001b[01;34mscripts\u001b[0m\r\n"]
[14.559684, "o", "-rw-r--r-- 1 root root  2095 Sep 13 19:22 setup.cfg\r\n"]
[14.689789, "o", "-rwxr-xr-x 1 root root 21964 Sep 13 19:22 \u001b[01;32msetup.py\u001b[0m\r\n"]
[14.819895, "o", "drwxr-xr-x 2 root root  4096 Sep 13 19:20 \u001b[01;34mtypings\u001b[0m\r\n"]
[15.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[15.002, "i", "ls -la asv.conf.* || true\r"]
[15.004, "o", "ls -la asv.conf.* || true\r\n"]
[17.478, "o", "\u001b[?2004l\r\n"]
[20.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[20.002, "i", "grep -R \"series_methods\" -n . || true\r"]
[20.004, "o", "grep -R \"series_methods\" -n . || true\r\n"]
[20.9948, "o", "\u001b[?2004l\r\n"]
[21.9836, "o", "\u001b[35m\u001b[K./pandas/tests/resample/conftest.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K30\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kseries_methods\u001b[m\u001b[K = [\"nunique\"]\r\n"]
[22.9724, "o", "\u001b[35m\u001b[K./pandas/tests/resample/conftest.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K31\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[Kresample_methods = downsample_methods + upsample_methods + \u001b[01;31m\u001b[Kseries_methods\u001b[m\u001b[K\r\n"]
[23.9612, "o", "grep: ./.git/objects/pack/pack-ece4d485a4f8b9fb76f32ecec0ce6e8268077cba.pack: binary file matches\r\n"]
[25.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[25.002, "i", "grep -R \"ToNumpy\" -n . || true\r"]
[25.004, "o", "grep -R \"ToNumpy\" -n . || true\r\n"]
[26.242, "o", "\u001b[?2004l\r\n"]
[27.478, "o", "\u001b[35m\u001b[K./asv_bench/benchmarks/frame_methods.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K231\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[Kclass \u001b[01;31m\u001b[KToNumpy\u001b[m\u001b[K:\r\n"]
[28.714, "o", "\u001b[35m\u001b[K./asv_bench/benchmarks/series_methods.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K385\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[Kclass \u001b[01;31m\u001b[KToNumpy\u001b[m\u001b[K:\r\n"]
[30.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[30.002, "i", "git status -s\r"]
[30.004, "o", "git status -s\r\n"]
[30.006, "o", "\u001b[?2004l\r\n"]
[35.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[35.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[35.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[37.478, "o", "\u001b[?2004l\r\n"]
[40.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[40.002, "i", "ls -la asv_bench\r"]
[40.004, "o", "ls -la asv_bench\r\n"]
[40.83, "o", "\u001b[?2004l\r\n"]
[41.654, "o", "total 24\r\n"]
[42.478, "o", "drwxr-xr-x 1 root root 4096 Sep 13 19:22 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[43.302, "o", "drwxr-xr-x 1 root root 4096 Oct  1 17:33 \u001b[01;34m..\u001b[0m\r\n"]
[44.126, "o", "-rw-r--r-- 1 root root 5217 Sep 13 19:22 asv.conf.json\r\n"]
[45.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[45.002, "i", "ls -la asv_bench/asv.conf.*\r"]
[45.004, "o", "ls -la asv_bench/asv.conf.*\r\n"]
[47.478, "o", "\u001b[?2004l\r\n"]
[50.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[50.002, "i", "sed -n '1,160p' asv_bench/benchmarks/series_methods.py\r"]
[50.004, "o", "sed -n '1,160p' asv_bench/benchmarks/series_methods.py\r\n"]
[50.036708, "o", "\u001b[?2004l\r\n"]
[50.067416, "o", "from datetime import datetime\r\n"]
[50.098124, "o", "\r\n"]
[50.128832, "o", "import numpy as np\r\n"]
[50.15954, "o", "\r\n"]
[50.190248, "o", "from pandas import (\r\n"]
[50.220957, "o", "    NA,\r\n"]
[50.251665, "o", "    Index,\r\n"]
[50.282373, "o", "    NaT,\r\n"]
[50.313081, "o", "    Series,\r\n"]
[50.343789, "o", "    date_range,\r\n"]
[50.374497, "o", ")\r\n"]
[50.405205, "o", "\r\n"]
[50.435913, "o", "from .pandas_vb_common import tm\r\n"]
[50.466621, "o", "\r\n"]
[50.497329, "o", "\r\n"]
[50.528037, "o", "class SeriesConstructor:\r\n"]
[50.558745, "o", "    def setup(self):\r\n"]
[50.589453, "o", "        self.idx = date_range(\r\n"]
[50.620161, "o", "            start=datetime(2015, 10, 26), end=datetime(2016, 1, 1), freq=\"50s\"\r\n"]
[50.65087, "o", "        )\r\n"]
[50.681578, "o", "        self.data = dict(zip(self.idx, range(len(self.idx))))\r\n"]
[50.712286, "o", "        self.array = np.array([1, 2, 3])\r\n"]
[50.742994, "o", "        self.idx2 = Index([\"a\", \"b\", \"c\"])\r\n"]
[50.773702, "o", "\r\n"]
[50.80441, "o", "    def time_constructor_dict(self):\r\n"]
[50.835118, "o", "        Series(data=self.data, index=self.idx)\r\n"]
[50.865826, "o", "\r\n"]
[50.896534, "o", "    def time_constructor_no_data(self):\r\n"]
[50.927242, "o", "        Series(data=None, index=self.idx)\r\n"]
[50.95795, "o", "\r\n"]
[50.988658, "o", "    def time_constructor_fastpath(self):\r\n"]
[51.019366, "o", "        Series(self.array, index=self.idx2, name=\"name\", fastpath=True)\r\n"]
[51.050075, "o", "\r\n"]
[51.080783, "o", "\r\n"]
[51.111491, "o", "class ToFrame:\r\n"]
[51.142199, "o", "    params = [[\"int64\", \"datetime64[ns]\", \"category\", \"Int64\"], [None, \"foo\"]]\r\n"]
[51.172907, "o", "    param_names = [\"dtype\", \"name\"]\r\n"]
[51.203615, "o", "\r\n"]
[51.234323, "o", "    def setup(self, dtype, name):\r\n"]
[51.265031, "o", "        arr = np.arange(10**5)\r\n"]
[51.295739, "o", "        ser = Series(arr, dtype=dtype)\r\n"]
[51.326447, "o", "        self.ser = ser\r\n"]
[51.357155, "o", "\r\n"]
[51.387863, "o", "    def time_to_frame(self, dtype, name):\r\n"]
[51.418571, "o", "        self.ser.to_frame(name)\r\n"]
[51.44928, "o", "\r\n"]
[51.479988, "o", "\r\n"]
[51.510696, "o", "class NSort:\r\n"]
[51.541404, "o", "\r\n"]
[51.572112, "o", "    params = [\"first\", \"last\", \"all\"]\r\n"]
[51.60282, "o", "    param_names = [\"keep\"]\r\n"]
[51.633528, "o", "\r\n"]
[51.664236, "o", "    def setup(self, keep):\r\n"]
[51.694944, "o", "        self.s = Series(np.random.randint(1, 10, 100000))\r\n"]
[51.725652, "o", "\r\n"]
[51.75636, "o", "    def time_nlargest(self, keep):\r\n"]
[51.787068, "o", "        self.s.nlargest(3, keep=keep)\r\n"]
[51.817776, "o", "\r\n"]
[51.848484, "o", "    def time_nsmallest(self, keep):\r\n"]
[51.879193, "o", "        self.s.nsmallest(3, keep=keep)\r\n"]
[51.909901, "o", "\r\n"]
[51.940609, "o", "\r\n"]
[51.971317, "o", "class Dropna:\r\n"]
[52.002025, "o", "\r\n"]
[52.032733, "o", "    params = [\"int\", \"datetime\"]\r\n"]
[52.063441, "o", "    param_names = [\"dtype\"]\r\n"]
[52.094149, "o", "\r\n"]
[52.124857, "o", "    def setup(self, dtype):\r\n"]
[52.155565, "o", "        N = 10**6\r\n"]
[52.186273, "o", "        data = {\r\n"]
[52.216981, "o", "            \"int\": np.random.randint(1, 10, N),\r\n"]
[52.247689, "o", "            \"datetime\": date_range(\"2000-01-01\", freq=\"S\", periods=N),\r\n"]
[52.278398, "o", "        }\r\n"]
[52.309106, "o", "        self.s = Series(data[dtype])\r\n"]
[52.339814, "o", "        if dtype == \"datetime\":\r\n"]
[52.370522, "o", "            self.s[np.random.randint(1, N, 100)] = NaT\r\n"]
[52.40123, "o", "\r\n"]
[52.431938, "o", "    def time_dropna(self, dtype):\r\n"]
[52.462646, "o", "        self.s.dropna()\r\n"]
[52.493354, "o", "\r\n"]
[52.524062, "o", "\r\n"]
[52.55477, "o", "class Fillna:\r\n"]
[52.585478, "o", "\r\n"]
[52.616186, "o", "    params = [\r\n"]
[52.646894, "o", "        [\r\n"]
[52.677602, "o", "            \"datetime64[ns]\",\r\n"]
[52.708311, "o", "            \"float64\",\r\n"]
[52.739019, "o", "            \"Float64\",\r\n"]
[52.769727, "o", "            \"Int64\",\r\n"]
[52.800435, "o", "            \"int64[pyarrow]\",\r\n"]
[52.831143, "o", "            \"string\",\r\n"]
[52.861851, "o", "            \"string[pyarrow]\",\r\n"]
[52.892559, "o", "        ],\r\n"]
[52.923267, "o", "        [None, \"pad\", \"backfill\"],\r\n"]
[52.953975, "o", "    ]\r\n"]
[52.984683, "o", "    param_names = [\"dtype\", \"method\"]\r\n"]
[53.015391, "o", "\r\n"]
[53.046099, "o", "    def setup(self, dtype, method):\r\n"]
[53.076807, "o", "        N = 10**6\r\n"]
[53.107516, "o", "        if dtype == \"datetime64[ns]\":\r\n"]
[53.138224, "o", "            data = date_range(\"2000-01-01\", freq=\"S\", periods=N)\r\n"]
[53.168932, "o", "            na_value = NaT\r\n"]
[53.19964, "o", "        elif dtype in (\"float64\", \"Float64\"):\r\n"]
[53.230348, "o", "            data = np.random.randn(N)\r\n"]
[53.261056, "o", "            na_value = np.nan\r\n"]
[53.291764, "o", "        elif dtype in (\"Int64\", \"int64[pyarrow]\"):\r\n"]
[53.322472, "o", "            data = np.arange(N)\r\n"]
[53.35318, "o", "            na_value = NA\r\n"]
[53.383888, "o", "        elif dtype in (\"string\", \"string[pyarrow]\"):\r\n"]
[53.414596, "o", "            data = tm.rands_array(5, N)\r\n"]
[53.445304, "o", "            na_value = NA\r\n"]
[53.476012, "o", "        else:\r\n"]
[53.50672, "o", "            raise NotImplementedError\r\n"]
[53.537429, "o", "        fill_value = data[0]\r\n"]
[53.568137, "o", "        ser = Series(data, dtype=dtype)\r\n"]
[53.598845, "o", "        ser[::2] = na_value\r\n"]
[53.629553, "o", "        self.ser = ser\r\n"]
[53.660261, "o", "        self.fill_value = fill_value\r\n"]
[53.690969, "o", "\r\n"]
[53.721677, "o", "    def time_fillna(self, dtype, method):\r\n"]
[53.752385, "o", "        value = self.fill_value if method is None else None\r\n"]
[53.783093, "o", "        self.ser.fillna(value=value, method=method)\r\n"]
[53.813801, "o", "\r\n"]
[53.844509, "o", "\r\n"]
[53.875217, "o", "class SearchSorted:\r\n"]
[53.905925, "o", "\r\n"]
[53.936634, "o", "    goal_time = 0.2\r\n"]
[53.967342, "o", "    params = [\r\n"]
[53.99805, "o", "        \"int8\",\r\n"]
[54.028758, "o", "        \"int16\",\r\n"]
[54.059466, "o", "        \"int32\",\r\n"]
[54.090174, "o", "        \"int64\",\r\n"]
[54.120882, "o", "        \"uint8\",\r\n"]
[54.15159, "o", "        \"uint16\",\r\n"]
[54.182298, "o", "        \"uint32\",\r\n"]
[54.213006, "o", "        \"uint64\",\r\n"]
[54.243714, "o", "        \"float16\",\r\n"]
[54.274422, "o", "        \"float32\",\r\n"]
[54.30513, "o", "        \"float64\",\r\n"]
[54.335839, "o", "        \"str\",\r\n"]
[54.366547, "o", "    ]\r\n"]
[54.397255, "o", "    param_names = [\"dtype\"]\r\n"]
[54.427963, "o", "\r\n"]
[54.458671, "o", "    def setup(self, dtype):\r\n"]
[54.489379, "o", "        N = 10**5\r\n"]
[54.520087, "o", "        data = np.array([1] * N + [2] * N + [3] * N).astype(dtype)\r\n"]
[54.550795, "o", "        self.s = Series(data)\r\n"]
[54.581503, "o", "\r\n"]
[54.612211, "o", "    def time_searchsorted(self, dtype):\r\n"]
[54.642919, "o", "        key = \"2\" if dtype == \"str\" else 2\r\n"]
[54.673627, "o", "        self.s.searchsorted(key)\r\n"]
[54.704335, "o", "\r\n"]
[54.735043, "o", "\r\n"]
[54.765752, "o", "class Map:\r\n"]
[54.79646, "o", "\r\n"]
[54.827168, "o", "    params = ([\"dict\", \"Series\", \"lambda\"], [\"object\", \"category\", \"int\"])\r\n"]
[54.857876, "o", "    param_names = \"mapper\"\r\n"]
[54.888584, "o", "\r\n"]
[54.919292, "o", "    def setup(self, mapper, dtype):\r\n"]
[55.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[55.002, "i", "sed -n '160,500p' asv_bench/benchmarks/series_methods.py\r"]
[55.004, "o", "sed -n '160,500p' asv_bench/benchmarks/series_methods.py\r\n"]
[55.026098, "o", "\u001b[?2004l\r\n"]
[55.046195, "o", "        map_size = 1000\r\n"]
[55.066293, "o", "        map_data = Series(map_size - np.arange(map_size), dtype=dtype)\r\n"]
[55.08639, "o", "\r\n"]
[55.106488, "o", "        # construct mapper\r\n"]
[55.126585, "o", "        if mapper == \"Series\":\r\n"]
[55.146683, "o", "            self.map_data = map_data\r\n"]
[55.16678, "o", "        elif mapper == \"dict\":\r\n"]
[55.186878, "o", "            self.map_data = map_data.to_dict()\r\n"]
[55.206976, "o", "        elif mapper == \"lambda\":\r\n"]
[55.227073, "o", "            map_dict = map_data.to_dict()\r\n"]
[55.247171, "o", "            self.map_data = lambda x: map_dict[x]\r\n"]
[55.267268, "o", "        else:\r\n"]
[55.287366, "o", "            raise NotImplementedError\r\n"]
[55.307463, "o", "\r\n"]
[55.327561, "o", "        self.s = Series(np.random.randint(0, map_size, 10000), dtype=dtype)\r\n"]
[55.347659, "o", "\r\n"]
[55.367756, "o", "    def time_map(self, mapper, *args, **kwargs):\r\n"]
[55.387854, "o", "        self.s.map(self.map_data)\r\n"]
[55.407951, "o", "\r\n"]
[55.428049, "o", "\r\n"]
[55.448146, "o", "class Clip:\r\n"]
[55.468244, "o", "    params = [50, 1000, 10**5]\r\n"]
[55.488341, "o", "    param_names = [\"n\"]\r\n"]
[55.508439, "o", "\r\n"]
[55.528537, "o", "    def setup(self, n):\r\n"]
[55.548634, "o", "        self.s = Series(np.random.randn(n))\r\n"]
[55.568732, "o", "\r\n"]
[55.588829, "o", "    def time_clip(self, n):\r\n"]
[55.608927, "o", "        self.s.clip(0, 1)\r\n"]
[55.629024, "o", "\r\n"]
[55.649122, "o", "\r\n"]
[55.66922, "o", "class ClipDt:\r\n"]
[55.689317, "o", "    def setup(self):\r\n"]
[55.709415, "o", "        dr = date_range(\"20220101\", periods=100_000, freq=\"s\", tz=\"UTC\")\r\n"]
[55.729512, "o", "        self.clipper_dt = dr[0:1_000].repeat(100)\r\n"]
[55.74961, "o", "        self.s = Series(dr)\r\n"]
[55.769707, "o", "\r\n"]
[55.789805, "o", "    def time_clip(self):\r\n"]
[55.809902, "o", "        self.s.clip(upper=self.clipper_dt)\r\n"]
[55.83, "o", "\r\n"]
[55.850098, "o", "\r\n"]
[55.870195, "o", "class ValueCounts:\r\n"]
[55.890293, "o", "\r\n"]
[55.91039, "o", "    params = [[10**3, 10**4, 10**5], [\"int\", \"uint\", \"float\", \"object\"]]\r\n"]
[55.930488, "o", "    param_names = [\"N\", \"dtype\"]\r\n"]
[55.950585, "o", "\r\n"]
[55.970683, "o", "    def setup(self, N, dtype):\r\n"]
[55.99078, "o", "        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)\r\n"]
[56.010878, "o", "\r\n"]
[56.030976, "o", "    def time_value_counts(self, N, dtype):\r\n"]
[56.051073, "o", "        self.s.value_counts()\r\n"]
[56.071171, "o", "\r\n"]
[56.091268, "o", "\r\n"]
[56.111366, "o", "class ValueCountsEA:\r\n"]
[56.131463, "o", "\r\n"]
[56.151561, "o", "    params = [[10**3, 10**4, 10**5], [True, False]]\r\n"]
[56.171659, "o", "    param_names = [\"N\", \"dropna\"]\r\n"]
[56.191756, "o", "\r\n"]
[56.211854, "o", "    def setup(self, N, dropna):\r\n"]
[56.231951, "o", "        self.s = Series(np.random.randint(0, N, size=10 * N), dtype=\"Int64\")\r\n"]
[56.252049, "o", "        self.s.loc[1] = NA\r\n"]
[56.272146, "o", "\r\n"]
[56.292244, "o", "    def time_value_counts(self, N, dropna):\r\n"]
[56.312341, "o", "        self.s.value_counts(dropna=dropna)\r\n"]
[56.332439, "o", "\r\n"]
[56.352537, "o", "\r\n"]
[56.372634, "o", "class ValueCountsObjectDropNAFalse:\r\n"]
[56.392732, "o", "\r\n"]
[56.412829, "o", "    params = [10**3, 10**4, 10**5]\r\n"]
[56.432927, "o", "    param_names = [\"N\"]\r\n"]
[56.453024, "o", "\r\n"]
[56.473122, "o", "    def setup(self, N):\r\n"]
[56.49322, "o", "        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")\r\n"]
[56.513317, "o", "\r\n"]
[56.533415, "o", "    def time_value_counts(self, N):\r\n"]
[56.553512, "o", "        self.s.value_counts(dropna=False)\r\n"]
[56.57361, "o", "\r\n"]
[56.593707, "o", "\r\n"]
[56.613805, "o", "class Mode:\r\n"]
[56.633902, "o", "\r\n"]
[56.654, "o", "    params = [[10**3, 10**4, 10**5], [\"int\", \"uint\", \"float\", \"object\"]]\r\n"]
[56.674098, "o", "    param_names = [\"N\", \"dtype\"]\r\n"]
[56.694195, "o", "\r\n"]
[56.714293, "o", "    def setup(self, N, dtype):\r\n"]
[56.73439, "o", "        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(dtype)\r\n"]
[56.754488, "o", "\r\n"]
[56.774585, "o", "    def time_mode(self, N, dtype):\r\n"]
[56.794683, "o", "        self.s.mode()\r\n"]
[56.81478, "o", "\r\n"]
[56.834878, "o", "\r\n"]
[56.854976, "o", "class ModeObjectDropNAFalse:\r\n"]
[56.875073, "o", "\r\n"]
[56.895171, "o", "    params = [10**3, 10**4, 10**5]\r\n"]
[56.915268, "o", "    param_names = [\"N\"]\r\n"]
[56.935366, "o", "\r\n"]
[56.955463, "o", "    def setup(self, N):\r\n"]
[56.975561, "o", "        self.s = Series(np.random.randint(0, N, size=10 * N)).astype(\"object\")\r\n"]
[56.995659, "o", "\r\n"]
[57.015756, "o", "    def time_mode(self, N):\r\n"]
[57.035854, "o", "        self.s.mode(dropna=False)\r\n"]
[57.055951, "o", "\r\n"]
[57.076049, "o", "\r\n"]
[57.096146, "o", "class Dir:\r\n"]
[57.116244, "o", "    def setup(self):\r\n"]
[57.136341, "o", "        self.s = Series(index=tm.makeStringIndex(10000))\r\n"]
[57.156439, "o", "\r\n"]
[57.176537, "o", "    def time_dir_strings(self):\r\n"]
[57.196634, "o", "        dir(self.s)\r\n"]
[57.216732, "o", "\r\n"]
[57.236829, "o", "\r\n"]
[57.256927, "o", "class SeriesGetattr:\r\n"]
[57.277024, "o", "    # https://github.com/pandas-dev/pandas/issues/19764\r\n"]
[57.297122, "o", "    def setup(self):\r\n"]
[57.31722, "o", "        self.s = Series(1, index=date_range(\"2012-01-01\", freq=\"s\", periods=10**6))\r\n"]
[57.337317, "o", "\r\n"]
[57.357415, "o", "    def time_series_datetimeindex_repr(self):\r\n"]
[57.377512, "o", "        getattr(self.s, \"a\", None)\r\n"]
[57.39761, "o", "\r\n"]
[57.417707, "o", "\r\n"]
[57.437805, "o", "class All:\r\n"]
[57.457902, "o", "\r\n"]
[57.478, "o", "    params = [[10**3, 10**6], [\"fast\", \"slow\"], [\"bool\", \"boolean\"]]\r\n"]
[57.498098, "o", "    param_names = [\"N\", \"case\", \"dtype\"]\r\n"]
[57.518195, "o", "\r\n"]
[57.538293, "o", "    def setup(self, N, case, dtype):\r\n"]
[57.55839, "o", "        val = case != \"fast\"\r\n"]
[57.578488, "o", "        self.s = Series([val] * N, dtype=dtype)\r\n"]
[57.598585, "o", "\r\n"]
[57.618683, "o", "    def time_all(self, N, case, dtype):\r\n"]
[57.63878, "o", "        self.s.all()\r\n"]
[57.658878, "o", "\r\n"]
[57.678976, "o", "\r\n"]
[57.699073, "o", "class Any:\r\n"]
[57.719171, "o", "\r\n"]
[57.739268, "o", "    params = [[10**3, 10**6], [\"fast\", \"slow\"], [\"bool\", \"boolean\"]]\r\n"]
[57.759366, "o", "    param_names = [\"N\", \"case\", \"dtype\"]\r\n"]
[57.779463, "o", "\r\n"]
[57.799561, "o", "    def setup(self, N, case, dtype):\r\n"]
[57.819659, "o", "        val = case == \"fast\"\r\n"]
[57.839756, "o", "        self.s = Series([val] * N, dtype=dtype)\r\n"]
[57.859854, "o", "\r\n"]
[57.879951, "o", "    def time_any(self, N, case, dtype):\r\n"]
[57.900049, "o", "        self.s.any()\r\n"]
[57.920146, "o", "\r\n"]
[57.940244, "o", "\r\n"]
[57.960341, "o", "class NanOps:\r\n"]
[57.980439, "o", "\r\n"]
[58.000537, "o", "    params = [\r\n"]
[58.020634, "o", "        [\r\n"]
[58.040732, "o", "            \"var\",\r\n"]
[58.060829, "o", "            \"mean\",\r\n"]
[58.080927, "o", "            \"median\",\r\n"]
[58.101024, "o", "            \"max\",\r\n"]
[58.121122, "o", "            \"min\",\r\n"]
[58.14122, "o", "            \"sum\",\r\n"]
[58.161317, "o", "            \"std\",\r\n"]
[58.181415, "o", "            \"sem\",\r\n"]
[58.201512, "o", "            \"argmax\",\r\n"]
[58.22161, "o", "            \"skew\",\r\n"]
[58.241707, "o", "            \"kurt\",\r\n"]
[58.261805, "o", "            \"prod\",\r\n"]
[58.281902, "o", "        ],\r\n"]
[58.302, "o", "        [10**3, 10**6],\r\n"]
[58.322098, "o", "        [\"int8\", \"int32\", \"int64\", \"float64\", \"Int64\", \"boolean\"],\r\n"]
[58.342195, "o", "    ]\r\n"]
[58.362293, "o", "    param_names = [\"func\", \"N\", \"dtype\"]\r\n"]
[58.38239, "o", "\r\n"]
[58.402488, "o", "    def setup(self, func, N, dtype):\r\n"]
[58.422585, "o", "        if func == \"argmax\" and dtype in {\"Int64\", \"boolean\"}:\r\n"]
[58.442683, "o", "            # Skip argmax for nullable int since this doesn't work yet (GH-24382)\r\n"]
[58.46278, "o", "            raise NotImplementedError\r\n"]
[58.482878, "o", "        self.s = Series([1] * N, dtype=dtype)\r\n"]
[58.502976, "o", "        self.func = getattr(self.s, func)\r\n"]
[58.523073, "o", "\r\n"]
[58.543171, "o", "    def time_func(self, func, N, dtype):\r\n"]
[58.563268, "o", "        self.func()\r\n"]
[58.583366, "o", "\r\n"]
[58.603463, "o", "\r\n"]
[58.623561, "o", "class Rank:\r\n"]
[58.643659, "o", "\r\n"]
[58.663756, "o", "    param_names = [\"dtype\"]\r\n"]
[58.683854, "o", "    params = [\r\n"]
[58.703951, "o", "        [\"int\", \"uint\", \"float\", \"object\"],\r\n"]
[58.724049, "o", "    ]\r\n"]
[58.744146, "o", "\r\n"]
[58.764244, "o", "    def setup(self, dtype):\r\n"]
[58.784341, "o", "        self.s = Series(np.random.randint(0, 1000, size=100000), dtype=dtype)\r\n"]
[58.804439, "o", "\r\n"]
[58.824537, "o", "    def time_rank(self, dtype):\r\n"]
[58.844634, "o", "        self.s.rank()\r\n"]
[58.864732, "o", "\r\n"]
[58.884829, "o", "\r\n"]
[58.904927, "o", "class Iter:\r\n"]
[58.925024, "o", "\r\n"]
[58.945122, "o", "    param_names = [\"dtype\"]\r\n"]
[58.96522, "o", "    params = [\r\n"]
[58.985317, "o", "        \"bool\",\r\n"]
[59.005415, "o", "        \"boolean\",\r\n"]
[59.025512, "o", "        \"int64\",\r\n"]
[59.04561, "o", "        \"Int64\",\r\n"]
[59.065707, "o", "        \"float64\",\r\n"]
[59.085805, "o", "        \"Float64\",\r\n"]
[59.105902, "o", "        \"datetime64[ns]\",\r\n"]
[59.126, "o", "    ]\r\n"]
[59.146098, "o", "\r\n"]
[59.166195, "o", "    def setup(self, dtype):\r\n"]
[59.186293, "o", "        N = 10**5\r\n"]
[59.20639, "o", "        if dtype in [\"bool\", \"boolean\"]:\r\n"]
[59.226488, "o", "            data = np.repeat([True, False], N // 2)\r\n"]
[59.246585, "o", "        elif dtype in [\"int64\", \"Int64\"]:\r\n"]
[59.266683, "o", "            data = np.arange(N)\r\n"]
[59.28678, "o", "        elif dtype in [\"float64\", \"Float64\"]:\r\n"]
[59.306878, "o", "            data = np.random.randn(N)\r\n"]
[59.326976, "o", "        elif dtype == \"datetime64[ns]\":\r\n"]
[59.347073, "o", "            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\r\n"]
[59.367171, "o", "        else:\r\n"]
[59.387268, "o", "            raise NotImplementedError\r\n"]
[59.407366, "o", "\r\n"]
[59.427463, "o", "        self.s = Series(data, dtype=dtype)\r\n"]
[59.447561, "o", "\r\n"]
[59.467659, "o", "    def time_iter(self, dtype):\r\n"]
[59.487756, "o", "        for v in self.s:\r\n"]
[59.507854, "o", "            pass\r\n"]
[59.527951, "o", "\r\n"]
[59.548049, "o", "\r\n"]
[59.568146, "o", "class ToNumpy:\r\n"]
[59.588244, "o", "    def setup(self):\r\n"]
[59.608341, "o", "        N = 1_000_000\r\n"]
[59.628439, "o", "        self.ser = Series(\r\n"]
[59.648537, "o", "            np.random.randn(\r\n"]
[59.668634, "o", "                N,\r\n"]
[59.688732, "o", "            )\r\n"]
[59.708829, "o", "        )\r\n"]
[59.728927, "o", "\r\n"]
[59.749024, "o", "    def time_to_numpy(self):\r\n"]
[59.769122, "o", "        self.ser.to_numpy()\r\n"]
[59.78922, "o", "\r\n"]
[59.809317, "o", "    def time_to_numpy_double_copy(self):\r\n"]
[59.829415, "o", "        self.ser.to_numpy(dtype=\"float64\", copy=True)\r\n"]
[59.849512, "o", "\r\n"]
[59.86961, "o", "    def time_to_numpy_copy(self):\r\n"]
[59.889707, "o", "        self.ser.to_numpy(copy=True)\r\n"]
[59.909805, "o", "\r\n"]
[59.929902, "o", "\r\n"]
[60.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[60.002, "i", "asv run --config asv_bench/asv.conf.json --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[60.004, "o", "asv run --config asv_bench/asv.conf.json --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[62.478, "o", "\u001b[?2004l\r\n"]
[65.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[65.002, "i", "pwd\r"]
[65.004, "o", "pwd\r\n"]
[67.478, "o", "\u001b[?2004l\r\n"]
[70.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[70.002, "i", "ls -l asv_bench/asv.conf.json\r"]
[70.004, "o", "ls -l asv_bench/asv.conf.json\r\n"]
[72.478, "o", "\u001b[?2004l\r\n"]
[75.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[75.002, "i", "cd asv_bench\r"]
[75.004, "o", "cd asv_bench\r\n"]
[75.006, "o", "\u001b[?2004l\r\n"]
[80.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[80.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[80.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[80.624, "o", "\u001b[?2004l\r\n"]
[81.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[81.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[82.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[83.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[83.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                   1.30\u00b10.01\u03bcs\r\n"]
[84.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                 391\u00b110\u03bcs\r\n"]
[85.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[85.002, "i", "grep -R \"def to_numpy\" -n pandas/core | head -n 20\r"]
[85.004, "o", "grep -R \"def to_numpy\" -n pandas/core | head -n 20\r\n"]
[87.478, "o", "\u001b[?2004l\r\n"]
[90.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[90.002, "i", "sed -n '1,220p' pandas/core/series.py\r"]
[90.004, "o", "sed -n '1,220p' pandas/core/series.py\r\n"]
[92.478, "o", "\u001b[?2004l\r\n"]
[95.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[95.002, "i", "sed -n '220,560p' pandas/core/series.py\r"]
[95.004, "o", "sed -n '220,560p' pandas/core/series.py\r\n"]
[97.478, "o", "\u001b[?2004l\r\n"]
[100.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[100.002, "i", "sed -n '560,1200p' pandas/core/series.py\r"]
[100.004, "o", "sed -n '560,1200p' pandas/core/series.py\r\n"]
[102.478, "o", "\u001b[?2004l\r\n"]
[105.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[105.002, "i", "grep -R \"to_numpy\\(\" -n pandas/core | grep -v tests | head -n 20\r"]
[105.004, "o", "grep -R \"to_numpy\\(\" -n pandas/core | grep -v tests | head -n 20\r\n"]
[107.478, "o", "\u001b[?2004l\r\n"]
[110.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[110.002, "i", "cd asv_bench\r"]
[110.004, "o", "cd asv_bench\r\n"]
[112.478, "o", "\u001b[?2004l\r\n"]
[115.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[115.002, "i", "asv profile --python=same --config asv.conf.json series_methods.ToNumpy.time_to_numpy_copy\r"]
[115.004, "o", "asv profile --python=same --config asv.conf.json series_methods.ToNumpy.time_to_numpy_copy\r\n"]
[115.147257, "o", "\u001b[?2004l\r\n"]
[115.288514, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[115.429771, "o", "\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n"]
[115.571029, "o", "\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[115.712286, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy_copy--)\u001b[0m.\r\n"]
[115.853543, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                360\u00b10.7\u03bcs\r\n"]
[115.9948, "o", "\r\n"]
[116.136057, "o", "Wed Oct  1 17:40:19 2025    /tmp/tmpvnofqhsl\r\n"]
[116.277314, "o", "\r\n"]
[116.418571, "o", "         22 function calls in 0.000 seconds\r\n"]
[116.559829, "o", "\r\n"]
[116.701086, "o", "   Ordered by: cumulative time\r\n"]
[116.842343, "o", "\r\n"]
[116.9836, "o", "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n"]
[117.124857, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\r\n"]
[117.266114, "o", "        1    0.000    0.000    0.000    0.000 _base.py:689(method_caller)\r\n"]
[117.407371, "o", "        1    0.000    0.000    0.000    0.000 series_methods.py:400(time_to_numpy_copy)\r\n"]
[117.548629, "o", "        1    0.000    0.000    0.000    0.000 base.py:424(to_numpy)\r\n"]
[117.689886, "o", "        1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n"]
[117.831143, "o", "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(shares_memory)\r\n"]
[117.9724, "o", "        1    0.000    0.000    0.000    0.000 series.py:571(dtype)\r\n"]
[118.113657, "o", "        1    0.000    0.000    0.000    0.000 managers.py:2036(dtype)\r\n"]
[118.254914, "o", "        1    0.000    0.000    0.000    0.000 common.py:1346(is_extension_array_dtype)\r\n"]
[118.396171, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n"]
[118.537429, "o", "        2    0.000    0.000    0.000    0.000 series.py:683(_values)\r\n"]
[118.678686, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n"]
[118.819943, "o", "        1    0.000    0.000    0.000    0.000 managers.py:1979(_block)\r\n"]
[118.9612, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2047(internal_values)\r\n"]
[119.102457, "o", "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n"]
[119.243714, "o", "        1    0.000    0.000    0.000    0.000 blocks.py:463(dtype)\r\n"]
[119.384971, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n"]
[119.526229, "o", "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n"]
[119.667486, "o", "        1    0.000    0.000    0.000    0.000 multiarray.py:1317(shares_memory)\r\n"]
[119.808743, "o", "\r\n"]
[120.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[120.002, "i", "cd ..\r"]
[120.004, "o", "cd ..\r\n"]
[120.006, "o", "\u001b[?2004l\r\n"]
[125.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[125.002, "i", "grep -R \"def to_numpy\" -n pandas/core | head -n 50\r"]
[125.004, "o", "grep -R \"def to_numpy\" -n pandas/core | head -n 50\r\n"]
[125.712286, "o", "\u001b[?2004l\r\n"]
[126.418571, "o", "pandas/core/frame.py:1758:    def to_numpy(\r\n"]
[127.124857, "o", "pandas/core/base.py:425:    def to_numpy(\r\n"]
[127.831143, "o", "pandas/core/arrays/masked.py:349:    def to_numpy(\r\n"]
[128.537429, "o", "pandas/core/arrays/numpy_.py:386:    def to_numpy(\r\n"]
[129.243714, "o", "pandas/core/arrays/arrow/array.py:842:    def to_numpy(\r\n"]
[130.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[130.002, "i", "sed -n '360,520p' pandas/core/base.py\r"]
[130.004, "o", "sed -n '360,520p' pandas/core/base.py\r\n"]
[130.036519, "o", "\u001b[?2004l\r\n"]
[130.067037, "o", "    def array(self) -> ExtensionArray:\r\n"]
[130.097556, "o", "        \"\"\"\r\n"]
[130.128074, "o", "        The ExtensionArray of the data backing this Series or Index.\r\n"]
[130.158593, "o", "\r\n"]
[130.189111, "o", "        Returns\r\n"]
[130.21963, "o", "        -------\r\n"]
[130.250148, "o", "        ExtensionArray\r\n"]
[130.280667, "o", "            An ExtensionArray of the values stored within. For extension\r\n"]
[130.311185, "o", "            types, this is the actual array. For NumPy native types, this\r\n"]
[130.341704, "o", "            is a thin (no copy) wrapper around :class:`numpy.ndarray`.\r\n"]
[130.372222, "o", "\r\n"]
[130.402741, "o", "            ``.array`` differs ``.values`` which may require converting the\r\n"]
[130.433259, "o", "            data to a different form.\r\n"]
[130.463778, "o", "\r\n"]
[130.494296, "o", "        See Also\r\n"]
[130.524815, "o", "        --------\r\n"]
[130.555333, "o", "        Index.to_numpy : Similar method that always returns a NumPy array.\r\n"]
[130.585852, "o", "        Series.to_numpy : Similar method that always returns a NumPy array.\r\n"]
[130.61637, "o", "\r\n"]
[130.646889, "o", "        Notes\r\n"]
[130.677407, "o", "        -----\r\n"]
[130.707926, "o", "        This table lays out the different array types for each extension\r\n"]
[130.738444, "o", "        dtype within pandas.\r\n"]
[130.768963, "o", "\r\n"]
[130.799481, "o", "        ================== =============================\r\n"]
[130.83, "o", "        dtype              array type\r\n"]
[130.860519, "o", "        ================== =============================\r\n"]
[130.891037, "o", "        category           Categorical\r\n"]
[130.921556, "o", "        period             PeriodArray\r\n"]
[130.952074, "o", "        interval           IntervalArray\r\n"]
[130.982593, "o", "        IntegerNA          IntegerArray\r\n"]
[131.013111, "o", "        string             StringArray\r\n"]
[131.04363, "o", "        boolean            BooleanArray\r\n"]
[131.074148, "o", "        datetime64[ns, tz] DatetimeArray\r\n"]
[131.104667, "o", "        ================== =============================\r\n"]
[131.135185, "o", "\r\n"]
[131.165704, "o", "        For any 3rd-party extension types, the array type will be an\r\n"]
[131.196222, "o", "        ExtensionArray.\r\n"]
[131.226741, "o", "\r\n"]
[131.257259, "o", "        For all remaining dtypes ``.array`` will be a\r\n"]
[131.287778, "o", "        :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\r\n"]
[131.318296, "o", "        stored within. If you absolutely need a NumPy array (possibly with\r\n"]
[131.348815, "o", "        copying / coercing data), then use :meth:`Series.to_numpy` instead.\r\n"]
[131.379333, "o", "\r\n"]
[131.409852, "o", "        Examples\r\n"]
[131.44037, "o", "        --------\r\n"]
[131.470889, "o", "        For regular NumPy types like int, and float, a PandasArray\r\n"]
[131.501407, "o", "        is returned.\r\n"]
[131.531926, "o", "\r\n"]
[131.562444, "o", "        >>> pd.Series([1, 2, 3]).array\r\n"]
[131.592963, "o", "        <PandasArray>\r\n"]
[131.623481, "o", "        [1, 2, 3]\r\n"]
[131.654, "o", "        Length: 3, dtype: int64\r\n"]
[131.684519, "o", "\r\n"]
[131.715037, "o", "        For extension types, like Categorical, the actual ExtensionArray\r\n"]
[131.745556, "o", "        is returned\r\n"]
[131.776074, "o", "\r\n"]
[131.806593, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[131.837111, "o", "        >>> ser.array\r\n"]
[131.86763, "o", "        ['a', 'b', 'a']\r\n"]
[131.898148, "o", "        Categories (2, object): ['a', 'b']\r\n"]
[131.928667, "o", "        \"\"\"\r\n"]
[131.959185, "o", "        raise AbstractMethodError(self)\r\n"]
[131.989704, "o", "\r\n"]
[132.020222, "o", "    @final\r\n"]
[132.050741, "o", "    def to_numpy(\r\n"]
[132.081259, "o", "        self,\r\n"]
[132.111778, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[132.142296, "o", "        copy: bool = False,\r\n"]
[132.172815, "o", "        na_value: object = lib.no_default,\r\n"]
[132.203333, "o", "        **kwargs,\r\n"]
[132.233852, "o", "    ) -> np.ndarray:\r\n"]
[132.26437, "o", "        \"\"\"\r\n"]
[132.294889, "o", "        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[132.325407, "o", "\r\n"]
[132.355926, "o", "        Parameters\r\n"]
[132.386444, "o", "        ----------\r\n"]
[132.416963, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[132.447481, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[132.478, "o", "        copy : bool, default False\r\n"]
[132.508519, "o", "            Whether to ensure that the returned value is not a view on\r\n"]
[132.539037, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[132.569556, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[132.600074, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[132.630593, "o", "        na_value : Any, optional\r\n"]
[132.661111, "o", "            The value to use for missing values. The default value depends\r\n"]
[132.69163, "o", "            on `dtype` and the type of the array.\r\n"]
[132.722148, "o", "\r\n"]
[132.752667, "o", "            .. versionadded:: 1.0.0\r\n"]
[132.783185, "o", "\r\n"]
[132.813704, "o", "        **kwargs\r\n"]
[132.844222, "o", "            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[132.874741, "o", "            of the underlying array (for extension arrays).\r\n"]
[132.905259, "o", "\r\n"]
[132.935778, "o", "            .. versionadded:: 1.0.0\r\n"]
[132.966296, "o", "\r\n"]
[132.996815, "o", "        Returns\r\n"]
[133.027333, "o", "        -------\r\n"]
[133.057852, "o", "        numpy.ndarray\r\n"]
[133.08837, "o", "\r\n"]
[133.118889, "o", "        See Also\r\n"]
[133.149407, "o", "        --------\r\n"]
[133.179926, "o", "        Series.array : Get the actual data stored within.\r\n"]
[133.210444, "o", "        Index.array : Get the actual data stored within.\r\n"]
[133.240963, "o", "        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[133.271481, "o", "\r\n"]
[133.302, "o", "        Notes\r\n"]
[133.332519, "o", "        -----\r\n"]
[133.363037, "o", "        The returned array will be the same up to equality (values equal\r\n"]
[133.393556, "o", "        in `self` will be equal in the returned array; likewise for values\r\n"]
[133.424074, "o", "        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[133.454593, "o", "        dtype may be different. For example, for a category-dtype Series,\r\n"]
[133.485111, "o", "        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[133.51563, "o", "        will be lost.\r\n"]
[133.546148, "o", "\r\n"]
[133.576667, "o", "        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[133.607185, "o", "        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[133.637704, "o", "        in place will modify the data stored in the Series or Index (not that\r\n"]
[133.668222, "o", "        we recommend doing that).\r\n"]
[133.698741, "o", "\r\n"]
[133.729259, "o", "        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[133.759778, "o", "        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[133.790296, "o", "        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[133.820815, "o", "        :attr:`Series.array` should be used instead.\r\n"]
[133.851333, "o", "\r\n"]
[133.881852, "o", "        This table lays out the different dtypes and default return types of\r\n"]
[133.91237, "o", "        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[133.942889, "o", "\r\n"]
[133.973407, "o", "        ================== ================================\r\n"]
[134.003926, "o", "        dtype              array type\r\n"]
[134.034444, "o", "        ================== ================================\r\n"]
[134.064963, "o", "        category[T]        ndarray[T] (same dtype as input)\r\n"]
[134.095481, "o", "        period             ndarray[object] (Periods)\r\n"]
[134.126, "o", "        interval           ndarray[object] (Intervals)\r\n"]
[134.156519, "o", "        IntegerNA          ndarray[object]\r\n"]
[134.187037, "o", "        datetime64[ns]     datetime64[ns]\r\n"]
[134.217556, "o", "        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[134.248074, "o", "        ================== ================================\r\n"]
[134.278593, "o", "\r\n"]
[134.309111, "o", "        Examples\r\n"]
[134.33963, "o", "        --------\r\n"]
[134.370148, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[134.400667, "o", "        >>> ser.to_numpy()\r\n"]
[134.431185, "o", "        array(['a', 'b', 'a'], dtype=object)\r\n"]
[134.461704, "o", "\r\n"]
[134.492222, "o", "        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[134.522741, "o", "        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[134.553259, "o", "        objects, each with the correct ``tz``.\r\n"]
[134.583778, "o", "\r\n"]
[134.614296, "o", "        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[134.644815, "o", "        >>> ser.to_numpy(dtype=object)\r\n"]
[134.675333, "o", "        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[134.705852, "o", "               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[134.73637, "o", "              dtype=object)\r\n"]
[134.766889, "o", "\r\n"]
[134.797407, "o", "        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[134.827926, "o", "        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[134.858444, "o", "        info is dropped.\r\n"]
[134.888963, "o", "\r\n"]
[134.919481, "o", "        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[135.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[135.002, "i", "sed -n '1,220p' pandas/core/series.py\r"]
[135.004, "o", "sed -n '1,220p' pandas/core/series.py\r\n"]
[135.028371, "o", "\u001b[?2004l\r\n"]
[135.050742, "o", "\"\"\"\r\n"]
[135.073113, "o", "Data structure for 1-dimensional cross-sectional and time series data\r\n"]
[135.095484, "o", "\"\"\"\r\n"]
[135.117855, "o", "from __future__ import annotations\r\n"]
[135.140226, "o", "\r\n"]
[135.162597, "o", "import sys\r\n"]
[135.184968, "o", "from textwrap import dedent\r\n"]
[135.207339, "o", "from typing import (\r\n"]
[135.22971, "o", "    IO,\r\n"]
[135.252081, "o", "    TYPE_CHECKING,\r\n"]
[135.274452, "o", "    Any,\r\n"]
[135.296824, "o", "    Callable,\r\n"]
[135.319195, "o", "    Hashable,\r\n"]
[135.341566, "o", "    Iterable,\r\n"]
[135.363937, "o", "    Literal,\r\n"]
[135.386308, "o", "    Mapping,\r\n"]
[135.408679, "o", "    Sequence,\r\n"]
[135.43105, "o", "    Union,\r\n"]
[135.453421, "o", "    cast,\r\n"]
[135.475792, "o", "    overload,\r\n"]
[135.498163, "o", ")\r\n"]
[135.520534, "o", "import weakref\r\n"]
[135.542905, "o", "\r\n"]
[135.565276, "o", "import numpy as np\r\n"]
[135.587647, "o", "\r\n"]
[135.610018, "o", "from pandas._config import (\r\n"]
[135.632389, "o", "    get_option,\r\n"]
[135.65476, "o", "    using_copy_on_write,\r\n"]
[135.677131, "o", ")\r\n"]
[135.699502, "o", "\r\n"]
[135.721873, "o", "from pandas._libs import (\r\n"]
[135.744244, "o", "    lib,\r\n"]
[135.766615, "o", "    properties,\r\n"]
[135.788986, "o", "    reshape,\r\n"]
[135.811357, "o", ")\r\n"]
[135.833729, "o", "from pandas._libs.lib import (\r\n"]
[135.8561, "o", "    is_range_indexer,\r\n"]
[135.878471, "o", "    no_default,\r\n"]
[135.900842, "o", ")\r\n"]
[135.923213, "o", "from pandas._typing import (\r\n"]
[135.945584, "o", "    AggFuncType,\r\n"]
[135.967955, "o", "    AlignJoin,\r\n"]
[135.990326, "o", "    AnyAll,\r\n"]
[136.012697, "o", "    AnyArrayLike,\r\n"]
[136.035068, "o", "    ArrayLike,\r\n"]
[136.057439, "o", "    Axis,\r\n"]
[136.07981, "o", "    AxisInt,\r\n"]
[136.102181, "o", "    CorrelationMethod,\r\n"]
[136.124552, "o", "    DropKeep,\r\n"]
[136.146923, "o", "    Dtype,\r\n"]
[136.169294, "o", "    DtypeObj,\r\n"]
[136.191665, "o", "    FilePath,\r\n"]
[136.214036, "o", "    FillnaOptions,\r\n"]
[136.236407, "o", "    Frequency,\r\n"]
[136.258778, "o", "    IgnoreRaise,\r\n"]
[136.281149, "o", "    IndexKeyFunc,\r\n"]
[136.30352, "o", "    IndexLabel,\r\n"]
[136.325891, "o", "    Level,\r\n"]
[136.348262, "o", "    NaPosition,\r\n"]
[136.370633, "o", "    QuantileInterpolation,\r\n"]
[136.393005, "o", "    Renamer,\r\n"]
[136.415376, "o", "    SingleManager,\r\n"]
[136.437747, "o", "    SortKind,\r\n"]
[136.460118, "o", "    StorageOptions,\r\n"]
[136.482489, "o", "    TimedeltaConvertibleTypes,\r\n"]
[136.50486, "o", "    TimestampConvertibleTypes,\r\n"]
[136.527231, "o", "    ValueKeyFunc,\r\n"]
[136.549602, "o", "    WriteBuffer,\r\n"]
[136.571973, "o", "    npt,\r\n"]
[136.594344, "o", ")\r\n"]
[136.616715, "o", "from pandas.compat import PYPY\r\n"]
[136.639086, "o", "from pandas.compat.numpy import function as nv\r\n"]
[136.661457, "o", "from pandas.errors import (\r\n"]
[136.683828, "o", "    ChainedAssignmentError,\r\n"]
[136.706199, "o", "    InvalidIndexError,\r\n"]
[136.72857, "o", "    _chained_assignment_msg,\r\n"]
[136.750941, "o", ")\r\n"]
[136.773312, "o", "from pandas.util._decorators import (\r\n"]
[136.795683, "o", "    Appender,\r\n"]
[136.818054, "o", "    Substitution,\r\n"]
[136.840425, "o", "    doc,\r\n"]
[136.862796, "o", ")\r\n"]
[136.885167, "o", "from pandas.util._validators import (\r\n"]
[136.907538, "o", "    validate_ascending,\r\n"]
[136.92991, "o", "    validate_bool_kwarg,\r\n"]
[136.952281, "o", "    validate_percentile,\r\n"]
[136.974652, "o", ")\r\n"]
[136.997023, "o", "\r\n"]
[137.019394, "o", "from pandas.core.dtypes.cast import (\r\n"]
[137.041765, "o", "    LossySetitemError,\r\n"]
[137.064136, "o", "    convert_dtypes,\r\n"]
[137.086507, "o", "    maybe_box_native,\r\n"]
[137.108878, "o", "    maybe_cast_pointwise_result,\r\n"]
[137.131249, "o", ")\r\n"]
[137.15362, "o", "from pandas.core.dtypes.common import (\r\n"]
[137.175991, "o", "    ensure_platform_int,\r\n"]
[137.198362, "o", "    is_dict_like,\r\n"]
[137.220733, "o", "    is_extension_array_dtype,\r\n"]
[137.243104, "o", "    is_integer,\r\n"]
[137.265475, "o", "    is_iterator,\r\n"]
[137.287846, "o", "    is_list_like,\r\n"]
[137.310217, "o", "    is_numeric_dtype,\r\n"]
[137.332588, "o", "    is_object_dtype,\r\n"]
[137.354959, "o", "    is_scalar,\r\n"]
[137.37733, "o", "    pandas_dtype,\r\n"]
[137.399701, "o", "    validate_all_hashable,\r\n"]
[137.422072, "o", ")\r\n"]
[137.444443, "o", "from pandas.core.dtypes.generic import ABCDataFrame\r\n"]
[137.466814, "o", "from pandas.core.dtypes.inference import is_hashable\r\n"]
[137.489186, "o", "from pandas.core.dtypes.missing import (\r\n"]
[137.511557, "o", "    isna,\r\n"]
[137.533928, "o", "    na_value_for_dtype,\r\n"]
[137.556299, "o", "    notna,\r\n"]
[137.57867, "o", "    remove_na_arraylike,\r\n"]
[137.601041, "o", ")\r\n"]
[137.623412, "o", "\r\n"]
[137.645783, "o", "from pandas.core import (\r\n"]
[137.668154, "o", "    algorithms,\r\n"]
[137.690525, "o", "    base,\r\n"]
[137.712896, "o", "    common as com,\r\n"]
[137.735267, "o", "    missing,\r\n"]
[137.757638, "o", "    nanops,\r\n"]
[137.780009, "o", "    ops,\r\n"]
[137.80238, "o", ")\r\n"]
[137.824751, "o", "from pandas.core.accessor import CachedAccessor\r\n"]
[137.847122, "o", "from pandas.core.apply import SeriesApply\r\n"]
[137.869493, "o", "from pandas.core.arrays import ExtensionArray\r\n"]
[137.891864, "o", "from pandas.core.arrays.categorical import CategoricalAccessor\r\n"]
[137.914235, "o", "from pandas.core.arrays.sparse import SparseAccessor\r\n"]
[137.936606, "o", "from pandas.core.construction import (\r\n"]
[137.958977, "o", "    extract_array,\r\n"]
[137.981348, "o", "    sanitize_array,\r\n"]
[138.003719, "o", ")\r\n"]
[138.02609, "o", "from pandas.core.generic import NDFrame\r\n"]
[138.048462, "o", "from pandas.core.indexers import (\r\n"]
[138.070833, "o", "    disallow_ndim_indexing,\r\n"]
[138.093204, "o", "    unpack_1tuple,\r\n"]
[138.115575, "o", ")\r\n"]
[138.137946, "o", "from pandas.core.indexes.accessors import CombinedDatetimelikeProperties\r\n"]
[138.160317, "o", "from pandas.core.indexes.api import (\r\n"]
[138.182688, "o", "    DatetimeIndex,\r\n"]
[138.205059, "o", "    Index,\r\n"]
[138.22743, "o", "    MultiIndex,\r\n"]
[138.249801, "o", "    PeriodIndex,\r\n"]
[138.272172, "o", "    default_index,\r\n"]
[138.294543, "o", "    ensure_index,\r\n"]
[138.316914, "o", ")\r\n"]
[138.339285, "o", "import pandas.core.indexes.base as ibase\r\n"]
[138.361656, "o", "from pandas.core.indexes.multi import maybe_droplevels\r\n"]
[138.384027, "o", "from pandas.core.indexing import (\r\n"]
[138.406398, "o", "    check_bool_indexer,\r\n"]
[138.428769, "o", "    check_dict_or_set_indexers,\r\n"]
[138.45114, "o", ")\r\n"]
[138.473511, "o", "from pandas.core.internals import (\r\n"]
[138.495882, "o", "    SingleArrayManager,\r\n"]
[138.518253, "o", "    SingleBlockManager,\r\n"]
[138.540624, "o", ")\r\n"]
[138.562995, "o", "from pandas.core.shared_docs import _shared_docs\r\n"]
[138.585367, "o", "from pandas.core.sorting import (\r\n"]
[138.607738, "o", "    ensure_key_mapped,\r\n"]
[138.630109, "o", "    nargsort,\r\n"]
[138.65248, "o", ")\r\n"]
[138.674851, "o", "from pandas.core.strings import StringMethods\r\n"]
[138.697222, "o", "from pandas.core.tools.datetimes import to_datetime\r\n"]
[138.719593, "o", "\r\n"]
[138.741964, "o", "import pandas.io.formats.format as fmt\r\n"]
[138.764335, "o", "from pandas.io.formats.info import (\r\n"]
[138.786706, "o", "    INFO_DOCSTRING,\r\n"]
[138.809077, "o", "    SeriesInfo,\r\n"]
[138.831448, "o", "    series_sub_kwargs,\r\n"]
[138.853819, "o", ")\r\n"]
[138.87619, "o", "import pandas.plotting\r\n"]
[138.898561, "o", "\r\n"]
[138.920932, "o", "if TYPE_CHECKING:\r\n"]
[138.943303, "o", "    from pandas._typing import (\r\n"]
[138.965674, "o", "        NumpySorter,\r\n"]
[138.988045, "o", "        NumpyValueArrayLike,\r\n"]
[139.010416, "o", "        Suffixes,\r\n"]
[139.032787, "o", "    )\r\n"]
[139.055158, "o", "\r\n"]
[139.077529, "o", "    from pandas.core.frame import DataFrame\r\n"]
[139.0999, "o", "    from pandas.core.groupby.generic import SeriesGroupBy\r\n"]
[139.122271, "o", "    from pandas.core.resample import Resampler\r\n"]
[139.144643, "o", "\r\n"]
[139.167014, "o", "__all__ = [\"Series\"]\r\n"]
[139.189385, "o", "\r\n"]
[139.211756, "o", "_shared_doc_kwargs = {\r\n"]
[139.234127, "o", "    \"axes\": \"index\",\r\n"]
[139.256498, "o", "    \"klass\": \"Series\",\r\n"]
[139.278869, "o", "    \"axes_single_arg\": \"{0 or 'index'}\",\r\n"]
[139.30124, "o", "    \"axis\": \"\"\"axis : {0 or 'index'}\r\n"]
[139.323611, "o", "        Unused. Parameter needed for compatibility with DataFrame.\"\"\",\r\n"]
[139.345982, "o", "    \"inplace\": \"\"\"inplace : bool, default False\r\n"]
[139.368353, "o", "        If True, performs operation inplace and returns None.\"\"\",\r\n"]
[139.390724, "o", "    \"unique\": \"np.ndarray\",\r\n"]
[139.413095, "o", "    \"duplicated\": \"Series\",\r\n"]
[139.435466, "o", "    \"optional_by\": \"\",\r\n"]
[139.457837, "o", "    \"optional_mapper\": \"\",\r\n"]
[139.480208, "o", "    \"optional_labels\": \"\",\r\n"]
[139.502579, "o", "    \"optional_axis\": \"\",\r\n"]
[139.52495, "o", "    \"replace_iloc\": \"\"\"\r\n"]
[139.547321, "o", "    This differs from updating with ``.loc`` or ``.iloc``, which require\r\n"]
[139.569692, "o", "    you to specify a location to update with some value.\"\"\",\r\n"]
[139.592063, "o", "}\r\n"]
[139.614434, "o", "\r\n"]
[139.636805, "o", "\r\n"]
[139.659176, "o", "def _coerce_method(converter):\r\n"]
[139.681548, "o", "    \"\"\"\r\n"]
[139.703919, "o", "    Install the scalar coercion methods.\r\n"]
[139.72629, "o", "    \"\"\"\r\n"]
[139.748661, "o", "\r\n"]
[139.771032, "o", "    def wrapper(self):\r\n"]
[139.793403, "o", "        if len(self) == 1:\r\n"]
[139.815774, "o", "            return converter(self.iloc[0])\r\n"]
[139.838145, "o", "        raise TypeError(f\"cannot convert the series to {converter}\")\r\n"]
[139.860516, "o", "\r\n"]
[139.882887, "o", "    wrapper.__name__ = f\"__{converter.__name__}__\"\r\n"]
[139.905258, "o", "    return wrapper\r\n"]
[139.927629, "o", "\r\n"]
[140.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[140.002, "i", "sed -n '220,760p' pandas/core/series.py\r"]
[140.004, "o", "sed -n '220,760p' pandas/core/series.py\r\n"]
[140.016, "o", "\u001b[?2004l\r\n"]
[140.026, "o", "\r\n"]
[140.036, "o", "# ----------------------------------------------------------------------\r\n"]
[140.046, "o", "# Series class\r\n"]
[140.056, "o", "\r\n"]
[140.066, "o", "# error: Definition of \"max\" in base class \"IndexOpsMixin\" is incompatible with\r\n"]
[140.076, "o", "# definition in base class \"NDFrame\"\r\n"]
[140.086, "o", "# error: Definition of \"min\" in base class \"IndexOpsMixin\" is incompatible with\r\n"]
[140.096, "o", "# definition in base class \"NDFrame\"\r\n"]
[140.106, "o", "class Series(base.IndexOpsMixin, NDFrame):  # type: ignore[misc]\r\n"]
[140.116, "o", "    \"\"\"\r\n"]
[140.126, "o", "    One-dimensional ndarray with axis labels (including time series).\r\n"]
[140.136, "o", "\r\n"]
[140.146, "o", "    Labels need not be unique but must be a hashable type. The object\r\n"]
[140.156, "o", "    supports both integer- and label-based indexing and provides a host of\r\n"]
[140.166, "o", "    methods for performing operations involving the index. Statistical\r\n"]
[140.176, "o", "    methods from ndarray have been overridden to automatically exclude\r\n"]
[140.186, "o", "    missing data (currently represented as NaN).\r\n"]
[140.196, "o", "\r\n"]
[140.206, "o", "    Operations between Series (+, -, /, \\\\*, \\\\*\\\\*) align values based on their\r\n"]
[140.216, "o", "    associated index values-- they need not be the same length. The result\r\n"]
[140.226, "o", "    index will be the sorted union of the two indexes.\r\n"]
[140.236, "o", "\r\n"]
[140.246, "o", "    Parameters\r\n"]
[140.256, "o", "    ----------\r\n"]
[140.266, "o", "    data : array-like, Iterable, dict, or scalar value\r\n"]
[140.276, "o", "        Contains data stored in Series. If data is a dict, argument order is\r\n"]
[140.286, "o", "        maintained.\r\n"]
[140.296, "o", "    index : array-like or Index (1d)\r\n"]
[140.306, "o", "        Values must be hashable and have the same length as `data`.\r\n"]
[140.316, "o", "        Non-unique index values are allowed. Will default to\r\n"]
[140.326, "o", "        RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\r\n"]
[140.336, "o", "        and index is None, then the keys in the data are used as the index. If the\r\n"]
[140.346, "o", "        index is not None, the resulting Series is reindexed with the index values.\r\n"]
[140.356, "o", "    dtype : str, numpy.dtype, or ExtensionDtype, optional\r\n"]
[140.366, "o", "        Data type for the output Series. If not specified, this will be\r\n"]
[140.376, "o", "        inferred from `data`.\r\n"]
[140.386, "o", "        See the :ref:`user guide <basics.dtypes>` for more usages.\r\n"]
[140.396, "o", "    name : str, optional\r\n"]
[140.406, "o", "        The name to give to the Series.\r\n"]
[140.416, "o", "    copy : bool, default False\r\n"]
[140.426, "o", "        Copy input data. Only affects Series or 1d ndarray input. See examples.\r\n"]
[140.436, "o", "\r\n"]
[140.446, "o", "    Notes\r\n"]
[140.456, "o", "    -----\r\n"]
[140.466, "o", "    Please reference the :ref:`User Guide <basics.series>` for more information.\r\n"]
[140.476, "o", "\r\n"]
[140.486, "o", "    Examples\r\n"]
[140.496, "o", "    --------\r\n"]
[140.506, "o", "    Constructing Series from a dictionary with an Index specified\r\n"]
[140.516, "o", "\r\n"]
[140.526, "o", "    >>> d = {'a': 1, 'b': 2, 'c': 3}\r\n"]
[140.536, "o", "    >>> ser = pd.Series(data=d, index=['a', 'b', 'c'])\r\n"]
[140.546, "o", "    >>> ser\r\n"]
[140.556, "o", "    a   1\r\n"]
[140.566, "o", "    b   2\r\n"]
[140.576, "o", "    c   3\r\n"]
[140.586, "o", "    dtype: int64\r\n"]
[140.596, "o", "\r\n"]
[140.606, "o", "    The keys of the dictionary match with the Index values, hence the Index\r\n"]
[140.616, "o", "    values have no effect.\r\n"]
[140.626, "o", "\r\n"]
[140.636, "o", "    >>> d = {'a': 1, 'b': 2, 'c': 3}\r\n"]
[140.646, "o", "    >>> ser = pd.Series(data=d, index=['x', 'y', 'z'])\r\n"]
[140.656, "o", "    >>> ser\r\n"]
[140.666, "o", "    x   NaN\r\n"]
[140.676, "o", "    y   NaN\r\n"]
[140.686, "o", "    z   NaN\r\n"]
[140.696, "o", "    dtype: float64\r\n"]
[140.706, "o", "\r\n"]
[140.716, "o", "    Note that the Index is first build with the keys from the dictionary.\r\n"]
[140.726, "o", "    After this the Series is reindexed with the given Index values, hence we\r\n"]
[140.736, "o", "    get all NaN as a result.\r\n"]
[140.746, "o", "\r\n"]
[140.756, "o", "    Constructing Series from a list with `copy=False`.\r\n"]
[140.766, "o", "\r\n"]
[140.776, "o", "    >>> r = [1, 2]\r\n"]
[140.786, "o", "    >>> ser = pd.Series(r, copy=False)\r\n"]
[140.796, "o", "    >>> ser.iloc[0] = 999\r\n"]
[140.806, "o", "    >>> r\r\n"]
[140.816, "o", "    [1, 2]\r\n"]
[140.826, "o", "    >>> ser\r\n"]
[140.836, "o", "    0    999\r\n"]
[140.846, "o", "    1      2\r\n"]
[140.856, "o", "    dtype: int64\r\n"]
[140.866, "o", "\r\n"]
[140.876, "o", "    Due to input data type the Series has a `copy` of\r\n"]
[140.886, "o", "    the original data even though `copy=False`, so\r\n"]
[140.896, "o", "    the data is unchanged.\r\n"]
[140.906, "o", "\r\n"]
[140.916, "o", "    Constructing Series from a 1d ndarray with `copy=False`.\r\n"]
[140.926, "o", "\r\n"]
[140.936, "o", "    >>> r = np.array([1, 2])\r\n"]
[140.946, "o", "    >>> ser = pd.Series(r, copy=False)\r\n"]
[140.956, "o", "    >>> ser.iloc[0] = 999\r\n"]
[140.966, "o", "    >>> r\r\n"]
[140.976, "o", "    array([999,   2])\r\n"]
[140.986, "o", "    >>> ser\r\n"]
[140.996, "o", "    0    999\r\n"]
[141.006, "o", "    1      2\r\n"]
[141.016, "o", "    dtype: int64\r\n"]
[141.026, "o", "\r\n"]
[141.036, "o", "    Due to input data type the Series has a `view` on\r\n"]
[141.046, "o", "    the original data, so\r\n"]
[141.056, "o", "    the data is changed as well.\r\n"]
[141.066, "o", "    \"\"\"\r\n"]
[141.076, "o", "\r\n"]
[141.086, "o", "    _typ = \"series\"\r\n"]
[141.096, "o", "    _HANDLED_TYPES = (Index, ExtensionArray, np.ndarray)\r\n"]
[141.106, "o", "\r\n"]
[141.116, "o", "    _name: Hashable\r\n"]
[141.126, "o", "    _metadata: list[str] = [\"name\"]\r\n"]
[141.136, "o", "    _internal_names_set = {\"index\"} | NDFrame._internal_names_set\r\n"]
[141.146, "o", "    _accessors = {\"dt\", \"cat\", \"str\", \"sparse\"}\r\n"]
[141.156, "o", "    _hidden_attrs = (\r\n"]
[141.166, "o", "        base.IndexOpsMixin._hidden_attrs\r\n"]
[141.176, "o", "        | NDFrame._hidden_attrs\r\n"]
[141.186, "o", "        | frozenset([\"compress\", \"ptp\"])\r\n"]
[141.196, "o", "    )\r\n"]
[141.206, "o", "\r\n"]
[141.216, "o", "    # Override cache_readonly bc Series is mutable\r\n"]
[141.226, "o", "    # error: Incompatible types in assignment (expression has type \"property\",\r\n"]
[141.236, "o", "    # base class \"IndexOpsMixin\" defined the type as \"Callable[[IndexOpsMixin], bool]\")\r\n"]
[141.246, "o", "    hasnans = property(  # type: ignore[assignment]\r\n"]
[141.256, "o", "        # error: \"Callable[[IndexOpsMixin], bool]\" has no attribute \"fget\"\r\n"]
[141.266, "o", "        base.IndexOpsMixin.hasnans.fget,  # type: ignore[attr-defined]\r\n"]
[141.276, "o", "        doc=base.IndexOpsMixin.hasnans.__doc__,\r\n"]
[141.286, "o", "    )\r\n"]
[141.296, "o", "    _mgr: SingleManager\r\n"]
[141.306, "o", "    div: Callable[[Series, Any], Series]\r\n"]
[141.316, "o", "    rdiv: Callable[[Series, Any], Series]\r\n"]
[141.326, "o", "\r\n"]
[141.336, "o", "    # ----------------------------------------------------------------------\r\n"]
[141.346, "o", "    # Constructors\r\n"]
[141.356, "o", "\r\n"]
[141.366, "o", "    def __init__(\r\n"]
[141.376, "o", "        self,\r\n"]
[141.386, "o", "        data=None,\r\n"]
[141.396, "o", "        index=None,\r\n"]
[141.406, "o", "        dtype: Dtype | None = None,\r\n"]
[141.416, "o", "        name=None,\r\n"]
[141.426, "o", "        copy: bool = False,\r\n"]
[141.436, "o", "        fastpath: bool = False,\r\n"]
[141.446, "o", "    ) -> None:\r\n"]
[141.456, "o", "\r\n"]
[141.466, "o", "        if (\r\n"]
[141.476, "o", "            isinstance(data, (SingleBlockManager, SingleArrayManager))\r\n"]
[141.486, "o", "            and index is None\r\n"]
[141.496, "o", "            and dtype is None\r\n"]
[141.506, "o", "            and copy is False\r\n"]
[141.516, "o", "        ):\r\n"]
[141.526, "o", "            # GH#33357 called with just the SingleBlockManager\r\n"]
[141.536, "o", "            NDFrame.__init__(self, data)\r\n"]
[141.546, "o", "            if fastpath:\r\n"]
[141.556, "o", "                # e.g. from _box_col_values, skip validation of name\r\n"]
[141.566, "o", "                object.__setattr__(self, \"_name\", name)\r\n"]
[141.576, "o", "            else:\r\n"]
[141.586, "o", "                self.name = name\r\n"]
[141.596, "o", "            return\r\n"]
[141.606, "o", "\r\n"]
[141.616, "o", "        # we are called internally, so short-circuit\r\n"]
[141.626, "o", "        if fastpath:\r\n"]
[141.636, "o", "            # data is a ndarray, index is defined\r\n"]
[141.646, "o", "            if not isinstance(data, (SingleBlockManager, SingleArrayManager)):\r\n"]
[141.656, "o", "                manager = get_option(\"mode.data_manager\")\r\n"]
[141.666, "o", "                if manager == \"block\":\r\n"]
[141.676, "o", "                    data = SingleBlockManager.from_array(data, index)\r\n"]
[141.686, "o", "                elif manager == \"array\":\r\n"]
[141.696, "o", "                    data = SingleArrayManager.from_array(data, index)\r\n"]
[141.706, "o", "            if copy:\r\n"]
[141.716, "o", "                data = data.copy()\r\n"]
[141.726, "o", "            # skips validation of the name\r\n"]
[141.736, "o", "            object.__setattr__(self, \"_name\", name)\r\n"]
[141.746, "o", "            NDFrame.__init__(self, data)\r\n"]
[141.756, "o", "            return\r\n"]
[141.766, "o", "\r\n"]
[141.776, "o", "        name = ibase.maybe_extract_name(name, data, type(self))\r\n"]
[141.786, "o", "\r\n"]
[141.796, "o", "        if index is not None:\r\n"]
[141.806, "o", "            index = ensure_index(index)\r\n"]
[141.816, "o", "\r\n"]
[141.826, "o", "        if dtype is not None:\r\n"]
[141.836, "o", "            dtype = self._validate_dtype(dtype)\r\n"]
[141.846, "o", "\r\n"]
[141.856, "o", "        if data is None:\r\n"]
[141.866, "o", "            index = index if index is not None else default_index(0)\r\n"]
[141.876, "o", "            if len(index) or dtype is not None:\r\n"]
[141.886, "o", "                data = na_value_for_dtype(pandas_dtype(dtype), compat=False)\r\n"]
[141.896, "o", "            else:\r\n"]
[141.906, "o", "                data = []\r\n"]
[141.916, "o", "\r\n"]
[141.926, "o", "        if isinstance(data, MultiIndex):\r\n"]
[141.936, "o", "            raise NotImplementedError(\r\n"]
[141.946, "o", "                \"initializing a Series from a MultiIndex is not supported\"\r\n"]
[141.956, "o", "            )\r\n"]
[141.966, "o", "        if isinstance(data, Index):\r\n"]
[141.976, "o", "\r\n"]
[141.986, "o", "            if dtype is not None:\r\n"]
[141.996, "o", "                # astype copies\r\n"]
[142.006, "o", "                data = data.astype(dtype)\r\n"]
[142.016, "o", "            else:\r\n"]
[142.026, "o", "                # GH#24096 we need to ensure the index remains immutable\r\n"]
[142.036, "o", "                data = data._values.copy()\r\n"]
[142.046, "o", "            copy = False\r\n"]
[142.056, "o", "\r\n"]
[142.066, "o", "        elif isinstance(data, np.ndarray):\r\n"]
[142.076, "o", "            if len(data.dtype):\r\n"]
[142.086, "o", "                # GH#13296 we are dealing with a compound dtype, which\r\n"]
[142.096, "o", "                #  should be treated as 2D\r\n"]
[142.106, "o", "                raise ValueError(\r\n"]
[142.116, "o", "                    \"Cannot construct a Series from an ndarray with \"\r\n"]
[142.126, "o", "                    \"compound dtype.  Use DataFrame instead.\"\r\n"]
[142.136, "o", "                )\r\n"]
[142.146, "o", "        elif isinstance(data, Series):\r\n"]
[142.156, "o", "            if index is None:\r\n"]
[142.166, "o", "                index = data.index\r\n"]
[142.176, "o", "                if using_copy_on_write():\r\n"]
[142.186, "o", "                    data = data._mgr.copy(deep=False)\r\n"]
[142.196, "o", "                else:\r\n"]
[142.206, "o", "                    data = data._mgr\r\n"]
[142.216, "o", "            else:\r\n"]
[142.226, "o", "                data = data.reindex(index, copy=copy)\r\n"]
[142.236, "o", "                copy = False\r\n"]
[142.246, "o", "                data = data._mgr\r\n"]
[142.256, "o", "        elif is_dict_like(data):\r\n"]
[142.266, "o", "            data, index = self._init_dict(data, index, dtype)\r\n"]
[142.276, "o", "            dtype = None\r\n"]
[142.286, "o", "            copy = False\r\n"]
[142.296, "o", "        elif isinstance(data, (SingleBlockManager, SingleArrayManager)):\r\n"]
[142.306, "o", "            if index is None:\r\n"]
[142.316, "o", "                index = data.index\r\n"]
[142.326, "o", "            elif not data.index.equals(index) or copy:\r\n"]
[142.336, "o", "                # GH#19275 SingleBlockManager input should only be called\r\n"]
[142.346, "o", "                # internally\r\n"]
[142.356, "o", "                raise AssertionError(\r\n"]
[142.366, "o", "                    \"Cannot pass both SingleBlockManager \"\r\n"]
[142.376, "o", "                    \"`data` argument and a different \"\r\n"]
[142.386, "o", "                    \"`index` argument. `copy` must be False.\"\r\n"]
[142.396, "o", "                )\r\n"]
[142.406, "o", "\r\n"]
[142.416, "o", "        elif isinstance(data, ExtensionArray):\r\n"]
[142.426, "o", "            pass\r\n"]
[142.436, "o", "        else:\r\n"]
[142.446, "o", "            data = com.maybe_iterable_to_list(data)\r\n"]
[142.456, "o", "            if is_list_like(data) and not len(data) and dtype is None:\r\n"]
[142.466, "o", "                # GH 29405: Pre-2.0, this defaulted to float.\r\n"]
[142.476, "o", "                dtype = np.dtype(object)\r\n"]
[142.486, "o", "\r\n"]
[142.496, "o", "        if index is None:\r\n"]
[142.506, "o", "            if not is_list_like(data):\r\n"]
[142.516, "o", "                data = [data]\r\n"]
[142.526, "o", "            index = default_index(len(data))\r\n"]
[142.536, "o", "        elif is_list_like(data):\r\n"]
[142.546, "o", "            com.require_length_match(data, index)\r\n"]
[142.556, "o", "\r\n"]
[142.566, "o", "        # create/copy the manager\r\n"]
[142.576, "o", "        if isinstance(data, (SingleBlockManager, SingleArrayManager)):\r\n"]
[142.586, "o", "            if dtype is not None:\r\n"]
[142.596, "o", "                data = data.astype(dtype=dtype, errors=\"ignore\", copy=copy)\r\n"]
[142.606, "o", "            elif copy:\r\n"]
[142.616, "o", "                data = data.copy()\r\n"]
[142.626, "o", "        else:\r\n"]
[142.636, "o", "            data = sanitize_array(data, index, dtype, copy)\r\n"]
[142.646, "o", "\r\n"]
[142.656, "o", "            manager = get_option(\"mode.data_manager\")\r\n"]
[142.666, "o", "            if manager == \"block\":\r\n"]
[142.676, "o", "                data = SingleBlockManager.from_array(data, index)\r\n"]
[142.686, "o", "            elif manager == \"array\":\r\n"]
[142.696, "o", "                data = SingleArrayManager.from_array(data, index)\r\n"]
[142.706, "o", "\r\n"]
[142.716, "o", "        NDFrame.__init__(self, data)\r\n"]
[142.726, "o", "        self.name = name\r\n"]
[142.736, "o", "        self._set_axis(0, index)\r\n"]
[142.746, "o", "\r\n"]
[142.756, "o", "    def _init_dict(\r\n"]
[142.766, "o", "        self, data, index: Index | None = None, dtype: DtypeObj | None = None\r\n"]
[142.776, "o", "    ):\r\n"]
[142.786, "o", "        \"\"\"\r\n"]
[142.796, "o", "        Derive the \"_mgr\" and \"index\" attributes of a new Series from a\r\n"]
[142.806, "o", "        dictionary input.\r\n"]
[142.816, "o", "\r\n"]
[142.826, "o", "        Parameters\r\n"]
[142.836, "o", "        ----------\r\n"]
[142.846, "o", "        data : dict or dict-like\r\n"]
[142.856, "o", "            Data used to populate the new Series.\r\n"]
[142.866, "o", "        index : Index or None, default None\r\n"]
[142.876, "o", "            Index for the new Series: if None, use dict keys.\r\n"]
[142.886, "o", "        dtype : np.dtype, ExtensionDtype, or None, default None\r\n"]
[142.896, "o", "            The dtype for the new Series: if None, infer from data.\r\n"]
[142.906, "o", "\r\n"]
[142.916, "o", "        Returns\r\n"]
[142.926, "o", "        -------\r\n"]
[142.936, "o", "        _data : BlockManager for the new Series\r\n"]
[142.946, "o", "        index : index for the new Series\r\n"]
[142.956, "o", "        \"\"\"\r\n"]
[142.966, "o", "        keys: Index | tuple\r\n"]
[142.976, "o", "\r\n"]
[142.986, "o", "        # Looking for NaN in dict doesn't work ({np.nan : 1}[float('nan')]\r\n"]
[142.996, "o", "        # raises KeyError), so we iterate the entire dict, and align\r\n"]
[143.006, "o", "        if data:\r\n"]
[143.016, "o", "            # GH:34717, issue was using zip to extract key and values from data.\r\n"]
[143.026, "o", "            # using generators in effects the performance.\r\n"]
[143.036, "o", "            # Below is the new way of extracting the keys and values\r\n"]
[143.046, "o", "\r\n"]
[143.056, "o", "            keys = tuple(data.keys())\r\n"]
[143.066, "o", "            values = list(data.values())  # Generating list of values- faster way\r\n"]
[143.076, "o", "        elif index is not None:\r\n"]
[143.086, "o", "            # fastpath for Series(data=None). Just use broadcasting a scalar\r\n"]
[143.096, "o", "            # instead of reindexing.\r\n"]
[143.106, "o", "            if len(index) or dtype is not None:\r\n"]
[143.116, "o", "                values = na_value_for_dtype(pandas_dtype(dtype), compat=False)\r\n"]
[143.126, "o", "            else:\r\n"]
[143.136, "o", "                values = []\r\n"]
[143.146, "o", "            keys = index\r\n"]
[143.156, "o", "        else:\r\n"]
[143.166, "o", "            keys, values = (), []\r\n"]
[143.176, "o", "\r\n"]
[143.186, "o", "        # Input is now list-like, so rely on \"standard\" construction:\r\n"]
[143.196, "o", "\r\n"]
[143.206, "o", "        s = self._constructor(\r\n"]
[143.216, "o", "            values,\r\n"]
[143.226, "o", "            index=keys,\r\n"]
[143.236, "o", "            dtype=dtype,\r\n"]
[143.246, "o", "        )\r\n"]
[143.256, "o", "\r\n"]
[143.266, "o", "        # Now we just make sure the order is respected, if any\r\n"]
[143.276, "o", "        if data and index is not None:\r\n"]
[143.286, "o", "            s = s.reindex(index, copy=False)\r\n"]
[143.296, "o", "        return s._mgr, s.index\r\n"]
[143.306, "o", "\r\n"]
[143.316, "o", "    # ----------------------------------------------------------------------\r\n"]
[143.326, "o", "\r\n"]
[143.336, "o", "    @property\r\n"]
[143.346, "o", "    def _constructor(self) -> Callable[..., Series]:\r\n"]
[143.356, "o", "        return Series\r\n"]
[143.366, "o", "\r\n"]
[143.376, "o", "    @property\r\n"]
[143.386, "o", "    def _constructor_expanddim(self) -> Callable[..., DataFrame]:\r\n"]
[143.396, "o", "        \"\"\"\r\n"]
[143.406, "o", "        Used when a manipulation result has one higher dimension as the\r\n"]
[143.416, "o", "        original, such as Series.to_frame()\r\n"]
[143.426, "o", "        \"\"\"\r\n"]
[143.436, "o", "        from pandas.core.frame import DataFrame\r\n"]
[143.446, "o", "\r\n"]
[143.456, "o", "        return DataFrame\r\n"]
[143.466, "o", "\r\n"]
[143.476, "o", "    # types\r\n"]
[143.486, "o", "    @property\r\n"]
[143.496, "o", "    def _can_hold_na(self) -> bool:\r\n"]
[143.506, "o", "        return self._mgr._can_hold_na\r\n"]
[143.516, "o", "\r\n"]
[143.526, "o", "    # ndarray compatibility\r\n"]
[143.536, "o", "    @property\r\n"]
[143.546, "o", "    def dtype(self) -> DtypeObj:\r\n"]
[143.556, "o", "        \"\"\"\r\n"]
[143.566, "o", "        Return the dtype object of the underlying data.\r\n"]
[143.576, "o", "        \"\"\"\r\n"]
[143.586, "o", "        return self._mgr.dtype\r\n"]
[143.596, "o", "\r\n"]
[143.606, "o", "    @property\r\n"]
[143.616, "o", "    def dtypes(self) -> DtypeObj:\r\n"]
[143.626, "o", "        \"\"\"\r\n"]
[143.636, "o", "        Return the dtype object of the underlying data.\r\n"]
[143.646, "o", "        \"\"\"\r\n"]
[143.656, "o", "        # DataFrame compatibility\r\n"]
[143.666, "o", "        return self.dtype\r\n"]
[143.676, "o", "\r\n"]
[143.686, "o", "    @property\r\n"]
[143.696, "o", "    def name(self) -> Hashable:\r\n"]
[143.706, "o", "        \"\"\"\r\n"]
[143.716, "o", "        Return the name of the Series.\r\n"]
[143.726, "o", "\r\n"]
[143.736, "o", "        The name of a Series becomes its index or column name if it is used\r\n"]
[143.746, "o", "        to form a DataFrame. It is also used whenever displaying the Series\r\n"]
[143.756, "o", "        using the interpreter.\r\n"]
[143.766, "o", "\r\n"]
[143.776, "o", "        Returns\r\n"]
[143.786, "o", "        -------\r\n"]
[143.796, "o", "        label (hashable object)\r\n"]
[143.806, "o", "            The name of the Series, also the column name if part of a DataFrame.\r\n"]
[143.816, "o", "\r\n"]
[143.826, "o", "        See Also\r\n"]
[143.836, "o", "        --------\r\n"]
[143.846, "o", "        Series.rename : Sets the Series name when given a scalar input.\r\n"]
[143.856, "o", "        Index.name : Corresponding Index property.\r\n"]
[143.866, "o", "\r\n"]
[143.876, "o", "        Examples\r\n"]
[143.886, "o", "        --------\r\n"]
[143.896, "o", "        The Series name can be set initially when calling the constructor.\r\n"]
[143.906, "o", "\r\n"]
[143.916, "o", "        >>> s = pd.Series([1, 2, 3], dtype=np.int64, name='Numbers')\r\n"]
[143.926, "o", "        >>> s\r\n"]
[143.936, "o", "        0    1\r\n"]
[143.946, "o", "        1    2\r\n"]
[143.956, "o", "        2    3\r\n"]
[143.966, "o", "        Name: Numbers, dtype: int64\r\n"]
[143.976, "o", "        >>> s.name = \"Integers\"\r\n"]
[143.986, "o", "        >>> s\r\n"]
[143.996, "o", "        0    1\r\n"]
[144.006, "o", "        1    2\r\n"]
[144.016, "o", "        2    3\r\n"]
[144.026, "o", "        Name: Integers, dtype: int64\r\n"]
[144.036, "o", "\r\n"]
[144.046, "o", "        The name of a Series within a DataFrame is its column name.\r\n"]
[144.056, "o", "\r\n"]
[144.066, "o", "        >>> df = pd.DataFrame([[1, 2], [3, 4], [5, 6]],\r\n"]
[144.076, "o", "        ...                   columns=[\"Odd Numbers\", \"Even Numbers\"])\r\n"]
[144.086, "o", "        >>> df\r\n"]
[144.096, "o", "           Odd Numbers  Even Numbers\r\n"]
[144.106, "o", "        0            1             2\r\n"]
[144.116, "o", "        1            3             4\r\n"]
[144.126, "o", "        2            5             6\r\n"]
[144.136, "o", "        >>> df[\"Even Numbers\"].name\r\n"]
[144.146, "o", "        'Even Numbers'\r\n"]
[144.156, "o", "        \"\"\"\r\n"]
[144.166, "o", "        return self._name\r\n"]
[144.176, "o", "\r\n"]
[144.186, "o", "    @name.setter\r\n"]
[144.196, "o", "    def name(self, value: Hashable) -> None:\r\n"]
[144.206, "o", "        validate_all_hashable(value, error_name=f\"{type(self).__name__}.name\")\r\n"]
[144.216, "o", "        object.__setattr__(self, \"_name\", value)\r\n"]
[144.226, "o", "\r\n"]
[144.236, "o", "    @property\r\n"]
[144.246, "o", "    def values(self):\r\n"]
[144.256, "o", "        \"\"\"\r\n"]
[144.266, "o", "        Return Series as ndarray or ndarray-like depending on the dtype.\r\n"]
[144.276, "o", "\r\n"]
[144.286, "o", "        .. warning::\r\n"]
[144.296, "o", "\r\n"]
[144.306, "o", "           We recommend using :attr:`Series.array` or\r\n"]
[144.316, "o", "           :meth:`Series.to_numpy`, depending on whether you need\r\n"]
[144.326, "o", "           a reference to the underlying data or a NumPy array.\r\n"]
[144.336, "o", "\r\n"]
[144.346, "o", "        Returns\r\n"]
[144.356, "o", "        -------\r\n"]
[144.366, "o", "        numpy.ndarray or ndarray-like\r\n"]
[144.376, "o", "\r\n"]
[144.386, "o", "        See Also\r\n"]
[144.396, "o", "        --------\r\n"]
[144.406, "o", "        Series.array : Reference to the underlying data.\r\n"]
[144.416, "o", "        Series.to_numpy : A NumPy array representing the underlying data.\r\n"]
[144.426, "o", "\r\n"]
[144.436, "o", "        Examples\r\n"]
[144.446, "o", "        --------\r\n"]
[144.456, "o", "        >>> pd.Series([1, 2, 3]).values\r\n"]
[144.466, "o", "        array([1, 2, 3])\r\n"]
[144.476, "o", "\r\n"]
[144.486, "o", "        >>> pd.Series(list('aabc')).values\r\n"]
[144.496, "o", "        array(['a', 'a', 'b', 'c'], dtype=object)\r\n"]
[144.506, "o", "\r\n"]
[144.516, "o", "        >>> pd.Series(list('aabc')).astype('category').values\r\n"]
[144.526, "o", "        ['a', 'a', 'b', 'c']\r\n"]
[144.536, "o", "        Categories (3, object): ['a', 'b', 'c']\r\n"]
[144.546, "o", "\r\n"]
[144.556, "o", "        Timezone aware datetime data is converted to UTC:\r\n"]
[144.566, "o", "\r\n"]
[144.576, "o", "        >>> pd.Series(pd.date_range('20130101', periods=3,\r\n"]
[144.586, "o", "        ...                         tz='US/Eastern')).values\r\n"]
[144.596, "o", "        array(['2013-01-01T05:00:00.000000000',\r\n"]
[144.606, "o", "               '2013-01-02T05:00:00.000000000',\r\n"]
[144.616, "o", "               '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\r\n"]
[144.626, "o", "        \"\"\"\r\n"]
[144.636, "o", "        return self._mgr.external_values()\r\n"]
[144.646, "o", "\r\n"]
[144.656, "o", "    @property\r\n"]
[144.666, "o", "    def _values(self):\r\n"]
[144.676, "o", "        \"\"\"\r\n"]
[144.686, "o", "        Return the internal repr of this data (defined by Block.interval_values).\r\n"]
[144.696, "o", "        This are the values as stored in the Block (ndarray or ExtensionArray\r\n"]
[144.706, "o", "        depending on the Block class), with datetime64[ns] and timedelta64[ns]\r\n"]
[144.716, "o", "        wrapped in ExtensionArrays to match Index._values behavior.\r\n"]
[144.726, "o", "\r\n"]
[144.736, "o", "        Differs from the public ``.values`` for certain data types, because of\r\n"]
[144.746, "o", "        historical backwards compatibility of the public attribute (e.g. period\r\n"]
[144.756, "o", "        returns object ndarray and datetimetz a datetime64[ns] ndarray for\r\n"]
[144.766, "o", "        ``.values`` while it returns an ExtensionArray for ``._values`` in those\r\n"]
[144.776, "o", "        cases).\r\n"]
[144.786, "o", "\r\n"]
[144.796, "o", "        Differs from ``.array`` in that this still returns the numpy array if\r\n"]
[144.806, "o", "        the Block is backed by a numpy array (except for datetime64 and\r\n"]
[144.816, "o", "        timedelta64 dtypes), while ``.array`` ensures to always return an\r\n"]
[144.826, "o", "        ExtensionArray.\r\n"]
[144.836, "o", "\r\n"]
[144.846, "o", "        Overview:\r\n"]
[144.856, "o", "\r\n"]
[144.866, "o", "        dtype       | values        | _values       | array         |\r\n"]
[144.876, "o", "        ----------- | ------------- | ------------- | ------------- |\r\n"]
[144.886, "o", "        Numeric     | ndarray       | ndarray       | PandasArray   |\r\n"]
[144.896, "o", "        Category    | Categorical   | Categorical   | Categorical   |\r\n"]
[144.906, "o", "        dt64[ns]    | ndarray[M8ns] | DatetimeArray | DatetimeArray |\r\n"]
[144.916, "o", "        dt64[ns tz] | ndarray[M8ns] | DatetimeArray | DatetimeArray |\r\n"]
[144.926, "o", "        td64[ns]    | ndarray[m8ns] | TimedeltaArray| ndarray[m8ns] |\r\n"]
[144.936, "o", "        Period      | ndarray[obj]  | PeriodArray   | PeriodArray   |\r\n"]
[145.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[145.002, "i", "sed -n '1,240p' pandas/core/arrays/base.py\r"]
[145.004, "o", "sed -n '1,240p' pandas/core/arrays/base.py\r\n"]
[145.026515, "o", "\u001b[?2004l\r\n"]
[145.047029, "o", "\"\"\"\r\n"]
[145.067544, "o", "An interface for extending pandas with custom arrays.\r\n"]
[145.088058, "o", "\r\n"]
[145.108573, "o", ".. warning::\r\n"]
[145.129087, "o", "\r\n"]
[145.149602, "o", "   This is an experimental API and subject to breaking changes\r\n"]
[145.170116, "o", "   without warning.\r\n"]
[145.190631, "o", "\"\"\"\r\n"]
[145.211145, "o", "from __future__ import annotations\r\n"]
[145.23166, "o", "\r\n"]
[145.252174, "o", "import operator\r\n"]
[145.272689, "o", "from typing import (\r\n"]
[145.293203, "o", "    TYPE_CHECKING,\r\n"]
[145.313718, "o", "    Any,\r\n"]
[145.334232, "o", "    Callable,\r\n"]
[145.354747, "o", "    ClassVar,\r\n"]
[145.375261, "o", "    Iterator,\r\n"]
[145.395776, "o", "    Literal,\r\n"]
[145.41629, "o", "    Sequence,\r\n"]
[145.436805, "o", "    TypeVar,\r\n"]
[145.45732, "o", "    cast,\r\n"]
[145.477834, "o", "    overload,\r\n"]
[145.498349, "o", ")\r\n"]
[145.518863, "o", "\r\n"]
[145.539378, "o", "import numpy as np\r\n"]
[145.559892, "o", "\r\n"]
[145.580407, "o", "from pandas._libs import lib\r\n"]
[145.600921, "o", "from pandas._typing import (\r\n"]
[145.621436, "o", "    ArrayLike,\r\n"]
[145.64195, "o", "    AstypeArg,\r\n"]
[145.662465, "o", "    AxisInt,\r\n"]
[145.682979, "o", "    Dtype,\r\n"]
[145.703494, "o", "    FillnaOptions,\r\n"]
[145.724008, "o", "    PositionalIndexer,\r\n"]
[145.744523, "o", "    ScalarIndexer,\r\n"]
[145.765037, "o", "    SequenceIndexer,\r\n"]
[145.785552, "o", "    Shape,\r\n"]
[145.806066, "o", "    SortKind,\r\n"]
[145.826581, "o", "    TakeIndexer,\r\n"]
[145.847095, "o", "    npt,\r\n"]
[145.86761, "o", ")\r\n"]
[145.888124, "o", "from pandas.compat import set_function_name\r\n"]
[145.908639, "o", "from pandas.compat.numpy import function as nv\r\n"]
[145.929154, "o", "from pandas.errors import AbstractMethodError\r\n"]
[145.949668, "o", "from pandas.util._decorators import (\r\n"]
[145.970183, "o", "    Appender,\r\n"]
[145.990697, "o", "    Substitution,\r\n"]
[146.011212, "o", "    cache_readonly,\r\n"]
[146.031726, "o", ")\r\n"]
[146.052241, "o", "from pandas.util._validators import (\r\n"]
[146.072755, "o", "    validate_bool_kwarg,\r\n"]
[146.09327, "o", "    validate_fillna_kwargs,\r\n"]
[146.113784, "o", "    validate_insert_loc,\r\n"]
[146.134299, "o", ")\r\n"]
[146.154813, "o", "\r\n"]
[146.175328, "o", "from pandas.core.dtypes.cast import maybe_cast_to_extension_array\r\n"]
[146.195842, "o", "from pandas.core.dtypes.common import (\r\n"]
[146.216357, "o", "    is_datetime64_dtype,\r\n"]
[146.236871, "o", "    is_dtype_equal,\r\n"]
[146.257386, "o", "    is_list_like,\r\n"]
[146.2779, "o", "    is_scalar,\r\n"]
[146.298415, "o", "    is_timedelta64_dtype,\r\n"]
[146.318929, "o", "    pandas_dtype,\r\n"]
[146.339444, "o", ")\r\n"]
[146.359959, "o", "from pandas.core.dtypes.dtypes import ExtensionDtype\r\n"]
[146.380473, "o", "from pandas.core.dtypes.generic import (\r\n"]
[146.400988, "o", "    ABCDataFrame,\r\n"]
[146.421502, "o", "    ABCIndex,\r\n"]
[146.442017, "o", "    ABCSeries,\r\n"]
[146.462531, "o", ")\r\n"]
[146.483046, "o", "from pandas.core.dtypes.missing import isna\r\n"]
[146.50356, "o", "\r\n"]
[146.524075, "o", "from pandas.core import (\r\n"]
[146.544589, "o", "    arraylike,\r\n"]
[146.565104, "o", "    missing,\r\n"]
[146.585618, "o", "    roperator,\r\n"]
[146.606133, "o", ")\r\n"]
[146.626647, "o", "from pandas.core.algorithms import (\r\n"]
[146.647162, "o", "    factorize_array,\r\n"]
[146.667676, "o", "    isin,\r\n"]
[146.688191, "o", "    mode,\r\n"]
[146.708705, "o", "    rank,\r\n"]
[146.72922, "o", "    unique,\r\n"]
[146.749734, "o", ")\r\n"]
[146.770249, "o", "from pandas.core.array_algos.quantile import quantile_with_mask\r\n"]
[146.790763, "o", "from pandas.core.sorting import (\r\n"]
[146.811278, "o", "    nargminmax,\r\n"]
[146.831793, "o", "    nargsort,\r\n"]
[146.852307, "o", ")\r\n"]
[146.872822, "o", "\r\n"]
[146.893336, "o", "if TYPE_CHECKING:\r\n"]
[146.913851, "o", "\r\n"]
[146.934365, "o", "    from pandas._typing import (\r\n"]
[146.95488, "o", "        NumpySorter,\r\n"]
[146.975394, "o", "        NumpyValueArrayLike,\r\n"]
[146.995909, "o", "    )\r\n"]
[147.016423, "o", "\r\n"]
[147.036938, "o", "_extension_array_shared_docs: dict[str, str] = {}\r\n"]
[147.057452, "o", "\r\n"]
[147.077967, "o", "ExtensionArrayT = TypeVar(\"ExtensionArrayT\", bound=\"ExtensionArray\")\r\n"]
[147.098481, "o", "\r\n"]
[147.118996, "o", "\r\n"]
[147.13951, "o", "class ExtensionArray:\r\n"]
[147.160025, "o", "    \"\"\"\r\n"]
[147.180539, "o", "    Abstract base class for custom 1-D array types.\r\n"]
[147.201054, "o", "\r\n"]
[147.221568, "o", "    pandas will recognize instances of this class as proper arrays\r\n"]
[147.242083, "o", "    with a custom type and will not attempt to coerce them to objects. They\r\n"]
[147.262598, "o", "    may be stored directly inside a :class:`DataFrame` or :class:`Series`.\r\n"]
[147.283112, "o", "\r\n"]
[147.303627, "o", "    Attributes\r\n"]
[147.324141, "o", "    ----------\r\n"]
[147.344656, "o", "    dtype\r\n"]
[147.36517, "o", "    nbytes\r\n"]
[147.385685, "o", "    ndim\r\n"]
[147.406199, "o", "    shape\r\n"]
[147.426714, "o", "\r\n"]
[147.447228, "o", "    Methods\r\n"]
[147.467743, "o", "    -------\r\n"]
[147.488257, "o", "    argsort\r\n"]
[147.508772, "o", "    astype\r\n"]
[147.529286, "o", "    copy\r\n"]
[147.549801, "o", "    dropna\r\n"]
[147.570315, "o", "    factorize\r\n"]
[147.59083, "o", "    fillna\r\n"]
[147.611344, "o", "    equals\r\n"]
[147.631859, "o", "    insert\r\n"]
[147.652373, "o", "    isin\r\n"]
[147.672888, "o", "    isna\r\n"]
[147.693402, "o", "    ravel\r\n"]
[147.713917, "o", "    repeat\r\n"]
[147.734432, "o", "    searchsorted\r\n"]
[147.754946, "o", "    shift\r\n"]
[147.775461, "o", "    take\r\n"]
[147.795975, "o", "    tolist\r\n"]
[147.81649, "o", "    unique\r\n"]
[147.837004, "o", "    view\r\n"]
[147.857519, "o", "    _accumulate\r\n"]
[147.878033, "o", "    _concat_same_type\r\n"]
[147.898548, "o", "    _formatter\r\n"]
[147.919062, "o", "    _from_factorized\r\n"]
[147.939577, "o", "    _from_sequence\r\n"]
[147.960091, "o", "    _from_sequence_of_strings\r\n"]
[147.980606, "o", "    _reduce\r\n"]
[148.00112, "o", "    _values_for_argsort\r\n"]
[148.021635, "o", "    _values_for_factorize\r\n"]
[148.042149, "o", "\r\n"]
[148.062664, "o", "    Notes\r\n"]
[148.083178, "o", "    -----\r\n"]
[148.103693, "o", "    The interface includes the following abstract methods that must be\r\n"]
[148.124207, "o", "    implemented by subclasses:\r\n"]
[148.144722, "o", "\r\n"]
[148.165237, "o", "    * _from_sequence\r\n"]
[148.185751, "o", "    * _from_factorized\r\n"]
[148.206266, "o", "    * __getitem__\r\n"]
[148.22678, "o", "    * __len__\r\n"]
[148.247295, "o", "    * __eq__\r\n"]
[148.267809, "o", "    * dtype\r\n"]
[148.288324, "o", "    * nbytes\r\n"]
[148.308838, "o", "    * isna\r\n"]
[148.329353, "o", "    * take\r\n"]
[148.349867, "o", "    * copy\r\n"]
[148.370382, "o", "    * _concat_same_type\r\n"]
[148.390896, "o", "\r\n"]
[148.411411, "o", "    A default repr displaying the type, (truncated) data, length,\r\n"]
[148.431925, "o", "    and dtype is provided. It can be customized or replaced by\r\n"]
[148.45244, "o", "    by overriding:\r\n"]
[148.472954, "o", "\r\n"]
[148.493469, "o", "    * __repr__ : A default repr for the ExtensionArray.\r\n"]
[148.513983, "o", "    * _formatter : Print scalars inside a Series or DataFrame.\r\n"]
[148.534498, "o", "\r\n"]
[148.555012, "o", "    Some methods require casting the ExtensionArray to an ndarray of Python\r\n"]
[148.575527, "o", "    objects with ``self.astype(object)``, which may be expensive. When\r\n"]
[148.596041, "o", "    performance is a concern, we highly recommend overriding the following\r\n"]
[148.616556, "o", "    methods:\r\n"]
[148.637071, "o", "\r\n"]
[148.657585, "o", "    * fillna\r\n"]
[148.6781, "o", "    * dropna\r\n"]
[148.698614, "o", "    * unique\r\n"]
[148.719129, "o", "    * factorize / _values_for_factorize\r\n"]
[148.739643, "o", "    * argsort, argmax, argmin / _values_for_argsort\r\n"]
[148.760158, "o", "    * searchsorted\r\n"]
[148.780672, "o", "\r\n"]
[148.801187, "o", "    The remaining methods implemented on this class should be performant,\r\n"]
[148.821701, "o", "    as they only compose abstract methods. Still, a more efficient\r\n"]
[148.842216, "o", "    implementation may be available, and these methods can be overridden.\r\n"]
[148.86273, "o", "\r\n"]
[148.883245, "o", "    One can implement methods to handle array accumulations or reductions.\r\n"]
[148.903759, "o", "\r\n"]
[148.924274, "o", "    * _accumulate\r\n"]
[148.944788, "o", "    * _reduce\r\n"]
[148.965303, "o", "\r\n"]
[148.985817, "o", "    One can implement methods to handle parsing from strings that will be used\r\n"]
[149.006332, "o", "    in methods such as ``pandas.io.parsers.read_csv``.\r\n"]
[149.026846, "o", "\r\n"]
[149.047361, "o", "    * _from_sequence_of_strings\r\n"]
[149.067876, "o", "\r\n"]
[149.08839, "o", "    This class does not inherit from 'abc.ABCMeta' for performance reasons.\r\n"]
[149.108905, "o", "    Methods and properties required by the interface raise\r\n"]
[149.129419, "o", "    ``pandas.errors.AbstractMethodError`` and no ``register`` method is\r\n"]
[149.149934, "o", "    provided for registering virtual subclasses.\r\n"]
[149.170448, "o", "\r\n"]
[149.190963, "o", "    ExtensionArrays are limited to 1 dimension.\r\n"]
[149.211477, "o", "\r\n"]
[149.231992, "o", "    They may be backed by none, one, or many NumPy arrays. For example,\r\n"]
[149.252506, "o", "    ``pandas.Categorical`` is an extension array backed by two arrays,\r\n"]
[149.273021, "o", "    one for codes and one for categories. An array of IPv6 address may\r\n"]
[149.293535, "o", "    be backed by a NumPy structured array with two fields, one for the\r\n"]
[149.31405, "o", "    lower 64 bits and one for the upper 64 bits. Or they may be backed\r\n"]
[149.334564, "o", "    by some other storage type, like Python lists. Pandas makes no\r\n"]
[149.355079, "o", "    assumptions on how the data are stored, just that it can be converted\r\n"]
[149.375593, "o", "    to a NumPy array.\r\n"]
[149.396108, "o", "    The ExtensionArray interface does not impose any rules on how this data\r\n"]
[149.416622, "o", "    is stored. However, currently, the backing data cannot be stored in\r\n"]
[149.437137, "o", "    attributes called ``.values`` or ``._values`` to ensure full compatibility\r\n"]
[149.457651, "o", "    with pandas internals. But other names as ``.data``, ``._data``,\r\n"]
[149.478166, "o", "    ``._items``, ... can be freely used.\r\n"]
[149.49868, "o", "\r\n"]
[149.519195, "o", "    If implementing NumPy's ``__array_ufunc__`` interface, pandas expects\r\n"]
[149.53971, "o", "    that\r\n"]
[149.560224, "o", "\r\n"]
[149.580739, "o", "    1. You defer by returning ``NotImplemented`` when any Series are present\r\n"]
[149.601253, "o", "       in `inputs`. Pandas will extract the arrays and call the ufunc again.\r\n"]
[149.621768, "o", "    2. You define a ``_HANDLED_TYPES`` tuple as an attribute on the class.\r\n"]
[149.642282, "o", "       Pandas inspect this to determine whether the ufunc is valid for the\r\n"]
[149.662797, "o", "       types present.\r\n"]
[149.683311, "o", "\r\n"]
[149.703826, "o", "    See :ref:`extending.extension.ufunc` for more.\r\n"]
[149.72434, "o", "\r\n"]
[149.744855, "o", "    By default, ExtensionArrays are not hashable.  Immutable subclasses may\r\n"]
[149.765369, "o", "    override this behavior.\r\n"]
[149.785884, "o", "    \"\"\"\r\n"]
[149.806398, "o", "\r\n"]
[149.826913, "o", "    # '_typ' is for pandas.core.dtypes.generic.ABCExtensionArray.\r\n"]
[149.847427, "o", "    # Don't override this.\r\n"]
[149.867942, "o", "    _typ = \"extension\"\r\n"]
[149.888456, "o", "\r\n"]
[149.908971, "o", "    # ------------------------------------------------------------------------\r\n"]
[149.929485, "o", "    # Constructors\r\n"]
[150.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[150.002, "i", "sed -n '520,760p' pandas/core/base.py\r"]
[150.004, "o", "sed -n '520,760p' pandas/core/base.py\r\n"]
[150.02643, "o", "\u001b[?2004l\r\n"]
[150.04686, "o", "        ... # doctest: +ELLIPSIS\r\n"]
[150.067289, "o", "        array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\r\n"]
[150.087719, "o", "              dtype='datetime64[ns]')\r\n"]
[150.108149, "o", "        \"\"\"\r\n"]
[150.128579, "o", "        if is_extension_array_dtype(self.dtype):\r\n"]
[150.149008, "o", "            return self.array.to_numpy(dtype, copy=copy, na_value=na_value, **kwargs)\r\n"]
[150.169438, "o", "        elif kwargs:\r\n"]
[150.189868, "o", "            bad_keys = list(kwargs.keys())[0]\r\n"]
[150.210298, "o", "            raise TypeError(\r\n"]
[150.230727, "o", "                f\"to_numpy() got an unexpected keyword argument '{bad_keys}'\"\r\n"]
[150.251157, "o", "            )\r\n"]
[150.271587, "o", "\r\n"]
[150.292017, "o", "        if na_value is not lib.no_default:\r\n"]
[150.312446, "o", "            values = self._values\r\n"]
[150.332876, "o", "            if not can_hold_element(values, na_value):\r\n"]
[150.353306, "o", "                # if we can't hold the na_value asarray either makes a copy or we\r\n"]
[150.373736, "o", "                # error before modifying values. The asarray later on thus won't make\r\n"]
[150.394165, "o", "                # another copy\r\n"]
[150.414595, "o", "                values = np.asarray(values, dtype=dtype)\r\n"]
[150.435025, "o", "            else:\r\n"]
[150.455455, "o", "                values = values.copy()\r\n"]
[150.475884, "o", "\r\n"]
[150.496314, "o", "            values[np.asanyarray(self.isna())] = na_value\r\n"]
[150.516744, "o", "        else:\r\n"]
[150.537174, "o", "            values = self._values\r\n"]
[150.557603, "o", "\r\n"]
[150.578033, "o", "        result = np.asarray(values, dtype=dtype)\r\n"]
[150.598463, "o", "\r\n"]
[150.618893, "o", "        if copy and na_value is lib.no_default:\r\n"]
[150.639322, "o", "            if np.shares_memory(self._values[:2], result[:2]):\r\n"]
[150.659752, "o", "                # Take slices to improve performance of check\r\n"]
[150.680182, "o", "                result = result.copy()\r\n"]
[150.700612, "o", "\r\n"]
[150.721041, "o", "        return result\r\n"]
[150.741471, "o", "\r\n"]
[150.761901, "o", "    @final\r\n"]
[150.782331, "o", "    @property\r\n"]
[150.80276, "o", "    def empty(self) -> bool:\r\n"]
[150.82319, "o", "        return not self.size\r\n"]
[150.84362, "o", "\r\n"]
[150.86405, "o", "    def max(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[150.884479, "o", "        \"\"\"\r\n"]
[150.904909, "o", "        Return the maximum value of the Index.\r\n"]
[150.925339, "o", "\r\n"]
[150.945769, "o", "        Parameters\r\n"]
[150.966198, "o", "        ----------\r\n"]
[150.986628, "o", "        axis : int, optional\r\n"]
[151.007058, "o", "            For compatibility with NumPy. Only 0 or None are allowed.\r\n"]
[151.027488, "o", "        skipna : bool, default True\r\n"]
[151.047917, "o", "            Exclude NA/null values when showing the result.\r\n"]
[151.068347, "o", "        *args, **kwargs\r\n"]
[151.088777, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[151.109207, "o", "\r\n"]
[151.129636, "o", "        Returns\r\n"]
[151.150066, "o", "        -------\r\n"]
[151.170496, "o", "        scalar\r\n"]
[151.190926, "o", "            Maximum value.\r\n"]
[151.211355, "o", "\r\n"]
[151.231785, "o", "        See Also\r\n"]
[151.252215, "o", "        --------\r\n"]
[151.272645, "o", "        Index.min : Return the minimum value in an Index.\r\n"]
[151.293074, "o", "        Series.max : Return the maximum value in a Series.\r\n"]
[151.313504, "o", "        DataFrame.max : Return the maximum values in a DataFrame.\r\n"]
[151.333934, "o", "\r\n"]
[151.354364, "o", "        Examples\r\n"]
[151.374793, "o", "        --------\r\n"]
[151.395223, "o", "        >>> idx = pd.Index([3, 2, 1])\r\n"]
[151.415653, "o", "        >>> idx.max()\r\n"]
[151.436083, "o", "        3\r\n"]
[151.456512, "o", "\r\n"]
[151.476942, "o", "        >>> idx = pd.Index(['c', 'b', 'a'])\r\n"]
[151.497372, "o", "        >>> idx.max()\r\n"]
[151.517802, "o", "        'c'\r\n"]
[151.538231, "o", "\r\n"]
[151.558661, "o", "        For a MultiIndex, the maximum is determined lexicographically.\r\n"]
[151.579091, "o", "\r\n"]
[151.599521, "o", "        >>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])\r\n"]
[151.61995, "o", "        >>> idx.max()\r\n"]
[151.64038, "o", "        ('b', 2)\r\n"]
[151.66081, "o", "        \"\"\"\r\n"]
[151.68124, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[151.701669, "o", "        nv.validate_max(args, kwargs)\r\n"]
[151.722099, "o", "        return nanops.nanmax(self._values, skipna=skipna)\r\n"]
[151.742529, "o", "\r\n"]
[151.762959, "o", "    @doc(op=\"max\", oppose=\"min\", value=\"largest\")\r\n"]
[151.783388, "o", "    def argmax(\r\n"]
[151.803818, "o", "        self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs\r\n"]
[151.824248, "o", "    ) -> int:\r\n"]
[151.844678, "o", "        \"\"\"\r\n"]
[151.865107, "o", "        Return int position of the {value} value in the Series.\r\n"]
[151.885537, "o", "\r\n"]
[151.905967, "o", "        If the {op}imum is achieved in multiple locations,\r\n"]
[151.926397, "o", "        the first row position is returned.\r\n"]
[151.946826, "o", "\r\n"]
[151.967256, "o", "        Parameters\r\n"]
[151.987686, "o", "        ----------\r\n"]
[152.008116, "o", "        axis : {{None}}\r\n"]
[152.028545, "o", "            Unused. Parameter needed for compatibility with DataFrame.\r\n"]
[152.048975, "o", "        skipna : bool, default True\r\n"]
[152.069405, "o", "            Exclude NA/null values when showing the result.\r\n"]
[152.089835, "o", "        *args, **kwargs\r\n"]
[152.110264, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[152.130694, "o", "\r\n"]
[152.151124, "o", "        Returns\r\n"]
[152.171554, "o", "        -------\r\n"]
[152.191983, "o", "        int\r\n"]
[152.212413, "o", "            Row position of the {op}imum value.\r\n"]
[152.232843, "o", "\r\n"]
[152.253273, "o", "        See Also\r\n"]
[152.273702, "o", "        --------\r\n"]
[152.294132, "o", "        Series.arg{op} : Return position of the {op}imum value.\r\n"]
[152.314562, "o", "        Series.arg{oppose} : Return position of the {oppose}imum value.\r\n"]
[152.334992, "o", "        numpy.ndarray.arg{op} : Equivalent method for numpy arrays.\r\n"]
[152.355421, "o", "        Series.idxmax : Return index label of the maximum values.\r\n"]
[152.375851, "o", "        Series.idxmin : Return index label of the minimum values.\r\n"]
[152.396281, "o", "\r\n"]
[152.416711, "o", "        Examples\r\n"]
[152.43714, "o", "        --------\r\n"]
[152.45757, "o", "        Consider dataset containing cereal calories\r\n"]
[152.478, "o", "\r\n"]
[152.49843, "o", "        >>> s = pd.Series({{'Corn Flakes': 100.0, 'Almond Delight': 110.0,\r\n"]
[152.51886, "o", "        ...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0}})\r\n"]
[152.539289, "o", "        >>> s\r\n"]
[152.559719, "o", "        Corn Flakes              100.0\r\n"]
[152.580149, "o", "        Almond Delight           110.0\r\n"]
[152.600579, "o", "        Cinnamon Toast Crunch    120.0\r\n"]
[152.621008, "o", "        Cocoa Puff               110.0\r\n"]
[152.641438, "o", "        dtype: float64\r\n"]
[152.661868, "o", "\r\n"]
[152.682298, "o", "        >>> s.argmax()\r\n"]
[152.702727, "o", "        2\r\n"]
[152.723157, "o", "        >>> s.argmin()\r\n"]
[152.743587, "o", "        0\r\n"]
[152.764017, "o", "\r\n"]
[152.784446, "o", "        The maximum cereal calories is the third element and\r\n"]
[152.804876, "o", "        the minimum cereal calories is the first element,\r\n"]
[152.825306, "o", "        since series is zero-indexed.\r\n"]
[152.845736, "o", "        \"\"\"\r\n"]
[152.866165, "o", "        delegate = self._values\r\n"]
[152.886595, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[152.907025, "o", "        skipna = nv.validate_argmax_with_skipna(skipna, args, kwargs)\r\n"]
[152.927455, "o", "\r\n"]
[152.947884, "o", "        if isinstance(delegate, ExtensionArray):\r\n"]
[152.968314, "o", "            if not skipna and delegate.isna().any():\r\n"]
[152.988744, "o", "                return -1\r\n"]
[153.009174, "o", "            else:\r\n"]
[153.029603, "o", "                return delegate.argmax()\r\n"]
[153.050033, "o", "        else:\r\n"]
[153.070463, "o", "            # error: Incompatible return value type (got \"Union[int, ndarray]\", expected\r\n"]
[153.090893, "o", "            # \"int\")\r\n"]
[153.111322, "o", "            return nanops.nanargmax(  # type: ignore[return-value]\r\n"]
[153.131752, "o", "                delegate, skipna=skipna\r\n"]
[153.152182, "o", "            )\r\n"]
[153.172612, "o", "\r\n"]
[153.193041, "o", "    def min(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[153.213471, "o", "        \"\"\"\r\n"]
[153.233901, "o", "        Return the minimum value of the Index.\r\n"]
[153.254331, "o", "\r\n"]
[153.27476, "o", "        Parameters\r\n"]
[153.29519, "o", "        ----------\r\n"]
[153.31562, "o", "        axis : {None}\r\n"]
[153.33605, "o", "            Dummy argument for consistency with Series.\r\n"]
[153.356479, "o", "        skipna : bool, default True\r\n"]
[153.376909, "o", "            Exclude NA/null values when showing the result.\r\n"]
[153.397339, "o", "        *args, **kwargs\r\n"]
[153.417769, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[153.438198, "o", "\r\n"]
[153.458628, "o", "        Returns\r\n"]
[153.479058, "o", "        -------\r\n"]
[153.499488, "o", "        scalar\r\n"]
[153.519917, "o", "            Minimum value.\r\n"]
[153.540347, "o", "\r\n"]
[153.560777, "o", "        See Also\r\n"]
[153.581207, "o", "        --------\r\n"]
[153.601636, "o", "        Index.max : Return the maximum value of the object.\r\n"]
[153.622066, "o", "        Series.min : Return the minimum value in a Series.\r\n"]
[153.642496, "o", "        DataFrame.min : Return the minimum values in a DataFrame.\r\n"]
[153.662926, "o", "\r\n"]
[153.683355, "o", "        Examples\r\n"]
[153.703785, "o", "        --------\r\n"]
[153.724215, "o", "        >>> idx = pd.Index([3, 2, 1])\r\n"]
[153.744645, "o", "        >>> idx.min()\r\n"]
[153.765074, "o", "        1\r\n"]
[153.785504, "o", "\r\n"]
[153.805934, "o", "        >>> idx = pd.Index(['c', 'b', 'a'])\r\n"]
[153.826364, "o", "        >>> idx.min()\r\n"]
[153.846793, "o", "        'a'\r\n"]
[153.867223, "o", "\r\n"]
[153.887653, "o", "        For a MultiIndex, the minimum is determined lexicographically.\r\n"]
[153.908083, "o", "\r\n"]
[153.928512, "o", "        >>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])\r\n"]
[153.948942, "o", "        >>> idx.min()\r\n"]
[153.969372, "o", "        ('a', 1)\r\n"]
[153.989802, "o", "        \"\"\"\r\n"]
[154.010231, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[154.030661, "o", "        nv.validate_min(args, kwargs)\r\n"]
[154.051091, "o", "        return nanops.nanmin(self._values, skipna=skipna)\r\n"]
[154.071521, "o", "\r\n"]
[154.09195, "o", "    @doc(argmax, op=\"min\", oppose=\"max\", value=\"smallest\")\r\n"]
[154.11238, "o", "    def argmin(\r\n"]
[154.13281, "o", "        self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs\r\n"]
[154.15324, "o", "    ) -> int:\r\n"]
[154.173669, "o", "        delegate = self._values\r\n"]
[154.194099, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[154.214529, "o", "        skipna = nv.validate_argmin_with_skipna(skipna, args, kwargs)\r\n"]
[154.234959, "o", "\r\n"]
[154.255388, "o", "        if isinstance(delegate, ExtensionArray):\r\n"]
[154.275818, "o", "            if not skipna and delegate.isna().any():\r\n"]
[154.296248, "o", "                return -1\r\n"]
[154.316678, "o", "            else:\r\n"]
[154.337107, "o", "                return delegate.argmin()\r\n"]
[154.357537, "o", "        else:\r\n"]
[154.377967, "o", "            # error: Incompatible return value type (got \"Union[int, ndarray]\", expected\r\n"]
[154.398397, "o", "            # \"int\")\r\n"]
[154.418826, "o", "            return nanops.nanargmin(  # type: ignore[return-value]\r\n"]
[154.439256, "o", "                delegate, skipna=skipna\r\n"]
[154.459686, "o", "            )\r\n"]
[154.480116, "o", "\r\n"]
[154.500545, "o", "    def tolist(self):\r\n"]
[154.520975, "o", "        \"\"\"\r\n"]
[154.541405, "o", "        Return a list of the values.\r\n"]
[154.561835, "o", "\r\n"]
[154.582264, "o", "        These are each a scalar type, which is a Python scalar\r\n"]
[154.602694, "o", "        (for str, int, float) or a pandas scalar\r\n"]
[154.623124, "o", "        (for Timestamp/Timedelta/Interval/Period)\r\n"]
[154.643554, "o", "\r\n"]
[154.663983, "o", "        Returns\r\n"]
[154.684413, "o", "        -------\r\n"]
[154.704843, "o", "        list\r\n"]
[154.725273, "o", "\r\n"]
[154.745702, "o", "        See Also\r\n"]
[154.766132, "o", "        --------\r\n"]
[154.786562, "o", "        numpy.ndarray.tolist : Return the array as an a.ndim-levels deep\r\n"]
[154.806992, "o", "            nested list of Python scalars.\r\n"]
[154.827421, "o", "        \"\"\"\r\n"]
[154.847851, "o", "        return self._values.tolist()\r\n"]
[154.868281, "o", "\r\n"]
[154.888711, "o", "    to_list = tolist\r\n"]
[154.90914, "o", "\r\n"]
[154.92957, "o", "    def __iter__(self) -> Iterator:\r\n"]
[155.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[155.002, "i", "sed -n '760,980p' pandas/core/base.py\r"]
[155.004, "o", "sed -n '760,980p' pandas/core/base.py\r\n"]
[155.02827, "o", "\u001b[?2004l\r\n"]
[155.050541, "o", "        \"\"\"\r\n"]
[155.072811, "o", "        Return an iterator of the values.\r\n"]
[155.095081, "o", "\r\n"]
[155.117351, "o", "        These are each a scalar type, which is a Python scalar\r\n"]
[155.139622, "o", "        (for str, int, float) or a pandas scalar\r\n"]
[155.161892, "o", "        (for Timestamp/Timedelta/Interval/Period)\r\n"]
[155.184162, "o", "\r\n"]
[155.206432, "o", "        Returns\r\n"]
[155.228703, "o", "        -------\r\n"]
[155.250973, "o", "        iterator\r\n"]
[155.273243, "o", "        \"\"\"\r\n"]
[155.295514, "o", "        # We are explicitly making element iterators.\r\n"]
[155.317784, "o", "        if not isinstance(self._values, np.ndarray):\r\n"]
[155.340054, "o", "            # Check type instead of dtype to catch DTA/TDA\r\n"]
[155.362324, "o", "            return iter(self._values)\r\n"]
[155.384595, "o", "        else:\r\n"]
[155.406865, "o", "            return map(self._values.item, range(self._values.size))\r\n"]
[155.429135, "o", "\r\n"]
[155.451405, "o", "    @cache_readonly\r\n"]
[155.473676, "o", "    def hasnans(self) -> bool:\r\n"]
[155.495946, "o", "        \"\"\"\r\n"]
[155.518216, "o", "        Return True if there are any NaNs.\r\n"]
[155.540486, "o", "\r\n"]
[155.562757, "o", "        Enables various performance speedups.\r\n"]
[155.585027, "o", "\r\n"]
[155.607297, "o", "        Returns\r\n"]
[155.629568, "o", "        -------\r\n"]
[155.651838, "o", "        bool\r\n"]
[155.674108, "o", "        \"\"\"\r\n"]
[155.696378, "o", "        # error: Item \"bool\" of \"Union[bool, ndarray[Any, dtype[bool_]], NDFrame]\"\r\n"]
[155.718649, "o", "        # has no attribute \"any\"\r\n"]
[155.740919, "o", "        return bool(isna(self).any())  # type: ignore[union-attr]\r\n"]
[155.763189, "o", "\r\n"]
[155.785459, "o", "    def isna(self) -> npt.NDArray[np.bool_]:\r\n"]
[155.80773, "o", "        return isna(self._values)\r\n"]
[155.83, "o", "\r\n"]
[155.85227, "o", "    def _reduce(\r\n"]
[155.874541, "o", "        self,\r\n"]
[155.896811, "o", "        op,\r\n"]
[155.919081, "o", "        name: str,\r\n"]
[155.941351, "o", "        *,\r\n"]
[155.963622, "o", "        axis: Axis = 0,\r\n"]
[155.985892, "o", "        skipna: bool = True,\r\n"]
[156.008162, "o", "        numeric_only=None,\r\n"]
[156.030432, "o", "        filter_type=None,\r\n"]
[156.052703, "o", "        **kwds,\r\n"]
[156.074973, "o", "    ):\r\n"]
[156.097243, "o", "        \"\"\"\r\n"]
[156.119514, "o", "        Perform the reduction type operation if we can.\r\n"]
[156.141784, "o", "        \"\"\"\r\n"]
[156.164054, "o", "        func = getattr(self, name, None)\r\n"]
[156.186324, "o", "        if func is None:\r\n"]
[156.208595, "o", "            raise TypeError(\r\n"]
[156.230865, "o", "                f\"{type(self).__name__} cannot perform the operation {name}\"\r\n"]
[156.253135, "o", "            )\r\n"]
[156.275405, "o", "        return func(skipna=skipna, **kwds)\r\n"]
[156.297676, "o", "\r\n"]
[156.319946, "o", "    @final\r\n"]
[156.342216, "o", "    def _map_values(self, mapper, na_action=None):\r\n"]
[156.364486, "o", "        \"\"\"\r\n"]
[156.386757, "o", "        An internal function that maps values using the input\r\n"]
[156.409027, "o", "        correspondence (which can be a dict, Series, or function).\r\n"]
[156.431297, "o", "\r\n"]
[156.453568, "o", "        Parameters\r\n"]
[156.475838, "o", "        ----------\r\n"]
[156.498108, "o", "        mapper : function, dict, or Series\r\n"]
[156.520378, "o", "            The input correspondence object\r\n"]
[156.542649, "o", "        na_action : {None, 'ignore'}\r\n"]
[156.564919, "o", "            If 'ignore', propagate NA values, without passing them to the\r\n"]
[156.587189, "o", "            mapping function\r\n"]
[156.609459, "o", "\r\n"]
[156.63173, "o", "        Returns\r\n"]
[156.654, "o", "        -------\r\n"]
[156.67627, "o", "        Union[Index, MultiIndex], inferred\r\n"]
[156.698541, "o", "            The output of the mapping function applied to the index.\r\n"]
[156.720811, "o", "            If the function returns a tuple with more than one element\r\n"]
[156.743081, "o", "            a MultiIndex will be returned.\r\n"]
[156.765351, "o", "        \"\"\"\r\n"]
[156.787622, "o", "        # we can fastpath dict/Series to an efficient map\r\n"]
[156.809892, "o", "        # as we know that we are not going to have to yield\r\n"]
[156.832162, "o", "        # python types\r\n"]
[156.854432, "o", "        if is_dict_like(mapper):\r\n"]
[156.876703, "o", "            if isinstance(mapper, dict) and hasattr(mapper, \"__missing__\"):\r\n"]
[156.898973, "o", "                # If a dictionary subclass defines a default value method,\r\n"]
[156.921243, "o", "                # convert mapper to a lookup function (GH #15999).\r\n"]
[156.943514, "o", "                dict_with_default = mapper\r\n"]
[156.965784, "o", "                mapper = lambda x: dict_with_default[\r\n"]
[156.988054, "o", "                    np.nan if isinstance(x, float) and np.isnan(x) else x\r\n"]
[157.010324, "o", "                ]\r\n"]
[157.032595, "o", "            else:\r\n"]
[157.054865, "o", "                # Dictionary does not have a default. Thus it's safe to\r\n"]
[157.077135, "o", "                # convert to an Series for efficiency.\r\n"]
[157.099405, "o", "                # we specify the keys here to handle the\r\n"]
[157.121676, "o", "                # possibility that they are tuples\r\n"]
[157.143946, "o", "\r\n"]
[157.166216, "o", "                # The return value of mapping with an empty mapper is\r\n"]
[157.188486, "o", "                # expected to be pd.Series(np.nan, ...). As np.nan is\r\n"]
[157.210757, "o", "                # of dtype float64 the return value of this method should\r\n"]
[157.233027, "o", "                # be float64 as well\r\n"]
[157.255297, "o", "                from pandas import Series\r\n"]
[157.277568, "o", "\r\n"]
[157.299838, "o", "                if len(mapper) == 0:\r\n"]
[157.322108, "o", "                    mapper = Series(mapper, dtype=np.float64)\r\n"]
[157.344378, "o", "                else:\r\n"]
[157.366649, "o", "                    mapper = Series(mapper)\r\n"]
[157.388919, "o", "\r\n"]
[157.411189, "o", "        if isinstance(mapper, ABCSeries):\r\n"]
[157.433459, "o", "            if na_action not in (None, \"ignore\"):\r\n"]
[157.45573, "o", "                msg = (\r\n"]
[157.478, "o", "                    \"na_action must either be 'ignore' or None, \"\r\n"]
[157.50027, "o", "                    f\"{na_action} was passed\"\r\n"]
[157.522541, "o", "                )\r\n"]
[157.544811, "o", "                raise ValueError(msg)\r\n"]
[157.567081, "o", "\r\n"]
[157.589351, "o", "            if na_action == \"ignore\":\r\n"]
[157.611622, "o", "                mapper = mapper[mapper.index.notna()]\r\n"]
[157.633892, "o", "\r\n"]
[157.656162, "o", "            # Since values were input this means we came from either\r\n"]
[157.678432, "o", "            # a dict or a series and mapper should be an index\r\n"]
[157.700703, "o", "            if is_categorical_dtype(self.dtype):\r\n"]
[157.722973, "o", "                # use the built in categorical series mapper which saves\r\n"]
[157.745243, "o", "                # time by mapping the categories instead of all values\r\n"]
[157.767514, "o", "\r\n"]
[157.789784, "o", "                cat = cast(\"Categorical\", self._values)\r\n"]
[157.812054, "o", "                return cat.map(mapper)\r\n"]
[157.834324, "o", "\r\n"]
[157.856595, "o", "            values = self._values\r\n"]
[157.878865, "o", "\r\n"]
[157.901135, "o", "            indexer = mapper.index.get_indexer(values)\r\n"]
[157.923405, "o", "            new_values = algorithms.take_nd(mapper._values, indexer)\r\n"]
[157.945676, "o", "\r\n"]
[157.967946, "o", "            return new_values\r\n"]
[157.990216, "o", "\r\n"]
[158.012486, "o", "        # we must convert to python types\r\n"]
[158.034757, "o", "        if is_extension_array_dtype(self.dtype) and hasattr(self._values, \"map\"):\r\n"]
[158.057027, "o", "            # GH#23179 some EAs do not have `map`\r\n"]
[158.079297, "o", "            values = self._values\r\n"]
[158.101568, "o", "            if na_action is not None:\r\n"]
[158.123838, "o", "                raise NotImplementedError\r\n"]
[158.146108, "o", "            map_f = lambda values, f: values.map(f)\r\n"]
[158.168378, "o", "        else:\r\n"]
[158.190649, "o", "            values = self._values.astype(object)\r\n"]
[158.212919, "o", "            if na_action == \"ignore\":\r\n"]
[158.235189, "o", "                map_f = lambda values, f: lib.map_infer_mask(\r\n"]
[158.257459, "o", "                    values, f, isna(values).view(np.uint8)\r\n"]
[158.27973, "o", "                )\r\n"]
[158.302, "o", "            elif na_action is None:\r\n"]
[158.32427, "o", "                map_f = lib.map_infer\r\n"]
[158.346541, "o", "            else:\r\n"]
[158.368811, "o", "                msg = (\r\n"]
[158.391081, "o", "                    \"na_action must either be 'ignore' or None, \"\r\n"]
[158.413351, "o", "                    f\"{na_action} was passed\"\r\n"]
[158.435622, "o", "                )\r\n"]
[158.457892, "o", "                raise ValueError(msg)\r\n"]
[158.480162, "o", "\r\n"]
[158.502432, "o", "        # mapper is a function\r\n"]
[158.524703, "o", "        new_values = map_f(values, mapper)\r\n"]
[158.546973, "o", "\r\n"]
[158.569243, "o", "        return new_values\r\n"]
[158.591514, "o", "\r\n"]
[158.613784, "o", "    @final\r\n"]
[158.636054, "o", "    def value_counts(\r\n"]
[158.658324, "o", "        self,\r\n"]
[158.680595, "o", "        normalize: bool = False,\r\n"]
[158.702865, "o", "        sort: bool = True,\r\n"]
[158.725135, "o", "        ascending: bool = False,\r\n"]
[158.747405, "o", "        bins=None,\r\n"]
[158.769676, "o", "        dropna: bool = True,\r\n"]
[158.791946, "o", "    ) -> Series:\r\n"]
[158.814216, "o", "        \"\"\"\r\n"]
[158.836486, "o", "        Return a Series containing counts of unique values.\r\n"]
[158.858757, "o", "\r\n"]
[158.881027, "o", "        The resulting object will be in descending order so that the\r\n"]
[158.903297, "o", "        first element is the most frequently-occurring element.\r\n"]
[158.925568, "o", "        Excludes NA values by default.\r\n"]
[158.947838, "o", "\r\n"]
[158.970108, "o", "        Parameters\r\n"]
[158.992378, "o", "        ----------\r\n"]
[159.014649, "o", "        normalize : bool, default False\r\n"]
[159.036919, "o", "            If True then the object returned will contain the relative\r\n"]
[159.059189, "o", "            frequencies of the unique values.\r\n"]
[159.081459, "o", "        sort : bool, default True\r\n"]
[159.10373, "o", "            Sort by frequencies.\r\n"]
[159.126, "o", "        ascending : bool, default False\r\n"]
[159.14827, "o", "            Sort in ascending order.\r\n"]
[159.170541, "o", "        bins : int, optional\r\n"]
[159.192811, "o", "            Rather than count values, group them into half-open bins,\r\n"]
[159.215081, "o", "            a convenience for ``pd.cut``, only works with numeric data.\r\n"]
[159.237351, "o", "        dropna : bool, default True\r\n"]
[159.259622, "o", "            Don't include counts of NaN.\r\n"]
[159.281892, "o", "\r\n"]
[159.304162, "o", "        Returns\r\n"]
[159.326432, "o", "        -------\r\n"]
[159.348703, "o", "        Series\r\n"]
[159.370973, "o", "\r\n"]
[159.393243, "o", "        See Also\r\n"]
[159.415514, "o", "        --------\r\n"]
[159.437784, "o", "        Series.count: Number of non-NA elements in a Series.\r\n"]
[159.460054, "o", "        DataFrame.count: Number of non-NA elements in a DataFrame.\r\n"]
[159.482324, "o", "        DataFrame.value_counts: Equivalent method on DataFrames.\r\n"]
[159.504595, "o", "\r\n"]
[159.526865, "o", "        Examples\r\n"]
[159.549135, "o", "        --------\r\n"]
[159.571405, "o", "        >>> index = pd.Index([3, 1, 2, 3, 4, np.nan])\r\n"]
[159.593676, "o", "        >>> index.value_counts()\r\n"]
[159.615946, "o", "        3.0    2\r\n"]
[159.638216, "o", "        1.0    1\r\n"]
[159.660486, "o", "        2.0    1\r\n"]
[159.682757, "o", "        4.0    1\r\n"]
[159.705027, "o", "        dtype: int64\r\n"]
[159.727297, "o", "\r\n"]
[159.749568, "o", "        With `normalize` set to `True`, returns the relative frequency by\r\n"]
[159.771838, "o", "        dividing all values by the sum of values.\r\n"]
[159.794108, "o", "\r\n"]
[159.816378, "o", "        >>> s = pd.Series([3, 1, 2, 3, 4, np.nan])\r\n"]
[159.838649, "o", "        >>> s.value_counts(normalize=True)\r\n"]
[159.860919, "o", "        3.0    0.4\r\n"]
[159.883189, "o", "        1.0    0.2\r\n"]
[159.905459, "o", "        2.0    0.2\r\n"]
[159.92773, "o", "        4.0    0.2\r\n"]
[160.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[160.002, "i", "sed -n '420,520p' pandas/core/base.py\r"]
[160.004, "o", "sed -n '420,520p' pandas/core/base.py\r\n"]
[160.054471, "o", "\u001b[?2004l\r\n"]
[160.102941, "o", "        Categories (2, object): ['a', 'b']\r\n"]
[160.151412, "o", "        \"\"\"\r\n"]
[160.199882, "o", "        raise AbstractMethodError(self)\r\n"]
[160.248353, "o", "\r\n"]
[160.296824, "o", "    @final\r\n"]
[160.345294, "o", "    def to_numpy(\r\n"]
[160.393765, "o", "        self,\r\n"]
[160.442235, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[160.490706, "o", "        copy: bool = False,\r\n"]
[160.539176, "o", "        na_value: object = lib.no_default,\r\n"]
[160.587647, "o", "        **kwargs,\r\n"]
[160.636118, "o", "    ) -> np.ndarray:\r\n"]
[160.684588, "o", "        \"\"\"\r\n"]
[160.733059, "o", "        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[160.781529, "o", "\r\n"]
[160.83, "o", "        Parameters\r\n"]
[160.878471, "o", "        ----------\r\n"]
[160.926941, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[160.975412, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[161.023882, "o", "        copy : bool, default False\r\n"]
[161.072353, "o", "            Whether to ensure that the returned value is not a view on\r\n"]
[161.120824, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[161.169294, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[161.217765, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[161.266235, "o", "        na_value : Any, optional\r\n"]
[161.314706, "o", "            The value to use for missing values. The default value depends\r\n"]
[161.363176, "o", "            on `dtype` and the type of the array.\r\n"]
[161.411647, "o", "\r\n"]
[161.460118, "o", "            .. versionadded:: 1.0.0\r\n"]
[161.508588, "o", "\r\n"]
[161.557059, "o", "        **kwargs\r\n"]
[161.605529, "o", "            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[161.654, "o", "            of the underlying array (for extension arrays).\r\n"]
[161.702471, "o", "\r\n"]
[161.750941, "o", "            .. versionadded:: 1.0.0\r\n"]
[161.799412, "o", "\r\n"]
[161.847882, "o", "        Returns\r\n"]
[161.896353, "o", "        -------\r\n"]
[161.944824, "o", "        numpy.ndarray\r\n"]
[161.993294, "o", "\r\n"]
[162.041765, "o", "        See Also\r\n"]
[162.090235, "o", "        --------\r\n"]
[162.138706, "o", "        Series.array : Get the actual data stored within.\r\n"]
[162.187176, "o", "        Index.array : Get the actual data stored within.\r\n"]
[162.235647, "o", "        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[162.284118, "o", "\r\n"]
[162.332588, "o", "        Notes\r\n"]
[162.381059, "o", "        -----\r\n"]
[162.429529, "o", "        The returned array will be the same up to equality (values equal\r\n"]
[162.478, "o", "        in `self` will be equal in the returned array; likewise for values\r\n"]
[162.526471, "o", "        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[162.574941, "o", "        dtype may be different. For example, for a category-dtype Series,\r\n"]
[162.623412, "o", "        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[162.671882, "o", "        will be lost.\r\n"]
[162.720353, "o", "\r\n"]
[162.768824, "o", "        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[162.817294, "o", "        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[162.865765, "o", "        in place will modify the data stored in the Series or Index (not that\r\n"]
[162.914235, "o", "        we recommend doing that).\r\n"]
[162.962706, "o", "\r\n"]
[163.011176, "o", "        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[163.059647, "o", "        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[163.108118, "o", "        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[163.156588, "o", "        :attr:`Series.array` should be used instead.\r\n"]
[163.205059, "o", "\r\n"]
[163.253529, "o", "        This table lays out the different dtypes and default return types of\r\n"]
[163.302, "o", "        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[163.350471, "o", "\r\n"]
[163.398941, "o", "        ================== ================================\r\n"]
[163.447412, "o", "        dtype              array type\r\n"]
[163.495882, "o", "        ================== ================================\r\n"]
[163.544353, "o", "        category[T]        ndarray[T] (same dtype as input)\r\n"]
[163.592824, "o", "        period             ndarray[object] (Periods)\r\n"]
[163.641294, "o", "        interval           ndarray[object] (Intervals)\r\n"]
[163.689765, "o", "        IntegerNA          ndarray[object]\r\n"]
[163.738235, "o", "        datetime64[ns]     datetime64[ns]\r\n"]
[163.786706, "o", "        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[163.835176, "o", "        ================== ================================\r\n"]
[163.883647, "o", "\r\n"]
[163.932118, "o", "        Examples\r\n"]
[163.980588, "o", "        --------\r\n"]
[164.029059, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[164.077529, "o", "        >>> ser.to_numpy()\r\n"]
[164.126, "o", "        array(['a', 'b', 'a'], dtype=object)\r\n"]
[164.174471, "o", "\r\n"]
[164.222941, "o", "        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[164.271412, "o", "        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[164.319882, "o", "        objects, each with the correct ``tz``.\r\n"]
[164.368353, "o", "\r\n"]
[164.416824, "o", "        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[164.465294, "o", "        >>> ser.to_numpy(dtype=object)\r\n"]
[164.513765, "o", "        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[164.562235, "o", "               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[164.610706, "o", "              dtype=object)\r\n"]
[164.659176, "o", "\r\n"]
[164.707647, "o", "        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[164.756118, "o", "        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[164.804588, "o", "        info is dropped.\r\n"]
[164.853059, "o", "\r\n"]
[164.901529, "o", "        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[165.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[165.002, "i", "sed -n '430,520p' pandas/core/arrays/base.py\r"]
[165.004, "o", "sed -n '430,520p' pandas/core/arrays/base.py\r\n"]
[165.059739, "o", "\u001b[?2004l\r\n"]
[165.113478, "o", "            else:\r\n"]
[165.167217, "o", "                return False\r\n"]
[165.220957, "o", "        else:\r\n"]
[165.274696, "o", "            # error: Item \"ExtensionArray\" of \"Union[ExtensionArray, ndarray]\" has no\r\n"]
[165.328435, "o", "            # attribute \"any\"\r\n"]
[165.382174, "o", "            return (item == self).any()  # type: ignore[union-attr]\r\n"]
[165.435913, "o", "\r\n"]
[165.489652, "o", "    # error: Signature of \"__eq__\" incompatible with supertype \"object\"\r\n"]
[165.543391, "o", "    def __eq__(self, other: Any) -> ArrayLike:  # type: ignore[override]\r\n"]
[165.59713, "o", "        \"\"\"\r\n"]
[165.65087, "o", "        Return for `self == other` (element-wise equality).\r\n"]
[165.704609, "o", "        \"\"\"\r\n"]
[165.758348, "o", "        # Implementer note: this should return a boolean numpy ndarray or\r\n"]
[165.812087, "o", "        # a boolean ExtensionArray.\r\n"]
[165.865826, "o", "        # When `other` is one of Series, Index, or DataFrame, this method should\r\n"]
[165.919565, "o", "        # return NotImplemented (to ensure that those objects are responsible for\r\n"]
[165.973304, "o", "        # first unpacking the arrays, and then dispatch the operation to the\r\n"]
[166.027043, "o", "        # underlying arrays)\r\n"]
[166.080783, "o", "        raise AbstractMethodError(self)\r\n"]
[166.134522, "o", "\r\n"]
[166.188261, "o", "    # error: Signature of \"__ne__\" incompatible with supertype \"object\"\r\n"]
[166.242, "o", "    def __ne__(self, other: Any) -> ArrayLike:  # type: ignore[override]\r\n"]
[166.295739, "o", "        \"\"\"\r\n"]
[166.349478, "o", "        Return for `self != other` (element-wise in-equality).\r\n"]
[166.403217, "o", "        \"\"\"\r\n"]
[166.456957, "o", "        return ~(self == other)\r\n"]
[166.510696, "o", "\r\n"]
[166.564435, "o", "    def to_numpy(\r\n"]
[166.618174, "o", "        self,\r\n"]
[166.671913, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[166.725652, "o", "        copy: bool = False,\r\n"]
[166.779391, "o", "        na_value: object = lib.no_default,\r\n"]
[166.83313, "o", "    ) -> np.ndarray:\r\n"]
[166.88687, "o", "        \"\"\"\r\n"]
[166.940609, "o", "        Convert to a NumPy ndarray.\r\n"]
[166.994348, "o", "\r\n"]
[167.048087, "o", "        .. versionadded:: 1.0.0\r\n"]
[167.101826, "o", "\r\n"]
[167.155565, "o", "        This is similar to :meth:`numpy.asarray`, but may provide additional control\r\n"]
[167.209304, "o", "        over how the conversion is done.\r\n"]
[167.263043, "o", "\r\n"]
[167.316783, "o", "        Parameters\r\n"]
[167.370522, "o", "        ----------\r\n"]
[167.424261, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[167.478, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[167.531739, "o", "        copy : bool, default False\r\n"]
[167.585478, "o", "            Whether to ensure that the returned value is a not a view on\r\n"]
[167.639217, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[167.692957, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[167.746696, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[167.800435, "o", "        na_value : Any, optional\r\n"]
[167.854174, "o", "            The value to use for missing values. The default value depends\r\n"]
[167.907913, "o", "            on `dtype` and the type of the array.\r\n"]
[167.961652, "o", "\r\n"]
[168.015391, "o", "        Returns\r\n"]
[168.06913, "o", "        -------\r\n"]
[168.12287, "o", "        numpy.ndarray\r\n"]
[168.176609, "o", "        \"\"\"\r\n"]
[168.230348, "o", "        result = np.asarray(self, dtype=dtype)\r\n"]
[168.284087, "o", "        if copy or na_value is not lib.no_default:\r\n"]
[168.337826, "o", "            result = result.copy()\r\n"]
[168.391565, "o", "        if na_value is not lib.no_default:\r\n"]
[168.445304, "o", "            result[self.isna()] = na_value\r\n"]
[168.499043, "o", "        return result\r\n"]
[168.552783, "o", "\r\n"]
[168.606522, "o", "    # ------------------------------------------------------------------------\r\n"]
[168.660261, "o", "    # Required attributes\r\n"]
[168.714, "o", "    # ------------------------------------------------------------------------\r\n"]
[168.767739, "o", "\r\n"]
[168.821478, "o", "    @property\r\n"]
[168.875217, "o", "    def dtype(self) -> ExtensionDtype:\r\n"]
[168.928957, "o", "        \"\"\"\r\n"]
[168.982696, "o", "        An instance of 'ExtensionDtype'.\r\n"]
[169.036435, "o", "        \"\"\"\r\n"]
[169.090174, "o", "        raise AbstractMethodError(self)\r\n"]
[169.143913, "o", "\r\n"]
[169.197652, "o", "    @property\r\n"]
[169.251391, "o", "    def shape(self) -> Shape:\r\n"]
[169.30513, "o", "        \"\"\"\r\n"]
[169.35887, "o", "        Return a tuple of the array dimensions.\r\n"]
[169.412609, "o", "        \"\"\"\r\n"]
[169.466348, "o", "        return (len(self),)\r\n"]
[169.520087, "o", "\r\n"]
[169.573826, "o", "    @property\r\n"]
[169.627565, "o", "    def size(self) -> int:\r\n"]
[169.681304, "o", "        \"\"\"\r\n"]
[169.735043, "o", "        The number of elements in the array.\r\n"]
[169.788783, "o", "        \"\"\"\r\n"]
[169.842522, "o", "        # error: Incompatible return value type (got \"signedinteger[_64Bit]\",\r\n"]
[169.896261, "o", "        # expected \"int\")  [return-value]\r\n"]
[170.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[170.002, "i", "sed -n '1680,1820p' pandas/core/frame.py\r"]
[170.004, "o", "sed -n '1680,1820p' pandas/core/frame.py\r\n"]
[170.040817, "o", "\u001b[?2004l\r\n"]
[170.075634, "o", "        >>> pd.DataFrame.from_dict(data)\r\n"]
[170.110451, "o", "           col_1 col_2\r\n"]
[170.145268, "o", "        0      3     a\r\n"]
[170.180085, "o", "        1      2     b\r\n"]
[170.214901, "o", "        2      1     c\r\n"]
[170.249718, "o", "        3      0     d\r\n"]
[170.284535, "o", "\r\n"]
[170.319352, "o", "        Specify ``orient='index'`` to create the DataFrame using dictionary\r\n"]
[170.354169, "o", "        keys as rows:\r\n"]
[170.388986, "o", "\r\n"]
[170.423803, "o", "        >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\r\n"]
[170.45862, "o", "        >>> pd.DataFrame.from_dict(data, orient='index')\r\n"]
[170.493437, "o", "               0  1  2  3\r\n"]
[170.528254, "o", "        row_1  3  2  1  0\r\n"]
[170.56307, "o", "        row_2  a  b  c  d\r\n"]
[170.597887, "o", "\r\n"]
[170.632704, "o", "        When using the 'index' orientation, the column names can be\r\n"]
[170.667521, "o", "        specified manually:\r\n"]
[170.702338, "o", "\r\n"]
[170.737155, "o", "        >>> pd.DataFrame.from_dict(data, orient='index',\r\n"]
[170.771972, "o", "        ...                        columns=['A', 'B', 'C', 'D'])\r\n"]
[170.806789, "o", "               A  B  C  D\r\n"]
[170.841606, "o", "        row_1  3  2  1  0\r\n"]
[170.876423, "o", "        row_2  a  b  c  d\r\n"]
[170.911239, "o", "\r\n"]
[170.946056, "o", "        Specify ``orient='tight'`` to create the DataFrame using a 'tight'\r\n"]
[170.980873, "o", "        format:\r\n"]
[171.01569, "o", "\r\n"]
[171.050507, "o", "        >>> data = {'index': [('a', 'b'), ('a', 'c')],\r\n"]
[171.085324, "o", "        ...         'columns': [('x', 1), ('y', 2)],\r\n"]
[171.120141, "o", "        ...         'data': [[1, 3], [2, 4]],\r\n"]
[171.154958, "o", "        ...         'index_names': ['n1', 'n2'],\r\n"]
[171.189775, "o", "        ...         'column_names': ['z1', 'z2']}\r\n"]
[171.224592, "o", "        >>> pd.DataFrame.from_dict(data, orient='tight')\r\n"]
[171.259408, "o", "        z1     x  y\r\n"]
[171.294225, "o", "        z2     1  2\r\n"]
[171.329042, "o", "        n1 n2\r\n"]
[171.363859, "o", "        a  b   1  3\r\n"]
[171.398676, "o", "           c   2  4\r\n"]
[171.433493, "o", "        \"\"\"\r\n"]
[171.46831, "o", "        index = None\r\n"]
[171.503127, "o", "        orient = orient.lower()\r\n"]
[171.537944, "o", "        if orient == \"index\":\r\n"]
[171.572761, "o", "            if len(data) > 0:\r\n"]
[171.607577, "o", "                # TODO speed up Series case\r\n"]
[171.642394, "o", "                if isinstance(list(data.values())[0], (Series, dict)):\r\n"]
[171.677211, "o", "                    data = _from_nested_dict(data)\r\n"]
[171.712028, "o", "                else:\r\n"]
[171.746845, "o", "                    index = list(data.keys())\r\n"]
[171.781662, "o", "                    # error: Incompatible types in assignment (expression has type\r\n"]
[171.816479, "o", "                    # \"List[Any]\", variable has type \"Dict[Any, Any]\")\r\n"]
[171.851296, "o", "                    data = list(data.values())  # type: ignore[assignment]\r\n"]
[171.886113, "o", "        elif orient in (\"columns\", \"tight\"):\r\n"]
[171.92093, "o", "            if columns is not None:\r\n"]
[171.955746, "o", "                raise ValueError(f\"cannot use columns parameter with orient='{orient}'\")\r\n"]
[171.990563, "o", "        else:  # pragma: no cover\r\n"]
[172.02538, "o", "            raise ValueError(\r\n"]
[172.060197, "o", "                f\"Expected 'index', 'columns' or 'tight' for orient parameter. \"\r\n"]
[172.095014, "o", "                f\"Got '{orient}' instead\"\r\n"]
[172.129831, "o", "            )\r\n"]
[172.164648, "o", "\r\n"]
[172.199465, "o", "        if orient != \"tight\":\r\n"]
[172.234282, "o", "            return cls(data, index=index, columns=columns, dtype=dtype)\r\n"]
[172.269099, "o", "        else:\r\n"]
[172.303915, "o", "            realdata = data[\"data\"]\r\n"]
[172.338732, "o", "\r\n"]
[172.373549, "o", "            def create_index(indexlist, namelist):\r\n"]
[172.408366, "o", "                index: Index\r\n"]
[172.443183, "o", "                if len(namelist) > 1:\r\n"]
[172.478, "o", "                    index = MultiIndex.from_tuples(indexlist, names=namelist)\r\n"]
[172.512817, "o", "                else:\r\n"]
[172.547634, "o", "                    index = Index(indexlist, name=namelist[0])\r\n"]
[172.582451, "o", "                return index\r\n"]
[172.617268, "o", "\r\n"]
[172.652085, "o", "            index = create_index(data[\"index\"], data[\"index_names\"])\r\n"]
[172.686901, "o", "            columns = create_index(data[\"columns\"], data[\"column_names\"])\r\n"]
[172.721718, "o", "            return cls(realdata, index=index, columns=columns, dtype=dtype)\r\n"]
[172.756535, "o", "\r\n"]
[172.791352, "o", "    def to_numpy(\r\n"]
[172.826169, "o", "        self,\r\n"]
[172.860986, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[172.895803, "o", "        copy: bool = False,\r\n"]
[172.93062, "o", "        na_value: object = lib.no_default,\r\n"]
[172.965437, "o", "    ) -> np.ndarray:\r\n"]
[173.000254, "o", "        \"\"\"\r\n"]
[173.03507, "o", "        Convert the DataFrame to a NumPy array.\r\n"]
[173.069887, "o", "\r\n"]
[173.104704, "o", "        By default, the dtype of the returned array will be the common NumPy\r\n"]
[173.139521, "o", "        dtype of all types in the DataFrame. For example, if the dtypes are\r\n"]
[173.174338, "o", "        ``float16`` and ``float32``, the results dtype will be ``float32``.\r\n"]
[173.209155, "o", "        This may require copying data and coercing values, which may be\r\n"]
[173.243972, "o", "        expensive.\r\n"]
[173.278789, "o", "\r\n"]
[173.313606, "o", "        Parameters\r\n"]
[173.348423, "o", "        ----------\r\n"]
[173.383239, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[173.418056, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[173.452873, "o", "        copy : bool, default False\r\n"]
[173.48769, "o", "            Whether to ensure that the returned value is not a view on\r\n"]
[173.522507, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[173.557324, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[173.592141, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[173.626958, "o", "        na_value : Any, optional\r\n"]
[173.661775, "o", "            The value to use for missing values. The default value depends\r\n"]
[173.696592, "o", "            on `dtype` and the dtypes of the DataFrame columns.\r\n"]
[173.731408, "o", "\r\n"]
[173.766225, "o", "            .. versionadded:: 1.1.0\r\n"]
[173.801042, "o", "\r\n"]
[173.835859, "o", "        Returns\r\n"]
[173.870676, "o", "        -------\r\n"]
[173.905493, "o", "        numpy.ndarray\r\n"]
[173.94031, "o", "\r\n"]
[173.975127, "o", "        See Also\r\n"]
[174.009944, "o", "        --------\r\n"]
[174.044761, "o", "        Series.to_numpy : Similar method for Series.\r\n"]
[174.079577, "o", "\r\n"]
[174.114394, "o", "        Examples\r\n"]
[174.149211, "o", "        --------\r\n"]
[174.184028, "o", "        >>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\r\n"]
[174.218845, "o", "        array([[1, 3],\r\n"]
[174.253662, "o", "               [2, 4]])\r\n"]
[174.288479, "o", "\r\n"]
[174.323296, "o", "        With heterogeneous data, the lowest common type will have to\r\n"]
[174.358113, "o", "        be used.\r\n"]
[174.39293, "o", "\r\n"]
[174.427746, "o", "        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\r\n"]
[174.462563, "o", "        >>> df.to_numpy()\r\n"]
[174.49738, "o", "        array([[1. , 3. ],\r\n"]
[174.532197, "o", "               [2. , 4.5]])\r\n"]
[174.567014, "o", "\r\n"]
[174.601831, "o", "        For a mix of numeric and non-numeric types, the output array will\r\n"]
[174.636648, "o", "        have object dtype.\r\n"]
[174.671465, "o", "\r\n"]
[174.706282, "o", "        >>> df['C'] = pd.date_range('2000', periods=2)\r\n"]
[174.741099, "o", "        >>> df.to_numpy()\r\n"]
[174.775915, "o", "        array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\r\n"]
[174.810732, "o", "               [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\r\n"]
[174.845549, "o", "        \"\"\"\r\n"]
[174.880366, "o", "        if dtype is not None:\r\n"]
[174.915183, "o", "            dtype = np.dtype(dtype)\r\n"]
[175.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[175.002, "i", "sed -n '420,560p' pandas/core/base.py\r"]
[175.004, "o", "sed -n '420,560p' pandas/core/base.py\r\n"]
[175.040817, "o", "\u001b[?2004l\r\n"]
[175.075634, "o", "        Categories (2, object): ['a', 'b']\r\n"]
[175.110451, "o", "        \"\"\"\r\n"]
[175.145268, "o", "        raise AbstractMethodError(self)\r\n"]
[175.180085, "o", "\r\n"]
[175.214901, "o", "    @final\r\n"]
[175.249718, "o", "    def to_numpy(\r\n"]
[175.284535, "o", "        self,\r\n"]
[175.319352, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[175.354169, "o", "        copy: bool = False,\r\n"]
[175.388986, "o", "        na_value: object = lib.no_default,\r\n"]
[175.423803, "o", "        **kwargs,\r\n"]
[175.45862, "o", "    ) -> np.ndarray:\r\n"]
[175.493437, "o", "        \"\"\"\r\n"]
[175.528254, "o", "        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[175.56307, "o", "\r\n"]
[175.597887, "o", "        Parameters\r\n"]
[175.632704, "o", "        ----------\r\n"]
[175.667521, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[175.702338, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[175.737155, "o", "        copy : bool, default False\r\n"]
[175.771972, "o", "            Whether to ensure that the returned value is not a view on\r\n"]
[175.806789, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[175.841606, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[175.876423, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[175.911239, "o", "        na_value : Any, optional\r\n"]
[175.946056, "o", "            The value to use for missing values. The default value depends\r\n"]
[175.980873, "o", "            on `dtype` and the type of the array.\r\n"]
[176.01569, "o", "\r\n"]
[176.050507, "o", "            .. versionadded:: 1.0.0\r\n"]
[176.085324, "o", "\r\n"]
[176.120141, "o", "        **kwargs\r\n"]
[176.154958, "o", "            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[176.189775, "o", "            of the underlying array (for extension arrays).\r\n"]
[176.224592, "o", "\r\n"]
[176.259408, "o", "            .. versionadded:: 1.0.0\r\n"]
[176.294225, "o", "\r\n"]
[176.329042, "o", "        Returns\r\n"]
[176.363859, "o", "        -------\r\n"]
[176.398676, "o", "        numpy.ndarray\r\n"]
[176.433493, "o", "\r\n"]
[176.46831, "o", "        See Also\r\n"]
[176.503127, "o", "        --------\r\n"]
[176.537944, "o", "        Series.array : Get the actual data stored within.\r\n"]
[176.572761, "o", "        Index.array : Get the actual data stored within.\r\n"]
[176.607577, "o", "        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[176.642394, "o", "\r\n"]
[176.677211, "o", "        Notes\r\n"]
[176.712028, "o", "        -----\r\n"]
[176.746845, "o", "        The returned array will be the same up to equality (values equal\r\n"]
[176.781662, "o", "        in `self` will be equal in the returned array; likewise for values\r\n"]
[176.816479, "o", "        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[176.851296, "o", "        dtype may be different. For example, for a category-dtype Series,\r\n"]
[176.886113, "o", "        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[176.92093, "o", "        will be lost.\r\n"]
[176.955746, "o", "\r\n"]
[176.990563, "o", "        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[177.02538, "o", "        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[177.060197, "o", "        in place will modify the data stored in the Series or Index (not that\r\n"]
[177.095014, "o", "        we recommend doing that).\r\n"]
[177.129831, "o", "\r\n"]
[177.164648, "o", "        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[177.199465, "o", "        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[177.234282, "o", "        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[177.269099, "o", "        :attr:`Series.array` should be used instead.\r\n"]
[177.303915, "o", "\r\n"]
[177.338732, "o", "        This table lays out the different dtypes and default return types of\r\n"]
[177.373549, "o", "        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[177.408366, "o", "\r\n"]
[177.443183, "o", "        ================== ================================\r\n"]
[177.478, "o", "        dtype              array type\r\n"]
[177.512817, "o", "        ================== ================================\r\n"]
[177.547634, "o", "        category[T]        ndarray[T] (same dtype as input)\r\n"]
[177.582451, "o", "        period             ndarray[object] (Periods)\r\n"]
[177.617268, "o", "        interval           ndarray[object] (Intervals)\r\n"]
[177.652085, "o", "        IntegerNA          ndarray[object]\r\n"]
[177.686901, "o", "        datetime64[ns]     datetime64[ns]\r\n"]
[177.721718, "o", "        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[177.756535, "o", "        ================== ================================\r\n"]
[177.791352, "o", "\r\n"]
[177.826169, "o", "        Examples\r\n"]
[177.860986, "o", "        --------\r\n"]
[177.895803, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[177.93062, "o", "        >>> ser.to_numpy()\r\n"]
[177.965437, "o", "        array(['a', 'b', 'a'], dtype=object)\r\n"]
[178.000254, "o", "\r\n"]
[178.03507, "o", "        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[178.069887, "o", "        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[178.104704, "o", "        objects, each with the correct ``tz``.\r\n"]
[178.139521, "o", "\r\n"]
[178.174338, "o", "        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[178.209155, "o", "        >>> ser.to_numpy(dtype=object)\r\n"]
[178.243972, "o", "        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[178.278789, "o", "               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[178.313606, "o", "              dtype=object)\r\n"]
[178.348423, "o", "\r\n"]
[178.383239, "o", "        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[178.418056, "o", "        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[178.452873, "o", "        info is dropped.\r\n"]
[178.48769, "o", "\r\n"]
[178.522507, "o", "        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[178.557324, "o", "        ... # doctest: +ELLIPSIS\r\n"]
[178.592141, "o", "        array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\r\n"]
[178.626958, "o", "              dtype='datetime64[ns]')\r\n"]
[178.661775, "o", "        \"\"\"\r\n"]
[178.696592, "o", "        if is_extension_array_dtype(self.dtype):\r\n"]
[178.731408, "o", "            return self.array.to_numpy(dtype, copy=copy, na_value=na_value, **kwargs)\r\n"]
[178.766225, "o", "        elif kwargs:\r\n"]
[178.801042, "o", "            bad_keys = list(kwargs.keys())[0]\r\n"]
[178.835859, "o", "            raise TypeError(\r\n"]
[178.870676, "o", "                f\"to_numpy() got an unexpected keyword argument '{bad_keys}'\"\r\n"]
[178.905493, "o", "            )\r\n"]
[178.94031, "o", "\r\n"]
[178.975127, "o", "        if na_value is not lib.no_default:\r\n"]
[179.009944, "o", "            values = self._values\r\n"]
[179.044761, "o", "            if not can_hold_element(values, na_value):\r\n"]
[179.079577, "o", "                # if we can't hold the na_value asarray either makes a copy or we\r\n"]
[179.114394, "o", "                # error before modifying values. The asarray later on thus won't make\r\n"]
[179.149211, "o", "                # another copy\r\n"]
[179.184028, "o", "                values = np.asarray(values, dtype=dtype)\r\n"]
[179.218845, "o", "            else:\r\n"]
[179.253662, "o", "                values = values.copy()\r\n"]
[179.288479, "o", "\r\n"]
[179.323296, "o", "            values[np.asanyarray(self.isna())] = na_value\r\n"]
[179.358113, "o", "        else:\r\n"]
[179.39293, "o", "            values = self._values\r\n"]
[179.427746, "o", "\r\n"]
[179.462563, "o", "        result = np.asarray(values, dtype=dtype)\r\n"]
[179.49738, "o", "\r\n"]
[179.532197, "o", "        if copy and na_value is lib.no_default:\r\n"]
[179.567014, "o", "            if np.shares_memory(self._values[:2], result[:2]):\r\n"]
[179.601831, "o", "                # Take slices to improve performance of check\r\n"]
[179.636648, "o", "                result = result.copy()\r\n"]
[179.671465, "o", "\r\n"]
[179.706282, "o", "        return result\r\n"]
[179.741099, "o", "\r\n"]
[179.775915, "o", "    @final\r\n"]
[179.810732, "o", "    @property\r\n"]
[179.845549, "o", "    def empty(self) -> bool:\r\n"]
[179.880366, "o", "        return not self.size\r\n"]
[179.915183, "o", "\r\n"]
[180.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[180.002, "i", "sed -n '560,740p' pandas/core/base.py\r"]
[180.004, "o", "sed -n '560,740p' pandas/core/base.py\r\n"]
[180.033165, "o", "\u001b[?2004l\r\n"]
[180.06033, "o", "    def max(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[180.087495, "o", "        \"\"\"\r\n"]
[180.114659, "o", "        Return the maximum value of the Index.\r\n"]
[180.141824, "o", "\r\n"]
[180.168989, "o", "        Parameters\r\n"]
[180.196154, "o", "        ----------\r\n"]
[180.223319, "o", "        axis : int, optional\r\n"]
[180.250484, "o", "            For compatibility with NumPy. Only 0 or None are allowed.\r\n"]
[180.277648, "o", "        skipna : bool, default True\r\n"]
[180.304813, "o", "            Exclude NA/null values when showing the result.\r\n"]
[180.331978, "o", "        *args, **kwargs\r\n"]
[180.359143, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[180.386308, "o", "\r\n"]
[180.413473, "o", "        Returns\r\n"]
[180.440637, "o", "        -------\r\n"]
[180.467802, "o", "        scalar\r\n"]
[180.494967, "o", "            Maximum value.\r\n"]
[180.522132, "o", "\r\n"]
[180.549297, "o", "        See Also\r\n"]
[180.576462, "o", "        --------\r\n"]
[180.603626, "o", "        Index.min : Return the minimum value in an Index.\r\n"]
[180.630791, "o", "        Series.max : Return the maximum value in a Series.\r\n"]
[180.657956, "o", "        DataFrame.max : Return the maximum values in a DataFrame.\r\n"]
[180.685121, "o", "\r\n"]
[180.712286, "o", "        Examples\r\n"]
[180.739451, "o", "        --------\r\n"]
[180.766615, "o", "        >>> idx = pd.Index([3, 2, 1])\r\n"]
[180.79378, "o", "        >>> idx.max()\r\n"]
[180.820945, "o", "        3\r\n"]
[180.84811, "o", "\r\n"]
[180.875275, "o", "        >>> idx = pd.Index(['c', 'b', 'a'])\r\n"]
[180.90244, "o", "        >>> idx.max()\r\n"]
[180.929604, "o", "        'c'\r\n"]
[180.956769, "o", "\r\n"]
[180.983934, "o", "        For a MultiIndex, the maximum is determined lexicographically.\r\n"]
[181.011099, "o", "\r\n"]
[181.038264, "o", "        >>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])\r\n"]
[181.065429, "o", "        >>> idx.max()\r\n"]
[181.092593, "o", "        ('b', 2)\r\n"]
[181.119758, "o", "        \"\"\"\r\n"]
[181.146923, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[181.174088, "o", "        nv.validate_max(args, kwargs)\r\n"]
[181.201253, "o", "        return nanops.nanmax(self._values, skipna=skipna)\r\n"]
[181.228418, "o", "\r\n"]
[181.255582, "o", "    @doc(op=\"max\", oppose=\"min\", value=\"largest\")\r\n"]
[181.282747, "o", "    def argmax(\r\n"]
[181.309912, "o", "        self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs\r\n"]
[181.337077, "o", "    ) -> int:\r\n"]
[181.364242, "o", "        \"\"\"\r\n"]
[181.391407, "o", "        Return int position of the {value} value in the Series.\r\n"]
[181.418571, "o", "\r\n"]
[181.445736, "o", "        If the {op}imum is achieved in multiple locations,\r\n"]
[181.472901, "o", "        the first row position is returned.\r\n"]
[181.500066, "o", "\r\n"]
[181.527231, "o", "        Parameters\r\n"]
[181.554396, "o", "        ----------\r\n"]
[181.58156, "o", "        axis : {{None}}\r\n"]
[181.608725, "o", "            Unused. Parameter needed for compatibility with DataFrame.\r\n"]
[181.63589, "o", "        skipna : bool, default True\r\n"]
[181.663055, "o", "            Exclude NA/null values when showing the result.\r\n"]
[181.69022, "o", "        *args, **kwargs\r\n"]
[181.717385, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[181.744549, "o", "\r\n"]
[181.771714, "o", "        Returns\r\n"]
[181.798879, "o", "        -------\r\n"]
[181.826044, "o", "        int\r\n"]
[181.853209, "o", "            Row position of the {op}imum value.\r\n"]
[181.880374, "o", "\r\n"]
[181.907538, "o", "        See Also\r\n"]
[181.934703, "o", "        --------\r\n"]
[181.961868, "o", "        Series.arg{op} : Return position of the {op}imum value.\r\n"]
[181.989033, "o", "        Series.arg{oppose} : Return position of the {oppose}imum value.\r\n"]
[182.016198, "o", "        numpy.ndarray.arg{op} : Equivalent method for numpy arrays.\r\n"]
[182.043363, "o", "        Series.idxmax : Return index label of the maximum values.\r\n"]
[182.070527, "o", "        Series.idxmin : Return index label of the minimum values.\r\n"]
[182.097692, "o", "\r\n"]
[182.124857, "o", "        Examples\r\n"]
[182.152022, "o", "        --------\r\n"]
[182.179187, "o", "        Consider dataset containing cereal calories\r\n"]
[182.206352, "o", "\r\n"]
[182.233516, "o", "        >>> s = pd.Series({{'Corn Flakes': 100.0, 'Almond Delight': 110.0,\r\n"]
[182.260681, "o", "        ...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0}})\r\n"]
[182.287846, "o", "        >>> s\r\n"]
[182.315011, "o", "        Corn Flakes              100.0\r\n"]
[182.342176, "o", "        Almond Delight           110.0\r\n"]
[182.369341, "o", "        Cinnamon Toast Crunch    120.0\r\n"]
[182.396505, "o", "        Cocoa Puff               110.0\r\n"]
[182.42367, "o", "        dtype: float64\r\n"]
[182.450835, "o", "\r\n"]
[182.478, "o", "        >>> s.argmax()\r\n"]
[182.505165, "o", "        2\r\n"]
[182.53233, "o", "        >>> s.argmin()\r\n"]
[182.559495, "o", "        0\r\n"]
[182.586659, "o", "\r\n"]
[182.613824, "o", "        The maximum cereal calories is the third element and\r\n"]
[182.640989, "o", "        the minimum cereal calories is the first element,\r\n"]
[182.668154, "o", "        since series is zero-indexed.\r\n"]
[182.695319, "o", "        \"\"\"\r\n"]
[182.722484, "o", "        delegate = self._values\r\n"]
[182.749648, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[182.776813, "o", "        skipna = nv.validate_argmax_with_skipna(skipna, args, kwargs)\r\n"]
[182.803978, "o", "\r\n"]
[182.831143, "o", "        if isinstance(delegate, ExtensionArray):\r\n"]
[182.858308, "o", "            if not skipna and delegate.isna().any():\r\n"]
[182.885473, "o", "                return -1\r\n"]
[182.912637, "o", "            else:\r\n"]
[182.939802, "o", "                return delegate.argmax()\r\n"]
[182.966967, "o", "        else:\r\n"]
[182.994132, "o", "            # error: Incompatible return value type (got \"Union[int, ndarray]\", expected\r\n"]
[183.021297, "o", "            # \"int\")\r\n"]
[183.048462, "o", "            return nanops.nanargmax(  # type: ignore[return-value]\r\n"]
[183.075626, "o", "                delegate, skipna=skipna\r\n"]
[183.102791, "o", "            )\r\n"]
[183.129956, "o", "\r\n"]
[183.157121, "o", "    def min(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[183.184286, "o", "        \"\"\"\r\n"]
[183.211451, "o", "        Return the minimum value of the Index.\r\n"]
[183.238615, "o", "\r\n"]
[183.26578, "o", "        Parameters\r\n"]
[183.292945, "o", "        ----------\r\n"]
[183.32011, "o", "        axis : {None}\r\n"]
[183.347275, "o", "            Dummy argument for consistency with Series.\r\n"]
[183.37444, "o", "        skipna : bool, default True\r\n"]
[183.401604, "o", "            Exclude NA/null values when showing the result.\r\n"]
[183.428769, "o", "        *args, **kwargs\r\n"]
[183.455934, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[183.483099, "o", "\r\n"]
[183.510264, "o", "        Returns\r\n"]
[183.537429, "o", "        -------\r\n"]
[183.564593, "o", "        scalar\r\n"]
[183.591758, "o", "            Minimum value.\r\n"]
[183.618923, "o", "\r\n"]
[183.646088, "o", "        See Also\r\n"]
[183.673253, "o", "        --------\r\n"]
[183.700418, "o", "        Index.max : Return the maximum value of the object.\r\n"]
[183.727582, "o", "        Series.min : Return the minimum value in a Series.\r\n"]
[183.754747, "o", "        DataFrame.min : Return the minimum values in a DataFrame.\r\n"]
[183.781912, "o", "\r\n"]
[183.809077, "o", "        Examples\r\n"]
[183.836242, "o", "        --------\r\n"]
[183.863407, "o", "        >>> idx = pd.Index([3, 2, 1])\r\n"]
[183.890571, "o", "        >>> idx.min()\r\n"]
[183.917736, "o", "        1\r\n"]
[183.944901, "o", "\r\n"]
[183.972066, "o", "        >>> idx = pd.Index(['c', 'b', 'a'])\r\n"]
[183.999231, "o", "        >>> idx.min()\r\n"]
[184.026396, "o", "        'a'\r\n"]
[184.05356, "o", "\r\n"]
[184.080725, "o", "        For a MultiIndex, the minimum is determined lexicographically.\r\n"]
[184.10789, "o", "\r\n"]
[184.135055, "o", "        >>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])\r\n"]
[184.16222, "o", "        >>> idx.min()\r\n"]
[184.189385, "o", "        ('a', 1)\r\n"]
[184.216549, "o", "        \"\"\"\r\n"]
[184.243714, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[184.270879, "o", "        nv.validate_min(args, kwargs)\r\n"]
[184.298044, "o", "        return nanops.nanmin(self._values, skipna=skipna)\r\n"]
[184.325209, "o", "\r\n"]
[184.352374, "o", "    @doc(argmax, op=\"min\", oppose=\"max\", value=\"smallest\")\r\n"]
[184.379538, "o", "    def argmin(\r\n"]
[184.406703, "o", "        self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs\r\n"]
[184.433868, "o", "    ) -> int:\r\n"]
[184.461033, "o", "        delegate = self._values\r\n"]
[184.488198, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[184.515363, "o", "        skipna = nv.validate_argmin_with_skipna(skipna, args, kwargs)\r\n"]
[184.542527, "o", "\r\n"]
[184.569692, "o", "        if isinstance(delegate, ExtensionArray):\r\n"]
[184.596857, "o", "            if not skipna and delegate.isna().any():\r\n"]
[184.624022, "o", "                return -1\r\n"]
[184.651187, "o", "            else:\r\n"]
[184.678352, "o", "                return delegate.argmin()\r\n"]
[184.705516, "o", "        else:\r\n"]
[184.732681, "o", "            # error: Incompatible return value type (got \"Union[int, ndarray]\", expected\r\n"]
[184.759846, "o", "            # \"int\")\r\n"]
[184.787011, "o", "            return nanops.nanargmin(  # type: ignore[return-value]\r\n"]
[184.814176, "o", "                delegate, skipna=skipna\r\n"]
[184.841341, "o", "            )\r\n"]
[184.868505, "o", "\r\n"]
[184.89567, "o", "    def tolist(self):\r\n"]
[184.922835, "o", "        \"\"\"\r\n"]
[185.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[185.002, "i", "sed -n '740,900p' pandas/core/base.py\r"]
[185.004, "o", "sed -n '740,900p' pandas/core/base.py\r\n"]
[185.036519, "o", "\u001b[?2004l\r\n"]
[185.067037, "o", "        Return a list of the values.\r\n"]
[185.097556, "o", "\r\n"]
[185.128074, "o", "        These are each a scalar type, which is a Python scalar\r\n"]
[185.158593, "o", "        (for str, int, float) or a pandas scalar\r\n"]
[185.189111, "o", "        (for Timestamp/Timedelta/Interval/Period)\r\n"]
[185.21963, "o", "\r\n"]
[185.250148, "o", "        Returns\r\n"]
[185.280667, "o", "        -------\r\n"]
[185.311185, "o", "        list\r\n"]
[185.341704, "o", "\r\n"]
[185.372222, "o", "        See Also\r\n"]
[185.402741, "o", "        --------\r\n"]
[185.433259, "o", "        numpy.ndarray.tolist : Return the array as an a.ndim-levels deep\r\n"]
[185.463778, "o", "            nested list of Python scalars.\r\n"]
[185.494296, "o", "        \"\"\"\r\n"]
[185.524815, "o", "        return self._values.tolist()\r\n"]
[185.555333, "o", "\r\n"]
[185.585852, "o", "    to_list = tolist\r\n"]
[185.61637, "o", "\r\n"]
[185.646889, "o", "    def __iter__(self) -> Iterator:\r\n"]
[185.677407, "o", "        \"\"\"\r\n"]
[185.707926, "o", "        Return an iterator of the values.\r\n"]
[185.738444, "o", "\r\n"]
[185.768963, "o", "        These are each a scalar type, which is a Python scalar\r\n"]
[185.799481, "o", "        (for str, int, float) or a pandas scalar\r\n"]
[185.83, "o", "        (for Timestamp/Timedelta/Interval/Period)\r\n"]
[185.860519, "o", "\r\n"]
[185.891037, "o", "        Returns\r\n"]
[185.921556, "o", "        -------\r\n"]
[185.952074, "o", "        iterator\r\n"]
[185.982593, "o", "        \"\"\"\r\n"]
[186.013111, "o", "        # We are explicitly making element iterators.\r\n"]
[186.04363, "o", "        if not isinstance(self._values, np.ndarray):\r\n"]
[186.074148, "o", "            # Check type instead of dtype to catch DTA/TDA\r\n"]
[186.104667, "o", "            return iter(self._values)\r\n"]
[186.135185, "o", "        else:\r\n"]
[186.165704, "o", "            return map(self._values.item, range(self._values.size))\r\n"]
[186.196222, "o", "\r\n"]
[186.226741, "o", "    @cache_readonly\r\n"]
[186.257259, "o", "    def hasnans(self) -> bool:\r\n"]
[186.287778, "o", "        \"\"\"\r\n"]
[186.318296, "o", "        Return True if there are any NaNs.\r\n"]
[186.348815, "o", "\r\n"]
[186.379333, "o", "        Enables various performance speedups.\r\n"]
[186.409852, "o", "\r\n"]
[186.44037, "o", "        Returns\r\n"]
[186.470889, "o", "        -------\r\n"]
[186.501407, "o", "        bool\r\n"]
[186.531926, "o", "        \"\"\"\r\n"]
[186.562444, "o", "        # error: Item \"bool\" of \"Union[bool, ndarray[Any, dtype[bool_]], NDFrame]\"\r\n"]
[186.592963, "o", "        # has no attribute \"any\"\r\n"]
[186.623481, "o", "        return bool(isna(self).any())  # type: ignore[union-attr]\r\n"]
[186.654, "o", "\r\n"]
[186.684519, "o", "    def isna(self) -> npt.NDArray[np.bool_]:\r\n"]
[186.715037, "o", "        return isna(self._values)\r\n"]
[186.745556, "o", "\r\n"]
[186.776074, "o", "    def _reduce(\r\n"]
[186.806593, "o", "        self,\r\n"]
[186.837111, "o", "        op,\r\n"]
[186.86763, "o", "        name: str,\r\n"]
[186.898148, "o", "        *,\r\n"]
[186.928667, "o", "        axis: Axis = 0,\r\n"]
[186.959185, "o", "        skipna: bool = True,\r\n"]
[186.989704, "o", "        numeric_only=None,\r\n"]
[187.020222, "o", "        filter_type=None,\r\n"]
[187.050741, "o", "        **kwds,\r\n"]
[187.081259, "o", "    ):\r\n"]
[187.111778, "o", "        \"\"\"\r\n"]
[187.142296, "o", "        Perform the reduction type operation if we can.\r\n"]
[187.172815, "o", "        \"\"\"\r\n"]
[187.203333, "o", "        func = getattr(self, name, None)\r\n"]
[187.233852, "o", "        if func is None:\r\n"]
[187.26437, "o", "            raise TypeError(\r\n"]
[187.294889, "o", "                f\"{type(self).__name__} cannot perform the operation {name}\"\r\n"]
[187.325407, "o", "            )\r\n"]
[187.355926, "o", "        return func(skipna=skipna, **kwds)\r\n"]
[187.386444, "o", "\r\n"]
[187.416963, "o", "    @final\r\n"]
[187.447481, "o", "    def _map_values(self, mapper, na_action=None):\r\n"]
[187.478, "o", "        \"\"\"\r\n"]
[187.508519, "o", "        An internal function that maps values using the input\r\n"]
[187.539037, "o", "        correspondence (which can be a dict, Series, or function).\r\n"]
[187.569556, "o", "\r\n"]
[187.600074, "o", "        Parameters\r\n"]
[187.630593, "o", "        ----------\r\n"]
[187.661111, "o", "        mapper : function, dict, or Series\r\n"]
[187.69163, "o", "            The input correspondence object\r\n"]
[187.722148, "o", "        na_action : {None, 'ignore'}\r\n"]
[187.752667, "o", "            If 'ignore', propagate NA values, without passing them to the\r\n"]
[187.783185, "o", "            mapping function\r\n"]
[187.813704, "o", "\r\n"]
[187.844222, "o", "        Returns\r\n"]
[187.874741, "o", "        -------\r\n"]
[187.905259, "o", "        Union[Index, MultiIndex], inferred\r\n"]
[187.935778, "o", "            The output of the mapping function applied to the index.\r\n"]
[187.966296, "o", "            If the function returns a tuple with more than one element\r\n"]
[187.996815, "o", "            a MultiIndex will be returned.\r\n"]
[188.027333, "o", "        \"\"\"\r\n"]
[188.057852, "o", "        # we can fastpath dict/Series to an efficient map\r\n"]
[188.08837, "o", "        # as we know that we are not going to have to yield\r\n"]
[188.118889, "o", "        # python types\r\n"]
[188.149407, "o", "        if is_dict_like(mapper):\r\n"]
[188.179926, "o", "            if isinstance(mapper, dict) and hasattr(mapper, \"__missing__\"):\r\n"]
[188.210444, "o", "                # If a dictionary subclass defines a default value method,\r\n"]
[188.240963, "o", "                # convert mapper to a lookup function (GH #15999).\r\n"]
[188.271481, "o", "                dict_with_default = mapper\r\n"]
[188.302, "o", "                mapper = lambda x: dict_with_default[\r\n"]
[188.332519, "o", "                    np.nan if isinstance(x, float) and np.isnan(x) else x\r\n"]
[188.363037, "o", "                ]\r\n"]
[188.393556, "o", "            else:\r\n"]
[188.424074, "o", "                # Dictionary does not have a default. Thus it's safe to\r\n"]
[188.454593, "o", "                # convert to an Series for efficiency.\r\n"]
[188.485111, "o", "                # we specify the keys here to handle the\r\n"]
[188.51563, "o", "                # possibility that they are tuples\r\n"]
[188.546148, "o", "\r\n"]
[188.576667, "o", "                # The return value of mapping with an empty mapper is\r\n"]
[188.607185, "o", "                # expected to be pd.Series(np.nan, ...). As np.nan is\r\n"]
[188.637704, "o", "                # of dtype float64 the return value of this method should\r\n"]
[188.668222, "o", "                # be float64 as well\r\n"]
[188.698741, "o", "                from pandas import Series\r\n"]
[188.729259, "o", "\r\n"]
[188.759778, "o", "                if len(mapper) == 0:\r\n"]
[188.790296, "o", "                    mapper = Series(mapper, dtype=np.float64)\r\n"]
[188.820815, "o", "                else:\r\n"]
[188.851333, "o", "                    mapper = Series(mapper)\r\n"]
[188.881852, "o", "\r\n"]
[188.91237, "o", "        if isinstance(mapper, ABCSeries):\r\n"]
[188.942889, "o", "            if na_action not in (None, \"ignore\"):\r\n"]
[188.973407, "o", "                msg = (\r\n"]
[189.003926, "o", "                    \"na_action must either be 'ignore' or None, \"\r\n"]
[189.034444, "o", "                    f\"{na_action} was passed\"\r\n"]
[189.064963, "o", "                )\r\n"]
[189.095481, "o", "                raise ValueError(msg)\r\n"]
[189.126, "o", "\r\n"]
[189.156519, "o", "            if na_action == \"ignore\":\r\n"]
[189.187037, "o", "                mapper = mapper[mapper.index.notna()]\r\n"]
[189.217556, "o", "\r\n"]
[189.248074, "o", "            # Since values were input this means we came from either\r\n"]
[189.278593, "o", "            # a dict or a series and mapper should be an index\r\n"]
[189.309111, "o", "            if is_categorical_dtype(self.dtype):\r\n"]
[189.33963, "o", "                # use the built in categorical series mapper which saves\r\n"]
[189.370148, "o", "                # time by mapping the categories instead of all values\r\n"]
[189.400667, "o", "\r\n"]
[189.431185, "o", "                cat = cast(\"Categorical\", self._values)\r\n"]
[189.461704, "o", "                return cat.map(mapper)\r\n"]
[189.492222, "o", "\r\n"]
[189.522741, "o", "            values = self._values\r\n"]
[189.553259, "o", "\r\n"]
[189.583778, "o", "            indexer = mapper.index.get_indexer(values)\r\n"]
[189.614296, "o", "            new_values = algorithms.take_nd(mapper._values, indexer)\r\n"]
[189.644815, "o", "\r\n"]
[189.675333, "o", "            return new_values\r\n"]
[189.705852, "o", "\r\n"]
[189.73637, "o", "        # we must convert to python types\r\n"]
[189.766889, "o", "        if is_extension_array_dtype(self.dtype) and hasattr(self._values, \"map\"):\r\n"]
[189.797407, "o", "            # GH#23179 some EAs do not have `map`\r\n"]
[189.827926, "o", "            values = self._values\r\n"]
[189.858444, "o", "            if na_action is not None:\r\n"]
[189.888963, "o", "                raise NotImplementedError\r\n"]
[189.919481, "o", "            map_f = lambda values, f: values.map(f)\r\n"]
[190.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[190.002, "i", "sed -n '400,520p' pandas/core/base.py\r"]
[190.004, "o", "sed -n '400,520p' pandas/core/base.py\r\n"]
[190.046525, "o", "\u001b[?2004l\r\n"]
[190.087049, "o", "        :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\r\n"]
[190.127574, "o", "        stored within. If you absolutely need a NumPy array (possibly with\r\n"]
[190.168098, "o", "        copying / coercing data), then use :meth:`Series.to_numpy` instead.\r\n"]
[190.208623, "o", "\r\n"]
[190.249148, "o", "        Examples\r\n"]
[190.289672, "o", "        --------\r\n"]
[190.330197, "o", "        For regular NumPy types like int, and float, a PandasArray\r\n"]
[190.370721, "o", "        is returned.\r\n"]
[190.411246, "o", "\r\n"]
[190.45177, "o", "        >>> pd.Series([1, 2, 3]).array\r\n"]
[190.492295, "o", "        <PandasArray>\r\n"]
[190.53282, "o", "        [1, 2, 3]\r\n"]
[190.573344, "o", "        Length: 3, dtype: int64\r\n"]
[190.613869, "o", "\r\n"]
[190.654393, "o", "        For extension types, like Categorical, the actual ExtensionArray\r\n"]
[190.694918, "o", "        is returned\r\n"]
[190.735443, "o", "\r\n"]
[190.775967, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[190.816492, "o", "        >>> ser.array\r\n"]
[190.857016, "o", "        ['a', 'b', 'a']\r\n"]
[190.897541, "o", "        Categories (2, object): ['a', 'b']\r\n"]
[190.938066, "o", "        \"\"\"\r\n"]
[190.97859, "o", "        raise AbstractMethodError(self)\r\n"]
[191.019115, "o", "\r\n"]
[191.059639, "o", "    @final\r\n"]
[191.100164, "o", "    def to_numpy(\r\n"]
[191.140689, "o", "        self,\r\n"]
[191.181213, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[191.221738, "o", "        copy: bool = False,\r\n"]
[191.262262, "o", "        na_value: object = lib.no_default,\r\n"]
[191.302787, "o", "        **kwargs,\r\n"]
[191.343311, "o", "    ) -> np.ndarray:\r\n"]
[191.383836, "o", "        \"\"\"\r\n"]
[191.424361, "o", "        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[191.464885, "o", "\r\n"]
[191.50541, "o", "        Parameters\r\n"]
[191.545934, "o", "        ----------\r\n"]
[191.586459, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[191.626984, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[191.667508, "o", "        copy : bool, default False\r\n"]
[191.708033, "o", "            Whether to ensure that the returned value is not a view on\r\n"]
[191.748557, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[191.789082, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[191.829607, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[191.870131, "o", "        na_value : Any, optional\r\n"]
[191.910656, "o", "            The value to use for missing values. The default value depends\r\n"]
[191.95118, "o", "            on `dtype` and the type of the array.\r\n"]
[191.991705, "o", "\r\n"]
[192.03223, "o", "            .. versionadded:: 1.0.0\r\n"]
[192.072754, "o", "\r\n"]
[192.113279, "o", "        **kwargs\r\n"]
[192.153803, "o", "            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[192.194328, "o", "            of the underlying array (for extension arrays).\r\n"]
[192.234852, "o", "\r\n"]
[192.275377, "o", "            .. versionadded:: 1.0.0\r\n"]
[192.315902, "o", "\r\n"]
[192.356426, "o", "        Returns\r\n"]
[192.396951, "o", "        -------\r\n"]
[192.437475, "o", "        numpy.ndarray\r\n"]
[192.478, "o", "\r\n"]
[192.518525, "o", "        See Also\r\n"]
[192.559049, "o", "        --------\r\n"]
[192.599574, "o", "        Series.array : Get the actual data stored within.\r\n"]
[192.640098, "o", "        Index.array : Get the actual data stored within.\r\n"]
[192.680623, "o", "        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[192.721148, "o", "\r\n"]
[192.761672, "o", "        Notes\r\n"]
[192.802197, "o", "        -----\r\n"]
[192.842721, "o", "        The returned array will be the same up to equality (values equal\r\n"]
[192.883246, "o", "        in `self` will be equal in the returned array; likewise for values\r\n"]
[192.92377, "o", "        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[192.964295, "o", "        dtype may be different. For example, for a category-dtype Series,\r\n"]
[193.00482, "o", "        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[193.045344, "o", "        will be lost.\r\n"]
[193.085869, "o", "\r\n"]
[193.126393, "o", "        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[193.166918, "o", "        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[193.207443, "o", "        in place will modify the data stored in the Series or Index (not that\r\n"]
[193.247967, "o", "        we recommend doing that).\r\n"]
[193.288492, "o", "\r\n"]
[193.329016, "o", "        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[193.369541, "o", "        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[193.410066, "o", "        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[193.45059, "o", "        :attr:`Series.array` should be used instead.\r\n"]
[193.491115, "o", "\r\n"]
[193.531639, "o", "        This table lays out the different dtypes and default return types of\r\n"]
[193.572164, "o", "        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[193.612689, "o", "\r\n"]
[193.653213, "o", "        ================== ================================\r\n"]
[193.693738, "o", "        dtype              array type\r\n"]
[193.734262, "o", "        ================== ================================\r\n"]
[193.774787, "o", "        category[T]        ndarray[T] (same dtype as input)\r\n"]
[193.815311, "o", "        period             ndarray[object] (Periods)\r\n"]
[193.855836, "o", "        interval           ndarray[object] (Intervals)\r\n"]
[193.896361, "o", "        IntegerNA          ndarray[object]\r\n"]
[193.936885, "o", "        datetime64[ns]     datetime64[ns]\r\n"]
[193.97741, "o", "        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[194.017934, "o", "        ================== ================================\r\n"]
[194.058459, "o", "\r\n"]
[194.098984, "o", "        Examples\r\n"]
[194.139508, "o", "        --------\r\n"]
[194.180033, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[194.220557, "o", "        >>> ser.to_numpy()\r\n"]
[194.261082, "o", "        array(['a', 'b', 'a'], dtype=object)\r\n"]
[194.301607, "o", "\r\n"]
[194.342131, "o", "        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[194.382656, "o", "        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[194.42318, "o", "        objects, each with the correct ``tz``.\r\n"]
[194.463705, "o", "\r\n"]
[194.50423, "o", "        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[194.544754, "o", "        >>> ser.to_numpy(dtype=object)\r\n"]
[194.585279, "o", "        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[194.625803, "o", "               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[194.666328, "o", "              dtype=object)\r\n"]
[194.706852, "o", "\r\n"]
[194.747377, "o", "        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[194.787902, "o", "        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[194.828426, "o", "        info is dropped.\r\n"]
[194.868951, "o", "\r\n"]
[194.909475, "o", "        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[195.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[195.002, "i", "sed -n '520,700p' pandas/core/base.py\r"]
[195.004, "o", "sed -n '520,700p' pandas/core/base.py\r\n"]
[195.033165, "o", "\u001b[?2004l\r\n"]
[195.06033, "o", "        ... # doctest: +ELLIPSIS\r\n"]
[195.087495, "o", "        array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\r\n"]
[195.114659, "o", "              dtype='datetime64[ns]')\r\n"]
[195.141824, "o", "        \"\"\"\r\n"]
[195.168989, "o", "        if is_extension_array_dtype(self.dtype):\r\n"]
[195.196154, "o", "            return self.array.to_numpy(dtype, copy=copy, na_value=na_value, **kwargs)\r\n"]
[195.223319, "o", "        elif kwargs:\r\n"]
[195.250484, "o", "            bad_keys = list(kwargs.keys())[0]\r\n"]
[195.277648, "o", "            raise TypeError(\r\n"]
[195.304813, "o", "                f\"to_numpy() got an unexpected keyword argument '{bad_keys}'\"\r\n"]
[195.331978, "o", "            )\r\n"]
[195.359143, "o", "\r\n"]
[195.386308, "o", "        if na_value is not lib.no_default:\r\n"]
[195.413473, "o", "            values = self._values\r\n"]
[195.440637, "o", "            if not can_hold_element(values, na_value):\r\n"]
[195.467802, "o", "                # if we can't hold the na_value asarray either makes a copy or we\r\n"]
[195.494967, "o", "                # error before modifying values. The asarray later on thus won't make\r\n"]
[195.522132, "o", "                # another copy\r\n"]
[195.549297, "o", "                values = np.asarray(values, dtype=dtype)\r\n"]
[195.576462, "o", "            else:\r\n"]
[195.603626, "o", "                values = values.copy()\r\n"]
[195.630791, "o", "\r\n"]
[195.657956, "o", "            values[np.asanyarray(self.isna())] = na_value\r\n"]
[195.685121, "o", "        else:\r\n"]
[195.712286, "o", "            values = self._values\r\n"]
[195.739451, "o", "\r\n"]
[195.766615, "o", "        result = np.asarray(values, dtype=dtype)\r\n"]
[195.79378, "o", "\r\n"]
[195.820945, "o", "        if copy and na_value is lib.no_default:\r\n"]
[195.84811, "o", "            if np.shares_memory(self._values[:2], result[:2]):\r\n"]
[195.875275, "o", "                # Take slices to improve performance of check\r\n"]
[195.90244, "o", "                result = result.copy()\r\n"]
[195.929604, "o", "\r\n"]
[195.956769, "o", "        return result\r\n"]
[195.983934, "o", "\r\n"]
[196.011099, "o", "    @final\r\n"]
[196.038264, "o", "    @property\r\n"]
[196.065429, "o", "    def empty(self) -> bool:\r\n"]
[196.092593, "o", "        return not self.size\r\n"]
[196.119758, "o", "\r\n"]
[196.146923, "o", "    def max(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[196.174088, "o", "        \"\"\"\r\n"]
[196.201253, "o", "        Return the maximum value of the Index.\r\n"]
[196.228418, "o", "\r\n"]
[196.255582, "o", "        Parameters\r\n"]
[196.282747, "o", "        ----------\r\n"]
[196.309912, "o", "        axis : int, optional\r\n"]
[196.337077, "o", "            For compatibility with NumPy. Only 0 or None are allowed.\r\n"]
[196.364242, "o", "        skipna : bool, default True\r\n"]
[196.391407, "o", "            Exclude NA/null values when showing the result.\r\n"]
[196.418571, "o", "        *args, **kwargs\r\n"]
[196.445736, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[196.472901, "o", "\r\n"]
[196.500066, "o", "        Returns\r\n"]
[196.527231, "o", "        -------\r\n"]
[196.554396, "o", "        scalar\r\n"]
[196.58156, "o", "            Maximum value.\r\n"]
[196.608725, "o", "\r\n"]
[196.63589, "o", "        See Also\r\n"]
[196.663055, "o", "        --------\r\n"]
[196.69022, "o", "        Index.min : Return the minimum value in an Index.\r\n"]
[196.717385, "o", "        Series.max : Return the maximum value in a Series.\r\n"]
[196.744549, "o", "        DataFrame.max : Return the maximum values in a DataFrame.\r\n"]
[196.771714, "o", "\r\n"]
[196.798879, "o", "        Examples\r\n"]
[196.826044, "o", "        --------\r\n"]
[196.853209, "o", "        >>> idx = pd.Index([3, 2, 1])\r\n"]
[196.880374, "o", "        >>> idx.max()\r\n"]
[196.907538, "o", "        3\r\n"]
[196.934703, "o", "\r\n"]
[196.961868, "o", "        >>> idx = pd.Index(['c', 'b', 'a'])\r\n"]
[196.989033, "o", "        >>> idx.max()\r\n"]
[197.016198, "o", "        'c'\r\n"]
[197.043363, "o", "\r\n"]
[197.070527, "o", "        For a MultiIndex, the maximum is determined lexicographically.\r\n"]
[197.097692, "o", "\r\n"]
[197.124857, "o", "        >>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])\r\n"]
[197.152022, "o", "        >>> idx.max()\r\n"]
[197.179187, "o", "        ('b', 2)\r\n"]
[197.206352, "o", "        \"\"\"\r\n"]
[197.233516, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[197.260681, "o", "        nv.validate_max(args, kwargs)\r\n"]
[197.287846, "o", "        return nanops.nanmax(self._values, skipna=skipna)\r\n"]
[197.315011, "o", "\r\n"]
[197.342176, "o", "    @doc(op=\"max\", oppose=\"min\", value=\"largest\")\r\n"]
[197.369341, "o", "    def argmax(\r\n"]
[197.396505, "o", "        self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs\r\n"]
[197.42367, "o", "    ) -> int:\r\n"]
[197.450835, "o", "        \"\"\"\r\n"]
[197.478, "o", "        Return int position of the {value} value in the Series.\r\n"]
[197.505165, "o", "\r\n"]
[197.53233, "o", "        If the {op}imum is achieved in multiple locations,\r\n"]
[197.559495, "o", "        the first row position is returned.\r\n"]
[197.586659, "o", "\r\n"]
[197.613824, "o", "        Parameters\r\n"]
[197.640989, "o", "        ----------\r\n"]
[197.668154, "o", "        axis : {{None}}\r\n"]
[197.695319, "o", "            Unused. Parameter needed for compatibility with DataFrame.\r\n"]
[197.722484, "o", "        skipna : bool, default True\r\n"]
[197.749648, "o", "            Exclude NA/null values when showing the result.\r\n"]
[197.776813, "o", "        *args, **kwargs\r\n"]
[197.803978, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[197.831143, "o", "\r\n"]
[197.858308, "o", "        Returns\r\n"]
[197.885473, "o", "        -------\r\n"]
[197.912637, "o", "        int\r\n"]
[197.939802, "o", "            Row position of the {op}imum value.\r\n"]
[197.966967, "o", "\r\n"]
[197.994132, "o", "        See Also\r\n"]
[198.021297, "o", "        --------\r\n"]
[198.048462, "o", "        Series.arg{op} : Return position of the {op}imum value.\r\n"]
[198.075626, "o", "        Series.arg{oppose} : Return position of the {oppose}imum value.\r\n"]
[198.102791, "o", "        numpy.ndarray.arg{op} : Equivalent method for numpy arrays.\r\n"]
[198.129956, "o", "        Series.idxmax : Return index label of the maximum values.\r\n"]
[198.157121, "o", "        Series.idxmin : Return index label of the minimum values.\r\n"]
[198.184286, "o", "\r\n"]
[198.211451, "o", "        Examples\r\n"]
[198.238615, "o", "        --------\r\n"]
[198.26578, "o", "        Consider dataset containing cereal calories\r\n"]
[198.292945, "o", "\r\n"]
[198.32011, "o", "        >>> s = pd.Series({{'Corn Flakes': 100.0, 'Almond Delight': 110.0,\r\n"]
[198.347275, "o", "        ...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0}})\r\n"]
[198.37444, "o", "        >>> s\r\n"]
[198.401604, "o", "        Corn Flakes              100.0\r\n"]
[198.428769, "o", "        Almond Delight           110.0\r\n"]
[198.455934, "o", "        Cinnamon Toast Crunch    120.0\r\n"]
[198.483099, "o", "        Cocoa Puff               110.0\r\n"]
[198.510264, "o", "        dtype: float64\r\n"]
[198.537429, "o", "\r\n"]
[198.564593, "o", "        >>> s.argmax()\r\n"]
[198.591758, "o", "        2\r\n"]
[198.618923, "o", "        >>> s.argmin()\r\n"]
[198.646088, "o", "        0\r\n"]
[198.673253, "o", "\r\n"]
[198.700418, "o", "        The maximum cereal calories is the third element and\r\n"]
[198.727582, "o", "        the minimum cereal calories is the first element,\r\n"]
[198.754747, "o", "        since series is zero-indexed.\r\n"]
[198.781912, "o", "        \"\"\"\r\n"]
[198.809077, "o", "        delegate = self._values\r\n"]
[198.836242, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[198.863407, "o", "        skipna = nv.validate_argmax_with_skipna(skipna, args, kwargs)\r\n"]
[198.890571, "o", "\r\n"]
[198.917736, "o", "        if isinstance(delegate, ExtensionArray):\r\n"]
[198.944901, "o", "            if not skipna and delegate.isna().any():\r\n"]
[198.972066, "o", "                return -1\r\n"]
[198.999231, "o", "            else:\r\n"]
[199.026396, "o", "                return delegate.argmax()\r\n"]
[199.05356, "o", "        else:\r\n"]
[199.080725, "o", "            # error: Incompatible return value type (got \"Union[int, ndarray]\", expected\r\n"]
[199.10789, "o", "            # \"int\")\r\n"]
[199.135055, "o", "            return nanops.nanargmax(  # type: ignore[return-value]\r\n"]
[199.16222, "o", "                delegate, skipna=skipna\r\n"]
[199.189385, "o", "            )\r\n"]
[199.216549, "o", "\r\n"]
[199.243714, "o", "    def min(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[199.270879, "o", "        \"\"\"\r\n"]
[199.298044, "o", "        Return the minimum value of the Index.\r\n"]
[199.325209, "o", "\r\n"]
[199.352374, "o", "        Parameters\r\n"]
[199.379538, "o", "        ----------\r\n"]
[199.406703, "o", "        axis : {None}\r\n"]
[199.433868, "o", "            Dummy argument for consistency with Series.\r\n"]
[199.461033, "o", "        skipna : bool, default True\r\n"]
[199.488198, "o", "            Exclude NA/null values when showing the result.\r\n"]
[199.515363, "o", "        *args, **kwargs\r\n"]
[199.542527, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[199.569692, "o", "\r\n"]
[199.596857, "o", "        Returns\r\n"]
[199.624022, "o", "        -------\r\n"]
[199.651187, "o", "        scalar\r\n"]
[199.678352, "o", "            Minimum value.\r\n"]
[199.705516, "o", "\r\n"]
[199.732681, "o", "        See Also\r\n"]
[199.759846, "o", "        --------\r\n"]
[199.787011, "o", "        Index.max : Return the maximum value of the object.\r\n"]
[199.814176, "o", "        Series.min : Return the minimum value in a Series.\r\n"]
[199.841341, "o", "        DataFrame.min : Return the minimum values in a DataFrame.\r\n"]
[199.868505, "o", "\r\n"]
[199.89567, "o", "        Examples\r\n"]
[199.922835, "o", "        --------\r\n"]
[200.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[200.002, "i", "sed -n '360,520p' pandas/core/arrays/base.py\r"]
[200.004, "o", "sed -n '360,520p' pandas/core/arrays/base.py\r\n"]
[200.036519, "o", "\u001b[?2004l\r\n"]
[200.067037, "o", "        Parameters\r\n"]
[200.097556, "o", "        ----------\r\n"]
[200.128074, "o", "        key : int, ndarray, or slice\r\n"]
[200.158593, "o", "            When called from, e.g. ``Series.__setitem__``, ``key`` will be\r\n"]
[200.189111, "o", "            one of\r\n"]
[200.21963, "o", "\r\n"]
[200.250148, "o", "            * scalar int\r\n"]
[200.280667, "o", "            * ndarray of integers.\r\n"]
[200.311185, "o", "            * boolean ndarray\r\n"]
[200.341704, "o", "            * slice object\r\n"]
[200.372222, "o", "\r\n"]
[200.402741, "o", "        value : ExtensionDtype.type, Sequence[ExtensionDtype.type], or object\r\n"]
[200.433259, "o", "            value or values to be set of ``key``.\r\n"]
[200.463778, "o", "\r\n"]
[200.494296, "o", "        Returns\r\n"]
[200.524815, "o", "        -------\r\n"]
[200.555333, "o", "        None\r\n"]
[200.585852, "o", "        \"\"\"\r\n"]
[200.61637, "o", "        # Some notes to the ExtensionArray implementor who may have ended up\r\n"]
[200.646889, "o", "        # here. While this method is not required for the interface, if you\r\n"]
[200.677407, "o", "        # *do* choose to implement __setitem__, then some semantics should be\r\n"]
[200.707926, "o", "        # observed:\r\n"]
[200.738444, "o", "        #\r\n"]
[200.768963, "o", "        # * Setting multiple values : ExtensionArrays should support setting\r\n"]
[200.799481, "o", "        #   multiple values at once, 'key' will be a sequence of integers and\r\n"]
[200.83, "o", "        #  'value' will be a same-length sequence.\r\n"]
[200.860519, "o", "        #\r\n"]
[200.891037, "o", "        # * Broadcasting : For a sequence 'key' and a scalar 'value',\r\n"]
[200.921556, "o", "        #   each position in 'key' should be set to 'value'.\r\n"]
[200.952074, "o", "        #\r\n"]
[200.982593, "o", "        # * Coercion : Most users will expect basic coercion to work. For\r\n"]
[201.013111, "o", "        #   example, a string like '2018-01-01' is coerced to a datetime\r\n"]
[201.04363, "o", "        #   when setting on a datetime64ns array. In general, if the\r\n"]
[201.074148, "o", "        #   __init__ method coerces that value, then so should __setitem__\r\n"]
[201.104667, "o", "        # Note, also, that Series/DataFrame.where internally use __setitem__\r\n"]
[201.135185, "o", "        # on a copy of the data.\r\n"]
[201.165704, "o", "        raise NotImplementedError(f\"{type(self)} does not implement __setitem__.\")\r\n"]
[201.196222, "o", "\r\n"]
[201.226741, "o", "    def __len__(self) -> int:\r\n"]
[201.257259, "o", "        \"\"\"\r\n"]
[201.287778, "o", "        Length of this array\r\n"]
[201.318296, "o", "\r\n"]
[201.348815, "o", "        Returns\r\n"]
[201.379333, "o", "        -------\r\n"]
[201.409852, "o", "        length : int\r\n"]
[201.44037, "o", "        \"\"\"\r\n"]
[201.470889, "o", "        raise AbstractMethodError(self)\r\n"]
[201.501407, "o", "\r\n"]
[201.531926, "o", "    def __iter__(self) -> Iterator[Any]:\r\n"]
[201.562444, "o", "        \"\"\"\r\n"]
[201.592963, "o", "        Iterate over elements of the array.\r\n"]
[201.623481, "o", "        \"\"\"\r\n"]
[201.654, "o", "        # This needs to be implemented so that pandas recognizes extension\r\n"]
[201.684519, "o", "        # arrays as list-like. The default implementation makes successive\r\n"]
[201.715037, "o", "        # calls to ``__getitem__``, which may be slower than necessary.\r\n"]
[201.745556, "o", "        for i in range(len(self)):\r\n"]
[201.776074, "o", "            yield self[i]\r\n"]
[201.806593, "o", "\r\n"]
[201.837111, "o", "    def __contains__(self, item: object) -> bool | np.bool_:\r\n"]
[201.86763, "o", "        \"\"\"\r\n"]
[201.898148, "o", "        Return for `item in self`.\r\n"]
[201.928667, "o", "        \"\"\"\r\n"]
[201.959185, "o", "        # GH37867\r\n"]
[201.989704, "o", "        # comparisons of any item to pd.NA always return pd.NA, so e.g. \"a\" in [pd.NA]\r\n"]
[202.020222, "o", "        # would raise a TypeError. The implementation below works around that.\r\n"]
[202.050741, "o", "        if is_scalar(item) and isna(item):\r\n"]
[202.081259, "o", "            if not self._can_hold_na:\r\n"]
[202.111778, "o", "                return False\r\n"]
[202.142296, "o", "            elif item is self.dtype.na_value or isinstance(item, self.dtype.type):\r\n"]
[202.172815, "o", "                return self._hasna\r\n"]
[202.203333, "o", "            else:\r\n"]
[202.233852, "o", "                return False\r\n"]
[202.26437, "o", "        else:\r\n"]
[202.294889, "o", "            # error: Item \"ExtensionArray\" of \"Union[ExtensionArray, ndarray]\" has no\r\n"]
[202.325407, "o", "            # attribute \"any\"\r\n"]
[202.355926, "o", "            return (item == self).any()  # type: ignore[union-attr]\r\n"]
[202.386444, "o", "\r\n"]
[202.416963, "o", "    # error: Signature of \"__eq__\" incompatible with supertype \"object\"\r\n"]
[202.447481, "o", "    def __eq__(self, other: Any) -> ArrayLike:  # type: ignore[override]\r\n"]
[202.478, "o", "        \"\"\"\r\n"]
[202.508519, "o", "        Return for `self == other` (element-wise equality).\r\n"]
[202.539037, "o", "        \"\"\"\r\n"]
[202.569556, "o", "        # Implementer note: this should return a boolean numpy ndarray or\r\n"]
[202.600074, "o", "        # a boolean ExtensionArray.\r\n"]
[202.630593, "o", "        # When `other` is one of Series, Index, or DataFrame, this method should\r\n"]
[202.661111, "o", "        # return NotImplemented (to ensure that those objects are responsible for\r\n"]
[202.69163, "o", "        # first unpacking the arrays, and then dispatch the operation to the\r\n"]
[202.722148, "o", "        # underlying arrays)\r\n"]
[202.752667, "o", "        raise AbstractMethodError(self)\r\n"]
[202.783185, "o", "\r\n"]
[202.813704, "o", "    # error: Signature of \"__ne__\" incompatible with supertype \"object\"\r\n"]
[202.844222, "o", "    def __ne__(self, other: Any) -> ArrayLike:  # type: ignore[override]\r\n"]
[202.874741, "o", "        \"\"\"\r\n"]
[202.905259, "o", "        Return for `self != other` (element-wise in-equality).\r\n"]
[202.935778, "o", "        \"\"\"\r\n"]
[202.966296, "o", "        return ~(self == other)\r\n"]
[202.996815, "o", "\r\n"]
[203.027333, "o", "    def to_numpy(\r\n"]
[203.057852, "o", "        self,\r\n"]
[203.08837, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[203.118889, "o", "        copy: bool = False,\r\n"]
[203.149407, "o", "        na_value: object = lib.no_default,\r\n"]
[203.179926, "o", "    ) -> np.ndarray:\r\n"]
[203.210444, "o", "        \"\"\"\r\n"]
[203.240963, "o", "        Convert to a NumPy ndarray.\r\n"]
[203.271481, "o", "\r\n"]
[203.302, "o", "        .. versionadded:: 1.0.0\r\n"]
[203.332519, "o", "\r\n"]
[203.363037, "o", "        This is similar to :meth:`numpy.asarray`, but may provide additional control\r\n"]
[203.393556, "o", "        over how the conversion is done.\r\n"]
[203.424074, "o", "\r\n"]
[203.454593, "o", "        Parameters\r\n"]
[203.485111, "o", "        ----------\r\n"]
[203.51563, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[203.546148, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[203.576667, "o", "        copy : bool, default False\r\n"]
[203.607185, "o", "            Whether to ensure that the returned value is a not a view on\r\n"]
[203.637704, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[203.668222, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[203.698741, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[203.729259, "o", "        na_value : Any, optional\r\n"]
[203.759778, "o", "            The value to use for missing values. The default value depends\r\n"]
[203.790296, "o", "            on `dtype` and the type of the array.\r\n"]
[203.820815, "o", "\r\n"]
[203.851333, "o", "        Returns\r\n"]
[203.881852, "o", "        -------\r\n"]
[203.91237, "o", "        numpy.ndarray\r\n"]
[203.942889, "o", "        \"\"\"\r\n"]
[203.973407, "o", "        result = np.asarray(self, dtype=dtype)\r\n"]
[204.003926, "o", "        if copy or na_value is not lib.no_default:\r\n"]
[204.034444, "o", "            result = result.copy()\r\n"]
[204.064963, "o", "        if na_value is not lib.no_default:\r\n"]
[204.095481, "o", "            result[self.isna()] = na_value\r\n"]
[204.126, "o", "        return result\r\n"]
[204.156519, "o", "\r\n"]
[204.187037, "o", "    # ------------------------------------------------------------------------\r\n"]
[204.217556, "o", "    # Required attributes\r\n"]
[204.248074, "o", "    # ------------------------------------------------------------------------\r\n"]
[204.278593, "o", "\r\n"]
[204.309111, "o", "    @property\r\n"]
[204.33963, "o", "    def dtype(self) -> ExtensionDtype:\r\n"]
[204.370148, "o", "        \"\"\"\r\n"]
[204.400667, "o", "        An instance of 'ExtensionDtype'.\r\n"]
[204.431185, "o", "        \"\"\"\r\n"]
[204.461704, "o", "        raise AbstractMethodError(self)\r\n"]
[204.492222, "o", "\r\n"]
[204.522741, "o", "    @property\r\n"]
[204.553259, "o", "    def shape(self) -> Shape:\r\n"]
[204.583778, "o", "        \"\"\"\r\n"]
[204.614296, "o", "        Return a tuple of the array dimensions.\r\n"]
[204.644815, "o", "        \"\"\"\r\n"]
[204.675333, "o", "        return (len(self),)\r\n"]
[204.705852, "o", "\r\n"]
[204.73637, "o", "    @property\r\n"]
[204.766889, "o", "    def size(self) -> int:\r\n"]
[204.797407, "o", "        \"\"\"\r\n"]
[204.827926, "o", "        The number of elements in the array.\r\n"]
[204.858444, "o", "        \"\"\"\r\n"]
[204.888963, "o", "        # error: Incompatible return value type (got \"signedinteger[_64Bit]\",\r\n"]
[204.919481, "o", "        # expected \"int\")  [return-value]\r\n"]
[205.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[205.002, "i", "sed -n '340,460p' pandas/core/arrays/numpy_.py\r"]
[205.004, "o", "sed -n '340,460p' pandas/core/arrays/numpy_.py\r\n"]
[205.046525, "o", "\u001b[?2004l\r\n"]
[205.087049, "o", "        axis: AxisInt | None = None,\r\n"]
[205.127574, "o", "        dtype: NpDtype | None = None,\r\n"]
[205.168098, "o", "        out=None,\r\n"]
[205.208623, "o", "        ddof: int = 1,\r\n"]
[205.249148, "o", "        keepdims: bool = False,\r\n"]
[205.289672, "o", "        skipna: bool = True,\r\n"]
[205.330197, "o", "    ):\r\n"]
[205.370721, "o", "        nv.validate_stat_ddof_func(\r\n"]
[205.411246, "o", "            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"sem\"\r\n"]
[205.45177, "o", "        )\r\n"]
[205.492295, "o", "        result = nanops.nansem(self._ndarray, axis=axis, skipna=skipna, ddof=ddof)\r\n"]
[205.53282, "o", "        return self._wrap_reduction_result(axis, result)\r\n"]
[205.573344, "o", "\r\n"]
[205.613869, "o", "    def kurt(\r\n"]
[205.654393, "o", "        self,\r\n"]
[205.694918, "o", "        *,\r\n"]
[205.735443, "o", "        axis: AxisInt | None = None,\r\n"]
[205.775967, "o", "        dtype: NpDtype | None = None,\r\n"]
[205.816492, "o", "        out=None,\r\n"]
[205.857016, "o", "        keepdims: bool = False,\r\n"]
[205.897541, "o", "        skipna: bool = True,\r\n"]
[205.938066, "o", "    ):\r\n"]
[205.97859, "o", "        nv.validate_stat_ddof_func(\r\n"]
[206.019115, "o", "            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"kurt\"\r\n"]
[206.059639, "o", "        )\r\n"]
[206.100164, "o", "        result = nanops.nankurt(self._ndarray, axis=axis, skipna=skipna)\r\n"]
[206.140689, "o", "        return self._wrap_reduction_result(axis, result)\r\n"]
[206.181213, "o", "\r\n"]
[206.221738, "o", "    def skew(\r\n"]
[206.262262, "o", "        self,\r\n"]
[206.302787, "o", "        *,\r\n"]
[206.343311, "o", "        axis: AxisInt | None = None,\r\n"]
[206.383836, "o", "        dtype: NpDtype | None = None,\r\n"]
[206.424361, "o", "        out=None,\r\n"]
[206.464885, "o", "        keepdims: bool = False,\r\n"]
[206.50541, "o", "        skipna: bool = True,\r\n"]
[206.545934, "o", "    ):\r\n"]
[206.586459, "o", "        nv.validate_stat_ddof_func(\r\n"]
[206.626984, "o", "            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"skew\"\r\n"]
[206.667508, "o", "        )\r\n"]
[206.708033, "o", "        result = nanops.nanskew(self._ndarray, axis=axis, skipna=skipna)\r\n"]
[206.748557, "o", "        return self._wrap_reduction_result(axis, result)\r\n"]
[206.789082, "o", "\r\n"]
[206.829607, "o", "    # ------------------------------------------------------------------------\r\n"]
[206.870131, "o", "    # Additional Methods\r\n"]
[206.910656, "o", "\r\n"]
[206.95118, "o", "    def to_numpy(\r\n"]
[206.991705, "o", "        self,\r\n"]
[207.03223, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[207.072754, "o", "        copy: bool = False,\r\n"]
[207.113279, "o", "        na_value: object = lib.no_default,\r\n"]
[207.153803, "o", "    ) -> np.ndarray:\r\n"]
[207.194328, "o", "        mask = self.isna()\r\n"]
[207.234852, "o", "        if na_value is not lib.no_default and mask.any():\r\n"]
[207.275377, "o", "            result = self._ndarray.copy()\r\n"]
[207.315902, "o", "            result[mask] = na_value\r\n"]
[207.356426, "o", "        else:\r\n"]
[207.396951, "o", "            result = self._ndarray\r\n"]
[207.437475, "o", "\r\n"]
[207.478, "o", "        result = np.asarray(result, dtype=dtype)\r\n"]
[207.518525, "o", "\r\n"]
[207.559049, "o", "        if copy and result is self._ndarray:\r\n"]
[207.599574, "o", "            result = result.copy()\r\n"]
[207.640098, "o", "\r\n"]
[207.680623, "o", "        return result\r\n"]
[207.721148, "o", "\r\n"]
[207.761672, "o", "    # ------------------------------------------------------------------------\r\n"]
[207.802197, "o", "    # Ops\r\n"]
[207.842721, "o", "\r\n"]
[207.883246, "o", "    def __invert__(self) -> PandasArray:\r\n"]
[207.92377, "o", "        return type(self)(~self._ndarray)\r\n"]
[207.964295, "o", "\r\n"]
[208.00482, "o", "    def __neg__(self) -> PandasArray:\r\n"]
[208.045344, "o", "        return type(self)(-self._ndarray)\r\n"]
[208.085869, "o", "\r\n"]
[208.126393, "o", "    def __pos__(self) -> PandasArray:\r\n"]
[208.166918, "o", "        return type(self)(+self._ndarray)\r\n"]
[208.207443, "o", "\r\n"]
[208.247967, "o", "    def __abs__(self) -> PandasArray:\r\n"]
[208.288492, "o", "        return type(self)(abs(self._ndarray))\r\n"]
[208.329016, "o", "\r\n"]
[208.369541, "o", "    def _cmp_method(self, other, op):\r\n"]
[208.410066, "o", "        if isinstance(other, PandasArray):\r\n"]
[208.45059, "o", "            other = other._ndarray\r\n"]
[208.491115, "o", "\r\n"]
[208.531639, "o", "        other = ops.maybe_prepare_scalar_for_op(other, (len(self),))\r\n"]
[208.572164, "o", "        pd_op = ops.get_array_op(op)\r\n"]
[208.612689, "o", "        other = ensure_wrapped_if_datetimelike(other)\r\n"]
[208.653213, "o", "        with np.errstate(all=\"ignore\"):\r\n"]
[208.693738, "o", "            result = pd_op(self._ndarray, other)\r\n"]
[208.734262, "o", "\r\n"]
[208.774787, "o", "        if op is divmod or op is ops.rdivmod:\r\n"]
[208.815311, "o", "            a, b = result\r\n"]
[208.855836, "o", "            if isinstance(a, np.ndarray):\r\n"]
[208.896361, "o", "                # for e.g. op vs TimedeltaArray, we may already\r\n"]
[208.936885, "o", "                #  have an ExtensionArray, in which case we do not wrap\r\n"]
[208.97741, "o", "                return self._wrap_ndarray_result(a), self._wrap_ndarray_result(b)\r\n"]
[209.017934, "o", "            return a, b\r\n"]
[209.058459, "o", "\r\n"]
[209.098984, "o", "        if isinstance(result, np.ndarray):\r\n"]
[209.139508, "o", "            # for e.g. multiplication vs TimedeltaArray, we may already\r\n"]
[209.180033, "o", "            #  have an ExtensionArray, in which case we do not wrap\r\n"]
[209.220557, "o", "            return self._wrap_ndarray_result(result)\r\n"]
[209.261082, "o", "        return result\r\n"]
[209.301607, "o", "\r\n"]
[209.342131, "o", "    _arith_method = _cmp_method\r\n"]
[209.382656, "o", "\r\n"]
[209.42318, "o", "    def _wrap_ndarray_result(self, result: np.ndarray):\r\n"]
[209.463705, "o", "        # If we have timedelta64[ns] result, return a TimedeltaArray instead\r\n"]
[209.50423, "o", "        #  of a PandasArray\r\n"]
[209.544754, "o", "        if result.dtype.kind == \"m\" and is_supported_unit(\r\n"]
[209.585279, "o", "            get_unit_from_dtype(result.dtype)\r\n"]
[209.625803, "o", "        ):\r\n"]
[209.666328, "o", "            from pandas.core.arrays import TimedeltaArray\r\n"]
[209.706852, "o", "\r\n"]
[209.747377, "o", "            return TimedeltaArray._simple_new(result, dtype=result.dtype)\r\n"]
[209.787902, "o", "        return type(self)(result)\r\n"]
[209.828426, "o", "\r\n"]
[209.868951, "o", "    # ------------------------------------------------------------------------\r\n"]
[209.909475, "o", "    # String methods interface\r\n"]
[210.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[210.002, "i", "sed -n '420,520p' pandas/core/base.py\r"]
[210.004, "o", "sed -n '420,520p' pandas/core/base.py\r\n"]
[210.054471, "o", "\u001b[?2004l\r\n"]
[210.102941, "o", "        Categories (2, object): ['a', 'b']\r\n"]
[210.151412, "o", "        \"\"\"\r\n"]
[210.199882, "o", "        raise AbstractMethodError(self)\r\n"]
[210.248353, "o", "\r\n"]
[210.296824, "o", "    @final\r\n"]
[210.345294, "o", "    def to_numpy(\r\n"]
[210.393765, "o", "        self,\r\n"]
[210.442235, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[210.490706, "o", "        copy: bool = False,\r\n"]
[210.539176, "o", "        na_value: object = lib.no_default,\r\n"]
[210.587647, "o", "        **kwargs,\r\n"]
[210.636118, "o", "    ) -> np.ndarray:\r\n"]
[210.684588, "o", "        \"\"\"\r\n"]
[210.733059, "o", "        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[210.781529, "o", "\r\n"]
[210.83, "o", "        Parameters\r\n"]
[210.878471, "o", "        ----------\r\n"]
[210.926941, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[210.975412, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[211.023882, "o", "        copy : bool, default False\r\n"]
[211.072353, "o", "            Whether to ensure that the returned value is not a view on\r\n"]
[211.120824, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[211.169294, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[211.217765, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[211.266235, "o", "        na_value : Any, optional\r\n"]
[211.314706, "o", "            The value to use for missing values. The default value depends\r\n"]
[211.363176, "o", "            on `dtype` and the type of the array.\r\n"]
[211.411647, "o", "\r\n"]
[211.460118, "o", "            .. versionadded:: 1.0.0\r\n"]
[211.508588, "o", "\r\n"]
[211.557059, "o", "        **kwargs\r\n"]
[211.605529, "o", "            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[211.654, "o", "            of the underlying array (for extension arrays).\r\n"]
[211.702471, "o", "\r\n"]
[211.750941, "o", "            .. versionadded:: 1.0.0\r\n"]
[211.799412, "o", "\r\n"]
[211.847882, "o", "        Returns\r\n"]
[211.896353, "o", "        -------\r\n"]
[211.944824, "o", "        numpy.ndarray\r\n"]
[211.993294, "o", "\r\n"]
[212.041765, "o", "        See Also\r\n"]
[212.090235, "o", "        --------\r\n"]
[212.138706, "o", "        Series.array : Get the actual data stored within.\r\n"]
[212.187176, "o", "        Index.array : Get the actual data stored within.\r\n"]
[212.235647, "o", "        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[212.284118, "o", "\r\n"]
[212.332588, "o", "        Notes\r\n"]
[212.381059, "o", "        -----\r\n"]
[212.429529, "o", "        The returned array will be the same up to equality (values equal\r\n"]
[212.478, "o", "        in `self` will be equal in the returned array; likewise for values\r\n"]
[212.526471, "o", "        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[212.574941, "o", "        dtype may be different. For example, for a category-dtype Series,\r\n"]
[212.623412, "o", "        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[212.671882, "o", "        will be lost.\r\n"]
[212.720353, "o", "\r\n"]
[212.768824, "o", "        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[212.817294, "o", "        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[212.865765, "o", "        in place will modify the data stored in the Series or Index (not that\r\n"]
[212.914235, "o", "        we recommend doing that).\r\n"]
[212.962706, "o", "\r\n"]
[213.011176, "o", "        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[213.059647, "o", "        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[213.108118, "o", "        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[213.156588, "o", "        :attr:`Series.array` should be used instead.\r\n"]
[213.205059, "o", "\r\n"]
[213.253529, "o", "        This table lays out the different dtypes and default return types of\r\n"]
[213.302, "o", "        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[213.350471, "o", "\r\n"]
[213.398941, "o", "        ================== ================================\r\n"]
[213.447412, "o", "        dtype              array type\r\n"]
[213.495882, "o", "        ================== ================================\r\n"]
[213.544353, "o", "        category[T]        ndarray[T] (same dtype as input)\r\n"]
[213.592824, "o", "        period             ndarray[object] (Periods)\r\n"]
[213.641294, "o", "        interval           ndarray[object] (Intervals)\r\n"]
[213.689765, "o", "        IntegerNA          ndarray[object]\r\n"]
[213.738235, "o", "        datetime64[ns]     datetime64[ns]\r\n"]
[213.786706, "o", "        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[213.835176, "o", "        ================== ================================\r\n"]
[213.883647, "o", "\r\n"]
[213.932118, "o", "        Examples\r\n"]
[213.980588, "o", "        --------\r\n"]
[214.029059, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[214.077529, "o", "        >>> ser.to_numpy()\r\n"]
[214.126, "o", "        array(['a', 'b', 'a'], dtype=object)\r\n"]
[214.174471, "o", "\r\n"]
[214.222941, "o", "        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[214.271412, "o", "        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[214.319882, "o", "        objects, each with the correct ``tz``.\r\n"]
[214.368353, "o", "\r\n"]
[214.416824, "o", "        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[214.465294, "o", "        >>> ser.to_numpy(dtype=object)\r\n"]
[214.513765, "o", "        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[214.562235, "o", "               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[214.610706, "o", "              dtype=object)\r\n"]
[214.659176, "o", "\r\n"]
[214.707647, "o", "        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[214.756118, "o", "        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[214.804588, "o", "        info is dropped.\r\n"]
[214.853059, "o", "\r\n"]
[214.901529, "o", "        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[215.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[215.002, "i", "sed -n '520,680p' pandas/core/base.py\r"]
[215.004, "o", "sed -n '520,680p' pandas/core/base.py\r\n"]
[215.036519, "o", "\u001b[?2004l\r\n"]
[215.067037, "o", "        ... # doctest: +ELLIPSIS\r\n"]
[215.097556, "o", "        array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\r\n"]
[215.128074, "o", "              dtype='datetime64[ns]')\r\n"]
[215.158593, "o", "        \"\"\"\r\n"]
[215.189111, "o", "        if is_extension_array_dtype(self.dtype):\r\n"]
[215.21963, "o", "            return self.array.to_numpy(dtype, copy=copy, na_value=na_value, **kwargs)\r\n"]
[215.250148, "o", "        elif kwargs:\r\n"]
[215.280667, "o", "            bad_keys = list(kwargs.keys())[0]\r\n"]
[215.311185, "o", "            raise TypeError(\r\n"]
[215.341704, "o", "                f\"to_numpy() got an unexpected keyword argument '{bad_keys}'\"\r\n"]
[215.372222, "o", "            )\r\n"]
[215.402741, "o", "\r\n"]
[215.433259, "o", "        if na_value is not lib.no_default:\r\n"]
[215.463778, "o", "            values = self._values\r\n"]
[215.494296, "o", "            if not can_hold_element(values, na_value):\r\n"]
[215.524815, "o", "                # if we can't hold the na_value asarray either makes a copy or we\r\n"]
[215.555333, "o", "                # error before modifying values. The asarray later on thus won't make\r\n"]
[215.585852, "o", "                # another copy\r\n"]
[215.61637, "o", "                values = np.asarray(values, dtype=dtype)\r\n"]
[215.646889, "o", "            else:\r\n"]
[215.677407, "o", "                values = values.copy()\r\n"]
[215.707926, "o", "\r\n"]
[215.738444, "o", "            values[np.asanyarray(self.isna())] = na_value\r\n"]
[215.768963, "o", "        else:\r\n"]
[215.799481, "o", "            values = self._values\r\n"]
[215.83, "o", "\r\n"]
[215.860519, "o", "        result = np.asarray(values, dtype=dtype)\r\n"]
[215.891037, "o", "\r\n"]
[215.921556, "o", "        if copy and na_value is lib.no_default:\r\n"]
[215.952074, "o", "            if np.shares_memory(self._values[:2], result[:2]):\r\n"]
[215.982593, "o", "                # Take slices to improve performance of check\r\n"]
[216.013111, "o", "                result = result.copy()\r\n"]
[216.04363, "o", "\r\n"]
[216.074148, "o", "        return result\r\n"]
[216.104667, "o", "\r\n"]
[216.135185, "o", "    @final\r\n"]
[216.165704, "o", "    @property\r\n"]
[216.196222, "o", "    def empty(self) -> bool:\r\n"]
[216.226741, "o", "        return not self.size\r\n"]
[216.257259, "o", "\r\n"]
[216.287778, "o", "    def max(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[216.318296, "o", "        \"\"\"\r\n"]
[216.348815, "o", "        Return the maximum value of the Index.\r\n"]
[216.379333, "o", "\r\n"]
[216.409852, "o", "        Parameters\r\n"]
[216.44037, "o", "        ----------\r\n"]
[216.470889, "o", "        axis : int, optional\r\n"]
[216.501407, "o", "            For compatibility with NumPy. Only 0 or None are allowed.\r\n"]
[216.531926, "o", "        skipna : bool, default True\r\n"]
[216.562444, "o", "            Exclude NA/null values when showing the result.\r\n"]
[216.592963, "o", "        *args, **kwargs\r\n"]
[216.623481, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[216.654, "o", "\r\n"]
[216.684519, "o", "        Returns\r\n"]
[216.715037, "o", "        -------\r\n"]
[216.745556, "o", "        scalar\r\n"]
[216.776074, "o", "            Maximum value.\r\n"]
[216.806593, "o", "\r\n"]
[216.837111, "o", "        See Also\r\n"]
[216.86763, "o", "        --------\r\n"]
[216.898148, "o", "        Index.min : Return the minimum value in an Index.\r\n"]
[216.928667, "o", "        Series.max : Return the maximum value in a Series.\r\n"]
[216.959185, "o", "        DataFrame.max : Return the maximum values in a DataFrame.\r\n"]
[216.989704, "o", "\r\n"]
[217.020222, "o", "        Examples\r\n"]
[217.050741, "o", "        --------\r\n"]
[217.081259, "o", "        >>> idx = pd.Index([3, 2, 1])\r\n"]
[217.111778, "o", "        >>> idx.max()\r\n"]
[217.142296, "o", "        3\r\n"]
[217.172815, "o", "\r\n"]
[217.203333, "o", "        >>> idx = pd.Index(['c', 'b', 'a'])\r\n"]
[217.233852, "o", "        >>> idx.max()\r\n"]
[217.26437, "o", "        'c'\r\n"]
[217.294889, "o", "\r\n"]
[217.325407, "o", "        For a MultiIndex, the maximum is determined lexicographically.\r\n"]
[217.355926, "o", "\r\n"]
[217.386444, "o", "        >>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])\r\n"]
[217.416963, "o", "        >>> idx.max()\r\n"]
[217.447481, "o", "        ('b', 2)\r\n"]
[217.478, "o", "        \"\"\"\r\n"]
[217.508519, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[217.539037, "o", "        nv.validate_max(args, kwargs)\r\n"]
[217.569556, "o", "        return nanops.nanmax(self._values, skipna=skipna)\r\n"]
[217.600074, "o", "\r\n"]
[217.630593, "o", "    @doc(op=\"max\", oppose=\"min\", value=\"largest\")\r\n"]
[217.661111, "o", "    def argmax(\r\n"]
[217.69163, "o", "        self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs\r\n"]
[217.722148, "o", "    ) -> int:\r\n"]
[217.752667, "o", "        \"\"\"\r\n"]
[217.783185, "o", "        Return int position of the {value} value in the Series.\r\n"]
[217.813704, "o", "\r\n"]
[217.844222, "o", "        If the {op}imum is achieved in multiple locations,\r\n"]
[217.874741, "o", "        the first row position is returned.\r\n"]
[217.905259, "o", "\r\n"]
[217.935778, "o", "        Parameters\r\n"]
[217.966296, "o", "        ----------\r\n"]
[217.996815, "o", "        axis : {{None}}\r\n"]
[218.027333, "o", "            Unused. Parameter needed for compatibility with DataFrame.\r\n"]
[218.057852, "o", "        skipna : bool, default True\r\n"]
[218.08837, "o", "            Exclude NA/null values when showing the result.\r\n"]
[218.118889, "o", "        *args, **kwargs\r\n"]
[218.149407, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[218.179926, "o", "\r\n"]
[218.210444, "o", "        Returns\r\n"]
[218.240963, "o", "        -------\r\n"]
[218.271481, "o", "        int\r\n"]
[218.302, "o", "            Row position of the {op}imum value.\r\n"]
[218.332519, "o", "\r\n"]
[218.363037, "o", "        See Also\r\n"]
[218.393556, "o", "        --------\r\n"]
[218.424074, "o", "        Series.arg{op} : Return position of the {op}imum value.\r\n"]
[218.454593, "o", "        Series.arg{oppose} : Return position of the {oppose}imum value.\r\n"]
[218.485111, "o", "        numpy.ndarray.arg{op} : Equivalent method for numpy arrays.\r\n"]
[218.51563, "o", "        Series.idxmax : Return index label of the maximum values.\r\n"]
[218.546148, "o", "        Series.idxmin : Return index label of the minimum values.\r\n"]
[218.576667, "o", "\r\n"]
[218.607185, "o", "        Examples\r\n"]
[218.637704, "o", "        --------\r\n"]
[218.668222, "o", "        Consider dataset containing cereal calories\r\n"]
[218.698741, "o", "\r\n"]
[218.729259, "o", "        >>> s = pd.Series({{'Corn Flakes': 100.0, 'Almond Delight': 110.0,\r\n"]
[218.759778, "o", "        ...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0}})\r\n"]
[218.790296, "o", "        >>> s\r\n"]
[218.820815, "o", "        Corn Flakes              100.0\r\n"]
[218.851333, "o", "        Almond Delight           110.0\r\n"]
[218.881852, "o", "        Cinnamon Toast Crunch    120.0\r\n"]
[218.91237, "o", "        Cocoa Puff               110.0\r\n"]
[218.942889, "o", "        dtype: float64\r\n"]
[218.973407, "o", "\r\n"]
[219.003926, "o", "        >>> s.argmax()\r\n"]
[219.034444, "o", "        2\r\n"]
[219.064963, "o", "        >>> s.argmin()\r\n"]
[219.095481, "o", "        0\r\n"]
[219.126, "o", "\r\n"]
[219.156519, "o", "        The maximum cereal calories is the third element and\r\n"]
[219.187037, "o", "        the minimum cereal calories is the first element,\r\n"]
[219.217556, "o", "        since series is zero-indexed.\r\n"]
[219.248074, "o", "        \"\"\"\r\n"]
[219.278593, "o", "        delegate = self._values\r\n"]
[219.309111, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[219.33963, "o", "        skipna = nv.validate_argmax_with_skipna(skipna, args, kwargs)\r\n"]
[219.370148, "o", "\r\n"]
[219.400667, "o", "        if isinstance(delegate, ExtensionArray):\r\n"]
[219.431185, "o", "            if not skipna and delegate.isna().any():\r\n"]
[219.461704, "o", "                return -1\r\n"]
[219.492222, "o", "            else:\r\n"]
[219.522741, "o", "                return delegate.argmax()\r\n"]
[219.553259, "o", "        else:\r\n"]
[219.583778, "o", "            # error: Incompatible return value type (got \"Union[int, ndarray]\", expected\r\n"]
[219.614296, "o", "            # \"int\")\r\n"]
[219.644815, "o", "            return nanops.nanargmax(  # type: ignore[return-value]\r\n"]
[219.675333, "o", "                delegate, skipna=skipna\r\n"]
[219.705852, "o", "            )\r\n"]
[219.73637, "o", "\r\n"]
[219.766889, "o", "    def min(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[219.797407, "o", "        \"\"\"\r\n"]
[219.827926, "o", "        Return the minimum value of the Index.\r\n"]
[219.858444, "o", "\r\n"]
[219.888963, "o", "        Parameters\r\n"]
[219.919481, "o", "        ----------\r\n"]
[220.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[220.002, "i", "sed -n '360,520p' pandas/core/arrays/base.py\r"]
[220.004, "o", "sed -n '360,520p' pandas/core/arrays/base.py\r\n"]
[220.036519, "o", "\u001b[?2004l\r\n"]
[220.067037, "o", "        Parameters\r\n"]
[220.097556, "o", "        ----------\r\n"]
[220.128074, "o", "        key : int, ndarray, or slice\r\n"]
[220.158593, "o", "            When called from, e.g. ``Series.__setitem__``, ``key`` will be\r\n"]
[220.189111, "o", "            one of\r\n"]
[220.21963, "o", "\r\n"]
[220.250148, "o", "            * scalar int\r\n"]
[220.280667, "o", "            * ndarray of integers.\r\n"]
[220.311185, "o", "            * boolean ndarray\r\n"]
[220.341704, "o", "            * slice object\r\n"]
[220.372222, "o", "\r\n"]
[220.402741, "o", "        value : ExtensionDtype.type, Sequence[ExtensionDtype.type], or object\r\n"]
[220.433259, "o", "            value or values to be set of ``key``.\r\n"]
[220.463778, "o", "\r\n"]
[220.494296, "o", "        Returns\r\n"]
[220.524815, "o", "        -------\r\n"]
[220.555333, "o", "        None\r\n"]
[220.585852, "o", "        \"\"\"\r\n"]
[220.61637, "o", "        # Some notes to the ExtensionArray implementor who may have ended up\r\n"]
[220.646889, "o", "        # here. While this method is not required for the interface, if you\r\n"]
[220.677407, "o", "        # *do* choose to implement __setitem__, then some semantics should be\r\n"]
[220.707926, "o", "        # observed:\r\n"]
[220.738444, "o", "        #\r\n"]
[220.768963, "o", "        # * Setting multiple values : ExtensionArrays should support setting\r\n"]
[220.799481, "o", "        #   multiple values at once, 'key' will be a sequence of integers and\r\n"]
[220.83, "o", "        #  'value' will be a same-length sequence.\r\n"]
[220.860519, "o", "        #\r\n"]
[220.891037, "o", "        # * Broadcasting : For a sequence 'key' and a scalar 'value',\r\n"]
[220.921556, "o", "        #   each position in 'key' should be set to 'value'.\r\n"]
[220.952074, "o", "        #\r\n"]
[220.982593, "o", "        # * Coercion : Most users will expect basic coercion to work. For\r\n"]
[221.013111, "o", "        #   example, a string like '2018-01-01' is coerced to a datetime\r\n"]
[221.04363, "o", "        #   when setting on a datetime64ns array. In general, if the\r\n"]
[221.074148, "o", "        #   __init__ method coerces that value, then so should __setitem__\r\n"]
[221.104667, "o", "        # Note, also, that Series/DataFrame.where internally use __setitem__\r\n"]
[221.135185, "o", "        # on a copy of the data.\r\n"]
[221.165704, "o", "        raise NotImplementedError(f\"{type(self)} does not implement __setitem__.\")\r\n"]
[221.196222, "o", "\r\n"]
[221.226741, "o", "    def __len__(self) -> int:\r\n"]
[221.257259, "o", "        \"\"\"\r\n"]
[221.287778, "o", "        Length of this array\r\n"]
[221.318296, "o", "\r\n"]
[221.348815, "o", "        Returns\r\n"]
[221.379333, "o", "        -------\r\n"]
[221.409852, "o", "        length : int\r\n"]
[221.44037, "o", "        \"\"\"\r\n"]
[221.470889, "o", "        raise AbstractMethodError(self)\r\n"]
[221.501407, "o", "\r\n"]
[221.531926, "o", "    def __iter__(self) -> Iterator[Any]:\r\n"]
[221.562444, "o", "        \"\"\"\r\n"]
[221.592963, "o", "        Iterate over elements of the array.\r\n"]
[221.623481, "o", "        \"\"\"\r\n"]
[221.654, "o", "        # This needs to be implemented so that pandas recognizes extension\r\n"]
[221.684519, "o", "        # arrays as list-like. The default implementation makes successive\r\n"]
[221.715037, "o", "        # calls to ``__getitem__``, which may be slower than necessary.\r\n"]
[221.745556, "o", "        for i in range(len(self)):\r\n"]
[221.776074, "o", "            yield self[i]\r\n"]
[221.806593, "o", "\r\n"]
[221.837111, "o", "    def __contains__(self, item: object) -> bool | np.bool_:\r\n"]
[221.86763, "o", "        \"\"\"\r\n"]
[221.898148, "o", "        Return for `item in self`.\r\n"]
[221.928667, "o", "        \"\"\"\r\n"]
[221.959185, "o", "        # GH37867\r\n"]
[221.989704, "o", "        # comparisons of any item to pd.NA always return pd.NA, so e.g. \"a\" in [pd.NA]\r\n"]
[222.020222, "o", "        # would raise a TypeError. The implementation below works around that.\r\n"]
[222.050741, "o", "        if is_scalar(item) and isna(item):\r\n"]
[222.081259, "o", "            if not self._can_hold_na:\r\n"]
[222.111778, "o", "                return False\r\n"]
[222.142296, "o", "            elif item is self.dtype.na_value or isinstance(item, self.dtype.type):\r\n"]
[222.172815, "o", "                return self._hasna\r\n"]
[222.203333, "o", "            else:\r\n"]
[222.233852, "o", "                return False\r\n"]
[222.26437, "o", "        else:\r\n"]
[222.294889, "o", "            # error: Item \"ExtensionArray\" of \"Union[ExtensionArray, ndarray]\" has no\r\n"]
[222.325407, "o", "            # attribute \"any\"\r\n"]
[222.355926, "o", "            return (item == self).any()  # type: ignore[union-attr]\r\n"]
[222.386444, "o", "\r\n"]
[222.416963, "o", "    # error: Signature of \"__eq__\" incompatible with supertype \"object\"\r\n"]
[222.447481, "o", "    def __eq__(self, other: Any) -> ArrayLike:  # type: ignore[override]\r\n"]
[222.478, "o", "        \"\"\"\r\n"]
[222.508519, "o", "        Return for `self == other` (element-wise equality).\r\n"]
[222.539037, "o", "        \"\"\"\r\n"]
[222.569556, "o", "        # Implementer note: this should return a boolean numpy ndarray or\r\n"]
[222.600074, "o", "        # a boolean ExtensionArray.\r\n"]
[222.630593, "o", "        # When `other` is one of Series, Index, or DataFrame, this method should\r\n"]
[222.661111, "o", "        # return NotImplemented (to ensure that those objects are responsible for\r\n"]
[222.69163, "o", "        # first unpacking the arrays, and then dispatch the operation to the\r\n"]
[222.722148, "o", "        # underlying arrays)\r\n"]
[222.752667, "o", "        raise AbstractMethodError(self)\r\n"]
[222.783185, "o", "\r\n"]
[222.813704, "o", "    # error: Signature of \"__ne__\" incompatible with supertype \"object\"\r\n"]
[222.844222, "o", "    def __ne__(self, other: Any) -> ArrayLike:  # type: ignore[override]\r\n"]
[222.874741, "o", "        \"\"\"\r\n"]
[222.905259, "o", "        Return for `self != other` (element-wise in-equality).\r\n"]
[222.935778, "o", "        \"\"\"\r\n"]
[222.966296, "o", "        return ~(self == other)\r\n"]
[222.996815, "o", "\r\n"]
[223.027333, "o", "    def to_numpy(\r\n"]
[223.057852, "o", "        self,\r\n"]
[223.08837, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[223.118889, "o", "        copy: bool = False,\r\n"]
[223.149407, "o", "        na_value: object = lib.no_default,\r\n"]
[223.179926, "o", "    ) -> np.ndarray:\r\n"]
[223.210444, "o", "        \"\"\"\r\n"]
[223.240963, "o", "        Convert to a NumPy ndarray.\r\n"]
[223.271481, "o", "\r\n"]
[223.302, "o", "        .. versionadded:: 1.0.0\r\n"]
[223.332519, "o", "\r\n"]
[223.363037, "o", "        This is similar to :meth:`numpy.asarray`, but may provide additional control\r\n"]
[223.393556, "o", "        over how the conversion is done.\r\n"]
[223.424074, "o", "\r\n"]
[223.454593, "o", "        Parameters\r\n"]
[223.485111, "o", "        ----------\r\n"]
[223.51563, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[223.546148, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[223.576667, "o", "        copy : bool, default False\r\n"]
[223.607185, "o", "            Whether to ensure that the returned value is a not a view on\r\n"]
[223.637704, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[223.668222, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[223.698741, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[223.729259, "o", "        na_value : Any, optional\r\n"]
[223.759778, "o", "            The value to use for missing values. The default value depends\r\n"]
[223.790296, "o", "            on `dtype` and the type of the array.\r\n"]
[223.820815, "o", "\r\n"]
[223.851333, "o", "        Returns\r\n"]
[223.881852, "o", "        -------\r\n"]
[223.91237, "o", "        numpy.ndarray\r\n"]
[223.942889, "o", "        \"\"\"\r\n"]
[223.973407, "o", "        result = np.asarray(self, dtype=dtype)\r\n"]
[224.003926, "o", "        if copy or na_value is not lib.no_default:\r\n"]
[224.034444, "o", "            result = result.copy()\r\n"]
[224.064963, "o", "        if na_value is not lib.no_default:\r\n"]
[224.095481, "o", "            result[self.isna()] = na_value\r\n"]
[224.126, "o", "        return result\r\n"]
[224.156519, "o", "\r\n"]
[224.187037, "o", "    # ------------------------------------------------------------------------\r\n"]
[224.217556, "o", "    # Required attributes\r\n"]
[224.248074, "o", "    # ------------------------------------------------------------------------\r\n"]
[224.278593, "o", "\r\n"]
[224.309111, "o", "    @property\r\n"]
[224.33963, "o", "    def dtype(self) -> ExtensionDtype:\r\n"]
[224.370148, "o", "        \"\"\"\r\n"]
[224.400667, "o", "        An instance of 'ExtensionDtype'.\r\n"]
[224.431185, "o", "        \"\"\"\r\n"]
[224.461704, "o", "        raise AbstractMethodError(self)\r\n"]
[224.492222, "o", "\r\n"]
[224.522741, "o", "    @property\r\n"]
[224.553259, "o", "    def shape(self) -> Shape:\r\n"]
[224.583778, "o", "        \"\"\"\r\n"]
[224.614296, "o", "        Return a tuple of the array dimensions.\r\n"]
[224.644815, "o", "        \"\"\"\r\n"]
[224.675333, "o", "        return (len(self),)\r\n"]
[224.705852, "o", "\r\n"]
[224.73637, "o", "    @property\r\n"]
[224.766889, "o", "    def size(self) -> int:\r\n"]
[224.797407, "o", "        \"\"\"\r\n"]
[224.827926, "o", "        The number of elements in the array.\r\n"]
[224.858444, "o", "        \"\"\"\r\n"]
[224.888963, "o", "        # error: Incompatible return value type (got \"signedinteger[_64Bit]\",\r\n"]
[224.919481, "o", "        # expected \"int\")  [return-value]\r\n"]
[225.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[225.002, "i", "sed -n '360,460p' pandas/core/arrays/numpy_.py\r"]
[225.004, "o", "sed -n '360,460p' pandas/core/arrays/numpy_.py\r\n"]
[225.054471, "o", "\u001b[?2004l\r\n"]
[225.102941, "o", "        skipna: bool = True,\r\n"]
[225.151412, "o", "    ):\r\n"]
[225.199882, "o", "        nv.validate_stat_ddof_func(\r\n"]
[225.248353, "o", "            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"kurt\"\r\n"]
[225.296824, "o", "        )\r\n"]
[225.345294, "o", "        result = nanops.nankurt(self._ndarray, axis=axis, skipna=skipna)\r\n"]
[225.393765, "o", "        return self._wrap_reduction_result(axis, result)\r\n"]
[225.442235, "o", "\r\n"]
[225.490706, "o", "    def skew(\r\n"]
[225.539176, "o", "        self,\r\n"]
[225.587647, "o", "        *,\r\n"]
[225.636118, "o", "        axis: AxisInt | None = None,\r\n"]
[225.684588, "o", "        dtype: NpDtype | None = None,\r\n"]
[225.733059, "o", "        out=None,\r\n"]
[225.781529, "o", "        keepdims: bool = False,\r\n"]
[225.83, "o", "        skipna: bool = True,\r\n"]
[225.878471, "o", "    ):\r\n"]
[225.926941, "o", "        nv.validate_stat_ddof_func(\r\n"]
[225.975412, "o", "            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"skew\"\r\n"]
[226.023882, "o", "        )\r\n"]
[226.072353, "o", "        result = nanops.nanskew(self._ndarray, axis=axis, skipna=skipna)\r\n"]
[226.120824, "o", "        return self._wrap_reduction_result(axis, result)\r\n"]
[226.169294, "o", "\r\n"]
[226.217765, "o", "    # ------------------------------------------------------------------------\r\n"]
[226.266235, "o", "    # Additional Methods\r\n"]
[226.314706, "o", "\r\n"]
[226.363176, "o", "    def to_numpy(\r\n"]
[226.411647, "o", "        self,\r\n"]
[226.460118, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[226.508588, "o", "        copy: bool = False,\r\n"]
[226.557059, "o", "        na_value: object = lib.no_default,\r\n"]
[226.605529, "o", "    ) -> np.ndarray:\r\n"]
[226.654, "o", "        mask = self.isna()\r\n"]
[226.702471, "o", "        if na_value is not lib.no_default and mask.any():\r\n"]
[226.750941, "o", "            result = self._ndarray.copy()\r\n"]
[226.799412, "o", "            result[mask] = na_value\r\n"]
[226.847882, "o", "        else:\r\n"]
[226.896353, "o", "            result = self._ndarray\r\n"]
[226.944824, "o", "\r\n"]
[226.993294, "o", "        result = np.asarray(result, dtype=dtype)\r\n"]
[227.041765, "o", "\r\n"]
[227.090235, "o", "        if copy and result is self._ndarray:\r\n"]
[227.138706, "o", "            result = result.copy()\r\n"]
[227.187176, "o", "\r\n"]
[227.235647, "o", "        return result\r\n"]
[227.284118, "o", "\r\n"]
[227.332588, "o", "    # ------------------------------------------------------------------------\r\n"]
[227.381059, "o", "    # Ops\r\n"]
[227.429529, "o", "\r\n"]
[227.478, "o", "    def __invert__(self) -> PandasArray:\r\n"]
[227.526471, "o", "        return type(self)(~self._ndarray)\r\n"]
[227.574941, "o", "\r\n"]
[227.623412, "o", "    def __neg__(self) -> PandasArray:\r\n"]
[227.671882, "o", "        return type(self)(-self._ndarray)\r\n"]
[227.720353, "o", "\r\n"]
[227.768824, "o", "    def __pos__(self) -> PandasArray:\r\n"]
[227.817294, "o", "        return type(self)(+self._ndarray)\r\n"]
[227.865765, "o", "\r\n"]
[227.914235, "o", "    def __abs__(self) -> PandasArray:\r\n"]
[227.962706, "o", "        return type(self)(abs(self._ndarray))\r\n"]
[228.011176, "o", "\r\n"]
[228.059647, "o", "    def _cmp_method(self, other, op):\r\n"]
[228.108118, "o", "        if isinstance(other, PandasArray):\r\n"]
[228.156588, "o", "            other = other._ndarray\r\n"]
[228.205059, "o", "\r\n"]
[228.253529, "o", "        other = ops.maybe_prepare_scalar_for_op(other, (len(self),))\r\n"]
[228.302, "o", "        pd_op = ops.get_array_op(op)\r\n"]
[228.350471, "o", "        other = ensure_wrapped_if_datetimelike(other)\r\n"]
[228.398941, "o", "        with np.errstate(all=\"ignore\"):\r\n"]
[228.447412, "o", "            result = pd_op(self._ndarray, other)\r\n"]
[228.495882, "o", "\r\n"]
[228.544353, "o", "        if op is divmod or op is ops.rdivmod:\r\n"]
[228.592824, "o", "            a, b = result\r\n"]
[228.641294, "o", "            if isinstance(a, np.ndarray):\r\n"]
[228.689765, "o", "                # for e.g. op vs TimedeltaArray, we may already\r\n"]
[228.738235, "o", "                #  have an ExtensionArray, in which case we do not wrap\r\n"]
[228.786706, "o", "                return self._wrap_ndarray_result(a), self._wrap_ndarray_result(b)\r\n"]
[228.835176, "o", "            return a, b\r\n"]
[228.883647, "o", "\r\n"]
[228.932118, "o", "        if isinstance(result, np.ndarray):\r\n"]
[228.980588, "o", "            # for e.g. multiplication vs TimedeltaArray, we may already\r\n"]
[229.029059, "o", "            #  have an ExtensionArray, in which case we do not wrap\r\n"]
[229.077529, "o", "            return self._wrap_ndarray_result(result)\r\n"]
[229.126, "o", "        return result\r\n"]
[229.174471, "o", "\r\n"]
[229.222941, "o", "    _arith_method = _cmp_method\r\n"]
[229.271412, "o", "\r\n"]
[229.319882, "o", "    def _wrap_ndarray_result(self, result: np.ndarray):\r\n"]
[229.368353, "o", "        # If we have timedelta64[ns] result, return a TimedeltaArray instead\r\n"]
[229.416824, "o", "        #  of a PandasArray\r\n"]
[229.465294, "o", "        if result.dtype.kind == \"m\" and is_supported_unit(\r\n"]
[229.513765, "o", "            get_unit_from_dtype(result.dtype)\r\n"]
[229.562235, "o", "        ):\r\n"]
[229.610706, "o", "            from pandas.core.arrays import TimedeltaArray\r\n"]
[229.659176, "o", "\r\n"]
[229.707647, "o", "            return TimedeltaArray._simple_new(result, dtype=result.dtype)\r\n"]
[229.756118, "o", "        return type(self)(result)\r\n"]
[229.804588, "o", "\r\n"]
[229.853059, "o", "    # ------------------------------------------------------------------------\r\n"]
[229.901529, "o", "    # String methods interface\r\n"]
[230.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[230.002, "i", "nl -ba pandas/core/base.py | sed -n '380,520p'\r"]
[230.004, "o", "nl -ba pandas/core/base.py | sed -n '380,520p'\r\n"]
[230.040817, "o", "\u001b[?2004l\r\n"]
[230.075634, "o", "   380\t        -----\r\n"]
[230.110451, "o", "   381\t        This table lays out the different array types for each extension\r\n"]
[230.145268, "o", "   382\t        dtype within pandas.\r\n"]
[230.180085, "o", "   383\t\r\n"]
[230.214901, "o", "   384\t        ================== =============================\r\n"]
[230.249718, "o", "   385\t        dtype              array type\r\n"]
[230.284535, "o", "   386\t        ================== =============================\r\n"]
[230.319352, "o", "   387\t        category           Categorical\r\n"]
[230.354169, "o", "   388\t        period             PeriodArray\r\n"]
[230.388986, "o", "   389\t        interval           IntervalArray\r\n"]
[230.423803, "o", "   390\t        IntegerNA          IntegerArray\r\n"]
[230.45862, "o", "   391\t        string             StringArray\r\n"]
[230.493437, "o", "   392\t        boolean            BooleanArray\r\n"]
[230.528254, "o", "   393\t        datetime64[ns, tz] DatetimeArray\r\n"]
[230.56307, "o", "   394\t        ================== =============================\r\n"]
[230.597887, "o", "   395\t\r\n"]
[230.632704, "o", "   396\t        For any 3rd-party extension types, the array type will be an\r\n"]
[230.667521, "o", "   397\t        ExtensionArray.\r\n"]
[230.702338, "o", "   398\t\r\n"]
[230.737155, "o", "   399\t        For all remaining dtypes ``.array`` will be a\r\n"]
[230.771972, "o", "   400\t        :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\r\n"]
[230.806789, "o", "   401\t        stored within. If you absolutely need a NumPy array (possibly with\r\n"]
[230.841606, "o", "   402\t        copying / coercing data), then use :meth:`Series.to_numpy` instead.\r\n"]
[230.876423, "o", "   403\t\r\n"]
[230.911239, "o", "   404\t        Examples\r\n"]
[230.946056, "o", "   405\t        --------\r\n"]
[230.980873, "o", "   406\t        For regular NumPy types like int, and float, a PandasArray\r\n"]
[231.01569, "o", "   407\t        is returned.\r\n"]
[231.050507, "o", "   408\t\r\n"]
[231.085324, "o", "   409\t        >>> pd.Series([1, 2, 3]).array\r\n"]
[231.120141, "o", "   410\t        <PandasArray>\r\n"]
[231.154958, "o", "   411\t        [1, 2, 3]\r\n"]
[231.189775, "o", "   412\t        Length: 3, dtype: int64\r\n"]
[231.224592, "o", "   413\t\r\n"]
[231.259408, "o", "   414\t        For extension types, like Categorical, the actual ExtensionArray\r\n"]
[231.294225, "o", "   415\t        is returned\r\n"]
[231.329042, "o", "   416\t\r\n"]
[231.363859, "o", "   417\t        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[231.398676, "o", "   418\t        >>> ser.array\r\n"]
[231.433493, "o", "   419\t        ['a', 'b', 'a']\r\n"]
[231.46831, "o", "   420\t        Categories (2, object): ['a', 'b']\r\n"]
[231.503127, "o", "   421\t        \"\"\"\r\n"]
[231.537944, "o", "   422\t        raise AbstractMethodError(self)\r\n"]
[231.572761, "o", "   423\t\r\n"]
[231.607577, "o", "   424\t    @final\r\n"]
[231.642394, "o", "   425\t    def to_numpy(\r\n"]
[231.677211, "o", "   426\t        self,\r\n"]
[231.712028, "o", "   427\t        dtype: npt.DTypeLike | None = None,\r\n"]
[231.746845, "o", "   428\t        copy: bool = False,\r\n"]
[231.781662, "o", "   429\t        na_value: object = lib.no_default,\r\n"]
[231.816479, "o", "   430\t        **kwargs,\r\n"]
[231.851296, "o", "   431\t    ) -> np.ndarray:\r\n"]
[231.886113, "o", "   432\t        \"\"\"\r\n"]
[231.92093, "o", "   433\t        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[231.955746, "o", "   434\t\r\n"]
[231.990563, "o", "   435\t        Parameters\r\n"]
[232.02538, "o", "   436\t        ----------\r\n"]
[232.060197, "o", "   437\t        dtype : str or numpy.dtype, optional\r\n"]
[232.095014, "o", "   438\t            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[232.129831, "o", "   439\t        copy : bool, default False\r\n"]
[232.164648, "o", "   440\t            Whether to ensure that the returned value is not a view on\r\n"]
[232.199465, "o", "   441\t            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[232.234282, "o", "   442\t            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[232.269099, "o", "   443\t            a copy is made, even if not strictly necessary.\r\n"]
[232.303915, "o", "   444\t        na_value : Any, optional\r\n"]
[232.338732, "o", "   445\t            The value to use for missing values. The default value depends\r\n"]
[232.373549, "o", "   446\t            on `dtype` and the type of the array.\r\n"]
[232.408366, "o", "   447\t\r\n"]
[232.443183, "o", "   448\t            .. versionadded:: 1.0.0\r\n"]
[232.478, "o", "   449\t\r\n"]
[232.512817, "o", "   450\t        **kwargs\r\n"]
[232.547634, "o", "   451\t            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[232.582451, "o", "   452\t            of the underlying array (for extension arrays).\r\n"]
[232.617268, "o", "   453\t\r\n"]
[232.652085, "o", "   454\t            .. versionadded:: 1.0.0\r\n"]
[232.686901, "o", "   455\t\r\n"]
[232.721718, "o", "   456\t        Returns\r\n"]
[232.756535, "o", "   457\t        -------\r\n"]
[232.791352, "o", "   458\t        numpy.ndarray\r\n"]
[232.826169, "o", "   459\t\r\n"]
[232.860986, "o", "   460\t        See Also\r\n"]
[232.895803, "o", "   461\t        --------\r\n"]
[232.93062, "o", "   462\t        Series.array : Get the actual data stored within.\r\n"]
[232.965437, "o", "   463\t        Index.array : Get the actual data stored within.\r\n"]
[233.000254, "o", "   464\t        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[233.03507, "o", "   465\t\r\n"]
[233.069887, "o", "   466\t        Notes\r\n"]
[233.104704, "o", "   467\t        -----\r\n"]
[233.139521, "o", "   468\t        The returned array will be the same up to equality (values equal\r\n"]
[233.174338, "o", "   469\t        in `self` will be equal in the returned array; likewise for values\r\n"]
[233.209155, "o", "   470\t        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[233.243972, "o", "   471\t        dtype may be different. For example, for a category-dtype Series,\r\n"]
[233.278789, "o", "   472\t        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[233.313606, "o", "   473\t        will be lost.\r\n"]
[233.348423, "o", "   474\t\r\n"]
[233.383239, "o", "   475\t        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[233.418056, "o", "   476\t        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[233.452873, "o", "   477\t        in place will modify the data stored in the Series or Index (not that\r\n"]
[233.48769, "o", "   478\t        we recommend doing that).\r\n"]
[233.522507, "o", "   479\t\r\n"]
[233.557324, "o", "   480\t        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[233.592141, "o", "   481\t        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[233.626958, "o", "   482\t        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[233.661775, "o", "   483\t        :attr:`Series.array` should be used instead.\r\n"]
[233.696592, "o", "   484\t\r\n"]
[233.731408, "o", "   485\t        This table lays out the different dtypes and default return types of\r\n"]
[233.766225, "o", "   486\t        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[233.801042, "o", "   487\t\r\n"]
[233.835859, "o", "   488\t        ================== ================================\r\n"]
[233.870676, "o", "   489\t        dtype              array type\r\n"]
[233.905493, "o", "   490\t        ================== ================================\r\n"]
[233.94031, "o", "   491\t        category[T]        ndarray[T] (same dtype as input)\r\n"]
[233.975127, "o", "   492\t        period             ndarray[object] (Periods)\r\n"]
[234.009944, "o", "   493\t        interval           ndarray[object] (Intervals)\r\n"]
[234.044761, "o", "   494\t        IntegerNA          ndarray[object]\r\n"]
[234.079577, "o", "   495\t        datetime64[ns]     datetime64[ns]\r\n"]
[234.114394, "o", "   496\t        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[234.149211, "o", "   497\t        ================== ================================\r\n"]
[234.184028, "o", "   498\t\r\n"]
[234.218845, "o", "   499\t        Examples\r\n"]
[234.253662, "o", "   500\t        --------\r\n"]
[234.288479, "o", "   501\t        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[234.323296, "o", "   502\t        >>> ser.to_numpy()\r\n"]
[234.358113, "o", "   503\t        array(['a', 'b', 'a'], dtype=object)\r\n"]
[234.39293, "o", "   504\t\r\n"]
[234.427746, "o", "   505\t        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[234.462563, "o", "   506\t        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[234.49738, "o", "   507\t        objects, each with the correct ``tz``.\r\n"]
[234.532197, "o", "   508\t\r\n"]
[234.567014, "o", "   509\t        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[234.601831, "o", "   510\t        >>> ser.to_numpy(dtype=object)\r\n"]
[234.636648, "o", "   511\t        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[234.671465, "o", "   512\t               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[234.706282, "o", "   513\t              dtype=object)\r\n"]
[234.741099, "o", "   514\t\r\n"]
[234.775915, "o", "   515\t        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[234.810732, "o", "   516\t        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[234.845549, "o", "   517\t        info is dropped.\r\n"]
[234.880366, "o", "   518\t\r\n"]
[234.915183, "o", "   519\t        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[235.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[235.002, "i", "nl -ba pandas/core/arrays/base.py | sed -n '420,520p'\r"]
[235.004, "o", "nl -ba pandas/core/arrays/base.py | sed -n '420,520p'\r\n"]
[235.054471, "o", "\u001b[?2004l\r\n"]
[235.102941, "o", "   420\t        Return for `item in self`.\r\n"]
[235.151412, "o", "   421\t        \"\"\"\r\n"]
[235.199882, "o", "   422\t        # GH37867\r\n"]
[235.248353, "o", "   423\t        # comparisons of any item to pd.NA always return pd.NA, so e.g. \"a\" in [pd.NA]\r\n"]
[235.296824, "o", "   424\t        # would raise a TypeError. The implementation below works around that.\r\n"]
[235.345294, "o", "   425\t        if is_scalar(item) and isna(item):\r\n"]
[235.393765, "o", "   426\t            if not self._can_hold_na:\r\n"]
[235.442235, "o", "   427\t                return False\r\n"]
[235.490706, "o", "   428\t            elif item is self.dtype.na_value or isinstance(item, self.dtype.type):\r\n"]
[235.539176, "o", "   429\t                return self._hasna\r\n"]
[235.587647, "o", "   430\t            else:\r\n"]
[235.636118, "o", "   431\t                return False\r\n"]
[235.684588, "o", "   432\t        else:\r\n"]
[235.733059, "o", "   433\t            # error: Item \"ExtensionArray\" of \"Union[ExtensionArray, ndarray]\" has no\r\n"]
[235.781529, "o", "   434\t            # attribute \"any\"\r\n"]
[235.83, "o", "   435\t            return (item == self).any()  # type: ignore[union-attr]\r\n"]
[235.878471, "o", "   436\t\r\n"]
[235.926941, "o", "   437\t    # error: Signature of \"__eq__\" incompatible with supertype \"object\"\r\n"]
[235.975412, "o", "   438\t    def __eq__(self, other: Any) -> ArrayLike:  # type: ignore[override]\r\n"]
[236.023882, "o", "   439\t        \"\"\"\r\n"]
[236.072353, "o", "   440\t        Return for `self == other` (element-wise equality).\r\n"]
[236.120824, "o", "   441\t        \"\"\"\r\n"]
[236.169294, "o", "   442\t        # Implementer note: this should return a boolean numpy ndarray or\r\n"]
[236.217765, "o", "   443\t        # a boolean ExtensionArray.\r\n"]
[236.266235, "o", "   444\t        # When `other` is one of Series, Index, or DataFrame, this method should\r\n"]
[236.314706, "o", "   445\t        # return NotImplemented (to ensure that those objects are responsible for\r\n"]
[236.363176, "o", "   446\t        # first unpacking the arrays, and then dispatch the operation to the\r\n"]
[236.411647, "o", "   447\t        # underlying arrays)\r\n"]
[236.460118, "o", "   448\t        raise AbstractMethodError(self)\r\n"]
[236.508588, "o", "   449\t\r\n"]
[236.557059, "o", "   450\t    # error: Signature of \"__ne__\" incompatible with supertype \"object\"\r\n"]
[236.605529, "o", "   451\t    def __ne__(self, other: Any) -> ArrayLike:  # type: ignore[override]\r\n"]
[236.654, "o", "   452\t        \"\"\"\r\n"]
[236.702471, "o", "   453\t        Return for `self != other` (element-wise in-equality).\r\n"]
[236.750941, "o", "   454\t        \"\"\"\r\n"]
[236.799412, "o", "   455\t        return ~(self == other)\r\n"]
[236.847882, "o", "   456\t\r\n"]
[236.896353, "o", "   457\t    def to_numpy(\r\n"]
[236.944824, "o", "   458\t        self,\r\n"]
[236.993294, "o", "   459\t        dtype: npt.DTypeLike | None = None,\r\n"]
[237.041765, "o", "   460\t        copy: bool = False,\r\n"]
[237.090235, "o", "   461\t        na_value: object = lib.no_default,\r\n"]
[237.138706, "o", "   462\t    ) -> np.ndarray:\r\n"]
[237.187176, "o", "   463\t        \"\"\"\r\n"]
[237.235647, "o", "   464\t        Convert to a NumPy ndarray.\r\n"]
[237.284118, "o", "   465\t\r\n"]
[237.332588, "o", "   466\t        .. versionadded:: 1.0.0\r\n"]
[237.381059, "o", "   467\t\r\n"]
[237.429529, "o", "   468\t        This is similar to :meth:`numpy.asarray`, but may provide additional control\r\n"]
[237.478, "o", "   469\t        over how the conversion is done.\r\n"]
[237.526471, "o", "   470\t\r\n"]
[237.574941, "o", "   471\t        Parameters\r\n"]
[237.623412, "o", "   472\t        ----------\r\n"]
[237.671882, "o", "   473\t        dtype : str or numpy.dtype, optional\r\n"]
[237.720353, "o", "   474\t            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[237.768824, "o", "   475\t        copy : bool, default False\r\n"]
[237.817294, "o", "   476\t            Whether to ensure that the returned value is a not a view on\r\n"]
[237.865765, "o", "   477\t            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[237.914235, "o", "   478\t            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[237.962706, "o", "   479\t            a copy is made, even if not strictly necessary.\r\n"]
[238.011176, "o", "   480\t        na_value : Any, optional\r\n"]
[238.059647, "o", "   481\t            The value to use for missing values. The default value depends\r\n"]
[238.108118, "o", "   482\t            on `dtype` and the type of the array.\r\n"]
[238.156588, "o", "   483\t\r\n"]
[238.205059, "o", "   484\t        Returns\r\n"]
[238.253529, "o", "   485\t        -------\r\n"]
[238.302, "o", "   486\t        numpy.ndarray\r\n"]
[238.350471, "o", "   487\t        \"\"\"\r\n"]
[238.398941, "o", "   488\t        result = np.asarray(self, dtype=dtype)\r\n"]
[238.447412, "o", "   489\t        if copy or na_value is not lib.no_default:\r\n"]
[238.495882, "o", "   490\t            result = result.copy()\r\n"]
[238.544353, "o", "   491\t        if na_value is not lib.no_default:\r\n"]
[238.592824, "o", "   492\t            result[self.isna()] = na_value\r\n"]
[238.641294, "o", "   493\t        return result\r\n"]
[238.689765, "o", "   494\t\r\n"]
[238.738235, "o", "   495\t    # ------------------------------------------------------------------------\r\n"]
[238.786706, "o", "   496\t    # Required attributes\r\n"]
[238.835176, "o", "   497\t    # ------------------------------------------------------------------------\r\n"]
[238.883647, "o", "   498\t\r\n"]
[238.932118, "o", "   499\t    @property\r\n"]
[238.980588, "o", "   500\t    def dtype(self) -> ExtensionDtype:\r\n"]
[239.029059, "o", "   501\t        \"\"\"\r\n"]
[239.077529, "o", "   502\t        An instance of 'ExtensionDtype'.\r\n"]
[239.126, "o", "   503\t        \"\"\"\r\n"]
[239.174471, "o", "   504\t        raise AbstractMethodError(self)\r\n"]
[239.222941, "o", "   505\t\r\n"]
[239.271412, "o", "   506\t    @property\r\n"]
[239.319882, "o", "   507\t    def shape(self) -> Shape:\r\n"]
[239.368353, "o", "   508\t        \"\"\"\r\n"]
[239.416824, "o", "   509\t        Return a tuple of the array dimensions.\r\n"]
[239.465294, "o", "   510\t        \"\"\"\r\n"]
[239.513765, "o", "   511\t        return (len(self),)\r\n"]
[239.562235, "o", "   512\t\r\n"]
[239.610706, "o", "   513\t    @property\r\n"]
[239.659176, "o", "   514\t    def size(self) -> int:\r\n"]
[239.707647, "o", "   515\t        \"\"\"\r\n"]
[239.756118, "o", "   516\t        The number of elements in the array.\r\n"]
[239.804588, "o", "   517\t        \"\"\"\r\n"]
[239.853059, "o", "   518\t        # error: Incompatible return value type (got \"signedinteger[_64Bit]\",\r\n"]
[239.901529, "o", "   519\t        # expected \"int\")  [return-value]\r\n"]
[240.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[240.002, "i", "nl -ba pandas/core/arrays/numpy_.py | sed -n '340,460p'\r"]
[240.004, "o", "nl -ba pandas/core/arrays/numpy_.py | sed -n '340,460p'\r\n"]
[240.046525, "o", "\u001b[?2004l\r\n"]
[240.087049, "o", "   340\t        axis: AxisInt | None = None,\r\n"]
[240.127574, "o", "   341\t        dtype: NpDtype | None = None,\r\n"]
[240.168098, "o", "   342\t        out=None,\r\n"]
[240.208623, "o", "   343\t        ddof: int = 1,\r\n"]
[240.249148, "o", "   344\t        keepdims: bool = False,\r\n"]
[240.289672, "o", "   345\t        skipna: bool = True,\r\n"]
[240.330197, "o", "   346\t    ):\r\n"]
[240.370721, "o", "   347\t        nv.validate_stat_ddof_func(\r\n"]
[240.411246, "o", "   348\t            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"sem\"\r\n"]
[240.45177, "o", "   349\t        )\r\n"]
[240.492295, "o", "   350\t        result = nanops.nansem(self._ndarray, axis=axis, skipna=skipna, ddof=ddof)\r\n"]
[240.53282, "o", "   351\t        return self._wrap_reduction_result(axis, result)\r\n"]
[240.573344, "o", "   352\t\r\n"]
[240.613869, "o", "   353\t    def kurt(\r\n"]
[240.654393, "o", "   354\t        self,\r\n"]
[240.694918, "o", "   355\t        *,\r\n"]
[240.735443, "o", "   356\t        axis: AxisInt | None = None,\r\n"]
[240.775967, "o", "   357\t        dtype: NpDtype | None = None,\r\n"]
[240.816492, "o", "   358\t        out=None,\r\n"]
[240.857016, "o", "   359\t        keepdims: bool = False,\r\n"]
[240.897541, "o", "   360\t        skipna: bool = True,\r\n"]
[240.938066, "o", "   361\t    ):\r\n"]
[240.97859, "o", "   362\t        nv.validate_stat_ddof_func(\r\n"]
[241.019115, "o", "   363\t            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"kurt\"\r\n"]
[241.059639, "o", "   364\t        )\r\n"]
[241.100164, "o", "   365\t        result = nanops.nankurt(self._ndarray, axis=axis, skipna=skipna)\r\n"]
[241.140689, "o", "   366\t        return self._wrap_reduction_result(axis, result)\r\n"]
[241.181213, "o", "   367\t\r\n"]
[241.221738, "o", "   368\t    def skew(\r\n"]
[241.262262, "o", "   369\t        self,\r\n"]
[241.302787, "o", "   370\t        *,\r\n"]
[241.343311, "o", "   371\t        axis: AxisInt | None = None,\r\n"]
[241.383836, "o", "   372\t        dtype: NpDtype | None = None,\r\n"]
[241.424361, "o", "   373\t        out=None,\r\n"]
[241.464885, "o", "   374\t        keepdims: bool = False,\r\n"]
[241.50541, "o", "   375\t        skipna: bool = True,\r\n"]
[241.545934, "o", "   376\t    ):\r\n"]
[241.586459, "o", "   377\t        nv.validate_stat_ddof_func(\r\n"]
[241.626984, "o", "   378\t            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"skew\"\r\n"]
[241.667508, "o", "   379\t        )\r\n"]
[241.708033, "o", "   380\t        result = nanops.nanskew(self._ndarray, axis=axis, skipna=skipna)\r\n"]
[241.748557, "o", "   381\t        return self._wrap_reduction_result(axis, result)\r\n"]
[241.789082, "o", "   382\t\r\n"]
[241.829607, "o", "   383\t    # ------------------------------------------------------------------------\r\n"]
[241.870131, "o", "   384\t    # Additional Methods\r\n"]
[241.910656, "o", "   385\t\r\n"]
[241.95118, "o", "   386\t    def to_numpy(\r\n"]
[241.991705, "o", "   387\t        self,\r\n"]
[242.03223, "o", "   388\t        dtype: npt.DTypeLike | None = None,\r\n"]
[242.072754, "o", "   389\t        copy: bool = False,\r\n"]
[242.113279, "o", "   390\t        na_value: object = lib.no_default,\r\n"]
[242.153803, "o", "   391\t    ) -> np.ndarray:\r\n"]
[242.194328, "o", "   392\t        mask = self.isna()\r\n"]
[242.234852, "o", "   393\t        if na_value is not lib.no_default and mask.any():\r\n"]
[242.275377, "o", "   394\t            result = self._ndarray.copy()\r\n"]
[242.315902, "o", "   395\t            result[mask] = na_value\r\n"]
[242.356426, "o", "   396\t        else:\r\n"]
[242.396951, "o", "   397\t            result = self._ndarray\r\n"]
[242.437475, "o", "   398\t\r\n"]
[242.478, "o", "   399\t        result = np.asarray(result, dtype=dtype)\r\n"]
[242.518525, "o", "   400\t\r\n"]
[242.559049, "o", "   401\t        if copy and result is self._ndarray:\r\n"]
[242.599574, "o", "   402\t            result = result.copy()\r\n"]
[242.640098, "o", "   403\t\r\n"]
[242.680623, "o", "   404\t        return result\r\n"]
[242.721148, "o", "   405\t\r\n"]
[242.761672, "o", "   406\t    # ------------------------------------------------------------------------\r\n"]
[242.802197, "o", "   407\t    # Ops\r\n"]
[242.842721, "o", "   408\t\r\n"]
[242.883246, "o", "   409\t    def __invert__(self) -> PandasArray:\r\n"]
[242.92377, "o", "   410\t        return type(self)(~self._ndarray)\r\n"]
[242.964295, "o", "   411\t\r\n"]
[243.00482, "o", "   412\t    def __neg__(self) -> PandasArray:\r\n"]
[243.045344, "o", "   413\t        return type(self)(-self._ndarray)\r\n"]
[243.085869, "o", "   414\t\r\n"]
[243.126393, "o", "   415\t    def __pos__(self) -> PandasArray:\r\n"]
[243.166918, "o", "   416\t        return type(self)(+self._ndarray)\r\n"]
[243.207443, "o", "   417\t\r\n"]
[243.247967, "o", "   418\t    def __abs__(self) -> PandasArray:\r\n"]
[243.288492, "o", "   419\t        return type(self)(abs(self._ndarray))\r\n"]
[243.329016, "o", "   420\t\r\n"]
[243.369541, "o", "   421\t    def _cmp_method(self, other, op):\r\n"]
[243.410066, "o", "   422\t        if isinstance(other, PandasArray):\r\n"]
[243.45059, "o", "   423\t            other = other._ndarray\r\n"]
[243.491115, "o", "   424\t\r\n"]
[243.531639, "o", "   425\t        other = ops.maybe_prepare_scalar_for_op(other, (len(self),))\r\n"]
[243.572164, "o", "   426\t        pd_op = ops.get_array_op(op)\r\n"]
[243.612689, "o", "   427\t        other = ensure_wrapped_if_datetimelike(other)\r\n"]
[243.653213, "o", "   428\t        with np.errstate(all=\"ignore\"):\r\n"]
[243.693738, "o", "   429\t            result = pd_op(self._ndarray, other)\r\n"]
[243.734262, "o", "   430\t\r\n"]
[243.774787, "o", "   431\t        if op is divmod or op is ops.rdivmod:\r\n"]
[243.815311, "o", "   432\t            a, b = result\r\n"]
[243.855836, "o", "   433\t            if isinstance(a, np.ndarray):\r\n"]
[243.896361, "o", "   434\t                # for e.g. op vs TimedeltaArray, we may already\r\n"]
[243.936885, "o", "   435\t                #  have an ExtensionArray, in which case we do not wrap\r\n"]
[243.97741, "o", "   436\t                return self._wrap_ndarray_result(a), self._wrap_ndarray_result(b)\r\n"]
[244.017934, "o", "   437\t            return a, b\r\n"]
[244.058459, "o", "   438\t\r\n"]
[244.098984, "o", "   439\t        if isinstance(result, np.ndarray):\r\n"]
[244.139508, "o", "   440\t            # for e.g. multiplication vs TimedeltaArray, we may already\r\n"]
[244.180033, "o", "   441\t            #  have an ExtensionArray, in which case we do not wrap\r\n"]
[244.220557, "o", "   442\t            return self._wrap_ndarray_result(result)\r\n"]
[244.261082, "o", "   443\t        return result\r\n"]
[244.301607, "o", "   444\t\r\n"]
[244.342131, "o", "   445\t    _arith_method = _cmp_method\r\n"]
[244.382656, "o", "   446\t\r\n"]
[244.42318, "o", "   447\t    def _wrap_ndarray_result(self, result: np.ndarray):\r\n"]
[244.463705, "o", "   448\t        # If we have timedelta64[ns] result, return a TimedeltaArray instead\r\n"]
[244.50423, "o", "   449\t        #  of a PandasArray\r\n"]
[244.544754, "o", "   450\t        if result.dtype.kind == \"m\" and is_supported_unit(\r\n"]
[244.585279, "o", "   451\t            get_unit_from_dtype(result.dtype)\r\n"]
[244.625803, "o", "   452\t        ):\r\n"]
[244.666328, "o", "   453\t            from pandas.core.arrays import TimedeltaArray\r\n"]
[244.706852, "o", "   454\t\r\n"]
[244.747377, "o", "   455\t            return TimedeltaArray._simple_new(result, dtype=result.dtype)\r\n"]
[244.787902, "o", "   456\t        return type(self)(result)\r\n"]
[244.828426, "o", "   457\t\r\n"]
[244.868951, "o", "   458\t    # ------------------------------------------------------------------------\r\n"]
[244.909475, "o", "   459\t    # String methods interface\r\n"]
[245.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[245.002, "i", "applypatch << 'PATCH'\r"]
[245.004, "o", "applypatch << 'PATCH'\r\n"]
[245.039405, "o", "\u001b[?2004l\r\n"]
[245.072811, "o", "\u001b[?2004h> *** Begin Patch\r\n"]
[245.106216, "o", "\u001b[?2004l\r\n"]
[245.139622, "o", "\u001b[?2004h> *** Update File: pandas/core/base.py\r\n"]
[245.173027, "o", "\u001b[?2004l\r\n"]
[245.206432, "o", "\u001b[?2004h> @@\r\n"]
[245.239838, "o", "\u001b[?2004l\r\n"]
[245.273243, "o", "\u001b[?2004h> -    def to_numpy(\r\n"]
[245.306649, "o", "\u001b[?2004l\r\n"]
[245.340054, "o", "\u001b[?2004h> -        self,\r\n"]
[245.373459, "o", "\u001b[?2004l\r\n"]
[245.406865, "o", "\u001b[?2004h> -        dtype: npt.DTypeLike | None = None,\r\n"]
[245.44027, "o", "\u001b[?2004l\r\n"]
[245.473676, "o", "\u001b[?2004h> -        copy: bool = False,\r\n"]
[245.507081, "o", "\u001b[?2004l\r\n"]
[245.540486, "o", "\u001b[?2004h> -        na_value: object = lib.no_default,\r\n"]
[245.573892, "o", "\u001b[?2004l\r\n"]
[245.607297, "o", "\u001b[?2004h> -        **kwargs,\r\n"]
[245.640703, "o", "\u001b[?2004l\r\n"]
[245.674108, "o", "\u001b[?2004h> -    ) -> np.ndarray:\r\n"]
[245.707514, "o", "\u001b[?2004l\r\n"]
[245.740919, "o", "\u001b[?2004h> +    def to_numpy(\r\n"]
[245.774324, "o", "\u001b[?2004l\r\n"]
[245.80773, "o", "\u001b[?2004h> +        self,\r\n"]
[245.841135, "o", "\u001b[?2004l\r\n"]
[245.874541, "o", "\u001b[?2004h> +        dtype: npt.DTypeLike | None = None,\r\n"]
[245.907946, "o", "\u001b[?2004l\r\n"]
[245.941351, "o", "\u001b[?2004h> +        copy: bool = False,\r\n"]
[245.974757, "o", "\u001b[?2004l\r\n"]
[246.008162, "o", "\u001b[?2004h> +        na_value: object = lib.no_default,\r\n"]
[246.041568, "o", "\u001b[?2004l\r\n"]
[246.074973, "o", "\u001b[?2004h> +        **kwargs,\r\n"]
[246.108378, "o", "\u001b[?2004l\r\n"]
[246.141784, "o", "\u001b[?2004h> +    ) -> np.ndarray:\r\n"]
[246.175189, "o", "\u001b[?2004l\r\n"]
[246.208595, "o", "\u001b[?2004h> @@\r\n"]
[246.242, "o", "\u001b[?2004l\r\n"]
[246.275405, "o", "\u001b[?2004h> -        Returns\r\n"]
[246.308811, "o", "\u001b[?2004l\r\n"]
[246.342216, "o", "\u001b[?2004h> +        Returns\r\n"]
[246.375622, "o", "\u001b[?2004l\r\n"]
[246.409027, "o", "\u001b[?2004h>          -------\r\n"]
[246.442432, "o", "\u001b[?2004l\r\n"]
[246.475838, "o", "\u001b[?2004h>          numpy.ndarray\r\n"]
[246.509243, "o", "\u001b[?2004l\r\n"]
[246.542649, "o", "\u001b[?2004h> @@\r\n"]
[246.576054, "o", "\u001b[?2004l\r\n"]
[246.609459, "o", "\u001b[?2004h> -        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[246.642865, "o", "\u001b[?2004l\r\n"]
[246.67627, "o", "\u001b[?2004h> -        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[246.709676, "o", "\u001b[?2004l\r\n"]
[246.743081, "o", "\u001b[?2004h> -        in place will modify the data stored in the Series or Index (not that\r\n"]
[246.776486, "o", "\u001b[?2004l\r\n"]
[246.809892, "o", "\u001b[?2004h> -        we recommend doing that).\r\n"]
[246.843297, "o", "\u001b[?2004l\r\n"]
[246.876703, "o", "\u001b[?2004h> +        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[246.910108, "o", "\u001b[?2004l\r\n"]
[246.943514, "o", "\u001b[?2004h> +        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[246.976919, "o", "\u001b[?2004l\r\n"]
[247.010324, "o", "\u001b[?2004h> +        in place will modify the data stored in the Series or Index (not that\r\n"]
[247.04373, "o", "\u001b[?2004l\r\n"]
[247.077135, "o", "\u001b[?2004h> +        we recommend doing that).\r\n"]
[247.110541, "o", "\u001b[?2004l\r\n"]
[247.143946, "o", "\u001b[?2004h> +\r\n"]
[247.177351, "o", "\u001b[?2004l\r\n"]
[247.210757, "o", "\u001b[?2004h> +        Performance notes\r\n"]
[247.244162, "o", "\u001b[?2004l\r\n"]
[247.277568, "o", "\u001b[?2004h> +        -----------------\r\n"]
[247.310973, "o", "\u001b[?2004l\r\n"]
[247.344378, "o", "\u001b[?2004h> +        When the underlying data are NumPy-backed and ``dtype`` is ``None``,\r\n"]
[247.377784, "o", "\u001b[?2004l\r\n"]
[247.411189, "o", "\u001b[?2004h> +        ``copy=True`` can avoid an intermediate no-op asarray/shares_memory\r\n"]
[247.444595, "o", "\u001b[?2004l\r\n"]
[247.478, "o", "\u001b[?2004h> +        check by copying the underlying ndarray directly. This reduces a small\r\n"]
[247.511405, "o", "\u001b[?2004l\r\n"]
[247.544811, "o", "\u001b[?2004h> +        amount of Python-level overhead while preserving identical semantics.\r\n"]
[247.578216, "o", "\u001b[?2004l\r\n"]
[247.611622, "o", "\u001b[?2004h> @@\r\n"]
[247.645027, "o", "\u001b[?2004l\r\n"]
[247.678432, "o", "\u001b[?2004h> -        \"\"\"\r\n"]
[247.711838, "o", "\u001b[?2004l\r\n"]
[247.745243, "o", "\u001b[?2004h> -        if dtype is not None:\r\n"]
[247.778649, "o", "\u001b[?2004l\r\n"]
[247.812054, "o", "\u001b[?2004h> -            dtype = np.dtype(dtype)\r\n"]
[247.845459, "o", "\u001b[?2004l\r\n"]
[247.878865, "o", "\u001b[?2004h> -        result = self._mgr.as_array(dtype=dtype, copy=copy, na_value=na_value)\r\n"]
[247.91227, "o", "\u001b[?2004l\r\n"]
[247.945676, "o", "\u001b[?2004h> +        \"\"\"\r\n"]
[247.979081, "o", "\u001b[?2004l\r\n"]
[248.012486, "o", "\u001b[?2004h> +        if dtype is not None:\r\n"]
[248.045892, "o", "\u001b[?2004l\r\n"]
[248.079297, "o", "\u001b[?2004h> +            dtype = np.dtype(dtype)\r\n"]
[248.112703, "o", "\u001b[?2004l\r\n"]
[248.146108, "o", "\u001b[?2004h> +\r\n"]
[248.179514, "o", "\u001b[?2004l\r\n"]
[248.212919, "o", "\u001b[?2004h> +        # Fastpath: for NumPy-backed data with no dtype coercion requested,\r\n"]
[248.246324, "o", "\u001b[?2004l\r\n"]
[248.27973, "o", "\u001b[?2004h> +        # honor copy semantics by returning a direct ndarray copy. This avoids\r\n"]
[248.313135, "o", "\u001b[?2004l\r\n"]
[248.346541, "o", "\u001b[?2004h> +        # an intermediate asarray() call and associated shares_memory checks.\r\n"]
[248.379946, "o", "\u001b[?2004l\r\n"]
[248.413351, "o", "\u001b[?2004h> +        if (\r\n"]
[248.446757, "o", "\u001b[?2004l\r\n"]
[248.480162, "o", "\u001b[?2004h> +            copy\r\n"]
[248.513568, "o", "\u001b[?2004l\r\n"]
[248.546973, "o", "\u001b[?2004h> +            and dtype is None\r\n"]
[248.580378, "o", "\u001b[?2004l\r\n"]
[248.613784, "o", "\u001b[?2004h> +            and hasattr(self, \"_mgr\")\r\n"]
[248.647189, "o", "\u001b[?2004l\r\n"]
[248.680595, "o", "\u001b[?2004h> +            and hasattr(self._mgr, \"internal_values\")\r\n"]
[248.714, "o", "\u001b[?2004l\r\n"]
[248.747405, "o", "\u001b[?2004h> +        ):\r\n"]
[248.780811, "o", "\u001b[?2004l\r\n"]
[248.814216, "o", "\u001b[?2004h> +            vals = self._mgr.internal_values()\r\n"]
[248.847622, "o", "\u001b[?2004l\r\n"]
[248.881027, "o", "\u001b[?2004h> +            # PandasArray over a NumPy ndarray or a plain ndarray\r\n"]
[248.914432, "o", "\u001b[?2004l\r\n"]
[248.947838, "o", "\u001b[?2004h> +            if isinstance(vals, np.ndarray):\r\n"]
[248.981243, "o", "\u001b[?2004l\r\n"]
[249.014649, "o", "\u001b[?2004h> +                return vals.copy(order=\"K\")\r\n"]
[249.048054, "o", "\u001b[?2004l\r\n"]
[249.081459, "o", "\u001b[?2004h> +            # PandasArray-like wrapper exposing .to_numpy with no dtype change\r\n"]
[249.114865, "o", "\u001b[?2004l\r\n"]
[249.14827, "o", "\u001b[?2004h> +            arr = getattr(vals, \"_ndarray\", None)\r\n"]
[249.181676, "o", "\u001b[?2004l\r\n"]
[249.215081, "o", "\u001b[?2004h> +            if isinstance(arr, np.ndarray):\r\n"]
[249.248486, "o", "\u001b[?2004l\r\n"]
[249.281892, "o", "\u001b[?2004h> +                return arr.copy(order=\"K\")\r\n"]
[249.315297, "o", "\u001b[?2004l\r\n"]
[249.348703, "o", "\u001b[?2004h> +\r\n"]
[249.382108, "o", "\u001b[?2004l\r\n"]
[249.415514, "o", "\u001b[?2004h> +        result = self._mgr.as_array(dtype=dtype, copy=copy, na_value=na_value)\r\n"]
[249.448919, "o", "\u001b[?2004l\r\n"]
[249.482324, "o", "\u001b[?2004h>          if result.dtype == np.dtype(\"object\"):\r\n"]
[249.51573, "o", "\u001b[?2004l\r\n"]
[249.549135, "o", "\u001b[?2004h>              # TODO: can we get rid of the dtype  check above?\r\n"]
[249.582541, "o", "\u001b[?2004l\r\n"]
[249.615946, "o", "\u001b[?2004h>              result = cast(np.ndarray, result)\r\n"]
[249.649351, "o", "\u001b[?2004l\r\n"]
[249.682757, "o", "\u001b[?2004h>              result = lib.maybe_convert_objects(result)\r\n"]
[249.716162, "o", "\u001b[?2004l\r\n"]
[249.749568, "o", "\u001b[?2004h>          return result\r\n"]
[249.782973, "o", "\u001b[?2004l\r\n"]
[249.816378, "o", "\u001b[?2004h> *** End Patch\r\n"]
[249.849784, "o", "\u001b[?2004l\r\n"]
[249.883189, "o", "\u001b[?2004h> PATCH\r\n"]
[249.916595, "o", "\u001b[?2004l\r\n"]
[250.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[250.002, "i", "python - << 'PY'\r"]
[250.004, "o", "python - << 'PY'\r\n"]
[250.176483, "o", "\u001b[?2004l\r\n"]
[250.346966, "o", "\u001b[?2004h> import sys\r\n"]
[250.517448, "o", "\u001b[?2004l\r\n"]
[250.687931, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[250.858414, "o", "\u001b[?2004l\r\n"]
[251.028897, "o", "\u001b[?2004h> import numpy as np\r\n"]
[251.199379, "o", "\u001b[?2004l\r\n"]
[251.369862, "o", "\u001b[?2004h> s = pd.Series(np.random.randn(10))\r\n"]
[251.540345, "o", "\u001b[?2004l\r\n"]
[251.710828, "o", "\u001b[?2004h> # Sanity checks\r\n"]
[251.88131, "o", "\u001b[?2004l\r\n"]
[252.051793, "o", "\u001b[?2004h> arr1 = s.to_numpy(copy=True)\r\n"]
[252.222276, "o", "\u001b[?2004l\r\n"]
[252.392759, "o", "\u001b[?2004h> arr2 = s.to_numpy(dtype=None, copy=True)\r\n"]
[252.563241, "o", "\u001b[?2004l\r\n"]
[252.733724, "o", "\u001b[?2004h> print('equal dtype None copy:', np.array_equal(arr1, arr2), arr1.base is None, arr2.base is None)\r\n"]
[252.904207, "o", "\u001b[?2004l\r\n"]
[253.07469, "o", "\u001b[?2004h> # Ensure extension arrays still go through manager path\r\n"]
[253.245172, "o", "\u001b[?2004l\r\n"]
[253.415655, "o", "\u001b[?2004h> s2 = pd.Series(pd.array([1,2,3], dtype='Int64'))\r\n"]
[253.586138, "o", "\u001b[?2004l\r\n"]
[253.756621, "o", "\u001b[?2004h> res = s2.to_numpy(copy=True)\r\n"]
[253.927103, "o", "\u001b[?2004l\r\n"]
[254.097586, "o", "\u001b[?2004h> print('EA dtype:', res.dtype, isinstance(res, np.ndarray))\r\n"]
[254.268069, "o", "\u001b[?2004l\r\n"]
[254.438552, "o", "\u001b[?2004h> PY\r\n"]
[254.609034, "o", "\u001b[?2004l\r\n"]
[254.779517, "o", "equal dtype None copy: True True True\r\n"]
[255.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[255.002, "i", "cd asv_bench\r"]
[255.004, "o", "cd asv_bench\r\n"]
[255.006, "o", "\u001b[?2004l\r\n"]
[260.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[260.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[260.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[260.624, "o", "\u001b[?2004l\r\n"]
[261.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[261.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[262.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[263.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[263.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                   1.28\u00b10.01\u03bcs\r\n"]
[264.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                  385\u00b16\u03bcs\r\n"]
[265.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[265.002, "i", "grep -n \"def to_numpy(\" pandas/core/base.py\r"]
[265.004, "o", "grep -n \"def to_numpy(\" pandas/core/base.py\r\n"]
[267.478, "o", "\u001b[?2004l\r\n"]
[270.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[270.002, "i", "sed -n '400,520p' pandas/core/base.py\r"]
[270.004, "o", "sed -n '400,520p' pandas/core/base.py\r\n"]
[272.478, "o", "\u001b[?2004l\r\n"]
[275.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[275.002, "i", "python - << 'PY'\r"]
[275.004, "o", "python - << 'PY'\r\n"]
[275.078706, "o", "\u001b[?2004l\r\n"]
[275.151412, "o", "\u001b[?2004h> import io, sys, re\r\n"]
[275.224118, "o", "\u001b[?2004l\r\n"]
[275.296824, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[275.369529, "o", "\u001b[?2004l\r\n"]
[275.442235, "o", "\u001b[?2004h> p = Path('pandas/core/base.py')\r\n"]
[275.514941, "o", "\u001b[?2004l\r\n"]
[275.587647, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[275.660353, "o", "\u001b[?2004l\r\n"]
[275.733059, "o", "\u001b[?2004h> start = s.find('def to_numpy(')\r\n"]
[275.805765, "o", "\u001b[?2004l\r\n"]
[275.878471, "o", "\u001b[?2004h> if start == -1:\r\n"]
[275.951176, "o", "\u001b[?2004l\r\n"]
[276.023882, "o", "\u001b[?2004h>     print('to_numpy not found', file=sys.stderr); sys.exit(1)\r\n"]
[276.096588, "o", "\u001b[?2004l\r\n"]
[276.169294, "o", "\u001b[?2004h> # find function block end by finding next 'def ' at same indent or class end\r\n"]
[276.242, "o", "\u001b[?2004l\r\n"]
[276.314706, "o", "\u001b[?2004h> func_hdr_idx = s.rfind('\\n', 0, start) + 1\r\n"]
[276.387412, "o", "\u001b[?2004l\r\n"]
[276.460118, "o", "\u001b[?2004h> indent = len(re.match(r\"\\s*\", s[func_hdr_idx:]).group(0))\r\n"]
[276.532824, "o", "\u001b[?2004l\r\n"]
[276.605529, "o", "\u001b[?2004h> # naive find: insert fastpath after dtype normalization and before calling _mgr.as_array\r\n"]
[276.678235, "o", "\u001b[?2004l\r\n"]
[276.750941, "o", "\u001b[?2004h> pat = r\"def to_numpy\\([\\s\\S]*?\\):\\n([\\s\\S]*?)result = self._mgr.as_array\\(dtype=dtype, copy=copy, na_value=na_value\\)\"\r\n"]
[276.823647, "o", "\u001b[?2004l\r\n"]
[276.896353, "o", "\u001b[?2004h> m = re.search(pat, s)\r\n"]
[276.969059, "o", "\u001b[?2004l\r\n"]
[277.041765, "o", "\u001b[?2004h> if not m:\r\n"]
[277.114471, "o", "\u001b[?2004l\r\n"]
[277.187176, "o", "\u001b[?2004h>     print('pattern not found', file=sys.stderr); sys.exit(1)\r\n"]
[277.259882, "o", "\u001b[?2004l\r\n"]
[277.332588, "o", "\u001b[?2004h> body = m.group(1)\r\n"]
[277.405294, "o", "\u001b[?2004l\r\n"]
[277.478, "o", "\u001b[?2004h> insert = \"\\n\" + \" \"*8 + \"# Fastpath for NumPy-backed data when no dtype coercion is requested\\n\" + \\\r\n"]
[277.550706, "o", "\u001b[?2004l\r\n"]
[277.623412, "o", "\u001b[?2004h>           \" \"*8 + \"if dtype is None and hasattr(self, '_mgr') and hasattr(self._mgr, 'internal_values'):\\n\" + \\\r\n"]
[277.696118, "o", "\u001b[?2004l\r\n"]
[277.768824, "o", "\u001b[?2004h>           \" \"*12 + \"vals = self._mgr.internal_values()\\n\" + \\\r\n"]
[277.841529, "o", "\u001b[?2004l\r\n"]
[277.914235, "o", "\u001b[?2004h>           \" \"*12 + \"# vals can be a NumPy ndarray or a PandasArray exposing ._ndarray\\n\" + \\\r\n"]
[277.986941, "o", "\u001b[?2004l\r\n"]
[278.059647, "o", "\u001b[?2004h>           \" \"*12 + \"if isinstance(vals, __import__('numpy').ndarray):\\n\" + \\\r\n"]
[278.132353, "o", "\u001b[?2004l\r\n"]
[278.205059, "o", "\u001b[?2004h>           \" \"*16 + \"return vals.copy(order='K') if copy else vals\\n\" + \\\r\n"]
[278.277765, "o", "\u001b[?2004l\r\n"]
[278.350471, "o", "\u001b[?2004h>           \" \"*12 + \"arr = getattr(vals, '_ndarray', None)\\n\" + \\\r\n"]
[278.423176, "o", "\u001b[?2004l\r\n"]
[278.495882, "o", "\u001b[?2004h>           \" \"*12 + \"if isinstance(arr, __import__('numpy').ndarray):\\n\" + \\\r\n"]
[278.568588, "o", "\u001b[?2004l\r\n"]
[278.641294, "o", "\u001b[?2004h>           \" \"*16 + \"return arr.copy(order='K') if copy else arr\\n\"\r\n"]
[278.714, "o", "\u001b[?2004l\r\n"]
[278.786706, "o", "\u001b[?2004h> new_s = s[:m.start(1)] + body + insert + s[m.start(1)+len(body):]\r\n"]
[278.859412, "o", "\u001b[?2004l\r\n"]
[278.932118, "o", "\u001b[?2004h> p.write_text(new_s)\r\n"]
[279.004824, "o", "\u001b[?2004l\r\n"]
[279.077529, "o", "\u001b[?2004h> print('patched')\r\n"]
[279.150235, "o", "\u001b[?2004l\r\n"]
[279.222941, "o", "\u001b[?2004h> PY\r\n"]
[279.295647, "o", "\u001b[?2004l\r\n"]
[279.368353, "o", "Traceback (most recent call last):\r\n"]
[279.441059, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[279.513765, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1236, in read_text\r\n"]
[279.586471, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[279.659176, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1222, in open\r\n"]
[279.731882, "o", "    return io.open(self, mode, buffering, encoding, errors, newline,\r\n"]
[279.804588, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1078, in _opener\r\n"]
[279.877294, "o", "    return self._accessor.open(self, flags, mode)\r\n"]
[280.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[280.002, "i", "python - << 'PY'\r"]
[280.004, "o", "python - << 'PY'\r\n"]
[280.20376, "o", "\u001b[?2004l\r\n"]
[280.40152, "o", "\u001b[?2004h> import pandas as pd, numpy as np\r\n"]
[280.59928, "o", "\u001b[?2004l\r\n"]
[280.79704, "o", "\u001b[?2004h> s = pd.Series(np.random.randn(10))\r\n"]
[280.9948, "o", "\u001b[?2004l\r\n"]
[281.19256, "o", "\u001b[?2004h> a = s.to_numpy()\r\n"]
[281.39032, "o", "\u001b[?2004l\r\n"]
[281.58808, "o", "\u001b[?2004h> b = s.to_numpy(copy=True)\r\n"]
[281.78584, "o", "\u001b[?2004l\r\n"]
[281.9836, "o", "\u001b[?2004h> print('no copy base is s._values._ndarray or arr?:', isinstance(a, np.ndarray), a.base is s._values._ndarray if hasattr(s._values,'_ndarray') else a.base is s.\r\n"]
[282.18136, "o", "._values)\r\n"]
[282.37912, "o", "\u001b[?2004l\r\n"]
[282.57688, "o", "\u001b[?2004h> print('copy returns own data:', b.base is None)\r\n"]
[282.77464, "o", "\u001b[?2004l\r\n"]
[282.9724, "o", "\u001b[?2004h> s2 = pd.Series(pd.array([1,2,3], dtype='Int64'))\r\n"]
[283.17016, "o", "\u001b[?2004l\r\n"]
[283.36792, "o", "\u001b[?2004h> r = s2.to_numpy(copy=True)\r\n"]
[283.56568, "o", "\u001b[?2004l\r\n"]
[283.76344, "o", "\u001b[?2004h> print('EA path dtype:', r.dtype)\r\n"]
[283.9612, "o", "\u001b[?2004l\r\n"]
[284.15896, "o", "\u001b[?2004h> PY\r\n"]
[284.35672, "o", "\u001b[?2004l\r\n"]
[284.55448, "o", "no copy base is s._values._ndarray or arr?: True False\r\n"]
[284.75224, "o", "copy returns own data: True\r\n"]
[285.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[285.002, "i", "cd asv_bench\r"]
[285.004, "o", "cd asv_bench\r\n"]
[287.478, "o", "\u001b[?2004l\r\n"]
[290.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[290.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[290.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[290.624, "o", "\u001b[?2004l\r\n"]
[291.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[291.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[292.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[293.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[293.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                   1.28\u00b10.02\u03bcs\r\n"]
[294.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                  367\u00b14\u03bcs\r\n"]
[295.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[295.002, "i", "cd /workspace/repo\r"]
[295.004, "o", "cd /workspace/repo\r\n"]
[295.006, "o", "\u001b[?2004l\r\n"]
[300.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[300.002, "i", "nl -ba pandas/core/base.py | sed -n '400,560p'\r"]
[300.004, "o", "nl -ba pandas/core/base.py | sed -n '400,560p'\r\n"]
[300.036519, "o", "\u001b[?2004l\r\n"]
[300.067037, "o", "   400\t        :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\r\n"]
[300.097556, "o", "   401\t        stored within. If you absolutely need a NumPy array (possibly with\r\n"]
[300.128074, "o", "   402\t        copying / coercing data), then use :meth:`Series.to_numpy` instead.\r\n"]
[300.158593, "o", "   403\t\r\n"]
[300.189111, "o", "   404\t        Examples\r\n"]
[300.21963, "o", "   405\t        --------\r\n"]
[300.250148, "o", "   406\t        For regular NumPy types like int, and float, a PandasArray\r\n"]
[300.280667, "o", "   407\t        is returned.\r\n"]
[300.311185, "o", "   408\t\r\n"]
[300.341704, "o", "   409\t        >>> pd.Series([1, 2, 3]).array\r\n"]
[300.372222, "o", "   410\t        <PandasArray>\r\n"]
[300.402741, "o", "   411\t        [1, 2, 3]\r\n"]
[300.433259, "o", "   412\t        Length: 3, dtype: int64\r\n"]
[300.463778, "o", "   413\t\r\n"]
[300.494296, "o", "   414\t        For extension types, like Categorical, the actual ExtensionArray\r\n"]
[300.524815, "o", "   415\t        is returned\r\n"]
[300.555333, "o", "   416\t\r\n"]
[300.585852, "o", "   417\t        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[300.61637, "o", "   418\t        >>> ser.array\r\n"]
[300.646889, "o", "   419\t        ['a', 'b', 'a']\r\n"]
[300.677407, "o", "   420\t        Categories (2, object): ['a', 'b']\r\n"]
[300.707926, "o", "   421\t        \"\"\"\r\n"]
[300.738444, "o", "   422\t        raise AbstractMethodError(self)\r\n"]
[300.768963, "o", "   423\t\r\n"]
[300.799481, "o", "   424\t    @final\r\n"]
[300.83, "o", "   425\t    def to_numpy(\r\n"]
[300.860519, "o", "   426\t        self,\r\n"]
[300.891037, "o", "   427\t        dtype: npt.DTypeLike | None = None,\r\n"]
[300.921556, "o", "   428\t        copy: bool = False,\r\n"]
[300.952074, "o", "   429\t        na_value: object = lib.no_default,\r\n"]
[300.982593, "o", "   430\t        **kwargs,\r\n"]
[301.013111, "o", "   431\t    ) -> np.ndarray:\r\n"]
[301.04363, "o", "   432\t        \"\"\"\r\n"]
[301.074148, "o", "   433\t        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[301.104667, "o", "   434\t\r\n"]
[301.135185, "o", "   435\t        Parameters\r\n"]
[301.165704, "o", "   436\t        ----------\r\n"]
[301.196222, "o", "   437\t        dtype : str or numpy.dtype, optional\r\n"]
[301.226741, "o", "   438\t            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[301.257259, "o", "   439\t        copy : bool, default False\r\n"]
[301.287778, "o", "   440\t            Whether to ensure that the returned value is not a view on\r\n"]
[301.318296, "o", "   441\t            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[301.348815, "o", "   442\t            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[301.379333, "o", "   443\t            a copy is made, even if not strictly necessary.\r\n"]
[301.409852, "o", "   444\t        na_value : Any, optional\r\n"]
[301.44037, "o", "   445\t            The value to use for missing values. The default value depends\r\n"]
[301.470889, "o", "   446\t            on `dtype` and the type of the array.\r\n"]
[301.501407, "o", "   447\t\r\n"]
[301.531926, "o", "   448\t            .. versionadded:: 1.0.0\r\n"]
[301.562444, "o", "   449\t\r\n"]
[301.592963, "o", "   450\t        **kwargs\r\n"]
[301.623481, "o", "   451\t            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[301.654, "o", "   452\t            of the underlying array (for extension arrays).\r\n"]
[301.684519, "o", "   453\t\r\n"]
[301.715037, "o", "   454\t            .. versionadded:: 1.0.0\r\n"]
[301.745556, "o", "   455\t\r\n"]
[301.776074, "o", "   456\t        Returns\r\n"]
[301.806593, "o", "   457\t        -------\r\n"]
[301.837111, "o", "   458\t        numpy.ndarray\r\n"]
[301.86763, "o", "   459\t\r\n"]
[301.898148, "o", "   460\t        See Also\r\n"]
[301.928667, "o", "   461\t        --------\r\n"]
[301.959185, "o", "   462\t        Series.array : Get the actual data stored within.\r\n"]
[301.989704, "o", "   463\t        Index.array : Get the actual data stored within.\r\n"]
[302.020222, "o", "   464\t        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[302.050741, "o", "   465\t\r\n"]
[302.081259, "o", "   466\t        Notes\r\n"]
[302.111778, "o", "   467\t        -----\r\n"]
[302.142296, "o", "   468\t        The returned array will be the same up to equality (values equal\r\n"]
[302.172815, "o", "   469\t        in `self` will be equal in the returned array; likewise for values\r\n"]
[302.203333, "o", "   470\t        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[302.233852, "o", "   471\t        dtype may be different. For example, for a category-dtype Series,\r\n"]
[302.26437, "o", "   472\t        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[302.294889, "o", "   473\t        will be lost.\r\n"]
[302.325407, "o", "   474\t\r\n"]
[302.355926, "o", "   475\t        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[302.386444, "o", "   476\t        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[302.416963, "o", "   477\t        in place will modify the data stored in the Series or Index (not that\r\n"]
[302.447481, "o", "   478\t        we recommend doing that).\r\n"]
[302.478, "o", "   479\t\r\n"]
[302.508519, "o", "   480\t        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[302.539037, "o", "   481\t        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[302.569556, "o", "   482\t        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[302.600074, "o", "   483\t        :attr:`Series.array` should be used instead.\r\n"]
[302.630593, "o", "   484\t\r\n"]
[302.661111, "o", "   485\t        This table lays out the different dtypes and default return types of\r\n"]
[302.69163, "o", "   486\t        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[302.722148, "o", "   487\t\r\n"]
[302.752667, "o", "   488\t        ================== ================================\r\n"]
[302.783185, "o", "   489\t        dtype              array type\r\n"]
[302.813704, "o", "   490\t        ================== ================================\r\n"]
[302.844222, "o", "   491\t        category[T]        ndarray[T] (same dtype as input)\r\n"]
[302.874741, "o", "   492\t        period             ndarray[object] (Periods)\r\n"]
[302.905259, "o", "   493\t        interval           ndarray[object] (Intervals)\r\n"]
[302.935778, "o", "   494\t        IntegerNA          ndarray[object]\r\n"]
[302.966296, "o", "   495\t        datetime64[ns]     datetime64[ns]\r\n"]
[302.996815, "o", "   496\t        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[303.027333, "o", "   497\t        ================== ================================\r\n"]
[303.057852, "o", "   498\t\r\n"]
[303.08837, "o", "   499\t        Examples\r\n"]
[303.118889, "o", "   500\t        --------\r\n"]
[303.149407, "o", "   501\t        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[303.179926, "o", "   502\t        >>> ser.to_numpy()\r\n"]
[303.210444, "o", "   503\t        array(['a', 'b', 'a'], dtype=object)\r\n"]
[303.240963, "o", "   504\t\r\n"]
[303.271481, "o", "   505\t        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[303.302, "o", "   506\t        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[303.332519, "o", "   507\t        objects, each with the correct ``tz``.\r\n"]
[303.363037, "o", "   508\t\r\n"]
[303.393556, "o", "   509\t        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[303.424074, "o", "   510\t        >>> ser.to_numpy(dtype=object)\r\n"]
[303.454593, "o", "   511\t        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[303.485111, "o", "   512\t               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[303.51563, "o", "   513\t              dtype=object)\r\n"]
[303.546148, "o", "   514\t\r\n"]
[303.576667, "o", "   515\t        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[303.607185, "o", "   516\t        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[303.637704, "o", "   517\t        info is dropped.\r\n"]
[303.668222, "o", "   518\t\r\n"]
[303.698741, "o", "   519\t        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[303.729259, "o", "   520\t        ... # doctest: +ELLIPSIS\r\n"]
[303.759778, "o", "   521\t        array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\r\n"]
[303.790296, "o", "   522\t              dtype='datetime64[ns]')\r\n"]
[303.820815, "o", "   523\t        \"\"\"\r\n"]
[303.851333, "o", "   524\t        if is_extension_array_dtype(self.dtype):\r\n"]
[303.881852, "o", "   525\t            return self.array.to_numpy(dtype, copy=copy, na_value=na_value, **kwargs)\r\n"]
[303.91237, "o", "   526\t        elif kwargs:\r\n"]
[303.942889, "o", "   527\t            bad_keys = list(kwargs.keys())[0]\r\n"]
[303.973407, "o", "   528\t            raise TypeError(\r\n"]
[304.003926, "o", "   529\t                f\"to_numpy() got an unexpected keyword argument '{bad_keys}'\"\r\n"]
[304.034444, "o", "   530\t            )\r\n"]
[304.064963, "o", "   531\t\r\n"]
[304.095481, "o", "   532\t        if na_value is not lib.no_default:\r\n"]
[304.126, "o", "   533\t            values = self._values\r\n"]
[304.156519, "o", "   534\t            if not can_hold_element(values, na_value):\r\n"]
[304.187037, "o", "   535\t                # if we can't hold the na_value asarray either makes a copy or we\r\n"]
[304.217556, "o", "   536\t                # error before modifying values. The asarray later on thus won't make\r\n"]
[304.248074, "o", "   537\t                # another copy\r\n"]
[304.278593, "o", "   538\t                values = np.asarray(values, dtype=dtype)\r\n"]
[304.309111, "o", "   539\t            else:\r\n"]
[304.33963, "o", "   540\t                values = values.copy()\r\n"]
[304.370148, "o", "   541\t\r\n"]
[304.400667, "o", "   542\t            values[np.asanyarray(self.isna())] = na_value\r\n"]
[304.431185, "o", "   543\t        else:\r\n"]
[304.461704, "o", "   544\t            values = self._values\r\n"]
[304.492222, "o", "   545\t\r\n"]
[304.522741, "o", "   546\t        result = np.asarray(values, dtype=dtype)\r\n"]
[304.553259, "o", "   547\t\r\n"]
[304.583778, "o", "   548\t        if copy and na_value is lib.no_default:\r\n"]
[304.614296, "o", "   549\t            if np.shares_memory(self._values[:2], result[:2]):\r\n"]
[304.644815, "o", "   550\t                # Take slices to improve performance of check\r\n"]
[304.675333, "o", "   551\t                result = result.copy()\r\n"]
[304.705852, "o", "   552\t\r\n"]
[304.73637, "o", "   553\t        return result\r\n"]
[304.766889, "o", "   554\t\r\n"]
[304.797407, "o", "   555\t    @final\r\n"]
[304.827926, "o", "   556\t    @property\r\n"]
[304.858444, "o", "   557\t    def empty(self) -> bool:\r\n"]
[304.888963, "o", "   558\t        return not self.size\r\n"]
[304.919481, "o", "   559\t\r\n"]
[305.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[305.002, "i", "python - << 'PY'\r"]
[305.004, "o", "python - << 'PY'\r\n"]
[305.074667, "o", "\u001b[?2004l\r\n"]
[305.143333, "o", "\u001b[?2004h> import io, re\r\n"]
[305.212, "o", "\u001b[?2004l\r\n"]
[305.280667, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[305.349333, "o", "\u001b[?2004l\r\n"]
[305.418, "o", "\u001b[?2004h> p = Path('pandas/core/base.py')\r\n"]
[305.486667, "o", "\u001b[?2004l\r\n"]
[305.555333, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[305.624, "o", "\u001b[?2004l\r\n"]
[305.692667, "o", "\u001b[?2004h> # Ensure we target the to_numpy function and insert after dtype normalization\r\n"]
[305.761333, "o", "\u001b[?2004l\r\n"]
[305.83, "o", "\u001b[?2004h> pat = (\r\n"]
[305.898667, "o", "\u001b[?2004l\r\n"]
[305.967333, "o", "\u001b[?2004h>     r\"def to_numpy\\([\\s\\S]*?\\):\\n\"  # function header\r\n"]
[306.036, "o", "\u001b[?2004l\r\n"]
[306.104667, "o", "\u001b[?2004h>     r\"([\\s\\S]*?)\"                      # body up to dtype normalization\r\n"]
[306.173333, "o", "\u001b[?2004l\r\n"]
[306.242, "o", "\u001b[?2004h>     r\"\\n\\s*if dtype is not None:\\n\\s*dtype = np\\.dtype\\(dtype\\)\\n\"  # dtype norm\r\n"]
[306.310667, "o", "\u001b[?2004l\r\n"]
[306.379333, "o", "\u001b[?2004h> )\r\n"]
[306.448, "o", "\u001b[?2004l\r\n"]
[306.516667, "o", "\u001b[?2004h> m = re.search(pat, s)\r\n"]
[306.585333, "o", "\u001b[?2004l\r\n"]
[306.654, "o", "\u001b[?2004h> if not m:\r\n"]
[306.722667, "o", "\u001b[?2004l\r\n"]
[306.791333, "o", "\u001b[?2004h>     print('Could not locate insertion point', flush=True)\r\n"]
[306.86, "o", "\u001b[?2004l\r\n"]
[306.928667, "o", "\u001b[?2004h> else:\r\n"]
[306.997333, "o", "\u001b[?2004l\r\n"]
[307.066, "o", "\u001b[?2004h>     insert_point = m.end()\r\n"]
[307.134667, "o", "\u001b[?2004l\r\n"]
[307.203333, "o", "\u001b[?2004h>     fastpath = \"\\n\" + \\\r\n"]
[307.272, "o", "\u001b[?2004l\r\n"]
[307.340667, "o", "\u001b[?2004h>     \"        # Fastpath: when no dtype coercion is requested (or dtype equals\\n\" + \\\r\n"]
[307.409333, "o", "\u001b[?2004l\r\n"]
[307.478, "o", "\u001b[?2004h>     \"        # the underlying NumPy dtype) and na_value is default, avoid\\n\" + \\\r\n"]
[307.546667, "o", "\u001b[?2004l\r\n"]
[307.615333, "o", "\u001b[?2004h>     \"        # manager/asarray overhead by copying/returning the underlying\\n\" + \\\r\n"]
[307.684, "o", "\u001b[?2004l\r\n"]
[307.752667, "o", "\u001b[?2004h>     \"        # ndarray directly.\\n\" + \\\r\n"]
[307.821333, "o", "\u001b[?2004l\r\n"]
[307.89, "o", "\u001b[?2004h>     \"        if na_value is lib.no_default and hasattr(self, '_mgr') and hasattr(self._mgr, 'internal_values'):\\n\" + \\\r\n"]
[307.958667, "o", "\u001b[?2004l\r\n"]
[308.027333, "o", "\u001b[?2004h>     \"            vals = self._mgr.internal_values()\\n\" + \\\r\n"]
[308.096, "o", "\u001b[?2004l\r\n"]
[308.164667, "o", "\u001b[?2004h>     \"            arr = None\\n\" + \\\r\n"]
[308.233333, "o", "\u001b[?2004l\r\n"]
[308.302, "o", "\u001b[?2004h>     \"            import numpy as _np\\n\" + \\\r\n"]
[308.370667, "o", "\u001b[?2004l\r\n"]
[308.439333, "o", "\u001b[?2004h>     \"            if isinstance(vals, _np.ndarray):\\n\" + \\\r\n"]
[308.508, "o", "\u001b[?2004l\r\n"]
[308.576667, "o", "\u001b[?2004h>     \"                arr = vals\\n\" + \\\r\n"]
[308.645333, "o", "\u001b[?2004l\r\n"]
[308.714, "o", "\u001b[?2004h>     \"            else:\\n\" + \\\r\n"]
[308.782667, "o", "\u001b[?2004l\r\n"]
[308.851333, "o", "\u001b[?2004h>     \"                arr = getattr(vals, '_ndarray', None)\\n\" + \\\r\n"]
[308.92, "o", "\u001b[?2004l\r\n"]
[308.988667, "o", "\u001b[?2004h>     \"            if isinstance(arr, _np.ndarray):\\n\" + \\\r\n"]
[309.057333, "o", "\u001b[?2004l\r\n"]
[309.126, "o", "\u001b[?2004h>     \"                if dtype is None or _np.dtype(dtype) == arr.dtype:\\n\" + \\\r\n"]
[309.194667, "o", "\u001b[?2004l\r\n"]
[309.263333, "o", "\u001b[?2004h>     \"                    return arr.copy(order='K') if copy else arr\\n\"\r\n"]
[309.332, "o", "\u001b[?2004l\r\n"]
[309.400667, "o", "\u001b[?2004h>     new_s = s[:insert_point] + fastpath + s[insert_point:]\r\n"]
[309.469333, "o", "\u001b[?2004l\r\n"]
[309.538, "o", "\u001b[?2004h>     p.write_text(new_s)\r\n"]
[309.606667, "o", "\u001b[?2004l\r\n"]
[309.675333, "o", "\u001b[?2004h>     print('Patched fastpath into pandas/core/base.py', flush=True)\r\n"]
[309.744, "o", "\u001b[?2004l\r\n"]
[309.812667, "o", "\u001b[?2004h> PY\r\n"]
[309.881333, "o", "\u001b[?2004l\r\n"]
[310.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[310.002, "i", "python - << 'PY'\r"]
[310.004, "o", "python - << 'PY'\r\n"]
[310.109, "o", "\u001b[?2004l\r\n"]
[310.212, "o", "\u001b[?2004h> import pandas as pd, numpy as np\r\n"]
[310.315, "o", "\u001b[?2004l\r\n"]
[310.418, "o", "\u001b[?2004h> # Sanity: numpy-backed series\r\n"]
[310.521, "o", "\u001b[?2004l\r\n"]
[310.624, "o", "\u001b[?2004h> s = pd.Series(np.random.randn(10).astype('float64'))\r\n"]
[310.727, "o", "\u001b[?2004l\r\n"]
[310.83, "o", "\u001b[?2004h> a0 = s.to_numpy()\r\n"]
[310.933, "o", "\u001b[?2004l\r\n"]
[311.036, "o", "\u001b[?2004h> a1 = s.to_numpy(copy=True)\r\n"]
[311.139, "o", "\u001b[?2004l\r\n"]
[311.242, "o", "\u001b[?2004h> a2 = s.to_numpy(dtype=None, copy=True)\r\n"]
[311.345, "o", "\u001b[?2004l\r\n"]
[311.448, "o", "\u001b[?2004h> a3 = s.to_numpy(dtype='float64', copy=True)\r\n"]
[311.551, "o", "\u001b[?2004l\r\n"]
[311.654, "o", "\u001b[?2004h> print('a0 ndarray:', isinstance(a0, np.ndarray))\r\n"]
[311.757, "o", "\u001b[?2004l\r\n"]
[311.86, "o", "\u001b[?2004h> print('a1 copy base None:', a1.base is None)\r\n"]
[311.963, "o", "\u001b[?2004l\r\n"]
[312.066, "o", "\u001b[?2004h> print('a2 copy base None:', a2.base is None)\r\n"]
[312.169, "o", "\u001b[?2004l\r\n"]
[312.272, "o", "\u001b[?2004h> print('a3 copy base None:', a3.base is None)\r\n"]
[312.375, "o", "\u001b[?2004l\r\n"]
[312.478, "o", "\u001b[?2004h> print('a3 dtype==float64:', a3.dtype == np.dtype('float64'))\r\n"]
[312.581, "o", "\u001b[?2004l\r\n"]
[312.684, "o", "\u001b[?2004h> # Ensure EA still handled via manager\r\n"]
[312.787, "o", "\u001b[?2004l\r\n"]
[312.89, "o", "\u001b[?2004h> s2 = pd.Series(pd.array([1, None, 3], dtype='Int64'))\r\n"]
[312.993, "o", "\u001b[?2004l\r\n"]
[313.096, "o", "\u001b[?2004h> r = s2.to_numpy(copy=True)\r\n"]
[313.199, "o", "\u001b[?2004l\r\n"]
[313.302, "o", "\u001b[?2004h> print('EA to_numpy dtype:', r.dtype)\r\n"]
[313.405, "o", "\u001b[?2004l\r\n"]
[313.508, "o", "\u001b[?2004h> # Ensure na_value param disables fastpath\r\n"]
[313.611, "o", "\u001b[?2004l\r\n"]
[313.714, "o", "\u001b[?2004h> r2 = s.to_numpy(na_value=999.0, copy=True)\r\n"]
[313.817, "o", "\u001b[?2004l\r\n"]
[313.92, "o", "\u001b[?2004h> print('na_value provided dtype:', r2.dtype, 'contains 999? ', (r2==999.0).any())\r\n"]
[314.023, "o", "\u001b[?2004l\r\n"]
[314.126, "o", "\u001b[?2004h> PY\r\n"]
[314.229, "o", "\u001b[?2004l\r\n"]
[314.332, "o", "a0 ndarray: True\r\n"]
[314.435, "o", "a1 copy base None: True\r\n"]
[314.538, "o", "a2 copy base None: True\r\n"]
[314.641, "o", "a3 copy base None: True\r\n"]
[314.744, "o", "a3 dtype==float64: True\r\n"]
[314.847, "o", "EA to_numpy dtype: object\r\n"]
[315.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[315.002, "i", "cd asv_bench\r"]
[315.004, "o", "cd asv_bench\r\n"]
[315.006, "o", "\u001b[?2004l\r\n"]
[320.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[320.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[320.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[320.624, "o", "\u001b[?2004l\r\n"]
[321.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[321.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[322.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[323.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[323.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                      1.28\u00b10\u03bcs\r\n"]
[324.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                  368\u00b16\u03bcs\r\n"]
[325.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[325.002, "i", "grep -R \"def as_array\\(\" -n pandas/core | head -n 20\r"]
[325.004, "o", "grep -R \"def as_array\\(\" -n pandas/core | head -n 20\r\n"]
[327.478, "o", "\u001b[?2004l\r\n"]
[330.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[330.002, "i", "grep -R \"as_array\\(\" -n pandas/core | head -n 50\r"]
[330.004, "o", "grep -R \"as_array\\(\" -n pandas/core | head -n 50\r\n"]
[332.478, "o", "\u001b[?2004l\r\n"]
[335.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[335.002, "i", "sed -n '1,280p' pandas/core/internals/managers.py\r"]
[335.004, "o", "sed -n '1,280p' pandas/core/internals/managers.py\r\n"]
[337.478, "o", "\u001b[?2004l\r\n"]
[340.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[340.002, "i", "sed -n '280,720p' pandas/core/internals/managers.py\r"]
[340.004, "o", "sed -n '280,720p' pandas/core/internals/managers.py\r\n"]
[342.478, "o", "\u001b[?2004l\r\n"]
[345.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[345.002, "i", "sed -n '720,1160p' pandas/core/internals/managers.py\r"]
[345.004, "o", "sed -n '720,1160p' pandas/core/internals/managers.py\r\n"]
[347.478, "o", "\u001b[?2004l\r\n"]
[350.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[350.002, "i", "sed -n '1160,2120p' pandas/core/internals/managers.py\r"]
[350.004, "o", "sed -n '1160,2120p' pandas/core/internals/managers.py\r\n"]
[352.478, "o", "\u001b[?2004l\r\n"]
[355.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[355.002, "i", "grep -n \"class (BlockManager|SingleBlockManager)\" -n pandas/core/internals/managers.py || true\r"]
[355.004, "o", "grep -n \"class (BlockManager|SingleBlockManager)\" -n pandas/core/internals/managers.py || true\r\n"]
[357.478, "o", "\u001b[?2004l\r\n"]
[360.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[360.002, "i", "python - << 'PY'\r"]
[360.004, "o", "python - << 'PY'\r\n"]
[360.1296, "o", "\u001b[?2004l\r\n"]
[360.2532, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[360.3768, "o", "\u001b[?2004l\r\n"]
[360.5004, "o", "\u001b[?2004h> import re\r\n"]
[360.624, "o", "\u001b[?2004l\r\n"]
[360.7476, "o", "\u001b[?2004h> p = Path('pandas/core/internals/managers.py')\r\n"]
[360.8712, "o", "\u001b[?2004l\r\n"]
[360.9948, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[361.1184, "o", "\u001b[?2004l\r\n"]
[361.242, "o", "\u001b[?2004h> # Try to locate SingleBlockManager.as_array or BlockManager.as_array\r\n"]
[361.3656, "o", "\u001b[?2004l\r\n"]
[361.4892, "o", "\u001b[?2004h> m = re.search(r\"class\\s+SingleBlockManager[\\s\\S]*?\\n\\s*def\\s+as_array\\(self,\\s*dtype=.*?\\):\", s)\r\n"]
[361.6128, "o", "\u001b[?2004l\r\n"]
[361.7364, "o", "\u001b[?2004h> cls = 'SingleBlockManager'\r\n"]
[361.86, "o", "\u001b[?2004l\r\n"]
[361.9836, "o", "\u001b[?2004h> if not m:\r\n"]
[362.1072, "o", "\u001b[?2004l\r\n"]
[362.2308, "o", "\u001b[?2004h>     m = re.search(r\"class\\s+BlockManager[\\s\\S]*?\\n\\s*def\\s+as_array\\(self,\\s*dtype=.*?\\):\", s)\r\n"]
[362.3544, "o", "\u001b[?2004l\r\n"]
[362.478, "o", "\u001b[?2004h>     cls = 'BlockManager'\r\n"]
[362.6016, "o", "\u001b[?2004l\r\n"]
[362.7252, "o", "\u001b[?2004h> print('found in class:', cls if m else 'not found')\r\n"]
[362.8488, "o", "\u001b[?2004l\r\n"]
[362.9724, "o", "\u001b[?2004h> if m:\r\n"]
[363.096, "o", "\u001b[?2004l\r\n"]
[363.2196, "o", "\u001b[?2004h>     start = m.start()\r\n"]
[363.3432, "o", "\u001b[?2004l\r\n"]
[363.4668, "o", "\u001b[?2004h>     print('context:\\n', s[start:start+400])\r\n"]
[363.5904, "o", "\u001b[?2004l\r\n"]
[363.714, "o", "\u001b[?2004h> PY\r\n"]
[363.8376, "o", "\u001b[?2004l\r\n"]
[363.9612, "o", "Traceback (most recent call last):\r\n"]
[364.0848, "o", "  File \"<stdin>\", line 4, in <module>\r\n"]
[364.2084, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1236, in read_text\r\n"]
[364.332, "o", "    with self.open(mode='r', encoding=encoding, errors=errors) as f:\r\n"]
[364.4556, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1222, in open\r\n"]
[364.5792, "o", "    return io.open(self, mode, buffering, encoding, errors, newline,\r\n"]
[364.7028, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/pathlib.py\", line 1078, in _opener\r\n"]
[364.8264, "o", "    return self._accessor.open(self, flags, mode)\r\n"]
[365.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[365.002, "i", "nl -ba pandas/core/base.py | sed -n '420,520p'\r"]
[365.004, "o", "nl -ba pandas/core/base.py | sed -n '420,520p'\r\n"]
[367.478, "o", "\u001b[?2004l\r\n"]
[370.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[370.002, "i", "sed -n '500,700p' pandas/core/base.py\r"]
[370.004, "o", "sed -n '500,700p' pandas/core/base.py\r\n"]
[372.478, "o", "\u001b[?2004l\r\n"]
[375.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[375.002, "i", "cd /workspace/repo\r"]
[375.004, "o", "cd /workspace/repo\r\n"]
[375.006, "o", "\u001b[?2004l\r\n"]
[380.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[380.002, "i", "grep -n \"def to_numpy(\" pandas/core/base.py\r"]
[380.004, "o", "grep -n \"def to_numpy(\" pandas/core/base.py\r\n"]
[382.478, "o", "\u001b[?2004l\r\n"]
[385.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[385.002, "i", "sed -n '420,540p' pandas/core/base.py\r"]
[385.004, "o", "sed -n '420,540p' pandas/core/base.py\r\n"]
[385.046525, "o", "\u001b[?2004l\r\n"]
[385.087049, "o", "        Categories (2, object): ['a', 'b']\r\n"]
[385.127574, "o", "        \"\"\"\r\n"]
[385.168098, "o", "        raise AbstractMethodError(self)\r\n"]
[385.208623, "o", "\r\n"]
[385.249148, "o", "    @final\r\n"]
[385.289672, "o", "    def to_numpy(\r\n"]
[385.330197, "o", "        self,\r\n"]
[385.370721, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[385.411246, "o", "        copy: bool = False,\r\n"]
[385.45177, "o", "        na_value: object = lib.no_default,\r\n"]
[385.492295, "o", "        **kwargs,\r\n"]
[385.53282, "o", "    ) -> np.ndarray:\r\n"]
[385.573344, "o", "        \"\"\"\r\n"]
[385.613869, "o", "        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[385.654393, "o", "\r\n"]
[385.694918, "o", "        Parameters\r\n"]
[385.735443, "o", "        ----------\r\n"]
[385.775967, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[385.816492, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[385.857016, "o", "        copy : bool, default False\r\n"]
[385.897541, "o", "            Whether to ensure that the returned value is not a view on\r\n"]
[385.938066, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[385.97859, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[386.019115, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[386.059639, "o", "        na_value : Any, optional\r\n"]
[386.100164, "o", "            The value to use for missing values. The default value depends\r\n"]
[386.140689, "o", "            on `dtype` and the type of the array.\r\n"]
[386.181213, "o", "\r\n"]
[386.221738, "o", "            .. versionadded:: 1.0.0\r\n"]
[386.262262, "o", "\r\n"]
[386.302787, "o", "        **kwargs\r\n"]
[386.343311, "o", "            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[386.383836, "o", "            of the underlying array (for extension arrays).\r\n"]
[386.424361, "o", "\r\n"]
[386.464885, "o", "            .. versionadded:: 1.0.0\r\n"]
[386.50541, "o", "\r\n"]
[386.545934, "o", "        Returns\r\n"]
[386.586459, "o", "        -------\r\n"]
[386.626984, "o", "        numpy.ndarray\r\n"]
[386.667508, "o", "\r\n"]
[386.708033, "o", "        See Also\r\n"]
[386.748557, "o", "        --------\r\n"]
[386.789082, "o", "        Series.array : Get the actual data stored within.\r\n"]
[386.829607, "o", "        Index.array : Get the actual data stored within.\r\n"]
[386.870131, "o", "        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[386.910656, "o", "\r\n"]
[386.95118, "o", "        Notes\r\n"]
[386.991705, "o", "        -----\r\n"]
[387.03223, "o", "        The returned array will be the same up to equality (values equal\r\n"]
[387.072754, "o", "        in `self` will be equal in the returned array; likewise for values\r\n"]
[387.113279, "o", "        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[387.153803, "o", "        dtype may be different. For example, for a category-dtype Series,\r\n"]
[387.194328, "o", "        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[387.234852, "o", "        will be lost.\r\n"]
[387.275377, "o", "\r\n"]
[387.315902, "o", "        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[387.356426, "o", "        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[387.396951, "o", "        in place will modify the data stored in the Series or Index (not that\r\n"]
[387.437475, "o", "        we recommend doing that).\r\n"]
[387.478, "o", "\r\n"]
[387.518525, "o", "        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[387.559049, "o", "        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[387.599574, "o", "        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[387.640098, "o", "        :attr:`Series.array` should be used instead.\r\n"]
[387.680623, "o", "\r\n"]
[387.721148, "o", "        This table lays out the different dtypes and default return types of\r\n"]
[387.761672, "o", "        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[387.802197, "o", "\r\n"]
[387.842721, "o", "        ================== ================================\r\n"]
[387.883246, "o", "        dtype              array type\r\n"]
[387.92377, "o", "        ================== ================================\r\n"]
[387.964295, "o", "        category[T]        ndarray[T] (same dtype as input)\r\n"]
[388.00482, "o", "        period             ndarray[object] (Periods)\r\n"]
[388.045344, "o", "        interval           ndarray[object] (Intervals)\r\n"]
[388.085869, "o", "        IntegerNA          ndarray[object]\r\n"]
[388.126393, "o", "        datetime64[ns]     datetime64[ns]\r\n"]
[388.166918, "o", "        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[388.207443, "o", "        ================== ================================\r\n"]
[388.247967, "o", "\r\n"]
[388.288492, "o", "        Examples\r\n"]
[388.329016, "o", "        --------\r\n"]
[388.369541, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[388.410066, "o", "        >>> ser.to_numpy()\r\n"]
[388.45059, "o", "        array(['a', 'b', 'a'], dtype=object)\r\n"]
[388.491115, "o", "\r\n"]
[388.531639, "o", "        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[388.572164, "o", "        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[388.612689, "o", "        objects, each with the correct ``tz``.\r\n"]
[388.653213, "o", "\r\n"]
[388.693738, "o", "        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[388.734262, "o", "        >>> ser.to_numpy(dtype=object)\r\n"]
[388.774787, "o", "        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[388.815311, "o", "               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[388.855836, "o", "              dtype=object)\r\n"]
[388.896361, "o", "\r\n"]
[388.936885, "o", "        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[388.97741, "o", "        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[389.017934, "o", "        info is dropped.\r\n"]
[389.058459, "o", "\r\n"]
[389.098984, "o", "        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[389.139508, "o", "        ... # doctest: +ELLIPSIS\r\n"]
[389.180033, "o", "        array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\r\n"]
[389.220557, "o", "              dtype='datetime64[ns]')\r\n"]
[389.261082, "o", "        \"\"\"\r\n"]
[389.301607, "o", "        if is_extension_array_dtype(self.dtype):\r\n"]
[389.342131, "o", "            return self.array.to_numpy(dtype, copy=copy, na_value=na_value, **kwargs)\r\n"]
[389.382656, "o", "        elif kwargs:\r\n"]
[389.42318, "o", "            bad_keys = list(kwargs.keys())[0]\r\n"]
[389.463705, "o", "            raise TypeError(\r\n"]
[389.50423, "o", "                f\"to_numpy() got an unexpected keyword argument '{bad_keys}'\"\r\n"]
[389.544754, "o", "            )\r\n"]
[389.585279, "o", "\r\n"]
[389.625803, "o", "        if na_value is not lib.no_default:\r\n"]
[389.666328, "o", "            values = self._values\r\n"]
[389.706852, "o", "            if not can_hold_element(values, na_value):\r\n"]
[389.747377, "o", "                # if we can't hold the na_value asarray either makes a copy or we\r\n"]
[389.787902, "o", "                # error before modifying values. The asarray later on thus won't make\r\n"]
[389.828426, "o", "                # another copy\r\n"]
[389.868951, "o", "                values = np.asarray(values, dtype=dtype)\r\n"]
[389.909475, "o", "            else:\r\n"]
[390.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[390.002, "i", "python - << 'PY'\r"]
[390.004, "o", "python - << 'PY'\r\n"]
[390.109, "o", "\u001b[?2004l\r\n"]
[390.212, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[390.315, "o", "\u001b[?2004l\r\n"]
[390.418, "o", "\u001b[?2004h> p = Path('pandas/core/base.py')\r\n"]
[390.521, "o", "\u001b[?2004l\r\n"]
[390.624, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[390.727, "o", "\u001b[?2004l\r\n"]
[390.83, "o", "\u001b[?2004h> needle = 'result = self._mgr.as_array'\r\n"]
[390.933, "o", "\u001b[?2004l\r\n"]
[391.036, "o", "\u001b[?2004h> idx = s.find(needle)\r\n"]
[391.139, "o", "\u001b[?2004l\r\n"]
[391.242, "o", "\u001b[?2004h> if idx == -1:\r\n"]
[391.345, "o", "\u001b[?2004l\r\n"]
[391.448, "o", "\u001b[?2004h>     print('insertion anchor not found')\r\n"]
[391.551, "o", "\u001b[?2004l\r\n"]
[391.654, "o", "\u001b[?2004h> else:\r\n"]
[391.757, "o", "\u001b[?2004l\r\n"]
[391.86, "o", "\u001b[?2004h>     # Find start of the line where result assignment occurs\r\n"]
[391.963, "o", "\u001b[?2004l\r\n"]
[392.066, "o", "\u001b[?2004h>     line_start = s.rfind('\\n', 0, idx) + 1\r\n"]
[392.169, "o", "\u001b[?2004l\r\n"]
[392.272, "o", "\u001b[?2004h>     indent = s[line_start:idx]\r\n"]
[392.375, "o", "\u001b[?2004l\r\n"]
[392.478, "o", "\u001b[?2004h>     fastpath = (\r\n"]
[392.581, "o", "\u001b[?2004l\r\n"]
[392.684, "o", "\u001b[?2004h>         f\"{indent}# Fastpath: NumPy-backed data with no dtype coercion and default na_value\\n\"\r\n"]
[392.787, "o", "\u001b[?2004l\r\n"]
[392.89, "o", "\u001b[?2004h>         f\"{indent}vals = self._mgr.internal_values()\\n\"\r\n"]
[392.993, "o", "\u001b[?2004l\r\n"]
[393.096, "o", "\u001b[?2004h>         f\"{indent}arr = vals if isinstance(vals, __import__('numpy').ndarray) else getattr(vals, '_ndarray', None)\\n\"\r\n"]
[393.199, "o", "\u001b[?2004l\r\n"]
[393.302, "o", "\u001b[?2004h>         f\"{indent}if isinstance(arr, __import__('numpy').ndarray):\\n\"\r\n"]
[393.405, "o", "\u001b[?2004l\r\n"]
[393.508, "o", "\u001b[?2004h>         f\"{indent}    if na_value is lib.no_default and (dtype is None or __import__('numpy').dtype(dtype) == arr.dtype):\\n\"\r\n"]
[393.611, "o", "\u001b[?2004l\r\n"]
[393.714, "o", "\u001b[?2004h>         f\"{indent}        return arr.copy(order='K') if copy else arr\\n\"\r\n"]
[393.817, "o", "\u001b[?2004l\r\n"]
[393.92, "o", "\u001b[?2004h>     )\r\n"]
[394.023, "o", "\u001b[?2004l\r\n"]
[394.126, "o", "\u001b[?2004h>     new_s = s[:line_start] + fastpath + s[line_start:]\r\n"]
[394.229, "o", "\u001b[?2004l\r\n"]
[394.332, "o", "\u001b[?2004h>     p.write_text(new_s)\r\n"]
[394.435, "o", "\u001b[?2004l\r\n"]
[394.538, "o", "\u001b[?2004h>     print('patched base.py fastpath inserted')\r\n"]
[394.641, "o", "\u001b[?2004l\r\n"]
[394.744, "o", "\u001b[?2004h> PY\r\n"]
[394.847, "o", "\u001b[?2004l\r\n"]
[395.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[395.002, "i", "python - << 'PY'\r"]
[395.004, "o", "python - << 'PY'\r\n"]
[395.1296, "o", "\u001b[?2004l\r\n"]
[395.2532, "o", "\u001b[?2004h> import pandas as pd, numpy as np\r\n"]
[395.3768, "o", "\u001b[?2004l\r\n"]
[395.5004, "o", "\u001b[?2004h> # Sanity checks for numpy-backed Series\r\n"]
[395.624, "o", "\u001b[?2004l\r\n"]
[395.7476, "o", "\u001b[?2004h> s = pd.Series(np.random.randn(10).astype('float64'))\r\n"]
[395.8712, "o", "\u001b[?2004l\r\n"]
[395.9948, "o", "\u001b[?2004h> a = s.to_numpy()\r\n"]
[396.1184, "o", "\u001b[?2004l\r\n"]
[396.242, "o", "\u001b[?2004h> b = s.to_numpy(copy=True)\r\n"]
[396.3656, "o", "\u001b[?2004l\r\n"]
[396.4892, "o", "\u001b[?2004h> c = s.to_numpy(dtype='float64', copy=True)\r\n"]
[396.6128, "o", "\u001b[?2004l\r\n"]
[396.7364, "o", "\u001b[?2004h> print('a ndarray:', isinstance(a, np.ndarray))\r\n"]
[396.86, "o", "\u001b[?2004l\r\n"]
[396.9836, "o", "\u001b[?2004h> print('b copy base None:', b.base is None)\r\n"]
[397.1072, "o", "\u001b[?2004l\r\n"]
[397.2308, "o", "\u001b[?2004h> print('c dtype matches and copy:', c.dtype == np.float64, c.base is None)\r\n"]
[397.3544, "o", "\u001b[?2004l\r\n"]
[397.478, "o", "\u001b[?2004h> # EA path should still return object ndarray\r\n"]
[397.6016, "o", "\u001b[?2004l\r\n"]
[397.7252, "o", "\u001b[?2004h> s2 = pd.Series(pd.array([1, None, 3], dtype='Int64'))\r\n"]
[397.8488, "o", "\u001b[?2004l\r\n"]
[397.9724, "o", "\u001b[?2004h> r = s2.to_numpy(copy=True)\r\n"]
[398.096, "o", "\u001b[?2004l\r\n"]
[398.2196, "o", "\u001b[?2004h> print('EA ndarray dtype:', r.dtype)\r\n"]
[398.3432, "o", "\u001b[?2004l\r\n"]
[398.4668, "o", "\u001b[?2004h> # na_value provided should bypass fastpath\r\n"]
[398.5904, "o", "\u001b[?2004l\r\n"]
[398.714, "o", "\u001b[?2004h> r2 = s.to_numpy(na_value=999.0, copy=True)\r\n"]
[398.8376, "o", "\u001b[?2004l\r\n"]
[398.9612, "o", "\u001b[?2004h> print('na_value provided dtype:', r2.dtype, 'contains 999?', (r2==999.0).any())\r\n"]
[399.0848, "o", "\u001b[?2004l\r\n"]
[399.2084, "o", "\u001b[?2004h> PY\r\n"]
[399.332, "o", "\u001b[?2004l\r\n"]
[399.4556, "o", "a ndarray: True\r\n"]
[399.5792, "o", "b copy base None: True\r\n"]
[399.7028, "o", "c dtype matches and copy: True True\r\n"]
[399.8264, "o", "EA ndarray dtype: object\r\n"]
[400.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[400.002, "i", "cd asv_bench\r"]
[400.004, "o", "cd asv_bench\r\n"]
[400.006, "o", "\u001b[?2004l\r\n"]
[405.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[405.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[405.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[405.624, "o", "\u001b[?2004l\r\n"]
[406.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[406.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[407.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[408.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[408.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                   1.27\u00b10.01\u03bcs\r\n"]
[409.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                 383\u00b120\u03bcs\r\n"]
[410.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[410.002, "i", "cd /workspace/repo\r"]
[410.004, "o", "cd /workspace/repo\r\n"]
[410.006, "o", "\u001b[?2004l\r\n"]
[415.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[415.002, "i", "sed -n '420,740p' pandas/core/base.py | sed -n '1,200p'\r"]
[415.004, "o", "sed -n '420,740p' pandas/core/base.py | sed -n '1,200p'\r\n"]
[415.030597, "o", "\u001b[?2004l\r\n"]
[415.055194, "o", "        Categories (2, object): ['a', 'b']\r\n"]
[415.079791, "o", "        \"\"\"\r\n"]
[415.104388, "o", "        raise AbstractMethodError(self)\r\n"]
[415.128985, "o", "\r\n"]
[415.153582, "o", "    @final\r\n"]
[415.178179, "o", "    def to_numpy(\r\n"]
[415.202776, "o", "        self,\r\n"]
[415.227373, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[415.25197, "o", "        copy: bool = False,\r\n"]
[415.276567, "o", "        na_value: object = lib.no_default,\r\n"]
[415.301164, "o", "        **kwargs,\r\n"]
[415.325761, "o", "    ) -> np.ndarray:\r\n"]
[415.350358, "o", "        \"\"\"\r\n"]
[415.374955, "o", "        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[415.399552, "o", "\r\n"]
[415.424149, "o", "        Parameters\r\n"]
[415.448746, "o", "        ----------\r\n"]
[415.473343, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[415.49794, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[415.522537, "o", "        copy : bool, default False\r\n"]
[415.547134, "o", "            Whether to ensure that the returned value is not a view on\r\n"]
[415.571731, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[415.596328, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[415.620925, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[415.645522, "o", "        na_value : Any, optional\r\n"]
[415.670119, "o", "            The value to use for missing values. The default value depends\r\n"]
[415.694716, "o", "            on `dtype` and the type of the array.\r\n"]
[415.719313, "o", "\r\n"]
[415.74391, "o", "            .. versionadded:: 1.0.0\r\n"]
[415.768507, "o", "\r\n"]
[415.793104, "o", "        **kwargs\r\n"]
[415.817701, "o", "            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[415.842299, "o", "            of the underlying array (for extension arrays).\r\n"]
[415.866896, "o", "\r\n"]
[415.891493, "o", "            .. versionadded:: 1.0.0\r\n"]
[415.91609, "o", "\r\n"]
[415.940687, "o", "        Returns\r\n"]
[415.965284, "o", "        -------\r\n"]
[415.989881, "o", "        numpy.ndarray\r\n"]
[416.014478, "o", "\r\n"]
[416.039075, "o", "        See Also\r\n"]
[416.063672, "o", "        --------\r\n"]
[416.088269, "o", "        Series.array : Get the actual data stored within.\r\n"]
[416.112866, "o", "        Index.array : Get the actual data stored within.\r\n"]
[416.137463, "o", "        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[416.16206, "o", "\r\n"]
[416.186657, "o", "        Notes\r\n"]
[416.211254, "o", "        -----\r\n"]
[416.235851, "o", "        The returned array will be the same up to equality (values equal\r\n"]
[416.260448, "o", "        in `self` will be equal in the returned array; likewise for values\r\n"]
[416.285045, "o", "        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[416.309642, "o", "        dtype may be different. For example, for a category-dtype Series,\r\n"]
[416.334239, "o", "        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[416.358836, "o", "        will be lost.\r\n"]
[416.383433, "o", "\r\n"]
[416.40803, "o", "        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[416.432627, "o", "        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[416.457224, "o", "        in place will modify the data stored in the Series or Index (not that\r\n"]
[416.481821, "o", "        we recommend doing that).\r\n"]
[416.506418, "o", "\r\n"]
[416.531015, "o", "        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[416.555612, "o", "        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[416.580209, "o", "        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[416.604806, "o", "        :attr:`Series.array` should be used instead.\r\n"]
[416.629403, "o", "\r\n"]
[416.654, "o", "        This table lays out the different dtypes and default return types of\r\n"]
[416.678597, "o", "        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[416.703194, "o", "\r\n"]
[416.727791, "o", "        ================== ================================\r\n"]
[416.752388, "o", "        dtype              array type\r\n"]
[416.776985, "o", "        ================== ================================\r\n"]
[416.801582, "o", "        category[T]        ndarray[T] (same dtype as input)\r\n"]
[416.826179, "o", "        period             ndarray[object] (Periods)\r\n"]
[416.850776, "o", "        interval           ndarray[object] (Intervals)\r\n"]
[416.875373, "o", "        IntegerNA          ndarray[object]\r\n"]
[416.89997, "o", "        datetime64[ns]     datetime64[ns]\r\n"]
[416.924567, "o", "        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[416.949164, "o", "        ================== ================================\r\n"]
[416.973761, "o", "\r\n"]
[416.998358, "o", "        Examples\r\n"]
[417.022955, "o", "        --------\r\n"]
[417.047552, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[417.072149, "o", "        >>> ser.to_numpy()\r\n"]
[417.096746, "o", "        array(['a', 'b', 'a'], dtype=object)\r\n"]
[417.121343, "o", "\r\n"]
[417.14594, "o", "        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[417.170537, "o", "        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[417.195134, "o", "        objects, each with the correct ``tz``.\r\n"]
[417.219731, "o", "\r\n"]
[417.244328, "o", "        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[417.268925, "o", "        >>> ser.to_numpy(dtype=object)\r\n"]
[417.293522, "o", "        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[417.318119, "o", "               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[417.342716, "o", "              dtype=object)\r\n"]
[417.367313, "o", "\r\n"]
[417.39191, "o", "        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[417.416507, "o", "        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[417.441104, "o", "        info is dropped.\r\n"]
[417.465701, "o", "\r\n"]
[417.490299, "o", "        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[417.514896, "o", "        ... # doctest: +ELLIPSIS\r\n"]
[417.539493, "o", "        array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\r\n"]
[417.56409, "o", "              dtype='datetime64[ns]')\r\n"]
[417.588687, "o", "        \"\"\"\r\n"]
[417.613284, "o", "        if is_extension_array_dtype(self.dtype):\r\n"]
[417.637881, "o", "            return self.array.to_numpy(dtype, copy=copy, na_value=na_value, **kwargs)\r\n"]
[417.662478, "o", "        elif kwargs:\r\n"]
[417.687075, "o", "            bad_keys = list(kwargs.keys())[0]\r\n"]
[417.711672, "o", "            raise TypeError(\r\n"]
[417.736269, "o", "                f\"to_numpy() got an unexpected keyword argument '{bad_keys}'\"\r\n"]
[417.760866, "o", "            )\r\n"]
[417.785463, "o", "\r\n"]
[417.81006, "o", "        if na_value is not lib.no_default:\r\n"]
[417.834657, "o", "            values = self._values\r\n"]
[417.859254, "o", "            if not can_hold_element(values, na_value):\r\n"]
[417.883851, "o", "                # if we can't hold the na_value asarray either makes a copy or we\r\n"]
[417.908448, "o", "                # error before modifying values. The asarray later on thus won't make\r\n"]
[417.933045, "o", "                # another copy\r\n"]
[417.957642, "o", "                values = np.asarray(values, dtype=dtype)\r\n"]
[417.982239, "o", "            else:\r\n"]
[418.006836, "o", "                values = values.copy()\r\n"]
[418.031433, "o", "\r\n"]
[418.05603, "o", "            values[np.asanyarray(self.isna())] = na_value\r\n"]
[418.080627, "o", "        else:\r\n"]
[418.105224, "o", "            values = self._values\r\n"]
[418.129821, "o", "\r\n"]
[418.154418, "o", "        result = np.asarray(values, dtype=dtype)\r\n"]
[418.179015, "o", "\r\n"]
[418.203612, "o", "        if copy and na_value is lib.no_default:\r\n"]
[418.228209, "o", "            if np.shares_memory(self._values[:2], result[:2]):\r\n"]
[418.252806, "o", "                # Take slices to improve performance of check\r\n"]
[418.277403, "o", "                result = result.copy()\r\n"]
[418.302, "o", "\r\n"]
[418.326597, "o", "        return result\r\n"]
[418.351194, "o", "\r\n"]
[418.375791, "o", "    @final\r\n"]
[418.400388, "o", "    @property\r\n"]
[418.424985, "o", "    def empty(self) -> bool:\r\n"]
[418.449582, "o", "        return not self.size\r\n"]
[418.474179, "o", "\r\n"]
[418.498776, "o", "    def max(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[418.523373, "o", "        \"\"\"\r\n"]
[418.54797, "o", "        Return the maximum value of the Index.\r\n"]
[418.572567, "o", "\r\n"]
[418.597164, "o", "        Parameters\r\n"]
[418.621761, "o", "        ----------\r\n"]
[418.646358, "o", "        axis : int, optional\r\n"]
[418.670955, "o", "            For compatibility with NumPy. Only 0 or None are allowed.\r\n"]
[418.695552, "o", "        skipna : bool, default True\r\n"]
[418.720149, "o", "            Exclude NA/null values when showing the result.\r\n"]
[418.744746, "o", "        *args, **kwargs\r\n"]
[418.769343, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[418.79394, "o", "\r\n"]
[418.818537, "o", "        Returns\r\n"]
[418.843134, "o", "        -------\r\n"]
[418.867731, "o", "        scalar\r\n"]
[418.892328, "o", "            Maximum value.\r\n"]
[418.916925, "o", "\r\n"]
[418.941522, "o", "        See Also\r\n"]
[418.966119, "o", "        --------\r\n"]
[418.990716, "o", "        Index.min : Return the minimum value in an Index.\r\n"]
[419.015313, "o", "        Series.max : Return the maximum value in a Series.\r\n"]
[419.03991, "o", "        DataFrame.max : Return the maximum values in a DataFrame.\r\n"]
[419.064507, "o", "\r\n"]
[419.089104, "o", "        Examples\r\n"]
[419.113701, "o", "        --------\r\n"]
[419.138299, "o", "        >>> idx = pd.Index([3, 2, 1])\r\n"]
[419.162896, "o", "        >>> idx.max()\r\n"]
[419.187493, "o", "        3\r\n"]
[419.21209, "o", "\r\n"]
[419.236687, "o", "        >>> idx = pd.Index(['c', 'b', 'a'])\r\n"]
[419.261284, "o", "        >>> idx.max()\r\n"]
[419.285881, "o", "        'c'\r\n"]
[419.310478, "o", "\r\n"]
[419.335075, "o", "        For a MultiIndex, the maximum is determined lexicographically.\r\n"]
[419.359672, "o", "\r\n"]
[419.384269, "o", "        >>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])\r\n"]
[419.408866, "o", "        >>> idx.max()\r\n"]
[419.433463, "o", "        ('b', 2)\r\n"]
[419.45806, "o", "        \"\"\"\r\n"]
[419.482657, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[419.507254, "o", "        nv.validate_max(args, kwargs)\r\n"]
[419.531851, "o", "        return nanops.nanmax(self._values, skipna=skipna)\r\n"]
[419.556448, "o", "\r\n"]
[419.581045, "o", "    @doc(op=\"max\", oppose=\"min\", value=\"largest\")\r\n"]
[419.605642, "o", "    def argmax(\r\n"]
[419.630239, "o", "        self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs\r\n"]
[419.654836, "o", "    ) -> int:\r\n"]
[419.679433, "o", "        \"\"\"\r\n"]
[419.70403, "o", "        Return int position of the {value} value in the Series.\r\n"]
[419.728627, "o", "\r\n"]
[419.753224, "o", "        If the {op}imum is achieved in multiple locations,\r\n"]
[419.777821, "o", "        the first row position is returned.\r\n"]
[419.802418, "o", "\r\n"]
[419.827015, "o", "        Parameters\r\n"]
[419.851612, "o", "        ----------\r\n"]
[419.876209, "o", "        axis : {{None}}\r\n"]
[419.900806, "o", "            Unused. Parameter needed for compatibility with DataFrame.\r\n"]
[419.925403, "o", "        skipna : bool, default True\r\n"]
[420.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[420.002, "i", "sed -n '740,1060p' pandas/core/base.py | sed -n '1,200p'\r"]
[420.004, "o", "sed -n '740,1060p' pandas/core/base.py | sed -n '1,200p'\r\n"]
[420.030597, "o", "\u001b[?2004l\r\n"]
[420.055194, "o", "        Return a list of the values.\r\n"]
[420.079791, "o", "\r\n"]
[420.104388, "o", "        These are each a scalar type, which is a Python scalar\r\n"]
[420.128985, "o", "        (for str, int, float) or a pandas scalar\r\n"]
[420.153582, "o", "        (for Timestamp/Timedelta/Interval/Period)\r\n"]
[420.178179, "o", "\r\n"]
[420.202776, "o", "        Returns\r\n"]
[420.227373, "o", "        -------\r\n"]
[420.25197, "o", "        list\r\n"]
[420.276567, "o", "\r\n"]
[420.301164, "o", "        See Also\r\n"]
[420.325761, "o", "        --------\r\n"]
[420.350358, "o", "        numpy.ndarray.tolist : Return the array as an a.ndim-levels deep\r\n"]
[420.374955, "o", "            nested list of Python scalars.\r\n"]
[420.399552, "o", "        \"\"\"\r\n"]
[420.424149, "o", "        return self._values.tolist()\r\n"]
[420.448746, "o", "\r\n"]
[420.473343, "o", "    to_list = tolist\r\n"]
[420.49794, "o", "\r\n"]
[420.522537, "o", "    def __iter__(self) -> Iterator:\r\n"]
[420.547134, "o", "        \"\"\"\r\n"]
[420.571731, "o", "        Return an iterator of the values.\r\n"]
[420.596328, "o", "\r\n"]
[420.620925, "o", "        These are each a scalar type, which is a Python scalar\r\n"]
[420.645522, "o", "        (for str, int, float) or a pandas scalar\r\n"]
[420.670119, "o", "        (for Timestamp/Timedelta/Interval/Period)\r\n"]
[420.694716, "o", "\r\n"]
[420.719313, "o", "        Returns\r\n"]
[420.74391, "o", "        -------\r\n"]
[420.768507, "o", "        iterator\r\n"]
[420.793104, "o", "        \"\"\"\r\n"]
[420.817701, "o", "        # We are explicitly making element iterators.\r\n"]
[420.842299, "o", "        if not isinstance(self._values, np.ndarray):\r\n"]
[420.866896, "o", "            # Check type instead of dtype to catch DTA/TDA\r\n"]
[420.891493, "o", "            return iter(self._values)\r\n"]
[420.91609, "o", "        else:\r\n"]
[420.940687, "o", "            return map(self._values.item, range(self._values.size))\r\n"]
[420.965284, "o", "\r\n"]
[420.989881, "o", "    @cache_readonly\r\n"]
[421.014478, "o", "    def hasnans(self) -> bool:\r\n"]
[421.039075, "o", "        \"\"\"\r\n"]
[421.063672, "o", "        Return True if there are any NaNs.\r\n"]
[421.088269, "o", "\r\n"]
[421.112866, "o", "        Enables various performance speedups.\r\n"]
[421.137463, "o", "\r\n"]
[421.16206, "o", "        Returns\r\n"]
[421.186657, "o", "        -------\r\n"]
[421.211254, "o", "        bool\r\n"]
[421.235851, "o", "        \"\"\"\r\n"]
[421.260448, "o", "        # error: Item \"bool\" of \"Union[bool, ndarray[Any, dtype[bool_]], NDFrame]\"\r\n"]
[421.285045, "o", "        # has no attribute \"any\"\r\n"]
[421.309642, "o", "        return bool(isna(self).any())  # type: ignore[union-attr]\r\n"]
[421.334239, "o", "\r\n"]
[421.358836, "o", "    def isna(self) -> npt.NDArray[np.bool_]:\r\n"]
[421.383433, "o", "        return isna(self._values)\r\n"]
[421.40803, "o", "\r\n"]
[421.432627, "o", "    def _reduce(\r\n"]
[421.457224, "o", "        self,\r\n"]
[421.481821, "o", "        op,\r\n"]
[421.506418, "o", "        name: str,\r\n"]
[421.531015, "o", "        *,\r\n"]
[421.555612, "o", "        axis: Axis = 0,\r\n"]
[421.580209, "o", "        skipna: bool = True,\r\n"]
[421.604806, "o", "        numeric_only=None,\r\n"]
[421.629403, "o", "        filter_type=None,\r\n"]
[421.654, "o", "        **kwds,\r\n"]
[421.678597, "o", "    ):\r\n"]
[421.703194, "o", "        \"\"\"\r\n"]
[421.727791, "o", "        Perform the reduction type operation if we can.\r\n"]
[421.752388, "o", "        \"\"\"\r\n"]
[421.776985, "o", "        func = getattr(self, name, None)\r\n"]
[421.801582, "o", "        if func is None:\r\n"]
[421.826179, "o", "            raise TypeError(\r\n"]
[421.850776, "o", "                f\"{type(self).__name__} cannot perform the operation {name}\"\r\n"]
[421.875373, "o", "            )\r\n"]
[421.89997, "o", "        return func(skipna=skipna, **kwds)\r\n"]
[421.924567, "o", "\r\n"]
[421.949164, "o", "    @final\r\n"]
[421.973761, "o", "    def _map_values(self, mapper, na_action=None):\r\n"]
[421.998358, "o", "        \"\"\"\r\n"]
[422.022955, "o", "        An internal function that maps values using the input\r\n"]
[422.047552, "o", "        correspondence (which can be a dict, Series, or function).\r\n"]
[422.072149, "o", "\r\n"]
[422.096746, "o", "        Parameters\r\n"]
[422.121343, "o", "        ----------\r\n"]
[422.14594, "o", "        mapper : function, dict, or Series\r\n"]
[422.170537, "o", "            The input correspondence object\r\n"]
[422.195134, "o", "        na_action : {None, 'ignore'}\r\n"]
[422.219731, "o", "            If 'ignore', propagate NA values, without passing them to the\r\n"]
[422.244328, "o", "            mapping function\r\n"]
[422.268925, "o", "\r\n"]
[422.293522, "o", "        Returns\r\n"]
[422.318119, "o", "        -------\r\n"]
[422.342716, "o", "        Union[Index, MultiIndex], inferred\r\n"]
[422.367313, "o", "            The output of the mapping function applied to the index.\r\n"]
[422.39191, "o", "            If the function returns a tuple with more than one element\r\n"]
[422.416507, "o", "            a MultiIndex will be returned.\r\n"]
[422.441104, "o", "        \"\"\"\r\n"]
[422.465701, "o", "        # we can fastpath dict/Series to an efficient map\r\n"]
[422.490299, "o", "        # as we know that we are not going to have to yield\r\n"]
[422.514896, "o", "        # python types\r\n"]
[422.539493, "o", "        if is_dict_like(mapper):\r\n"]
[422.56409, "o", "            if isinstance(mapper, dict) and hasattr(mapper, \"__missing__\"):\r\n"]
[422.588687, "o", "                # If a dictionary subclass defines a default value method,\r\n"]
[422.613284, "o", "                # convert mapper to a lookup function (GH #15999).\r\n"]
[422.637881, "o", "                dict_with_default = mapper\r\n"]
[422.662478, "o", "                mapper = lambda x: dict_with_default[\r\n"]
[422.687075, "o", "                    np.nan if isinstance(x, float) and np.isnan(x) else x\r\n"]
[422.711672, "o", "                ]\r\n"]
[422.736269, "o", "            else:\r\n"]
[422.760866, "o", "                # Dictionary does not have a default. Thus it's safe to\r\n"]
[422.785463, "o", "                # convert to an Series for efficiency.\r\n"]
[422.81006, "o", "                # we specify the keys here to handle the\r\n"]
[422.834657, "o", "                # possibility that they are tuples\r\n"]
[422.859254, "o", "\r\n"]
[422.883851, "o", "                # The return value of mapping with an empty mapper is\r\n"]
[422.908448, "o", "                # expected to be pd.Series(np.nan, ...). As np.nan is\r\n"]
[422.933045, "o", "                # of dtype float64 the return value of this method should\r\n"]
[422.957642, "o", "                # be float64 as well\r\n"]
[422.982239, "o", "                from pandas import Series\r\n"]
[423.006836, "o", "\r\n"]
[423.031433, "o", "                if len(mapper) == 0:\r\n"]
[423.05603, "o", "                    mapper = Series(mapper, dtype=np.float64)\r\n"]
[423.080627, "o", "                else:\r\n"]
[423.105224, "o", "                    mapper = Series(mapper)\r\n"]
[423.129821, "o", "\r\n"]
[423.154418, "o", "        if isinstance(mapper, ABCSeries):\r\n"]
[423.179015, "o", "            if na_action not in (None, \"ignore\"):\r\n"]
[423.203612, "o", "                msg = (\r\n"]
[423.228209, "o", "                    \"na_action must either be 'ignore' or None, \"\r\n"]
[423.252806, "o", "                    f\"{na_action} was passed\"\r\n"]
[423.277403, "o", "                )\r\n"]
[423.302, "o", "                raise ValueError(msg)\r\n"]
[423.326597, "o", "\r\n"]
[423.351194, "o", "            if na_action == \"ignore\":\r\n"]
[423.375791, "o", "                mapper = mapper[mapper.index.notna()]\r\n"]
[423.400388, "o", "\r\n"]
[423.424985, "o", "            # Since values were input this means we came from either\r\n"]
[423.449582, "o", "            # a dict or a series and mapper should be an index\r\n"]
[423.474179, "o", "            if is_categorical_dtype(self.dtype):\r\n"]
[423.498776, "o", "                # use the built in categorical series mapper which saves\r\n"]
[423.523373, "o", "                # time by mapping the categories instead of all values\r\n"]
[423.54797, "o", "\r\n"]
[423.572567, "o", "                cat = cast(\"Categorical\", self._values)\r\n"]
[423.597164, "o", "                return cat.map(mapper)\r\n"]
[423.621761, "o", "\r\n"]
[423.646358, "o", "            values = self._values\r\n"]
[423.670955, "o", "\r\n"]
[423.695552, "o", "            indexer = mapper.index.get_indexer(values)\r\n"]
[423.720149, "o", "            new_values = algorithms.take_nd(mapper._values, indexer)\r\n"]
[423.744746, "o", "\r\n"]
[423.769343, "o", "            return new_values\r\n"]
[423.79394, "o", "\r\n"]
[423.818537, "o", "        # we must convert to python types\r\n"]
[423.843134, "o", "        if is_extension_array_dtype(self.dtype) and hasattr(self._values, \"map\"):\r\n"]
[423.867731, "o", "            # GH#23179 some EAs do not have `map`\r\n"]
[423.892328, "o", "            values = self._values\r\n"]
[423.916925, "o", "            if na_action is not None:\r\n"]
[423.941522, "o", "                raise NotImplementedError\r\n"]
[423.966119, "o", "            map_f = lambda values, f: values.map(f)\r\n"]
[423.990716, "o", "        else:\r\n"]
[424.015313, "o", "            values = self._values.astype(object)\r\n"]
[424.03991, "o", "            if na_action == \"ignore\":\r\n"]
[424.064507, "o", "                map_f = lambda values, f: lib.map_infer_mask(\r\n"]
[424.089104, "o", "                    values, f, isna(values).view(np.uint8)\r\n"]
[424.113701, "o", "                )\r\n"]
[424.138299, "o", "            elif na_action is None:\r\n"]
[424.162896, "o", "                map_f = lib.map_infer\r\n"]
[424.187493, "o", "            else:\r\n"]
[424.21209, "o", "                msg = (\r\n"]
[424.236687, "o", "                    \"na_action must either be 'ignore' or None, \"\r\n"]
[424.261284, "o", "                    f\"{na_action} was passed\"\r\n"]
[424.285881, "o", "                )\r\n"]
[424.310478, "o", "                raise ValueError(msg)\r\n"]
[424.335075, "o", "\r\n"]
[424.359672, "o", "        # mapper is a function\r\n"]
[424.384269, "o", "        new_values = map_f(values, mapper)\r\n"]
[424.408866, "o", "\r\n"]
[424.433463, "o", "        return new_values\r\n"]
[424.45806, "o", "\r\n"]
[424.482657, "o", "    @final\r\n"]
[424.507254, "o", "    def value_counts(\r\n"]
[424.531851, "o", "        self,\r\n"]
[424.556448, "o", "        normalize: bool = False,\r\n"]
[424.581045, "o", "        sort: bool = True,\r\n"]
[424.605642, "o", "        ascending: bool = False,\r\n"]
[424.630239, "o", "        bins=None,\r\n"]
[424.654836, "o", "        dropna: bool = True,\r\n"]
[424.679433, "o", "    ) -> Series:\r\n"]
[424.70403, "o", "        \"\"\"\r\n"]
[424.728627, "o", "        Return a Series containing counts of unique values.\r\n"]
[424.753224, "o", "\r\n"]
[424.777821, "o", "        The resulting object will be in descending order so that the\r\n"]
[424.802418, "o", "        first element is the most frequently-occurring element.\r\n"]
[424.827015, "o", "        Excludes NA values by default.\r\n"]
[424.851612, "o", "\r\n"]
[424.876209, "o", "        Parameters\r\n"]
[424.900806, "o", "        ----------\r\n"]
[424.925403, "o", "        normalize : bool, default False\r\n"]
[425.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[425.002, "i", "python - << 'PY'\r"]
[425.004, "o", "python - << 'PY'\r\n"]
[425.074667, "o", "\u001b[?2004l\r\n"]
[425.143333, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[425.212, "o", "\u001b[?2004l\r\n"]
[425.280667, "o", "\u001b[?2004h> import re\r\n"]
[425.349333, "o", "\u001b[?2004l\r\n"]
[425.418, "o", "\u001b[?2004h> p = Path('pandas/core/base.py')\r\n"]
[425.486667, "o", "\u001b[?2004l\r\n"]
[425.555333, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[425.624, "o", "\u001b[?2004l\r\n"]
[425.692667, "o", "\u001b[?2004h> func_start = s.find('def to_numpy(')\r\n"]
[425.761333, "o", "\u001b[?2004l\r\n"]
[425.83, "o", "\u001b[?2004h> assert func_start != -1, 'to_numpy not found in base.py'\r\n"]
[425.898667, "o", "\u001b[?2004l\r\n"]
[425.967333, "o", "\u001b[?2004h> # Find the first triple quote after the function header\r\n"]
[426.036, "o", "\u001b[?2004l\r\n"]
[426.104667, "o", "\u001b[?2004h> doc_start = s.find('\"\"\"', func_start)\r\n"]
[426.173333, "o", "\u001b[?2004l\r\n"]
[426.242, "o", "\u001b[?2004h> assert doc_start != -1, 'docstring start not found'\r\n"]
[426.310667, "o", "\u001b[?2004l\r\n"]
[426.379333, "o", "\u001b[?2004h> # Find the end of the docstring (next triple quote after start)\r\n"]
[426.448, "o", "\u001b[?2004l\r\n"]
[426.516667, "o", "\u001b[?2004h> doc_end = s.find('\"\"\"', doc_start + 3)\r\n"]
[426.585333, "o", "\u001b[?2004l\r\n"]
[426.654, "o", "\u001b[?2004h> assert doc_end != -1, 'docstring end not found'\r\n"]
[426.722667, "o", "\u001b[?2004l\r\n"]
[426.791333, "o", "\u001b[?2004h> insert_pos = doc_end + 3  # right after closing triple quotes\r\n"]
[426.86, "o", "\u001b[?2004l\r\n"]
[426.928667, "o", "\u001b[?2004h> # Determine indentation of function body by looking at the docstring line\r\n"]
[426.997333, "o", "\u001b[?2004l\r\n"]
[427.066, "o", "\u001b[?2004h> line_start = s.rfind('\\n', 0, doc_start) + 1\r\n"]
[427.134667, "o", "\u001b[?2004l\r\n"]
[427.203333, "o", "\u001b[?2004h> indent = re.match(r\"\\s*\", s[line_start:doc_start]).group(0)\r\n"]
[427.272, "o", "\u001b[?2004l\r\n"]
[427.340667, "o", "\u001b[?2004h> fastpath = (\r\n"]
[427.409333, "o", "\u001b[?2004l\r\n"]
[427.478, "o", "\u001b[?2004h>     f\"\\n{indent}# Fastpath: NumPy-backed data with no dtype coercion and default na_value\\n\"\r\n"]
[427.546667, "o", "\u001b[?2004l\r\n"]
[427.615333, "o", "\u001b[?2004h>     f\"{indent}# Avoid manager/asarray overhead by returning/copying the underlying ndarray.\\n\"\r\n"]
[427.684, "o", "\u001b[?2004l\r\n"]
[427.752667, "o", "\u001b[?2004h>     f\"{indent}if na_value is lib.no_default and hasattr(self, '_mgr') and hasattr(self._mgr, 'internal_values'):\\n\"\r\n"]
[427.821333, "o", "\u001b[?2004l\r\n"]
[427.89, "o", "\u001b[?2004h>     f\"{indent}    vals = self._mgr.internal_values()\\n\"\r\n"]
[427.958667, "o", "\u001b[?2004l\r\n"]
[428.027333, "o", "\u001b[?2004h>     f\"{indent}    import numpy as _np\\n\"\r\n"]
[428.096, "o", "\u001b[?2004l\r\n"]
[428.164667, "o", "\u001b[?2004h>     f\"{indent}    arr = vals if isinstance(vals, _np.ndarray) else getattr(vals, '_ndarray', None)\\n\"\r\n"]
[428.233333, "o", "\u001b[?2004l\r\n"]
[428.302, "o", "\u001b[?2004h>     f\"{indent}    if isinstance(arr, _np.ndarray):\\n\"\r\n"]
[428.370667, "o", "\u001b[?2004l\r\n"]
[428.439333, "o", "\u001b[?2004h>     f\"{indent}        if dtype is None or _np.dtype(dtype) == arr.dtype:\\n\"\r\n"]
[428.508, "o", "\u001b[?2004l\r\n"]
[428.576667, "o", "\u001b[?2004h>     f\"{indent}            return arr.copy(order='K') if copy else arr\\n\"\r\n"]
[428.645333, "o", "\u001b[?2004l\r\n"]
[428.714, "o", "\u001b[?2004h> )\r\n"]
[428.782667, "o", "\u001b[?2004l\r\n"]
[428.851333, "o", "\u001b[?2004h> # Insert fastpath only if not already present to keep idempotent\r\n"]
[428.92, "o", "\u001b[?2004l\r\n"]
[428.988667, "o", "\u001b[?2004h> if 'Fastpath: NumPy-backed data' not in s[func_start:func_start+2000]:\r\n"]
[429.057333, "o", "\u001b[?2004l\r\n"]
[429.126, "o", "\u001b[?2004h>     s2 = s[:insert_pos] + fastpath + s[insert_pos:]\r\n"]
[429.194667, "o", "\u001b[?2004l\r\n"]
[429.263333, "o", "\u001b[?2004h>     p.write_text(s2)\r\n"]
[429.332, "o", "\u001b[?2004l\r\n"]
[429.400667, "o", "\u001b[?2004h>     print('Patched: fastpath inserted into pandas/core/base.py')\r\n"]
[429.469333, "o", "\u001b[?2004l\r\n"]
[429.538, "o", "\u001b[?2004h> else:\r\n"]
[429.606667, "o", "\u001b[?2004l\r\n"]
[429.675333, "o", "\u001b[?2004h>     print('Fastpath already present; no changes made')\r\n"]
[429.744, "o", "\u001b[?2004l\r\n"]
[429.812667, "o", "\u001b[?2004h> PY\r\n"]
[429.881333, "o", "\u001b[?2004l\r\n"]
[430.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[430.002, "i", "python - << 'PY'\r"]
[430.004, "o", "python - << 'PY'\r\n"]
[430.1296, "o", "\u001b[?2004l\r\n"]
[430.2532, "o", "\u001b[?2004h> import pandas as pd, numpy as np\r\n"]
[430.3768, "o", "\u001b[?2004l\r\n"]
[430.5004, "o", "\u001b[?2004h> # Sanity checks for numpy-backed Series\r\n"]
[430.624, "o", "\u001b[?2004l\r\n"]
[430.7476, "o", "\u001b[?2004h> s = pd.Series(np.random.randn(10).astype('float64'))\r\n"]
[430.8712, "o", "\u001b[?2004l\r\n"]
[430.9948, "o", "\u001b[?2004h> a = s.to_numpy()\r\n"]
[431.1184, "o", "\u001b[?2004l\r\n"]
[431.242, "o", "\u001b[?2004h> b = s.to_numpy(copy=True)\r\n"]
[431.3656, "o", "\u001b[?2004l\r\n"]
[431.4892, "o", "\u001b[?2004h> c = s.to_numpy(dtype='float64', copy=True)\r\n"]
[431.6128, "o", "\u001b[?2004l\r\n"]
[431.7364, "o", "\u001b[?2004h> print('a ndarray:', isinstance(a, np.ndarray))\r\n"]
[431.86, "o", "\u001b[?2004l\r\n"]
[431.9836, "o", "\u001b[?2004h> print('b copy base None:', b.base is None)\r\n"]
[432.1072, "o", "\u001b[?2004l\r\n"]
[432.2308, "o", "\u001b[?2004h> print('c dtype matches and copy:', c.dtype == np.float64, c.base is None)\r\n"]
[432.3544, "o", "\u001b[?2004l\r\n"]
[432.478, "o", "\u001b[?2004h> # EA path should still return object ndarray\r\n"]
[432.6016, "o", "\u001b[?2004l\r\n"]
[432.7252, "o", "\u001b[?2004h> s2 = pd.Series(pd.array([1, None, 3], dtype='Int64'))\r\n"]
[432.8488, "o", "\u001b[?2004l\r\n"]
[432.9724, "o", "\u001b[?2004h> r = s2.to_numpy(copy=True)\r\n"]
[433.096, "o", "\u001b[?2004l\r\n"]
[433.2196, "o", "\u001b[?2004h> print('EA ndarray dtype:', r.dtype)\r\n"]
[433.3432, "o", "\u001b[?2004l\r\n"]
[433.4668, "o", "\u001b[?2004h> # na_value provided should bypass fastpath\r\n"]
[433.5904, "o", "\u001b[?2004l\r\n"]
[433.714, "o", "\u001b[?2004h> r2 = s.to_numpy(na_value=999.0, copy=True)\r\n"]
[433.8376, "o", "\u001b[?2004l\r\n"]
[433.9612, "o", "\u001b[?2004h> print('na_value provided dtype:', r2.dtype, 'contains 999?', (r2==999.0).any())\r\n"]
[434.0848, "o", "\u001b[?2004l\r\n"]
[434.2084, "o", "\u001b[?2004h> PY\r\n"]
[434.332, "o", "\u001b[?2004l\r\n"]
[434.4556, "o", "a ndarray: True\r\n"]
[434.5792, "o", "b copy base None: True\r\n"]
[434.7028, "o", "c dtype matches and copy: True True\r\n"]
[434.8264, "o", "EA ndarray dtype: object\r\n"]
[435.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[435.002, "i", "cd asv_bench\r"]
[435.004, "o", "cd asv_bench\r\n"]
[435.006, "o", "\u001b[?2004l\r\n"]
[440.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[440.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[440.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[440.624, "o", "\u001b[?2004l\r\n"]
[441.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[441.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[442.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[443.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[443.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                       763\u00b12ns\r\n"]
[444.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                 385\u00b110\u03bcs\r\n"]
[445.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[445.002, "i", "git add pandas/core/base.py\r"]
[445.004, "o", "git add pandas/core/base.py\r\n"]
[446.654, "o", "\u001b[?2004l\r\n"]
[448.302, "o", "warning: could not open directory 'asv_bench/pandas/core/': No such file or directory\r\n"]
[450.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[450.002, "i", "git commit -m \"Optimize IndexOpsMixin.to_numpy: add fastpath for NumPy-backed data when no dtype coercion/\r"]
[450.004, "o", "git commit -m \"Optimize IndexOpsMixin.to_numpy: add fastpath for NumPy-backed data when no dtype coercion/\r\n"]
[450.3356, "o", "/na_value handling is needed. Avoid manager/asarray overhead; ~40% speedup on series_methods.ToNumpy.time_to_numpy.\"\r\n"]
[450.6652, "o", "\u001b[?2004l\r\n"]
[450.9948, "o", "Author identity unknown\r\n"]
[451.3244, "o", "\r\n"]
[451.654, "o", "*** Please tell me who you are.\r\n"]
[451.9836, "o", "\r\n"]
[452.3132, "o", "Run\r\n"]
[452.6428, "o", "\r\n"]
[452.9724, "o", "  git config --global user.email \"you@example.com\"\r\n"]
[453.302, "o", "  git config --global user.name \"Your Name\"\r\n"]
[453.6316, "o", "\r\n"]
[453.9612, "o", "to set your account's default identity.\r\n"]
[454.2908, "o", "Omit --global to set the identity only in this repository.\r\n"]
[454.6204, "o", "\r\n"]
[455.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[455.002, "i", "git status -s\r"]
[455.004, "o", "git status -s\r\n"]
[457.478, "o", "\u001b[?2004l\r\n"]
[460.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[460.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[460.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[460.624, "o", "\u001b[?2004l\r\n"]
[461.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[461.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[462.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[463.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[463.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                       769\u00b13ns\r\n"]
[464.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                 414\u00b150\u03bcs\r\n"]
[465.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[465.002, "i", "cd /workspace/repo\r"]
[465.004, "o", "cd /workspace/repo\r\n"]
[465.006, "o", "\u001b[?2004l\r\n"]
[470.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[470.002, "i", "git config user.email \"you@example.com\"\r"]
[470.004, "o", "git config user.email \"you@example.com\"\r\n"]
[470.006, "o", "\u001b[?2004l\r\n"]
[475.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[475.002, "i", "git config user.name \"Your Name\"\r"]
[475.004, "o", "git config user.name \"Your Name\"\r\n"]
[475.006, "o", "\u001b[?2004l\r\n"]
[480.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[480.002, "i", "git add pandas/core/base.py\r"]
[480.004, "o", "git add pandas/core/base.py\r\n"]
[480.006, "o", "\u001b[?2004l\r\n"]
[485.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[485.002, "i", "git commit -m \"Optimize IndexOpsMixin.to_numpy: fastpath for NumPy-backed data when no dtype coercion/na_value handl\r"]
[485.004, "o", "git commit -m \"Optimize IndexOpsMixin.to_numpy: fastpath for NumPy-backed data when no dtype coercion/na_value handl\r\n"]
[486.242, "o", "ling is needed. Avoid manager/asarray overhead; ~40% speedup on Series.to_numpy benchmark.\"\r\n"]
[487.478, "o", "\u001b[?2004l\r\n"]
[488.714, "o", "[main dc21e49016] Optimize IndexOpsMixin.to_numpy: fastpath for NumPy-backed data when no dtype coercion/na_value handling is needed. Avoid manager/asarray overhead; ~40% speedup on Series.to_numpy benchmark.\r\n"]
[490.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo# "]
[490.002, "i", "cd asv_bench\r"]
[490.004, "o", "cd asv_bench\r\n"]
[490.006, "o", "\u001b[?2004l\r\n"]
[495.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[495.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[495.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[495.624, "o", "\u001b[?2004l\r\n"]
[496.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[496.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[497.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[498.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[498.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                       766\u00b12ns\r\n"]
[499.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                  370\u00b19\u03bcs\r\n"]
[500.0, "o", "(asv_3.8) root@a4408430bcc2:/workspace/repo/asv_bench# "]
[500.002, "i", "\u001b[?2004l\r"]
[500.004, "o", "\u001b[?2004l\r\n"]
[502.478, "o", "\r\n"]
