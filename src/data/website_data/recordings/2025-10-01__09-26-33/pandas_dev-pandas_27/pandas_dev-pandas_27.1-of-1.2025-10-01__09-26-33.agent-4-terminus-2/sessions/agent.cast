{"version": 2, "width": 160, "height": 40, "timestamp": 1762995157, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[0.002, "i", "asciinema rec --stdin /logs/agent.cast\r"]
[0.004, "o", "asciinema rec --stdin /logs/agent.cast\r\n"]
[1.242, "o", "\u001b[?2004l\r\n"]
[2.478, "o", "\u001b[0;31masciinema: /logs/agent.cast already exists, aborting\u001b[0m\r\n"]
[3.714, "o", "\u001b[0;31masciinema: use --overwrite option if you want to overwrite existing recording\u001b[0m\r\n"]
[5.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[5.002, "i", "clear\r"]
[5.004, "o", "clear\r\n"]
[7.478, "o", "\u001b[?2004l\r\n"]
[10.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[10.002, "i", "ls -la\r"]
[10.004, "o", "ls -la\r\n"]
[10.143333, "o", "\u001b[?2004l\r\n"]
[10.280667, "o", "total 208\r\n"]
[10.418, "o", "drwxr-xr-x 1 root root  4096 Oct  1 17:59 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[10.555333, "o", "drwxr-xr-x 1 root root  4096 Sep 15 17:17 \u001b[01;34m..\u001b[0m\r\n"]
[10.692667, "o", "drwxr-xr-x 2 root root  4096 Sep 13 12:45 \u001b[01;34m.circleci\u001b[0m\r\n"]
[10.83, "o", "-rw-r--r-- 1 root root  1021 Sep 13 12:45 .devcontainer.json\r\n"]
[10.967333, "o", "drwxr-xr-x 1 root root  4096 Oct  1 17:59 \u001b[01;34m.git\u001b[0m\r\n"]
[11.104667, "o", "-rw-r--r-- 1 root root   229 Sep 13 12:45 .gitattributes\r\n"]
[11.242, "o", "drwxr-xr-x 1 root root  4096 Sep 13 12:45 \u001b[01;34m.github\u001b[0m\r\n"]
[11.379333, "o", "-rw-r--r-- 1 root root  1765 Sep 13 12:45 .gitignore\r\n"]
[11.516667, "o", "-rw-r--r-- 1 root root  2322 Sep 13 12:45 .gitpod.yml\r\n"]
[11.654, "o", "-rw-r--r-- 1 root root   761 Sep 13 12:45 .libcst.codemod.yaml\r\n"]
[11.791333, "o", "-rw-r--r-- 1 root root 15546 Sep 13 12:45 .pre-commit-config.yaml\r\n"]
[11.928667, "o", "-rw-r--r-- 1 root root  2284 Sep 13 12:45 AUTHORS.md\r\n"]
[12.066, "o", "-rw-r--r-- 1 root root   372 Sep 13 12:45 CITATION.cff\r\n"]
[12.203333, "o", "-rw-r--r-- 1 root root   369 Sep 13 12:45 Dockerfile\r\n"]
[12.340667, "o", "-rw-r--r-- 1 root root  1634 Sep 13 12:45 LICENSE\r\n"]
[12.478, "o", "drwxr-xr-x 1 root root  4096 Sep 13 12:45 \u001b[01;34mLICENSES\u001b[0m\r\n"]
[12.615333, "o", "-rw-r--r-- 1 root root  1294 Sep 13 12:45 MANIFEST.in\r\n"]
[12.752667, "o", "-rw-r--r-- 1 root root 10387 Sep 13 12:45 README.md\r\n"]
[12.89, "o", "-rw-r--r-- 1 root root   246 Sep 13 12:45 RELEASE.md\r\n"]
[13.027333, "o", "drwxr-xr-x 1 root root  4096 Sep 13 12:45 \u001b[01;34masv_bench\u001b[0m\r\n"]
[13.164667, "o", "drwxr-xr-x 1 root root  4096 Sep 13 12:45 \u001b[01;34mci\u001b[0m\r\n"]
[13.302, "o", "-rw-r--r-- 1 root root   256 Sep 13 12:44 codecov.yml\r\n"]
[13.439333, "o", "drwxr-xr-x 1 root root  4096 Sep 13 12:45 \u001b[01;34mdoc\u001b[0m\r\n"]
[13.576667, "o", "-rw-r--r-- 1 root root  2398 Sep 13 12:45 environment.yml\r\n"]
[13.714, "o", "drwxr-xr-x 1 root root  4096 Sep 13 12:45 \u001b[01;34mgitpod\u001b[0m\r\n"]
[13.851333, "o", "drwxr-xr-x 1 root root  4096 Sep 13 22:01 \u001b[01;34mpandas\u001b[0m\r\n"]
[13.988667, "o", "-rw-r--r-- 1 root root 17415 Sep 13 12:45 pyproject.toml\r\n"]
[14.126, "o", "-rw-r--r-- 1 root root  4429 Sep 13 12:45 pyright_reportGeneralTypeIssues.json\r\n"]
[14.263333, "o", "-rw-r--r-- 1 root root  1348 Sep 13 12:45 requirements-dev.txt\r\n"]
[14.400667, "o", "drwxr-xr-x 1 root root  4096 Sep 13 12:45 \u001b[01;34mscripts\u001b[0m\r\n"]
[14.538, "o", "-rw-r--r-- 1 root root   608 Sep 13 12:45 setup.cfg\r\n"]
[14.675333, "o", "-rwxr-xr-x 1 root root 22455 Sep 13 12:45 \u001b[01;32msetup.py\u001b[0m\r\n"]
[14.812667, "o", "drwxr-xr-x 1 root root  4096 Sep 13 12:45 \u001b[01;34mtypings\u001b[0m\r\n"]
[15.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[15.002, "i", "git status -sb\r"]
[15.004, "o", "git status -sb\r\n"]
[17.478, "o", "\u001b[?2004l\r\n"]
[20.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[20.002, "i", "ls -la asv.conf.json .asv.json .asv\r"]
[20.004, "o", "ls -la asv.conf.json .asv.json .asv\r\n"]
[21.242, "o", "\u001b[?2004l\r\n"]
[22.478, "o", "ls: cannot access 'asv.conf.json': No such file or directory\r\n"]
[23.714, "o", "ls: cannot access '.asv.json': No such file or directory\r\n"]
[25.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[25.002, "i", "grep -R \"series_methods\" -n . || true\r"]
[25.004, "o", "grep -R \"series_methods\" -n . || true\r\n"]
[25.9948, "o", "\u001b[?2004l\r\n"]
[26.9836, "o", "grep: ./.git/objects/pack/pack-228fe36a14f38976543871af40ff70d29522aa28.pack: binary file matches\r\n"]
[27.9724, "o", "grep: ./.git/index: binary file matches\r\n"]
[28.9612, "o", "\u001b[35m\u001b[K./pandas/tests/resample/conftest.py\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[32m\u001b[K30\u001b[m\u001b[K\u001b[36m\u001b[K:\u001b[m\u001b[K\u001b[01;31m\u001b[Kseries_methods\u001b[m\u001b[K = [\"nunique\"]\r\n"]
[30.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[30.002, "i", "grep -R \"ToNumpy\" -n benchmarks asv_benchmarks . 2>/dev/null | head -n 50\r"]
[30.004, "o", "grep -R \"ToNumpy\" -n benchmarks asv_benchmarks . 2>/dev/null | head -n 50\r\n"]
[31.242, "o", "\u001b[?2004l\r\n"]
[32.478, "o", "./asv_bench/benchmarks/series_methods.py:370:class ToNumpy:\r\n"]
[33.714, "o", "./asv_bench/benchmarks/frame_methods.py:246:class ToNumpy:\r\n"]
[35.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[35.002, "i", "ls -la benchmarks asv_benchmarks 2>/dev/null\r"]
[35.004, "o", "ls -la benchmarks asv_benchmarks 2>/dev/null\r\n"]
[35.006, "o", "\u001b[?2004l\r\n"]
[40.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[40.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[40.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[42.478, "o", "\u001b[?2004l\r\n"]
[45.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[45.002, "i", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r"]
[45.004, "o", "asv run --python=same --bench=\"series_methods.ToNumpy.*\"\r\n"]
[47.478, "o", "\u001b[?2004l\r\n"]
[50.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[50.002, "i", "asv show\r"]
[50.004, "o", "asv show\r\n"]
[52.478, "o", "\u001b[?2004l\r\n"]
[55.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[55.002, "i", "asv find --python=same --bench \"series_methods.ToNumpy.*\"\r"]
[55.004, "o", "asv find --python=same --bench \"series_methods.ToNumpy.*\"\r\n"]
[55.220957, "o", "\u001b[?2004l\r\n"]
[55.435913, "o", "Traceback (most recent call last):\r\n"]
[55.65087, "o", "  File \"/opt/conda/envs/asv_3.8/bin/asv\", line 8, in <module>\r\n"]
[55.865826, "o", "    sys.exit(main())\r\n"]
[56.080783, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/main.py\", line 13, in main\r\n"]
[56.295739, "o", "    args = parser.parse_args()\r\n"]
[56.510696, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1768, in parse_args\r\n"]
[56.725652, "o", "    args, argv = self.parse_known_args(args, namespace)\r\n"]
[56.940609, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1800, in parse_known_args\r\n"]
[57.155565, "o", "    namespace, args = self._parse_known_args(args, namespace)\r\n"]
[57.370522, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1988, in _parse_known_args\r\n"]
[57.585478, "o", "    positionals_end_index = consume_positionals(start_index)\r\n"]
[57.800435, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1965, in consume_positionals\r\n"]
[58.015391, "o", "    take_action(action, args)\r\n"]
[58.230348, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1874, in take_action\r\n"]
[58.445304, "o", "    action(self, namespace, argument_values, option_string)\r\n"]
[58.660261, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1159, in __call__\r\n"]
[58.875217, "o", "    subnamespace, arg_strings = parser.parse_known_args(arg_strings, None)\r\n"]
[59.090174, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 1800, in parse_known_args\r\n"]
[59.30513, "o", "    namespace, args = self._parse_known_args(args, namespace)\r\n"]
[59.520087, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/argparse.py\", line 2035, in _parse_known_args\r\n"]
[59.735043, "o", "    ', '.join(required_actions))\r\n"]
[60.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[60.002, "i", "asv profile --python=same \"series_methods.ToNumpy.*\"\r"]
[60.004, "o", "asv profile --python=same \"series_methods.ToNumpy.*\"\r\n"]
[62.478, "o", "\u001b[?2004l\r\n"]
[65.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[65.002, "i", "rg -n \"ToNumpy|to_numpy|to_numpy\\(|to_numpy\\s*=|to_numpy\\b\" -S\r"]
[65.004, "o", "rg -n \"ToNumpy|to_numpy|to_numpy\\(|to_numpy\\s*=|to_numpy\\b\" -S\r\n"]
[67.478, "o", "\u001b[?2004l\r\n"]
[70.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[70.002, "i", "rg -n \"bool_t|bool_|numpy\\.bool_|np\\.bool_\" -S\r"]
[70.004, "o", "rg -n \"bool_t|bool_|numpy\\.bool_|np\\.bool_\" -S\r\n"]
[72.478, "o", "\u001b[?2004l\r\n"]
[75.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[75.002, "i", "git grep -n \"guess-common-names\" || true\r"]
[75.004, "o", "git grep -n \"guess-common-names\" || true\r\n"]
[76.654, "o", "\u001b[?2004l\r\n"]
[78.302, "o", "error: cannot run less: No such file or directory\r\n"]
[80.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[80.002, "i", "ls -la asv_bench\r"]
[80.004, "o", "ls -la asv_bench\r\n"]
[80.83, "o", "\u001b[?2004l\r\n"]
[81.654, "o", "total 24\r\n"]
[82.478, "o", "drwxr-xr-x 1 root root 4096 Sep 13 12:45 \u001b[0m\u001b[01;34m.\u001b[0m\r\n"]
[83.302, "o", "drwxr-xr-x 1 root root 4096 Oct  1 17:59 \u001b[01;34m..\u001b[0m\r\n"]
[84.126, "o", "-rw-r--r-- 1 root root 5217 Sep 13 12:45 asv.conf.json\r\n"]
[85.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[85.002, "i", "ls -la asv_bench/asv.conf.json\r"]
[85.004, "o", "ls -la asv_bench/asv.conf.json\r\n"]
[87.478, "o", "\u001b[?2004l\r\n"]
[90.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[90.002, "i", "sed -n '320,460p' asv_bench/benchmarks/series_methods.py\r"]
[90.004, "o", "sed -n '320,460p' asv_bench/benchmarks/series_methods.py\r\n"]
[90.05544, "o", "\u001b[?2004l\r\n"]
[90.10488, "o", "\r\n"]
[90.15432, "o", "    def time_func(self, func, N, dtype):\r\n"]
[90.20376, "o", "        self.func()\r\n"]
[90.2532, "o", "\r\n"]
[90.30264, "o", "\r\n"]
[90.35208, "o", "class Rank:\r\n"]
[90.40152, "o", "    param_names = [\"dtype\"]\r\n"]
[90.45096, "o", "    params = [\r\n"]
[90.5004, "o", "        [\"int\", \"uint\", \"float\", \"object\"],\r\n"]
[90.54984, "o", "    ]\r\n"]
[90.59928, "o", "\r\n"]
[90.64872, "o", "    def setup(self, dtype):\r\n"]
[90.69816, "o", "        self.s = Series(np.random.randint(0, 1000, size=100000), dtype=dtype)\r\n"]
[90.7476, "o", "\r\n"]
[90.79704, "o", "    def time_rank(self, dtype):\r\n"]
[90.84648, "o", "        self.s.rank()\r\n"]
[90.89592, "o", "\r\n"]
[90.94536, "o", "\r\n"]
[90.9948, "o", "class Iter:\r\n"]
[91.04424, "o", "    param_names = [\"dtype\"]\r\n"]
[91.09368, "o", "    params = [\r\n"]
[91.14312, "o", "        \"bool\",\r\n"]
[91.19256, "o", "        \"boolean\",\r\n"]
[91.242, "o", "        \"int64\",\r\n"]
[91.29144, "o", "        \"Int64\",\r\n"]
[91.34088, "o", "        \"float64\",\r\n"]
[91.39032, "o", "        \"Float64\",\r\n"]
[91.43976, "o", "        \"datetime64[ns]\",\r\n"]
[91.4892, "o", "    ]\r\n"]
[91.53864, "o", "\r\n"]
[91.58808, "o", "    def setup(self, dtype):\r\n"]
[91.63752, "o", "        N = 10**5\r\n"]
[91.68696, "o", "        if dtype in [\"bool\", \"boolean\"]:\r\n"]
[91.7364, "o", "            data = np.repeat([True, False], N // 2)\r\n"]
[91.78584, "o", "        elif dtype in [\"int64\", \"Int64\"]:\r\n"]
[91.83528, "o", "            data = np.arange(N)\r\n"]
[91.88472, "o", "        elif dtype in [\"float64\", \"Float64\"]:\r\n"]
[91.93416, "o", "            data = np.random.randn(N)\r\n"]
[91.9836, "o", "        elif dtype == \"datetime64[ns]\":\r\n"]
[92.03304, "o", "            data = date_range(\"2000-01-01\", freq=\"s\", periods=N)\r\n"]
[92.08248, "o", "        else:\r\n"]
[92.13192, "o", "            raise NotImplementedError\r\n"]
[92.18136, "o", "\r\n"]
[92.2308, "o", "        self.s = Series(data, dtype=dtype)\r\n"]
[92.28024, "o", "\r\n"]
[92.32968, "o", "    def time_iter(self, dtype):\r\n"]
[92.37912, "o", "        for v in self.s:\r\n"]
[92.42856, "o", "            pass\r\n"]
[92.478, "o", "\r\n"]
[92.52744, "o", "\r\n"]
[92.57688, "o", "class ToNumpy:\r\n"]
[92.62632, "o", "    def setup(self):\r\n"]
[92.67576, "o", "        N = 1_000_000\r\n"]
[92.7252, "o", "        self.ser = Series(\r\n"]
[92.77464, "o", "            np.random.randn(\r\n"]
[92.82408, "o", "                N,\r\n"]
[92.87352, "o", "            )\r\n"]
[92.92296, "o", "        )\r\n"]
[92.9724, "o", "\r\n"]
[93.02184, "o", "    def time_to_numpy(self):\r\n"]
[93.07128, "o", "        self.ser.to_numpy()\r\n"]
[93.12072, "o", "\r\n"]
[93.17016, "o", "    def time_to_numpy_double_copy(self):\r\n"]
[93.2196, "o", "        self.ser.to_numpy(dtype=\"float64\", copy=True)\r\n"]
[93.26904, "o", "\r\n"]
[93.31848, "o", "    def time_to_numpy_copy(self):\r\n"]
[93.36792, "o", "        self.ser.to_numpy(copy=True)\r\n"]
[93.41736, "o", "\r\n"]
[93.4668, "o", "\r\n"]
[93.51624, "o", "class Replace:\r\n"]
[93.56568, "o", "    param_names = [\"num_to_replace\"]\r\n"]
[93.61512, "o", "    params = [100, 1000]\r\n"]
[93.66456, "o", "\r\n"]
[93.714, "o", "    def setup(self, num_to_replace):\r\n"]
[93.76344, "o", "        N = 1_000_000\r\n"]
[93.81288, "o", "        self.arr = np.random.randn(N)\r\n"]
[93.86232, "o", "        self.arr1 = self.arr.copy()\r\n"]
[93.91176, "o", "        np.random.shuffle(self.arr1)\r\n"]
[93.9612, "o", "        self.ser = Series(self.arr)\r\n"]
[94.01064, "o", "\r\n"]
[94.06008, "o", "        self.to_replace_list = np.random.choice(self.arr, num_to_replace)\r\n"]
[94.10952, "o", "        self.values_list = np.random.choice(self.arr1, num_to_replace)\r\n"]
[94.15896, "o", "\r\n"]
[94.2084, "o", "        self.replace_dict = dict(zip(self.to_replace_list, self.values_list))\r\n"]
[94.25784, "o", "\r\n"]
[94.30728, "o", "    def time_replace_dict(self, num_to_replace):\r\n"]
[94.35672, "o", "        self.ser.replace(self.replace_dict)\r\n"]
[94.40616, "o", "\r\n"]
[94.4556, "o", "    def peakmem_replace_dict(self, num_to_replace):\r\n"]
[94.50504, "o", "        self.ser.replace(self.replace_dict)\r\n"]
[94.55448, "o", "\r\n"]
[94.60392, "o", "    def time_replace_list(self, num_to_replace):\r\n"]
[94.65336, "o", "        self.ser.replace(self.to_replace_list, self.values_list)\r\n"]
[94.7028, "o", "\r\n"]
[94.75224, "o", "    def peakmem_replace_list(self, num_to_replace):\r\n"]
[94.80168, "o", "        self.ser.replace(self.to_replace_list, self.values_list)\r\n"]
[94.85112, "o", "\r\n"]
[94.90056, "o", "\r\n"]
[95.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[95.002, "i", "asv run --python=same --config=asv_bench/asv.conf.json --bench=\"series_methods.ToNumpy.*\"\r"]
[95.004, "o", "asv run --python=same --config=asv_bench/asv.conf.json --bench=\"series_methods.ToNumpy.*\"\r\n"]
[97.478, "o", "\u001b[?2004l\r\n"]
[100.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[100.002, "i", "asv show --config=asv_bench/asv.conf.json\r"]
[100.004, "o", "asv show --config=asv_bench/asv.conf.json\r\n"]
[102.478, "o", "\u001b[?2004l\r\n"]
[105.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[105.002, "i", "asv profile --python=same --config=asv_bench/asv.conf.json series_methods.ToNumpy.*\r"]
[105.004, "o", "asv profile --python=same --config=asv_bench/asv.conf.json series_methods.ToNumpy.*\r\n"]
[107.478, "o", "\u001b[?2004l\r\n"]
[110.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[110.002, "i", "grep -R \"def to_numpy\\b\" -n pandas | head -n 20\r"]
[110.004, "o", "grep -R \"def to_numpy\\b\" -n pandas | head -n 20\r\n"]
[110.241429, "o", "\u001b[?2004l\r\n"]
[110.476857, "o", "pandas/core/base.py:474:    def to_numpy(\r\n"]
[110.712286, "o", "pandas/core/frame.py:1786:    def to_numpy(\r\n"]
[110.947714, "o", "pandas/core/arrays/base.py:459:    def to_numpy(\r\n"]
[111.183143, "o", "pandas/core/arrays/masked.py:342:    def to_numpy(\r\n"]
[111.418571, "o", "pandas/core/arrays/numpy_.py:406:    def to_numpy(\r\n"]
[111.654, "o", "pandas/core/arrays/arrow/array.py:1026:    def to_numpy(\r\n"]
[111.889429, "o", "pandas/tests/extension/decimal/array.py:109:    def to_numpy(\r\n"]
[112.124857, "o", "pandas/_libs/tslibs/timedeltas.pyx:1274:    def to_numpy(self, dtype=None, copy=False) -> np.timedelta64:\r\n"]
[112.360286, "o", "pandas/_libs/tslibs/nattype.pyi:27:    def to_numpy(\r\n"]
[112.595714, "o", "pandas/_libs/tslibs/timestamps.pyi:210:    def to_numpy(\r\n"]
[112.831143, "o", "pandas/_libs/tslibs/nattype.pyx:264:    def to_numpy(self, dtype=None, copy=False) -> np.datetime64 | np.timedelta64:\r\n"]
[113.066571, "o", "pandas/_libs/tslibs/timedeltas.pyi:162:    def to_numpy(self) -> np.timedelta64: ...\r\n"]
[113.302, "o", "pandas/_libs/tslibs/timestamps.pyx:1198:    def to_numpy(self, dtype=None, copy=False) -> np.datetime64:\r\n"]
[113.537429, "o", "pandas/_libs/tslibs/nattype.c:6281: *     def to_numpy(self, dtype=None, copy=False) -> np.datetime64 | np.timedelta64:\r\n"]
[113.772857, "o", "pandas/_libs/tslibs/nattype.c:6319: *     def to_numpy(self, dtype=None, copy=False) -> np.datetime64 | np.timedelta64:             # <<<<<<<<<<<<<<\r\n"]
[114.008286, "o", "pandas/_libs/tslibs/nattype.c:6653: *     def to_numpy(self, dtype=None, copy=False) -> np.datetime64 | np.timedelta64:             # <<<<<<<<<<<<<<\r\n"]
[114.243714, "o", "pandas/_libs/tslibs/nattype.c:13918: *     def to_numpy(self, dtype=None, copy=False) -> np.datetime64 | np.timedelta64:\r\n"]
[114.479143, "o", "pandas/_libs/tslibs/timestamps.c:15972: *     def to_numpy(self, dtype=None, copy=False) -> np.datetime64:\r\n"]
[114.714571, "o", "pandas/_libs/tslibs/timestamps.c:16100: *     def to_numpy(self, dtype=None, copy=False) -> np.datetime64:             # <<<<<<<<<<<<<<\r\n"]
[115.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[115.002, "i", "grep -R \"to_numpy\\(\" -n pandas/core | head -n 50\r"]
[115.004, "o", "grep -R \"to_numpy\\(\" -n pandas/core | head -n 50\r\n"]
[117.478, "o", "\u001b[?2004l\r\n"]
[120.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[120.002, "i", "sed -n '1,220p' pandas/core/generic.py\r"]
[120.004, "o", "sed -n '1,220p' pandas/core/generic.py\r\n"]
[120.028371, "o", "\u001b[?2004l\r\n"]
[120.050742, "o", "# pyright: reportPropertyTypeMismatch=false\r\n"]
[120.073113, "o", "from __future__ import annotations\r\n"]
[120.095484, "o", "\r\n"]
[120.117855, "o", "import collections\r\n"]
[120.140226, "o", "import datetime as dt\r\n"]
[120.162597, "o", "from functools import partial\r\n"]
[120.184968, "o", "import gc\r\n"]
[120.207339, "o", "from json import loads\r\n"]
[120.22971, "o", "import operator\r\n"]
[120.252081, "o", "import pickle\r\n"]
[120.274452, "o", "import re\r\n"]
[120.296824, "o", "from typing import (\r\n"]
[120.319195, "o", "    TYPE_CHECKING,\r\n"]
[120.341566, "o", "    Any,\r\n"]
[120.363937, "o", "    Callable,\r\n"]
[120.386308, "o", "    ClassVar,\r\n"]
[120.408679, "o", "    Hashable,\r\n"]
[120.43105, "o", "    Iterator,\r\n"]
[120.453421, "o", "    Literal,\r\n"]
[120.475792, "o", "    Mapping,\r\n"]
[120.498163, "o", "    NoReturn,\r\n"]
[120.520534, "o", "    Sequence,\r\n"]
[120.542905, "o", "    Type,\r\n"]
[120.565276, "o", "    cast,\r\n"]
[120.587647, "o", "    final,\r\n"]
[120.610018, "o", "    overload,\r\n"]
[120.632389, "o", ")\r\n"]
[120.65476, "o", "import warnings\r\n"]
[120.677131, "o", "import weakref\r\n"]
[120.699502, "o", "\r\n"]
[120.721873, "o", "import numpy as np\r\n"]
[120.744244, "o", "\r\n"]
[120.766615, "o", "from pandas._config import (\r\n"]
[120.788986, "o", "    config,\r\n"]
[120.811357, "o", "    using_copy_on_write,\r\n"]
[120.833729, "o", ")\r\n"]
[120.8561, "o", "\r\n"]
[120.878471, "o", "from pandas._libs import lib\r\n"]
[120.900842, "o", "from pandas._libs.lib import is_range_indexer\r\n"]
[120.923213, "o", "from pandas._libs.tslibs import (\r\n"]
[120.945584, "o", "    Period,\r\n"]
[120.967955, "o", "    Tick,\r\n"]
[120.990326, "o", "    Timestamp,\r\n"]
[121.012697, "o", "    to_offset,\r\n"]
[121.035068, "o", ")\r\n"]
[121.057439, "o", "from pandas._typing import (\r\n"]
[121.07981, "o", "    AlignJoin,\r\n"]
[121.102181, "o", "    AnyArrayLike,\r\n"]
[121.124552, "o", "    ArrayLike,\r\n"]
[121.146923, "o", "    Axis,\r\n"]
[121.169294, "o", "    AxisInt,\r\n"]
[121.191665, "o", "    CompressionOptions,\r\n"]
[121.214036, "o", "    Dtype,\r\n"]
[121.236407, "o", "    DtypeArg,\r\n"]
[121.258778, "o", "    DtypeBackend,\r\n"]
[121.281149, "o", "    DtypeObj,\r\n"]
[121.30352, "o", "    FilePath,\r\n"]
[121.325891, "o", "    FillnaOptions,\r\n"]
[121.348262, "o", "    FloatFormatType,\r\n"]
[121.370633, "o", "    FormattersType,\r\n"]
[121.393005, "o", "    Frequency,\r\n"]
[121.415376, "o", "    IgnoreRaise,\r\n"]
[121.437747, "o", "    IndexKeyFunc,\r\n"]
[121.460118, "o", "    IndexLabel,\r\n"]
[121.482489, "o", "    IntervalClosedType,\r\n"]
[121.50486, "o", "    JSONSerializable,\r\n"]
[121.527231, "o", "    Level,\r\n"]
[121.549602, "o", "    Manager,\r\n"]
[121.571973, "o", "    NaPosition,\r\n"]
[121.594344, "o", "    NDFrameT,\r\n"]
[121.616715, "o", "    RandomState,\r\n"]
[121.639086, "o", "    Renamer,\r\n"]
[121.661457, "o", "    Scalar,\r\n"]
[121.683828, "o", "    Self,\r\n"]
[121.706199, "o", "    SortKind,\r\n"]
[121.72857, "o", "    StorageOptions,\r\n"]
[121.750941, "o", "    Suffixes,\r\n"]
[121.773312, "o", "    T,\r\n"]
[121.795683, "o", "    TimeAmbiguous,\r\n"]
[121.818054, "o", "    TimedeltaConvertibleTypes,\r\n"]
[121.840425, "o", "    TimeNonexistent,\r\n"]
[121.862796, "o", "    TimestampConvertibleTypes,\r\n"]
[121.885167, "o", "    ValueKeyFunc,\r\n"]
[121.907538, "o", "    WriteBuffer,\r\n"]
[121.92991, "o", "    WriteExcelBuffer,\r\n"]
[121.952281, "o", "    npt,\r\n"]
[121.974652, "o", ")\r\n"]
[121.997023, "o", "from pandas.compat._optional import import_optional_dependency\r\n"]
[122.019394, "o", "from pandas.compat.numpy import function as nv\r\n"]
[122.041765, "o", "from pandas.errors import (\r\n"]
[122.064136, "o", "    AbstractMethodError,\r\n"]
[122.086507, "o", "    InvalidIndexError,\r\n"]
[122.108878, "o", "    SettingWithCopyError,\r\n"]
[122.131249, "o", "    SettingWithCopyWarning,\r\n"]
[122.15362, "o", ")\r\n"]
[122.175991, "o", "from pandas.util._decorators import doc\r\n"]
[122.198362, "o", "from pandas.util._exceptions import find_stack_level\r\n"]
[122.220733, "o", "from pandas.util._validators import (\r\n"]
[122.243104, "o", "    check_dtype_backend,\r\n"]
[122.265475, "o", "    validate_ascending,\r\n"]
[122.287846, "o", "    validate_bool_kwarg,\r\n"]
[122.310217, "o", "    validate_fillna_kwargs,\r\n"]
[122.332588, "o", "    validate_inclusive,\r\n"]
[122.354959, "o", ")\r\n"]
[122.37733, "o", "\r\n"]
[122.399701, "o", "from pandas.core.dtypes.common import (\r\n"]
[122.422072, "o", "    ensure_object,\r\n"]
[122.444443, "o", "    ensure_platform_int,\r\n"]
[122.466814, "o", "    ensure_str,\r\n"]
[122.489186, "o", "    is_bool,\r\n"]
[122.511557, "o", "    is_bool_dtype,\r\n"]
[122.533928, "o", "    is_datetime64_any_dtype,\r\n"]
[122.556299, "o", "    is_datetime64tz_dtype,\r\n"]
[122.57867, "o", "    is_dict_like,\r\n"]
[122.601041, "o", "    is_dtype_equal,\r\n"]
[122.623412, "o", "    is_extension_array_dtype,\r\n"]
[122.645783, "o", "    is_float,\r\n"]
[122.668154, "o", "    is_list_like,\r\n"]
[122.690525, "o", "    is_number,\r\n"]
[122.712896, "o", "    is_numeric_dtype,\r\n"]
[122.735267, "o", "    is_re_compilable,\r\n"]
[122.757638, "o", "    is_scalar,\r\n"]
[122.780009, "o", "    is_timedelta64_dtype,\r\n"]
[122.80238, "o", "    pandas_dtype,\r\n"]
[122.824751, "o", ")\r\n"]
[122.847122, "o", "from pandas.core.dtypes.generic import (\r\n"]
[122.869493, "o", "    ABCDataFrame,\r\n"]
[122.891864, "o", "    ABCSeries,\r\n"]
[122.914235, "o", ")\r\n"]
[122.936606, "o", "from pandas.core.dtypes.inference import (\r\n"]
[122.958977, "o", "    is_hashable,\r\n"]
[122.981348, "o", "    is_nested_list_like,\r\n"]
[123.003719, "o", ")\r\n"]
[123.02609, "o", "from pandas.core.dtypes.missing import (\r\n"]
[123.048462, "o", "    isna,\r\n"]
[123.070833, "o", "    notna,\r\n"]
[123.093204, "o", ")\r\n"]
[123.115575, "o", "\r\n"]
[123.137946, "o", "from pandas.core import (\r\n"]
[123.160317, "o", "    algorithms as algos,\r\n"]
[123.182688, "o", "    arraylike,\r\n"]
[123.205059, "o", "    common,\r\n"]
[123.22743, "o", "    indexing,\r\n"]
[123.249801, "o", "    nanops,\r\n"]
[123.272172, "o", "    sample,\r\n"]
[123.294543, "o", ")\r\n"]
[123.316914, "o", "from pandas.core.array_algos.replace import should_use_regex\r\n"]
[123.339285, "o", "from pandas.core.arrays import ExtensionArray\r\n"]
[123.361656, "o", "from pandas.core.base import PandasObject\r\n"]
[123.384027, "o", "from pandas.core.construction import extract_array\r\n"]
[123.406398, "o", "from pandas.core.flags import Flags\r\n"]
[123.428769, "o", "from pandas.core.indexes.api import (\r\n"]
[123.45114, "o", "    DatetimeIndex,\r\n"]
[123.473511, "o", "    Index,\r\n"]
[123.495882, "o", "    MultiIndex,\r\n"]
[123.518253, "o", "    PeriodIndex,\r\n"]
[123.540624, "o", "    RangeIndex,\r\n"]
[123.562995, "o", "    default_index,\r\n"]
[123.585367, "o", "    ensure_index,\r\n"]
[123.607738, "o", ")\r\n"]
[123.630109, "o", "from pandas.core.internals import (\r\n"]
[123.65248, "o", "    ArrayManager,\r\n"]
[123.674851, "o", "    BlockManager,\r\n"]
[123.697222, "o", "    SingleArrayManager,\r\n"]
[123.719593, "o", ")\r\n"]
[123.741964, "o", "from pandas.core.internals.construction import (\r\n"]
[123.764335, "o", "    mgr_to_mgr,\r\n"]
[123.786706, "o", "    ndarray_to_mgr,\r\n"]
[123.809077, "o", ")\r\n"]
[123.831448, "o", "from pandas.core.methods.describe import describe_ndframe\r\n"]
[123.853819, "o", "from pandas.core.missing import (\r\n"]
[123.87619, "o", "    clean_fill_method,\r\n"]
[123.898561, "o", "    clean_reindex_fill_method,\r\n"]
[123.920932, "o", "    find_valid_index,\r\n"]
[123.943303, "o", ")\r\n"]
[123.965674, "o", "from pandas.core.reshape.concat import concat\r\n"]
[123.988045, "o", "from pandas.core.shared_docs import _shared_docs\r\n"]
[124.010416, "o", "from pandas.core.sorting import get_indexer_indexer\r\n"]
[124.032787, "o", "from pandas.core.window import (\r\n"]
[124.055158, "o", "    Expanding,\r\n"]
[124.077529, "o", "    ExponentialMovingWindow,\r\n"]
[124.0999, "o", "    Rolling,\r\n"]
[124.122271, "o", "    Window,\r\n"]
[124.144643, "o", ")\r\n"]
[124.167014, "o", "\r\n"]
[124.189385, "o", "from pandas.io.formats.format import (\r\n"]
[124.211756, "o", "    DataFrameFormatter,\r\n"]
[124.234127, "o", "    DataFrameRenderer,\r\n"]
[124.256498, "o", ")\r\n"]
[124.278869, "o", "from pandas.io.formats.printing import pprint_thing\r\n"]
[124.30124, "o", "\r\n"]
[124.323611, "o", "if TYPE_CHECKING:\r\n"]
[124.345982, "o", "    from pandas._libs.tslibs import BaseOffset\r\n"]
[124.368353, "o", "\r\n"]
[124.390724, "o", "    from pandas import (\r\n"]
[124.413095, "o", "        DataFrame,\r\n"]
[124.435466, "o", "        ExcelWriter,\r\n"]
[124.457837, "o", "        HDFStore,\r\n"]
[124.480208, "o", "        Series,\r\n"]
[124.502579, "o", "    )\r\n"]
[124.52495, "o", "    from pandas.core.indexers.objects import BaseIndexer\r\n"]
[124.547321, "o", "    from pandas.core.resample import Resampler\r\n"]
[124.569692, "o", "\r\n"]
[124.592063, "o", "# goal is to be able to define the docs close to function, while still being\r\n"]
[124.614434, "o", "# able to share\r\n"]
[124.636805, "o", "_shared_docs = {**_shared_docs}\r\n"]
[124.659176, "o", "_shared_doc_kwargs = {\r\n"]
[124.681548, "o", "    \"axes\": \"keywords for axes\",\r\n"]
[124.703919, "o", "    \"klass\": \"Series/DataFrame\",\r\n"]
[124.72629, "o", "    \"axes_single_arg\": \"int or labels for object\",\r\n"]
[124.748661, "o", "    \"args_transpose\": \"axes to permute (int or label for object)\",\r\n"]
[124.771032, "o", "    \"inplace\": \"\"\"\r\n"]
[124.793403, "o", "    inplace : bool, default False\r\n"]
[124.815774, "o", "        If True, performs operation inplace and returns None.\"\"\",\r\n"]
[124.838145, "o", "    \"optional_by\": \"\"\"\r\n"]
[124.860516, "o", "        by : str or list of str\r\n"]
[124.882887, "o", "            Name or list of names to sort by\"\"\",\r\n"]
[124.905258, "o", "    \"replace_iloc\": \"\"\"\r\n"]
[124.927629, "o", "    This differs from updating with ``.loc`` or ``.iloc``, which require\r\n"]
[125.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[125.002, "i", "sed -n '1,260p' pandas/core/series.py\r"]
[125.004, "o", "sed -n '1,260p' pandas/core/series.py\r\n"]
[125.024943, "o", "\u001b[?2004l\r\n"]
[125.043885, "o", "\"\"\"\r\n"]
[125.062828, "o", "Data structure for 1-dimensional cross-sectional and time series data\r\n"]
[125.08177, "o", "\"\"\"\r\n"]
[125.100713, "o", "from __future__ import annotations\r\n"]
[125.119655, "o", "\r\n"]
[125.138598, "o", "import operator\r\n"]
[125.15754, "o", "import sys\r\n"]
[125.176483, "o", "from textwrap import dedent\r\n"]
[125.195425, "o", "from typing import (\r\n"]
[125.214368, "o", "    IO,\r\n"]
[125.23331, "o", "    TYPE_CHECKING,\r\n"]
[125.252253, "o", "    Any,\r\n"]
[125.271195, "o", "    Callable,\r\n"]
[125.290138, "o", "    Hashable,\r\n"]
[125.30908, "o", "    Iterable,\r\n"]
[125.328023, "o", "    Literal,\r\n"]
[125.346966, "o", "    Mapping,\r\n"]
[125.365908, "o", "    Sequence,\r\n"]
[125.384851, "o", "    Union,\r\n"]
[125.403793, "o", "    cast,\r\n"]
[125.422736, "o", "    overload,\r\n"]
[125.441678, "o", ")\r\n"]
[125.460621, "o", "import warnings\r\n"]
[125.479563, "o", "import weakref\r\n"]
[125.498506, "o", "\r\n"]
[125.517448, "o", "import numpy as np\r\n"]
[125.536391, "o", "\r\n"]
[125.555333, "o", "from pandas._config import (\r\n"]
[125.574276, "o", "    get_option,\r\n"]
[125.593218, "o", "    using_copy_on_write,\r\n"]
[125.612161, "o", ")\r\n"]
[125.631103, "o", "\r\n"]
[125.650046, "o", "from pandas._libs import (\r\n"]
[125.668989, "o", "    lib,\r\n"]
[125.687931, "o", "    properties,\r\n"]
[125.706874, "o", "    reshape,\r\n"]
[125.725816, "o", ")\r\n"]
[125.744759, "o", "from pandas._libs.lib import is_range_indexer\r\n"]
[125.763701, "o", "from pandas.compat import PYPY\r\n"]
[125.782644, "o", "from pandas.compat.numpy import function as nv\r\n"]
[125.801586, "o", "from pandas.errors import (\r\n"]
[125.820529, "o", "    ChainedAssignmentError,\r\n"]
[125.839471, "o", "    InvalidIndexError,\r\n"]
[125.858414, "o", "    _chained_assignment_msg,\r\n"]
[125.877356, "o", ")\r\n"]
[125.896299, "o", "from pandas.util._decorators import (\r\n"]
[125.915241, "o", "    Appender,\r\n"]
[125.934184, "o", "    Substitution,\r\n"]
[125.953126, "o", "    doc,\r\n"]
[125.972069, "o", ")\r\n"]
[125.991011, "o", "from pandas.util._exceptions import find_stack_level\r\n"]
[126.009954, "o", "from pandas.util._validators import (\r\n"]
[126.028897, "o", "    validate_ascending,\r\n"]
[126.047839, "o", "    validate_bool_kwarg,\r\n"]
[126.066782, "o", "    validate_percentile,\r\n"]
[126.085724, "o", ")\r\n"]
[126.104667, "o", "\r\n"]
[126.123609, "o", "from pandas.core.dtypes.cast import (\r\n"]
[126.142552, "o", "    LossySetitemError,\r\n"]
[126.161494, "o", "    convert_dtypes,\r\n"]
[126.180437, "o", "    maybe_box_native,\r\n"]
[126.199379, "o", "    maybe_cast_pointwise_result,\r\n"]
[126.218322, "o", ")\r\n"]
[126.237264, "o", "from pandas.core.dtypes.common import (\r\n"]
[126.256207, "o", "    is_dict_like,\r\n"]
[126.275149, "o", "    is_extension_array_dtype,\r\n"]
[126.294092, "o", "    is_integer,\r\n"]
[126.313034, "o", "    is_iterator,\r\n"]
[126.331977, "o", "    is_list_like,\r\n"]
[126.35092, "o", "    is_numeric_dtype,\r\n"]
[126.369862, "o", "    is_object_dtype,\r\n"]
[126.388805, "o", "    is_scalar,\r\n"]
[126.407747, "o", "    pandas_dtype,\r\n"]
[126.42669, "o", "    validate_all_hashable,\r\n"]
[126.445632, "o", ")\r\n"]
[126.464575, "o", "from pandas.core.dtypes.generic import ABCDataFrame\r\n"]
[126.483517, "o", "from pandas.core.dtypes.inference import is_hashable\r\n"]
[126.50246, "o", "from pandas.core.dtypes.missing import (\r\n"]
[126.521402, "o", "    isna,\r\n"]
[126.540345, "o", "    na_value_for_dtype,\r\n"]
[126.559287, "o", "    notna,\r\n"]
[126.57823, "o", "    remove_na_arraylike,\r\n"]
[126.597172, "o", ")\r\n"]
[126.616115, "o", "\r\n"]
[126.635057, "o", "from pandas.core import (\r\n"]
[126.654, "o", "    algorithms,\r\n"]
[126.672943, "o", "    base,\r\n"]
[126.691885, "o", "    common as com,\r\n"]
[126.710828, "o", "    missing,\r\n"]
[126.72977, "o", "    nanops,\r\n"]
[126.748713, "o", "    ops,\r\n"]
[126.767655, "o", "    roperator,\r\n"]
[126.786598, "o", ")\r\n"]
[126.80554, "o", "from pandas.core.accessor import CachedAccessor\r\n"]
[126.824483, "o", "from pandas.core.apply import SeriesApply\r\n"]
[126.843425, "o", "from pandas.core.arrays import ExtensionArray\r\n"]
[126.862368, "o", "from pandas.core.arrays.categorical import CategoricalAccessor\r\n"]
[126.88131, "o", "from pandas.core.arrays.sparse import SparseAccessor\r\n"]
[126.900253, "o", "from pandas.core.construction import (\r\n"]
[126.919195, "o", "    extract_array,\r\n"]
[126.938138, "o", "    sanitize_array,\r\n"]
[126.95708, "o", ")\r\n"]
[126.976023, "o", "from pandas.core.generic import NDFrame\r\n"]
[126.994966, "o", "from pandas.core.indexers import (\r\n"]
[127.013908, "o", "    disallow_ndim_indexing,\r\n"]
[127.032851, "o", "    unpack_1tuple,\r\n"]
[127.051793, "o", ")\r\n"]
[127.070736, "o", "from pandas.core.indexes.accessors import CombinedDatetimelikeProperties\r\n"]
[127.089678, "o", "from pandas.core.indexes.api import (\r\n"]
[127.108621, "o", "    DatetimeIndex,\r\n"]
[127.127563, "o", "    Index,\r\n"]
[127.146506, "o", "    MultiIndex,\r\n"]
[127.165448, "o", "    PeriodIndex,\r\n"]
[127.184391, "o", "    default_index,\r\n"]
[127.203333, "o", "    ensure_index,\r\n"]
[127.222276, "o", ")\r\n"]
[127.241218, "o", "import pandas.core.indexes.base as ibase\r\n"]
[127.260161, "o", "from pandas.core.indexes.multi import maybe_droplevels\r\n"]
[127.279103, "o", "from pandas.core.indexing import (\r\n"]
[127.298046, "o", "    check_bool_indexer,\r\n"]
[127.316989, "o", "    check_dict_or_set_indexers,\r\n"]
[127.335931, "o", ")\r\n"]
[127.354874, "o", "from pandas.core.internals import (\r\n"]
[127.373816, "o", "    SingleArrayManager,\r\n"]
[127.392759, "o", "    SingleBlockManager,\r\n"]
[127.411701, "o", ")\r\n"]
[127.430644, "o", "from pandas.core.methods import selectn\r\n"]
[127.449586, "o", "from pandas.core.shared_docs import _shared_docs\r\n"]
[127.468529, "o", "from pandas.core.sorting import (\r\n"]
[127.487471, "o", "    ensure_key_mapped,\r\n"]
[127.506414, "o", "    nargsort,\r\n"]
[127.525356, "o", ")\r\n"]
[127.544299, "o", "from pandas.core.strings.accessor import StringMethods\r\n"]
[127.563241, "o", "from pandas.core.tools.datetimes import to_datetime\r\n"]
[127.582184, "o", "\r\n"]
[127.601126, "o", "import pandas.io.formats.format as fmt\r\n"]
[127.620069, "o", "from pandas.io.formats.info import (\r\n"]
[127.639011, "o", "    INFO_DOCSTRING,\r\n"]
[127.657954, "o", "    SeriesInfo,\r\n"]
[127.676897, "o", "    series_sub_kwargs,\r\n"]
[127.695839, "o", ")\r\n"]
[127.714782, "o", "import pandas.plotting\r\n"]
[127.733724, "o", "\r\n"]
[127.752667, "o", "if TYPE_CHECKING:\r\n"]
[127.771609, "o", "    from pandas._libs.internals import BlockValuesRefs\r\n"]
[127.790552, "o", "    from pandas._typing import (\r\n"]
[127.809494, "o", "        AggFuncType,\r\n"]
[127.828437, "o", "        AlignJoin,\r\n"]
[127.847379, "o", "        AnyAll,\r\n"]
[127.866322, "o", "        AnyArrayLike,\r\n"]
[127.885264, "o", "        ArrayLike,\r\n"]
[127.904207, "o", "        Axis,\r\n"]
[127.923149, "o", "        AxisInt,\r\n"]
[127.942092, "o", "        CorrelationMethod,\r\n"]
[127.961034, "o", "        DropKeep,\r\n"]
[127.979977, "o", "        Dtype,\r\n"]
[127.99892, "o", "        DtypeBackend,\r\n"]
[128.017862, "o", "        DtypeObj,\r\n"]
[128.036805, "o", "        FilePath,\r\n"]
[128.055747, "o", "        FillnaOptions,\r\n"]
[128.07469, "o", "        Frequency,\r\n"]
[128.093632, "o", "        IgnoreRaise,\r\n"]
[128.112575, "o", "        IndexKeyFunc,\r\n"]
[128.131517, "o", "        IndexLabel,\r\n"]
[128.15046, "o", "        Level,\r\n"]
[128.169402, "o", "        NaPosition,\r\n"]
[128.188345, "o", "        NDFrameT,\r\n"]
[128.207287, "o", "        NumpySorter,\r\n"]
[128.22623, "o", "        NumpyValueArrayLike,\r\n"]
[128.245172, "o", "        QuantileInterpolation,\r\n"]
[128.264115, "o", "        Renamer,\r\n"]
[128.283057, "o", "        Scalar,\r\n"]
[128.302, "o", "        Self,\r\n"]
[128.320943, "o", "        SingleManager,\r\n"]
[128.339885, "o", "        SortKind,\r\n"]
[128.358828, "o", "        StorageOptions,\r\n"]
[128.37777, "o", "        Suffixes,\r\n"]
[128.396713, "o", "        TimedeltaConvertibleTypes,\r\n"]
[128.415655, "o", "        TimestampConvertibleTypes,\r\n"]
[128.434598, "o", "        ValueKeyFunc,\r\n"]
[128.45354, "o", "        WriteBuffer,\r\n"]
[128.472483, "o", "        npt,\r\n"]
[128.491425, "o", "    )\r\n"]
[128.510368, "o", "\r\n"]
[128.52931, "o", "    from pandas.core.frame import DataFrame\r\n"]
[128.548253, "o", "    from pandas.core.groupby.generic import SeriesGroupBy\r\n"]
[128.567195, "o", "    from pandas.core.resample import Resampler\r\n"]
[128.586138, "o", "\r\n"]
[128.60508, "o", "__all__ = [\"Series\"]\r\n"]
[128.624023, "o", "\r\n"]
[128.642966, "o", "_shared_doc_kwargs = {\r\n"]
[128.661908, "o", "    \"axes\": \"index\",\r\n"]
[128.680851, "o", "    \"klass\": \"Series\",\r\n"]
[128.699793, "o", "    \"axes_single_arg\": \"{0 or 'index'}\",\r\n"]
[128.718736, "o", "    \"axis\": \"\"\"axis : {0 or 'index'}\r\n"]
[128.737678, "o", "        Unused. Parameter needed for compatibility with DataFrame.\"\"\",\r\n"]
[128.756621, "o", "    \"inplace\": \"\"\"inplace : bool, default False\r\n"]
[128.775563, "o", "        If True, performs operation inplace and returns None.\"\"\",\r\n"]
[128.794506, "o", "    \"unique\": \"np.ndarray\",\r\n"]
[128.813448, "o", "    \"duplicated\": \"Series\",\r\n"]
[128.832391, "o", "    \"optional_by\": \"\",\r\n"]
[128.851333, "o", "    \"optional_mapper\": \"\",\r\n"]
[128.870276, "o", "    \"optional_reindex\": \"\"\"\r\n"]
[128.889218, "o", "index : array-like, optional\r\n"]
[128.908161, "o", "    New labels for the index. Preferably an Index object to avoid\r\n"]
[128.927103, "o", "    duplicating data.\r\n"]
[128.946046, "o", "axis : int or str, optional\r\n"]
[128.964989, "o", "    Unused.\"\"\",\r\n"]
[128.983931, "o", "    \"replace_iloc\": \"\"\"\r\n"]
[129.002874, "o", "    This differs from updating with ``.loc`` or ``.iloc``, which require\r\n"]
[129.021816, "o", "    you to specify a location to update with some value.\"\"\",\r\n"]
[129.040759, "o", "}\r\n"]
[129.059701, "o", "\r\n"]
[129.078644, "o", "\r\n"]
[129.097586, "o", "def _coerce_method(converter):\r\n"]
[129.116529, "o", "    \"\"\"\r\n"]
[129.135471, "o", "    Install the scalar coercion methods.\r\n"]
[129.154414, "o", "    \"\"\"\r\n"]
[129.173356, "o", "\r\n"]
[129.192299, "o", "    def wrapper(self):\r\n"]
[129.211241, "o", "        if len(self) == 1:\r\n"]
[129.230184, "o", "            warnings.warn(\r\n"]
[129.249126, "o", "                f\"Calling {converter.__name__} on a single element Series is \"\r\n"]
[129.268069, "o", "                \"deprecated and will raise a TypeError in the future. \"\r\n"]
[129.287011, "o", "                f\"Use {converter.__name__}(ser.iloc[0]) instead\",\r\n"]
[129.305954, "o", "                FutureWarning,\r\n"]
[129.324897, "o", "                stacklevel=find_stack_level(),\r\n"]
[129.343839, "o", "            )\r\n"]
[129.362782, "o", "            return converter(self.iloc[0])\r\n"]
[129.381724, "o", "        raise TypeError(f\"cannot convert the series to {converter}\")\r\n"]
[129.400667, "o", "\r\n"]
[129.419609, "o", "    wrapper.__name__ = f\"__{converter.__name__}__\"\r\n"]
[129.438552, "o", "    return wrapper\r\n"]
[129.457494, "o", "\r\n"]
[129.476437, "o", "\r\n"]
[129.495379, "o", "# ----------------------------------------------------------------------\r\n"]
[129.514322, "o", "# Series class\r\n"]
[129.533264, "o", "\r\n"]
[129.552207, "o", "\r\n"]
[129.571149, "o", "# error: Definition of \"max\" in base class \"IndexOpsMixin\" is incompatible with\r\n"]
[129.590092, "o", "# definition in base class \"NDFrame\"\r\n"]
[129.609034, "o", "# error: Definition of \"min\" in base class \"IndexOpsMixin\" is incompatible with\r\n"]
[129.627977, "o", "# definition in base class \"NDFrame\"\r\n"]
[129.64692, "o", "class Series(base.IndexOpsMixin, NDFrame):  # type: ignore[misc]\r\n"]
[129.665862, "o", "    \"\"\"\r\n"]
[129.684805, "o", "    One-dimensional ndarray with axis labels (including time series).\r\n"]
[129.703747, "o", "\r\n"]
[129.72269, "o", "    Labels need not be unique but must be a hashable type. The object\r\n"]
[129.741632, "o", "    supports both integer- and label-based indexing and provides a host of\r\n"]
[129.760575, "o", "    methods for performing operations involving the index. Statistical\r\n"]
[129.779517, "o", "    methods from ndarray have been overridden to automatically exclude\r\n"]
[129.79846, "o", "    missing data (currently represented as NaN).\r\n"]
[129.817402, "o", "\r\n"]
[129.836345, "o", "    Operations between Series (+, -, /, \\\\*, \\\\*\\\\*) align values based on their\r\n"]
[129.855287, "o", "    associated index values-- they need not be the same length. The result\r\n"]
[129.87423, "o", "    index will be the sorted union of the two indexes.\r\n"]
[129.893172, "o", "\r\n"]
[129.912115, "o", "    Parameters\r\n"]
[129.931057, "o", "    ----------\r\n"]
[130.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[130.002, "i", "sed -n '1,200p' asv_bench/asv.conf.json\r"]
[130.004, "o", "sed -n '1,200p' asv_bench/asv.conf.json\r\n"]
[130.043455, "o", "\u001b[?2004l\r\n"]
[130.080909, "o", "{\r\n"]
[130.118364, "o", "    // The version of the config file format.  Do not change, unless\r\n"]
[130.155818, "o", "    // you know what you are doing.\r\n"]
[130.193273, "o", "    \"version\": 1,\r\n"]
[130.230727, "o", "\r\n"]
[130.268182, "o", "    // The name of the project being benchmarked\r\n"]
[130.305636, "o", "    \"project\": \"pandas\",\r\n"]
[130.343091, "o", "\r\n"]
[130.380545, "o", "    // The project's homepage\r\n"]
[130.418, "o", "    \"project_url\": \"https://pandas.pydata.org/\",\r\n"]
[130.455455, "o", "\r\n"]
[130.492909, "o", "    // The URL of the source code repository for the project being\r\n"]
[130.530364, "o", "    // benchmarked\r\n"]
[130.567818, "o", "    \"repo\": \"..\",\r\n"]
[130.605273, "o", "\r\n"]
[130.642727, "o", "    // List of branches to benchmark. If not provided, defaults to \"master\"\r\n"]
[130.680182, "o", "    // (for git) or \"default\" (for mercurial).\r\n"]
[130.717636, "o", "    \"branches\": [\"main\"],\r\n"]
[130.755091, "o", "\r\n"]
[130.792545, "o", "    // The tool to use to create environments.  May be \"conda\",\r\n"]
[130.83, "o", "    // \"virtualenv\" or other value depending on the plugins in use.\r\n"]
[130.867455, "o", "    // If missing or the empty string, the tool will be automatically\r\n"]
[130.904909, "o", "    // determined by looking for tools on the PATH environment\r\n"]
[130.942364, "o", "    // variable.\r\n"]
[130.979818, "o", "    \"environment_type\": \"conda\",\r\n"]
[131.017273, "o", "\r\n"]
[131.054727, "o", "    // the base URL to show a commit for the project.\r\n"]
[131.092182, "o", "    \"show_commit_url\": \"https://github.com/pandas-dev/pandas/commit/\",\r\n"]
[131.129636, "o", "\r\n"]
[131.167091, "o", "    // The Pythons you'd like to test against.  If not provided, defaults\r\n"]
[131.204545, "o", "    // to the current version of Python used to run `asv`.\r\n"]
[131.242, "o", "    \"pythons\": [\"3.8\"],\r\n"]
[131.279455, "o", "\r\n"]
[131.316909, "o", "    // The matrix of dependencies to test.  Each key is the name of a\r\n"]
[131.354364, "o", "    // package (in PyPI) and the values are version numbers.  An empty\r\n"]
[131.391818, "o", "    // list or empty string indicates to just test against the default\r\n"]
[131.429273, "o", "    // (latest) version. null indicates that the package is to not be\r\n"]
[131.466727, "o", "    // installed. If the package to be tested is only available from\r\n"]
[131.504182, "o", "    // PyPi, and the 'environment_type' is conda, then you can preface\r\n"]
[131.541636, "o", "    // the package name by 'pip+', and the package will be installed via\r\n"]
[131.579091, "o", "    // pip (with all the conda available packages installed first,\r\n"]
[131.616545, "o", "    // followed by the pip installed packages).\r\n"]
[131.654, "o", "    \"matrix\": {\r\n"]
[131.691455, "o", "        \"numpy\": [],\r\n"]
[131.728909, "o", "        \"Cython\": [\"0.29.33\"],\r\n"]
[131.766364, "o", "        \"matplotlib\": [],\r\n"]
[131.803818, "o", "        \"sqlalchemy\": [],\r\n"]
[131.841273, "o", "        \"scipy\": [],\r\n"]
[131.878727, "o", "        \"numba\": [],\r\n"]
[131.916182, "o", "        \"numexpr\": [],\r\n"]
[131.953636, "o", "        \"pytables\": [null, \"\"],  // platform dependent, see excludes below\r\n"]
[131.991091, "o", "        \"pyarrow\": [],\r\n"]
[132.028545, "o", "        \"tables\": [null, \"\"],\r\n"]
[132.066, "o", "        \"openpyxl\": [],\r\n"]
[132.103455, "o", "        \"xlsxwriter\": [],\r\n"]
[132.140909, "o", "        \"xlrd\": [],\r\n"]
[132.178364, "o", "        \"odfpy\": [],\r\n"]
[132.215818, "o", "        \"jinja2\": [],\r\n"]
[132.253273, "o", "    },\r\n"]
[132.290727, "o", "    \"conda_channels\": [\"conda-forge\"],\r\n"]
[132.328182, "o", "    // Combinations of libraries/python versions can be excluded/included\r\n"]
[132.365636, "o", "    // from the set to test. Each entry is a dictionary containing additional\r\n"]
[132.403091, "o", "    // key-value pairs to include/exclude.\r\n"]
[132.440545, "o", "    //\r\n"]
[132.478, "o", "    // An exclude entry excludes entries where all values match. The\r\n"]
[132.515455, "o", "    // values are regexps that should match the whole string.\r\n"]
[132.552909, "o", "    //\r\n"]
[132.590364, "o", "    // An include entry adds an environment. Only the packages listed\r\n"]
[132.627818, "o", "    // are installed. The 'python' key is required. The exclude rules\r\n"]
[132.665273, "o", "    // do not apply to includes.\r\n"]
[132.702727, "o", "    //\r\n"]
[132.740182, "o", "    // In addition to package names, the following keys are available:\r\n"]
[132.777636, "o", "    //\r\n"]
[132.815091, "o", "    // - python\r\n"]
[132.852545, "o", "    //     Python version, as in the *pythons* variable above.\r\n"]
[132.89, "o", "    // - environment_type\r\n"]
[132.927455, "o", "    //     Environment type, as above.\r\n"]
[132.964909, "o", "    // - sys_platform\r\n"]
[133.002364, "o", "    //     Platform, as in sys.platform. Possible values for the common\r\n"]
[133.039818, "o", "    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.\r\n"]
[133.077273, "o", "    \"exclude\": [\r\n"]
[133.114727, "o", "        // On conda install pytables, otherwise tables\r\n"]
[133.152182, "o", "        {\"environment_type\": \"conda\", \"tables\": \"\"},\r\n"]
[133.189636, "o", "        {\"environment_type\": \"conda\", \"pytables\": null},\r\n"]
[133.227091, "o", "        {\"environment_type\": \"(?!conda).*\", \"tables\": null},\r\n"]
[133.264545, "o", "        {\"environment_type\": \"(?!conda).*\", \"pytables\": \"\"},\r\n"]
[133.302, "o", "    ],\r\n"]
[133.339455, "o", "    \"include\": [],\r\n"]
[133.376909, "o", "\r\n"]
[133.414364, "o", "    // The directory (relative to the current directory) that benchmarks are\r\n"]
[133.451818, "o", "    // stored in.  If not provided, defaults to \"benchmarks\"\r\n"]
[133.489273, "o", "    // \"benchmark_dir\": \"benchmarks\",\r\n"]
[133.526727, "o", "\r\n"]
[133.564182, "o", "    // The directory (relative to the current directory) to cache the Python\r\n"]
[133.601636, "o", "    // environments in.  If not provided, defaults to \"env\"\r\n"]
[133.639091, "o", "    // \"env_dir\": \"env\",\r\n"]
[133.676545, "o", "\r\n"]
[133.714, "o", "    // The directory (relative to the current directory) that raw benchmark\r\n"]
[133.751455, "o", "    // results are stored in.  If not provided, defaults to \"results\".\r\n"]
[133.788909, "o", "    // \"results_dir\": \"results\",\r\n"]
[133.826364, "o", "\r\n"]
[133.863818, "o", "    // The directory (relative to the current directory) that the html tree\r\n"]
[133.901273, "o", "    // should be written to.  If not provided, defaults to \"html\".\r\n"]
[133.938727, "o", "    // \"html_dir\": \"html\",\r\n"]
[133.976182, "o", "\r\n"]
[134.013636, "o", "    // The number of characters to retain in the commit hashes.\r\n"]
[134.051091, "o", "    // \"hash_length\": 8,\r\n"]
[134.088545, "o", "\r\n"]
[134.126, "o", "    // `asv` will cache wheels of the recent builds in each\r\n"]
[134.163455, "o", "    // environment, making them faster to install next time.  This is\r\n"]
[134.200909, "o", "    // number of builds to keep, per environment.\r\n"]
[134.238364, "o", "    \"build_cache_size\": 8,\r\n"]
[134.275818, "o", "\r\n"]
[134.313273, "o", "    // The commits after which the regression search in `asv publish`\r\n"]
[134.350727, "o", "    // should start looking for regressions. Dictionary whose keys are\r\n"]
[134.388182, "o", "    // regexps matching to benchmark names, and values corresponding to\r\n"]
[134.425636, "o", "    // the commit (exclusive) after which to start looking for\r\n"]
[134.463091, "o", "    // regressions.  The default is to start from the first commit\r\n"]
[134.500545, "o", "    // with results. If the commit is `null`, regression detection is\r\n"]
[134.538, "o", "    // skipped for the matching benchmark.\r\n"]
[134.575455, "o", "    //\r\n"]
[134.612909, "o", "    \"regressions_first_commits\": {\r\n"]
[134.650364, "o", "        \".*\": \"0409521665\"\r\n"]
[134.687818, "o", "    },\r\n"]
[134.725273, "o", "    \"regression_thresholds\": {\r\n"]
[134.762727, "o", "    },\r\n"]
[134.800182, "o", "    \"build_command\":\r\n"]
[134.837636, "o", "    [\"python -m pip install versioneer[toml]\",\r\n"]
[134.875091, "o", "     \"python setup.py build -j4\",\r\n"]
[134.912545, "o", "     \"PIP_NO_BUILD_ISOLATION=false python -mpip wheel --no-deps --no-index -w {build_cache_dir} {build_dir}\"],\r\n"]
[135.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[135.002, "i", "asv --help | head -n 50\r"]
[135.004, "o", "asv --help | head -n 50\r\n"]
[135.139622, "o", "\u001b[?2004l\r\n"]
[135.273243, "o", "usage: asv [-h] [--verbose] [--config CONFIG] [--version]\r\n"]
[135.406865, "o", "           {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages}\r\n"]
[135.540486, "o", "           ...\r\n"]
[135.674108, "o", "\r\n"]
[135.80773, "o", "Airspeed Velocity: Simple benchmarking tool for Python\r\n"]
[135.941351, "o", "\r\n"]
[136.074973, "o", "optional arguments:\r\n"]
[136.208595, "o", "  -h, --help            show this help message and exit\r\n"]
[136.342216, "o", "  --verbose, -v         Increase verbosity\r\n"]
[136.475838, "o", "  --config CONFIG       Benchmark configuration file\r\n"]
[136.609459, "o", "  --version             Print program version\r\n"]
[136.743081, "o", "\r\n"]
[136.876703, "o", "subcommands:\r\n"]
[137.010324, "o", "  valid subcommands\r\n"]
[137.143946, "o", "\r\n"]
[137.277568, "o", "  {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages}\r\n"]
[137.411189, "o", "    help                Display usage information\r\n"]
[137.544811, "o", "    quickstart          Create a new benchmarking suite\r\n"]
[137.678432, "o", "    machine             Define information about this machine\r\n"]
[137.812054, "o", "    setup               Setup virtual environments\r\n"]
[137.945676, "o", "    run                 Run a benchmark suite\r\n"]
[138.079297, "o", "    continuous          Compare two commits directly\r\n"]
[138.212919, "o", "    find                Find commits that introduced large regressions\r\n"]
[138.346541, "o", "    rm                  Remove results from the database\r\n"]
[138.480162, "o", "    publish             Collate results into a website\r\n"]
[138.613784, "o", "    preview             Preview the results using a local web server\r\n"]
[138.747405, "o", "    profile             Run the profiler on a particular benchmark on a\r\n"]
[138.881027, "o", "                        particular revision\r\n"]
[139.014649, "o", "    update              Update the results and config files to the current\r\n"]
[139.14827, "o", "                        version\r\n"]
[139.281892, "o", "    show                Print recorded data\r\n"]
[139.415514, "o", "    compare             Compare the benchmark results between two revisions\r\n"]
[139.549135, "o", "                        (averaged over configurations)\r\n"]
[139.682757, "o", "    check               Import and check benchmark suite, but do not run\r\n"]
[139.816378, "o", "                        benchmarks\r\n"]
[140.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[140.002, "i", "asv run --python=same --config=/workspace/repo/asv_bench/asv.conf.json --bench=\"series_methods.ToNumpy.*\"\r"]
[140.004, "o", "asv run --python=same --config=/workspace/repo/asv_bench/asv.conf.json --bench=\"series_methods.ToNumpy.*\"\r\n"]
[140.624, "o", "\u001b[?2004l\r\n"]
[141.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[141.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[142.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[143.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[143.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                   1.38\u00b10.01\u03bcs\r\n"]
[144.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                  372\u00b14\u03bcs\r\n"]
[145.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[145.002, "i", "asv show --config=/workspace/repo/asv_bench/asv.conf.json\r"]
[145.004, "o", "asv show --config=/workspace/repo/asv_bench/asv.conf.json\r\n"]
[146.654, "o", "\u001b[?2004l\r\n"]
[148.302, "o", "Commits with results:\r\n"]
[150.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[150.002, "i", "asv profile --python=same --config=/workspace/repo/asv_bench/asv.conf.json series_methods.ToNumpy.*\r"]
[150.004, "o", "asv profile --python=same --config=/workspace/repo/asv_bench/asv.conf.json series_methods.ToNumpy.*\r\n"]
[151.654, "o", "\u001b[?2004l\r\n"]
[153.302, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[155.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[155.002, "i", "sed -n '430,520p' pandas/core/base.py\r"]
[155.004, "o", "sed -n '430,520p' pandas/core/base.py\r\n"]
[155.059739, "o", "\u001b[?2004l\r\n"]
[155.113478, "o", "        This table lays out the different array types for each extension\r\n"]
[155.167217, "o", "        dtype within pandas.\r\n"]
[155.220957, "o", "\r\n"]
[155.274696, "o", "        ================== =============================\r\n"]
[155.328435, "o", "        dtype              array type\r\n"]
[155.382174, "o", "        ================== =============================\r\n"]
[155.435913, "o", "        category           Categorical\r\n"]
[155.489652, "o", "        period             PeriodArray\r\n"]
[155.543391, "o", "        interval           IntervalArray\r\n"]
[155.59713, "o", "        IntegerNA          IntegerArray\r\n"]
[155.65087, "o", "        string             StringArray\r\n"]
[155.704609, "o", "        boolean            BooleanArray\r\n"]
[155.758348, "o", "        datetime64[ns, tz] DatetimeArray\r\n"]
[155.812087, "o", "        ================== =============================\r\n"]
[155.865826, "o", "\r\n"]
[155.919565, "o", "        For any 3rd-party extension types, the array type will be an\r\n"]
[155.973304, "o", "        ExtensionArray.\r\n"]
[156.027043, "o", "\r\n"]
[156.080783, "o", "        For all remaining dtypes ``.array`` will be a\r\n"]
[156.134522, "o", "        :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\r\n"]
[156.188261, "o", "        stored within. If you absolutely need a NumPy array (possibly with\r\n"]
[156.242, "o", "        copying / coercing data), then use :meth:`Series.to_numpy` instead.\r\n"]
[156.295739, "o", "\r\n"]
[156.349478, "o", "        Examples\r\n"]
[156.403217, "o", "        --------\r\n"]
[156.456957, "o", "        For regular NumPy types like int, and float, a PandasArray\r\n"]
[156.510696, "o", "        is returned.\r\n"]
[156.564435, "o", "\r\n"]
[156.618174, "o", "        >>> pd.Series([1, 2, 3]).array\r\n"]
[156.671913, "o", "        <PandasArray>\r\n"]
[156.725652, "o", "        [1, 2, 3]\r\n"]
[156.779391, "o", "        Length: 3, dtype: int64\r\n"]
[156.83313, "o", "\r\n"]
[156.88687, "o", "        For extension types, like Categorical, the actual ExtensionArray\r\n"]
[156.940609, "o", "        is returned\r\n"]
[156.994348, "o", "\r\n"]
[157.048087, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[157.101826, "o", "        >>> ser.array\r\n"]
[157.155565, "o", "        ['a', 'b', 'a']\r\n"]
[157.209304, "o", "        Categories (2, object): ['a', 'b']\r\n"]
[157.263043, "o", "        \"\"\"\r\n"]
[157.316783, "o", "        raise AbstractMethodError(self)\r\n"]
[157.370522, "o", "\r\n"]
[157.424261, "o", "    @final\r\n"]
[157.478, "o", "    def to_numpy(\r\n"]
[157.531739, "o", "        self,\r\n"]
[157.585478, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[157.639217, "o", "        copy: bool = False,\r\n"]
[157.692957, "o", "        na_value: object = lib.no_default,\r\n"]
[157.746696, "o", "        **kwargs,\r\n"]
[157.800435, "o", "    ) -> np.ndarray:\r\n"]
[157.854174, "o", "        \"\"\"\r\n"]
[157.907913, "o", "        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[157.961652, "o", "\r\n"]
[158.015391, "o", "        Parameters\r\n"]
[158.06913, "o", "        ----------\r\n"]
[158.12287, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[158.176609, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[158.230348, "o", "        copy : bool, default False\r\n"]
[158.284087, "o", "            Whether to ensure that the returned value is not a view on\r\n"]
[158.337826, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[158.391565, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[158.445304, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[158.499043, "o", "        na_value : Any, optional\r\n"]
[158.552783, "o", "            The value to use for missing values. The default value depends\r\n"]
[158.606522, "o", "            on `dtype` and the type of the array.\r\n"]
[158.660261, "o", "        **kwargs\r\n"]
[158.714, "o", "            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[158.767739, "o", "            of the underlying array (for extension arrays).\r\n"]
[158.821478, "o", "\r\n"]
[158.875217, "o", "        Returns\r\n"]
[158.928957, "o", "        -------\r\n"]
[158.982696, "o", "        numpy.ndarray\r\n"]
[159.036435, "o", "\r\n"]
[159.090174, "o", "        See Also\r\n"]
[159.143913, "o", "        --------\r\n"]
[159.197652, "o", "        Series.array : Get the actual data stored within.\r\n"]
[159.251391, "o", "        Index.array : Get the actual data stored within.\r\n"]
[159.30513, "o", "        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[159.35887, "o", "\r\n"]
[159.412609, "o", "        Notes\r\n"]
[159.466348, "o", "        -----\r\n"]
[159.520087, "o", "        The returned array will be the same up to equality (values equal\r\n"]
[159.573826, "o", "        in `self` will be equal in the returned array; likewise for values\r\n"]
[159.627565, "o", "        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[159.681304, "o", "        dtype may be different. For example, for a category-dtype Series,\r\n"]
[159.735043, "o", "        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[159.788783, "o", "        will be lost.\r\n"]
[159.842522, "o", "\r\n"]
[159.896261, "o", "        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[160.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[160.002, "i", "sed -n '1680,1820p' pandas/core/series.py\r"]
[160.004, "o", "sed -n '1680,1820p' pandas/core/series.py\r\n"]
[160.040817, "o", "\u001b[?2004l\r\n"]
[160.075634, "o", "            na_rep=na_rep,\r\n"]
[160.110451, "o", "            float_format=float_format,\r\n"]
[160.145268, "o", "            min_rows=min_rows,\r\n"]
[160.180085, "o", "            max_rows=max_rows,\r\n"]
[160.214901, "o", "        )\r\n"]
[160.249718, "o", "        result = formatter.to_string()\r\n"]
[160.284535, "o", "\r\n"]
[160.319352, "o", "        # catch contract violations\r\n"]
[160.354169, "o", "        if not isinstance(result, str):\r\n"]
[160.388986, "o", "            raise AssertionError(\r\n"]
[160.423803, "o", "                \"result must be of type str, type \"\r\n"]
[160.45862, "o", "                f\"of result is {repr(type(result).__name__)}\"\r\n"]
[160.493437, "o", "            )\r\n"]
[160.528254, "o", "\r\n"]
[160.56307, "o", "        if buf is None:\r\n"]
[160.597887, "o", "            return result\r\n"]
[160.632704, "o", "        else:\r\n"]
[160.667521, "o", "            if hasattr(buf, \"write\"):\r\n"]
[160.702338, "o", "                buf.write(result)\r\n"]
[160.737155, "o", "            else:\r\n"]
[160.771972, "o", "                with open(buf, \"w\") as f:\r\n"]
[160.806789, "o", "                    f.write(result)\r\n"]
[160.841606, "o", "        return None\r\n"]
[160.876423, "o", "\r\n"]
[160.911239, "o", "    @doc(\r\n"]
[160.946056, "o", "        klass=_shared_doc_kwargs[\"klass\"],\r\n"]
[160.980873, "o", "        storage_options=_shared_docs[\"storage_options\"],\r\n"]
[161.01569, "o", "        examples=dedent(\r\n"]
[161.050507, "o", "            \"\"\"Examples\r\n"]
[161.085324, "o", "            --------\r\n"]
[161.120141, "o", "            >>> s = pd.Series([\"elk\", \"pig\", \"dog\", \"quetzal\"], name=\"animal\")\r\n"]
[161.154958, "o", "            >>> print(s.to_markdown())\r\n"]
[161.189775, "o", "            |    | animal   |\r\n"]
[161.224592, "o", "            |---:|:---------|\r\n"]
[161.259408, "o", "            |  0 | elk      |\r\n"]
[161.294225, "o", "            |  1 | pig      |\r\n"]
[161.329042, "o", "            |  2 | dog      |\r\n"]
[161.363859, "o", "            |  3 | quetzal  |\r\n"]
[161.398676, "o", "\r\n"]
[161.433493, "o", "            Output markdown with a tabulate option.\r\n"]
[161.46831, "o", "\r\n"]
[161.503127, "o", "            >>> print(s.to_markdown(tablefmt=\"grid\"))\r\n"]
[161.537944, "o", "            +----+----------+\r\n"]
[161.572761, "o", "            |    | animal   |\r\n"]
[161.607577, "o", "            +====+==========+\r\n"]
[161.642394, "o", "            |  0 | elk      |\r\n"]
[161.677211, "o", "            +----+----------+\r\n"]
[161.712028, "o", "            |  1 | pig      |\r\n"]
[161.746845, "o", "            +----+----------+\r\n"]
[161.781662, "o", "            |  2 | dog      |\r\n"]
[161.816479, "o", "            +----+----------+\r\n"]
[161.851296, "o", "            |  3 | quetzal  |\r\n"]
[161.886113, "o", "            +----+----------+\"\"\"\r\n"]
[161.92093, "o", "        ),\r\n"]
[161.955746, "o", "    )\r\n"]
[161.990563, "o", "    def to_markdown(\r\n"]
[162.02538, "o", "        self,\r\n"]
[162.060197, "o", "        buf: IO[str] | None = None,\r\n"]
[162.095014, "o", "        mode: str = \"wt\",\r\n"]
[162.129831, "o", "        index: bool = True,\r\n"]
[162.164648, "o", "        storage_options: StorageOptions = None,\r\n"]
[162.199465, "o", "        **kwargs,\r\n"]
[162.234282, "o", "    ) -> str | None:\r\n"]
[162.269099, "o", "        \"\"\"\r\n"]
[162.303915, "o", "        Print {klass} in Markdown-friendly format.\r\n"]
[162.338732, "o", "\r\n"]
[162.373549, "o", "        Parameters\r\n"]
[162.408366, "o", "        ----------\r\n"]
[162.443183, "o", "        buf : str, Path or StringIO-like, optional, default None\r\n"]
[162.478, "o", "            Buffer to write to. If None, the output is returned as a string.\r\n"]
[162.512817, "o", "        mode : str, optional\r\n"]
[162.547634, "o", "            Mode in which file is opened, \"wt\" by default.\r\n"]
[162.582451, "o", "        index : bool, optional, default True\r\n"]
[162.617268, "o", "            Add index (row) labels.\r\n"]
[162.652085, "o", "\r\n"]
[162.686901, "o", "            .. versionadded:: 1.1.0\r\n"]
[162.721718, "o", "        {storage_options}\r\n"]
[162.756535, "o", "\r\n"]
[162.791352, "o", "            .. versionadded:: 1.2.0\r\n"]
[162.826169, "o", "\r\n"]
[162.860986, "o", "        **kwargs\r\n"]
[162.895803, "o", "            These parameters will be passed to `tabulate \\\r\n"]
[162.93062, "o", "                <https://pypi.org/project/tabulate>`_.\r\n"]
[162.965437, "o", "\r\n"]
[163.000254, "o", "        Returns\r\n"]
[163.03507, "o", "        -------\r\n"]
[163.069887, "o", "        str\r\n"]
[163.104704, "o", "            {klass} in Markdown-friendly format.\r\n"]
[163.139521, "o", "\r\n"]
[163.174338, "o", "        Notes\r\n"]
[163.209155, "o", "        -----\r\n"]
[163.243972, "o", "        Requires the `tabulate <https://pypi.org/project/tabulate>`_ package.\r\n"]
[163.278789, "o", "\r\n"]
[163.313606, "o", "        {examples}\r\n"]
[163.348423, "o", "        \"\"\"\r\n"]
[163.383239, "o", "        return self.to_frame().to_markdown(\r\n"]
[163.418056, "o", "            buf, mode, index, storage_options=storage_options, **kwargs\r\n"]
[163.452873, "o", "        )\r\n"]
[163.48769, "o", "\r\n"]
[163.522507, "o", "    # ----------------------------------------------------------------------\r\n"]
[163.557324, "o", "\r\n"]
[163.592141, "o", "    def items(self) -> Iterable[tuple[Hashable, Any]]:\r\n"]
[163.626958, "o", "        \"\"\"\r\n"]
[163.661775, "o", "        Lazily iterate over (index, value) tuples.\r\n"]
[163.696592, "o", "\r\n"]
[163.731408, "o", "        This method returns an iterable tuple (index, value). This is\r\n"]
[163.766225, "o", "        convenient if you want to create a lazy iterator.\r\n"]
[163.801042, "o", "\r\n"]
[163.835859, "o", "        Returns\r\n"]
[163.870676, "o", "        -------\r\n"]
[163.905493, "o", "        iterable\r\n"]
[163.94031, "o", "            Iterable of tuples containing the (index, value) pairs from a\r\n"]
[163.975127, "o", "            Series.\r\n"]
[164.009944, "o", "\r\n"]
[164.044761, "o", "        See Also\r\n"]
[164.079577, "o", "        --------\r\n"]
[164.114394, "o", "        DataFrame.items : Iterate over (column name, Series) pairs.\r\n"]
[164.149211, "o", "        DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) pairs.\r\n"]
[164.184028, "o", "\r\n"]
[164.218845, "o", "        Examples\r\n"]
[164.253662, "o", "        --------\r\n"]
[164.288479, "o", "        >>> s = pd.Series(['A', 'B', 'C'])\r\n"]
[164.323296, "o", "        >>> for index, value in s.items():\r\n"]
[164.358113, "o", "        ...     print(f\"Index : {index}, Value : {value}\")\r\n"]
[164.39293, "o", "        Index : 0, Value : A\r\n"]
[164.427746, "o", "        Index : 1, Value : B\r\n"]
[164.462563, "o", "        Index : 2, Value : C\r\n"]
[164.49738, "o", "        \"\"\"\r\n"]
[164.532197, "o", "        return zip(iter(self.index), iter(self))\r\n"]
[164.567014, "o", "\r\n"]
[164.601831, "o", "    # ----------------------------------------------------------------------\r\n"]
[164.636648, "o", "    # Misc public methods\r\n"]
[164.671465, "o", "\r\n"]
[164.706282, "o", "    def keys(self) -> Index:\r\n"]
[164.741099, "o", "        \"\"\"\r\n"]
[164.775915, "o", "        Return alias for index.\r\n"]
[164.810732, "o", "\r\n"]
[164.845549, "o", "        Returns\r\n"]
[164.880366, "o", "        -------\r\n"]
[164.915183, "o", "        Index\r\n"]
[165.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[165.002, "i", "sed -n '360,520p' pandas/core/arrays/numpy_.py\r"]
[165.004, "o", "sed -n '360,520p' pandas/core/arrays/numpy_.py\r\n"]
[165.046525, "o", "\u001b[?2004l\r\n"]
[165.087049, "o", "        axis: AxisInt | None = None,\r\n"]
[165.127574, "o", "        dtype: NpDtype | None = None,\r\n"]
[165.168098, "o", "        out=None,\r\n"]
[165.208623, "o", "        ddof: int = 1,\r\n"]
[165.249148, "o", "        keepdims: bool = False,\r\n"]
[165.289672, "o", "        skipna: bool = True,\r\n"]
[165.330197, "o", "    ):\r\n"]
[165.370721, "o", "        nv.validate_stat_ddof_func(\r\n"]
[165.411246, "o", "            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"sem\"\r\n"]
[165.45177, "o", "        )\r\n"]
[165.492295, "o", "        result = nanops.nansem(self._ndarray, axis=axis, skipna=skipna, ddof=ddof)\r\n"]
[165.53282, "o", "        return self._wrap_reduction_result(axis, result)\r\n"]
[165.573344, "o", "\r\n"]
[165.613869, "o", "    def kurt(\r\n"]
[165.654393, "o", "        self,\r\n"]
[165.694918, "o", "        *,\r\n"]
[165.735443, "o", "        axis: AxisInt | None = None,\r\n"]
[165.775967, "o", "        dtype: NpDtype | None = None,\r\n"]
[165.816492, "o", "        out=None,\r\n"]
[165.857016, "o", "        keepdims: bool = False,\r\n"]
[165.897541, "o", "        skipna: bool = True,\r\n"]
[165.938066, "o", "    ):\r\n"]
[165.97859, "o", "        nv.validate_stat_ddof_func(\r\n"]
[166.019115, "o", "            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"kurt\"\r\n"]
[166.059639, "o", "        )\r\n"]
[166.100164, "o", "        result = nanops.nankurt(self._ndarray, axis=axis, skipna=skipna)\r\n"]
[166.140689, "o", "        return self._wrap_reduction_result(axis, result)\r\n"]
[166.181213, "o", "\r\n"]
[166.221738, "o", "    def skew(\r\n"]
[166.262262, "o", "        self,\r\n"]
[166.302787, "o", "        *,\r\n"]
[166.343311, "o", "        axis: AxisInt | None = None,\r\n"]
[166.383836, "o", "        dtype: NpDtype | None = None,\r\n"]
[166.424361, "o", "        out=None,\r\n"]
[166.464885, "o", "        keepdims: bool = False,\r\n"]
[166.50541, "o", "        skipna: bool = True,\r\n"]
[166.545934, "o", "    ):\r\n"]
[166.586459, "o", "        nv.validate_stat_ddof_func(\r\n"]
[166.626984, "o", "            (), {\"dtype\": dtype, \"out\": out, \"keepdims\": keepdims}, fname=\"skew\"\r\n"]
[166.667508, "o", "        )\r\n"]
[166.708033, "o", "        result = nanops.nanskew(self._ndarray, axis=axis, skipna=skipna)\r\n"]
[166.748557, "o", "        return self._wrap_reduction_result(axis, result)\r\n"]
[166.789082, "o", "\r\n"]
[166.829607, "o", "    # ------------------------------------------------------------------------\r\n"]
[166.870131, "o", "    # Additional Methods\r\n"]
[166.910656, "o", "\r\n"]
[166.95118, "o", "    def to_numpy(\r\n"]
[166.991705, "o", "        self,\r\n"]
[167.03223, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[167.072754, "o", "        copy: bool = False,\r\n"]
[167.113279, "o", "        na_value: object = lib.no_default,\r\n"]
[167.153803, "o", "    ) -> np.ndarray:\r\n"]
[167.194328, "o", "        mask = self.isna()\r\n"]
[167.234852, "o", "        if na_value is not lib.no_default and mask.any():\r\n"]
[167.275377, "o", "            result = self._ndarray.copy()\r\n"]
[167.315902, "o", "            result[mask] = na_value\r\n"]
[167.356426, "o", "        else:\r\n"]
[167.396951, "o", "            result = self._ndarray\r\n"]
[167.437475, "o", "\r\n"]
[167.478, "o", "        result = np.asarray(result, dtype=dtype)\r\n"]
[167.518525, "o", "\r\n"]
[167.559049, "o", "        if copy and result is self._ndarray:\r\n"]
[167.599574, "o", "            result = result.copy()\r\n"]
[167.640098, "o", "\r\n"]
[167.680623, "o", "        return result\r\n"]
[167.721148, "o", "\r\n"]
[167.761672, "o", "    # ------------------------------------------------------------------------\r\n"]
[167.802197, "o", "    # Ops\r\n"]
[167.842721, "o", "\r\n"]
[167.883246, "o", "    def __invert__(self) -> PandasArray:\r\n"]
[167.92377, "o", "        return type(self)(~self._ndarray)\r\n"]
[167.964295, "o", "\r\n"]
[168.00482, "o", "    def __neg__(self) -> PandasArray:\r\n"]
[168.045344, "o", "        return type(self)(-self._ndarray)\r\n"]
[168.085869, "o", "\r\n"]
[168.126393, "o", "    def __pos__(self) -> PandasArray:\r\n"]
[168.166918, "o", "        return type(self)(+self._ndarray)\r\n"]
[168.207443, "o", "\r\n"]
[168.247967, "o", "    def __abs__(self) -> PandasArray:\r\n"]
[168.288492, "o", "        return type(self)(abs(self._ndarray))\r\n"]
[168.329016, "o", "\r\n"]
[168.369541, "o", "    def _cmp_method(self, other, op):\r\n"]
[168.410066, "o", "        if isinstance(other, PandasArray):\r\n"]
[168.45059, "o", "            other = other._ndarray\r\n"]
[168.491115, "o", "\r\n"]
[168.531639, "o", "        other = ops.maybe_prepare_scalar_for_op(other, (len(self),))\r\n"]
[168.572164, "o", "        pd_op = ops.get_array_op(op)\r\n"]
[168.612689, "o", "        other = ensure_wrapped_if_datetimelike(other)\r\n"]
[168.653213, "o", "        with np.errstate(all=\"ignore\"):\r\n"]
[168.693738, "o", "            result = pd_op(self._ndarray, other)\r\n"]
[168.734262, "o", "\r\n"]
[168.774787, "o", "        if op is divmod or op is ops.rdivmod:\r\n"]
[168.815311, "o", "            a, b = result\r\n"]
[168.855836, "o", "            if isinstance(a, np.ndarray):\r\n"]
[168.896361, "o", "                # for e.g. op vs TimedeltaArray, we may already\r\n"]
[168.936885, "o", "                #  have an ExtensionArray, in which case we do not wrap\r\n"]
[168.97741, "o", "                return self._wrap_ndarray_result(a), self._wrap_ndarray_result(b)\r\n"]
[169.017934, "o", "            return a, b\r\n"]
[169.058459, "o", "\r\n"]
[169.098984, "o", "        if isinstance(result, np.ndarray):\r\n"]
[169.139508, "o", "            # for e.g. multiplication vs TimedeltaArray, we may already\r\n"]
[169.180033, "o", "            #  have an ExtensionArray, in which case we do not wrap\r\n"]
[169.220557, "o", "            return self._wrap_ndarray_result(result)\r\n"]
[169.261082, "o", "        return result\r\n"]
[169.301607, "o", "\r\n"]
[169.342131, "o", "    _arith_method = _cmp_method\r\n"]
[169.382656, "o", "\r\n"]
[169.42318, "o", "    def _wrap_ndarray_result(self, result: np.ndarray):\r\n"]
[169.463705, "o", "        # If we have timedelta64[ns] result, return a TimedeltaArray instead\r\n"]
[169.50423, "o", "        #  of a PandasArray\r\n"]
[169.544754, "o", "        if result.dtype.kind == \"m\" and is_supported_unit(\r\n"]
[169.585279, "o", "            get_unit_from_dtype(result.dtype)\r\n"]
[169.625803, "o", "        ):\r\n"]
[169.666328, "o", "            from pandas.core.arrays import TimedeltaArray\r\n"]
[169.706852, "o", "\r\n"]
[169.747377, "o", "            return TimedeltaArray._simple_new(result, dtype=result.dtype)\r\n"]
[169.787902, "o", "        return type(self)(result)\r\n"]
[169.828426, "o", "\r\n"]
[169.868951, "o", "    # ------------------------------------------------------------------------\r\n"]
[169.909475, "o", "    # String methods interface\r\n"]
[170.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[170.002, "i", "cd asv_bench\r"]
[170.004, "o", "cd asv_bench\r\n"]
[170.006, "o", "\u001b[?2004l\r\n"]
[175.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[175.002, "i", "asv --help | head -n 60\r"]
[175.004, "o", "asv --help | head -n 60\r\n"]
[175.139622, "o", "\u001b[?2004l\r\n"]
[175.273243, "o", "usage: asv [-h] [--verbose] [--config CONFIG] [--version]\r\n"]
[175.406865, "o", "           {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages}\r\n"]
[175.540486, "o", "           ...\r\n"]
[175.674108, "o", "\r\n"]
[175.80773, "o", "Airspeed Velocity: Simple benchmarking tool for Python\r\n"]
[175.941351, "o", "\r\n"]
[176.074973, "o", "optional arguments:\r\n"]
[176.208595, "o", "  -h, --help            show this help message and exit\r\n"]
[176.342216, "o", "  --verbose, -v         Increase verbosity\r\n"]
[176.475838, "o", "  --config CONFIG       Benchmark configuration file\r\n"]
[176.609459, "o", "  --version             Print program version\r\n"]
[176.743081, "o", "\r\n"]
[176.876703, "o", "subcommands:\r\n"]
[177.010324, "o", "  valid subcommands\r\n"]
[177.143946, "o", "\r\n"]
[177.277568, "o", "  {help,quickstart,machine,setup,run,continuous,find,rm,publish,preview,profile,update,show,compare,check,gh-pages}\r\n"]
[177.411189, "o", "    help                Display usage information\r\n"]
[177.544811, "o", "    quickstart          Create a new benchmarking suite\r\n"]
[177.678432, "o", "    machine             Define information about this machine\r\n"]
[177.812054, "o", "    setup               Setup virtual environments\r\n"]
[177.945676, "o", "    run                 Run a benchmark suite\r\n"]
[178.079297, "o", "    continuous          Compare two commits directly\r\n"]
[178.212919, "o", "    find                Find commits that introduced large regressions\r\n"]
[178.346541, "o", "    rm                  Remove results from the database\r\n"]
[178.480162, "o", "    publish             Collate results into a website\r\n"]
[178.613784, "o", "    preview             Preview the results using a local web server\r\n"]
[178.747405, "o", "    profile             Run the profiler on a particular benchmark on a\r\n"]
[178.881027, "o", "                        particular revision\r\n"]
[179.014649, "o", "    update              Update the results and config files to the current\r\n"]
[179.14827, "o", "                        version\r\n"]
[179.281892, "o", "    show                Print recorded data\r\n"]
[179.415514, "o", "    compare             Compare the benchmark results between two revisions\r\n"]
[179.549135, "o", "                        (averaged over configurations)\r\n"]
[179.682757, "o", "    check               Import and check benchmark suite, but do not run\r\n"]
[179.816378, "o", "                        benchmarks\r\n"]
[180.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[180.002, "i", "cp asv.conf.json asv.existing.conf.json\r"]
[180.004, "o", "cp asv.conf.json asv.existing.conf.json\r\n"]
[180.006, "o", "\u001b[?2004l\r\n"]
[185.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[185.002, "i", "python - << 'PY'\r"]
[185.004, "o", "python - << 'PY'\r\n"]
[185.151412, "o", "\u001b[?2004l\r\n"]
[185.296824, "o", "\u001b[?2004h> import json, sys\r\n"]
[185.442235, "o", "\u001b[?2004l\r\n"]
[185.587647, "o", "\u001b[?2004h> p='asv.existing.conf.json'\r\n"]
[185.733059, "o", "\u001b[?2004l\r\n"]
[185.878471, "o", "\u001b[?2004h> with open(p) as f: cfg=json.load(f)\r\n"]
[186.023882, "o", "\u001b[?2004l\r\n"]
[186.169294, "o", "\u001b[?2004h> cfg['environment_type']='existing'\r\n"]
[186.314706, "o", "\u001b[?2004l\r\n"]
[186.460118, "o", "\u001b[?2004h> # minimize matrix to avoid extra deps\r\n"]
[186.605529, "o", "\u001b[?2004l\r\n"]
[186.750941, "o", "\u001b[?2004h> cfg['matrix']={}\r\n"]
[186.896353, "o", "\u001b[?2004l\r\n"]
[187.041765, "o", "\u001b[?2004h> # ensure we only use current python\r\n"]
[187.187176, "o", "\u001b[?2004l\r\n"]
[187.332588, "o", "\u001b[?2004h> cfg['pythons']=['3.8']\r\n"]
[187.478, "o", "\u001b[?2004l\r\n"]
[187.623412, "o", "\u001b[?2004h> with open(p,'w') as f: json.dump(cfg,f,indent=2)\r\n"]
[187.768824, "o", "\u001b[?2004l\r\n"]
[187.914235, "o", "\u001b[?2004h> print('Wrote',p)\r\n"]
[188.059647, "o", "\u001b[?2004l\r\n"]
[188.205059, "o", "\u001b[?2004h> PY\r\n"]
[188.350471, "o", "\u001b[?2004l\r\n"]
[188.495882, "o", "Traceback (most recent call last):\r\n"]
[188.641294, "o", "  File \"<stdin>\", line 3, in <module>\r\n"]
[188.786706, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/json/__init__.py\", line 293, in load\r\n"]
[188.932118, "o", "    return loads(fp.read(),\r\n"]
[189.077529, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/json/__init__.py\", line 357, in loads\r\n"]
[189.222941, "o", "    return _default_decoder.decode(s)\r\n"]
[189.368353, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/json/decoder.py\", line 337, in decode\r\n"]
[189.513765, "o", "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n"]
[189.659176, "o", "  File \"/opt/conda/envs/asv_3.8/lib/python3.8/json/decoder.py\", line 353, in raw_decode\r\n"]
[189.804588, "o", "    obj, end = self.scan_once(s, idx)\r\n"]
[190.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[190.002, "i", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r"]
[190.004, "o", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r\n"]
[190.624, "o", "\u001b[?2004l\r\n"]
[191.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[191.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[192.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[193.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[193.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                      1.38\u00b10\u03bcs\r\n"]
[194.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                  376\u00b13\u03bcs\r\n"]
[195.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[195.002, "i", "asv show --config=asv.existing.conf.json | head -n 100\r"]
[195.004, "o", "asv show --config=asv.existing.conf.json | head -n 100\r\n"]
[196.654, "o", "\u001b[?2004l\r\n"]
[198.302, "o", "Commits with results:\r\n"]
[200.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[200.002, "i", "asv profile --python=same --config=asv.existing.conf.json series_methods.ToNumpy.time_to_numpy\r"]
[200.004, "o", "asv profile --python=same --config=asv.existing.conf.json series_methods.ToNumpy.time_to_numpy\r\n"]
[200.1605, "o", "\u001b[?2004l\r\n"]
[200.315, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[200.4695, "o", "\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n"]
[200.624, "o", "\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[200.7785, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m.\r\n"]
[200.933, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                   1.38\u00b10.01\u03bcs\r\n"]
[201.0875, "o", "\r\n"]
[201.242, "o", "Wed Oct  1 18:10:07 2025    /tmp/tmprqmf3899\r\n"]
[201.3965, "o", "\r\n"]
[201.551, "o", "         17 function calls in 0.000 seconds\r\n"]
[201.7055, "o", "\r\n"]
[201.86, "o", "   Ordered by: cumulative time\r\n"]
[202.0145, "o", "\r\n"]
[202.169, "o", "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n"]
[202.3235, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\r\n"]
[202.478, "o", "        1    0.000    0.000    0.000    0.000 _base.py:689(method_caller)\r\n"]
[202.6325, "o", "        1    0.000    0.000    0.000    0.000 series_methods.py:379(time_to_numpy)\r\n"]
[202.787, "o", "        1    0.000    0.000    0.000    0.000 base.py:473(to_numpy)\r\n"]
[202.9415, "o", "        1    0.000    0.000    0.000    0.000 series.py:587(dtype)\r\n"]
[203.096, "o", "        1    0.000    0.000    0.000    0.000 managers.py:2009(dtype)\r\n"]
[203.2505, "o", "        1    0.000    0.000    0.000    0.000 common.py:1351(is_extension_array_dtype)\r\n"]
[203.405, "o", "        1    0.000    0.000    0.000    0.000 series.py:711(_values)\r\n"]
[203.5595, "o", "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n"]
[203.714, "o", "        1    0.000    0.000    0.000    0.000 managers.py:1953(_block)\r\n"]
[203.8685, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:33(using_copy_on_write)\r\n"]
[204.023, "o", "        1    0.000    0.000    0.000    0.000 blocks.py:478(dtype)\r\n"]
[204.1775, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n"]
[204.332, "o", "        1    0.000    0.000    0.000    0.000 managers.py:2020(internal_values)\r\n"]
[204.4865, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n"]
[204.641, "o", "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n"]
[204.7955, "o", "\r\n"]
[205.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[205.002, "i", "asv profile --python=same --config=asv.existing.conf.json series_methods.ToNumpy.time_to_numpy_copy\r"]
[205.004, "o", "asv profile --python=same --config=asv.existing.conf.json series_methods.ToNumpy.time_to_numpy_copy\r\n"]
[205.143333, "o", "\u001b[?2004l\r\n"]
[205.280667, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[205.418, "o", "\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n"]
[205.555333, "o", "\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[205.692667, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy_copy--)\u001b[0m.\r\n"]
[205.83, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                371\u00b10.7\u03bcs\r\n"]
[205.967333, "o", "\r\n"]
[206.104667, "o", "Wed Oct  1 18:10:27 2025    /tmp/tmp8jyxlmiq\r\n"]
[206.242, "o", "\r\n"]
[206.379333, "o", "         23 function calls in 0.000 seconds\r\n"]
[206.516667, "o", "\r\n"]
[206.654, "o", "   Ordered by: cumulative time\r\n"]
[206.791333, "o", "\r\n"]
[206.928667, "o", "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n"]
[207.066, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\r\n"]
[207.203333, "o", "        1    0.000    0.000    0.000    0.000 _base.py:689(method_caller)\r\n"]
[207.340667, "o", "        1    0.000    0.000    0.000    0.000 series_methods.py:385(time_to_numpy_copy)\r\n"]
[207.478, "o", "        1    0.000    0.000    0.000    0.000 base.py:473(to_numpy)\r\n"]
[207.615333, "o", "        1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n"]
[207.752667, "o", "        1    0.000    0.000    0.000    0.000 series.py:587(dtype)\r\n"]
[207.89, "o", "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(shares_memory)\r\n"]
[208.027333, "o", "        1    0.000    0.000    0.000    0.000 managers.py:2009(dtype)\r\n"]
[208.164667, "o", "        1    0.000    0.000    0.000    0.000 common.py:1351(is_extension_array_dtype)\r\n"]
[208.302, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n"]
[208.439333, "o", "        2    0.000    0.000    0.000    0.000 series.py:711(_values)\r\n"]
[208.576667, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n"]
[208.714, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:33(using_copy_on_write)\r\n"]
[208.851333, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2020(internal_values)\r\n"]
[208.988667, "o", "        1    0.000    0.000    0.000    0.000 managers.py:1953(_block)\r\n"]
[209.126, "o", "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n"]
[209.263333, "o", "        1    0.000    0.000    0.000    0.000 blocks.py:478(dtype)\r\n"]
[209.400667, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n"]
[209.538, "o", "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n"]
[209.675333, "o", "        1    0.000    0.000    0.000    0.000 multiarray.py:1317(shares_memory)\r\n"]
[209.812667, "o", "\r\n"]
[210.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[210.002, "i", "asv profile --python=same --config=asv.existing.conf.json series_methods.ToNumpy.time_to_numpy_double_copy\r"]
[210.004, "o", "asv profile --python=same --config=asv.existing.conf.json series_methods.ToNumpy.time_to_numpy_double_copy\r\n"]
[210.139622, "o", "y\r\n"]
[210.273243, "o", "\u001b[?2004l\r\n"]
[210.406865, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[210.540486, "o", "\u00b7 \u001b[0;32mProfile data does not already exist. Running profiler now.\u001b[0m\r\n"]
[210.674108, "o", "\u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[210.80773, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy_double_copy--)\u001b[0m.\r\n"]
[210.941351, "o", "\u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_double_copy\u001b[0m                                                                                           373\u00b13\u03bcs\r\n"]
[211.074973, "o", "\r\n"]
[211.208595, "o", "Wed Oct  1 18:10:47 2025    /tmp/tmp77d0tzfv\r\n"]
[211.342216, "o", "\r\n"]
[211.475838, "o", "         23 function calls in 0.000 seconds\r\n"]
[211.609459, "o", "\r\n"]
[211.743081, "o", "   Ordered by: cumulative time\r\n"]
[211.876703, "o", "\r\n"]
[212.010324, "o", "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n"]
[212.143946, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}\r\n"]
[212.277568, "o", "        1    0.000    0.000    0.000    0.000 _base.py:689(method_caller)\r\n"]
[212.411189, "o", "        1    0.000    0.000    0.000    0.000 series_methods.py:382(time_to_numpy_double_copy)\r\n"]
[212.544811, "o", "        1    0.000    0.000    0.000    0.000 base.py:473(to_numpy)\r\n"]
[212.678432, "o", "        1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\r\n"]
[212.812054, "o", "        1    0.000    0.000    0.000    0.000 series.py:587(dtype)\r\n"]
[212.945676, "o", "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:177(shares_memory)\r\n"]
[213.079297, "o", "        1    0.000    0.000    0.000    0.000 managers.py:2009(dtype)\r\n"]
[213.212919, "o", "        1    0.000    0.000    0.000    0.000 common.py:1351(is_extension_array_dtype)\r\n"]
[213.346541, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\r\n"]
[213.480162, "o", "        2    0.000    0.000    0.000    0.000 series.py:711(_values)\r\n"]
[213.613784, "o", "        1    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\r\n"]
[213.747405, "o", "        1    0.000    0.000    0.000    0.000 managers.py:1953(_block)\r\n"]
[213.881027, "o", "        2    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\r\n"]
[214.014649, "o", "        1    0.000    0.000    0.000    0.000 blocks.py:478(dtype)\r\n"]
[214.14827, "o", "        2    0.000    0.000    0.000    0.000 managers.py:2020(internal_values)\r\n"]
[214.281892, "o", "        1    0.000    0.000    0.000    0.000 __init__.py:33(using_copy_on_write)\r\n"]
[214.415514, "o", "        1    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\r\n"]
[214.549135, "o", "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\r\n"]
[214.682757, "o", "        1    0.000    0.000    0.000    0.000 multiarray.py:1317(shares_memory)\r\n"]
[214.816378, "o", "\r\n"]
[215.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[215.002, "i", "cd ..\r"]
[215.004, "o", "cd ..\r\n"]
[215.006, "o", "\u001b[?2004l\r\n"]
[220.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[220.002, "i", "grep -n \"def to_numpy\\b\" -n pandas/core/series.py pandas/core/base.py | head -n 20\r"]
[220.004, "o", "grep -n \"def to_numpy\\b\" -n pandas/core/series.py pandas/core/base.py | head -n 20\r\n"]
[222.478, "o", "\u001b[?2004l\r\n"]
[225.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[225.002, "i", "sed -n '1,260p' pandas/core/base.py | sed -n '430,560p'\r"]
[225.004, "o", "sed -n '1,260p' pandas/core/base.py | sed -n '430,560p'\r\n"]
[225.006, "o", "\u001b[?2004l\r\n"]
[230.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[230.002, "i", "grep -n \"def to_numpy\\b\" pandas/core/series.py\r"]
[230.004, "o", "grep -n \"def to_numpy\\b\" pandas/core/series.py\r\n"]
[230.006, "o", "\u001b[?2004l\r\n"]
[235.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[235.002, "i", "sed -n '1,260p' pandas/core/series.py | sed -n '1600,1900p'\r"]
[235.004, "o", "sed -n '1,260p' pandas/core/series.py | sed -n '1600,1900p'\r\n"]
[235.006, "o", "\u001b[?2004l\r\n"]
[240.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[240.002, "i", "sed -n '440,540p' pandas/core/base.py\r"]
[240.004, "o", "sed -n '440,540p' pandas/core/base.py\r\n"]
[240.054471, "o", "\u001b[?2004l\r\n"]
[240.102941, "o", "        string             StringArray\r\n"]
[240.151412, "o", "        boolean            BooleanArray\r\n"]
[240.199882, "o", "        datetime64[ns, tz] DatetimeArray\r\n"]
[240.248353, "o", "        ================== =============================\r\n"]
[240.296824, "o", "\r\n"]
[240.345294, "o", "        For any 3rd-party extension types, the array type will be an\r\n"]
[240.393765, "o", "        ExtensionArray.\r\n"]
[240.442235, "o", "\r\n"]
[240.490706, "o", "        For all remaining dtypes ``.array`` will be a\r\n"]
[240.539176, "o", "        :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\r\n"]
[240.587647, "o", "        stored within. If you absolutely need a NumPy array (possibly with\r\n"]
[240.636118, "o", "        copying / coercing data), then use :meth:`Series.to_numpy` instead.\r\n"]
[240.684588, "o", "\r\n"]
[240.733059, "o", "        Examples\r\n"]
[240.781529, "o", "        --------\r\n"]
[240.83, "o", "        For regular NumPy types like int, and float, a PandasArray\r\n"]
[240.878471, "o", "        is returned.\r\n"]
[240.926941, "o", "\r\n"]
[240.975412, "o", "        >>> pd.Series([1, 2, 3]).array\r\n"]
[241.023882, "o", "        <PandasArray>\r\n"]
[241.072353, "o", "        [1, 2, 3]\r\n"]
[241.120824, "o", "        Length: 3, dtype: int64\r\n"]
[241.169294, "o", "\r\n"]
[241.217765, "o", "        For extension types, like Categorical, the actual ExtensionArray\r\n"]
[241.266235, "o", "        is returned\r\n"]
[241.314706, "o", "\r\n"]
[241.363176, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[241.411647, "o", "        >>> ser.array\r\n"]
[241.460118, "o", "        ['a', 'b', 'a']\r\n"]
[241.508588, "o", "        Categories (2, object): ['a', 'b']\r\n"]
[241.557059, "o", "        \"\"\"\r\n"]
[241.605529, "o", "        raise AbstractMethodError(self)\r\n"]
[241.654, "o", "\r\n"]
[241.702471, "o", "    @final\r\n"]
[241.750941, "o", "    def to_numpy(\r\n"]
[241.799412, "o", "        self,\r\n"]
[241.847882, "o", "        dtype: npt.DTypeLike | None = None,\r\n"]
[241.896353, "o", "        copy: bool = False,\r\n"]
[241.944824, "o", "        na_value: object = lib.no_default,\r\n"]
[241.993294, "o", "        **kwargs,\r\n"]
[242.041765, "o", "    ) -> np.ndarray:\r\n"]
[242.090235, "o", "        \"\"\"\r\n"]
[242.138706, "o", "        A NumPy ndarray representing the values in this Series or Index.\r\n"]
[242.187176, "o", "\r\n"]
[242.235647, "o", "        Parameters\r\n"]
[242.284118, "o", "        ----------\r\n"]
[242.332588, "o", "        dtype : str or numpy.dtype, optional\r\n"]
[242.381059, "o", "            The dtype to pass to :meth:`numpy.asarray`.\r\n"]
[242.429529, "o", "        copy : bool, default False\r\n"]
[242.478, "o", "            Whether to ensure that the returned value is not a view on\r\n"]
[242.526471, "o", "            another array. Note that ``copy=False`` does not *ensure* that\r\n"]
[242.574941, "o", "            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\r\n"]
[242.623412, "o", "            a copy is made, even if not strictly necessary.\r\n"]
[242.671882, "o", "        na_value : Any, optional\r\n"]
[242.720353, "o", "            The value to use for missing values. The default value depends\r\n"]
[242.768824, "o", "            on `dtype` and the type of the array.\r\n"]
[242.817294, "o", "        **kwargs\r\n"]
[242.865765, "o", "            Additional keywords passed through to the ``to_numpy`` method\r\n"]
[242.914235, "o", "            of the underlying array (for extension arrays).\r\n"]
[242.962706, "o", "\r\n"]
[243.011176, "o", "        Returns\r\n"]
[243.059647, "o", "        -------\r\n"]
[243.108118, "o", "        numpy.ndarray\r\n"]
[243.156588, "o", "\r\n"]
[243.205059, "o", "        See Also\r\n"]
[243.253529, "o", "        --------\r\n"]
[243.302, "o", "        Series.array : Get the actual data stored within.\r\n"]
[243.350471, "o", "        Index.array : Get the actual data stored within.\r\n"]
[243.398941, "o", "        DataFrame.to_numpy : Similar method for DataFrame.\r\n"]
[243.447412, "o", "\r\n"]
[243.495882, "o", "        Notes\r\n"]
[243.544353, "o", "        -----\r\n"]
[243.592824, "o", "        The returned array will be the same up to equality (values equal\r\n"]
[243.641294, "o", "        in `self` will be equal in the returned array; likewise for values\r\n"]
[243.689765, "o", "        that are not equal). When `self` contains an ExtensionArray, the\r\n"]
[243.738235, "o", "        dtype may be different. For example, for a category-dtype Series,\r\n"]
[243.786706, "o", "        ``to_numpy()`` will return a NumPy array and the categorical dtype\r\n"]
[243.835176, "o", "        will be lost.\r\n"]
[243.883647, "o", "\r\n"]
[243.932118, "o", "        For NumPy dtypes, this will be a reference to the actual data stored\r\n"]
[243.980588, "o", "        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[244.029059, "o", "        in place will modify the data stored in the Series or Index (not that\r\n"]
[244.077529, "o", "        we recommend doing that).\r\n"]
[244.126, "o", "\r\n"]
[244.174471, "o", "        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[244.222941, "o", "        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[244.271412, "o", "        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[244.319882, "o", "        :attr:`Series.array` should be used instead.\r\n"]
[244.368353, "o", "\r\n"]
[244.416824, "o", "        This table lays out the different dtypes and default return types of\r\n"]
[244.465294, "o", "        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[244.513765, "o", "\r\n"]
[244.562235, "o", "        ================== ================================\r\n"]
[244.610706, "o", "        dtype              array type\r\n"]
[244.659176, "o", "        ================== ================================\r\n"]
[244.707647, "o", "        category[T]        ndarray[T] (same dtype as input)\r\n"]
[244.756118, "o", "        period             ndarray[object] (Periods)\r\n"]
[244.804588, "o", "        interval           ndarray[object] (Intervals)\r\n"]
[244.853059, "o", "        IntegerNA          ndarray[object]\r\n"]
[244.901529, "o", "        datetime64[ns]     datetime64[ns]\r\n"]
[245.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[245.002, "i", "sed -n '540,660p' pandas/core/base.py\r"]
[245.004, "o", "sed -n '540,660p' pandas/core/base.py\r\n"]
[245.046525, "o", "\u001b[?2004l\r\n"]
[245.087049, "o", "        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[245.127574, "o", "        ================== ================================\r\n"]
[245.168098, "o", "\r\n"]
[245.208623, "o", "        Examples\r\n"]
[245.249148, "o", "        --------\r\n"]
[245.289672, "o", "        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[245.330197, "o", "        >>> ser.to_numpy()\r\n"]
[245.370721, "o", "        array(['a', 'b', 'a'], dtype=object)\r\n"]
[245.411246, "o", "\r\n"]
[245.45177, "o", "        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[245.492295, "o", "        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[245.53282, "o", "        objects, each with the correct ``tz``.\r\n"]
[245.573344, "o", "\r\n"]
[245.613869, "o", "        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[245.654393, "o", "        >>> ser.to_numpy(dtype=object)\r\n"]
[245.694918, "o", "        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[245.735443, "o", "               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[245.775967, "o", "              dtype=object)\r\n"]
[245.816492, "o", "\r\n"]
[245.857016, "o", "        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[245.897541, "o", "        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[245.938066, "o", "        info is dropped.\r\n"]
[245.97859, "o", "\r\n"]
[246.019115, "o", "        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[246.059639, "o", "        ... # doctest: +ELLIPSIS\r\n"]
[246.100164, "o", "        array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\r\n"]
[246.140689, "o", "              dtype='datetime64[ns]')\r\n"]
[246.181213, "o", "        \"\"\"\r\n"]
[246.221738, "o", "        if is_extension_array_dtype(self.dtype):\r\n"]
[246.262262, "o", "            return self.array.to_numpy(dtype, copy=copy, na_value=na_value, **kwargs)\r\n"]
[246.302787, "o", "        elif kwargs:\r\n"]
[246.343311, "o", "            bad_keys = list(kwargs.keys())[0]\r\n"]
[246.383836, "o", "            raise TypeError(\r\n"]
[246.424361, "o", "                f\"to_numpy() got an unexpected keyword argument '{bad_keys}'\"\r\n"]
[246.464885, "o", "            )\r\n"]
[246.50541, "o", "\r\n"]
[246.545934, "o", "        if na_value is not lib.no_default:\r\n"]
[246.586459, "o", "            values = self._values\r\n"]
[246.626984, "o", "            if not can_hold_element(values, na_value):\r\n"]
[246.667508, "o", "                # if we can't hold the na_value asarray either makes a copy or we\r\n"]
[246.708033, "o", "                # error before modifying values. The asarray later on thus won't make\r\n"]
[246.748557, "o", "                # another copy\r\n"]
[246.789082, "o", "                values = np.asarray(values, dtype=dtype)\r\n"]
[246.829607, "o", "            else:\r\n"]
[246.870131, "o", "                values = values.copy()\r\n"]
[246.910656, "o", "\r\n"]
[246.95118, "o", "            values[np.asanyarray(self.isna())] = na_value\r\n"]
[246.991705, "o", "        else:\r\n"]
[247.03223, "o", "            values = self._values\r\n"]
[247.072754, "o", "\r\n"]
[247.113279, "o", "        result = np.asarray(values, dtype=dtype)\r\n"]
[247.153803, "o", "\r\n"]
[247.194328, "o", "        if (copy and na_value is lib.no_default) or (\r\n"]
[247.234852, "o", "            not copy and using_copy_on_write()\r\n"]
[247.275377, "o", "        ):\r\n"]
[247.315902, "o", "            if np.shares_memory(self._values[:2], result[:2]):\r\n"]
[247.356426, "o", "                # Take slices to improve performance of check\r\n"]
[247.396951, "o", "                if using_copy_on_write() and not copy:\r\n"]
[247.437475, "o", "                    result = result.view()\r\n"]
[247.478, "o", "                    result.flags.writeable = False\r\n"]
[247.518525, "o", "                else:\r\n"]
[247.559049, "o", "                    result = result.copy()\r\n"]
[247.599574, "o", "\r\n"]
[247.640098, "o", "        return result\r\n"]
[247.680623, "o", "\r\n"]
[247.721148, "o", "    @final\r\n"]
[247.761672, "o", "    @property\r\n"]
[247.802197, "o", "    def empty(self) -> bool:\r\n"]
[247.842721, "o", "        return not self.size\r\n"]
[247.883246, "o", "\r\n"]
[247.92377, "o", "    def max(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[247.964295, "o", "        \"\"\"\r\n"]
[248.00482, "o", "        Return the maximum value of the Index.\r\n"]
[248.045344, "o", "\r\n"]
[248.085869, "o", "        Parameters\r\n"]
[248.126393, "o", "        ----------\r\n"]
[248.166918, "o", "        axis : int, optional\r\n"]
[248.207443, "o", "            For compatibility with NumPy. Only 0 or None are allowed.\r\n"]
[248.247967, "o", "        skipna : bool, default True\r\n"]
[248.288492, "o", "            Exclude NA/null values when showing the result.\r\n"]
[248.329016, "o", "        *args, **kwargs\r\n"]
[248.369541, "o", "            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[248.410066, "o", "\r\n"]
[248.45059, "o", "        Returns\r\n"]
[248.491115, "o", "        -------\r\n"]
[248.531639, "o", "        scalar\r\n"]
[248.572164, "o", "            Maximum value.\r\n"]
[248.612689, "o", "\r\n"]
[248.653213, "o", "        See Also\r\n"]
[248.693738, "o", "        --------\r\n"]
[248.734262, "o", "        Index.min : Return the minimum value in an Index.\r\n"]
[248.774787, "o", "        Series.max : Return the maximum value in a Series.\r\n"]
[248.815311, "o", "        DataFrame.max : Return the maximum values in a DataFrame.\r\n"]
[248.855836, "o", "\r\n"]
[248.896361, "o", "        Examples\r\n"]
[248.936885, "o", "        --------\r\n"]
[248.97741, "o", "        >>> idx = pd.Index([3, 2, 1])\r\n"]
[249.017934, "o", "        >>> idx.max()\r\n"]
[249.058459, "o", "        3\r\n"]
[249.098984, "o", "\r\n"]
[249.139508, "o", "        >>> idx = pd.Index(['c', 'b', 'a'])\r\n"]
[249.180033, "o", "        >>> idx.max()\r\n"]
[249.220557, "o", "        'c'\r\n"]
[249.261082, "o", "\r\n"]
[249.301607, "o", "        For a MultiIndex, the maximum is determined lexicographically.\r\n"]
[249.342131, "o", "\r\n"]
[249.382656, "o", "        >>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])\r\n"]
[249.42318, "o", "        >>> idx.max()\r\n"]
[249.463705, "o", "        ('b', 2)\r\n"]
[249.50423, "o", "        \"\"\"\r\n"]
[249.544754, "o", "        nv.validate_minmax_axis(axis)\r\n"]
[249.585279, "o", "        nv.validate_max(args, kwargs)\r\n"]
[249.625803, "o", "        return nanops.nanmax(self._values, skipna=skipna)\r\n"]
[249.666328, "o", "\r\n"]
[249.706852, "o", "    @doc(op=\"max\", oppose=\"min\", value=\"largest\")\r\n"]
[249.747377, "o", "    def argmax(\r\n"]
[249.787902, "o", "        self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs\r\n"]
[249.828426, "o", "    ) -> int:\r\n"]
[249.868951, "o", "        \"\"\"\r\n"]
[249.909475, "o", "        Return int position of the {value} value in the Series.\r\n"]
[250.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[250.002, "i", "applypatch << 'PATCH'\r"]
[250.004, "o", "applypatch << 'PATCH'\r\n"]
[250.044625, "o", "\u001b[?2004l\r\n"]
[250.08325, "o", "\u001b[?2004h> *** Begin Patch\r\n"]
[250.121875, "o", "\u001b[?2004l\r\n"]
[250.1605, "o", "\u001b[?2004h> *** Update File: pandas/core/base.py\r\n"]
[250.199125, "o", "\u001b[?2004l\r\n"]
[250.23775, "o", "\u001b[?2004h> @@\r\n"]
[250.276375, "o", "\u001b[?2004l\r\n"]
[250.315, "o", "\u001b[?2004h> -        if na_value is not lib.no_default:\r\n"]
[250.353625, "o", "\u001b[?2004l\r\n"]
[250.39225, "o", "\u001b[?2004h> +        if na_value is not lib.no_default:\r\n"]
[250.430875, "o", "\u001b[?2004l\r\n"]
[250.4695, "o", "\u001b[?2004h>              values = self._values\r\n"]
[250.508125, "o", "\u001b[?2004l\r\n"]
[250.54675, "o", "\u001b[?2004h>              if not can_hold_element(values, na_value):\r\n"]
[250.585375, "o", "\u001b[?2004l\r\n"]
[250.624, "o", "\u001b[?2004h>                  # if we can't hold the na_value asarray either makes a copy or we\r\n"]
[250.662625, "o", "\u001b[?2004l\r\n"]
[250.70125, "o", "\u001b[?2004h>                  # error before modifying values. The asarray later on thus won't make\r\n"]
[250.739875, "o", "\u001b[?2004l\r\n"]
[250.7785, "o", "\u001b[?2004h>                  # another copy\r\n"]
[250.817125, "o", "\u001b[?2004l\r\n"]
[250.85575, "o", "\u001b[?2004h>                  values = np.asarray(values, dtype=dtype)\r\n"]
[250.894375, "o", "\u001b[?2004l\r\n"]
[250.933, "o", "\u001b[?2004h>              else:\r\n"]
[250.971625, "o", "\u001b[?2004l\r\n"]
[251.01025, "o", "\u001b[?2004h>                  values = values.copy()\r\n"]
[251.048875, "o", "\u001b[?2004l\r\n"]
[251.0875, "o", "\u001b[?2004h>  \r\n"]
[251.126125, "o", "\u001b[?2004l\r\n"]
[251.16475, "o", "\u001b[?2004h>              values[np.asanyarray(self.isna())] = na_value\r\n"]
[251.203375, "o", "\u001b[?2004l\r\n"]
[251.242, "o", "\u001b[?2004h>          else:\r\n"]
[251.280625, "o", "\u001b[?2004l\r\n"]
[251.31925, "o", "\u001b[?2004h>              values = self._values\r\n"]
[251.357875, "o", "\u001b[?2004l\r\n"]
[251.3965, "o", "\u001b[?2004h> -\r\n"]
[251.435125, "o", "\u001b[?2004l\r\n"]
[251.47375, "o", "\u001b[?2004h> -        result = np.asarray(values, dtype=dtype)\r\n"]
[251.512375, "o", "\u001b[?2004l\r\n"]
[251.551, "o", "\u001b[?2004h> -\r\n"]
[251.589625, "o", "\u001b[?2004l\r\n"]
[251.62825, "o", "\u001b[?2004h> -        if (copy and na_value is lib.no_default) or (\r\n"]
[251.666875, "o", "\u001b[?2004l\r\n"]
[251.7055, "o", "\u001b[?2004h> -            not copy and using_copy_on_write()\r\n"]
[251.744125, "o", "\u001b[?2004l\r\n"]
[251.78275, "o", "\u001b[?2004h> -        ):\r\n"]
[251.821375, "o", "\u001b[?2004l\r\n"]
[251.86, "o", "\u001b[?2004h> -            if np.shares_memory(self._values[:2], result[:2]):\r\n"]
[251.898625, "o", "\u001b[?2004l\r\n"]
[251.93725, "o", "\u001b[?2004h> -                # Take slices to improve performance of check\r\n"]
[251.975875, "o", "\u001b[?2004l\r\n"]
[252.0145, "o", "\u001b[?2004h> -                if using_copy_on_write() and not copy:\r\n"]
[252.053125, "o", "\u001b[?2004l\r\n"]
[252.09175, "o", "\u001b[?2004h> -                    result = result.view()\r\n"]
[252.130375, "o", "\u001b[?2004l\r\n"]
[252.169, "o", "\u001b[?2004h> -                    result.flags.writeable = False\r\n"]
[252.207625, "o", "\u001b[?2004l\r\n"]
[252.24625, "o", "\u001b[?2004h> -                else:\r\n"]
[252.284875, "o", "\u001b[?2004l\r\n"]
[252.3235, "o", "\u001b[?2004h> -                    result = result.copy()\r\n"]
[252.362125, "o", "\u001b[?2004l\r\n"]
[252.40075, "o", "\u001b[?2004h> -\r\n"]
[252.439375, "o", "\u001b[?2004l\r\n"]
[252.478, "o", "\u001b[?2004h> -        return result\r\n"]
[252.516625, "o", "\u001b[?2004l\r\n"]
[252.55525, "o", "\u001b[?2004h> +        # Fast-paths when we can avoid an asarray+shares_memory roundtrip.\r\n"]
[252.593875, "o", "\u001b[?2004l\r\n"]
[252.6325, "o", "\u001b[?2004h> +        # Only safe when no na_value replacement is requested and\r\n"]
[252.671125, "o", "\u001b[?2004l\r\n"]
[252.70975, "o", "\u001b[?2004h> +        # the dtype is either not specified or matches the existing dtype.\r\n"]
[252.748375, "o", "\u001b[?2004l\r\n"]
[252.787, "o", "\u001b[?2004h> +        if na_value is lib.no_default and isinstance(values, np.ndarray):\r\n"]
[252.825625, "o", "\u001b[?2004l\r\n"]
[252.86425, "o", "\u001b[?2004h> +            if dtype is None or np.dtype(dtype) == values.dtype:\r\n"]
[252.902875, "o", "\u001b[?2004l\r\n"]
[252.9415, "o", "\u001b[?2004h> +                if copy:\r\n"]
[252.980125, "o", "\u001b[?2004l\r\n"]
[253.01875, "o", "\u001b[?2004h> +                    return values.copy()\r\n"]
[253.057375, "o", "\u001b[?2004l\r\n"]
[253.096, "o", "\u001b[?2004h> +                if using_copy_on_write():\r\n"]
[253.134625, "o", "\u001b[?2004l\r\n"]
[253.17325, "o", "\u001b[?2004h> +                    # Return a non-writeable view to preserve CoW semantics\r\n"]
[253.211875, "o", "\u001b[?2004l\r\n"]
[253.2505, "o", "\u001b[?2004h> +                    result = values.view()\r\n"]
[253.289125, "o", "\u001b[?2004l\r\n"]
[253.32775, "o", "\u001b[?2004h> +                    result.flags.writeable = False\r\n"]
[253.366375, "o", "\u001b[?2004l\r\n"]
[253.405, "o", "\u001b[?2004h> +                    return result\r\n"]
[253.443625, "o", "\u001b[?2004l\r\n"]
[253.48225, "o", "\u001b[?2004h> +                # No copy and CoW disabled: can return the underlying array\r\n"]
[253.520875, "o", "\u001b[?2004l\r\n"]
[253.5595, "o", "\u001b[?2004h> +                return values\r\n"]
[253.598125, "o", "\u001b[?2004l\r\n"]
[253.63675, "o", "\u001b[?2004h> +\r\n"]
[253.675375, "o", "\u001b[?2004l\r\n"]
[253.714, "o", "\u001b[?2004h> +        result = np.asarray(values, dtype=dtype)\r\n"]
[253.752625, "o", "\u001b[?2004l\r\n"]
[253.79125, "o", "\u001b[?2004h> +\r\n"]
[253.829875, "o", "\u001b[?2004l\r\n"]
[253.8685, "o", "\u001b[?2004h> +        if (copy and na_value is lib.no_default) or (\r\n"]
[253.907125, "o", "\u001b[?2004l\r\n"]
[253.94575, "o", "\u001b[?2004h> +            not copy and using_copy_on_write()\r\n"]
[253.984375, "o", "\u001b[?2004l\r\n"]
[254.023, "o", "\u001b[?2004h> +        ):\r\n"]
[254.061625, "o", "\u001b[?2004l\r\n"]
[254.10025, "o", "\u001b[?2004h> +            # Take small slices to improve performance of the shares_memory check\r\n"]
[254.138875, "o", "\u001b[?2004l\r\n"]
[254.1775, "o", "\u001b[?2004h> +            if np.shares_memory(self._values[:2], result[:2]):\r\n"]
[254.216125, "o", "\u001b[?2004l\r\n"]
[254.25475, "o", "\u001b[?2004h> +                if using_copy_on_write() and not copy:\r\n"]
[254.293375, "o", "\u001b[?2004l\r\n"]
[254.332, "o", "\u001b[?2004h> +                    result = result.view()\r\n"]
[254.370625, "o", "\u001b[?2004l\r\n"]
[254.40925, "o", "\u001b[?2004h> +                    result.flags.writeable = False\r\n"]
[254.447875, "o", "\u001b[?2004l\r\n"]
[254.4865, "o", "\u001b[?2004h> +                else:\r\n"]
[254.525125, "o", "\u001b[?2004l\r\n"]
[254.56375, "o", "\u001b[?2004h> +                    result = result.copy()\r\n"]
[254.602375, "o", "\u001b[?2004l\r\n"]
[254.641, "o", "\u001b[?2004h> +\r\n"]
[254.679625, "o", "\u001b[?2004l\r\n"]
[254.71825, "o", "\u001b[?2004h> +        return result\r\n"]
[254.756875, "o", "\u001b[?2004l\r\n"]
[254.7955, "o", "\u001b[?2004h> *** End Patch\r\n"]
[254.834125, "o", "\u001b[?2004l\r\n"]
[254.87275, "o", "\u001b[?2004h> PATCH\r\n"]
[254.911375, "o", "\u001b[?2004l\r\n"]
[255.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[255.002, "i", "python - << 'PY'\r"]
[255.004, "o", "python - << 'PY'\r\n"]
[255.3356, "o", "\u001b[?2004l\r\n"]
[255.6652, "o", "\u001b[?2004h> import sys, difflib\r\n"]
[255.9948, "o", "\u001b[?2004l\r\n"]
[256.3244, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[256.654, "o", "\u001b[?2004l\r\n"]
[256.9836, "o", "\u001b[?2004h> p = Path('pandas/core/base.py')\r\n"]
[257.3132, "o", "\u001b[?2004l\r\n"]
[257.6428, "o", "\u001b[?2004h> print('Patched file exists:', p.exists())\r\n"]
[257.9724, "o", "\u001b[?2004l\r\n"]
[258.302, "o", "\u001b[?2004h> print('to_numpy occurrences:', sum(1 for line in p.open() if 'def to_numpy' in line))\r\n"]
[258.6316, "o", "\u001b[?2004l\r\n"]
[258.9612, "o", "\u001b[?2004h> PY\r\n"]
[259.2908, "o", "\u001b[?2004l\r\n"]
[259.6204, "o", "Patched file exists: True\r\n"]
[260.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[260.002, "i", "cd asv_bench\r"]
[260.004, "o", "cd asv_bench\r\n"]
[260.006, "o", "\u001b[?2004l\r\n"]
[265.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[265.002, "i", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r"]
[265.004, "o", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r\n"]
[265.624, "o", "\u001b[?2004l\r\n"]
[266.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[266.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[267.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[268.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[268.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                   1.37\u00b10.01\u03bcs\r\n"]
[269.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                  369\u00b13\u03bcs\r\n"]
[270.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[270.002, "i", "asv show --config=asv.existing.conf.json | head -n 50\r"]
[270.004, "o", "asv show --config=asv.existing.conf.json | head -n 50\r\n"]
[271.654, "o", "\u001b[?2004l\r\n"]
[273.302, "o", "Commits with results:\r\n"]
[275.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[275.002, "i", "cd ..\r"]
[275.004, "o", "cd ..\r\n"]
[275.006, "o", "\u001b[?2004l\r\n"]
[280.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[280.002, "i", "python - << 'PY'\r"]
[280.004, "o", "python - << 'PY'\r\n"]
[280.08325, "o", "\u001b[?2004l\r\n"]
[280.1605, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[280.23775, "o", "\u001b[?2004l\r\n"]
[280.315, "o", "\u001b[?2004h> p = Path('pandas/core/base.py')\r\n"]
[280.39225, "o", "\u001b[?2004l\r\n"]
[280.4695, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[280.54675, "o", "\u001b[?2004l\r\n"]
[280.624, "o", "\u001b[?2004h> marker = 'Fast-paths when we can avoid an asarray+shares_memory roundtrip.'\r\n"]
[280.70125, "o", "\u001b[?2004l\r\n"]
[280.7785, "o", "\u001b[?2004h> if marker in s:\r\n"]
[280.85575, "o", "\u001b[?2004l\r\n"]
[280.933, "o", "\u001b[?2004h>     print('Already patched')\r\n"]
[281.01025, "o", "\u001b[?2004l\r\n"]
[281.0875, "o", "\u001b[?2004h> else:\r\n"]
[281.16475, "o", "\u001b[?2004l\r\n"]
[281.242, "o", "\u001b[?2004h>     target = 'result = np.asarray(values, dtype=dtype)'\r\n"]
[281.31925, "o", "\u001b[?2004l\r\n"]
[281.3965, "o", "\u001b[?2004h>     idx = s.find(target)\r\n"]
[281.47375, "o", "\u001b[?2004l\r\n"]
[281.551, "o", "\u001b[?2004h>     if idx == -1:\r\n"]
[281.62825, "o", "\u001b[?2004l\r\n"]
[281.7055, "o", "\u001b[?2004h>         raise SystemExit('Target line not found; aborting patch')\r\n"]
[281.78275, "o", "\u001b[?2004l\r\n"]
[281.86, "o", "\u001b[?2004h>     insert = (\r\n"]
[281.93725, "o", "\u001b[?2004l\r\n"]
[282.0145, "o", "\u001b[?2004h>         '        # Fast-paths when we can avoid an asarray+shares_memory roundtrip.\\n'\r\n"]
[282.09175, "o", "\u001b[?2004l\r\n"]
[282.169, "o", "\u001b[?2004h>         '        # Only safe when no na_value replacement is requested and\\n'\r\n"]
[282.24625, "o", "\u001b[?2004l\r\n"]
[282.3235, "o", "\u001b[?2004h>         '        # the dtype is either not specified or matches the existing dtype.\\n'\r\n"]
[282.40075, "o", "\u001b[?2004l\r\n"]
[282.478, "o", "\u001b[?2004h>         '        if na_value is lib.no_default and isinstance(values, np.ndarray):\\n'\r\n"]
[282.55525, "o", "\u001b[?2004l\r\n"]
[282.6325, "o", "\u001b[?2004h>         '            if dtype is None or np.dtype(dtype) == values.dtype:\\n'\r\n"]
[282.70975, "o", "\u001b[?2004l\r\n"]
[282.787, "o", "\u001b[?2004h>         '                if copy:\\n'\r\n"]
[282.86425, "o", "\u001b[?2004l\r\n"]
[282.9415, "o", "\u001b[?2004h>         '                    return values.copy()\\n'\r\n"]
[283.01875, "o", "\u001b[?2004l\r\n"]
[283.096, "o", "\u001b[?2004h>         '                if using_copy_on_write():\\n'\r\n"]
[283.17325, "o", "\u001b[?2004l\r\n"]
[283.2505, "o", "\u001b[?2004h>         '                    # Return a non-writeable view to preserve CoW semantics\\n'\r\n"]
[283.32775, "o", "\u001b[?2004l\r\n"]
[283.405, "o", "\u001b[?2004h>         '                    result = values.view()\\n'\r\n"]
[283.48225, "o", "\u001b[?2004l\r\n"]
[283.5595, "o", "\u001b[?2004h>         '                    result.flags.writeable = False\\n'\r\n"]
[283.63675, "o", "\u001b[?2004l\r\n"]
[283.714, "o", "\u001b[?2004h>         '                    return result\\n'\r\n"]
[283.79125, "o", "\u001b[?2004l\r\n"]
[283.8685, "o", "\u001b[?2004h>         '                # No copy and CoW disabled: can return the underlying array\\n'\r\n"]
[283.94575, "o", "\u001b[?2004l\r\n"]
[284.023, "o", "\u001b[?2004h>         '                return values\\n\\n'\r\n"]
[284.10025, "o", "\u001b[?2004l\r\n"]
[284.1775, "o", "\u001b[?2004h>     )\r\n"]
[284.25475, "o", "\u001b[?2004l\r\n"]
[284.332, "o", "\u001b[?2004h>     s = s[:idx] + insert + s[idx:]\r\n"]
[284.40925, "o", "\u001b[?2004l\r\n"]
[284.4865, "o", "\u001b[?2004h>     p.write_text(s)\r\n"]
[284.56375, "o", "\u001b[?2004l\r\n"]
[284.641, "o", "\u001b[?2004h>     print('Patched base.py')\r\n"]
[284.71825, "o", "\u001b[?2004l\r\n"]
[284.7955, "o", "\u001b[?2004h> PY\r\n"]
[284.87275, "o", "\u001b[?2004l\r\n"]
[285.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[285.002, "i", "grep -n \"Fast-paths when we can avoid an asarray\\+shares_memory\" -n pandas/core/base.py\r"]
[285.004, "o", "grep -n \"Fast-paths when we can avoid an asarray\\+shares_memory\" -n pandas/core/base.py\r\n"]
[285.006, "o", "\u001b[?2004l\r\n"]
[290.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[290.002, "i", "cd asv_bench\r"]
[290.004, "o", "cd asv_bench\r\n"]
[290.006, "o", "\u001b[?2004l\r\n"]
[295.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[295.002, "i", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r"]
[295.004, "o", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r\n"]
[295.113478, "o", "\u001b[?2004l\r\n"]
[295.220957, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[295.328435, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpzvvquitr/result.json (exit status 1)\u001b[0m\r\n"]
[295.435913, "o", "   STDOUT -------->\r\n"]
[295.543391, "o", "   \r\n"]
[295.65087, "o", "   STDERR -------->\r\n"]
[295.758348, "o", "   Traceback (most recent call last):\r\n"]
[295.865826, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[295.973304, "o", "       main()\r\n"]
[296.080783, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[296.188261, "o", "       commands[mode](args)\r\n"]
[296.295739, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[296.403217, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[296.510696, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[296.618174, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[296.725652, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[296.83313, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[296.940609, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[297.048087, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[297.155565, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[297.263043, "o", "       module = importlib.import_module(module_name)\r\n"]
[297.370522, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n"]
[297.478, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[297.585478, "o", "     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n"]
[297.692957, "o", "     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n"]
[297.800435, "o", "     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n"]
[297.907913, "o", "     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n"]
[298.015391, "o", "     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n"]
[298.12287, "o", "     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n"]
[298.230348, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[298.337826, "o", "       import pandas as pd\r\n"]
[298.445304, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[298.552783, "o", "       from pandas.core.api import (\r\n"]
[298.660261, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[298.767739, "o", "       from pandas.core.arrays import Categorical\r\n"]
[298.875217, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 8, in <module>\r\n"]
[298.982696, "o", "       from pandas.core.arrays.categorical import Categorical\r\n"]
[299.090174, "o", "     File \"/workspace/repo/pandas/core/arrays/categorical.py\", line 84, in <module>\r\n"]
[299.197652, "o", "       from pandas.core.base import (\r\n"]
[299.30513, "o", "     File \"/workspace/repo/pandas/core/base.py\", line 607\r\n"]
[299.412609, "o", "       if (copy and na_value is lib.no_default) or (\r\n"]
[299.520087, "o", "       ^\r\n"]
[299.627565, "o", "   IndentationError: unexpected indent\r\n"]
[299.735043, "o", "\r\n"]
[299.842522, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpzvvquitr/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[300.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[300.002, "i", "asv show --config=asv.existing.conf.json | head -n 20\r"]
[300.004, "o", "asv show --config=asv.existing.conf.json | head -n 20\r\n"]
[301.654, "o", "\u001b[?2004l\r\n"]
[303.302, "o", "Commits with results:\r\n"]
[305.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[305.002, "i", "sed -n '560,700p' pandas/core/base.py\r"]
[305.004, "o", "sed -n '560,700p' pandas/core/base.py\r\n"]
[307.478, "o", "\u001b[?2004l\r\n"]
[310.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[310.002, "i", "sed -n '500,680p' pandas/core/base.py | nl -ba | sed -n '1,200p'\r"]
[310.004, "o", "sed -n '500,680p' pandas/core/base.py | nl -ba | sed -n '1,200p'\r\n"]
[312.478, "o", "\u001b[?2004l\r\n"]
[315.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[315.002, "i", "python - << 'PY'\r"]
[315.004, "o", "python - << 'PY'\r\n"]
[315.029211, "o", "\u001b[?2004l\r\n"]
[315.052423, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[315.075634, "o", "\u001b[?2004l\r\n"]
[315.098845, "o", "\u001b[?2004h> p = Path('pandas/core/base.py')\r\n"]
[315.122056, "o", "\u001b[?2004l\r\n"]
[315.145268, "o", "\u001b[?2004h> s = p.read_text().splitlines()\r\n"]
[315.168479, "o", "\u001b[?2004l\r\n"]
[315.19169, "o", "\u001b[?2004h> start = None\r\n"]
[315.214901, "o", "\u001b[?2004l\r\n"]
[315.238113, "o", "\u001b[?2004h> end = None\r\n"]
[315.261324, "o", "\u001b[?2004l\r\n"]
[315.284535, "o", "\u001b[?2004h> # Find the to_numpy definition block to rewrite cleanly\r\n"]
[315.307746, "o", "\u001b[?2004l\r\n"]
[315.330958, "o", "\u001b[?2004h> for i, line in enumerate(s):\r\n"]
[315.354169, "o", "\u001b[?2004l\r\n"]
[315.37738, "o", "\u001b[?2004h>     if line.strip().startswith('def to_numpy('):\r\n"]
[315.400592, "o", "\u001b[?2004l\r\n"]
[315.423803, "o", "\u001b[?2004h>         start = i\r\n"]
[315.447014, "o", "\u001b[?2004l\r\n"]
[315.470225, "o", "\u001b[?2004h>         break\r\n"]
[315.493437, "o", "\u001b[?2004l\r\n"]
[315.516648, "o", "\u001b[?2004h> # Find end of function by next top-level def or @final or @property\r\n"]
[315.539859, "o", "\u001b[?2004l\r\n"]
[315.56307, "o", "\u001b[?2004h> if start is None:\r\n"]
[315.586282, "o", "\u001b[?2004l\r\n"]
[315.609493, "o", "\u001b[?2004h>     raise SystemExit('to_numpy not found')\r\n"]
[315.632704, "o", "\u001b[?2004l\r\n"]
[315.655915, "o", "\u001b[?2004h> indent = len(s[start]) - len(s[start].lstrip())\r\n"]
[315.679127, "o", "\u001b[?2004l\r\n"]
[315.702338, "o", "\u001b[?2004h> for j in range(start+1, len(s)):\r\n"]
[315.725549, "o", "\u001b[?2004l\r\n"]
[315.748761, "o", "\u001b[?2004h>     line = s[j]\r\n"]
[315.771972, "o", "\u001b[?2004l\r\n"]
[315.795183, "o", "\u001b[?2004h>     if line and (len(line) - len(line.lstrip()) <= indent) and (line.lstrip().startswith(('def ', '@final', '@property', 'class '))):\r\n"]
[315.818394, "o", "\u001b[?2004l\r\n"]
[315.841606, "o", "\u001b[?2004h>         end = j\r\n"]
[315.864817, "o", "\u001b[?2004l\r\n"]
[315.888028, "o", "\u001b[?2004h>         break\r\n"]
[315.911239, "o", "\u001b[?2004l\r\n"]
[315.934451, "o", "\u001b[?2004h> if end is None:\r\n"]
[315.957662, "o", "\u001b[?2004l\r\n"]
[315.980873, "o", "\u001b[?2004h>     end = len(s)\r\n"]
[316.004085, "o", "\u001b[?2004l\r\n"]
[316.027296, "o", "\u001b[?2004h> orig = s[start:end]\r\n"]
[316.050507, "o", "\u001b[?2004l\r\n"]
[316.073718, "o", "\u001b[?2004h> print('Original block lines:', len(orig))\r\n"]
[316.09693, "o", "\u001b[?2004l\r\n"]
[316.120141, "o", "\u001b[?2004h> # Reconstruct a correct implementation for the function body\r\n"]
[316.143352, "o", "\u001b[?2004l\r\n"]
[316.166563, "o", "\u001b[?2004h> header_idx = 0\r\n"]
[316.189775, "o", "\u001b[?2004l\r\n"]
[316.212986, "o", "\u001b[?2004h> for k,l in enumerate(orig):\r\n"]
[316.236197, "o", "\u001b[?2004l\r\n"]
[316.259408, "o", "\u001b[?2004h>     if l.strip().startswith(') -> np.ndarray:') or l.strip().endswith(') -> np.ndarray:'):\r\n"]
[316.28262, "o", "\u001b[?2004l\r\n"]
[316.305831, "o", "\u001b[?2004h>         header_idx = k\r\n"]
[316.329042, "o", "\u001b[?2004l\r\n"]
[316.352254, "o", "\u001b[?2004h>         break\r\n"]
[316.375465, "o", "\u001b[?2004l\r\n"]
[316.398676, "o", "\u001b[?2004h> head = orig[:header_idx+1]\r\n"]
[316.421887, "o", "\u001b[?2004l\r\n"]
[316.445099, "o", "\u001b[?2004h> body = [\r\n"]
[316.46831, "o", "\u001b[?2004l\r\n"]
[316.491521, "o", "\u001b[?2004h> \"        \\\"\\\"\\\"\",\r\n"]
[316.514732, "o", "\u001b[?2004l\r\n"]
[316.537944, "o", "\u001b[?2004h> \"        A NumPy ndarray representing the values in this Series or Index.\",\r\n"]
[316.561155, "o", "\u001b[?2004l\r\n"]
[316.584366, "o", "\u001b[?2004h> \"\",\r\n"]
[316.607577, "o", "\u001b[?2004l\r\n"]
[316.630789, "o", "\u001b[?2004h> \"        Parameters\",\r\n"]
[316.654, "o", "\u001b[?2004l\r\n"]
[316.677211, "o", "\u001b[?2004h> \"        ----------\",\r\n"]
[316.700423, "o", "\u001b[?2004l\r\n"]
[316.723634, "o", "\u001b[?2004h> \"        dtype : str or numpy.dtype, optional\",\r\n"]
[316.746845, "o", "\u001b[?2004l\r\n"]
[316.770056, "o", "\u001b[?2004h> \"            The dtype to pass to :meth:`numpy.asarray`.\",\r\n"]
[316.793268, "o", "\u001b[?2004l\r\n"]
[316.816479, "o", "\u001b[?2004h> \"        copy : bool, default False\",\r\n"]
[316.83969, "o", "\u001b[?2004l\r\n"]
[316.862901, "o", "\u001b[?2004h> \"            Whether to ensure that the returned value is not a view on\",\r\n"]
[316.886113, "o", "\u001b[?2004l\r\n"]
[316.909324, "o", "\u001b[?2004h> \"            another array. Note that ``copy=False`` does not *ensure* that\",\r\n"]
[316.932535, "o", "\u001b[?2004l\r\n"]
[316.955746, "o", "\u001b[?2004h> \"            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\",\r\n"]
[316.978958, "o", "\u001b[?2004l\r\n"]
[317.002169, "o", "\u001b[?2004h> \"            a copy is made, even if not strictly necessary.\",\r\n"]
[317.02538, "o", "\u001b[?2004l\r\n"]
[317.048592, "o", "\u001b[?2004h> \"        na_value : Any, optional\",\r\n"]
[317.071803, "o", "\u001b[?2004l\r\n"]
[317.095014, "o", "\u001b[?2004h> \"            The value to use for missing values. The default value depends\",\r\n"]
[317.118225, "o", "\u001b[?2004l\r\n"]
[317.141437, "o", "\u001b[?2004h> \"            on `dtype` and the type of the array.\",\r\n"]
[317.164648, "o", "\u001b[?2004l\r\n"]
[317.187859, "o", "\u001b[?2004h> \"        **kwargs\",\r\n"]
[317.21107, "o", "\u001b[?2004l\r\n"]
[317.234282, "o", "\u001b[?2004h> \"            Additional keywords passed through to the ``to_numpy`` method\",\r\n"]
[317.257493, "o", "\u001b[?2004l\r\n"]
[317.280704, "o", "\u001b[?2004h> \"            of the underlying array (for extension arrays).\",\r\n"]
[317.303915, "o", "\u001b[?2004l\r\n"]
[317.327127, "o", "\u001b[?2004h> \"\",\r\n"]
[317.350338, "o", "\u001b[?2004l\r\n"]
[317.373549, "o", "\u001b[?2004h> \"        Returns\",\r\n"]
[317.396761, "o", "\u001b[?2004l\r\n"]
[317.419972, "o", "\u001b[?2004h> \"        -------\",\r\n"]
[317.443183, "o", "\u001b[?2004l\r\n"]
[317.466394, "o", "\u001b[?2004h> \"        numpy.ndarray\",\r\n"]
[317.489606, "o", "\u001b[?2004l\r\n"]
[317.512817, "o", "\u001b[?2004h> \"        \\\"\\\"\\\"\",\r\n"]
[317.536028, "o", "\u001b[?2004l\r\n"]
[317.559239, "o", "\u001b[?2004h> \"        if is_extension_array_dtype(self.dtype):\",\r\n"]
[317.582451, "o", "\u001b[?2004l\r\n"]
[317.605662, "o", "\u001b[?2004h> \"            return self.array.to_numpy(dtype, copy=copy, na_value=na_value, **kwargs)\",\r\n"]
[317.628873, "o", "\u001b[?2004l\r\n"]
[317.652085, "o", "\u001b[?2004h> \"        elif kwargs:\r\n"]
[317.675296, "o", "\u001b[?2004l\r\n"]
[317.698507, "o", "\u001b[?2004h>             bad_keys = list(kwargs.keys())[0]\r\n"]
[317.721718, "o", "\u001b[?2004l\r\n"]
[317.74493, "o", "\u001b[?2004h>             raise TypeError(f\\\"to_numpy() got an unexpected keyword argument '{bad_keys}'\\\")\",\r\n"]
[317.768141, "o", "\u001b[?2004l\r\n"]
[317.791352, "o", "\u001b[?2004h> \"\",\r\n"]
[317.814563, "o", "\u001b[?2004l\r\n"]
[317.837775, "o", "\u001b[?2004h> \"        if na_value is not lib.no_default:\",\r\n"]
[317.860986, "o", "\u001b[?2004l\r\n"]
[317.884197, "o", "\u001b[?2004h> \"            values = self._values\",\r\n"]
[317.907408, "o", "\u001b[?2004l\r\n"]
[317.93062, "o", "\u001b[?2004h> \"            if not can_hold_element(values, na_value):\",\r\n"]
[317.953831, "o", "\u001b[?2004l\r\n"]
[317.977042, "o", "\u001b[?2004h> \"                values = np.asarray(values, dtype=dtype)\",\r\n"]
[318.000254, "o", "\u001b[?2004l\r\n"]
[318.023465, "o", "\u001b[?2004h> \"            else:\",\r\n"]
[318.046676, "o", "\u001b[?2004l\r\n"]
[318.069887, "o", "\u001b[?2004h> \"                values = values.copy()\",\r\n"]
[318.093099, "o", "\u001b[?2004l\r\n"]
[318.11631, "o", "\u001b[?2004h> \"            values[np.asanyarray(self.isna())] = na_value\",\r\n"]
[318.139521, "o", "\u001b[?2004l\r\n"]
[318.162732, "o", "\u001b[?2004h> \"        else:\",\r\n"]
[318.185944, "o", "\u001b[?2004l\r\n"]
[318.209155, "o", "\u001b[?2004h> \"            values = self._values\",\r\n"]
[318.232366, "o", "\u001b[?2004l\r\n"]
[318.255577, "o", "\u001b[?2004h> \"\",\r\n"]
[318.278789, "o", "\u001b[?2004l\r\n"]
[318.302, "o", "\u001b[?2004h> \"        # Fast-paths when we can avoid an asarray+shares_memory roundtrip.\",\r\n"]
[318.325211, "o", "\u001b[?2004l\r\n"]
[318.348423, "o", "\u001b[?2004h> \"        # Only safe when no na_value replacement is requested and the dtype\",\r\n"]
[318.371634, "o", "\u001b[?2004l\r\n"]
[318.394845, "o", "\u001b[?2004h> \"        # is either not specified or matches the existing dtype.\",\r\n"]
[318.418056, "o", "\u001b[?2004l\r\n"]
[318.441268, "o", "\u001b[?2004h> \"        if na_value is lib.no_default and isinstance(values, np.ndarray):\",\r\n"]
[318.464479, "o", "\u001b[?2004l\r\n"]
[318.48769, "o", "\u001b[?2004h> \"            if dtype is None or np.dtype(dtype) == values.dtype:\",\r\n"]
[318.510901, "o", "\u001b[?2004l\r\n"]
[318.534113, "o", "\u001b[?2004h> \"                if copy:\",\r\n"]
[318.557324, "o", "\u001b[?2004l\r\n"]
[318.580535, "o", "\u001b[?2004h> \"                    return values.copy()\",\r\n"]
[318.603746, "o", "\u001b[?2004l\r\n"]
[318.626958, "o", "\u001b[?2004h> \"                if using_copy_on_write():\",\r\n"]
[318.650169, "o", "\u001b[?2004l\r\n"]
[318.67338, "o", "\u001b[?2004h> \"                    # Return a non-writeable view to preserve CoW semantics\",\r\n"]
[318.696592, "o", "\u001b[?2004l\r\n"]
[318.719803, "o", "\u001b[?2004h> \"                    result = values.view()\",\r\n"]
[318.743014, "o", "\u001b[?2004l\r\n"]
[318.766225, "o", "\u001b[?2004h> \"                    result.flags.writeable = False\",\r\n"]
[318.789437, "o", "\u001b[?2004l\r\n"]
[318.812648, "o", "\u001b[?2004h> \"                    return result\",\r\n"]
[318.835859, "o", "\u001b[?2004l\r\n"]
[318.85907, "o", "\u001b[?2004h> \"                return values\",\r\n"]
[318.882282, "o", "\u001b[?2004l\r\n"]
[318.905493, "o", "\u001b[?2004h> \"\",\r\n"]
[318.928704, "o", "\u001b[?2004l\r\n"]
[318.951915, "o", "\u001b[?2004h> \"        result = np.asarray(values, dtype=dtype)\",\r\n"]
[318.975127, "o", "\u001b[?2004l\r\n"]
[318.998338, "o", "\u001b[?2004h> \"\",\r\n"]
[319.021549, "o", "\u001b[?2004l\r\n"]
[319.044761, "o", "\u001b[?2004h> \"        if (copy and na_value is lib.no_default) or (not copy and using_copy_on_write()):\",\r\n"]
[319.067972, "o", "\u001b[?2004l\r\n"]
[319.091183, "o", "\u001b[?2004h> \"            # Take small slices to improve performance of the shares_memory check\",\r\n"]
[319.114394, "o", "\u001b[?2004l\r\n"]
[319.137606, "o", "\u001b[?2004h> \"            if np.shares_memory(self._values[:2], result[:2]):\",\r\n"]
[319.160817, "o", "\u001b[?2004l\r\n"]
[319.184028, "o", "\u001b[?2004h> \"                if using_copy_on_write() and not copy:\",\r\n"]
[319.207239, "o", "\u001b[?2004l\r\n"]
[319.230451, "o", "\u001b[?2004h> \"                    result = result.view()\",\r\n"]
[319.253662, "o", "\u001b[?2004l\r\n"]
[319.276873, "o", "\u001b[?2004h> \"                    result.flags.writeable = False\",\r\n"]
[319.300085, "o", "\u001b[?2004l\r\n"]
[319.323296, "o", "\u001b[?2004h> \"                else:\",\r\n"]
[319.346507, "o", "\u001b[?2004l\r\n"]
[319.369718, "o", "\u001b[?2004h> \"                    result = result.copy()\",\r\n"]
[319.39293, "o", "\u001b[?2004l\r\n"]
[319.416141, "o", "\u001b[?2004h> \"\",\r\n"]
[319.439352, "o", "\u001b[?2004l\r\n"]
[319.462563, "o", "\u001b[?2004h> \"        return result\",\r\n"]
[319.485775, "o", "\u001b[?2004l\r\n"]
[319.508986, "o", "\u001b[?2004h> ]\r\n"]
[319.532197, "o", "\u001b[?2004l\r\n"]
[319.555408, "o", "\u001b[?2004h> # Ensure proper indentation\r\n"]
[319.57862, "o", "\u001b[?2004l\r\n"]
[319.601831, "o", "\u001b[?2004h> body = [ ((' ' * (indent+4)) + line if line else line) for line in body ]\r\n"]
[319.625042, "o", "\u001b[?2004l\r\n"]
[319.648254, "o", "\u001b[?2004h> new_block = head + body\r\n"]
[319.671465, "o", "\u001b[?2004l\r\n"]
[319.694676, "o", "\u001b[?2004h> s2 = s[:start] + new_block + s[end:]\r\n"]
[319.717887, "o", "\u001b[?2004l\r\n"]
[319.741099, "o", "\u001b[?2004h> p.write_text('\\n'.join(s2) + ('\\n' if not s2[-1].endswith('\\n') else ''))\r\n"]
[319.76431, "o", "\u001b[?2004l\r\n"]
[319.787521, "o", "\u001b[?2004h> print('Rewrote to_numpy block with corrected indentation')\r\n"]
[319.810732, "o", "\u001b[?2004l\r\n"]
[319.833944, "o", "\u001b[?2004h> PY\r\n"]
[319.857155, "o", "\u001b[?2004l\r\n"]
[319.880366, "o", "  File \"<stdin>\", line 57\r\n"]
[319.903577, "o", "    \"        elif kwargs:\r\n"]
[319.926789, "o", "                        ^\r\n"]
[320.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[320.002, "i", "python -m pyflakes pandas/core/base.py 2>/dev/null || true\r"]
[320.004, "o", "python -m pyflakes pandas/core/base.py 2>/dev/null || true\r\n"]
[320.006, "o", "\u001b[?2004l\r\n"]
[325.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[325.002, "i", "sed -n '560,700p' pandas/core/base.py\r"]
[325.004, "o", "sed -n '560,700p' pandas/core/base.py\r\n"]
[327.478, "o", "\u001b[?2004l\r\n"]
[330.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[330.002, "i", "cd asv_bench\r"]
[330.004, "o", "cd asv_bench\r\n"]
[332.478, "o", "\u001b[?2004l\r\n"]
[335.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[335.002, "i", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r"]
[335.004, "o", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r\n"]
[335.113478, "o", "\u001b[?2004l\r\n"]
[335.220957, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[335.328435, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpny5ut9qq/result.json (exit status 1)\u001b[0m\r\n"]
[335.435913, "o", "   STDOUT -------->\r\n"]
[335.543391, "o", "   \r\n"]
[335.65087, "o", "   STDERR -------->\r\n"]
[335.758348, "o", "   Traceback (most recent call last):\r\n"]
[335.865826, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[335.973304, "o", "       main()\r\n"]
[336.080783, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[336.188261, "o", "       commands[mode](args)\r\n"]
[336.295739, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[336.403217, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[336.510696, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[336.618174, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[336.725652, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[336.83313, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[336.940609, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[337.048087, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[337.155565, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[337.263043, "o", "       module = importlib.import_module(module_name)\r\n"]
[337.370522, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n"]
[337.478, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[337.585478, "o", "     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n"]
[337.692957, "o", "     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n"]
[337.800435, "o", "     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n"]
[337.907913, "o", "     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n"]
[338.015391, "o", "     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n"]
[338.12287, "o", "     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n"]
[338.230348, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[338.337826, "o", "       import pandas as pd\r\n"]
[338.445304, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[338.552783, "o", "       from pandas.core.api import (\r\n"]
[338.660261, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[338.767739, "o", "       from pandas.core.arrays import Categorical\r\n"]
[338.875217, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 8, in <module>\r\n"]
[338.982696, "o", "       from pandas.core.arrays.categorical import Categorical\r\n"]
[339.090174, "o", "     File \"/workspace/repo/pandas/core/arrays/categorical.py\", line 84, in <module>\r\n"]
[339.197652, "o", "       from pandas.core.base import (\r\n"]
[339.30513, "o", "     File \"/workspace/repo/pandas/core/base.py\", line 607\r\n"]
[339.412609, "o", "       if (copy and na_value is lib.no_default) or (\r\n"]
[339.520087, "o", "       ^\r\n"]
[339.627565, "o", "   IndentationError: unexpected indent\r\n"]
[339.735043, "o", "\r\n"]
[339.842522, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmpny5ut9qq/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[340.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[340.002, "i", "asv show --config=asv.existing.conf.json | head -n 20\r"]
[340.004, "o", "asv show --config=asv.existing.conf.json | head -n 20\r\n"]
[341.654, "o", "\u001b[?2004l\r\n"]
[343.302, "o", "Commits with results:\r\n"]
[345.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[345.002, "i", "pwd\r"]
[345.004, "o", "pwd\r\n"]
[347.478, "o", "\u001b[?2004l\r\n"]
[350.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[350.002, "i", "cd ..\r"]
[350.004, "o", "cd ..\r\n"]
[350.006, "o", "\u001b[?2004l\r\n"]
[355.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[355.002, "i", "git checkout -- pandas/core/base.py\r"]
[355.004, "o", "git checkout -- pandas/core/base.py\r\n"]
[355.006, "o", "\u001b[?2004l\r\n"]
[360.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[360.002, "i", "python - << 'PY'\r"]
[360.004, "o", "python - << 'PY'\r\n"]
[360.418, "o", "\u001b[?2004l\r\n"]
[360.83, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[361.242, "o", "\u001b[?2004l\r\n"]
[361.654, "o", "\u001b[?2004h> s = pd.Series([1.0, 2.0, 3.0])\r\n"]
[362.066, "o", "\u001b[?2004l\r\n"]
[362.478, "o", "\u001b[?2004h> arr = s.to_numpy()\r\n"]
[362.89, "o", "\u001b[?2004l\r\n"]
[363.302, "o", "\u001b[?2004h> print('ok', arr[:3])\r\n"]
[363.714, "o", "\u001b[?2004l\r\n"]
[364.126, "o", "\u001b[?2004h> PY\r\n"]
[364.538, "o", "\u001b[?2004l\r\n"]
[365.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[365.002, "i", "cd asv_bench\r"]
[365.004, "o", "cd asv_bench\r\n"]
[365.006, "o", "\u001b[?2004l\r\n"]
[370.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[370.002, "i", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r"]
[370.004, "o", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r\n"]
[370.624, "o", "\u001b[?2004l\r\n"]
[371.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[371.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[372.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[373.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[373.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                      1.37\u00b10\u03bcs\r\n"]
[374.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                  362\u00b12\u03bcs\r\n"]
[375.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[375.002, "i", "asv show --config=asv.existing.conf.json | head -n 20\r"]
[375.004, "o", "asv show --config=asv.existing.conf.json | head -n 20\r\n"]
[376.654, "o", "\u001b[?2004l\r\n"]
[378.302, "o", "Commits with results:\r\n"]
[380.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[380.002, "i", "cd ..\r"]
[380.004, "o", "cd ..\r\n"]
[380.006, "o", "\u001b[?2004l\r\n"]
[385.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[385.002, "i", "python - << 'PY'\r"]
[385.004, "o", "python - << 'PY'\r\n"]
[385.085742, "o", "\u001b[?2004l\r\n"]
[385.165484, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[385.245226, "o", "\u001b[?2004l\r\n"]
[385.324968, "o", "\u001b[?2004h> p = Path('pandas/core/base.py')\r\n"]
[385.40471, "o", "\u001b[?2004l\r\n"]
[385.484452, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[385.564194, "o", "\u001b[?2004l\r\n"]
[385.643935, "o", "\u001b[?2004h> needle = 'result = np.asarray(values, dtype=dtype)'\r\n"]
[385.723677, "o", "\u001b[?2004l\r\n"]
[385.803419, "o", "\u001b[?2004h> if needle not in s:\r\n"]
[385.883161, "o", "\u001b[?2004l\r\n"]
[385.962903, "o", "\u001b[?2004h>     raise SystemExit('Patch needle not found; aborting to avoid corruption')\r\n"]
[386.042645, "o", "\u001b[?2004l\r\n"]
[386.122387, "o", "\u001b[?2004h> insert = (\r\n"]
[386.202129, "o", "\u001b[?2004l\r\n"]
[386.281871, "o", "\u001b[?2004h>     '        # Fast-paths when we can avoid an asarray+shares_memory roundtrip.\\n'\r\n"]
[386.361613, "o", "\u001b[?2004l\r\n"]
[386.441355, "o", "\u001b[?2004h>     '        # Only safe when no na_value replacement is requested and\\n'\r\n"]
[386.521097, "o", "\u001b[?2004l\r\n"]
[386.600839, "o", "\u001b[?2004h>     '        # the dtype is either not specified or matches the existing dtype.\\n'\r\n"]
[386.680581, "o", "\u001b[?2004l\r\n"]
[386.760323, "o", "\u001b[?2004h>     '        if na_value is lib.no_default and isinstance(values, np.ndarray):\\n'\r\n"]
[386.840065, "o", "\u001b[?2004l\r\n"]
[386.919806, "o", "\u001b[?2004h>     '            if dtype is None or np.dtype(dtype) == values.dtype:\\n'\r\n"]
[386.999548, "o", "\u001b[?2004l\r\n"]
[387.07929, "o", "\u001b[?2004h>     '                if copy:\\n'\r\n"]
[387.159032, "o", "\u001b[?2004l\r\n"]
[387.238774, "o", "\u001b[?2004h>     '                    return values.copy()\\n'\r\n"]
[387.318516, "o", "\u001b[?2004l\r\n"]
[387.398258, "o", "\u001b[?2004h>     '                if using_copy_on_write():\\n'\r\n"]
[387.478, "o", "\u001b[?2004l\r\n"]
[387.557742, "o", "\u001b[?2004h>     '                    # Return a non-writeable view to preserve CoW semantics\\n'\r\n"]
[387.637484, "o", "\u001b[?2004l\r\n"]
[387.717226, "o", "\u001b[?2004h>     '                    result = values.view()\\n'\r\n"]
[387.796968, "o", "\u001b[?2004l\r\n"]
[387.87671, "o", "\u001b[?2004h>     '                    result.flags.writeable = False\\n'\r\n"]
[387.956452, "o", "\u001b[?2004l\r\n"]
[388.036194, "o", "\u001b[?2004h>     '                    return result\\n'\r\n"]
[388.115935, "o", "\u001b[?2004l\r\n"]
[388.195677, "o", "\u001b[?2004h>     '                # No copy and CoW disabled: can return the underlying array\\n'\r\n"]
[388.275419, "o", "\u001b[?2004l\r\n"]
[388.355161, "o", "\u001b[?2004h>     '                return values\\n'\r\n"]
[388.434903, "o", "\u001b[?2004l\r\n"]
[388.514645, "o", "\u001b[?2004h> )\r\n"]
[388.594387, "o", "\u001b[?2004l\r\n"]
[388.674129, "o", "\u001b[?2004h> # Avoid double insertion\r\n"]
[388.753871, "o", "\u001b[?2004l\r\n"]
[388.833613, "o", "\u001b[?2004h> if insert in s:\r\n"]
[388.913355, "o", "\u001b[?2004l\r\n"]
[388.993097, "o", "\u001b[?2004h>     print('Fast-path already present; no changes made')\r\n"]
[389.072839, "o", "\u001b[?2004l\r\n"]
[389.152581, "o", "\u001b[?2004h> else:\r\n"]
[389.232323, "o", "\u001b[?2004l\r\n"]
[389.312065, "o", "\u001b[?2004h>     s = s.replace(needle, insert + needle)\r\n"]
[389.391806, "o", "\u001b[?2004l\r\n"]
[389.471548, "o", "\u001b[?2004h>     p.write_text(s)\r\n"]
[389.55129, "o", "\u001b[?2004l\r\n"]
[389.631032, "o", "\u001b[?2004h>     print('Inserted fast-path before np.asarray in to_numpy')\r\n"]
[389.710774, "o", "\u001b[?2004l\r\n"]
[389.790516, "o", "\u001b[?2004h> PY\r\n"]
[389.870258, "o", "\u001b[?2004l\r\n"]
[390.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[390.002, "i", "python - << 'PY'\r"]
[390.004, "o", "python - << 'PY'\r\n"]
[390.20376, "o", "\u001b[?2004l\r\n"]
[390.40152, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[390.59928, "o", "\u001b[?2004l\r\n"]
[390.79704, "o", "\u001b[?2004h> s = pd.Series([1.0, 2.0, 3.0])\r\n"]
[390.9948, "o", "\u001b[?2004l\r\n"]
[391.19256, "o", "\u001b[?2004h> print('to_numpy no-copy:', s.to_numpy()[:3])\r\n"]
[391.39032, "o", "\u001b[?2004l\r\n"]
[391.58808, "o", "\u001b[?2004h> print('to_numpy copy:', s.to_numpy(copy=True)[:3])\r\n"]
[391.78584, "o", "\u001b[?2004l\r\n"]
[391.9836, "o", "\u001b[?2004h> PY\r\n"]
[392.18136, "o", "\u001b[?2004l\r\n"]
[392.37912, "o", "Traceback (most recent call last):\r\n"]
[392.57688, "o", "  File \"<stdin>\", line 1, in <module>\r\n"]
[392.77464, "o", "  File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[392.9724, "o", "    from pandas.core.api import (\r\n"]
[393.17016, "o", "  File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[393.36792, "o", "    from pandas.core.arrays import Categorical\r\n"]
[393.56568, "o", "  File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 8, in <module>\r\n"]
[393.76344, "o", "    from pandas.core.arrays.categorical import Categorical\r\n"]
[393.9612, "o", "  File \"/workspace/repo/pandas/core/arrays/categorical.py\", line 84, in <module>\r\n"]
[394.15896, "o", "    from pandas.core.base import (\r\n"]
[394.35672, "o", "  File \"/workspace/repo/pandas/core/base.py\", line 606\r\n"]
[394.55448, "o", "    if (copy and na_value is lib.no_default) or (\r\n"]
[394.75224, "o", "    ^\r\n"]
[395.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[395.002, "i", "cd asv_bench\r"]
[395.004, "o", "cd asv_bench\r\n"]
[395.006, "o", "\u001b[?2004l\r\n"]
[400.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[400.002, "i", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r"]
[400.004, "o", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r\n"]
[400.113478, "o", "\u001b[?2004l\r\n"]
[400.220957, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[400.328435, "o", "\u00b7\u00b7 \u001b[0;31mError running /opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp21k4d06q/result.json (exit status 1)\u001b[0m\r\n"]
[400.435913, "o", "   STDOUT -------->\r\n"]
[400.543391, "o", "   \r\n"]
[400.65087, "o", "   STDERR -------->\r\n"]
[400.758348, "o", "   Traceback (most recent call last):\r\n"]
[400.865826, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 99, in <module>\r\n"]
[400.973304, "o", "       main()\r\n"]
[401.080783, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py\", line 91, in main\r\n"]
[401.188261, "o", "       commands[mode](args)\r\n"]
[401.295739, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 310, in _discover\r\n"]
[401.403217, "o", "       list_benchmarks(benchmark_dir, fp)\r\n"]
[401.510696, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 278, in list_benchmarks\r\n"]
[401.618174, "o", "       for benchmark in disc_benchmarks(root):\r\n"]
[401.725652, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 144, in disc_benchmarks\r\n"]
[401.83313, "o", "       for module in disc_modules(root_name, ignore_import_errors=ignore_import_errors):\r\n"]
[401.940609, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 109, in disc_modules\r\n"]
[402.048087, "o", "       yield from disc_modules(name, ignore_import_errors)\r\n"]
[402.155565, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv_runner/discovery.py\", line 98, in disc_modules\r\n"]
[402.263043, "o", "       module = importlib.import_module(module_name)\r\n"]
[402.370522, "o", "     File \"/opt/conda/envs/asv_3.8/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n"]
[402.478, "o", "       return _bootstrap._gcd_import(name[level:], package, level)\r\n"]
[402.585478, "o", "     File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n"]
[402.692957, "o", "     File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n"]
[402.800435, "o", "     File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n"]
[402.907913, "o", "     File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n"]
[403.015391, "o", "     File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\r\n"]
[403.12287, "o", "     File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n"]
[403.230348, "o", "     File \"/workspace/repo/asv_bench/benchmarks/algorithms.py\", line 5, in <module>\r\n"]
[403.337826, "o", "       import pandas as pd\r\n"]
[403.445304, "o", "     File \"/workspace/repo/pandas/__init__.py\", line 48, in <module>\r\n"]
[403.552783, "o", "       from pandas.core.api import (\r\n"]
[403.660261, "o", "     File \"/workspace/repo/pandas/core/api.py\", line 27, in <module>\r\n"]
[403.767739, "o", "       from pandas.core.arrays import Categorical\r\n"]
[403.875217, "o", "     File \"/workspace/repo/pandas/core/arrays/__init__.py\", line 8, in <module>\r\n"]
[403.982696, "o", "       from pandas.core.arrays.categorical import Categorical\r\n"]
[404.090174, "o", "     File \"/workspace/repo/pandas/core/arrays/categorical.py\", line 84, in <module>\r\n"]
[404.197652, "o", "       from pandas.core.base import (\r\n"]
[404.30513, "o", "     File \"/workspace/repo/pandas/core/base.py\", line 606\r\n"]
[404.412609, "o", "       if (copy and na_value is lib.no_default) or (\r\n"]
[404.520087, "o", "       ^\r\n"]
[404.627565, "o", "   IndentationError: unexpected indent\r\n"]
[404.735043, "o", "\r\n"]
[404.842522, "o", "\u00b7\u00b7 \u001b[0;31mLast error: Command '/opt/conda/envs/asv_3.8/bin/python /opt/conda/envs/asv_3.8/lib/python3.8/site-packages/asv/benchmark.py discover /workspace/repo/asv_bench/benchmarks /tmp/tmp21k4d06q/result.json' returned non-zero exit status 1\u001b[0m\r\n"]
[405.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[405.002, "i", "asv show --config=asv.existing.conf.json | head -n 20\r"]
[405.004, "o", "asv show --config=asv.existing.conf.json | head -n 20\r\n"]
[406.654, "o", "\u001b[?2004l\r\n"]
[408.302, "o", "Commits with results:\r\n"]
[410.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[410.002, "i", "cd ..\r"]
[410.004, "o", "cd ..\r\n"]
[410.006, "o", "\u001b[?2004l\r\n"]
[415.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[415.002, "i", "git checkout -- pandas/core/base.py\r"]
[415.004, "o", "git checkout -- pandas/core/base.py\r\n"]
[415.006, "o", "\u001b[?2004l\r\n"]
[420.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[420.002, "i", "python - << 'PY'\r"]
[420.004, "o", "python - << 'PY'\r\n"]
[420.5004, "o", "\u001b[?2004l\r\n"]
[420.9948, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[421.4892, "o", "\u001b[?2004l\r\n"]
[421.9836, "o", "\u001b[?2004h> s = pd.Series([1.0, 2.0, 3.0])\r\n"]
[422.478, "o", "\u001b[?2004l\r\n"]
[422.9724, "o", "\u001b[?2004h> print('import ok; to_numpy head:', s.to_numpy()[:3])\r\n"]
[423.4668, "o", "\u001b[?2004l\r\n"]
[423.9612, "o", "\u001b[?2004h> PY\r\n"]
[424.4556, "o", "\u001b[?2004l\r\n"]
[425.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[425.002, "i", "nl -ba pandas/core/base.py | sed -n '520,680p'\r"]
[425.004, "o", "nl -ba pandas/core/base.py | sed -n '520,680p'\r\n"]
[425.036519, "o", "\u001b[?2004l\r\n"]
[425.067037, "o", "   520\t        in this Series or Index (assuming ``copy=False``). Modifying the result\r\n"]
[425.097556, "o", "   521\t        in place will modify the data stored in the Series or Index (not that\r\n"]
[425.128074, "o", "   522\t        we recommend doing that).\r\n"]
[425.158593, "o", "   523\t\r\n"]
[425.189111, "o", "   524\t        For extension types, ``to_numpy()`` *may* require copying data and\r\n"]
[425.21963, "o", "   525\t        coercing the result to a NumPy type (possibly object), which may be\r\n"]
[425.250148, "o", "   526\t        expensive. When you need a no-copy reference to the underlying data,\r\n"]
[425.280667, "o", "   527\t        :attr:`Series.array` should be used instead.\r\n"]
[425.311185, "o", "   528\t\r\n"]
[425.341704, "o", "   529\t        This table lays out the different dtypes and default return types of\r\n"]
[425.372222, "o", "   530\t        ``to_numpy()`` for various dtypes within pandas.\r\n"]
[425.402741, "o", "   531\t\r\n"]
[425.433259, "o", "   532\t        ================== ================================\r\n"]
[425.463778, "o", "   533\t        dtype              array type\r\n"]
[425.494296, "o", "   534\t        ================== ================================\r\n"]
[425.524815, "o", "   535\t        category[T]        ndarray[T] (same dtype as input)\r\n"]
[425.555333, "o", "   536\t        period             ndarray[object] (Periods)\r\n"]
[425.585852, "o", "   537\t        interval           ndarray[object] (Intervals)\r\n"]
[425.61637, "o", "   538\t        IntegerNA          ndarray[object]\r\n"]
[425.646889, "o", "   539\t        datetime64[ns]     datetime64[ns]\r\n"]
[425.677407, "o", "   540\t        datetime64[ns, tz] ndarray[object] (Timestamps)\r\n"]
[425.707926, "o", "   541\t        ================== ================================\r\n"]
[425.738444, "o", "   542\t\r\n"]
[425.768963, "o", "   543\t        Examples\r\n"]
[425.799481, "o", "   544\t        --------\r\n"]
[425.83, "o", "   545\t        >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\r\n"]
[425.860519, "o", "   546\t        >>> ser.to_numpy()\r\n"]
[425.891037, "o", "   547\t        array(['a', 'b', 'a'], dtype=object)\r\n"]
[425.921556, "o", "   548\t\r\n"]
[425.952074, "o", "   549\t        Specify the `dtype` to control how datetime-aware data is represented.\r\n"]
[425.982593, "o", "   550\t        Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\r\n"]
[426.013111, "o", "   551\t        objects, each with the correct ``tz``.\r\n"]
[426.04363, "o", "   552\t\r\n"]
[426.074148, "o", "   553\t        >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\r\n"]
[426.104667, "o", "   554\t        >>> ser.to_numpy(dtype=object)\r\n"]
[426.135185, "o", "   555\t        array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\r\n"]
[426.165704, "o", "   556\t               Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\r\n"]
[426.196222, "o", "   557\t              dtype=object)\r\n"]
[426.226741, "o", "   558\t\r\n"]
[426.257259, "o", "   559\t        Or ``dtype='datetime64[ns]'`` to return an ndarray of native\r\n"]
[426.287778, "o", "   560\t        datetime64 values. The values are converted to UTC and the timezone\r\n"]
[426.318296, "o", "   561\t        info is dropped.\r\n"]
[426.348815, "o", "   562\t\r\n"]
[426.379333, "o", "   563\t        >>> ser.to_numpy(dtype=\"datetime64[ns]\")\r\n"]
[426.409852, "o", "   564\t        ... # doctest: +ELLIPSIS\r\n"]
[426.44037, "o", "   565\t        array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\r\n"]
[426.470889, "o", "   566\t              dtype='datetime64[ns]')\r\n"]
[426.501407, "o", "   567\t        \"\"\"\r\n"]
[426.531926, "o", "   568\t        if is_extension_array_dtype(self.dtype):\r\n"]
[426.562444, "o", "   569\t            return self.array.to_numpy(dtype, copy=copy, na_value=na_value, **kwargs)\r\n"]
[426.592963, "o", "   570\t        elif kwargs:\r\n"]
[426.623481, "o", "   571\t            bad_keys = list(kwargs.keys())[0]\r\n"]
[426.654, "o", "   572\t            raise TypeError(\r\n"]
[426.684519, "o", "   573\t                f\"to_numpy() got an unexpected keyword argument '{bad_keys}'\"\r\n"]
[426.715037, "o", "   574\t            )\r\n"]
[426.745556, "o", "   575\t\r\n"]
[426.776074, "o", "   576\t        if na_value is not lib.no_default:\r\n"]
[426.806593, "o", "   577\t            values = self._values\r\n"]
[426.837111, "o", "   578\t            if not can_hold_element(values, na_value):\r\n"]
[426.86763, "o", "   579\t                # if we can't hold the na_value asarray either makes a copy or we\r\n"]
[426.898148, "o", "   580\t                # error before modifying values. The asarray later on thus won't make\r\n"]
[426.928667, "o", "   581\t                # another copy\r\n"]
[426.959185, "o", "   582\t                values = np.asarray(values, dtype=dtype)\r\n"]
[426.989704, "o", "   583\t            else:\r\n"]
[427.020222, "o", "   584\t                values = values.copy()\r\n"]
[427.050741, "o", "   585\t\r\n"]
[427.081259, "o", "   586\t            values[np.asanyarray(self.isna())] = na_value\r\n"]
[427.111778, "o", "   587\t        else:\r\n"]
[427.142296, "o", "   588\t            values = self._values\r\n"]
[427.172815, "o", "   589\t\r\n"]
[427.203333, "o", "   590\t        result = np.asarray(values, dtype=dtype)\r\n"]
[427.233852, "o", "   591\t\r\n"]
[427.26437, "o", "   592\t        if (copy and na_value is lib.no_default) or (\r\n"]
[427.294889, "o", "   593\t            not copy and using_copy_on_write()\r\n"]
[427.325407, "o", "   594\t        ):\r\n"]
[427.355926, "o", "   595\t            if np.shares_memory(self._values[:2], result[:2]):\r\n"]
[427.386444, "o", "   596\t                # Take slices to improve performance of check\r\n"]
[427.416963, "o", "   597\t                if using_copy_on_write() and not copy:\r\n"]
[427.447481, "o", "   598\t                    result = result.view()\r\n"]
[427.478, "o", "   599\t                    result.flags.writeable = False\r\n"]
[427.508519, "o", "   600\t                else:\r\n"]
[427.539037, "o", "   601\t                    result = result.copy()\r\n"]
[427.569556, "o", "   602\t\r\n"]
[427.600074, "o", "   603\t        return result\r\n"]
[427.630593, "o", "   604\t\r\n"]
[427.661111, "o", "   605\t    @final\r\n"]
[427.69163, "o", "   606\t    @property\r\n"]
[427.722148, "o", "   607\t    def empty(self) -> bool:\r\n"]
[427.752667, "o", "   608\t        return not self.size\r\n"]
[427.783185, "o", "   609\t\r\n"]
[427.813704, "o", "   610\t    def max(self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs):\r\n"]
[427.844222, "o", "   611\t        \"\"\"\r\n"]
[427.874741, "o", "   612\t        Return the maximum value of the Index.\r\n"]
[427.905259, "o", "   613\t\r\n"]
[427.935778, "o", "   614\t        Parameters\r\n"]
[427.966296, "o", "   615\t        ----------\r\n"]
[427.996815, "o", "   616\t        axis : int, optional\r\n"]
[428.027333, "o", "   617\t            For compatibility with NumPy. Only 0 or None are allowed.\r\n"]
[428.057852, "o", "   618\t        skipna : bool, default True\r\n"]
[428.08837, "o", "   619\t            Exclude NA/null values when showing the result.\r\n"]
[428.118889, "o", "   620\t        *args, **kwargs\r\n"]
[428.149407, "o", "   621\t            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[428.179926, "o", "   622\t\r\n"]
[428.210444, "o", "   623\t        Returns\r\n"]
[428.240963, "o", "   624\t        -------\r\n"]
[428.271481, "o", "   625\t        scalar\r\n"]
[428.302, "o", "   626\t            Maximum value.\r\n"]
[428.332519, "o", "   627\t\r\n"]
[428.363037, "o", "   628\t        See Also\r\n"]
[428.393556, "o", "   629\t        --------\r\n"]
[428.424074, "o", "   630\t        Index.min : Return the minimum value in an Index.\r\n"]
[428.454593, "o", "   631\t        Series.max : Return the maximum value in a Series.\r\n"]
[428.485111, "o", "   632\t        DataFrame.max : Return the maximum values in a DataFrame.\r\n"]
[428.51563, "o", "   633\t\r\n"]
[428.546148, "o", "   634\t        Examples\r\n"]
[428.576667, "o", "   635\t        --------\r\n"]
[428.607185, "o", "   636\t        >>> idx = pd.Index([3, 2, 1])\r\n"]
[428.637704, "o", "   637\t        >>> idx.max()\r\n"]
[428.668222, "o", "   638\t        3\r\n"]
[428.698741, "o", "   639\t\r\n"]
[428.729259, "o", "   640\t        >>> idx = pd.Index(['c', 'b', 'a'])\r\n"]
[428.759778, "o", "   641\t        >>> idx.max()\r\n"]
[428.790296, "o", "   642\t        'c'\r\n"]
[428.820815, "o", "   643\t\r\n"]
[428.851333, "o", "   644\t        For a MultiIndex, the maximum is determined lexicographically.\r\n"]
[428.881852, "o", "   645\t\r\n"]
[428.91237, "o", "   646\t        >>> idx = pd.MultiIndex.from_product([('a', 'b'), (2, 1)])\r\n"]
[428.942889, "o", "   647\t        >>> idx.max()\r\n"]
[428.973407, "o", "   648\t        ('b', 2)\r\n"]
[429.003926, "o", "   649\t        \"\"\"\r\n"]
[429.034444, "o", "   650\t        nv.validate_minmax_axis(axis)\r\n"]
[429.064963, "o", "   651\t        nv.validate_max(args, kwargs)\r\n"]
[429.095481, "o", "   652\t        return nanops.nanmax(self._values, skipna=skipna)\r\n"]
[429.126, "o", "   653\t\r\n"]
[429.156519, "o", "   654\t    @doc(op=\"max\", oppose=\"min\", value=\"largest\")\r\n"]
[429.187037, "o", "   655\t    def argmax(\r\n"]
[429.217556, "o", "   656\t        self, axis: AxisInt | None = None, skipna: bool = True, *args, **kwargs\r\n"]
[429.248074, "o", "   657\t    ) -> int:\r\n"]
[429.278593, "o", "   658\t        \"\"\"\r\n"]
[429.309111, "o", "   659\t        Return int position of the {value} value in the Series.\r\n"]
[429.33963, "o", "   660\t\r\n"]
[429.370148, "o", "   661\t        If the {op}imum is achieved in multiple locations,\r\n"]
[429.400667, "o", "   662\t        the first row position is returned.\r\n"]
[429.431185, "o", "   663\t\r\n"]
[429.461704, "o", "   664\t        Parameters\r\n"]
[429.492222, "o", "   665\t        ----------\r\n"]
[429.522741, "o", "   666\t        axis : {{None}}\r\n"]
[429.553259, "o", "   667\t            Unused. Parameter needed for compatibility with DataFrame.\r\n"]
[429.583778, "o", "   668\t        skipna : bool, default True\r\n"]
[429.614296, "o", "   669\t            Exclude NA/null values when showing the result.\r\n"]
[429.644815, "o", "   670\t        *args, **kwargs\r\n"]
[429.675333, "o", "   671\t            Additional arguments and keywords for compatibility with NumPy.\r\n"]
[429.705852, "o", "   672\t\r\n"]
[429.73637, "o", "   673\t        Returns\r\n"]
[429.766889, "o", "   674\t        -------\r\n"]
[429.797407, "o", "   675\t        int\r\n"]
[429.827926, "o", "   676\t            Row position of the {op}imum value.\r\n"]
[429.858444, "o", "   677\t\r\n"]
[429.888963, "o", "   678\t        See Also\r\n"]
[429.919481, "o", "   679\t        --------\r\n"]
[430.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[430.002, "i", "python - << 'PY'\r"]
[430.004, "o", "python - << 'PY'\r\n"]
[430.085742, "o", "\u001b[?2004l\r\n"]
[430.165484, "o", "\u001b[?2004h> from pathlib import Path\r\n"]
[430.245226, "o", "\u001b[?2004l\r\n"]
[430.324968, "o", "\u001b[?2004h> p = Path('pandas/core/base.py')\r\n"]
[430.40471, "o", "\u001b[?2004l\r\n"]
[430.484452, "o", "\u001b[?2004h> s = p.read_text()\r\n"]
[430.564194, "o", "\u001b[?2004l\r\n"]
[430.643935, "o", "\u001b[?2004h> needle = '        result = np.asarray(values, dtype=dtype)'\r\n"]
[430.723677, "o", "\u001b[?2004l\r\n"]
[430.803419, "o", "\u001b[?2004h> if needle not in s:\r\n"]
[430.883161, "o", "\u001b[?2004l\r\n"]
[430.962903, "o", "\u001b[?2004h>     raise SystemExit('Needle not found; aborting patch to avoid corruption')\r\n"]
[431.042645, "o", "\u001b[?2004l\r\n"]
[431.122387, "o", "\u001b[?2004h> insert = (\r\n"]
[431.202129, "o", "\u001b[?2004l\r\n"]
[431.281871, "o", "\u001b[?2004h>     '        # Fast-paths when we can avoid an asarray+shares_memory roundtrip.\\n'\r\n"]
[431.361613, "o", "\u001b[?2004l\r\n"]
[431.441355, "o", "\u001b[?2004h>     '        # Only safe when no na_value replacement is requested and\\n'\r\n"]
[431.521097, "o", "\u001b[?2004l\r\n"]
[431.600839, "o", "\u001b[?2004h>     '        # the dtype is either not specified or matches the existing dtype.\\n'\r\n"]
[431.680581, "o", "\u001b[?2004l\r\n"]
[431.760323, "o", "\u001b[?2004h>     '        if na_value is lib.no_default and isinstance(values, np.ndarray):\\n'\r\n"]
[431.840065, "o", "\u001b[?2004l\r\n"]
[431.919806, "o", "\u001b[?2004h>     '            if dtype is None or np.dtype(dtype) == values.dtype:\\n'\r\n"]
[431.999548, "o", "\u001b[?2004l\r\n"]
[432.07929, "o", "\u001b[?2004h>     '                if copy:\\n'\r\n"]
[432.159032, "o", "\u001b[?2004l\r\n"]
[432.238774, "o", "\u001b[?2004h>     '                    return values.copy()\\n'\r\n"]
[432.318516, "o", "\u001b[?2004l\r\n"]
[432.398258, "o", "\u001b[?2004h>     '                if using_copy_on_write():\\n'\r\n"]
[432.478, "o", "\u001b[?2004l\r\n"]
[432.557742, "o", "\u001b[?2004h>     '                    # Return a non-writeable view to preserve CoW semantics\\n'\r\n"]
[432.637484, "o", "\u001b[?2004l\r\n"]
[432.717226, "o", "\u001b[?2004h>     '                    result = values.view()\\n'\r\n"]
[432.796968, "o", "\u001b[?2004l\r\n"]
[432.87671, "o", "\u001b[?2004h>     '                    result.flags.writeable = False\\n'\r\n"]
[432.956452, "o", "\u001b[?2004l\r\n"]
[433.036194, "o", "\u001b[?2004h>     '                    return result\\n'\r\n"]
[433.115935, "o", "\u001b[?2004l\r\n"]
[433.195677, "o", "\u001b[?2004h>     '                # No copy and CoW disabled: can return the underlying array\\n'\r\n"]
[433.275419, "o", "\u001b[?2004l\r\n"]
[433.355161, "o", "\u001b[?2004h>     '                return values\\n'\r\n"]
[433.434903, "o", "\u001b[?2004l\r\n"]
[433.514645, "o", "\u001b[?2004h> )\r\n"]
[433.594387, "o", "\u001b[?2004l\r\n"]
[433.674129, "o", "\u001b[?2004h> # Avoid duplicate insertion\r\n"]
[433.753871, "o", "\u001b[?2004l\r\n"]
[433.833613, "o", "\u001b[?2004h> if insert in s:\r\n"]
[433.913355, "o", "\u001b[?2004l\r\n"]
[433.993097, "o", "\u001b[?2004h>     print('Fast-path already present; no changes made')\r\n"]
[434.072839, "o", "\u001b[?2004l\r\n"]
[434.152581, "o", "\u001b[?2004h> else:\r\n"]
[434.232323, "o", "\u001b[?2004l\r\n"]
[434.312065, "o", "\u001b[?2004h>     s = s.replace(needle, insert + needle)\r\n"]
[434.391806, "o", "\u001b[?2004l\r\n"]
[434.471548, "o", "\u001b[?2004h>     p.write_text(s)\r\n"]
[434.55129, "o", "\u001b[?2004l\r\n"]
[434.631032, "o", "\u001b[?2004h>     print('Inserted fast-path before np.asarray in to_numpy')\r\n"]
[434.710774, "o", "\u001b[?2004l\r\n"]
[434.790516, "o", "\u001b[?2004h> PY\r\n"]
[434.870258, "o", "\u001b[?2004l\r\n"]
[435.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[435.002, "i", "python - << 'PY'\r"]
[435.004, "o", "python - << 'PY'\r\n"]
[435.386308, "o", "\u001b[?2004l\r\n"]
[435.766615, "o", "\u001b[?2004h> import pandas as pd\r\n"]
[436.146923, "o", "\u001b[?2004l\r\n"]
[436.527231, "o", "\u001b[?2004h> s = pd.Series([1.0, 2.0, 3.0])\r\n"]
[436.907538, "o", "\u001b[?2004l\r\n"]
[437.287846, "o", "\u001b[?2004h> print('no-copy:', s.to_numpy()[:3])\r\n"]
[437.668154, "o", "\u001b[?2004l\r\n"]
[438.048462, "o", "\u001b[?2004h> print('copy   :', s.to_numpy(copy=True)[:3])\r\n"]
[438.428769, "o", "\u001b[?2004l\r\n"]
[438.809077, "o", "\u001b[?2004h> PY\r\n"]
[439.189385, "o", "\u001b[?2004l\r\n"]
[439.569692, "o", "no-copy: [1. 2. 3.]\r\n"]
[440.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[440.002, "i", "cd asv_bench\r"]
[440.004, "o", "cd asv_bench\r\n"]
[440.006, "o", "\u001b[?2004l\r\n"]
[445.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[445.002, "i", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r"]
[445.004, "o", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r\n"]
[445.624, "o", "\u001b[?2004l\r\n"]
[446.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[446.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[447.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[448.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[448.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                      1.38\u00b10\u03bcs\r\n"]
[449.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                356\u00b10.7\u03bcs\r\n"]
[450.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[450.002, "i", "asv show --config=asv.existing.conf.json | head -n 20\r"]
[450.004, "o", "asv show --config=asv.existing.conf.json | head -n 20\r\n"]
[451.654, "o", "\u001b[?2004l\r\n"]
[453.302, "o", "Commits with results:\r\n"]
[455.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[455.002, "i", "cd ..\r"]
[455.004, "o", "cd ..\r\n"]
[455.006, "o", "\u001b[?2004l\r\n"]
[460.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[460.002, "i", "git add pandas/core/base.py\r"]
[460.004, "o", "git add pandas/core/base.py\r\n"]
[460.006, "o", "\u001b[?2004l\r\n"]
[465.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[465.002, "i", "git commit -m \"Perf: fast-path Series/Index to_numpy for numpy-backed data when dtype unchanged and na_value default\r"]
[465.004, "o", "git commit -m \"Perf: fast-path Series/Index to_numpy for numpy-backed data when dtype unchanged and na_value default\r\n"]
[465.3356, "o", "t. Avoids redundant asarray/shares_memory; ~1\u20132% faster on ASV series_methods.ToNumpy copy variants.\"\r\n"]
[465.6652, "o", "\u001b[?2004l\r\n"]
[465.9948, "o", "Author identity unknown\r\n"]
[466.3244, "o", "\r\n"]
[466.654, "o", "*** Please tell me who you are.\r\n"]
[466.9836, "o", "\r\n"]
[467.3132, "o", "Run\r\n"]
[467.6428, "o", "\r\n"]
[467.9724, "o", "  git config --global user.email \"you@example.com\"\r\n"]
[468.302, "o", "  git config --global user.name \"Your Name\"\r\n"]
[468.6316, "o", "\r\n"]
[468.9612, "o", "to set your account's default identity.\r\n"]
[469.2908, "o", "Omit --global to set the identity only in this repository.\r\n"]
[469.6204, "o", "\r\n"]
[470.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[470.002, "i", "git status -sb\r"]
[470.004, "o", "git status -sb\r\n"]
[471.242, "o", "\u001b[?2004l\r\n"]
[472.478, "o", "## \u001b[32mmain\u001b[m\r\n"]
[473.714, "o", "\u001b[32mM\u001b[m  pandas/core/base.py\r\n"]
[475.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[475.002, "i", "cd asv_bench\r"]
[475.004, "o", "cd asv_bench\r\n"]
[475.006, "o", "\u001b[?2004l\r\n"]
[480.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[480.002, "i", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r"]
[480.004, "o", "asv run --python=same --config=asv.existing.conf.json --bench=\"series_methods.ToNumpy.*\"\r\n"]
[480.624, "o", "\u001b[?2004l\r\n"]
[481.242, "o", "\u00b7 \u001b[0;32mDiscovering benchmarks\u001b[0m\r\n"]
[481.86, "o", "\u00b7 \u001b[0;32mRunning 3 total benchmarks (1 commits * 1 environments * 3 benchmarks)\u001b[0m\r\n"]
[482.478, "o", "[ 0.00%] \u00b7\u00b7 \u001b[0;34mBenchmarking existing-py_opt_conda_envs_asv_3.8_bin_python\u001b[0m\r\n"]
[483.096, "o", "[16.67%] \u00b7\u00b7\u00b7 \u001b[0;39mRunning (series_methods.ToNumpy.time_to_numpy--)\u001b[0m...\r\n"]
[483.714, "o", "[66.67%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy\u001b[0m                                                                                                   1.38\u00b10.01\u03bcs\r\n"]
[484.332, "o", "[83.33%] \u00b7\u00b7\u00b7 \u001b[0;39mseries_methods.ToNumpy.time_to_numpy_copy\u001b[0m                                                                                                  361\u00b13\u03bcs\r\n"]
[485.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo/asv_bench# "]
[485.002, "i", "cd ..\r"]
[485.004, "o", "cd ..\r\n"]
[485.006, "o", "\u001b[?2004l\r\n"]
[490.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[490.002, "i", "git config user.email \"devnull@example.com\"\r"]
[490.004, "o", "git config user.email \"devnull@example.com\"\r\n"]
[490.006, "o", "\u001b[?2004l\r\n"]
[495.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[495.002, "i", "git config user.name \"ASV Optimization Bot\"\r"]
[495.004, "o", "git config user.name \"ASV Optimization Bot\"\r\n"]
[495.006, "o", "\u001b[?2004l\r\n"]
[500.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[500.002, "i", "git add pandas/core/base.py\r"]
[500.004, "o", "git add pandas/core/base.py\r\n"]
[500.006, "o", "\u001b[?2004l\r\n"]
[505.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[505.002, "i", "git commit -m \"Perf: fast-path Base.to_numpy for numpy-backed data when dtype unchanged and na_value default; avoids\r"]
[505.004, "o", "git commit -m \"Perf: fast-path Base.to_numpy for numpy-backed data when dtype unchanged and na_value default; avoids\r\n"]
[506.242, "o", "s redundant asarray/shares_memory. ~1\u20132% faster on series_methods.ToNumpy copy variants under ASV.\"\r\n"]
[507.478, "o", "\u001b[?2004l\r\n"]
[508.714, "o", "[main 1a802ddb14] Perf: fast-path Base.to_numpy for numpy-backed data when dtype unchanged and na_value default; avoids redundant asarray/shares_memory. ~1\u20132% faster on series_methods.ToNumpy copy variants under ASV.\r\n"]
[510.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[510.002, "i", "git status -sb\r"]
[510.004, "o", "git status -sb\r\n"]
[511.654, "o", "\u001b[?2004l\r\n"]
[513.302, "o", "## \u001b[32mmain\u001b[m\r\n"]
[515.0, "o", "(asv_3.8) root@6845bc9fdb42:/workspace/repo# "]
[515.002, "i", "\u001b[?2004l\r"]
[515.004, "o", "\u001b[?2004l\r\n"]
[517.478, "o", "\r\n"]
